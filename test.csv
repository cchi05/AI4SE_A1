code
"public static String convertTz(String dateStr, String format, String tzFrom, String tzTo) {
		return dateFormatTz(toTimestampTz(dateStr, format, tzFrom), tzTo);
	}"
"@SafeVarargs
	public static <T> Collection<T> union(Collection<T> coll1, Collection<T> coll2, Collection<T>... otherColls) {
		Collection<T> union = union(coll1, coll2);
		for (Collection<T> coll : otherColls) {
			union = union(union, coll);
		}
		return union;
	}"
"public static <K,V> List<Pair<K,V>> mapToPair(Map<K,V> map) {
        List<Pair<K,V>> ret = new ArrayList<>(map.size());
        for(Map.Entry<K,V> entry : map.entrySet()) {
            ret.add(Pair.of(entry.getKey(),entry.getValue()));
        }

        return ret;
    }"
"private void compactPartition(final int partitionNumber) throws IOException {
		// do nothing if table was closed, parameter is invalid or no garbage exists
		if (this.closed || partitionNumber >= this.partitions.size() || this.partitions.get(partitionNumber).isCompacted()) {
			return;
		}
		// release all segments owned by compaction partition
		this.compactionMemory.clearAllMemory(availableMemory);
		this.compactionMemory.allocateSegments(1);
		this.compactionMemory.pushDownPages();
		T tempHolder = this.buildSideSerializer.createInstance();
		final int numPartitions = this.partitions.size();
		InMemoryPartition<T> partition = this.partitions.remove(partitionNumber);
		MemorySegment[] overflowSegments = partition.overflowSegments;
		long pointer;
		int pointerOffset;
		int bucketOffset;
		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1;
		for (int i = 0, bucket = partitionNumber; i < this.buckets.length && bucket < this.numBuckets; i++) {
			MemorySegment segment = this.buckets[i];
			// go over all buckets in the segment belonging to the partition
			for (int k = bucket % bucketsPerSegment; k < bucketsPerSegment && bucket < this.numBuckets; k += numPartitions, bucket += numPartitions) {
				bucketOffset = k * HASH_BUCKET_SIZE;
				if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != partitionNumber) {
					throw new IOException(""Accessed wrong bucket! wanted: "" + partitionNumber + "" got: "" + segment.get(bucketOffset + HEADER_PARTITION_OFFSET));
				}
				// loop over all segments that are involved in the bucket (original bucket plus overflow buckets)
				int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET);
				int numInSegment = 0;
				pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET;
				while (true) {
					while (numInSegment < countInSegment) {
						pointer = segment.getLong(pointerOffset);
						tempHolder = partition.readRecordAt(pointer, tempHolder);
						pointer = this.compactionMemory.appendRecord(tempHolder);
						segment.putLong(pointerOffset, pointer);
						pointerOffset += POINTER_LEN;
						numInSegment++;
					}
					// this segment is done. check if there is another chained bucket
					final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET);
					if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {
						break;
					}
					final int overflowSegNum = (int) (forwardPointer >>> 32);
					segment = overflowSegments[overflowSegNum];
					bucketOffset = (int) forwardPointer;
					countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET);
					pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET;
					numInSegment = 0;
				}
				segment = this.buckets[i];
			}
		}
		// swap partition with compaction partition
		this.compactionMemory.setPartitionNumber(partitionNumber);
		this.partitions.add(partitionNumber, compactionMemory);
		this.partitions.get(partitionNumber).overflowSegments = partition.overflowSegments;
		this.partitions.get(partitionNumber).numOverflowSegments = partition.numOverflowSegments;
		this.partitions.get(partitionNumber).nextOverflowBucket = partition.nextOverflowBucket;
		this.partitions.get(partitionNumber).setIsCompacted(true);
		//this.partitions.get(partitionNumber).pushDownPages();
		this.compactionMemory = partition;
		this.compactionMemory.resetRecordCounter();
		this.compactionMemory.setPartitionNumber(-1);
		this.compactionMemory.overflowSegments = null;
		this.compactionMemory.numOverflowSegments = 0;
		this.compactionMemory.nextOverflowBucket = 0;
		// try to allocate maximum segment count
		this.compactionMemory.clearAllMemory(this.availableMemory);
		int maxSegmentNumber = this.getMaxPartition();
		this.compactionMemory.allocateSegments(maxSegmentNumber);
		this.compactionMemory.resetRWViews();
		this.compactionMemory.pushDownPages();
	}"
"synchronized public boolean load(URL groupedSetUrl) {
		if (groupedSetUrl == null) {
			throw new RuntimeException(""Null GroupSet url define!"");
		}
		// log.debug(""Load GroupSet file [{}]"", groupedSetUrl.getPath());
		InputStream settingStream = null;
		try {
			settingStream = groupedSetUrl.openStream();
			load(settingStream);
		} catch (IOException e) {
			// log.error(e, ""Load GroupSet error!"");
			return false;
		} finally {
			IoUtil.close(settingStream);
		}
		return true;
	}"
"public static MetricReportManager getInstance() {
    if (instance == null) {
      synchronized (MetricReportManager.class) {
        if (instance == null) {
          logger.info(""Instantiating MetricReportManager"");
          instance = new MetricReportManager();
        }
      }
    }
    return instance;
  }"
"LevelDBTypeInfo getTypeInfo(Class<?> type) throws Exception {
    LevelDBTypeInfo ti = types.get(type);
    if (ti == null) {
      LevelDBTypeInfo tmp = new LevelDBTypeInfo(this, type, getTypeAlias(type));
      ti = types.putIfAbsent(type, tmp);
      if (ti == null) {
        ti = tmp;
      }
    }
    return ti;
  }"
"private ImageIcon createIcon(String resourcePath) {
		if (getView() == null) {
			return null;
		}
		return new ImageIcon(ExtensionScript.class.getResource(resourcePath));
	}"
"@Override
    public boolean isValid(Object input) {
        String str = input.toString();
        int len = str.length();
        if (minLength != null && len < minLength)
            return false;
        if (maxLength != null && len > maxLength)
            return false;

        return regex == null || str.matches(regex);
    }"
"public static RestartStrategyConfiguration fixedDelayRestart(int restartAttempts, long delayBetweenAttempts) {
		return fixedDelayRestart(restartAttempts, Time.of(delayBetweenAttempts, TimeUnit.MILLISECONDS));
	}"
"public static PrivateKey generatePrivateKey(String algorithm, KeySpec keySpec) {
		return KeyUtil.generatePrivateKey(algorithm, keySpec);
	}"
"public Graph<KB, VVB, Tuple2<EV, EV>> projectionBottomSimple() {
		DataSet<Edge<KB, Tuple2<EV, EV>>> newEdges =  edges.join(edges)
			.where(0)
			.equalTo(0)
			.with(new ProjectionBottomSimple<>())
			.name(""Simple bottom projection"");

		return Graph.fromDataSet(bottomVertices, newEdges, context);
	}"
"public static Type getActualType(Type actualType, Class<?> typeDefineClass, Type typeVariable) {
		Type[] types = getActualTypes(actualType, typeDefineClass, typeVariable);
		if(ArrayUtil.isNotEmpty(types)) {
			return types[0];
		}
		return null;
	}"
"private DictionaryCompressionProjection selectDictionaryColumnToConvert(int totalNonDictionaryBytes, int stripeRowCount)
    {
        checkState(!directConversionCandidates.isEmpty());

        int totalNonDictionaryBytesPerRow = totalNonDictionaryBytes / stripeRowCount;

        // rawBytes = sum of the length of every row value (without dictionary encoding)
        // dictionaryBytes = sum of the length of every entry in the dictionary
        // indexBytes = bytes used encode the dictionary index (e.g., 2 byte for dictionary less than 65536 entries)

        long totalDictionaryRawBytes = 0;
        long totalDictionaryBytes = 0;
        long totalDictionaryIndexBytes = 0;

        long totalDictionaryRawBytesPerRow = 0;
        long totalDictionaryBytesPerNewRow = 0;
        long totalDictionaryIndexBytesPerRow = 0;

        for (DictionaryColumnManager column : allWriters) {
            if (!column.isDirectEncoded()) {
                totalDictionaryRawBytes += column.getRawBytes();
                totalDictionaryBytes += column.getDictionaryBytes();
                totalDictionaryIndexBytes += column.getIndexBytes();

                totalDictionaryRawBytesPerRow += column.getRawBytesPerRow();
                totalDictionaryBytesPerNewRow += column.getDictionaryBytesPerFutureRow();
                totalDictionaryIndexBytesPerRow += column.getIndexBytesPerRow();
            }
        }

        long totalUncompressedBytesPerRow = totalNonDictionaryBytesPerRow + totalDictionaryRawBytesPerRow;

        DictionaryCompressionProjection maxProjectedCompression = null;
        for (DictionaryColumnManager column : directConversionCandidates) {
            // determine the size of the currently written stripe if we were convert this column to direct
            long currentRawBytes = totalNonDictionaryBytes + column.getRawBytes();
            long currentDictionaryBytes = totalDictionaryBytes - column.getDictionaryBytes();
            long currentIndexBytes = totalDictionaryIndexBytes - column.getIndexBytes();
            long currentTotalBytes = currentRawBytes + currentDictionaryBytes + currentIndexBytes;

            // estimate the size of each new row if we were convert this column to direct
            double rawBytesPerFutureRow = totalNonDictionaryBytesPerRow + column.getRawBytesPerRow();
            double dictionaryBytesPerFutureRow = totalDictionaryBytesPerNewRow - column.getDictionaryBytesPerFutureRow();
            double indexBytesPerFutureRow = totalDictionaryIndexBytesPerRow - column.getIndexBytesPerRow();
            double totalBytesPerFutureRow = rawBytesPerFutureRow + dictionaryBytesPerFutureRow + indexBytesPerFutureRow;

            // estimate how many rows until we hit a limit and flush the stripe if we convert this column to direct
            long rowsToDictionaryMemoryLimit = (long) ((dictionaryMemoryMaxBytesLow - currentDictionaryBytes) / dictionaryBytesPerFutureRow);
            long rowsToStripeMemoryLimit = (long) ((stripeMaxBytes - currentTotalBytes) / totalBytesPerFutureRow);
            long rowsToStripeRowLimit = stripeMaxRowCount - stripeRowCount;
            long rowsToLimit = Longs.min(rowsToDictionaryMemoryLimit, rowsToStripeMemoryLimit, rowsToStripeRowLimit);

            // predict the compression ratio at that limit if we were convert this column to direct
            long predictedUncompressedSizeAtLimit = totalNonDictionaryBytes + totalDictionaryRawBytes + (totalUncompressedBytesPerRow * rowsToLimit);
            long predictedCompressedSizeAtLimit = (long) (currentTotalBytes + (totalBytesPerFutureRow * rowsToLimit));
            double predictedCompressionRatioAtLimit = 1.0 * predictedUncompressedSizeAtLimit / predictedCompressedSizeAtLimit;

            // convert the column that creates the best compression ratio
            if (maxProjectedCompression == null || maxProjectedCompression.getPredictedFileCompressionRatio() < predictedCompressionRatioAtLimit) {
                maxProjectedCompression = new DictionaryCompressionProjection(column, predictedCompressionRatioAtLimit);
            }
        }
        return maxProjectedCompression;
    }"
"public void endArray() throws IOException {
    int p = peeked;
    if (p == PEEKED_NONE) {
      p = doPeek();
    }
    if (p == PEEKED_END_ARRAY) {
      stackSize--;
      pathIndices[stackSize - 1]++;
      peeked = PEEKED_NONE;
    } else {
      throw new IllegalStateException(""Expected END_ARRAY but was "" + peek() + locationString());
    }
  }"
"public static BigDecimal yuan2fen(BigDecimal y) {
		if (y != null) {
			return yuan2fen(y.toString());
		} else {
			return new BigDecimal(0);
		}
	}"
"public static ComputationGraph restoreComputationGraph(@NonNull String path) throws IOException {
        return restoreComputationGraph(new File(path), true);
    }"
"public static Date getDate(Map<?, ?> map, Object key) {
		return get(map, key, Date.class);
	}"
"public static String maskJson(String input, String key) {
        DocumentContext ctx = JsonPath.parse(input);
        return maskJson(ctx, key);
    }"
"public void addBrowser(DesiredCapabilities cap, int instances) {
    String s = cap.getBrowserName();
    if (s == null || """".equals(s)) {
      throw new InvalidParameterException(cap + "" does seems to be a valid browser."");
    }
    if (cap.getPlatform() == null) {
      cap.setPlatform(Platform.getCurrent());
    }
    cap.setCapability(RegistrationRequest.MAX_INSTANCES, instances);
    registrationRequest.getConfiguration().capabilities.add(cap);
    registrationRequest.getConfiguration().fixUpCapabilities();
  }"
"@Override
  protected Object primTransform(Object anObject) throws Exception {
    Object current = anObject;
    for (Transformer transformer : this.transformers) {
      current = transformer.transform(current);
    }
    return current;
  }"
"@GET
  @Path(""/db/{authenticatorName}/cachedSerializedUserMap"")
  @Produces(SmileMediaTypes.APPLICATION_JACKSON_SMILE)
  @Consumes(MediaType.APPLICATION_JSON)
  @ResourceFilters(BasicSecurityResourceFilter.class)
  public Response getCachedSerializedUserMap(
      @Context HttpServletRequest req,
      @PathParam(""authenticatorName"") final String authenticatorName
  )
  {
    return handler.getCachedSerializedUserMap(authenticatorName);
  }"
"public static String getJwt(JwtClaims claims) throws JoseException {
        String jwt;
        RSAPrivateKey privateKey = (RSAPrivateKey) getPrivateKey(
                jwtConfig.getKey().getFilename(), (String)secretConfig.get(JWT_PRIVATE_KEY_PASSWORD), jwtConfig.getKey().getKeyName());

        // A JWT is a JWS and/or a JWE with JSON claims as the payload.
        // In this example it is a JWS nested inside a JWE
        // So we first create a JsonWebSignature object.
        JsonWebSignature jws = new JsonWebSignature();

        // The payload of the JWS is JSON content of the JWT Claims
        jws.setPayload(claims.toJson());

        // The JWT is signed using the sender's private key
        jws.setKey(privateKey);

        // Get provider from security config file, it should be two digit
        // And the provider id will set as prefix for keyid in the token header, for example: 05100
        // if there is no provider id, we use ""00"" for the default value
        String provider_id = """";
        if (jwtConfig.getProviderId() != null) {
            provider_id = jwtConfig.getProviderId();
            if (provider_id.length() == 1) {
                provider_id = ""0"" + provider_id;
            } else if (provider_id.length() > 2) {
                logger.error(""provider_id defined in the security.yml file is invalid; the length should be 2"");
                provider_id = provider_id.substring(0, 2);
            }
        }
        jws.setKeyIdHeaderValue(provider_id + jwtConfig.getKey().getKid());

        // Set the signature algorithm on the JWT/JWS that will integrity protect the claims
        jws.setAlgorithmHeaderValue(AlgorithmIdentifiers.RSA_USING_SHA256);

        // Sign the JWS and produce the compact serialization, which will be the inner JWT/JWS
        // representation, which is a string consisting of three dot ('.') separated
        // base64url-encoded parts in the form Header.Payload.Signature
        jwt = jws.getCompactSerialization();
        return jwt;
    }"
"@Deprecated
    public static <V,T extends Exception> V impersonate(Authentication auth, Callable<V,T> body) throws T {
        SecurityContext old = impersonate(auth);
        try {
            return body.call();
        } finally {
            SecurityContextHolder.setContext(old);
        }
    }"
"void pushDataLater(final int streamId, final BufferedSource source, final int byteCount,
      final boolean inFinished) throws IOException {
    final Buffer buffer = new Buffer();
    source.require(byteCount); // Eagerly read the frame before firing client thread.
    source.read(buffer, byteCount);
    if (buffer.size() != byteCount) throw new IOException(buffer.size() + "" != "" + byteCount);
    pushExecutorExecute(new NamedRunnable(""OkHttp %s Push Data[%s]"", connectionName, streamId) {
      @Override public void execute() {
        try {
          boolean cancel = pushObserver.onData(streamId, buffer, byteCount, inFinished);
          if (cancel) writer.rstStream(streamId, ErrorCode.CANCEL);
          if (cancel || inFinished) {
            synchronized (Http2Connection.this) {
              currentPushRequests.remove(streamId);
            }
          }
        } catch (IOException ignored) {
        }
      }
    });
  }"
"public static void raw_remove(Key key) {
    Value v = STORE.remove(key);
    if( v != null ) v.removePersist();
  }"
"@PostConstruct
    public void init() {
        validatedText.focusedProperty().addListener((o, oldVal, newVal) -> {
            if (!newVal) {
                validatedText.validate();
            }
        });
        validatedPassowrd.focusedProperty().addListener((o, oldVal, newVal) -> {
            if (!newVal) {
                validatedPassowrd.validate();
            }
        });
        jfxTextArea.focusedProperty().addListener((o, oldVal, newVal) -> {
            if (!newVal) {
                jfxTextArea.validate();
            }
        });
    }"
"protected void validateHyperParams(P params, Map<String, Object[]> hyperParams) {
    List<SchemaMetadata.FieldMetadata> fsMeta = SchemaMetadata.getFieldMetadata(params);
    for (Map.Entry<String, Object[]> hparam : hyperParams.entrySet()) {
      SchemaMetadata.FieldMetadata fieldMetadata = null;
      // Found corresponding metadata about the field
      for (SchemaMetadata.FieldMetadata fm : fsMeta) {
        if (fm.name.equals(hparam.getKey())) {
          fieldMetadata = fm;
          break;
        }
      }
      if (fieldMetadata == null) {
        throw new H2OIllegalArgumentException(hparam.getKey(), ""grid"",
                                              ""Unknown hyper parameter for grid search!"");
      }
      if (!fieldMetadata.is_gridable) {
        throw new H2OIllegalArgumentException(hparam.getKey(), ""grid"",
                                              ""Illegal hyper parameter for grid search! The parameter '""
                                              + fieldMetadata.name + "" is not gridable!"");
      }
    }
  }"
"public static Excel03SaxReader read03BySax(File file, int sheetIndex, RowHandler rowHandler) {
		try {
			return new Excel03SaxReader(rowHandler).read(file, sheetIndex);
		} catch (NoClassDefFoundError e) {
			throw new DependencyException(ObjectUtil.defaultIfNull(e.getCause(), e), PoiChecker.NO_POI_ERROR_MSG);
		}
	}"
"public @CheckForNull V start() throws Exception {
        V result = null;
        int currentAttempt = 0;
        boolean success = false;

        while (currentAttempt < attempts && !success) {
            currentAttempt++;
            try {
                if (LOGGER.isLoggable(Level.INFO)) {
                    LOGGER.log(Level.INFO, Messages.Retrier_Attempt(currentAttempt, action));
                }
                result = callable.call();

            } catch (Exception e) {
                if(duringActionExceptions == null || Stream.of(duringActionExceptions).noneMatch(exception -> exception.isAssignableFrom(e.getClass()))) {
                    // if the raised exception is not considered as a controlled exception doing the action, rethrow it
                    LOGGER.log(Level.WARNING, Messages.Retrier_ExceptionThrown(currentAttempt, action), e);
                    throw e;
                } else {
                    // if the exception is considered as a failed action, notify it to the listener
                    LOGGER.log(Level.INFO, Messages.Retrier_ExceptionFailed(currentAttempt, action), e);
                    if (duringActionExceptionListener != null) {
                        LOGGER.log(Level.INFO, Messages.Retrier_CallingListener(e.getLocalizedMessage(), currentAttempt, action));
                        result = duringActionExceptionListener.apply(currentAttempt, e);
                    }
                }
            }

            // After the call and the call to the listener, which can change the result, test the result
            success = checkResult.test(currentAttempt, result);
            if (!success) {
                if (currentAttempt < attempts) {
                    LOGGER.log(Level.WARNING, Messages.Retrier_AttemptFailed(currentAttempt, action));
                    LOGGER.log(Level.FINE, Messages.Retrier_Sleeping(delay, action));
                    try {
                        Thread.sleep(delay);
                    } catch (InterruptedException ie) {
                        LOGGER.log(Level.FINE, Messages.Retrier_Interruption(action));
                        Thread.currentThread().interrupt(); // flag this thread as interrupted
                        currentAttempt = attempts; // finish
                    }
                } else {
                    // Failed to perform the action
                    LOGGER.log(Level.INFO, Messages.Retrier_NoSuccess(action, attempts));
                }
            } else {
                LOGGER.log(Level.INFO, Messages.Retrier_Success(action, currentAttempt));
            }
        }

        return result;
    }"
"@Override
  public void close() {
    // Go through all clients and close them if they are active.
    for (ClientPool clientPool : connectionPool.values()) {
      for (int i = 0; i < clientPool.clients.length; i++) {
        TransportClient client = clientPool.clients[i];
        if (client != null) {
          clientPool.clients[i] = null;
          JavaUtils.closeQuietly(client);
        }
      }
    }
    connectionPool.clear();

    if (workerGroup != null) {
      workerGroup.shutdownGracefully();
      workerGroup = null;
    }
  }"
"public Integer getIntValue(char key) {
        Long value = get(key);
        if (value == null) {
            return null;
        }
        return value.intValue();
    }"
"public static Result<TokenResponse> getSignResult(SignRequest signRequest, String envTag) {
        final AtomicReference<Result<TokenResponse>> reference = new AtomicReference<>();
        final Http2Client client = Http2Client.getInstance();
        final CountDownLatch latch = new CountDownLatch(1);
        final ClientConnection connection;
        try {
            if(signRequest.getServerUrl() != null) {
                connection = client.connect(new URI(signRequest.getServerUrl()), Http2Client.WORKER, Http2Client.SSL, Http2Client.BUFFER_POOL, signRequest.enableHttp2 ? OptionMap.create(UndertowOptions.ENABLE_HTTP2, true): OptionMap.EMPTY).get();
            } else if(signRequest.getServiceId() != null) {
                Cluster cluster = SingletonServiceFactory.getBean(Cluster.class);
                String url = cluster.serviceToUrl(""https"", signRequest.getServiceId(), envTag, null);
                connection = client.connect(new URI(url), Http2Client.WORKER, Http2Client.SSL, Http2Client.BUFFER_POOL, signRequest.enableHttp2 ? OptionMap.create(UndertowOptions.ENABLE_HTTP2, true): OptionMap.EMPTY).get();
            } else {
                // both server_url and serviceId are empty in the config.
                logger.error(""Error: both server_url and serviceId are not configured in client.yml for "" + signRequest.getClass());
                throw new ClientException(""both server_url and serviceId are not configured in client.yml for "" + signRequest.getClass());
            }
        } catch (Exception e) {
            logger.error(""cannot establish connection:"", e);
            return Failure.of(new Status(ESTABLISH_CONNECTION_ERROR, signRequest.getServerUrl() != null ? signRequest.getServerUrl() : signRequest.getServiceId()));
        }

        try {
            Map<String, Object> map = new HashMap<>();
            map.put(""expires"", signRequest.getExpires());
            map.put(""payload"", signRequest.getPayload());
            String requestBody = Config.getInstance().getMapper().writeValueAsString(map);
            connection.getIoThread().execute(() -> {
                final ClientRequest request = new ClientRequest().setMethod(Methods.POST).setPath(signRequest.getUri());
                request.getRequestHeaders().put(Headers.HOST, ""localhost"");
                request.getRequestHeaders().put(Headers.TRANSFER_ENCODING, ""chunked"");
                request.getRequestHeaders().put(Headers.CONTENT_TYPE, ""application/x-www-form-urlencoded"");
                request.getRequestHeaders().put(Headers.AUTHORIZATION, getBasicAuthHeader(signRequest.getClientId(), signRequest.getClientSecret()));
                connection.sendRequest(request, new ClientCallback<ClientExchange>() {
                    @Override
                    public void completed(ClientExchange result) {
                        new StringWriteChannelListener(requestBody).setup(result.getRequestChannel());
                        result.setResponseListener(new ClientCallback<ClientExchange>() {
                            @Override
                            public void completed(ClientExchange result) {
                                new StringReadChannelListener(Http2Client.BUFFER_POOL) {

                                    @Override
                                    protected void stringDone(String string) {

                                        logger.debug(""getToken response = "" + string);
                                        reference.set(handleResponse(getContentTypeFromExchange(result), string));
                                        latch.countDown();
                                    }

                                    @Override
                                    protected void error(IOException e) {
                                        logger.error(""IOException:"", e);
                                        reference.set(Failure.of(new Status(FAIL_TO_SEND_REQUEST)));
                                        latch.countDown();
                                    }
                                }.setup(result.getResponseChannel());
                            }

                            @Override
                            public void failed(IOException e) {
                                logger.error(""IOException:"", e);
                                reference.set(Failure.of(new Status(FAIL_TO_SEND_REQUEST)));
                                latch.countDown();
                            }
                        });
                    }

                    @Override
                    public void failed(IOException e) {
                        logger.error(""IOException:"", e);
                        reference.set(Failure.of(new Status(FAIL_TO_SEND_REQUEST)));
                        latch.countDown();
                    }
                });
            });

            latch.await(signRequest.getTimeout(), TimeUnit.MILLISECONDS);
        } catch (Exception e) {
            logger.error(""IOException: "", e);
            return Failure.of(new Status(FAIL_TO_SEND_REQUEST));
        } finally {
            IoUtils.safeClose(connection);
        }

        //if reference.get() is null at this point, mostly likely couldn't get token within latch.await() timeout.
        return reference.get() == null ? Failure.of(new Status(GET_TOKEN_TIMEOUT)) : reference.get();
    }"
"@SuppressWarnings(""resource"")
  @Override public void run() {
    // No multicast?  Then do not bother with listening for them
    if (H2O.isFlatfileEnabled()) return;
    Thread.currentThread().setPriority(Thread.MAX_PRIORITY);

    MulticastSocket sock = null, errsock = null;
    InetAddress group = null, errgroup = null;
    boolean saw_error = false;

    // Loop forever accepting Cloud Management requests
    while( true ) {
      try {
        // ---
        // Cleanup from any prior socket failures.  Rare unless we're really sick.
        if( errsock != null && errgroup != null ) { // socket error AND group present
          final InetAddress tmp = errgroup; errgroup = null;
          errsock.leaveGroup(tmp); // Could throw, but errgroup cleared for next pass
        }
        if( errsock != null ) { // One time attempt a socket close
          final MulticastSocket tmp2 = errsock; errsock = null;
          tmp2.close();       // Could throw, but errsock cleared for next pass
        }
        if( saw_error ) Thread.sleep(1000); // prevent deny-of-service endless socket-creates
        saw_error = false;

        // ---
        // Actually do the common-case setup of Inet multicast group
        if( group == null ) group = H2O.CLOUD_MULTICAST_GROUP;
        // More common-case setup of a MultiCast socket
        if( sock == null ) {
          sock = new MulticastSocket(H2O.CLOUD_MULTICAST_PORT);
          if( H2O.CLOUD_MULTICAST_IF != null ) {
            try { 
              sock.setNetworkInterface(H2O.CLOUD_MULTICAST_IF);
            } catch( SocketException e ) {
              Log.err(""Exception calling setNetworkInterface, Multicast Interface, Group, Port - ""+
                      H2O.CLOUD_MULTICAST_IF+"" ""+H2O.CLOUD_MULTICAST_GROUP+"":""+H2O.CLOUD_MULTICAST_PORT, e);
              throw e;
            }
          }
          sock.joinGroup(group);
        }

        // Receive a packet & handle it
        byte[] buf = new byte[AutoBuffer.MTU];
        DatagramPacket pack = new DatagramPacket(buf,buf.length);
        sock.receive(pack);
        TCPReceiverThread.basic_packet_handling(new AutoBuffer(pack));
      } catch( SocketException e ) {
        // This rethrow will not be caught and thus kills the multi-cast thread.
        Log.err(""Turning off multicast, which will disable further cloud building"");
        throw new RuntimeException(e);
      } catch( Exception e ) {
        Log.err(""Exception on Multicast Interface, Group, Port - ""+
          H2O.CLOUD_MULTICAST_IF+"" ""+H2O.CLOUD_MULTICAST_GROUP+"":""+H2O.CLOUD_MULTICAST_PORT, e);
        // On any error from anybody, close all sockets & re-open
        saw_error = true;
        errsock  = sock ;  sock  = null; // Signal error recovery on the next loop
        errgroup = group;  group = null;
      }
    }
  }"
"private KeyPair createKeyPair() throws NoSuchAlgorithmException {
		final KeyPairGenerator keyGen = KeyPairGenerator.getInstance(""RSA"");
		final SecureRandom random  = SecureRandom.getInstance(""SHA1PRNG"");
		random.setSeed(Long.toString(System.currentTimeMillis()).getBytes());
		keyGen.initialize(2048, random);
		final KeyPair keypair = keyGen.generateKeyPair();
		return keypair;
	}"
"public List<Object> insertForGeneratedKeys(Entity record) throws SQLException {
		Connection conn = null;
		try {
			conn = this.getConnection();
			return runner.insertForGeneratedKeys(conn, record);
		} catch (SQLException e) {
			throw e;
		} finally {
			this.closeConnection(conn);
		}
	}"
"public static JavaRDD<String> listPaths(JavaSparkContext sc, String path, boolean recursive, Set<String> allowedExtensions) throws IOException {
        return listPaths(sc, path, recursive, allowedExtensions, sc.hadoopConfiguration());
    }"
"private RectF getDisplayRect(Matrix matrix) {
        Drawable d = mImageView.getDrawable();
        if (d != null) {
            mDisplayRect.set(0, 0, d.getIntrinsicWidth(),
                d.getIntrinsicHeight());
            matrix.mapRect(mDisplayRect);
            return mDisplayRect;
        }
        return null;
    }"
"public boolean shouldSchedule(List<Action> actions) {
        List<ParametersAction> others = Util.filter(actions, ParametersAction.class);
        if (others.isEmpty()) {
            return !parameters.isEmpty();
        } else {
            // I don't think we need multiple ParametersActions, but let's be defensive
            Set<ParameterValue> params = new HashSet<>();
            for (ParametersAction other: others) {
                params.addAll(other.parameters);
            }
            return !params.equals(new HashSet<>(this.parameters));
        }
    }"
"public static <T extends Collection<Entity>> T handleRs(ResultSet rs, T collection) throws SQLException {
		final ResultSetMetaData meta = rs.getMetaData();
		final int columnCount = meta.getColumnCount();

		while (rs.next()) {
			collection.add(HandleHelper.handleRow(columnCount, meta, rs));
		}

		return collection;
	}"
"public int indexOf(UTF8String v, int start) {
    if (v.numBytes() == 0) {
      return 0;
    }

    // locate to the start position.
    int i = 0; // position in byte
    int c = 0; // position in character
    while (i < numBytes && c < start) {
      i += numBytesForFirstByte(getByte(i));
      c += 1;
    }

    do {
      if (i + v.numBytes > numBytes) {
        return -1;
      }
      if (ByteArrayMethods.arrayEquals(base, offset + i, v.base, v.offset, v.numBytes)) {
        return c;
      }
      i += numBytesForFirstByte(getByte(i));
      c += 1;
    } while (i < numBytes);

    return -1;
  }"
"private Map<?, ?> aliasMap(Map<?, ?> rowMap) {
		if (MapUtil.isEmpty(this.headerAlias)) {
			return rowMap;
		}

		final Map<Object, Object> filteredMap = new LinkedHashMap<>();
		String aliasName;
		for (Entry<?, ?> entry : rowMap.entrySet()) {
			aliasName = this.headerAlias.get(entry.getKey());
			if (null != aliasName) {
				// 别名键值对加入
				filteredMap.put(aliasName, entry.getValue());
			} else if (false == this.onlyAlias) {
				// 保留无别名设置的键值对
				filteredMap.put(entry.getKey(), entry.getValue());
			}
		}
		return filteredMap;
	}"
"public StackTraceElement filterFirst(Throwable target, boolean isInline) {
        boolean shouldSkip = isInline;

        if (GET_STACK_TRACE_ELEMENT != null) {
            int i = 0;

            // The assumption here is that the CLEANER filter will not filter out every single
            // element. However, since we don't want to compute the full length of the stacktrace,
            // we don't know the upper boundary. Therefore, simply increment the counter and go as
            // far as we have to go, assuming that we get there. If, in the rare occassion, we
            // don't, we fall back to the old slow path.
            while (true) {
                try {
                    StackTraceElement stackTraceElement =
                        (StackTraceElement)
                            GET_STACK_TRACE_ELEMENT.invoke(JAVA_LANG_ACCESS, target, i);

                    if (CLEANER.isIn(stackTraceElement)) {
                        if (shouldSkip) {
                            shouldSkip = false;
                        } else {
                            return stackTraceElement;
                        }
                    }
                } catch (Exception e) {
                    // Fall back to slow path
                    break;
                }
                i++;
            }
        }

        // If we can't use the fast path of retrieving stackTraceElements, use the slow path by
        // iterating over the actual stacktrace
        for (StackTraceElement stackTraceElement : target.getStackTrace()) {
            if (CLEANER.isIn(stackTraceElement)) {
                if (shouldSkip) {
                    shouldSkip = false;
                } else {
                    return stackTraceElement;
                }
            }
        }
        return null;
    }"
"List<String> buildClassPath(String appClassPath) throws IOException {
    String sparkHome = getSparkHome();

    Set<String> cp = new LinkedHashSet<>();
    addToClassPath(cp, appClassPath);

    addToClassPath(cp, getConfDir());

    boolean prependClasses = !isEmpty(getenv(""SPARK_PREPEND_CLASSES""));
    boolean isTesting = ""1"".equals(getenv(""SPARK_TESTING""));
    if (prependClasses || isTesting) {
      String scala = getScalaVersion();
      List<String> projects = Arrays.asList(
        ""common/kvstore"",
        ""common/network-common"",
        ""common/network-shuffle"",
        ""common/network-yarn"",
        ""common/sketch"",
        ""common/tags"",
        ""common/unsafe"",
        ""core"",
        ""examples"",
        ""graphx"",
        ""launcher"",
        ""mllib"",
        ""repl"",
        ""resource-managers/mesos"",
        ""resource-managers/yarn"",
        ""sql/catalyst"",
        ""sql/core"",
        ""sql/hive"",
        ""sql/hive-thriftserver"",
        ""streaming""
      );
      if (prependClasses) {
        if (!isTesting) {
          System.err.println(
            ""NOTE: SPARK_PREPEND_CLASSES is set, placing locally compiled Spark classes ahead of "" +
            ""assembly."");
        }
        for (String project : projects) {
          addToClassPath(cp, String.format(""%s/%s/target/scala-%s/classes"", sparkHome, project,
            scala));
        }
      }
      if (isTesting) {
        for (String project : projects) {
          addToClassPath(cp, String.format(""%s/%s/target/scala-%s/test-classes"", sparkHome,
            project, scala));
        }
      }

      // Add this path to include jars that are shaded in the final deliverable created during
      // the maven build. These jars are copied to this directory during the build.
      addToClassPath(cp, String.format(""%s/core/target/jars/*"", sparkHome));
      addToClassPath(cp, String.format(""%s/mllib/target/jars/*"", sparkHome));
    }

    // Add Spark jars to the classpath. For the testing case, we rely on the test code to set and
    // propagate the test classpath appropriately. For normal invocation, look for the jars
    // directory under SPARK_HOME.
    boolean isTestingSql = ""1"".equals(getenv(""SPARK_SQL_TESTING""));
    String jarsDir = findJarsDir(getSparkHome(), getScalaVersion(), !isTesting && !isTestingSql);
    if (jarsDir != null) {
      addToClassPath(cp, join(File.separator, jarsDir, ""*""));
    }

    addToClassPath(cp, getenv(""HADOOP_CONF_DIR""));
    addToClassPath(cp, getenv(""YARN_CONF_DIR""));
    addToClassPath(cp, getenv(""SPARK_DIST_CLASSPATH""));
    return new ArrayList<>(cp);
  }"
"public static Object getValueByColumnType(final ResultSet resultSet, final int columnIndex) throws SQLException {
        ResultSetMetaData metaData = resultSet.getMetaData();
        switch (metaData.getColumnType(columnIndex)) {
            case Types.BIT:
            case Types.BOOLEAN:
                return resultSet.getBoolean(columnIndex);
            case Types.TINYINT:
                return resultSet.getByte(columnIndex);
            case Types.SMALLINT:
                return resultSet.getShort(columnIndex);
            case Types.INTEGER:
                return resultSet.getInt(columnIndex);
            case Types.BIGINT:
                return resultSet.getLong(columnIndex);
            case Types.NUMERIC:
            case Types.DECIMAL:
                return resultSet.getBigDecimal(columnIndex);
            case Types.FLOAT:
            case Types.DOUBLE:
                return resultSet.getDouble(columnIndex);
            case Types.CHAR:
            case Types.VARCHAR:
            case Types.LONGVARCHAR:
                return resultSet.getString(columnIndex);
            case Types.BINARY:
            case Types.VARBINARY:
            case Types.LONGVARBINARY:
                return resultSet.getBytes(columnIndex);
            case Types.DATE:
                return resultSet.getDate(columnIndex);
            case Types.TIME:
                return resultSet.getTime(columnIndex);
            case Types.TIMESTAMP:
                return resultSet.getTimestamp(columnIndex);
            case Types.CLOB:
                return resultSet.getClob(columnIndex);
            case Types.BLOB:
                return resultSet.getBlob(columnIndex);
            default:
                return resultSet.getObject(columnIndex);
        }
    }"
"public static AeronNDArrayResponder startSubscriber(Aeron.Context context, String host, int port,
                    NDArrayHolder callback, int streamId) {
        if (callback == null)
            throw new IllegalArgumentException(""NDArrayHolder must be specified"");


        final AtomicBoolean running = new AtomicBoolean(true);


        AeronNDArrayResponder subscriber = AeronNDArrayResponder.builder().streamId(streamId).ctx(context)
                        .channel(String.format(""aeron:udp?endpoint=%s:%d"", host, port)).running(running)
                        .ndArrayHolder(callback).build();


        Thread t = new Thread(() -> {
            try {
                subscriber.launch();
            } catch (Exception e) {
                e.printStackTrace();
            }

        });

        t.start();

        return subscriber;
    }"
"private static long getSizeOfPhysicalMemoryForWindows() {
		BufferedReader bi = null;
		try {
			Process proc = Runtime.getRuntime().exec(""wmic memorychip get capacity"");

			bi = new BufferedReader(new InputStreamReader(proc.getInputStream()));

			String line = bi.readLine();
			if (line == null) {
				return -1L;
			}

			if (!line.startsWith(""Capacity"")) {
				return -1L;
			}

			long sizeOfPhyiscalMemory = 0L;
			while ((line = bi.readLine()) != null) {
				if (line.isEmpty()) {
					continue;
				}

				line = line.replaceAll("" "", """");
				sizeOfPhyiscalMemory += Long.parseLong(line);
			}
			return sizeOfPhyiscalMemory;
		}
		catch (Throwable t) {
			LOG.error(""Cannot determine the size of the physical memory for Windows host "" +
					""(using 'wmic memorychip')"", t);
			return -1L;
		}
		finally {
			if (bi != null) {
				try {
					bi.close();
				} catch (Throwable ignored) {}
			}
		}
	}"
"private void initOutputs(ClassLoader cl) throws Exception {
		this.chainedTasks = new ArrayList<ChainedDriver<?, ?>>();
		this.eventualOutputs = new ArrayList<RecordWriter<?>>();

		this.output = BatchTask.initOutputs(this, cl, this.config, this.chainedTasks, this.eventualOutputs,
				getExecutionConfig(), getEnvironment().getAccumulatorRegistry().getUserMap());
	}"
"public static synchronized I18N getInstance(String sessionId) {
        if (!sessionInstances.containsKey(sessionId)) {
            sessionInstances.put(sessionId, new DefaultI18N());
        }
        return sessionInstances.get(sessionId);
    }"
"@Override
  public void updateProcessBusinessKeyInHistory(ExecutionEntity processInstance) {
    if (isHistoryEnabled()) {
      if (log.isDebugEnabled()) {
        log.debug(""updateProcessBusinessKeyInHistory : {}"", processInstance.getId());
      }
      if (processInstance != null) {
        HistoricProcessInstanceEntity historicProcessInstance = getHistoricProcessInstanceEntityManager().findById(processInstance.getId());
        if (historicProcessInstance != null) {
          historicProcessInstance.setBusinessKey(processInstance.getProcessInstanceBusinessKey());
          getHistoricProcessInstanceEntityManager().update(historicProcessInstance, false);
        }
      }
    }
  }"
"private boolean announceTask(
      final Task task,
      final ZkWorker theZkWorker,
      final RemoteTaskRunnerWorkItem taskRunnerWorkItem
  ) throws Exception
  {
    Preconditions.checkArgument(task.getId().equals(taskRunnerWorkItem.getTaskId()), ""task id != workItem id"");
    final String worker = theZkWorker.getWorker().getHost();
    synchronized (statusLock) {
      if (!zkWorkers.containsKey(worker) || lazyWorkers.containsKey(worker)) {
        // the worker might have been killed or marked as lazy
        log.info(""Not assigning task to already removed worker[%s]"", worker);
        return false;
      }
      log.info(""Coordinator asking Worker[%s] to add task[%s]"", worker, task.getId());

      CuratorUtils.createIfNotExists(
          cf,
          JOINER.join(indexerZkConfig.getTasksPath(), worker, task.getId()),
          CreateMode.EPHEMERAL,
          jsonMapper.writeValueAsBytes(task),
          config.getMaxZnodeBytes()
      );

      RemoteTaskRunnerWorkItem workItem = pendingTasks.remove(task.getId());
      if (workItem == null) {
        log.makeAlert(""WTF?! Got a null work item from pending tasks?! How can this be?!"")
           .addData(""taskId"", task.getId())
           .emit();
        return false;
      }

      RemoteTaskRunnerWorkItem newWorkItem = workItem.withWorker(theZkWorker.getWorker(), null);
      runningTasks.put(task.getId(), newWorkItem);
      log.info(""Task %s switched from pending to running (on [%s])"", task.getId(), newWorkItem.getWorker().getHost());
      TaskRunnerUtils.notifyStatusChanged(listeners, task.getId(), TaskStatus.running(task.getId()));

      // Syncing state with Zookeeper - don't assign new tasks until the task we just assigned is actually running
      // on a worker - this avoids overflowing a worker with tasks
      Stopwatch timeoutStopwatch = Stopwatch.createStarted();
      while (!isWorkerRunningTask(theZkWorker, task.getId())) {
        final long waitMs = config.getTaskAssignmentTimeout().toStandardDuration().getMillis();
        statusLock.wait(waitMs);
        long elapsed = timeoutStopwatch.elapsed(TimeUnit.MILLISECONDS);
        if (elapsed >= waitMs) {
          log.makeAlert(
              ""Task assignment timed out on worker [%s], never ran task [%s]! Timeout: (%s >= %s)!"",
              worker,
              task.getId(),
              elapsed,
              config.getTaskAssignmentTimeout()
          ).emit();
          taskComplete(taskRunnerWorkItem, theZkWorker, TaskStatus.failure(task.getId()));
          break;
        }
      }
      return true;
    }
  }"
"public SingleOutputStreamOperator<T> filter(FilterFunction<T> filter) {
		return transform(""Filter"", getType(), new StreamFilter<>(clean(filter)));

	}"
"private JPanel getJPanel() {
		if (jPanel == null) {
			final java.awt.GridBagConstraints gridBagConstraints12 = new GridBagConstraints();

			final java.awt.GridBagConstraints gridBagConstraints11 = new GridBagConstraints();

			final javax.swing.JLabel jLabel = new JLabel();

			final java.awt.GridBagConstraints gridBagConstraints1 = new GridBagConstraints();

			jPanel = new JPanel();
			jPanel.setLayout(new GridBagLayout());
			gridBagConstraints1.gridx = 0;
			gridBagConstraints1.gridy = 1;
			gridBagConstraints1.insets = new java.awt.Insets(2,2,2,2);
			gridBagConstraints1.anchor = java.awt.GridBagConstraints.NORTHWEST;
			gridBagConstraints1.fill = java.awt.GridBagConstraints.BOTH;
			gridBagConstraints1.gridwidth = 1;
			gridBagConstraints1.weightx = 1.0D;
			gridBagConstraints1.weighty = 1.0D;
			jLabel.setText(""<html><body><font size=+1>"" +
				""<p>ZAP : Licensed under the Apache License, Version 2.0.</p></font>"" +
				""<p></p>"" +
				""<p>For the other libraries included in ZAP, please refer to respective "" +
				""licenses of the libraries enclosed with this package.</p></body></html>"");
			gridBagConstraints11.anchor = java.awt.GridBagConstraints.NORTHWEST;
			gridBagConstraints11.fill = java.awt.GridBagConstraints.HORIZONTAL;
			gridBagConstraints11.gridx = 0;
			gridBagConstraints11.gridy = 0;
			gridBagConstraints11.weightx = 1.0D;
			gridBagConstraints11.gridwidth = 1;
			gridBagConstraints11.insets = new java.awt.Insets(2,2,2,2);
			gridBagConstraints12.gridx = 0;
			gridBagConstraints12.gridy = 2;
			jPanel.add(jLabel, gridBagConstraints11);
			jPanel.add(getJPanel1(), gridBagConstraints1);
			jPanel.add(getJPanel2(), gridBagConstraints12);
		}
		return jPanel;
	}"
"@CLIMethod(name=""safe-restart"")
    public HttpResponse doSafeRestart(StaplerRequest req) throws IOException, ServletException, RestartNotSupportedException {
        checkPermission(ADMINISTER);
        if (req != null && req.getMethod().equals(""GET""))
            return HttpResponses.forwardToView(this,""_safeRestart.jelly"");

        if (req == null || req.getMethod().equals(""POST"")) {
            safeRestart();
        }

        return HttpResponses.redirectToDot();
    }"
"public static String escapeHtml4(String html) {
		Html4Escape escape = new Html4Escape();
		return escape.replace(html).toString();
	}"
"private void sendMultipart() throws IOException {
		setMultipart();// 设置表单类型为Multipart

		final OutputStream out = this.httpConnection.getOutputStream();
		try {
			writeFileForm(out);
			writeForm(out);
			formEnd(out);
		} catch (IOException e) {
			throw e;
		} finally {
			IoUtil.close(out);
		}
	}"
"private String showPrompt(String prompt) {
        verifySystemOut();
        cursorMove = 0;
        if (!userInputActive) {
            return readLine(prompt, false);
        }

        out.print(prompt);
        out.flush();
        return null;
    }"
"public static String downloadString(String url, Charset customCharset) {
		return downloadString(url, customCharset, null);
	}"
"public void setDefaultDelay(long delay, TimeUnit unit) {
        if (delay < 0) {
            throw new IllegalArgumentException(""Parameter delay must be greater or equal to zero."");
        }
        if (unit == null) {
            throw new IllegalArgumentException(""Parameter unit must not be null."");
        }
        this.defaultDelayInMs = unit.toMillis(delay);
    }"
"public long getLong(String key, long defaultValue) {
		Object o = getRawValue(key);
		if (o == null) {
			return defaultValue;
		}

		return convertToLong(o, defaultValue);
	}"
"protected static Key<Grid> gridKeyName(String modelName, Frame fr) {
    if (fr == null || fr._key == null) {
      throw new IllegalArgumentException(""The frame being grid-searched over must have a Key"");
    }
    return Key.make(""Grid_"" + modelName + ""_"" + fr._key.toString() + H2O.calcNextUniqueModelId(""""));
  }"
"@Override
    public long opHash() {
        if (hash == 0) {
            val map = Nd4j.getExecutioner().getCustomOperations();
            val desc = map.get(opName());
            if (desc == null) {
                throw new ND4JIllegalStateException(""Op name "" + opName() + "" is missing!"");
            }

            hash = desc.getHash();
        }

        return hash;
    }"
"public List<INDArray> rnnActivateUsingStoredState(INDArray input, boolean training, boolean storeLastForTBPTT) {
        return ffToLayerActivationsDetached(training, FwdPassType.RNN_ACTIVATE_WITH_STORED_STATE, storeLastForTBPTT, layers.length-1, input, mask, null, false);
    }"
"public static PublicKey decodeECPoint(String encode, String curveName) {
		return decodeECPoint(SecureUtil.decode(encode), curveName);
	}"
"private void skipToEndOfLine() {
		for (; this.pos < this.in.length(); this.pos++) {
			char c = this.in.charAt(this.pos);
			if (c == '\r' || c == '\n') {
				this.pos++;
				break;
			}
		}
	}"
"private O setResources(ResourceSpec minResources, ResourceSpec preferredResources) {
		Preconditions.checkNotNull(minResources, ""The min resources must be not null."");
		Preconditions.checkNotNull(preferredResources, ""The preferred resources must be not null."");

		Preconditions.checkArgument(minResources.isValid() && preferredResources.isValid() && minResources.lessThanOrEqual(preferredResources),
				""The values in resources must be not less than 0 and the preferred resources must be greater than the min resources."");

		this.minResources = minResources;
		this.preferredResources = preferredResources;

		@SuppressWarnings(""unchecked"")
		O returnType = (O) this;
		return returnType;
	}"
"public static long copy(InputStream in, OutputStream out, int bufferSize) throws IORuntimeException {
		return copy(in, out, bufferSize, null);
	}"
"private MapperTemplate fromMapperClass(Class<?> mapperClass) {
        Method[] methods = mapperClass.getDeclaredMethods();
        Class<?> templateClass = null;
        Class<?> tempClass = null;
        Set<String> methodSet = new HashSet<String>();
        for (Method method : methods) {
            if (method.isAnnotationPresent(SelectProvider.class)) {
                SelectProvider provider = method.getAnnotation(SelectProvider.class);
                tempClass = provider.type();
                methodSet.add(method.getName());
            } else if (method.isAnnotationPresent(InsertProvider.class)) {
                InsertProvider provider = method.getAnnotation(InsertProvider.class);
                tempClass = provider.type();
                methodSet.add(method.getName());
            } else if (method.isAnnotationPresent(DeleteProvider.class)) {
                DeleteProvider provider = method.getAnnotation(DeleteProvider.class);
                tempClass = provider.type();
                methodSet.add(method.getName());
            } else if (method.isAnnotationPresent(UpdateProvider.class)) {
                UpdateProvider provider = method.getAnnotation(UpdateProvider.class);
                tempClass = provider.type();
                methodSet.add(method.getName());
            }
            if (templateClass == null) {
                templateClass = tempClass;
            } else if (templateClass != tempClass) {
                throw new MapperException(""一个通用Mapper中只允许存在一个MapperTemplate子类!"");
            }
        }
        if (templateClass == null || !MapperTemplate.class.isAssignableFrom(templateClass)) {
            templateClass = EmptyProvider.class;
        }
        MapperTemplate mapperTemplate = null;
        try {
            mapperTemplate = (MapperTemplate) templateClass.getConstructor(Class.class, MapperHelper.class).newInstance(mapperClass, this);
        } catch (Exception e) {
            throw new MapperException(""实例化MapperTemplate对象失败:"" + e.getMessage());
        }
        //注册方法
        for (String methodName : methodSet) {
            try {
                mapperTemplate.addMethodMap(methodName, templateClass.getMethod(methodName, MappedStatement.class));
            } catch (NoSuchMethodException e) {
                throw new MapperException(templateClass.getCanonicalName() + ""中缺少"" + methodName + ""方法!"");
            }
        }
        return mapperTemplate;
    }"
"private void addTimeConstructorAssignment(MethodSpec.Builder constructor, String field) {
    constructor.addStatement(""$T.UNSAFE.putLong(this, $N, $N)"",
        UNSAFE_ACCESS, offsetName(field), ""now"");
  }"
"protected void validateRequiredNameIdFormatIfAny(final RequestAbstractType authnRequest,
                                                     final SamlRegisteredServiceServiceProviderMetadataFacade adaptor,
                                                     final List<String> supportedNameFormats,
                                                     final String requiredNameFormat) {
        if (StringUtils.isNotBlank(requiredNameFormat) && !supportedNameFormats.contains(requiredNameFormat)) {
            LOGGER.warn(""Required NameID format [{}] in the AuthN request issued by [{}] is not supported based on the metadata for [{}]. ""
                    + ""The requested NameID format may not be honored. You should consult the metadata for this service ""
                    + ""and ensure the requested NameID format is present in the collection of supported ""
                    + ""metadata formats in the metadata, which are the following: [{}]"",
                requiredNameFormat, SamlIdPUtils.getIssuerFromSamlObject(authnRequest),
                adaptor.getEntityId(), adaptor.getSupportedNameIdFormats());
        }
    }"
"public static SimplePageDecorator first(){
        List<SimplePageDecorator> decorators = all();
        return decorators.isEmpty() ? null : decorators.get(0);
    }"
"public static boolean isAllLetter(String text)
    {
        for (int i = 0; i < text.length(); ++i)
        {
            char c = text.charAt(i);
            if ((((c < 'a' || c > 'z')) && ((c < 'A' || c > 'Z'))))
            {
                return false;
            }
        }

        return true;
    }"
"public List<Protos.Resource> takeScalar(String resourceName, double amount, Set<String> roles) {
		if (LOG.isDebugEnabled()) {
			LOG.debug(""Allocating {} {}"", amount, resourceName);
		}

		List<Protos.Resource> result = new ArrayList<>(1);
		for (ListIterator<Protos.Resource> i = resources.listIterator(); i.hasNext();) {
			if (amount <= EPSILON) {
				break;
			}

			// take from next available scalar resource that is unreserved or reserved for an applicable role
			Protos.Resource available = i.next();
			if (!resourceName.equals(available.getName()) || !available.hasScalar()) {
				continue;
			}
			if (!UNRESERVED_ROLE.equals(available.getRole()) && !roles.contains(available.getRole())) {
				continue;
			}

			double amountToTake = Math.min(available.getScalar().getValue(), amount);
			Protos.Resource taken = available.toBuilder().setScalar(Protos.Value.Scalar.newBuilder().setValue(amountToTake)).build();
			amount -= amountToTake;
			result.add(taken);
			if (LOG.isDebugEnabled()) {
				LOG.debug(""Taking {} from {}"", amountToTake, Utils.toString(available));
			}

			// keep remaining amount (if any)
			double remaining = available.getScalar().getValue() - taken.getScalar().getValue();
			if (remaining > EPSILON) {
				i.set(available.toBuilder().setScalar(Protos.Value.Scalar.newBuilder().setValue(remaining)).build());
			}
			else {
				i.remove();
			}
		}

		if (LOG.isDebugEnabled()) {
			LOG.debug(""Allocated: {}, unsatisfied: {}"", Utils.toString(result), amount);
		}
		return result;
	}"
"public static String getSerializerClass(Map<String, Object> tableProperties)
    {
        requireNonNull(tableProperties);

        @SuppressWarnings(""unchecked"")
        String serializerClass = (String) tableProperties.get(SERIALIZER);
        return serializerClass;
    }"
"public static Thread newThread(Runnable runnable, String name) {
		final Thread t = newThread(runnable, name, false);
		if (t.getPriority() != Thread.NORM_PRIORITY) {
			t.setPriority(Thread.NORM_PRIORITY);
		}
		return t;
	}"
"public static double w_1(double[] x, double[] y, int n) {
        return (n * sumOfProducts(x, y) - sum(x) * sum(y)) / (n * sumOfSquares(x) - Math.pow(sum(x), 2));
    }"
"@Override
  public WebElement findElement() {
    SlowLoadingElement loadingElement = new SlowLoadingElement(clock, timeOutInSeconds);
    try {
      return loadingElement.get().getElement();
    } catch (NoSuchElementError e) {
      throw new NoSuchElementException(
          String.format(""Timed out after %d seconds. %s"", timeOutInSeconds, e.getMessage()),
          e.getCause());
    }
  }"
"@Internal
	public Plan createProgramPlan(String jobName, boolean clearSinks) {
		if (this.sinks.isEmpty()) {
			if (wasExecuted) {
				throw new RuntimeException(""No new data sinks have been defined since the "" +
						""last execution. The last execution refers to the latest call to "" +
						""'execute()', 'count()', 'collect()', or 'print()'."");
			} else {
				throw new RuntimeException(""No data sinks have been created yet. "" +
						""A program needs at least one sink that consumes data. "" +
						""Examples are writing the data set or printing it."");
			}
		}

		if (jobName == null) {
			jobName = getDefaultName();
		}

		OperatorTranslation translator = new OperatorTranslation();
		Plan plan = translator.translateToPlan(this.sinks, jobName);

		if (getParallelism() > 0) {
			plan.setDefaultParallelism(getParallelism());
		}
		plan.setExecutionConfig(getConfig());

		// Check plan for GenericTypeInfo's and register the types at the serializers.
		if (!config.isAutoTypeRegistrationDisabled()) {
			plan.accept(new Visitor<org.apache.flink.api.common.operators.Operator<?>>() {

				private final Set<Class<?>> registeredTypes = new HashSet<>();
				private final Set<org.apache.flink.api.common.operators.Operator<?>> visitedOperators = new HashSet<>();

				@Override
				public boolean preVisit(org.apache.flink.api.common.operators.Operator<?> visitable) {
					if (!visitedOperators.add(visitable)) {
						return false;
					}
					OperatorInformation<?> opInfo = visitable.getOperatorInfo();
					Serializers.recursivelyRegisterType(opInfo.getOutputType(), config, registeredTypes);
					return true;
				}

				@Override
				public void postVisit(org.apache.flink.api.common.operators.Operator<?> visitable) {}
			});
		}

		try {
			registerCachedFilesWithPlan(plan);
		} catch (Exception e) {
			throw new RuntimeException(""Error while registering cached files: "" + e.getMessage(), e);
		}

		// clear all the sinks such that the next execution does not redo everything
		if (clearSinks) {
			this.sinks.clear();
			wasExecuted = true;
		}

		// All types are registered now. Print information.
		int registeredTypes = config.getRegisteredKryoTypes().size() +
				config.getRegisteredPojoTypes().size() +
				config.getRegisteredTypesWithKryoSerializerClasses().size() +
				config.getRegisteredTypesWithKryoSerializers().size();
		int defaultKryoSerializers = config.getDefaultKryoSerializers().size() +
				config.getDefaultKryoSerializerClasses().size();
		LOG.info(""The job has {} registered types and {} default Kryo serializers"", registeredTypes, defaultKryoSerializers);

		if (config.isForceKryoEnabled() && config.isForceAvroEnabled()) {
			LOG.warn(""In the ExecutionConfig, both Avro and Kryo are enforced. Using Kryo serializer"");
		}
		if (config.isForceKryoEnabled()) {
			LOG.info(""Using KryoSerializer for serializing POJOs"");
		}
		if (config.isForceAvroEnabled()) {
			LOG.info(""Using AvroSerializer for serializing POJOs"");
		}

		if (LOG.isDebugEnabled()) {
			LOG.debug(""Registered Kryo types: {}"", config.getRegisteredKryoTypes().toString());
			LOG.debug(""Registered Kryo with Serializers types: {}"", config.getRegisteredTypesWithKryoSerializers().entrySet().toString());
			LOG.debug(""Registered Kryo with Serializer Classes types: {}"", config.getRegisteredTypesWithKryoSerializerClasses().entrySet().toString());
			LOG.debug(""Registered Kryo default Serializers: {}"", config.getDefaultKryoSerializers().entrySet().toString());
			LOG.debug(""Registered Kryo default Serializers Classes {}"", config.getDefaultKryoSerializerClasses().entrySet().toString());
			LOG.debug(""Registered POJO types: {}"", config.getRegisteredPojoTypes().toString());

			// print information about static code analysis
			LOG.debug(""Static code analysis mode: {}"", config.getCodeAnalysisMode());
		}

		return plan;
	}"
"private static Optional<String> getColumnLocalityGroup(String columnName, Optional<Map<String, Set<String>>> groups)
    {
        if (groups.isPresent()) {
            for (Map.Entry<String, Set<String>> group : groups.get().entrySet()) {
                if (group.getValue().contains(columnName.toLowerCase(Locale.ENGLISH))) {
                    return Optional.of(group.getKey());
                }
            }
        }

        return Optional.empty();
    }"
"public static TimestampSpec mergeTimestampSpec(List<TimestampSpec> toMerge)
  {
    if (toMerge == null || toMerge.size() == 0) {
      return null;
    }

    TimestampSpec result = toMerge.get(0);
    for (int i = 1; i < toMerge.size(); i++) {
      if (toMerge.get(i) == null) {
        continue;
      }
      if (!Objects.equals(result, toMerge.get(i))) {
        return null;
      }
    }

    return result;
  }"
"public static BufferedImage cut(Image srcImage, int x, int y) {
		return cut(srcImage, x, y, -1);
	}"
"public static Color randomColor() {
		final Random random = getRandom();
		return new Color(random.nextInt(255), random.nextInt(255), random.nextInt(255));
	}"
"public static String[] tokenizeToStringArray(String str, String delimiters) {
        return tokenizeToStringArray(str, delimiters, true, true);
    }"
"public static <T extends Comparable<?>> List<T> bottomN(Iterable<T> coll, int n) {
		return Ordering.natural().leastOf(coll, n);
	}"
"private void failTask(final ExecutionAttemptID executionAttemptID, final Throwable cause) {
		final Task task = taskSlotTable.getTask(executionAttemptID);

		if (task != null) {
			try {
				task.failExternally(cause);
			} catch (Throwable t) {
				log.error(""Could not fail task {}."", executionAttemptID, t);
			}
		} else {
			log.debug(""Cannot find task to fail for execution {}."", executionAttemptID);
		}
	}"
"void copy(State source)
    {
        this.ref = source.ref;
        this.score = source.score;
        this.previous = source.previous;
        this.buffer = source.buffer;
        this.top0 = source.top0;
        this.top1 = source.top1;
        this.stack = source.stack;
        this.last_action = source.last_action;
        this.heads = source.heads;
        this.deprels = source.deprels;
        this.left_most_child = source.left_most_child;
        this.right_most_child = source.right_most_child;
        this.left_2nd_most_child = source.left_2nd_most_child;
        this.right_2nd_most_child = source.right_2nd_most_child;
        this.nr_left_children = source.nr_left_children;
        this.nr_right_children = source.nr_right_children;
    }"
"@Override
    public void startMonitor() {
        // 监听application.yml变化
        executor.scheduleWithFixedDelay(() -> {
            try {
                loadRemoteConfig();
            } catch (Throwable e) {
                logger.error(""scan remote application.yml failed"", e);
            }
        }, 10, 3, TimeUnit.SECONDS);

        // 监听adapter变化
        executor.scheduleWithFixedDelay(() -> {
            try {
                loadRemoteAdapterConfigs();
            } catch (Throwable e) {
                logger.error(""scan remote adapter configs failed"", e);
            }
        }, 10, 3, TimeUnit.SECONDS);
    }"
"public <K> DistinctOperator<T> distinct(KeySelector<T, K> keyExtractor) {
		TypeInformation<K> keyType = TypeExtractor.getKeySelectorTypes(keyExtractor, getType());
		return new DistinctOperator<>(this, new Keys.SelectorFunctionKeys<>(keyExtractor, getType(), keyType), Utils.getCallLocationName());
	}"
"public void startMonitor(final RemoteCanalConfigMonitor remoteCanalConfigMonitor) {
        // 监听canal.properties变化
        executor.scheduleWithFixedDelay(new Runnable() {

            public void run() {
                try {
                    Properties properties = loadRemoteConfig();
                    if (properties != null) {
                        remoteCanalConfigMonitor.onChange(properties);
                    }
                } catch (Throwable e) {
                    logger.error(""Scan remote canal config failed"", e);
                }
            }

        }, 10, scanIntervalInSecond, TimeUnit.SECONDS);

        // 监听instance变化
        executor.scheduleWithFixedDelay(new Runnable() {

            public void run() {
                try {
                    loadRemoteInstanceConfigs();
                } catch (Throwable e) {
                    logger.error(""Scan remote instance config failed"", e);
                }
            }

        }, 10, 3, TimeUnit.SECONDS);
    }"
"public static File writeUtf8String(String content, File file) throws IORuntimeException {
		return writeString(content, file, CharsetUtil.CHARSET_UTF_8);
	}"
"public static byte[] decodeHexDump(CharSequence hexDump, int fromIndex, int length) {
        if (length < 0 || (length & 1) != 0) {
            throw new IllegalArgumentException(""length: "" + length);
        }
        if (length == 0) {
            return EmptyArrays.EMPTY_BYTES;
        }
        byte[] bytes = new byte[length >>> 1];
        for (int i = 0; i < length; i += 2) {
            bytes[i >>> 1] = decodeHexByte(hexDump, fromIndex + i);
        }
        return bytes;
    }"
"protected Postcard build(String path, String group) {
        if (TextUtils.isEmpty(path) || TextUtils.isEmpty(group)) {
            throw new HandlerException(Consts.TAG + ""Parameter is invalid!"");
        } else {
            PathReplaceService pService = ARouter.getInstance().navigation(PathReplaceService.class);
            if (null != pService) {
                path = pService.forString(path);
            }
            return new Postcard(path, group);
        }
    }"
"private void add(int previous, int index, Trie.Node node) {

        if (!node.getChildren().isEmpty() && node.hasSinglePath()
                        && node.getChildren().get(0).getKey() != TERMINATING_CHARACTER) { // If node has only one path, put the rest in tail array
            baseBuffer.put(index, tailIndex); // current index of tail array
            addToTail(node.getChildren().get(0));
            checkBuffer.put(index, previous);
            return; // No more child to process
        }

        int startIndex = (compact ? 0 : index);
        int base = findBase(startIndex, node.getChildren());

        baseBuffer.put(index, base);

        if (previous >= 0) {
            checkBuffer.put(index, previous); // Set check value
        }

        for (Trie.Node child : node.getChildren()) { // For each child to double array trie
            if (compact) {
                add(index, base + child.getKey(), child);
            } else {
                add(index, index + base + child.getKey(), child);
            }
        }

    }"
"@Nullable
  public static List<LbConfig> getFallbackPolicyFromXdsConfig(LbConfig xdsConfig) {
    Map<String, ?> map = xdsConfig.getRawConfigValue();
    List<?> rawFallbackPolicies = getList(map, XDS_CONFIG_FALLBACK_POLICY_KEY);
    if (rawFallbackPolicies != null) {
      return unwrapLoadBalancingConfigList(checkObjectList(rawFallbackPolicies));
    }
    return null;
  }"
"@Override
    protected void putDumpInfoTo(Map<String, Object> result) {
        if(this.cookieMap.size() > 0) {
            result.put(DumpConstants.COOKIES, cookieMap);
        }
    }"
"private void notifyOfNewResourceManagerLeader(String newLeaderAddress, ResourceManagerId newResourceManagerId) {
		resourceManagerAddress = createResourceManagerAddress(newLeaderAddress, newResourceManagerId);
		reconnectToResourceManager(new FlinkException(String.format(""ResourceManager leader changed to new address %s"", resourceManagerAddress)));
	}"
"public void build(Keyset keyset)
    {
        if (keyset.hasValues())
        {
            DawgBuilder dawgBuilder = new DawgBuilder();
            buildDawg(keyset, dawgBuilder);
            buildFromDawg(dawgBuilder);
            dawgBuilder.clear();
        }
        else
        {
            buildFromKeyset(keyset);
        }
    }"
"private void sendPingFrame(ChannelHandlerContext ctx, SendPingCommand msg,
      ChannelPromise promise) {
    // Don't check lifecycleManager.getShutdownStatus() since we want to allow pings after shutdown
    // but before termination. After termination, messages will no longer arrive because the
    // pipeline clears all handlers on channel close.

    PingCallback callback = msg.callback();
    Executor executor = msg.executor();
    // we only allow one outstanding ping at a time, so just add the callback to
    // any outstanding operation
    if (ping != null) {
      promise.setSuccess();
      ping.addCallback(callback, executor);
      return;
    }

    // Use a new promise to prevent calling the callback twice on write failure: here and in
    // NettyClientTransport.ping(). It may appear strange, but it will behave the same as if
    // ping != null above.
    promise.setSuccess();
    promise = ctx().newPromise();
    // set outstanding operation
    long data = USER_PING_PAYLOAD;
    Stopwatch stopwatch = stopwatchFactory.get();
    stopwatch.start();
    ping = new Http2Ping(data, stopwatch);
    ping.addCallback(callback, executor);
    // and then write the ping
    encoder().writePing(ctx, false, USER_PING_PAYLOAD, promise);
    ctx.flush();
    final Http2Ping finalPing = ping;
    promise.addListener(new ChannelFutureListener() {
      @Override
      public void operationComplete(ChannelFuture future) throws Exception {
        if (future.isSuccess()) {
          transportTracer.reportKeepAliveSent();
        } else {
          Throwable cause = future.cause();
          if (cause instanceof ClosedChannelException) {
            cause = lifecycleManager.getShutdownThrowable();
            if (cause == null) {
              cause = Status.UNKNOWN.withDescription(""Ping failed but for unknown reason."")
                  .withCause(future.cause()).asException();
            }
          }
          finalPing.failed(cause);
          if (ping == finalPing) {
            ping = null;
          }
        }
      }
    });
  }"
"public double falseAlarmRate() {
        if(binaryPositiveClass != null && numClasses() == 2){
            return (falsePositiveRate(binaryPositiveClass) + falseNegativeRate(binaryPositiveClass)) / 2.0;
        }
        return (falsePositiveRate() + falseNegativeRate()) / 2.0;
    }"
"public static WatchMonitor createAll(Path path, Watcher watcher){
		final WatchMonitor watchMonitor = create(path, EVENTS_ALL);
		watchMonitor.setWatcher(watcher);
		return watchMonitor;
	}"
"public static <T> Callable<T> recover(Callable<T> callable, Function<Exception, T> exceptionHandler){
        return () -> {
            try{
                return callable.call();
            }catch (Exception exception){
                return exceptionHandler.apply(exception);
            }
        };
    }"
"private ByteBuf allocate(ChannelHandlerContext ctx, int capacity) {
        ByteBufAllocator alloc = ctx.alloc();
        if (engineType.wantsDirectBuffer) {
            return alloc.directBuffer(capacity);
        } else {
            return alloc.buffer(capacity);
        }
    }"
"private void checkNidVaild(String nid) {
        Node node = configClientService.currentNode();
        String hostIp = AddressUtils.getHostIp();
        String nodeIp = node.getIp();
        int nodePort = node.getPort().intValue();
        if (!AddressUtils.isHostIp(nodeIp)) {
            throw new IllegalArgumentException(
                                               String.format(""node[%s] ip[%s] port[%s] , but your host ip[%s] is not matched!"",
                                                             nid, nodeIp, nodePort, hostIp));
        }
    }"
"protected void mergeNumberQuantifier(List<Vertex> termList, WordNet wordNetAll, Config config)
    {
        if (termList.size() < 4) return;
        StringBuilder sbQuantifier = new StringBuilder();
        ListIterator<Vertex> iterator = termList.listIterator();
        iterator.next();
        int line = 1;
        while (iterator.hasNext())
        {
            Vertex pre = iterator.next();
            if (pre.hasNature(Nature.m))
            {
                sbQuantifier.append(pre.realWord);
                Vertex cur = null;
                while (iterator.hasNext() && (cur = iterator.next()).hasNature(Nature.m))
                {
                    sbQuantifier.append(cur.realWord);
                    iterator.remove();
                    removeFromWordNet(cur, wordNetAll, line, sbQuantifier.length());
                }
                if (cur != null)
                {
                    if ((cur.hasNature(Nature.q) || cur.hasNature(Nature.qv) || cur.hasNature(Nature.qt)))
                    {
                        if (config.indexMode > 0)
                        {
                            wordNetAll.add(line, new Vertex(sbQuantifier.toString(), new CoreDictionary.Attribute(Nature.m)));
                        }
                        sbQuantifier.append(cur.realWord);
                        iterator.remove();
                        removeFromWordNet(cur, wordNetAll, line, sbQuantifier.length());
                    }
                    else
                    {
                        line += cur.realWord.length();   // (cur = iterator.next()).hasNature(Nature.m) 最后一个next可能不含q词性
                    }
                }
                if (sbQuantifier.length() != pre.realWord.length())
                {
                    for (Vertex vertex : wordNetAll.get(line + pre.realWord.length()))
                    {
                        vertex.from = null;
                    }
                    pre.realWord = sbQuantifier.toString();
                    pre.word = Predefine.TAG_NUMBER;
                    pre.attribute = new CoreDictionary.Attribute(Nature.mq);
                    pre.wordID = CoreDictionary.M_WORD_ID;
                    sbQuantifier.setLength(0);
                }
            }
            sbQuantifier.setLength(0);
            line += pre.realWord.length();
        }
//        System.out.println(wordNetAll);
    }"
"private void writeOutRequestParams(List<String> elements, Writer out) throws IOException {
		if (elements != null && elements.size() > 0) {
			for (String param : elements) {
				out.write(""\n\t\t\"""" + param + ""\"": "");
				if (param.equalsIgnoreCase(""boolean"")) {
					addImports = true;
					out.write(""strconv.FormatBool(boolean)"");
				} else if (param.equalsIgnoreCase(""integer"")) {
					addImports = true;
					out.write(""strconv.Itoa(i)"");
				} else if (param.equalsIgnoreCase(""string"")) {
					out.write(""str"");
				} else if (param.equalsIgnoreCase(""type"")) {
					out.write(""t"");
				} else {
					out.write(param.toLowerCase());
				}
				out.write("","");
			}
		}
	}"
"private static int next_idx( long [] tl ) {
    // Spin until we can CAS-acquire a fresh index
    while( true ) {
      int oldidx = (int)tl[0];
      int newidx = (oldidx+1)&(MAX_EVENTS-1);
      if( CAS( tl, 0, oldidx, newidx ) )
        return oldidx;
    }
  }"
"public SingleCSVRecord transform(SingleCSVRecord record) {
        List<Writable> record2 = toArrowWritablesSingle(
                toArrowColumnsStringSingle(bufferAllocator,
                        transformProcess.getInitialSchema(),record.getValues()),
                transformProcess.getInitialSchema());
        List<Writable> finalRecord = execute(Arrays.asList(record2),transformProcess).get(0);
        String[] values = new String[finalRecord.size()];
        for (int i = 0; i < values.length; i++)
            values[i] = finalRecord.get(i).toString();
        return new SingleCSVRecord(values);

    }"
"void setValue(int value) {
    Integer confidence = values.get(value);
    if (confidence == null) {
      confidence = 0;
    }
    confidence++;
    values.put(value, confidence);
  }"
"@Override
  public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception {
    if (evt instanceof IdleStateEvent) {
      IdleStateEvent e = (IdleStateEvent) evt;
      // See class comment for timeout semantics. In addition to ensuring we only timeout while
      // there are outstanding requests, we also do a secondary consistency check to ensure
      // there's no race between the idle timeout and incrementing the numOutstandingRequests
      // (see SPARK-7003).
      //
      // To avoid a race between TransportClientFactory.createClient() and this code which could
      // result in an inactive client being returned, this needs to run in a synchronized block.
      synchronized (this) {
        boolean hasInFlightRequests = responseHandler.numOutstandingRequests() > 0;
        boolean isActuallyOverdue =
          System.nanoTime() - responseHandler.getTimeOfLastRequestNs() > requestTimeoutNs;
        if (e.state() == IdleState.ALL_IDLE && isActuallyOverdue) {
          if (hasInFlightRequests) {
            String address = getRemoteAddress(ctx.channel());
            logger.error(""Connection to {} has been quiet for {} ms while there are outstanding "" +
              ""requests. Assuming connection is dead; please adjust spark.network.timeout if "" +
              ""this is wrong."", address, requestTimeoutNs / 1000 / 1000);
            client.timeOut();
            ctx.close();
          } else if (closeIdleConnections) {
            // While CloseIdleConnections is enable, we also close idle connection
            client.timeOut();
            ctx.close();
          }
        }
      }
    }
    ctx.fireUserEventTriggered(evt);
  }"
"public Log getLog(String name) {
		Log log = logCache.get(name);
		if (null == log) {
			log = createLog(name);
			logCache.put(name, log);
		}
		return log;
	}"
"public boolean skipPast(String to) throws JSONException {
		boolean b;
		char c;
		int i;
		int j;
		int offset = 0;
		int length = to.length();
		char[] circle = new char[length];

		/*
		 * First fill the circle buffer with as many characters as are in the to string. If we reach an early end, bail.
		 */

		for (i = 0; i < length; i += 1) {
			c = next();
			if (c == 0) {
				return false;
			}
			circle[i] = c;
		}

		/* We will loop, possibly for all of the remaining characters. */

		for (;;) {
			j = offset;
			b = true;

			/* Compare the circle buffer with the to string. */

			for (i = 0; i < length; i += 1) {
				if (circle[j] != to.charAt(i)) {
					b = false;
					break;
				}
				j += 1;
				if (j >= length) {
					j -= length;
				}
			}

			/* If we exit the loop with b intact, then victory is ours. */

			if (b) {
				return true;
			}

			/* Get the next character. If there isn't one, then defeat is ours. */

			c = next();
			if (c == 0) {
				return false;
			}
			/*
			 * Shove the character in the circle buffer and advance the circle offset. The offset is mod n.
			 */
			circle[offset] = c;
			offset += 1;
			if (offset >= length) {
				offset -= length;
			}
		}
	}"
"public static void parseText(String text, AhoCorasickDoubleArrayTrie.IHit<CoreDictionary.Attribute> processor)
    {
        if (trie != null)
        {
            BaseSearcher searcher = CustomDictionary.getSearcher(text);
            int offset;
            Map.Entry<String, CoreDictionary.Attribute> entry;
            while ((entry = searcher.next()) != null)
            {
                offset = searcher.getOffset();
                processor.hit(offset, offset + entry.getKey().length(), entry.getValue());
            }
        }
        DoubleArrayTrie<CoreDictionary.Attribute>.Searcher searcher = dat.getSearcher(text, 0);
        while (searcher.next())
        {
            processor.hit(searcher.begin, searcher.begin + searcher.length, searcher.value);
        }
    }"
"public void registerFrame(@NonNull String frame_name) {
        if (!frames.containsKey(frame_name))
            frames.put(frame_name, new FrameState(frame_name));
    }"
"protected static ForkJoinTask<?> pollTask() {
        ForkJoinWorkerThread wt =
            (ForkJoinWorkerThread)Thread.currentThread();
        return wt.pool.nextTaskFor(wt.workQueue);
    }"
"public boolean canStoreCompact()
  {
    final long exactCount = getExactCount();
    return (size <= Short.MAX_VALUE && exactCount <= Byte.MAX_VALUE && (count - exactCount) <= Byte.MAX_VALUE);
  }"
"@Override
    public void set(final long value)
    {
        final Sequence[] sequences = this.sequences;
        for (Sequence sequence : sequences)
        {
            sequence.set(value);
        }
    }"
"protected boolean doRejectedAttributesRefusePrincipalAccess(final Map<String, Object> principalAttributes) {
        LOGGER.debug(""These rejected attributes [{}] are examined against [{}] before service can proceed."", rejectedAttributes, principalAttributes);
        if (rejectedAttributes.isEmpty()) {
            return false;
        }
        return requiredAttributesFoundInMap(principalAttributes, rejectedAttributes);
    }"
"protected void pushToGrid(OpDescriptor descriptor, boolean flush) {

        // we should just add op to queue here
        //deviceQueues.get().add(descriptor);

        // FIXME: following code should be removed, since it's just executing supers instead of batching

        execCounter.incrementAndGet();

        Op op = descriptor.getOp();
        int[] dimensions = descriptor.getDimensions();

        if (op instanceof TransformOp) {
            TransformOp t = (TransformOp) op;
            if (flush)
                flushQueue();

            //logger.info(""Sending TransformOp to CudaExecutioner"");
            super.invoke(t);
        } else if (op instanceof Variance) {
            Variance acc = (Variance) op;
            if (flush)
                flushQueue();

            super.naiveExec(acc, dimensions);
        } else if (op instanceof ReduceOp) {
            ReduceOp acc = (ReduceOp) op;
            if (flush)
                flushQueue();

            //logger.info(""Sending AccumulationOp to CudaExecutioner: {}"", Arrays.toString(dimensions));
            super.naiveExec(acc, dimensions);
        } else if (op instanceof ScalarOp) {
            ScalarOp sc = (ScalarOp) op;
            if (flush)
                flushQueue();

            //logger.info(""Sending ScalarOp to CudaExecutioner"");
            super.invoke(sc);
        } else if (op instanceof BroadcastOp) {
            BroadcastOp broadcastOp = (BroadcastOp) op;
            if (flush)
                flushQueue();

            //logger.info(""Sending BroadcastOp to CudaExecutioner"");
            if (dimensions != null) {
                super.exec(broadcastOp);
            } else {
                super.invoke(broadcastOp);
            }
        } else if (op instanceof IndexAccumulation) {
            IndexAccumulation indexAccumulation = (IndexAccumulation) op;
            if (flush)
                flushQueue();

            //logger.info(""Sending IndexAccumulationOp to CudaExecutioner"");
            //super.exec(indexAccumulation, dimensions);
        } else if (op instanceof MetaOp) {
            //     logger.info(""Executing MetaOp"");
            metaCounter.incrementAndGet();
            exec((MetaOp) op);
        } else if (op instanceof GridOp) {
            //    logger.info(""Executing GridOp"");
            exec((GridOp) op);
        }
    }"
"private <T> void deployJob(ExecutionContext<T> context, JobGraph jobGraph, Result<T> result) {
		// create or retrieve cluster and deploy job
		try (final ClusterDescriptor<T> clusterDescriptor = context.createClusterDescriptor()) {
			try {
				// new cluster
				if (context.getClusterId() == null) {
					deployJobOnNewCluster(clusterDescriptor, jobGraph, result, context.getClassLoader());
				}
				// reuse existing cluster
				else {
					deployJobOnExistingCluster(context.getClusterId(), clusterDescriptor, jobGraph, result);
				}
			} catch (Exception e) {
				throw new SqlExecutionException(""Could not retrieve or create a cluster."", e);
			}
		} catch (SqlExecutionException e) {
			throw e;
		} catch (Exception e) {
			throw new SqlExecutionException(""Could not locate a cluster."", e);
		}
	}"
"public static Map<String, Object> beanToMap(Object bean, Map<String, Object> targetMap, final boolean isToUnderlineCase, boolean ignoreNullValue) {
		if (bean == null) {
			return null;
		}

		return beanToMap(bean, targetMap, ignoreNullValue, new Editor<String>() {

			@Override
			public String edit(String key) {
				return isToUnderlineCase ? StrUtil.toUnderlineCase(key) : key;
			}
		});
	}"
"public BlockingQueue<Runnable> getBlockingQueue(int maxQueueSize) {
        /*
         * We are using SynchronousQueue if maxQueueSize <= 0 (meaning a queue is not wanted).
         * <p>
         * SynchronousQueue will do a handoff from calling thread to worker thread and not allow queuing which is what we want.
         * <p>
         * Queuing results in added latency and would only occur when the thread-pool is full at which point there are latency issues
         * and rejecting is the preferred solution.
         */
        if (maxQueueSize <= 0) {
            return new SynchronousQueue<Runnable>();
        } else {
            return new LinkedBlockingQueue<Runnable>(maxQueueSize);
        }
    }"
"public ProcessBuilder processBuilder(String... arguments) {
		ProcessBuilder processBuilder = new ProcessBuilder(toString());
		processBuilder.command().addAll(Arrays.asList(arguments));
		return processBuilder;
	}"
"static public DisabledJob fromDeprecatedObject(Object obj) {
    if (obj == null) {
      return null;
    }
    if (obj instanceof String) {
      return new DisabledJob((String)obj);
    } else if (obj instanceof Map) {
      Map<String, Object> map = (Map<String, Object>)obj;
      String name = (String)map.get(SUBFLOW_ID_KEY);
      List<DisabledJob> childJobs = fromDeprecatedObjectList((List<Object>)map.get
          (SUBFLOW_CHILDREN_KEY));
      if (name != null && childJobs != null) {
        return new DisabledJob(name, childJobs);
      }
    }
    return null;
  }"
"@Override
	protected List<OUT> executeOnCollections(List<IN1> inputData1, List<IN2> inputData2, RuntimeContext ctx, ExecutionConfig executionConfig) throws Exception {
		CrossFunction<IN1, IN2, OUT> function = this.userFunction.getUserCodeObject();
		
		FunctionUtils.setFunctionRuntimeContext(function, ctx);
		FunctionUtils.openFunction(function, this.parameters);

		ArrayList<OUT> result = new ArrayList<OUT>(inputData1.size() * inputData2.size());
		
		TypeSerializer<IN1> inSerializer1 = getOperatorInfo().getFirstInputType().createSerializer(executionConfig);
		TypeSerializer<IN2> inSerializer2 = getOperatorInfo().getSecondInputType().createSerializer(executionConfig);
		TypeSerializer<OUT> outSerializer = getOperatorInfo().getOutputType().createSerializer(executionConfig);

		for (IN1 element1 : inputData1) {
			for (IN2 element2 : inputData2) {
				IN1 copy1 = inSerializer1.copy(element1);
				IN2 copy2 = inSerializer2.copy(element2);
				OUT o = function.cross(copy1, copy2);
				result.add(outSerializer.copy(o));
			}
		}

		FunctionUtils.closeFunction(function);
		return result;
	}"
"public void recreateUISharedContexts(Session session) {
		uiContexts.clear();
		for (Context context : session.getContexts()) {
			Context uiContext = context.duplicate();
			uiContexts.put(context.getIndex(), uiContext);
		}
	}"
"protected KinesisDataFetcher<T> createFetcher(
			List<String> streams,
			SourceFunction.SourceContext<T> sourceContext,
			RuntimeContext runtimeContext,
			Properties configProps,
			KinesisDeserializationSchema<T> deserializationSchema) {

		return new KinesisDataFetcher<>(streams, sourceContext, runtimeContext, configProps, deserializationSchema, shardAssigner, periodicWatermarkAssigner);
	}"
"@Override
	public void configure(Configuration parameters) {

		// enforce sequential configuration() calls
		synchronized (CONFIGURE_MUTEX) {
			if (mapreduceInputFormat instanceof Configurable) {
				((Configurable) mapreduceInputFormat).setConf(configuration);
			}
		}
	}"
"public void initDelegateDialect(MappedStatement ms) {
        if (delegate == null) {
            if (autoDialect) {
                this.delegate = getDialect(ms);
            } else {
                dialectThreadLocal.set(getDialect(ms));
            }
        }
    }"
"protected final ByteBuf composeIntoComposite(ByteBufAllocator alloc, ByteBuf cumulation, ByteBuf next) {
        // Create a composite buffer to accumulate this pair and potentially all the buffers
        // in the queue. Using +2 as we have already dequeued current and next.
        CompositeByteBuf composite = alloc.compositeBuffer(size() + 2);
        try {
            composite.addComponent(true, cumulation);
            composite.addComponent(true, next);
        } catch (Throwable cause) {
            composite.release();
            safeRelease(next);
            throwException(cause);
        }
        return composite;
    }"
"public static UTF8String blankString(int length) {
    byte[] spaces = new byte[length];
    Arrays.fill(spaces, (byte) ' ');
    return fromBytes(spaces);
  }"
"public static BufferedWriter asBufferedWriter(Path path) throws IOException {
		Validate.notNull(path, ""path is null"");
		return Files.newBufferedWriter(path, Charsets.UTF_8);
	}"
"@ReadOperation
    public Map<?, ?> getReport(@Nullable final String flowId) {
        val jsonMap = new LinkedHashMap<String, Object>();
        val map = this.applicationContext.getBeansOfType(FlowDefinitionRegistry.class, false, true);

        map.forEach((k, v) -> Arrays.stream(v.getFlowDefinitionIds())
            .filter(currentId -> {
                if (StringUtils.isNotBlank(flowId)) {
                    return flowId.equalsIgnoreCase(currentId);
                }
                return true;
            })
            .forEach(id -> {
                val flowDetails = new LinkedHashMap<String, Object>();
                val def = Flow.class.cast(v.getFlowDefinition(id));
                flowDetails.put(""startState"", def.getStartState().getId());

                val states = new LinkedHashMap<String, Map>();
                Arrays.stream(def.getStateIds()).forEach(st -> {

                    val state = (State) def.getState(st);
                    val stateMap = new LinkedHashMap<String, Object>();

                    if (!state.getAttributes().asMap().isEmpty()) {
                        stateMap.put(""attributes"", CollectionUtils.wrap(state.getAttributes()));
                    }
                    if (StringUtils.isNotBlank(state.getCaption())) {
                        stateMap.put(""caption"", state.getCaption());
                    }

                    var acts = StreamSupport.stream(state.getEntryActionList().spliterator(), false)
                        .map(Object::toString)
                        .collect(Collectors.toList());

                    if (!acts.isEmpty()) {
                        stateMap.put(""entryActions"", acts);
                    }

                    if (state instanceof ActionState) {
                        acts = StreamSupport.stream(ActionState.class.cast(state).getActionList().spliterator(), false)
                            .map(Object::toString)
                            .collect(Collectors.toList());
                        if (!acts.isEmpty()) {
                            stateMap.put(""actionList"", acts);
                        }
                    }

                    if (state instanceof EndState) {
                        stateMap.put(""isEndState"", Boolean.TRUE);
                    }
                    if (state.isViewState()) {
                        stateMap.put(""isViewState"", state.isViewState());
                        stateMap.put(""isRedirect"", ((ViewState) state).getRedirect());

                        acts = StreamSupport.stream(state.getEntryActionList().spliterator(), false)
                            .map(Object::toString)
                            .collect(Collectors.toList());

                        if (!acts.isEmpty()) {
                            stateMap.put(""renderActions"", ((ViewState) state).getRenderActionList());
                        }

                        acts = Arrays.stream(((ViewState) state).getVariables())
                            .map(value -> value.getName() + "" -> "" + value.getValueFactory().toString())
                            .collect(Collectors.toList());

                        if (!acts.isEmpty()) {
                            stateMap.put(""viewVariables"", acts);
                        }

                        val field = ReflectionUtils.findField(((ViewState) state).getViewFactory().getClass(), ""viewId"");
                        if (field != null) {
                            ReflectionUtils.makeAccessible(field);
                            val exp = (Expression) ReflectionUtils.getField(field, ((ViewState) state).getViewFactory());
                            stateMap.put(""viewId"", StringUtils.defaultIfBlank(exp.getExpressionString(), exp.getValue(null).toString()));
                        } else {
                            LOGGER.warn(""Field viewId cannot be located on view state [{}]"", state);
                        }
                    }

                    if (state instanceof TransitionableState) {
                        val stDef = TransitionableState.class.cast(state);

                        acts = StreamSupport.stream(stDef.getExitActionList().spliterator(), false)
                            .map(Object::toString)
                            .collect(Collectors.toList());

                        if (!acts.isEmpty()) {
                            stateMap.put(""exitActions"", acts);
                        }

                        acts = Arrays.stream(stDef.getTransitions())
                            .map(tr -> tr.getId() + "" -> "" + tr.getTargetStateId())
                            .collect(Collectors.toList());

                        if (!acts.isEmpty()) {
                            stateMap.put(""transitions"", acts);
                        }
                    }
                    states.put(st, stateMap);
                });
                flowDetails.put(""states"", states);
                flowDetails.put(""possibleOutcomes"", def.getPossibleOutcomes());
                flowDetails.put(""stateCount"", def.getStateCount());

                var acts = StreamSupport.stream(def.getEndActionList().spliterator(), false)
                    .map(Object::toString)
                    .collect(Collectors.toList());
                if (!acts.isEmpty()) {
                    flowDetails.put(""endActions"", acts);
                }

                acts = StreamSupport.stream(def.getGlobalTransitionSet().spliterator(), false)
                    .map(tr -> tr.getId() + "" -> "" + tr.getTargetStateId() + "" @ "" + tr.getExecutionCriteria().toString())
                    .collect(Collectors.toList());
                if (!acts.isEmpty()) {
                    flowDetails.put(""globalTransitions"", acts);
                }

                acts = Arrays.stream(def.getExceptionHandlerSet().toArray())
                    .map(Object::toString)
                    .collect(Collectors.toList());
                if (!acts.isEmpty()) {
                    flowDetails.put(""exceptionHandlers"", acts);
                }

                val vars = Arrays.stream(def.getVariables())
                    .map(FlowVariable::getName)
                    .collect(Collectors.joining("",""));

                if (StringUtils.isNotBlank(vars)) {
                    flowDetails.put(""variables"", vars);
                }

                jsonMap.put(id, flowDetails);
            }));

        return jsonMap;
    }"
"public void addPoint(Point point, boolean moveClusterCenter) {
        if (moveClusterCenter) {
            if (isInverse()) {
                center.getArray().muli(points.size()).subi(point.getArray()).divi(points.size() + 1);
            } else {
                center.getArray().muli(points.size()).addi(point.getArray()).divi(points.size() + 1);
            }
        }

        getPoints().add(point);
    }"
"public EpollChannelConfig setEpollMode(EpollMode mode) {
        if (mode == null) {
            throw new NullPointerException(""mode"");
        }
        try {
            switch (mode) {
            case EDGE_TRIGGERED:
                checkChannelNotRegistered();
                ((AbstractEpollChannel) channel).setFlag(Native.EPOLLET);
                break;
            case LEVEL_TRIGGERED:
                checkChannelNotRegistered();
                ((AbstractEpollChannel) channel).clearFlag(Native.EPOLLET);
                break;
            default:
                throw new Error();
            }
        } catch (IOException e) {
            throw new ChannelException(e);
        }
        return this;
    }"
"private void checkCloseConnection(ChannelFuture future) {
        // If this connection is closing and the graceful shutdown has completed, close the connection
        // once this operation completes.
        if (closeListener != null && isGracefulShutdownComplete()) {
            ChannelFutureListener closeListener = this.closeListener;
            // This method could be called multiple times
            // and we don't want to notify the closeListener multiple times.
            this.closeListener = null;
            try {
                closeListener.operationComplete(future);
            } catch (Exception e) {
                throw new IllegalStateException(""Close listener threw an unexpected exception"", e);
            }
        }
    }"
"@VisibleForTesting
  static <T> Iterable<T> getCandidatesViaHardCoded(Class<T> klass, Iterable<Class<?>> hardcoded) {
    List<T> list = new ArrayList<>();
    for (Class<?> candidate : hardcoded) {
      list.add(create(klass, candidate));
    }
    return list;
  }"
"public Graph<K, VV, EV> removeEdge(Edge<K, EV> edge) {
		DataSet<Edge<K, EV>> newEdges = getEdges().filter(new EdgeRemovalEdgeFilter<>(edge)).name(""Remove edge"");
		return new Graph<>(this.vertices, newEdges, this.context);
	}"
"@Deprecated
    protected final void requirePOST() throws ServletException {
        StaplerRequest req = Stapler.getCurrentRequest();
        if (req==null)  return; // invoked outside the context of servlet
        String method = req.getMethod();
        if(!method.equalsIgnoreCase(""POST""))
            throw new ServletException(""Must be POST, Can't be ""+method);
    }"
"protected void configureSamlClient(final Collection<BaseClient> properties) {
        val index = new AtomicInteger();
        pac4jProperties.getSaml()
            .stream()
            .filter(saml -> StringUtils.isNotBlank(saml.getKeystorePath())
                && StringUtils.isNotBlank(saml.getIdentityProviderMetadataPath())
                && StringUtils.isNotBlank(saml.getServiceProviderEntityId())
                && StringUtils.isNotBlank(saml.getServiceProviderMetadataPath()))
            .forEach(saml -> {
                val cfg = new SAML2Configuration(saml.getKeystorePath(),
                    saml.getKeystorePassword(),
                    saml.getPrivateKeyPassword(), saml.getIdentityProviderMetadataPath());
                cfg.setMaximumAuthenticationLifetime(saml.getMaximumAuthenticationLifetime());
                cfg.setServiceProviderEntityId(saml.getServiceProviderEntityId());
                cfg.setServiceProviderMetadataPath(saml.getServiceProviderMetadataPath());
                cfg.setAuthnRequestBindingType(saml.getDestinationBinding());
                cfg.setForceAuth(saml.isForceAuth());
                cfg.setPassive(saml.isPassive());
                cfg.setSignMetadata(saml.isSignServiceProviderMetadata());

                if (StringUtils.isNotBlank(saml.getPrincipalIdAttribute())) {
                    cfg.setAttributeAsId(saml.getPrincipalIdAttribute());
                }
                cfg.setWantsAssertionsSigned(saml.isWantsAssertionsSigned());
                cfg.setLogoutHandler(casServerSpecificLogoutHandler);
                cfg.setUseNameQualifier(saml.isUseNameQualifier());
                cfg.setAttributeConsumingServiceIndex(saml.getAttributeConsumingServiceIndex());
                if (saml.getAssertionConsumerServiceIndex() >= 0) {
                    cfg.setAssertionConsumerServiceIndex(saml.getAssertionConsumerServiceIndex());
                }
                if (StringUtils.isNotBlank(saml.getAuthnContextClassRef())) {
                    cfg.setComparisonType(saml.getAuthnContextComparisonType().toUpperCase());
                    cfg.setAuthnContextClassRef(saml.getAuthnContextClassRef());
                }
                if (StringUtils.isNotBlank(saml.getKeystoreAlias())) {
                    cfg.setKeystoreAlias(saml.getKeystoreAlias());
                }
                if (StringUtils.isNotBlank(saml.getNameIdPolicyFormat())) {
                    cfg.setNameIdPolicyFormat(saml.getNameIdPolicyFormat());
                }

                if (!saml.getRequestedAttributes().isEmpty()) {
                    saml.getRequestedAttributes().stream()
                        .map(attribute -> new SAML2ServiceProvicerRequestedAttribute(attribute.getName(), attribute.getFriendlyName(),
                            attribute.getNameFormat(), attribute.isRequired()))
                        .forEach(attribute -> cfg.getRequestedServiceProviderAttributes().add(attribute));
                }

                val mappedAttributes = saml.getMappedAttributes();
                if (!mappedAttributes.isEmpty()) {
                    val results = mappedAttributes
                        .stream()
                        .collect(Collectors.toMap(Pac4jSamlClientProperties.ServiceProviderMappedAttribute::getName,
                            Pac4jSamlClientProperties.ServiceProviderMappedAttribute::getMappedTo));
                    cfg.setMappedAttributes(results);
                }

                val client = new SAML2Client(cfg);

                val count = index.intValue();
                if (StringUtils.isBlank(saml.getClientName())) {
                    client.setName(client.getClass().getSimpleName() + count);
                }
                configureClient(client, saml);

                index.incrementAndGet();
                LOGGER.debug(""Created delegated client [{}]"", client);
                properties.add(client);
            });
    }"
"@Override
	public boolean publish(ResultPartitionID partitionId, TaskEvent event) {
		checkNotNull(partitionId);
		checkNotNull(event);

		TaskEventHandler taskEventHandler;
		synchronized (registeredHandlers) {
			taskEventHandler = registeredHandlers.get(partitionId);
		}

		if (taskEventHandler != null) {
			taskEventHandler.publish(event);
			return true;
		}

		return false;
	}"
"private static URL findHelpSetUrl() {
		return LocaleUtils.findResource(
				HELP_SET_FILE_NAME,
				HELP_SET_FILE_EXTENSION,
				Constant.getLocale(),
				r -> ExtensionFactory.getAddOnLoader().getResource(r));
	}"
"public INDArray activate(INDArray input, TrainingMode training) {
        return output(input, training == TrainingMode.TRAIN);
    }"
"private static void checkNewNetworkConfig(
		final int pageSize,
		final float networkBufFraction,
		final long networkBufMin,
		final long networkBufMax) throws IllegalConfigurationException {

		ConfigurationParserUtils.checkConfigParameter(networkBufFraction > 0.0f && networkBufFraction < 1.0f, networkBufFraction,
			TaskManagerOptions.NETWORK_BUFFERS_MEMORY_FRACTION.key(),
			""Network buffer memory fraction of the free memory must be between 0.0 and 1.0"");

		ConfigurationParserUtils.checkConfigParameter(networkBufMin >= pageSize, networkBufMin,
			TaskManagerOptions.NETWORK_BUFFERS_MEMORY_MIN.key(),
			""Minimum memory for network buffers must allow at least one network "" +
				""buffer with respect to the memory segment size"");

		ConfigurationParserUtils.checkConfigParameter(networkBufMax >= pageSize, networkBufMax,
			TaskManagerOptions.NETWORK_BUFFERS_MEMORY_MAX.key(),
			""Maximum memory for network buffers must allow at least one network "" +
				""buffer with respect to the memory segment size"");

		ConfigurationParserUtils.checkConfigParameter(networkBufMax >= networkBufMin, networkBufMax,
			TaskManagerOptions.NETWORK_BUFFERS_MEMORY_MAX.key(),
			""Maximum memory for network buffers must not be smaller than minimum memory ("" +
				TaskManagerOptions.NETWORK_BUFFERS_MEMORY_MAX.key() + "": "" + networkBufMin + "")"");
	}"
"public static boolean hasPublicNullaryConstructor(Class<?> clazz) {
		Constructor<?>[] constructors = clazz.getConstructors();
		for (Constructor<?> constructor : constructors) {
			if (constructor.getParameterTypes().length == 0 &&
					Modifier.isPublic(constructor.getModifiers())) {
				return true;
			}
		}
		return false;
	}"
"@Override
	public int compare(E o1, E o2) {
		return comparator.compare(o2, o1);
	}"
"public Actions release(WebElement target) {
    if (isBuildingActions()) {
      action.addAction(new ButtonReleaseAction(jsonMouse, (Locatable) target));
    }

    return moveInTicks(target, 0, 0).tick(defaultMouse.createPointerUp(LEFT.asArg()));
  }"
"void addCredit(InputChannelID receiverId, int credit) throws Exception {
		if (fatalError) {
			return;
		}

		NetworkSequenceViewReader reader = allReaders.get(receiverId);
		if (reader != null) {
			reader.addCredit(credit);

			enqueueAvailableReader(reader);
		} else {
			throw new IllegalStateException(""No reader for receiverId = "" + receiverId + "" exists."");
		}
	}"
"public static Expr binaryOp(BinaryOpExprBase binary, Expr left, Expr right)
  {
    try {
      return binary.getClass()
                   .getDeclaredConstructor(String.class, Expr.class, Expr.class)
                   .newInstance(binary.op, left, right);
    }
    catch (Exception e) {
      log.warn(e, ""failed to rewrite expression "" + binary);
      return binary;  // best effort.. keep it working
    }
  }"
"static int getIndex(CharSequence name) {
        Integer index = STATIC_INDEX_BY_NAME.get(name);
        if (index == null) {
            return -1;
        }
        return index;
    }"
"static String buildMessage(BeanResolutionContext resolutionContext, MethodInjectionPoint methodInjectionPoint, Argument argument, String message, boolean circular) {
        StringBuilder builder = new StringBuilder(""Failed to inject value for parameter ["");
        String ls = System.getProperty(""line.separator"");
        builder
            .append(argument.getName()).append(""] of method ["")
            .append(methodInjectionPoint.getName())
            .append(""] of class: "")
            .append(methodInjectionPoint.getDeclaringBean().getName())
            .append(ls)
            .append(ls);

        if (message != null) {
            builder.append(""Message: "").append(message).append(ls);
        }
        appendPath(resolutionContext, circular, builder, ls);
        return builder.toString();
    }"
"@Override
    @SuppressWarnings({ ""unchecked"", ""SuspiciousToArrayCall"" })
    public void close() {
        final AddressResolver<T>[] rArray;
        synchronized (resolvers) {
            rArray = (AddressResolver<T>[]) resolvers.values().toArray(new AddressResolver[0]);
            resolvers.clear();
        }

        for (AddressResolver<T> r: rArray) {
            try {
                r.close();
            } catch (Throwable t) {
                logger.warn(""Failed to close a resolver:"", t);
            }
        }
    }"
"public PythonDataStream socket_text_stream(String host, int port) {
		return new PythonDataStream<>(env.socketTextStream(host, port).map(new AdapterMap<String>()));
	}"
"public WebServiceTemplateBuilder setCheckConnectionForFault(
			boolean checkConnectionForFault) {
		return new WebServiceTemplateBuilder(this.detectHttpMessageSender,
				this.interceptors,
				append(this.internalCustomizers,
						new CheckConnectionFaultCustomizer(checkConnectionForFault)),
				this.customizers, this.messageSenders, this.marshaller, this.unmarshaller,
				this.destinationProvider, this.transformerFactoryClass,
				this.messageFactory);
	}"
"@SuppressWarnings(""unchecked"")
	public O withForwardedFieldsFirst(String... forwardedFieldsFirst) {
		if (this.udfSemantics == null || this.analyzedUdfSemantics) {
			// extract semantic properties from function annotations
			setSemanticProperties(extractSemanticAnnotationsFromUdf(getFunction().getClass()));
		}

		if (this.udfSemantics == null || this.analyzedUdfSemantics) {
			setSemanticProperties(new DualInputSemanticProperties());
			SemanticPropUtil.getSemanticPropsDualFromString(this.udfSemantics, forwardedFieldsFirst, null,
					null, null, null, null, getInput1Type(), getInput2Type(), getResultType());
		} else {
			if (this.udfWithForwardedFieldsFirstAnnotation(getFunction().getClass())) {
				// refuse semantic information as it would override the function annotation
				throw new SemanticProperties.InvalidSemanticAnnotationException(""Forwarded field information "" +
						""has already been added by a function annotation for the first input of this operator. "" +
						""Cannot overwrite function annotations."");
			} else {
				SemanticPropUtil.getSemanticPropsDualFromString(this.udfSemantics, forwardedFieldsFirst, null,
						null, null, null, null, getInput1Type(), getInput2Type(), getResultType());
			}
		}

		O returnType = (O) this;
		return returnType;
	}"
"private void addPanelForContext(Context context, ContextPanelFactory contextPanelFactory, String[] panelPath) {
        AbstractContextPropertiesPanel panel = contextPanelFactory.getContextPanel(context);
        panel.setSessionDialog(getSessionDialog());
        getSessionDialog().addParamPanel(panelPath, panel, false);
        this.contextPanels.add(panel);

        List<AbstractContextPropertiesPanel> panels = contextPanelFactoriesPanels.get(contextPanelFactory);
        if (panels == null) {
            panels = new ArrayList<>();
            contextPanelFactoriesPanels.put(contextPanelFactory, panels);
        }
        panels.add(panel);
    }"
"protected String buildSingleAttributeDefinitionLine(final String attributeName, final Object value) {
        return new StringBuilder()
            .append(""<cas:"".concat(attributeName).concat("">""))
            .append(encodeAttributeValue(value))
            .append(""</cas:"".concat(attributeName).concat("">""))
            .toString();
    }"
"public Context duplicate() {
		Context newContext = new Context(session, getIndex());
		newContext.description = this.description;
		newContext.name = this.name;
		newContext.includeInRegexs = new ArrayList<>(this.includeInRegexs);
		newContext.includeInPatterns = new ArrayList<>(this.includeInPatterns);
		newContext.excludeFromRegexs = new ArrayList<>(this.excludeFromRegexs);
		newContext.excludeFromPatterns = new ArrayList<>(this.excludeFromPatterns);
		newContext.inScope = this.inScope;
		newContext.techSet = new TechSet(this.techSet);
		newContext.authenticationMethod = this.authenticationMethod.clone();
		newContext.sessionManagementMethod = this.sessionManagementMethod.clone();
		newContext.urlParamParser = this.urlParamParser.clone();
		newContext.postParamParser = this.postParamParser.clone();
		newContext.authorizationDetectionMethod = this.authorizationDetectionMethod.clone();
		newContext.dataDrivenNodes = this.getDataDrivenNodes();
		return newContext;
	}"
"@Override
  public void close() throws HiveSQLException {
    try {
      acquire(true);
      cancelDelegationToken();
    } finally {
      try {
        super.close();
      } finally {
        try {
          FileSystem.closeAllForUGI(sessionUgi);
        } catch (IOException ioe) {
          throw new HiveSQLException(""Could not clean up file-system handles for UGI: ""
              + sessionUgi, ioe);
        }
      }
    }
  }"
"static Type getSupertype(Type context, Class<?> contextRawType, Class<?> supertype) {
    if (!supertype.isAssignableFrom(contextRawType)) {
      throw new IllegalArgumentException();
    }
    return resolve(context, contextRawType,
        getGenericSupertype(context, contextRawType, supertype));
  }"
"public static SSLContext createSSLContext() throws IOException {
    	Map<String, Object> tlsMap = (Map<String, Object>)ClientConfig.get().getMappedConfig().get(TLS);
    	
    	return null==tlsMap?null:createSSLContext((String)tlsMap.get(TLSConfig.DEFAULT_GROUP_KEY));
    }"
"@Override
	public boolean validate(Graph<K, VV, EV> graph) throws Exception {
		DataSet<Tuple1<K>> edgeIds = graph.getEdges()
				.flatMap(new MapEdgeIds<>()).distinct();
		DataSet<K> invalidIds = graph.getVertices().coGroup(edgeIds).where(0)
				.equalTo(0).with(new GroupInvalidIds<>()).first(1);

		return invalidIds.map(new KToTupleMap<>()).count() == 0;
	}"
"@Override
    public Object intercept(MethodInvocationContext<Object, Object> context) {
        AnnotationValue<Client> clientAnnotation = context.findAnnotation(Client.class).orElseThrow(() ->
                new IllegalStateException(""Client advice called from type that is not annotated with @Client: "" + context)
        );

        HttpClient httpClient = getClient(context, clientAnnotation);

        Class<?> declaringType = context.getDeclaringType();
        if (Closeable.class == declaringType || AutoCloseable.class == declaringType) {
            String clientId = clientAnnotation.getValue(String.class).orElse(null);
            String path = clientAnnotation.get(""path"", String.class).orElse(null);
            String clientKey = computeClientKey(clientId, path);
            clients.remove(clientKey);
            httpClient.close();
            return null;
        }

        Optional<Class<? extends Annotation>> httpMethodMapping = context.getAnnotationTypeByStereotype(HttpMethodMapping.class);
        if (context.hasStereotype(HttpMethodMapping.class) && httpClient != null) {
            AnnotationValue<HttpMethodMapping> mapping = context.getAnnotation(HttpMethodMapping.class);
            String uri = mapping.getRequiredValue(String.class);
            if (StringUtils.isEmpty(uri)) {
                uri = ""/"" + context.getMethodName();
            }

            Class<? extends Annotation> annotationType = httpMethodMapping.get();

            HttpMethod httpMethod = HttpMethod.valueOf(annotationType.getSimpleName().toUpperCase());

            ReturnType returnType = context.getReturnType();
            Class<?> javaReturnType = returnType.getType();

            UriMatchTemplate uriTemplate = UriMatchTemplate.of("""");
            if (!(uri.length() == 1 && uri.charAt(0) == '/')) {
                uriTemplate = uriTemplate.nest(uri);
            }

            Map<String, Object> paramMap = context.getParameterValueMap();
            Map<String, String> queryParams = new LinkedHashMap<>();
            List<String> uriVariables = uriTemplate.getVariableNames();

            boolean variableSatisfied = uriVariables.isEmpty() || uriVariables.containsAll(paramMap.keySet());
            MutableHttpRequest<Object> request;
            Object body = null;
            Map<String, MutableArgumentValue<?>> parameters = context.getParameters();
            Argument[] arguments = context.getArguments();


            Map<String, String> headers = new LinkedHashMap<>(HEADERS_INITIAL_CAPACITY);

            List<AnnotationValue<Header>> headerAnnotations = context.getAnnotationValuesByType(Header.class);
            for (AnnotationValue<Header> headerAnnotation : headerAnnotations) {
                String headerName = headerAnnotation.get(""name"", String.class).orElse(null);
                String headerValue = headerAnnotation.getValue(String.class).orElse(null);
                if (StringUtils.isNotEmpty(headerName) && StringUtils.isNotEmpty(headerValue)) {
                    headers.put(headerName, headerValue);
                }
            }

            context.findAnnotation(Version.class)
                    .flatMap(versionAnnotation -> versionAnnotation.getValue(String.class))
                    .filter(StringUtils::isNotEmpty)
                    .ifPresent(version -> {

                        ClientVersioningConfiguration configuration = getVersioningConfiguration(clientAnnotation);

                        configuration.getHeaders()
                                .forEach(header -> headers.put(header, version));

                        configuration.getParameters()
                                .forEach(parameter -> queryParams.put(parameter, version));
                    });
          
            Map<String, Object> attributes = new LinkedHashMap<>(ATTRIBUTES_INITIAL_CAPACITY);

            List<AnnotationValue<RequestAttribute>> attributeAnnotations = context.getAnnotationValuesByType(RequestAttribute.class);
            for (AnnotationValue<RequestAttribute> attributeAnnotation : attributeAnnotations) {
                String attributeName = attributeAnnotation.get(""name"", String.class).orElse(null);
                Object attributeValue = attributeAnnotation.getValue(Object.class).orElse(null);
                if (StringUtils.isNotEmpty(attributeName) && attributeValue != null) {
                    attributes.put(attributeName, attributeValue);
                }
            }

            List<NettyCookie> cookies = new ArrayList<>();
            List<Argument> bodyArguments = new ArrayList<>();
            ConversionService<?> conversionService = ConversionService.SHARED;
            for (Argument argument : arguments) {
                String argumentName = argument.getName();
                AnnotationMetadata annotationMetadata = argument.getAnnotationMetadata();
                MutableArgumentValue<?> value = parameters.get(argumentName);
                Object definedValue = value.getValue();

                if (paramMap.containsKey(argumentName)) {
                    if (annotationMetadata.hasStereotype(Format.class)) {
                        final Object v = paramMap.get(argumentName);
                        if (v != null) {
                            paramMap.put(argumentName, conversionService.convert(v, ConversionContext.of(String.class).with(argument.getAnnotationMetadata())));
                        }
                    }
                }
                if (definedValue == null) {
                    definedValue = argument.getAnnotationMetadata().getValue(Bindable.class, ""defaultValue"", String.class).orElse(null);
                }

                if (definedValue == null && !argument.isAnnotationPresent(Nullable.class)) {
                    throw new IllegalArgumentException(
                            String.format(""Null values are not allowed to be passed to client methods (%s). Add @javax.validation.Nullable if that is the desired behavior"", context.getExecutableMethod().toString())
                    );
                }

                if (argument.isAnnotationPresent(Body.class)) {
                    body = definedValue;
                } else if (annotationMetadata.isAnnotationPresent(Header.class)) {

                    String headerName = annotationMetadata.getValue(Header.class, String.class).orElse(null);
                    if (StringUtils.isEmpty(headerName)) {
                        headerName = NameUtils.hyphenate(argumentName);
                    }
                    String finalHeaderName = headerName;
                    conversionService.convert(definedValue, String.class)
                        .ifPresent(o -> headers.put(finalHeaderName, o));
                } else if (annotationMetadata.isAnnotationPresent(CookieValue.class)) {
                    String cookieName = annotationMetadata.getValue(CookieValue.class, String.class).orElse(null);
                    if (StringUtils.isEmpty(cookieName)) {
                        cookieName = argumentName;
                    }
                    String finalCookieName = cookieName;

                    conversionService.convert(definedValue, String.class)
                        .ifPresent(o -> cookies.add(new NettyCookie(finalCookieName, o)));

                } else if (annotationMetadata.isAnnotationPresent(QueryValue.class)) {
                    String parameterName = annotationMetadata.getValue(QueryValue.class, String.class).orElse(null);
                    conversionService.convert(definedValue, ConversionContext.of(String.class).with(annotationMetadata)).ifPresent(o -> {
                        if (!StringUtils.isEmpty(parameterName)) {
                            paramMap.put(parameterName, o);
                            queryParams.put(parameterName, o);
                        } else {
                            queryParams.put(argumentName, o);
                        }
                    });
                } else if (annotationMetadata.isAnnotationPresent(RequestAttribute.class)) {
                    String attributeName = annotationMetadata.getValue(Annotation.class, String.class).orElse(null);
                    if (StringUtils.isEmpty(attributeName)) {
                        attributeName = NameUtils.hyphenate(argumentName);
                    }
                    String finalAttributeName = attributeName;
                    conversionService.convert(definedValue, Object.class)
                        .ifPresent(o -> attributes.put(finalAttributeName, o));
                } else if (annotationMetadata.isAnnotationPresent(PathVariable.class)) {
                    String parameterName = annotationMetadata.getValue(PathVariable.class, String.class).orElse(null);
                    conversionService.convert(definedValue, ConversionContext.of(String.class).with(annotationMetadata)).ifPresent(o -> {
                        if (!StringUtils.isEmpty(o)) {
                            paramMap.put(parameterName, o);
                        }
                    });
                } else if (!uriVariables.contains(argumentName)) {
                    bodyArguments.add(argument);
                }
            }

            if (HttpMethod.permitsRequestBody(httpMethod)) {
                if (body == null && !bodyArguments.isEmpty()) {
                    Map<String, Object> bodyMap = new LinkedHashMap<>();

                    for (Argument bodyArgument : bodyArguments) {
                        String argumentName = bodyArgument.getName();
                        MutableArgumentValue<?> value = parameters.get(argumentName);
                        bodyMap.put(argumentName, value.getValue());
                    }
                    body = bodyMap;
                }

                if (body != null) {
                    if (!variableSatisfied) {

                        if (body instanceof Map) {
                            paramMap.putAll((Map) body);
                        } else {
                            BeanMap<Object> beanMap = BeanMap.of(body);
                            for (Map.Entry<String, Object> entry : beanMap.entrySet()) {
                                String k = entry.getKey();
                                Object v = entry.getValue();
                                if (v != null) {
                                    paramMap.put(k, v);
                                }
                            }
                        }
                    }
                }
            }

            uri = uriTemplate.expand(paramMap);
            uriVariables.forEach(queryParams::remove);

            request = HttpRequest.create(httpMethod, appendQuery(uri, queryParams));
            if (body != null) {
                request.body(body);

                MediaType[] contentTypes = context.getValue(Produces.class, MediaType[].class).orElse(DEFAULT_ACCEPT_TYPES);
                if (ArrayUtils.isNotEmpty(contentTypes)) {
                    request.contentType(contentTypes[0]);
                }
            }

            // Set the URI template used to make the request for tracing purposes
            request.setAttribute(HttpAttributes.URI_TEMPLATE, resolveTemplate(clientAnnotation, uriTemplate.toString()));
            String serviceId = clientAnnotation.getValue(String.class).orElse(null);
            Argument<?> errorType = clientAnnotation.get(""errorType"", Class.class).map((Function<Class, Argument>) Argument::of).orElse(HttpClient.DEFAULT_ERROR_TYPE);
            request.setAttribute(HttpAttributes.SERVICE_ID, serviceId);


            if (!headers.isEmpty()) {
                for (Map.Entry<String, String> entry : headers.entrySet()) {
                    request.header(entry.getKey(), entry.getValue());
                }
            }

            cookies.forEach(request::cookie);

            if (!attributes.isEmpty()) {
                for (Map.Entry<String, Object> entry : attributes.entrySet()) {
                    request.setAttribute(entry.getKey(), entry.getValue());
                }
            }

            MediaType[] acceptTypes = context.getValue(Consumes.class, MediaType[].class).orElse(DEFAULT_ACCEPT_TYPES);

            boolean isFuture = CompletableFuture.class.isAssignableFrom(javaReturnType);
            final Class<?> methodDeclaringType = declaringType;
            if (Publishers.isConvertibleToPublisher(javaReturnType) || isFuture) {
                boolean isSingle = Publishers.isSingle(javaReturnType) || isFuture || context.getValue(Consumes.class, ""single"", Boolean.class).orElse(false);
                Argument<?> publisherArgument = returnType.asArgument().getFirstTypeVariable().orElse(Argument.OBJECT_ARGUMENT);


                Class<?> argumentType = publisherArgument.getType();

                if (HttpResponse.class.isAssignableFrom(argumentType) || HttpStatus.class.isAssignableFrom(argumentType)) {
                    isSingle = true;
                }

                Publisher<?> publisher;

                if (!isSingle && httpClient instanceof StreamingHttpClient) {
                    StreamingHttpClient streamingHttpClient = (StreamingHttpClient) httpClient;

                    if (!Void.class.isAssignableFrom(argumentType)) {
                        request.accept(acceptTypes);
                    }

                    if (HttpResponse.class.isAssignableFrom(argumentType) ||
                            Void.class.isAssignableFrom(argumentType)) {
                        publisher = streamingHttpClient.exchangeStream(
                                request
                        );
                    } else {
                        boolean isEventStream = Arrays.asList(acceptTypes).contains(MediaType.TEXT_EVENT_STREAM_TYPE);

                        if (isEventStream && streamingHttpClient instanceof SseClient) {
                            SseClient sseClient = (SseClient) streamingHttpClient;
                            if (publisherArgument.getType() == Event.class) {
                                publisher = sseClient.eventStream(
                                        request, publisherArgument.getFirstTypeVariable().orElse(Argument.OBJECT_ARGUMENT)
                                );
                            } else {
                                publisher = Flowable.fromPublisher(sseClient.eventStream(
                                        request, publisherArgument
                                )).map(Event::getData);
                            }
                        } else {
                            boolean isJson = isJsonParsedMediaType(acceptTypes);
                            if (isJson) {
                                publisher = streamingHttpClient.jsonStream(
                                        request, publisherArgument
                                );
                            } else {
                                Publisher<ByteBuffer<?>> byteBufferPublisher = streamingHttpClient.dataStream(
                                        request
                                );
                                if (argumentType == ByteBuffer.class) {
                                    publisher = byteBufferPublisher;
                                } else {
                                    if (conversionService.canConvert(ByteBuffer.class, argumentType)) {
                                        // It would be nice if we could capture the TypeConverter here
                                        publisher = Flowable.fromPublisher(byteBufferPublisher)
                                                .map(value -> conversionService.convert(value, argumentType).get());
                                    } else {
                                        throw new ConfigurationException(""Cannot create the generated HTTP client's "" +
                                                ""required return type, since no TypeConverter from ByteBuffer to "" +
                                                argumentType + "" is registered"");
                                    }
                                }

                            }
                        }
                    }

                } else {

                    if (Void.class.isAssignableFrom(argumentType)) {
                        publisher = httpClient.exchange(
                                request, null, errorType
                        );
                    } else {
                        request.accept(acceptTypes);
                        if (HttpResponse.class.isAssignableFrom(argumentType)) {
                            publisher = httpClient.exchange(
                                    request, publisherArgument, errorType
                            );
                        } else {
                            publisher = httpClient.retrieve(
                                    request, publisherArgument, errorType
                            );
                        }
                    }
                }

                if (isFuture) {
                    CompletableFuture<Object> future = new CompletableFuture<>();
                    publisher.subscribe(new CompletionAwareSubscriber<Object>() {
                        AtomicReference<Object> reference = new AtomicReference<>();

                        @Override
                        protected void doOnSubscribe(Subscription subscription) {
                            subscription.request(1);
                        }

                        @Override
                        protected void doOnNext(Object message) {
                            if (!Void.class.isAssignableFrom(argumentType)) {
                                reference.set(message);
                            }
                        }

                        @Override
                        protected void doOnError(Throwable t) {
                            if (t instanceof HttpClientResponseException) {
                                HttpClientResponseException e = (HttpClientResponseException) t;
                                if (e.getStatus() == HttpStatus.NOT_FOUND) {
                                    future.complete(null);
                                    return;
                                }
                            }
                            if (LOG.isErrorEnabled()) {
                                LOG.error(""Client ["" + methodDeclaringType.getName() + ""] received HTTP error response: "" + t.getMessage(), t);
                            }

                            future.completeExceptionally(t);
                        }

                        @Override
                        protected void doOnComplete() {
                            future.complete(reference.get());
                        }
                    });
                    return future;
                } else {
                    Object finalPublisher = conversionService.convert(publisher, javaReturnType).orElseThrow(() ->
                        new HttpClientException(""Cannot convert response publisher to Reactive type (Unsupported Reactive type): "" + javaReturnType)
                    );
                    for (ReactiveClientResultTransformer transformer : transformers) {
                        finalPublisher = transformer.transform(finalPublisher);
                    }
                    return finalPublisher;
                }
            } else {
                BlockingHttpClient blockingHttpClient = httpClient.toBlocking();

                if (void.class != javaReturnType) {
                    request.accept(acceptTypes);
                }

                if (HttpResponse.class.isAssignableFrom(javaReturnType)) {
                    return blockingHttpClient.exchange(
                        request, returnType.asArgument().getFirstTypeVariable().orElse(Argument.OBJECT_ARGUMENT), errorType
                    );
                } else if (void.class == javaReturnType) {
                    blockingHttpClient.exchange(request, null, errorType);
                    return null;
                } else {
                    try {
                        return blockingHttpClient.retrieve(
                                request, returnType.asArgument(), errorType
                        );
                    } catch (RuntimeException t) {
                        if (t instanceof HttpClientResponseException && ((HttpClientResponseException) t).getStatus() == HttpStatus.NOT_FOUND) {
                            if (javaReturnType == Optional.class) {
                                return Optional.empty();
                            }
                            return null;
                        } else {
                            throw t;
                        }
                    }
                }
            }
        }
        // try other introduction advice
        return context.proceed();
    }"
"@SuppressWarnings({""unchecked""})
    public static String[] tokenizeToStringArray(
        String str, String delimiters, boolean trimTokens, boolean ignoreEmptyTokens) {

        if (str == null) {
            return null;
        }
        StringTokenizer st = new StringTokenizer(str, delimiters);
        List<String> tokens = new ArrayList();
        while (st.hasMoreTokens()) {
            String token = st.nextToken();
            if (trimTokens) {
                token = token.trim();
            }
            if (!ignoreEmptyTokens || token.length() > 0) {
                tokens.add(token);
            }
        }
        return tokens.toArray(new String[0]);
    }"
"public long getLong(String key) throws JSONException {
    Object o = get(key);
    try {
      return o instanceof Number ? ((Number) o).longValue() : Long.parseLong((String) o);
    } catch (Exception e) {
      throw new JSONException(""JSONObject["" + quote(key) + ""] is not a long."");
    }
  }"
"@Deprecated
  @WorkerThread
  public static LottieResult<LottieComposition> fromJsonSync(JSONObject json, @Nullable String cacheKey) {
    return fromJsonStringSync(json.toString(), cacheKey);
  }"
"public AssertionConsumerService getAssertionConsumerService(final String binding) {
        return getAssertionConsumerServices().stream().filter(acs -> acs.getBinding().equalsIgnoreCase(binding)).findFirst().orElse(null);
    }"
"public String getString(final String key) {
    if (containsKey(key)) {
      return get(key);
    } else {
      throw new UndefinedPropertyException(""Missing required property '"" + key
          + ""'"");
    }
  }"
"public AnnotationValueBuilder<T> value(@Nullable Enum<?> enumObj) {
        return member(AnnotationMetadata.VALUE_MEMBER, enumObj);
    }"
"static String byteToBinaryString(byte b, int limit) {
    final StringBuilder sb = new StringBuilder();
    if (limit > 8) {
      limit = 8;
    }
    for (int i = 0; i < limit; i++) {
      sb.append((char)('0' + (b&1)));
      b>>=1;
    }
    return sb.toString();
  }"
"public JavaDoubleRDD scoreExamplesMultiDataSet(JavaRDD<MultiDataSet> data, boolean includeRegularizationTerms) {
        return scoreExamplesMultiDataSet(data, includeRegularizationTerms, DEFAULT_EVAL_SCORE_BATCH_SIZE);
    }"
"State endBinaryShift(int index) {
    if (binaryShiftByteCount == 0) {
      return this;
    }
    Token token = this.token;
    token = token.addBinaryShift(index - binaryShiftByteCount, binaryShiftByteCount);
    //assert token.getTotalBitCount() == this.bitCount;
    return new State(token, mode, 0, this.bitCount);
  }"
"public static void bindCurrent(final Credential... credentials) {
        CURRENT_CREDENTIAL_IDS.set(Arrays.stream(credentials).map(Credential::getId).toArray(String[]::new));
    }"
"private SystemParameterDO modelToDo(SystemParameter systemParameter) {
        SystemParameterDO systemParameterDo = new SystemParameterDO();
        systemParameterDo.setValue(systemParameter);
        systemParameterDo.setGmtCreate(new Date());
        systemParameterDo.setGmtModified(new Date());
        return systemParameterDo;
    }"
"public static <T extends CharSequence> Collection<T> removeBlank(Collection<T> collection) {
		return filter(collection, new Filter<T>() {
			@Override
			public boolean accept(T t) {
				return false == StrUtil.isBlank(t);
			}
		});
	}"
"public static double bytesHighFirstToDouble(byte[] bytes, int start)
    {
        long l = ((long) bytes[start] << 56) & 0xFF00000000000000L;
        // 如果不强制转换为long，那么默认会当作int，导致最高32位丢失
        l |= ((long) bytes[1 + start] << 48) & 0xFF000000000000L;
        l |= ((long) bytes[2 + start] << 40) & 0xFF0000000000L;
        l |= ((long) bytes[3 + start] << 32) & 0xFF00000000L;
        l |= ((long) bytes[4 + start] << 24) & 0xFF000000L;
        l |= ((long) bytes[5 + start] << 16) & 0xFF0000L;
        l |= ((long) bytes[6 + start] << 8) & 0xFF00L;
        l |= (long) bytes[7 + start] & 0xFFL;

        return Double.longBitsToDouble(l);
    }"
"public static List<String> splitTrim(String str, char separator, boolean ignoreEmpty){
		return split(str, separator, 0, true, ignoreEmpty);
	}"
"protected void initCudaContextForThread(Long threadId) {

        // we set device to be used prior to stream creation

        nativeOps.setDevice(getDeviceId());

        CudaContext context = new CudaContext();
        context.initHandle();
        context.initOldStream();
        context.initStream();
        context.associateHandle();
        //contextPool.put(threadId, context);
    }"
"@Override
    public void visitBeanDefinitionConstructor(AnnotationMetadata annotationMetadata,
                                               boolean requiresReflection,
                                               Map<String, Object> argumentTypes,
                                               Map<String, AnnotationMetadata> argumentAnnotationMetadata,
                                               Map<String, Map<String, Object>> genericTypes) {
        if (constructorVisitor == null) {
            // first build the constructor
            visitBeanDefinitionConstructorInternal(
                    annotationMetadata,
                    requiresReflection,
                    argumentTypes,
                    argumentAnnotationMetadata,
                    genericTypes);

            // now prepare the implementation of the build method. See BeanFactory interface
            visitBuildMethodDefinition(annotationMetadata, argumentTypes, argumentAnnotationMetadata);

            // now override the injectBean method
            visitInjectMethodDefinition();
        }
    }"
"public static <T> T executeScriptEngine(final String scriptFile, final Object[] args, final Class<T> clazz) {
        try {
            val engineName = getScriptEngineName(scriptFile);
            val engine = new ScriptEngineManager().getEngineByName(engineName);
            if (engine == null || StringUtils.isBlank(engineName)) {
                LOGGER.warn(""Script engine is not available for [{}]"", engineName);
                return null;
            }

            val resourceFrom = ResourceUtils.getResourceFrom(scriptFile);
            val theScriptFile = resourceFrom.getFile();
            if (theScriptFile.exists()) {
                LOGGER.debug(""Created object instance from class [{}]"", theScriptFile.getCanonicalPath());

                try (val reader = Files.newBufferedReader(theScriptFile.toPath(), StandardCharsets.UTF_8)) {
                    engine.eval(reader);
                }
                val invocable = (Invocable) engine;
                LOGGER.debug(""Executing script's run method, with parameters [{}]"", args);
                val result = invocable.invokeFunction(""run"", args);
                LOGGER.debug(""Groovy script result is [{}]"", result);
                return getGroovyScriptExecutionResultOrThrow(clazz, result);
            }
            LOGGER.warn(""[{}] script [{}] does not exist, or cannot be loaded"", StringUtils.capitalize(engineName), scriptFile);
        } catch (final Exception e) {
            LOGGER.error(e.getMessage(), e);
        }
        return null;
    }"
"public static List<String> readLines(File file, String charset) throws IORuntimeException {
		return readLines(file, charset, new ArrayList<String>());
	}"
"@PublicApi
  public ConditionalMultibind<T> addConditionBinding(
      String property,
      Predicate<String> condition,
      TypeLiteral<T> target
  )
  {
    if (matchCondition(property, condition)) {
      multibinder.addBinding().to(target);
    }
    return this;
  }"
"public static void error(Log log, Throwable e) {
		error(log, e, e.getMessage());
	}"
"protected OAuthConsumerToken getTokenFromProvider(ProtectedResourceDetails details, URL tokenURL, String httpMethod,
                                                    OAuthConsumerToken requestToken, Map<String, String> additionalParameters) {
    boolean isAccessToken = requestToken != null;
    if (!isAccessToken) {
      //create an empty token to make a request for a new unauthorized request token.
      requestToken = new OAuthConsumerToken();
    }

    TreeMap<String, String> requestHeaders = new TreeMap<String, String>();
    if (""POST"".equalsIgnoreCase(httpMethod)) {
      requestHeaders.put(""Content-Type"", ""application/x-www-form-urlencoded"");
    }
    InputStream inputStream = readResource(details, tokenURL, httpMethod, requestToken, additionalParameters, requestHeaders);
    String tokenInfo;
    try {
      ByteArrayOutputStream out = new ByteArrayOutputStream();
      byte[] buffer = new byte[1024];
      int len = inputStream.read(buffer);
      while (len >= 0) {
        out.write(buffer, 0, len);
        len = inputStream.read(buffer);
      }

      tokenInfo = new String(out.toByteArray(), ""UTF-8"");
    }
    catch (IOException e) {
      throw new OAuthRequestFailedException(""Unable to read the token."", e);
    }

    StringTokenizer tokenProperties = new StringTokenizer(tokenInfo, ""&"");
    Map<String, String> tokenPropertyValues = new TreeMap<String, String>();
    while (tokenProperties.hasMoreElements()) {
      try {
        String tokenProperty = (String) tokenProperties.nextElement();
        int equalsIndex = tokenProperty.indexOf('=');
        if (equalsIndex > 0) {
          String propertyName = OAuthCodec.oauthDecode(tokenProperty.substring(0, equalsIndex));
          String propertyValue = OAuthCodec.oauthDecode(tokenProperty.substring(equalsIndex + 1));
          tokenPropertyValues.put(propertyName, propertyValue);
        }
        else {
          tokenProperty = OAuthCodec.oauthDecode(tokenProperty);
          tokenPropertyValues.put(tokenProperty, null);
        }
      }
      catch (DecoderException e) {
        throw new OAuthRequestFailedException(""Unable to decode token parameters."");
      }
    }

    String tokenValue = tokenPropertyValues.remove(OAuthProviderParameter.oauth_token.toString());
    if (tokenValue == null) {
      throw new OAuthRequestFailedException(""OAuth provider failed to return a token."");
    }

    String tokenSecret = tokenPropertyValues.remove(OAuthProviderParameter.oauth_token_secret.toString());
    if (tokenSecret == null) {
      throw new OAuthRequestFailedException(""OAuth provider failed to return a token secret."");
    }

    OAuthConsumerToken consumerToken = new OAuthConsumerToken();
    consumerToken.setValue(tokenValue);
    consumerToken.setSecret(tokenSecret);
    consumerToken.setResourceId(details.getId());
    consumerToken.setAccessToken(isAccessToken);
    if (!tokenPropertyValues.isEmpty()) {
      consumerToken.setAdditionalParameters(tokenPropertyValues);
    }
    return consumerToken;
  }"
"@Override
    public Schema transform(Schema inputSchema) {
        Schema.Builder newSchema = new Schema.Builder();
        for (int i = 0; i < inputSchema.numColumns(); i++) {
            if (inputSchema.getType(i) == ColumnType.String) {
                newSchema.addColumnDouble(inputSchema.getMetaData(i).getName());
            } else
                newSchema.addColumn(inputSchema.getMetaData(i));

        }
        return newSchema.build();
    }"
"private boolean readModule(int row, int column, int numRows, int numColumns) {
    // Adjust the row and column indices based on boundary wrapping
    if (row < 0) {
      row += numRows;
      column += 4 - ((numRows + 4) & 0x07);
    }
    if (column < 0) {
      column += numColumns;
      row += 4 - ((numColumns + 4) & 0x07);
    }
    readMappingMatrix.set(column, row);
    return mappingBitMatrix.get(column, row);
  }"
"public RelDataType getRelDataType(final RelDataTypeFactory typeFactory)
  {
    final RelDataTypeFactory.Builder builder = typeFactory.builder();
    for (final String columnName : columnNames) {
      final ValueType columnType = getColumnType(columnName);
      final RelDataType type;

      if (ColumnHolder.TIME_COLUMN_NAME.equals(columnName)) {
        type = Calcites.createSqlType(typeFactory, SqlTypeName.TIMESTAMP);
      } else {
        switch (columnType) {
          case STRING:
            // Note that there is no attempt here to handle multi-value in any special way. Maybe one day...
            type = Calcites.createSqlTypeWithNullability(typeFactory, SqlTypeName.VARCHAR, true);
            break;
          case LONG:
            type = Calcites.createSqlType(typeFactory, SqlTypeName.BIGINT);
            break;
          case FLOAT:
            type = Calcites.createSqlType(typeFactory, SqlTypeName.FLOAT);
            break;
          case DOUBLE:
            type = Calcites.createSqlType(typeFactory, SqlTypeName.DOUBLE);
            break;
          case COMPLEX:
            // Loses information about exactly what kind of complex column this is.
            type = Calcites.createSqlTypeWithNullability(typeFactory, SqlTypeName.OTHER, true);
            break;
          default:
            throw new ISE(""WTF?! valueType[%s] not translatable?"", columnType);
        }
      }

      builder.add(columnName, type);
    }

    return builder.build();
  }"
"private boolean crossCheckDiagonal(int centerI, int centerJ) {
    int[] stateCount = getCrossCheckStateCount();

    // Start counting up, left from center finding black center mass
    int i = 0;
    while (centerI >= i && centerJ >= i && image.get(centerJ - i, centerI - i)) {
      stateCount[2]++;
      i++;
    }
    if (stateCount[2] == 0) {
      return false;
    }

    // Continue up, left finding white space
    while (centerI >= i && centerJ >= i && !image.get(centerJ - i, centerI - i)) {
      stateCount[1]++;
      i++;
    }
    if (stateCount[1] == 0) {
      return false;
    }

    // Continue up, left finding black border
    while (centerI >= i && centerJ >= i && image.get(centerJ - i, centerI - i)) {
      stateCount[0]++;
      i++;
    }
    if (stateCount[0] == 0) {
      return false;
    }

    int maxI = image.getHeight();
    int maxJ = image.getWidth();

    // Now also count down, right from center
    i = 1;
    while (centerI + i < maxI && centerJ + i < maxJ && image.get(centerJ + i, centerI + i)) {
      stateCount[2]++;
      i++;
    }

    while (centerI + i < maxI && centerJ + i < maxJ && !image.get(centerJ + i, centerI + i)) {
      stateCount[3]++;
      i++;
    }
    if (stateCount[3] == 0) {
      return false;
    }

    while (centerI + i < maxI && centerJ + i < maxJ && image.get(centerJ + i, centerI + i)) {
      stateCount[4]++;
      i++;
    }
    if (stateCount[4] == 0) {
      return false;
    }

    return foundPatternDiagonal(stateCount);
  }"
"@Benchmark
  @BenchmarkMode(Mode.SampleTime)
  @OutputTimeUnit(TimeUnit.NANOSECONDS)
  public AsciiString direct() {
    return new AsciiString(directBytes, false);
  }"
"public static Set<String> getClassPaths(String packageName, boolean isDecode) {
		String packagePath = packageName.replace(StrUtil.DOT, StrUtil.SLASH);
		Enumeration<URL> resources;
		try {
			resources = getClassLoader().getResources(packagePath);
		} catch (IOException e) {
			throw new UtilException(e, ""Loading classPath [{}] error!"", packagePath);
		}
		final Set<String> paths = new HashSet<String>();
		String path;
		while (resources.hasMoreElements()) {
			path = resources.nextElement().getPath();
			paths.add(isDecode ? URLUtil.decode(path, CharsetUtil.systemCharsetName()) : path);
		}
		return paths;
	}"
"public static DataRowsFacade normalize(DataRowsFacade dataFrame, double min, double max, List<String> skipColumns) {
        List<String> columnsList = DataFrames.toList(dataFrame.get().columns());
        columnsList.removeAll(skipColumns);
        String[] columnNames = DataFrames.toArray(columnsList);
        //first row is min second row is max, each column in a row is for a particular column
        List<Row> minMax = minMaxColumns(dataFrame, columnNames);
        for (int i = 0; i < columnNames.length; i++) {
            String columnName = columnNames[i];
            double dMin = ((Number) minMax.get(0).get(i)).doubleValue();
            double dMax = ((Number) minMax.get(1).get(i)).doubleValue();
            double maxSubMin = (dMax - dMin);
            if (maxSubMin == 0)
                maxSubMin = 1;

            Column newCol = dataFrame.get().col(columnName).minus(dMin).divide(maxSubMin).multiply(max - min).plus(min);
            dataFrame = dataRows(dataFrame.get().withColumn(columnName, newCol));
        }


        return dataFrame;
    }"
"public String getQueryString(MultiValueMap<String, String> params) {
		if (params.isEmpty()) {
			return """";
		}
		StringBuilder query = new StringBuilder();
		Map<String, Object> singles = new HashMap<>();
		for (String param : params.keySet()) {
			int i = 0;
			for (String value : params.get(param)) {
				query.append(""&"");
				query.append(param);
				if (!"""".equals(value)) { // don't add =, if original is ?wsdl, output is
					// not ?wsdl=
					String key = param;
					// if form feed is already part of param name double
					// since form feed is used as the colon replacement below
					if (key.contains(""\f"")) {
						key = (FORM_FEED_PATTERN.matcher(key).replaceAll(""\f\f""));
					}
					// colon is special to UriTemplate
					if (key.contains("":"")) {
						key = COLON_PATTERN.matcher(key).replaceAll(""\f"");
					}
					key = key + i;
					singles.put(key, value);
					query.append(""={"");
					query.append(key);
					query.append(""}"");
				}
				i++;
			}
		}

		UriTemplate template = new UriTemplate(""?"" + query.toString().substring(1));
		return template.expand(singles).toString();
	}"
"public SDVariable reshape(SDVariable x, SDVariable shape) {
        return reshape(null, x, shape);
    }"
"protected boolean isAccessTokenRequest(final HttpServletRequest request, final HttpServletResponse response) {
        val requestPath = request.getRequestURI();
        val pattern = String.format(""(%s|%s)"", OAuth20Constants.ACCESS_TOKEN_URL, OAuth20Constants.TOKEN_URL);
        return doesUriMatchPattern(requestPath, pattern);
    }"
"public List<Model> executeList(CommandContext commandContext, Map<String, Object> parameterMap, int firstResult, int maxResults) {
    return commandContext.getModelEntityManager().findModelsByNativeQuery(parameterMap, firstResult, maxResults);
  }"
"public SDVariable variance(String name, @NonNull SDVariable x, boolean biasCorrected, boolean keepDims, int... dimensions) {
        validateNumerical(""variance"", x);
        SDVariable result = f().variance(x, biasCorrected, keepDims, dimensions);
        return updateVariableNameAndReference(result, name);
    }"
"public boolean isApplicable(Class<? extends Job> jobType) {
        Type parameterization = Types.getBaseClass(clazz, JobProperty.class);
        if (parameterization instanceof ParameterizedType) {
            ParameterizedType pt = (ParameterizedType) parameterization;
            Class applicable = Types.erasure(Types.getTypeArgument(pt, 0));
            return applicable.isAssignableFrom(jobType);
        } else {
            throw new AssertionError(clazz+"" doesn't properly parameterize JobProperty. The isApplicable() method must be overridden."");
        }
    }"
"int readBits(final int count) {
        if (count < 0 || count > 32) {
            throw new IllegalArgumentException(""count: "" + count + "" (expected: 0-32 )"");
        }
        int bitCount = this.bitCount;
        long bitBuffer = this.bitBuffer;

        if (bitCount < count) {
            long readData;
            int offset;
            switch (in.readableBytes()) {
                case 1: {
                    readData = in.readUnsignedByte();
                    offset = 8;
                    break;
                }
                case 2: {
                    readData = in.readUnsignedShort();
                    offset = 16;
                    break;
                }
                case 3: {
                    readData = in.readUnsignedMedium();
                    offset = 24;
                    break;
                }
                default: {
                    readData = in.readUnsignedInt();
                    offset = 32;
                    break;
                }
            }

            bitBuffer = bitBuffer << offset | readData;
            bitCount += offset;
            this.bitBuffer = bitBuffer;
        }

        this.bitCount = bitCount -= count;
        return (int) (bitBuffer >>> bitCount & (count != 32 ? (1 << count) - 1 : 0xFFFFFFFFL));
    }"
"int set(int bitIndex, boolean value) {
        int wordIndex = wordIndex(bitIndex);
        long bitMask = 1L << bitIndex;
        int previous = (words[wordIndex] & bitMask) != 0 ? 1 : 0;
        if (value) {
            words[wordIndex] |= bitMask;
        } else {
            words[wordIndex] &= ~bitMask;
        }
        return previous;
    }"
"public SDVariable jaccardDistance(SDVariable x, SDVariable y, int... dimensions) {
        return jaccardDistance(null, x, y, dimensions);
    }"
"public static <ReqT, RespT> ServerCallHandler<ReqT, RespT> asyncUnaryCall(
      UnaryMethod<ReqT, RespT> method) {
    return asyncUnaryRequestCall(method);
  }"
"public void registerPojoType(Class<?> type) {
		if (type == null) {
			throw new NullPointerException(""Cannot register null type class."");
		}
		if (!registeredPojoTypes.contains(type)) {
			registeredPojoTypes.add(type);
		}
	}"
"@SuppressWarnings(""unchecked"")
  public <T> T fromJson(String json, Type typeOfT) throws JsonSyntaxException {
    if (json == null) {
      return null;
    }
    StringReader reader = new StringReader(json);
    T target = (T) fromJson(reader, typeOfT);
    return target;
  }"
"public static INDArray gte(INDArray x, INDArray y, INDArray z, int... dimensions) {
        if(dimensions == null || dimensions.length == 0) {
            validateShapesNoDimCase(x,y,z);
            return Nd4j.getExecutioner().exec(new OldGreaterThanOrEqual(x,y,z));
        }

        return Nd4j.getExecutioner().exec(new BroadcastGreaterThanOrEqual(x,y,z,dimensions));
    }"
"@Override
  public TriggerInstance getTriggerInstanceById(final String triggerInstanceId) {
    TriggerInstance triggerInstance = null;
    try {
      final Collection<TriggerInstance> res = this.dbOperator
          .query(SELECT_EXECUTIONS_BY_INSTANCE_ID,
              new TriggerInstanceHandler(SORT_MODE.SORT_ON_START_TIME_ASC),
              triggerInstanceId);
      triggerInstance = !res.isEmpty() ? res.iterator().next() : null;
    } catch (final SQLException ex) {
      handleSQLException(ex);
    }
    populateFlowTriggerProperties(triggerInstance);
    return triggerInstance;
  }"
"@SuppressWarnings(""unchecked"")
	@Override
	public <N, S extends State> S getPartitionedState(
			final N namespace,
			final TypeSerializer<N> namespaceSerializer,
			final StateDescriptor<S, ?> stateDescriptor) throws Exception {

		checkNotNull(namespace, ""Namespace"");

		if (lastName != null && lastName.equals(stateDescriptor.getName())) {
			lastState.setCurrentNamespace(namespace);
			return (S) lastState;
		}

		InternalKvState<K, ?, ?> previous = keyValueStatesByName.get(stateDescriptor.getName());
		if (previous != null) {
			lastState = previous;
			lastState.setCurrentNamespace(namespace);
			lastName = stateDescriptor.getName();
			return (S) previous;
		}

		final S state = getOrCreateKeyedState(namespaceSerializer, stateDescriptor);
		final InternalKvState<K, N, ?> kvState = (InternalKvState<K, N, ?>) state;

		lastName = stateDescriptor.getName();
		lastState = kvState;
		kvState.setCurrentNamespace(namespace);

		return state;
	}"
"public NettyServerBuilder bossEventLoopGroup(EventLoopGroup group) {
    if (group != null) {
      return bossEventLoopGroupPool(new FixedObjectPool<>(group));
    }
    return bossEventLoopGroupPool(DEFAULT_BOSS_EVENT_LOOP_GROUP_POOL);
  }"
"public static Expression castToExpression(RowExpression rowExpression)
    {
        checkArgument(isExpression(rowExpression));
        return ((OriginalExpression) rowExpression).getExpression();
    }"
"public static String getRandomString(Random rnd, int minLength, int maxLength) {
		int len = rnd.nextInt(maxLength - minLength + 1) + minLength;

		char[] data = new char[len];
		for (int i = 0; i < data.length; i++) {
			data[i] = (char) (rnd.nextInt(0x7fff) + 1);
		}
		return new String(data);
	}"
"public static void delete( Key key ) { 
    Value val = DKV.get(key);
    if( val==null ) return;
    ((Lockable)val.get()).delete();
  }"
"public void setSessionProperty(String name, String value)
    {
        requireNonNull(name, ""name is null"");
        requireNonNull(value, ""value is null"");
        checkArgument(!name.isEmpty(), ""name is empty"");

        CharsetEncoder charsetEncoder = US_ASCII.newEncoder();
        checkArgument(name.indexOf('=') < 0, ""Session property name must not contain '=': %s"", name);
        checkArgument(charsetEncoder.canEncode(name), ""Session property name is not US_ASCII: %s"", name);
        checkArgument(charsetEncoder.canEncode(value), ""Session property value is not US_ASCII: %s"", value);

        sessionProperties.put(name, value);
    }"
"public static <T> Collection<T> removeNull(Collection<T> collection) {
		return filter(collection, new Editor<T>() {
			@Override
			public T edit(T t) {
				// 返回null便不加入集合
				return t;
			}
		});
	}"
"public IfImportState nodesForIf(NodeDef from, GraphDef graph) {
        //Assume we start with a switch statement
        int currNodeIndex = graph.getNodeList().indexOf(from);
        val trueDefName = from.getInput(1);
        val falseDefName = from.getInput(0);
        val scopeId = UUID.randomUUID().toString();
        val scopeName = scopeId + ""-"" + trueDefName.substring(0,trueDefName.indexOf(""/""));
        val trueDefScopeName = scopeName + ""-true-scope"";
        val falseDefScopeName = scopeName + ""-false-scope"";


        boolean onFalseDefinition = true;
        //start with the true
        boolean onTrueDefinition = false;

        List<NodeDef> falseBodyNodes = new ArrayList<>();
        List<NodeDef> trueBodyNodes = new ArrayList<>();
        List<NodeDef> conditionNodes = new ArrayList<>();
        Set<String> seenNames = new LinkedHashSet<>();
        /**
         * Accumulate a list backwards to get proper ordering.
         *
         */
        for(int i = currNodeIndex; i >= 0; i--) {
            //switch to false names
            if(graph.getNode(i).getName().equals(trueDefName)) {
                onFalseDefinition = false;
                onTrueDefinition = true;
            }

            //on predicate now
            if(graph.getNode(i).getName().contains(""pred_id"")) {
                onTrueDefinition = false;
            }
            //don't readd the same node, this causes a stackoverflow
            if(onTrueDefinition  && !graph.getNode(i).equals(from)) {
                trueBodyNodes.add(graph.getNode(i));
            }
            else if(onFalseDefinition && !graph.getNode(i).equals(from)) {
                falseBodyNodes.add(graph.getNode(i));
            }
            //condition scope now
            else {
                val currNode = graph.getNode(i);
                if(currNode.equals(from))
                    continue;

                //break only after bootstrapping the first node (the predicate id node)
                if(!seenNames.contains(graph.getNode(i).getName()) && !graph.getNode(i).getName().contains(""pred_id"")) {
                    break;
                }

                /**
                 * Continuously add inputs seen for each node in the sub graph that occurs.
                 * Starting from the predicate id, any node that has inputs in the condition scope
                 * are by definition within the scope. Any node not encountered after that is considered out of scope.
                 * This means we break.
                 */
                for(int inputIdx = 0; inputIdx < currNode.getInputCount(); inputIdx++) {
                    seenNames.add(currNode.getInput(inputIdx));
                }



                //ensure the ""current node"" is added as well
                seenNames.add(graph.getNode(i).getName());
                conditionNodes.add(graph.getNode(i));
            }
        }

        /**
         * Since we are going over the graph backwards,
         * we need to reverse the nodes to ensure proper ordering.
         */
        Collections.reverse(falseBodyNodes);
        Collections.reverse(trueBodyNodes);
        Collections.reverse(conditionNodes);


        return IfImportState.builder()
                .condNodes(conditionNodes)
                .falseNodes(falseBodyNodes)
                .trueNodes(trueBodyNodes)
                .conditionBodyScopeName(falseDefScopeName)
                .falseBodyScopeName(falseDefScopeName)
                .trueBodyScopeName(trueDefScopeName)
                .conditionBodyScopeName(scopeName)
                .build();
    }"
"private void closeResponse(ClientResponse response) {
        if (response != null) {
            try {
                response.close();
            } catch (Throwable th) {
                logger.error(""Cannot release response resource :"", th);
            }
        }
    }"
"private Map<String, Object> toFieldsMap(Map<String, DocumentField> fields) {
		Map<String, Object> result = new HashMap<>();
		for (Entry<String, DocumentField> entry : fields.entrySet()) {
			if (entry.getValue().getValues().size() > 1) {
				result.put(entry.getKey(), entry.getValue().getValues());
			} else {
				result.put(entry.getKey(), entry.getValue().getValue());
			}

		}
		return result;
	}"
"@Override
  public OperationHandle getTables(SessionHandle sessionHandle, String catalogName,
      String schemaName, String tableName, List<String> tableTypes)
          throws HiveSQLException {
    try {
      TGetTablesReq req = new TGetTablesReq(sessionHandle.toTSessionHandle());
      req.setTableName(tableName);
      req.setTableTypes(tableTypes);
      req.setSchemaName(schemaName);
      TGetTablesResp resp = cliService.GetTables(req);
      checkStatus(resp.getStatus());
      TProtocolVersion protocol = sessionHandle.getProtocolVersion();
      return new OperationHandle(resp.getOperationHandle(), protocol);
    } catch (HiveSQLException e) {
      throw e;
    } catch (Exception e) {
      throw new HiveSQLException(e);
    }
  }"
"private JButton getBtnReset() {
		if (btnReset == null) {
			btnReset = new JButton();
			btnReset.setText(Constant.messages.getString(""history.filter.button.clear""));
			btnReset.addActionListener(new java.awt.event.ActionListener() { 

				@Override
				public void actionPerformed(java.awt.event.ActionEvent e) {    

					exitResult = JOptionPane.NO_OPTION;
					// Unset everything
					methodList.setSelectedIndices(new int[0]);
					codeList.setSelectedIndices(new int[0]);
					tagList.setSelectedIndices(new int[0]);
					riskList.setSelectedIndices(new int[0]);
					confidenceList.setSelectedIndices(new int[0]);
					notesComboBox.setSelectedItem(HistoryFilter.NOTES_IGNORE);
					regexInc.setText("""");
					regexExc.setText("""");
					filter.reset();
				}
			});

		}
		return btnReset;
	}"
"private boolean isAllSuitableNodesOffline(R build) {
        Label label = getAssignedLabel();
        List<Node> allNodes = Jenkins.getInstance().getNodes();

        if (label != null) {
            //Invalid label. Put in queue to make administrator fix
            if(label.getNodes().isEmpty()) {
                return false;
            }
            //Returns true, if all suitable nodes are offline
            return label.isOffline();
        } else {
            if(canRoam) {
                for (Node n : Jenkins.getInstance().getNodes()) {
                    Computer c = n.toComputer();
                    if (c != null && c.isOnline() && c.isAcceptingTasks() && n.getMode() == Mode.NORMAL) {
                        // Some executor is online that  is ready and this job can run anywhere
                        return false;
                    }
                }
                //We can roam, check that the master is set to be used as much as possible, and not tied jobs only.
                return Jenkins.getInstance().getMode() == Mode.EXCLUSIVE;
            }
        }
        return true;
    }"
"public static boolean containsContentEqualsIgnoreCase(Collection<CharSequence> collection, CharSequence value) {
        for (CharSequence v : collection) {
            if (contentEqualsIgnoreCase(value, v)) {
                return true;
            }
        }
        return false;
    }"
"public static byte schemaToColumnType(String s) {
        switch (s.toLowerCase()) {
            case ""boolean"":
            case ""smallint"":
            case ""tinyint"":
            case ""bigint"":  // FIXME: make sure this is fixed by Tomas.
            case ""int"":
            case ""float"":
            case ""double"":
            case ""decimal"":
                return Vec.T_NUM;
            case ""timestamp"":
            case ""date"":
                return Vec.T_TIME;
            case ""enum"":
                return Vec.T_CAT;
            case ""string"":
            case ""varchar"":
//      case ""binary"":  // Removed binary column type support for now
            case ""char"":
                return Vec.T_STR;
            default:
                throw new IllegalArgumentException(""Unsupported Orc schema type: "" + s);
        }
    }"
"public long finalize64() {
    permuteAndUpdate();
    permuteAndUpdate();
    permuteAndUpdate();
    permuteAndUpdate();
    done = true;
    return v0[0] + v1[0] + mul0[0] + mul1[0];
  }"
"public Character getChar(String key, String group) {
		final String value = getByGroup(key, group);
		if (StrUtil.isBlank(value)) {
			return null;
		}
		return value.charAt(0);
	}"
"public static boolean call(Connection conn, String sql, Object... params) throws SQLException {
		CallableStatement call = null;
		try {
			call = StatementUtil.prepareCall(conn, sql, params);
			return call.execute();
		} finally {
			DbUtil.close(call);
		}
	}"
"public Configuration banDevice(@NonNull Integer deviceId) {
        if (!availableDevices.contains(deviceId))
            return this;

        if (!bannedDevices.contains(deviceId)) {
            bannedDevices.add(deviceId);
        }

        availableDevices.remove(deviceId);

        return this;
    }"
"public void freeSlot(SlotID slotId, AllocationID allocationId) {
		checkInit();

		TaskManagerSlot slot = slots.get(slotId);

		if (null != slot) {
			if (slot.getState() == TaskManagerSlot.State.ALLOCATED) {
				if (Objects.equals(allocationId, slot.getAllocationId())) {

					TaskManagerRegistration taskManagerRegistration = taskManagerRegistrations.get(slot.getInstanceId());

					if (taskManagerRegistration == null) {
						throw new IllegalStateException(""Trying to free a slot from a TaskManager "" +
							slot.getInstanceId() + "" which has not been registered."");
					}

					updateSlotState(slot, taskManagerRegistration, null, null);
				} else {
					LOG.debug(""Received request to free slot {} with expected allocation id {}, "" +
						""but actual allocation id {} differs. Ignoring the request."", slotId, allocationId, slot.getAllocationId());
				}
			} else {
				LOG.debug(""Slot {} has not been allocated."", allocationId);
			}
		} else {
			LOG.debug(""Trying to free a slot {} which has not been registered. Ignoring this message."", slotId);
		}
	}"
"public <X> DataSource<X> readFile(FileInputFormat<X> inputFormat, String filePath) {
		if (inputFormat == null) {
			throw new IllegalArgumentException(""InputFormat must not be null."");
		}
		if (filePath == null) {
			throw new IllegalArgumentException(""The file path must not be null."");
		}

		inputFormat.setFilePath(new Path(filePath));
		try {
			return createInput(inputFormat, TypeExtractor.getInputFormatTypes(inputFormat));
		}
		catch (Exception e) {
			throw new InvalidProgramException(""The type returned by the input format could not be automatically determined. "" +
					""Please specify the TypeInformation of the produced type explicitly by using the "" +
					""'createInput(InputFormat, TypeInformation)' method instead."");
		}
	}"
"public long registerStream(String appId, Iterator<ManagedBuffer> buffers, Channel channel) {
    long myStreamId = nextStreamId.getAndIncrement();
    streams.put(myStreamId, new StreamState(appId, buffers, channel));
    return myStreamId;
  }"
"public Transition<A> dup() {
        INDArray[] dupObservation = dup(observation);
        INDArray nextObs = nextObservation.dup();

        return new Transition<>(dupObservation, action, reward, isTerminal, nextObs);
    }"
"private List<Descriptor<T>> store() {
        if(type==null)
            return legacy;
        else
            return Jenkins.getInstance().<T,Descriptor<T>>getDescriptorList(type);
    }"
"public void setSecure(boolean isSecure) throws URIException {
        mIsSecure = isSecure;

        if (mUri == null) {
            // mUri not yet set
            return;
        }

        URI newUri = mUri;

        // check if URI consistent
        if (isSecure() && mUri.getScheme().equalsIgnoreCase(HTTP)) {
            newUri = new URI(mUri.toString().replaceFirst(HTTP, HTTPS), true);
            
        } else if (!isSecure() && mUri.getScheme().equalsIgnoreCase(HTTPS)) {
            newUri = new URI(mUri.toString().replaceFirst(HTTPS, HTTP), true);
        }

        if (newUri != mUri) {
            mUri = newUri;
            setHostPort(mUri.getPort());
        }
    }"
"public Map<String, OptionalFailure<Object>> getAccumulators(JobID jobID) throws Exception {
		return getAccumulators(jobID, ClassLoader.getSystemClassLoader());
	}"
"int DEPREL(final List<Integer> deprels, int id)
    {
        return ((id != -1) ? (deprels.get(id) + kDeprelInFeaturespace) : kNilDeprel);
    }"
"public static int getParallelism(Long pipelineId) {
        return ArbitrateConfigRegistry.getConfig().findPipeline(pipelineId).getParameters().getParallelism().intValue();
    }"
"public static Certificate readCertificate(String type, InputStream in, char[] password, String alias) {
		final KeyStore keyStore = readKeyStore(type, in, password);
		try {
			return keyStore.getCertificate(alias);
		} catch (KeyStoreException e) {
			throw new CryptoException(e);
		}
	}"
"protected void initBroadcastInputReaders() throws Exception {
		final int numBroadcastInputs = this.config.getNumBroadcastInputs();
		final MutableReader<?>[] broadcastInputReaders = new MutableReader<?>[numBroadcastInputs];

		int currentReaderOffset = config.getNumInputs();

		for (int i = 0; i < this.config.getNumBroadcastInputs(); i++) {
			//  ---------------- create the input readers ---------------------
			// in case where a logical input unions multiple physical inputs, create a union reader
			final int groupSize = this.config.getBroadcastGroupSize(i);
			if (groupSize == 1) {
				// non-union case
				broadcastInputReaders[i] = new MutableRecordReader<IOReadableWritable>(
						getEnvironment().getInputGate(currentReaderOffset),
						getEnvironment().getTaskManagerInfo().getTmpDirectories());
			} else if (groupSize > 1){
				// union case
				InputGate[] readers = new InputGate[groupSize];
				for (int j = 0; j < groupSize; ++j) {
					readers[j] = getEnvironment().getInputGate(currentReaderOffset + j);
				}
				broadcastInputReaders[i] = new MutableRecordReader<IOReadableWritable>(
						new UnionInputGate(readers),
						getEnvironment().getTaskManagerInfo().getTmpDirectories());
			} else {
				throw new Exception(""Illegal input group size in task configuration: "" + groupSize);
			}

			currentReaderOffset += groupSize;
		}
		this.broadcastInputReaders = broadcastInputReaders;
	}"
"public static String getUpTime() {
        long diff = ManagementFactory.getRuntimeMXBean().getUptime();
        diff /= 1000 * 60;
        long minutes = diff % 60;
        diff /= 60;
        long hours = diff % 24;
        diff /= 24;
        long days = diff;
        StringBuilder buf = new StringBuilder();
        if (days == 1) {
            buf.append(""1 day "");
        } else if (days > 1) {
            buf.append(Long.valueOf(days).toString()).append("" days "");
        }
        DecimalFormat format = new DecimalFormat();
        format.setMinimumIntegerDigits(2);
        buf.append(format.format(hours)).append("":"")
                .append(format.format(minutes));
        return buf.toString();
    }"
"protected SerializerFactory getSerializerFactory(boolean multipleClassLoader, boolean generic) {
        if (generic) {
            return multipleClassLoader ? new GenericMultipleClassLoaderSofaSerializerFactory() :
                new GenericSingleClassLoaderSofaSerializerFactory();
        } else {
            return multipleClassLoader ? new MultipleClassLoaderSofaSerializerFactory() :
                new SingleClassLoaderSofaSerializerFactory();
        }
    }"
"private static String sanitizeUrl(final String url) {
        val m = NON_PRINTABLE.matcher(url);
        val sb = new StringBuffer(url.length());
        var hasNonPrintable = false;
        while (m.find()) {
            m.appendReplacement(sb, "" "");
            hasNonPrintable = true;
        }
        m.appendTail(sb);
        if (hasNonPrintable) {
            LOGGER.warn(""The following redirect URL has been sanitized and may be sign of attack:\n[{}]"", url);
        }
        return sb.toString();
    }"
"@Override public GLRMModel createImpl() {
    GLRMModel.GLRMParameters parms = parameters.createImpl();
    return new GLRMModel( model_id.key(), parms, null );
  }"
"public static String formatParameterList(Collection<String> value) {
		return value == null ? null : StringUtils.collectionToDelimitedString(value, "" "");
	}"
"public static boolean nodeHasDeprecatedFlag(JCTree node) {
		if (node instanceof JCVariableDecl) return (((JCVariableDecl) node).mods.flags & Flags.DEPRECATED) != 0;
		if (node instanceof JCMethodDecl) return (((JCMethodDecl) node).mods.flags & Flags.DEPRECATED) != 0;
		if (node instanceof JCClassDecl) return (((JCClassDecl) node).mods.flags & Flags.DEPRECATED) != 0;
		return false;
	}"
"protected Event handleException(final J2EContext webContext, final BaseClient<Credentials, CommonProfile> client, final Exception e) {
        if (e instanceof RequestSloException) {
            try {
                webContext.getResponse().sendRedirect(""logout"");
            } catch (final IOException ioe) {
                throw new IllegalArgumentException(""Unable to call logout"", ioe);
            }
            return stopWebflow();
        }
        val msg = String.format(""Delegated authentication has failed with client %s"", client.getName());
        LOGGER.error(msg, e);
        throw new IllegalArgumentException(msg);
    }"
"private void update(ESSyncConfig config, Dml dml) {
        List<Map<String, Object>> dataList = dml.getData();
        List<Map<String, Object>> oldList = dml.getOld();
        if (dataList == null || dataList.isEmpty() || oldList == null || oldList.isEmpty()) {
            return;
        }
        SchemaItem schemaItem = config.getEsMapping().getSchemaItem();
        int i = 0;
        for (Map<String, Object> data : dataList) {
            Map<String, Object> old = oldList.get(i);
            if (data == null || data.isEmpty() || old == null || old.isEmpty()) {
                continue;
            }

            if (schemaItem.getAliasTableItems().size() == 1 && schemaItem.isAllFieldsSimple()) {
                // ------单表 & 所有字段都为简单字段------
                singleTableSimpleFiledUpdate(config, dml, data, old);
            } else {
                // ------主表 查询sql来更新------
                if (schemaItem.getMainTable().getTableName().equalsIgnoreCase(dml.getTable())) {
                    ESMapping mapping = config.getEsMapping();
                    String idFieldName = mapping.get_id() == null ? mapping.getPk() : mapping.get_id();
                    FieldItem idFieldItem = schemaItem.getSelectFields().get(idFieldName);

                    boolean idFieldSimple = true;
                    if (idFieldItem.isMethod() || idFieldItem.isBinaryOp()) {
                        idFieldSimple = false;
                    }

                    boolean allUpdateFieldSimple = true;
                    out: for (FieldItem fieldItem : schemaItem.getSelectFields().values()) {
                        for (ColumnItem columnItem : fieldItem.getColumnItems()) {
                            if (old.containsKey(columnItem.getColumnName())) {
                                if (fieldItem.isMethod() || fieldItem.isBinaryOp()) {
                                    allUpdateFieldSimple = false;
                                    break out;
                                }
                            }
                        }
                    }

                    // 不支持主键更新!!

                    // 判断是否有外键更新
                    boolean fkChanged = false;
                    for (TableItem tableItem : schemaItem.getAliasTableItems().values()) {
                        if (tableItem.isMain()) {
                            continue;
                        }
                        boolean changed = false;
                        for (List<FieldItem> fieldItems : tableItem.getRelationTableFields().values()) {
                            for (FieldItem fieldItem : fieldItems) {
                                if (old.containsKey(fieldItem.getColumn().getColumnName())) {
                                    fkChanged = true;
                                    changed = true;
                                    break;
                                }
                            }
                        }
                        // 如果外键有修改,则更新所对应该表的所有查询条件数据
                        if (changed) {
                            for (FieldItem fieldItem : tableItem.getRelationSelectFieldItems()) {
                                fieldItem.getColumnItems()
                                    .forEach(columnItem -> old.put(columnItem.getColumnName(), null));
                            }
                        }
                    }

                    // 判断主键和所更新的字段是否全为简单字段
                    if (idFieldSimple && allUpdateFieldSimple && !fkChanged) {
                        singleTableSimpleFiledUpdate(config, dml, data, old);
                    } else {
                        mainTableUpdate(config, dml, data, old);
                    }
                }

                // 从表的操作
                for (TableItem tableItem : schemaItem.getAliasTableItems().values()) {
                    if (tableItem.isMain()) {
                        continue;
                    }
                    if (!tableItem.getTableName().equals(dml.getTable())) {
                        continue;
                    }

                    // 关联条件出现在主表查询条件是否为简单字段
                    boolean allFieldsSimple = true;
                    for (FieldItem fieldItem : tableItem.getRelationSelectFieldItems()) {
                        if (fieldItem.isMethod() || fieldItem.isBinaryOp()) {
                            allFieldsSimple = false;
                            break;
                        }
                    }

                    // 所有查询字段均为简单字段
                    if (allFieldsSimple) {
                        // 不是子查询
                        if (!tableItem.isSubQuery()) {
                            // ------关联表简单字段更新------
                            Map<String, Object> esFieldData = new LinkedHashMap<>();
                            for (FieldItem fieldItem : tableItem.getRelationSelectFieldItems()) {
                                if (old.containsKey(fieldItem.getColumn().getColumnName())) {
                                    Object value = esTemplate.getValFromData(config.getEsMapping(),
                                        data,
                                        fieldItem.getFieldName(),
                                        fieldItem.getColumn().getColumnName());
                                    esFieldData.put(Util.cleanColumn(fieldItem.getFieldName()), value);
                                }
                            }
                            joinTableSimpleFieldOperation(config, dml, data, tableItem, esFieldData);
                        } else {
                            // ------关联子表简单字段更新------
                            subTableSimpleFieldOperation(config, dml, data, old, tableItem);
                        }
                    } else {
                        // ------关联子表复杂字段更新 执行全sql更新es------
                        wholeSqlOperation(config, dml, data, old, tableItem);
                    }
                }
            }

            i++;
        }
    }"
"protected static INDArray rebuildUpdaterStateArray(INDArray origUpdaterState, List<UpdaterBlock> orig, List<UpdaterBlock> newUpdater){
        if(origUpdaterState == null)
            return origUpdaterState;

        //First: check if there has been any change in the updater blocks to warrant rearranging the updater state view array
        if(orig.size() == newUpdater.size()){
            boolean allEq = true;
            for( int i=0; i<orig.size(); i++ ){
                UpdaterBlock ub1 = orig.get(i);
                UpdaterBlock ub2 = newUpdater.get(i);
                if(!ub1.getLayersAndVariablesInBlock().equals(ub2.getLayersAndVariablesInBlock())){
                    allEq = false;
                    break;
                }
            }
            if(allEq){
                return origUpdaterState;
            }
        }

        Map<String,List<INDArray>> stateViewsPerParam = new HashMap<>();
        for(UpdaterBlock ub : orig){
            List<UpdaterBlock.ParamState> params = ub.getLayersAndVariablesInBlock();
            int blockPStart = ub.getParamOffsetStart();
            int blockPEnd = ub.getParamOffsetEnd();

            int blockUStart = ub.getUpdaterViewOffsetStart();
            int blockUEnd = ub.getUpdaterViewOffsetEnd();

            int paramsMultiplier = (blockUEnd-blockUStart)/(blockPEnd-blockPStart);     //Updater state length should be exactly 0, 1, 2 or 3x number of params

            INDArray updaterView = ub.getUpdaterView();
            long nParamsInBlock = blockPEnd - blockPStart;

            long soFar = 0;
            for( int sub=0; sub<paramsMultiplier; sub++) {
                //subsetUpdaterView: [m0, m1, m2] etc
                INDArray subsetUpdaterView = updaterView.get(NDArrayIndex.interval(0, 0, true), NDArrayIndex.interval(soFar, soFar + nParamsInBlock));

                long offsetWithinSub = 0;
                for (UpdaterBlock.ParamState ps : params) {
                    int idx = getId(ps.getLayer());
                    String paramName = idx + ""_"" + ps.getParamName();
                    INDArray pv = ps.getParamView();
                    long nParamsThisParam = pv.length();

                    INDArray currSplit = subsetUpdaterView.get(NDArrayIndex.interval(0, 0, true), NDArrayIndex.interval(offsetWithinSub, offsetWithinSub + nParamsThisParam));
                    if(!stateViewsPerParam.containsKey(paramName))
                        stateViewsPerParam.put(paramName, new ArrayList<INDArray>());
                    stateViewsPerParam.get(paramName).add(currSplit);
                    offsetWithinSub += nParamsThisParam;
                }

                soFar += nParamsInBlock;
            }
        }

        //Now that we've got updater state per param, we need to reconstruct it in an order suitable for the new updater blocks...
        List<INDArray> toConcat = new ArrayList<>();
        for(UpdaterBlock ub : newUpdater){
            List<UpdaterBlock.ParamState> ps = ub.getLayersAndVariablesInBlock();
            int idx = getId(ps.get(0).getLayer());
            String firstParam = idx + ""_"" + ps.get(0).getParamName();
            int size = stateViewsPerParam.get(firstParam).size();
            //For multiple params in the one block, we want to order like [a0, b0, c0][a1,b1,c1]
            for( int i=0; i<size; i++ ){
                for(UpdaterBlock.ParamState p : ps) {
                    idx = getId(p.getLayer());
                    String paramName = idx + ""_"" + p.getParamName();
                    INDArray arr = stateViewsPerParam.get(paramName).get(i);
                    toConcat.add(arr);
                }
            }
        }
        INDArray newUpdaterState = Nd4j.hstack(toConcat);
        Preconditions.checkState(newUpdaterState.rank() == 2, ""Expected rank 2"");
        Preconditions.checkState(origUpdaterState.length() == newUpdaterState.length(), ""Updater state array lengths should be equal: got %s s. %s"",
                origUpdaterState.length(), newUpdaterState.length());
        return newUpdaterState;
    }"
"static Map<String, JwkDefinitionHolder> loadJwkDefinitions(URL jwkSetUrl) {
		InputStream jwkSetSource;
		try {
			jwkSetSource = jwkSetUrl.openStream();
		} catch (IOException ex) {
			throw new JwkException(""An I/O error occurred while reading from the JWK Set source: "" + ex.getMessage(), ex);
		}

		Set<JwkDefinition> jwkDefinitionSet = jwkSetConverter.convert(jwkSetSource);

		Map<String, JwkDefinitionHolder> jwkDefinitions = new LinkedHashMap<String, JwkDefinitionHolder>();

		for (JwkDefinition jwkDefinition : jwkDefinitionSet) {
			if (JwkDefinition.KeyType.RSA.equals(jwkDefinition.getKeyType())) {
				jwkDefinitions.put(jwkDefinition.getKeyId(),
						new JwkDefinitionHolder(jwkDefinition, createRsaVerifier((RsaJwkDefinition) jwkDefinition)));
			} else if (JwkDefinition.KeyType.EC.equals(jwkDefinition.getKeyType())) {
				jwkDefinitions.put(jwkDefinition.getKeyId(),
						new JwkDefinitionHolder(jwkDefinition, createEcVerifier((EllipticCurveJwkDefinition) jwkDefinition)));
			}
		}

		return jwkDefinitions;
	}"
"@Override
	public Bulkhead bulkhead(String name, BulkheadConfig config) {
		return computeIfAbsent(name, () -> Bulkhead.of(name, Objects.requireNonNull(config, CONFIG_MUST_NOT_BE_NULL)));
	}"
"public static Log getLog(Class<?> source) {
		synchronized (logs) {
			Log log = new DeferredLog();
			logs.put(log, source);
			return log;
		}
	}"
"public static String bytesToString(ByteBuffer b) {
    return Unpooled.wrappedBuffer(b).toString(StandardCharsets.UTF_8);
  }"
"private void dispatch(final ExecutionReference reference, final ExecutableFlow exflow,
      final Executor choosenExecutor) throws ExecutorManagerException {
    exflow.setUpdateTime(System.currentTimeMillis());

    this.executorLoader.assignExecutor(choosenExecutor.getId(),
        exflow.getExecutionId());
    try {
      this.apiGateway.callWithExecutable(exflow, choosenExecutor,
          ConnectorParams.EXECUTE_ACTION);
    } catch (final ExecutorManagerException ex) {
      logger.error(""Rolling back executor assignment for execution id:""
          + exflow.getExecutionId(), ex);
      this.executorLoader.unassignExecutor(exflow.getExecutionId());
      throw new ExecutorManagerException(ex);
    }
    reference.setExecutor(choosenExecutor);

    // move from flow to running flows
    this.runningExecutions.get().put(exflow.getExecutionId(), new Pair<>(reference, exflow));
    synchronized (this.runningExecutions.get()) {
      // Wake up RunningExecutionsUpdaterThread from wait() so that it will immediately check status
      // from executor(s). Normally flows will run at least some time and can't be cleaned up
      // immediately, so there will be another wait round (or many, actually), but for unit tests
      // this is significant to let them run quickly.
      this.runningExecutions.get().notifyAll();
    }
    synchronized (this) {
      // wake up all internal waiting threads, too
      this.notifyAll();
    }

    logger.info(String.format(
        ""Successfully dispatched exec %d with error count %d"",
        exflow.getExecutionId(), reference.getNumErrors()));
  }"
"protected <V> CompletableFuture<V> callAsyncWithoutFencing(Callable<V> callable, Time timeout) {
		if (rpcServer instanceof FencedMainThreadExecutable) {
			return ((FencedMainThreadExecutable) rpcServer).callAsyncWithoutFencing(callable, timeout);
		} else {
			throw new RuntimeException(""FencedRpcEndpoint has not been started with a FencedMainThreadExecutable RpcServer."");
		}
	}"
"public void putProperties(DescriptorProperties otherProperties) {
		for (Map.Entry<String, String> otherProperty : otherProperties.properties.entrySet()) {
			put(otherProperty.getKey(), otherProperty.getValue());
		}
	}"
"public static int bitMix(int in) {
		in ^= in >>> 16;
		in *= 0x85ebca6b;
		in ^= in >>> 13;
		in *= 0xc2b2ae35;
		in ^= in >>> 16;
		return in;
	}"
"public void add(IWord word)
    {
        Item item = trie.get(word.getValue());
        if (item == null)
        {
            item = new Item(word.getValue(), word.getLabel());
            trie.put(item.key, item);
        }
        else
        {
            item.addLabel(word.getLabel());
        }
    }"
"public void info( String oinfo ) {
		//
		String methodName = moduleCode + ""."" + ""info"";
		//
		out.format( ""%s%n"", oinfo );
		//
		charsCount += oinfo.length();
		//
		String FOInfo = getFullInfoString( oinfo );
		//
		if ( !isFileOpen( methodName ) ) return;
		//
		outFile( FOInfo );
		//
        flushFile();
		//
	}"
"@Override
    public void axpy(long n, double alpha, INDArray x, INDArray y) {
        BaseSparseNDArray sparseX = (BaseSparseNDArray) x;
        DataBuffer pointers = sparseX.getVectorCoordinates();
        switch (x.data().dataType()) {
            case DOUBLE:
                DefaultOpExecutioner.validateDataType(DataType.DOUBLE, x);
                DefaultOpExecutioner.validateDataType(DataType.DOUBLE, y);
                daxpyi(n, alpha, x, pointers, y);
                break;
            case FLOAT:
                DefaultOpExecutioner.validateDataType(DataType.FLOAT, x);
                DefaultOpExecutioner.validateDataType(DataType.FLOAT, y);
                saxpyi(n, alpha, x, pointers, y);
                break;
            case HALF:
                DefaultOpExecutioner.validateDataType(DataType.HALF, x);
                DefaultOpExecutioner.validateDataType(DataType.HALF, y);
                haxpyi(n, alpha, x, pointers, y);
                break;
            default:
                throw new UnsupportedOperationException();
        }
    }"
"public Future<AddressedEnvelope<DnsResponse, InetSocketAddress>> query(DnsQuestion question) {
        return query(nextNameServerAddress(), question);
    }"
"public static Sftp createSftp(String sshHost, int sshPort, String sshUser, String sshPass) {
		return new Sftp(sshHost, sshPort, sshUser, sshPass);
	}"
"public static List<Object> getFieldValues(Iterable<?> collection, final String fieldName) {
		return getFieldValues(collection, fieldName, false);
	}"
"public Optional<FieldReferenceExpression> lookupField(String name) {
		List<FieldReferenceExpression> matchingFields = fieldReferences.stream()
			.map(input -> input.get(name))
			.filter(Objects::nonNull)
			.collect(toList());

		if (matchingFields.size() == 1) {
			return Optional.of(matchingFields.get(0));
		} else if (matchingFields.size() == 0) {
			return Optional.empty();
		} else {
			throw failAmbigousColumn(name);
		}
	}"
"public static CellStyle createDefaultCellStyle(Workbook workbook) {
		final CellStyle cellStyle = workbook.createCellStyle();
		setAlign(cellStyle, HorizontalAlignment.CENTER, VerticalAlignment.CENTER);
		setBorder(cellStyle, BorderStyle.THIN, IndexedColors.BLACK);
		return cellStyle;
	}"
"public List<String> watchForChilds(final String path) {
        if (_zookeeperEventThread != null && Thread.currentThread() == _zookeeperEventThread) {
            throw new IllegalArgumentException(""Must not be done in the zookeeper event thread."");
        }
        return retryUntilConnected(new Callable<List<String>>() {

            @Override
            public List<String> call() throws Exception {
                exists(path, true);
                try {
                    return getChildren(path, true);
                } catch (ZkNoNodeException e) {
                    // ignore, the ""exists"" watch will listen for the parent node to appear
                }
                return null;
            }
        });
    }"
"private void handleDecodeInternally(Result rawResult, ResultHandler resultHandler, Bitmap barcode) {

    maybeSetClipboard(resultHandler);

    SharedPreferences prefs = PreferenceManager.getDefaultSharedPreferences(this);

    if (resultHandler.getDefaultButtonID() != null && prefs.getBoolean(PreferencesActivity.KEY_AUTO_OPEN_WEB, false)) {
      resultHandler.handleButtonPress(resultHandler.getDefaultButtonID());
      return;
    }

    statusView.setVisibility(View.GONE);
    viewfinderView.setVisibility(View.GONE);
    resultView.setVisibility(View.VISIBLE);

    ImageView barcodeImageView = (ImageView) findViewById(R.id.barcode_image_view);
    if (barcode == null) {
      barcodeImageView.setImageBitmap(BitmapFactory.decodeResource(getResources(),
          R.drawable.launcher_icon));
    } else {
      barcodeImageView.setImageBitmap(barcode);
    }

    TextView formatTextView = (TextView) findViewById(R.id.format_text_view);
    formatTextView.setText(rawResult.getBarcodeFormat().toString());

    TextView typeTextView = (TextView) findViewById(R.id.type_text_view);
    typeTextView.setText(resultHandler.getType().toString());

    DateFormat formatter = DateFormat.getDateTimeInstance(DateFormat.SHORT, DateFormat.SHORT);
    TextView timeTextView = (TextView) findViewById(R.id.time_text_view);
    timeTextView.setText(formatter.format(rawResult.getTimestamp()));


    TextView metaTextView = (TextView) findViewById(R.id.meta_text_view);
    View metaTextViewLabel = findViewById(R.id.meta_text_view_label);
    metaTextView.setVisibility(View.GONE);
    metaTextViewLabel.setVisibility(View.GONE);
    Map<ResultMetadataType,Object> metadata = rawResult.getResultMetadata();
    if (metadata != null) {
      StringBuilder metadataText = new StringBuilder(20);
      for (Map.Entry<ResultMetadataType,Object> entry : metadata.entrySet()) {
        if (DISPLAYABLE_METADATA_TYPES.contains(entry.getKey())) {
          metadataText.append(entry.getValue()).append('\n');
        }
      }
      if (metadataText.length() > 0) {
        metadataText.setLength(metadataText.length() - 1);
        metaTextView.setText(metadataText);
        metaTextView.setVisibility(View.VISIBLE);
        metaTextViewLabel.setVisibility(View.VISIBLE);
      }
    }

    CharSequence displayContents = resultHandler.getDisplayContents();
    TextView contentsTextView = (TextView) findViewById(R.id.contents_text_view);
    contentsTextView.setText(displayContents);
    int scaledSize = Math.max(22, 32 - displayContents.length() / 4);
    contentsTextView.setTextSize(TypedValue.COMPLEX_UNIT_SP, scaledSize);

    TextView supplementTextView = (TextView) findViewById(R.id.contents_supplement_text_view);
    supplementTextView.setText("""");
    supplementTextView.setOnClickListener(null);
    if (PreferenceManager.getDefaultSharedPreferences(this).getBoolean(
        PreferencesActivity.KEY_SUPPLEMENTAL, true)) {
      SupplementalInfoRetriever.maybeInvokeRetrieval(supplementTextView,
                                                     resultHandler.getResult(),
                                                     historyManager,
                                                     this);
    }

    int buttonCount = resultHandler.getButtonCount();
    ViewGroup buttonView = (ViewGroup) findViewById(R.id.result_button_view);
    buttonView.requestFocus();
    for (int x = 0; x < ResultHandler.MAX_BUTTON_COUNT; x++) {
      TextView button = (TextView) buttonView.getChildAt(x);
      if (x < buttonCount) {
        button.setVisibility(View.VISIBLE);
        button.setText(resultHandler.getButtonText(x));
        button.setOnClickListener(new ResultButtonListener(resultHandler, x));
      } else {
        button.setVisibility(View.GONE);
      }
    }

  }"
"public static void writeObjects(OutputStream out, boolean isCloseOut, Serializable... contents) throws IORuntimeException {
		ObjectOutputStream osw = null;
		try {
			osw = out instanceof ObjectOutputStream ? (ObjectOutputStream) out : new ObjectOutputStream(out);
			for (Object content : contents) {
				if (content != null) {
					osw.writeObject(content);
					osw.flush();
				}
			}
		} catch (IOException e) {
			throw new IORuntimeException(e);
		} finally {
			if (isCloseOut) {
				close(osw);
			}
		}
	}"
"public void sendRPC(final String mod, final String fun,
            final OtpErlangObject[] args) throws IOException {
        sendRPC(mod, fun, new OtpErlangList(args));
    }"
"public Pair<Double, INDArray> nn(INDArray point) {
        return nn(root, point, rect, Double.POSITIVE_INFINITY, null, 0);
    }"
"public void setBody(String contents)  {
		if (contents == null) {
			return ;
		}
		
		cachedString = null;
		if (charset == null && isDetermineCharset()) {
			// Attempt to determine the charset to avoid data loss.
			charset = determineCharset(contents);
		}
		
		body = contents.getBytes(getCharsetImpl());
		
		pos = body.length;
	}"
"public final <R> Call<R> map(Mapper<V, R> mapper) {
    return new Mapping<>(mapper, this);
  }"
"private void loadPreset() {
    String presetName = getJobProps().get(GobblinConstants.GOBBLIN_PRESET_KEY);
    if (presetName == null) {
      return;
    }

    GobblinPresets preset = GobblinPresets.fromName(presetName);
    Properties presetProperties = gobblinPresets.get(preset);
    if (presetProperties == null) {
      throw new IllegalArgumentException(
          ""Preset "" + presetName + "" is not supported. Supported presets: ""
              + gobblinPresets.keySet());
    }

    getLog().info(""Loading preset "" + presetName + "" : "" + presetProperties);
    Map<String, String> skipped = Maps.newHashMap();
    for (String key : presetProperties.stringPropertyNames()) {
      if (getJobProps().containsKey(key)) {
        skipped.put(key, presetProperties.getProperty(key));
        continue;
      }
      getJobProps().put(key, presetProperties.getProperty(key));
    }
    getLog().info(""Loaded preset "" + presetName);
    if (!skipped.isEmpty()) {
      getLog().info(
          ""Skipped some properties from preset as already exists in job properties. Skipped: ""
              + skipped);
    }

    if (getJobProps().getBoolean(GobblinConstants.GOBBLIN_PROPERTIES_HELPER_ENABLED_KEY, true)) {
      getValidator(preset).validate(getJobProps());
    }
  }"
"public static <T extends Collection<String>> T readLines(URL url, String charsetName, T collection) throws IORuntimeException {
		return readLines(url, CharsetUtil.charset(charsetName), collection);
	}"
"public String serializeTransformList(List<Transform> list) {
        ObjectMapper om = getObjectMapper();
        try {
            return om.writeValueAsString(new ListWrappers.TransformList(list));
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    }"
"public static InstrumentedThreadFactory privilegedThreadFactory(MetricRegistry registry, String name) {
        return new InstrumentedThreadFactory(Executors.privilegedThreadFactory(), registry, name);
    }"
"public static boolean isIdCard(@Nullable CharSequence input) {
		return isMatch(PATTERN_REGEX_ID_CARD15, input) || isMatch(PATTERN_REGEX_ID_CARD18, input);
	}"
"double[][] initial_centers(KMeansModel model, final Vec[] vecs, final double[] means, final double[] mults, final int[] modes, int k) {

      // Categoricals use a different distance metric than numeric columns.
      model._output._categorical_column_count=0;
      _isCats = new String[vecs.length][];
      for( int v=0; v<vecs.length; v++ ) {
        _isCats[v] = vecs[v].isCategorical() ? new String[0] : null;
        if (_isCats[v] != null) model._output._categorical_column_count++;
      }
      Random rand = water.util.RandomUtils.getRNG(_parms._seed-1);
      double centers[][];    // Cluster centers
      if( null != _parms._user_points ) { // User-specified starting points
        Frame user_points = _parms._user_points.get();
        int numCenters = (int)user_points.numRows();
        int numCols = model._output.nfeatures();
        centers = new double[numCenters][numCols];
        Vec[] centersVecs = user_points.vecs();
        // Get the centers and standardize them if requested
        for (int r=0; r<numCenters; r++) {
          for (int c=0; c<numCols; c++){
            centers[r][c] = centersVecs[c].at(r);
            centers[r][c] = Kmeans_preprocessData(centers[r][c], c, means, mults, modes);
          }
        }
      }
      else { // Random, Furthest, or PlusPlus initialization
        if (_parms._init == Initialization.Random) {
          // Initialize all cluster centers to random rows
          centers = new double[k][model._output.nfeatures()];
          for (double[] center : centers)
            randomRow(vecs, rand, center, means, mults, modes);
        } else {
          centers = new double[1][model._output.nfeatures()];
          // Initialize first cluster center to random row
          randomRow(vecs, rand, centers[0], means, mults, modes);

          model._output._iterations = 0;
          while (model._output._iterations < 5) {
            // Sum squares distances to cluster center
            SumSqr sqr = new SumSqr(centers, means, mults, modes, _isCats).doAll(vecs);

            // Sample with probability inverse to square distance
            Sampler sampler = new Sampler(centers, means, mults, modes, _isCats, sqr._sqr, k * 3, _parms.getOrMakeRealSeed(), hasWeightCol()).doAll(vecs);
            centers = ArrayUtils.append(centers, sampler._sampled);

            // Fill in sample centers into the model
            model._output._centers_raw = destandardize(centers, _isCats, means, mults);
            model._output._tot_withinss = sqr._sqr / _train.numRows();

            model._output._iterations++;     // One iteration done

            model.update(_job); // Make early version of model visible, but don't update progress using update(1)
            if (stop_requested()) {
              if (timeout())
                warn(""_max_runtime_secs reached."", ""KMeans exited before finishing all iterations."");
              break; // Stopped/cancelled
            }
          }
          // Recluster down to k cluster centers
          centers = recluster(centers, rand, k, _parms._init, _isCats);
          model._output._iterations = 0; // Reset iteration count
        }
      }
      assert(centers.length == k);
      return centers;
    }"
"public int totalCount(int outputNum) {
        assertIndex(outputNum);
        return countTruePositive[outputNum] + countTrueNegative[outputNum] + countFalseNegative[outputNum]
                        + countFalsePositive[outputNum];
    }"
"HpackHeaderField getHeaderField(int index) {
        HeaderEntry entry = head;
        while (index-- >= 0) {
            entry = entry.before;
        }
        return entry;
    }"
"public static void warn(Log log, String format, Object... arguments) {
		warn(log, null, format, arguments);
	}"
"public static <IN> StreamingFileSink.BulkFormatBuilder<IN, String> forBulkFormat(
			final Path basePath, final BulkWriter.Factory<IN> writerFactory) {
		return new StreamingFileSink.BulkFormatBuilder<>(basePath, writerFactory, new DateTimeBucketAssigner<>());
	}"
"private boolean checkUnGetSlotAt(LogPosition startPosition, int batchSize) {
        if (batchMode.isItemSize()) {
            long current = getSequence.get();
            long maxAbleSequence = putSequence.get();
            long next = current;
            if (startPosition == null || !startPosition.getPostion().isIncluded()) { // 第一次订阅之后，需要包含一下start位置，防止丢失第一条记录
                next = next + 1;// 少一条数据
            }

            if (current < maxAbleSequence && next + batchSize - 1 <= maxAbleSequence) {
                return true;
            } else {
                return false;
            }
        } else {
            // 处理内存大小判断
            long currentSize = getMemSize.get();
            long maxAbleSize = putMemSize.get();

            if (maxAbleSize - currentSize >= batchSize * bufferMemUnit) {
                return true;
            } else {
                return false;
            }
        }
    }"
"public static void toFile(String templateFileName, VelocityContext context, String destPath) {
		assertInit();

		toFile(Velocity.getTemplate(templateFileName), context, destPath);
	}"
"public static <T extends MessageNano> Marshaller<T> marshaller(MessageNanoFactory<T> factory) {
    return new MessageMarshaller<>(factory);
  }"
"public static ThymeleafTemplate wrap(TemplateEngine engine, String template, Charset charset) {
		return (null == engine) ? null : new ThymeleafTemplate(engine, template, charset);
	}"
"private Identity build(BatchProto.Identity identityProto) {
        Identity identity = new Identity();
        identity.setChannelId(identityProto.getChannelId());
        identity.setPipelineId(identityProto.getPipelineId());
        identity.setProcessId(identityProto.getProcessId());
        return identity;
    }"
"public void lockLocation() throws IllegalStateException {
		checkState(lockedLocation == null, ""Location is already locked"");
		checkState(sharedSlot != null, ""Cannot lock location without a slot."");

		lockedLocation = sharedSlot.getTaskManagerLocation();
	}"
"public String read_string() throws OtpErlangDecodeException {
        int tag;
        int len;
        byte[] strbuf;
        int[] intbuf;
        tag = read1skip_version();
        switch (tag) {
        case OtpExternal.stringTag:
            len = read2BE();
            strbuf = new byte[len];
            this.readN(strbuf);
            return OtpErlangString.newString(strbuf);
        case OtpExternal.nilTag:
            return """";
        case OtpExternal.listTag: // List when unicode +
            len = read4BE();
            intbuf = new int[len];
            for (int i = 0; i < len; i++) {
                intbuf[i] = read_int();
                if (!OtpErlangString.isValidCodePoint(intbuf[i])) {
                    throw new OtpErlangDecodeException(""Invalid CodePoint: ""
                            + intbuf[i]);
                }
            }
            read_nil();
            return new String(intbuf, 0, intbuf.length);
        default:
            throw new OtpErlangDecodeException(
                    ""Wrong tag encountered, expected "" + OtpExternal.stringTag
                            + "" or "" + OtpExternal.listTag + "", got "" + tag);
        }
    }"
"public void recordEvaluationCandidates(List<String> evaluationCandidates) {
		Assert.notNull(evaluationCandidates, ""evaluationCandidates must not be null"");
		this.unconditionalClasses.addAll(evaluationCandidates);
	}"
"public static Number toNumber(Object value, Number defaultValue) {
		return convert(Number.class, value, defaultValue);
	}"
"public T get(String variable, String frame, int iteration, FrameIter parentFrameIter, boolean enforceExistence) {
        //TODO eventually we'll cache and reuse VarId objects here to avoid garbage generation on lookup etc
        VarId varId = newVarId(variable, frame, iteration, parentFrameIter);
        T out = nodeOutputs.get(varId);
        if(enforceExistence) {
            Preconditions.checkNotNull(out, ""No output found for variable %s (frame %s, iteration %s)"", variable, frame, iteration);
        }
        return out;
    }"
"public static boolean isBasicType(Class<?> clazz) {
		if (null == clazz) {
			return false;
		}
		return (clazz.isPrimitive() || isPrimitiveWrapper(clazz));
	}"
"public static int getClosestFixedBits(int width)
    {
        if (width == 0) {
            return 1;
        }

        if (width >= 1 && width <= 24) {
            return width;
        }
        else if (width > 24 && width <= 26) {
            return 26;
        }
        else if (width > 26 && width <= 28) {
            return 28;
        }
        else if (width > 28 && width <= 30) {
            return 30;
        }
        else if (width > 30 && width <= 32) {
            return 32;
        }
        else if (width > 32 && width <= 40) {
            return 40;
        }
        else if (width > 40 && width <= 48) {
            return 48;
        }
        else if (width > 48 && width <= 56) {
            return 56;
        }
        else {
            return 64;
        }
    }"
"public SoapClient setHeader(QName name, String actorURI, String roleUri, Boolean mustUnderstand, Boolean relay) {
		SOAPHeader header;
		SOAPHeaderElement ele;
		try {
			header = this.message.getSOAPHeader();
			ele = header.addHeaderElement(name);
			if (StrUtil.isNotBlank(roleUri)) {
				ele.setRole(roleUri);
			}
			if (null != relay) {
				ele.setRelay(relay);
			}
		} catch (SOAPException e) {
			throw new SoapRuntimeException(e);
		}

		if (StrUtil.isNotBlank(actorURI)) {
			ele.setActor(actorURI);
		}
		if (null != mustUnderstand) {
			ele.setMustUnderstand(mustUnderstand);
		}

		return this;
	}"
"public String getAuthorizationUrl(final String relyingPartyIdentifier, final String wctx) {
        return String.format(getIdentityProviderUrl() + QUERYSTRING, relyingPartyIdentifier, wctx);
    }"
"@Nonnull
    public static List<ViewDescriptor> allInstantiable() {
        List<ViewDescriptor> r = new ArrayList<>();
        StaplerRequest request = Stapler.getCurrentRequest();
        if (request == null) {
            throw new IllegalStateException(""This method can only be invoked from a stapler request"");
        }
        ViewGroup owner = request.findAncestorObject(ViewGroup.class);
        if (owner == null) {
            throw new IllegalStateException(""This method can only be invoked from a request with a ViewGroup ancestor"");
        }
        for (ViewDescriptor d : DescriptorVisibilityFilter.apply(owner, all())) {
            if (d.isApplicableIn(owner) && d.isInstantiable()
                    && owner.getACL().hasCreatePermission(Jenkins.getAuthentication(), owner, d)) {
                r.add(d);
            }
        }
        return r;
    }"
"public static InstrumentedThreadFactory defaultThreadFactory(MetricRegistry registry, String name) {
        return new InstrumentedThreadFactory(Executors.defaultThreadFactory(), registry, name);
    }"
"public static <T> List<T> wrapList(final T... source) {
        val list = new ArrayList<T>();
        addToCollection(list, source);
        return list;
    }"
"public int read(byte[] buf, int offset, int numToRead) throws IOException {
        int totalRead = 0;

        if (this.entryOffset >= this.entrySize) {
            return -1;
        }

        if ((numToRead + this.entryOffset) > this.entrySize) {
            numToRead = (int) (this.entrySize - this.entryOffset);
        }

        if (this.readBuf != null) {
            int sz = (numToRead > this.readBuf.length) ? this.readBuf.length
                    : numToRead;

            System.arraycopy(this.readBuf, 0, buf, offset, sz);

            if (sz >= this.readBuf.length) {
                this.readBuf = null;
            } else {
                int newLen = this.readBuf.length - sz;
                byte[] newBuf = new byte[newLen];

                System.arraycopy(this.readBuf, sz, newBuf, 0, newLen);

                this.readBuf = newBuf;
            }

            totalRead += sz;
            numToRead -= sz;
            offset += sz;
        }

        while (numToRead > 0) {
            byte[] rec = this.buffer.readRecord();

            if (rec == null) {
                // Unexpected EOF!
                throw new IOException(""unexpected EOF with "" + numToRead
                        + "" bytes unread"");
            }

            int sz = numToRead;
            int recLen = rec.length;

            if (recLen > sz) {
                System.arraycopy(rec, 0, buf, offset, sz);

                this.readBuf = new byte[recLen - sz];

                System.arraycopy(rec, sz, this.readBuf, 0, recLen - sz);
            } else {
                sz = recLen;

                System.arraycopy(rec, 0, buf, offset, recLen);
            }

            totalRead += sz;
            numToRead -= sz;
            offset += sz;
        }

        this.entryOffset += totalRead;

        return totalRead;
    }"
"private JPanel getJPanel() {
		if (jPanel == null) {
			GridBagConstraints gridBagConstraints12 = new GridBagConstraints();
			java.awt.GridBagConstraints gridBagConstraints11 = new GridBagConstraints();

			java.awt.GridBagConstraints gridBagConstraints6 = new GridBagConstraints();

			ZapLabel descLabel = new ZapLabel();
			descLabel.setLineWrap(true);
			descLabel.setWrapStyleWord(true);
			descLabel.setText(Constant.messages.getString(""history.filter.label.desc""));
			
			jPanel = new JPanel();
			jPanel.setLayout(new GridBagLayout());

			gridBagConstraints6.gridwidth = 3;
			gridBagConstraints6.gridx = 0;
			gridBagConstraints6.gridy = 3;
			gridBagConstraints6.insets = new java.awt.Insets(5,2,5,2);
			gridBagConstraints6.ipadx = 3;
			gridBagConstraints6.ipady = 3;
			gridBagConstraints11.gridx = 0;
			gridBagConstraints11.gridy = 0;
			gridBagConstraints11.insets = new java.awt.Insets(5,10,5,10);
			gridBagConstraints11.weightx = 1.0D;
			gridBagConstraints11.gridwidth = 3;
			gridBagConstraints11.anchor = java.awt.GridBagConstraints.WEST;
			gridBagConstraints11.fill = java.awt.GridBagConstraints.HORIZONTAL;
			gridBagConstraints11.ipadx = 3;
			gridBagConstraints11.ipady = 3;
			gridBagConstraints12.gridx = 0;
			gridBagConstraints12.weighty = 1.0D;
			gridBagConstraints12.gridwidth = 3;
			gridBagConstraints12.gridy = 2;
			gridBagConstraints12.fill = java.awt.GridBagConstraints.BOTH;
			gridBagConstraints12.insets = new java.awt.Insets(2,10,2,10);
			gridBagConstraints12.ipadx = 0;
			gridBagConstraints12.ipady = 1;
			jPanel.add(descLabel, gridBagConstraints11);
			jPanel.add(getJPanel2(), gridBagConstraints12);
			jPanel.add(getJPanel1(), gridBagConstraints6);
		}
		return jPanel;
	}"
"private void applyConnectionParams(final HttpMethod method) throws IOException {
        int timeout = 0;
        // see if a timeout is given for this method
        Object param = method.getParams().getParameter(HttpMethodParams.SO_TIMEOUT);
        if (param == null) {
            // if not, use the default value
            param = this.conn.getParams().getParameter(HttpConnectionParams.SO_TIMEOUT);
        }
        if (param != null) {
            timeout = ((Integer)param).intValue();
        }
        this.conn.setSocketTimeout(timeout);                    
    }"
"private void checkUpdateKeyColumns(Map<String, EventColumn> oldKeyColumns, Map<String, EventColumn> keyColumns) {
        // 在变更前没有主键的情况
        if (oldKeyColumns.size() == 0) {
            return;
        }
        // 变更后的主键数据大于变更前的，不符合
        if (keyColumns.size() > oldKeyColumns.size()) {
            return;
        }
        // 主键没有变更，把所有变更前的主键拷贝到变更后的主键中.
        if (keyColumns.size() == 0) {
            keyColumns.putAll(oldKeyColumns);
            return;
        }

        // 把old中存在而new中不存在的主键拷贝到new中
        if (oldKeyColumns.size() != keyColumns.size()) {
            for (String oldKey : oldKeyColumns.keySet()) {
                if (keyColumns.get(oldKey) == null) {
                    keyColumns.put(oldKey, oldKeyColumns.get(oldKey));
                }
            }
        }
    }"
"private float crossCheckVertical(int startI, int centerJ, int maxCount,
      int originalStateCountTotal) {
    BitMatrix image = this.image;

    int maxI = image.getHeight();
    int[] stateCount = getCrossCheckStateCount();

    // Start counting up from center
    int i = startI;
    while (i >= 0 && image.get(centerJ, i)) {
      stateCount[2]++;
      i--;
    }
    if (i < 0) {
      return Float.NaN;
    }
    while (i >= 0 && !image.get(centerJ, i) && stateCount[1] <= maxCount) {
      stateCount[1]++;
      i--;
    }
    // If already too many modules in this state or ran off the edge:
    if (i < 0 || stateCount[1] > maxCount) {
      return Float.NaN;
    }
    while (i >= 0 && image.get(centerJ, i) && stateCount[0] <= maxCount) {
      stateCount[0]++;
      i--;
    }
    if (stateCount[0] > maxCount) {
      return Float.NaN;
    }

    // Now also count down from center
    i = startI + 1;
    while (i < maxI && image.get(centerJ, i)) {
      stateCount[2]++;
      i++;
    }
    if (i == maxI) {
      return Float.NaN;
    }
    while (i < maxI && !image.get(centerJ, i) && stateCount[3] < maxCount) {
      stateCount[3]++;
      i++;
    }
    if (i == maxI || stateCount[3] >= maxCount) {
      return Float.NaN;
    }
    while (i < maxI && image.get(centerJ, i) && stateCount[4] < maxCount) {
      stateCount[4]++;
      i++;
    }
    if (stateCount[4] >= maxCount) {
      return Float.NaN;
    }

    // If we found a finder-pattern-like section, but its size is more than 40% different than
    // the original, assume it's a false positive
    int stateCountTotal = stateCount[0] + stateCount[1] + stateCount[2] + stateCount[3] +
        stateCount[4];
    if (5 * Math.abs(stateCountTotal - originalStateCountTotal) >= 2 * originalStateCountTotal) {
      return Float.NaN;
    }

    return foundPatternCross(stateCount) ? centerFromEnd(stateCount, i) : Float.NaN;
  }"
"@Override
    public void execute(Client client, Map<String, String> params, QueryAction queryAction, RestChannel channel) throws Exception {
        //zhongshu-comment queryAction的使命结束了，交由SqlElasticRequestBuilder接力，SqlElasticRequestBuilder是es-sql自己定义的一个类，不是es原生api
        SqlElasticRequestBuilder requestBuilder = queryAction.explain();

        //zhongshu-comment 看这行，将QueryAction对象转为es查询对象，这个是重点了，到这步就已经成功将sql字符串转化为es查询请求了
        //zhongshu-comment ActionRequest是es的原生api
        ActionRequest request = requestBuilder.request();

        //zhongshu-comment 应该是分别对应6中QueryAction子类实现
        if (requestBuilder instanceof JoinRequestBuilder) { //zhongshu-comment 对应连接查询：ESJoinQueryAction
            ElasticJoinExecutor executor = ElasticJoinExecutor.createJoinExecutor(client, requestBuilder);
            executor.run();
            executor.sendResponse(channel);
        } else if (requestBuilder instanceof MultiQueryRequestBuilder) { //zhongshu-comment 对应union查询：MultiQueryAction
            ElasticHitsExecutor executor = MultiRequestExecutorFactory.createExecutor(client, (MultiQueryRequestBuilder) requestBuilder);
            executor.run();
            sendDefaultResponse(executor.getHits(), channel);
        } else if (request instanceof SearchRequest) {
            //zhongshu-comment 对应的QueryAction实现子类：DefaultQueryAction、AggregationQueryAction
            //zhongshu-comment 对应的SqlElasticRequestBuilder实现子类：SqlElasticSearchRequestBuilder
            client.search((SearchRequest) request, new RestStatusToXContentListener<>(channel));
        } else if (request instanceof DeleteByQueryRequest) {
            //zhongshu-comment 对应的QueryAction实现子类：DeleteQueryAction
            //zhongshu-comment 对应的SqlElasticRequestBuilder实现子类：SqlElasticDeleteByQueryRequestBuilder
            requestBuilder.getBuilder().execute(new BulkIndexByScrollResponseContentListener(channel, Maps.newHashMap()));
        } else if (request instanceof GetIndexRequest) {
            //zhongshu-comment 对应的QueryAction实现子类：ShowQueryAction
            //zhongshu-comment 对应的SqlElasticRequestBuilder实现子类：是一个匿名内部类，跳进去queryAction.explain()看
            requestBuilder.getBuilder().execute(new GetIndexRequestRestListener(channel, (GetIndexRequest) request));
        } else if (request instanceof SearchScrollRequest) {
            client.searchScroll((SearchScrollRequest) request, new RestStatusToXContentListener<>(channel));
        } else {
            throw new Exception(String.format(""Unsupported ActionRequest provided: %s"", request.getClass().getName()));
        }
    }"
"public <T extends JobProperty> T removeProperty(Class<T> clazz) throws IOException {
        for (JobProperty<? super JobT> p : properties) {
            if (clazz.isInstance(p)) {
                removeProperty(p);
                return clazz.cast(p);
            }
        }
        return null;
    }"
"public final DetectorResult detect(Map<DecodeHintType,?> hints) throws NotFoundException, FormatException {

    resultPointCallback = hints == null ? null :
        (ResultPointCallback) hints.get(DecodeHintType.NEED_RESULT_POINT_CALLBACK);

    FinderPatternFinder finder = new FinderPatternFinder(image, resultPointCallback);
    FinderPatternInfo info = finder.find(hints);

    return processFinderPatternInfo(info);
  }"
"@Override
    public final double[] score0(double[] row, double offset, double[] preds) {
        super.scoreAllTrees(row, preds);
        return unifyPreds(row, offset, preds);
    }"
"public Http2Stream pushStream(int associatedStreamId, List<Header> requestHeaders, boolean out)
      throws IOException {
    if (client) throw new IllegalStateException(""Client cannot push requests."");
    return newStream(associatedStreamId, requestHeaders, out);
  }"
"public Optional<OperatorBackPressureStats> getOperatorBackPressureStats(ExecutionJobVertex vertex) {
		synchronized (lock) {
			final OperatorBackPressureStats stats = operatorStatsCache.getIfPresent(vertex);
			if (stats == null || backPressureStatsRefreshInterval <= System.currentTimeMillis() - stats.getEndTimestamp()) {
				triggerStackTraceSampleInternal(vertex);
			}
			return Optional.ofNullable(stats);
		}
	}"
"private void addAdditionalNamenodesFromConf(final Props props) {
    final String sparkConfDir = getSparkLibConf()[1];
    final File sparkConfFile = new File(sparkConfDir, ""spark-defaults.conf"");
    try {
      final InputStreamReader inReader =
          new InputStreamReader(new FileInputStream(sparkConfFile), StandardCharsets.UTF_8);
      // Use Properties to avoid needing Spark on our classpath
      final Properties sparkProps = new Properties();
      sparkProps.load(inReader);
      inReader.close();
      final String additionalNamenodes =
          sparkProps.getProperty(SPARK_CONF_ADDITIONAL_NAMENODES);
      if (additionalNamenodes != null && additionalNamenodes.length() > 0) {
        getLog().info(""Found property "" + SPARK_CONF_ADDITIONAL_NAMENODES +
            "" = "" + additionalNamenodes + ""; setting additional namenodes"");
        HadoopJobUtils.addAdditionalNamenodesToProps(props, additionalNamenodes);
      }
    } catch (final IOException e) {
      getLog().warn(""Unable to load Spark configuration; not adding any additional "" +
          ""namenode delegation tokens."", e);
    }
  }"
"public static void putServiceTicketInRequestScope(final RequestContext context, final ServiceTicket ticketValue) {
        context.getRequestScope().put(PARAMETER_SERVICE_TICKET_ID, ticketValue.getId());
    }"
"public static <T extends Savepoint> void storeCheckpointMetadata(
			T checkpointMetadata,
			OutputStream out) throws IOException {

		DataOutputStream dos = new DataOutputStream(out);
		storeCheckpointMetadata(checkpointMetadata, dos);
	}"
"@Override
    protected synchronized String issueCrumb(ServletRequest request, String salt) {
        if (request instanceof HttpServletRequest) {
            if (md != null) {
                HttpServletRequest req = (HttpServletRequest) request;
                StringBuilder buffer = new StringBuilder();
                Authentication a = Jenkins.getAuthentication();
                if (a != null) {
                    buffer.append(a.getName());
                }
                buffer.append(';');
                if (!isExcludeClientIPFromCrumb()) {
                    buffer.append(getClientIP(req));
                }

                md.update(buffer.toString().getBytes());
                return Util.toHexString(md.digest(salt.getBytes()));
            }
        }
        return null;
    }"
"public synchronized ScheduledService start() {
        if (started) {
            return this;
        }
        if (scheduledExecutorService == null) {
            scheduledExecutorService = new ScheduledThreadPoolExecutor(1,
                new NamedThreadFactory(threadName, true));
        }
        ScheduledFuture future = null;
        switch (mode) {
            case MODE_FIXEDRATE:
                future = scheduledExecutorService.scheduleAtFixedRate(runnable, initialDelay,
                    period,
                    unit);
                break;
            case MODE_FIXEDDELAY:
                future = scheduledExecutorService.scheduleWithFixedDelay(runnable, initialDelay, period,
                    unit);
                break;
            default:
                break;
        }
        if (future != null) {
            this.future = future;
            // 缓存一下
            SCHEDULED_SERVICE_MAP.put(this, System.currentTimeMillis());
            started = true;
        } else {
            started = false;
        }
        return this;
    }"
"private MethodHandle nullChecker(Class<?> javaType)
    {
        if (javaType == Long.class) {
            return CHECK_LONG_IS_NOT_NULL;
        }
        else if (javaType == Double.class) {
            return CHECK_DOUBLE_IS_NOT_NULL;
        }
        else if (javaType == Boolean.class) {
            return CHECK_BOOLEAN_IS_NOT_NULL;
        }
        else if (javaType == Slice.class) {
            return CHECK_SLICE_IS_NOT_NULL;
        }
        else if (javaType == Block.class) {
            return CHECK_BLOCK_IS_NOT_NULL;
        }
        else {
            throw new IllegalArgumentException(""Unknown java type "" + javaType);
        }
    }"
"public static DataSource createDataSource(final byte[] yamlBytes) throws SQLException, IOException {
        YamlRootShardingConfiguration config = YamlEngine.unmarshal(yamlBytes, YamlRootShardingConfiguration.class);
        return ShardingDataSourceFactory.createDataSource(config.getDataSources(), new ShardingRuleConfigurationYamlSwapper().swap(config.getShardingRule()), config.getProps());
    }"
"public void write_pid(final String node, final int id, final int serial,
            final int creation) {
	write1(OtpExternal.pidTag);
	write_atom(node);
	write4BE(id & 0x7fff); // 15 bits
	write4BE(serial & 0x1fff); // 13 bits
	write1(creation & 0x3); // 2 bits
    }"
"private void createIndexTables(AccumuloTable table)
    {
        // Early-out if table is not indexed
        if (!table.isIndexed()) {
            return;
        }

        // Create index table if it does not exist (for 'external' table)
        if (!tableManager.exists(table.getIndexTableName())) {
            tableManager.createAccumuloTable(table.getIndexTableName());
        }

        // Create index metrics table if it does not exist
        if (!tableManager.exists(table.getMetricsTableName())) {
            tableManager.createAccumuloTable(table.getMetricsTableName());
        }

        // Set locality groups on index and metrics table
        Map<String, Set<Text>> indexGroups = Indexer.getLocalityGroups(table);
        tableManager.setLocalityGroups(table.getIndexTableName(), indexGroups);
        tableManager.setLocalityGroups(table.getMetricsTableName(), indexGroups);

        // Attach iterators to metrics table
        for (IteratorSetting setting : Indexer.getMetricIterators(table)) {
            tableManager.setIterator(table.getMetricsTableName(), setting);
        }
    }"
"public static YarnHighAvailabilityServices forSingleJobAppMaster(
			Configuration flinkConfig,
			org.apache.hadoop.conf.Configuration hadoopConfig) throws IOException {

		checkNotNull(flinkConfig, ""flinkConfig"");
		checkNotNull(hadoopConfig, ""hadoopConfig"");

		final HighAvailabilityMode mode = HighAvailabilityMode.fromConfig(flinkConfig);
		switch (mode) {
			case NONE:
				return new YarnIntraNonHaMasterServices(flinkConfig, hadoopConfig);

			case ZOOKEEPER:
				throw  new UnsupportedOperationException(""to be implemented"");

			default:
				throw new IllegalConfigurationException(""Unrecognized high availability mode: "" + mode);
		}
	}"
"public static String escape(String text) {
        boolean hasQuote = text.indexOf(QUOTE) >= 0;
        boolean hasComma = text.indexOf(COMMA) >= 0;

        if (!(hasQuote || hasComma)) {
            return text;
        }

        StringBuilder builder = new StringBuilder();

        if (hasQuote) {
            for (int i = 0; i < text.length(); i++) {
                char c = text.charAt(i);

                if (c == QUOTE) {
                    builder.append(QUOTE_ESCAPED);
                } else {
                    builder.append(c);
                }
            }
        } else {
            builder.append(text);
        }

        if (hasComma) {
            builder.insert(0, QUOTE);
            builder.append(QUOTE);
        }
        return builder.toString();
    }"
"synchronized void dispose() {
    if (!isDisposed()) {
      // First wait for all data from the connection to be read. Then unregister the handle.
      // Otherwise, unregistering might cause the server to be stopped and all child connections
      // to be closed.
      if (connection != null) {
        try {
          connection.waitForClose();
        } catch (IOException ioe) {
          // no-op.
        }
      }
      server.unregister(this);

      // Set state to LOST if not yet final.
      setState(State.LOST, false);
      this.disposed = true;
    }
  }"
"@Override
	public void start(LeaderRetrievalListener listener) {
		checkNotNull(listener, ""Listener must not be null."");

		synchronized (startStopLock) {
			checkState(!started, ""StandaloneLeaderRetrievalService can only be started once."");
			started = true;

			// directly notify the listener, because we already know the leading JobManager's address
			listener.notifyLeaderAddress(leaderAddress, leaderId);
		}
	}"
"public synchronized void updateNextBuildNumber(int next) throws IOException {
        RunT lb = getLastBuild();
        if (lb!=null ?  next>lb.getNumber() : next>0) {
            this.nextBuildNumber = next;
            saveNextBuildNumber();
        }
    }"
"public String decryptStrFromBcd(String data, KeyType keyType) {
		return decryptStrFromBcd(data, keyType, CharsetUtil.CHARSET_UTF_8);
	}"
"public final void setColumnValue(final String columnName, final Object columnValue) {
        SQLExpression sqlExpression = values[getColumnIndex(columnName)];
        if (sqlExpression instanceof SQLParameterMarkerExpression) {
            parameters[getParameterIndex(sqlExpression)] = columnValue;
        } else {
            SQLExpression columnExpression = String.class == columnValue.getClass() ? new SQLTextExpression(String.valueOf(columnValue)) : new SQLNumberExpression((Number) columnValue);
            values[getColumnIndex(columnName)] = columnExpression;
        }
    }"
"public boolean isDefaultSessionToken(String token) {
		if (getParam().getDefaultTokensEnabled().contains(token.toLowerCase(Locale.ENGLISH)))
			return true;
		return false;
	}"
"protected XmlFile getConfigXml() {
        return new XmlFile(Jenkins.XSTREAM,
                new File(Jenkins.getInstance().getRootDir(),wrapper.getShortName()+"".xml""));
    }"
"public TypeInformation<T> getType() {
		if (type instanceof MissingTypeInfo) {
			MissingTypeInfo typeInfo = (MissingTypeInfo) type;
			throw new InvalidTypesException(""The return type of function '"" + typeInfo.getFunctionName()
					+ ""' could not be determined automatically, due to type erasure. ""
					+ ""You can give type information hints by using the returns(...) method on the result of ""
					+ ""the transformation call, or by letting your function implement the 'ResultTypeQueryable' ""
					+ ""interface."", typeInfo.getTypeException());
		}
		typeUsed = true;
		return this.type;
	}"
"public List<IRequestDumpable> createRequestDumpers(DumpConfig config, HttpServerExchange exchange) {

        RequestDumperFactory factory = new RequestDumperFactory();
        List<IRequestDumpable> dumpers = new ArrayList<>();
        for(String dumperNames: requestDumpers) {
            IRequestDumpable dumper = factory.create(dumperNames, config, exchange);
            dumpers.add(dumper);
        }
        return dumpers;
    }"
"public static String buildCleanedParametersURIRepresentation(org.apache.commons.httpclient.URI uri,
			SpiderParam.HandleParametersOption handleParameters, boolean handleODataParametersVisited) throws URIException {
		// If the option is set to use all the information, just use the default string representation
		if (handleParameters.equals(HandleParametersOption.USE_ALL)) {
			return uri.toString();
		}

		// If the option is set to ignore parameters completely, ignore the query completely
		if (handleParameters.equals(HandleParametersOption.IGNORE_COMPLETELY)) {
			return createBaseUriWithCleanedPath(uri, handleParameters, handleODataParametersVisited);
		}

		// If the option is set to ignore the value, we get the parameters and we only add their name to the
		// query
		if (handleParameters.equals(HandleParametersOption.IGNORE_VALUE)) {
			StringBuilder retVal = new StringBuilder(
					createBaseUriWithCleanedPath(uri, handleParameters, handleODataParametersVisited));
			
			String cleanedQuery = getCleanedQuery(uri.getEscapedQuery());
			
			// Add the parameters' names to the uri representation. 
			if(cleanedQuery.length()>0) {
				retVal.append('?').append(cleanedQuery);
			}

			return retVal.toString();
		}

		// Should not be reached
		return uri.toString();
	}"
"void trimLabels() {
        for (Iterator<Label> itr = labels.values().iterator(); itr.hasNext();) {
            Label l = itr.next();
            resetLabel(l);
            if(l.isEmpty())
                itr.remove();
        }
    }"
"public static XAConnection createXAConnection(final DatabaseType databaseType, final XADataSource xaDataSource, final Connection connection) {
        switch (databaseType) {
            case MySQL:
                return new MySQLXAConnectionWrapper().wrap(xaDataSource, connection);
            case PostgreSQL:
                return new PostgreSQLXAConnectionWrapper().wrap(xaDataSource, connection);
            case H2:
                return new H2XAConnectionWrapper().wrap(xaDataSource, connection);
            default:
                throw new UnsupportedOperationException(String.format(""Cannot support database type: `%s`"", databaseType));
        }
    }"
"private static StringBuilder simpleQuote(final StringBuilder sb, final String value) {
		for (int i = 0; i < value.length(); ++i) {
			final char c = value.charAt(i);
			switch (c) {
				case '\\':
				case '^':
				case '$':
				case '.':
				case '|':
				case '?':
				case '*':
				case '+':
				case '(':
				case ')':
				case '[':
				case '{':
					sb.append('\\');
				default:
					sb.append(c);
			}
		}
		return sb;
	}"
"public static MemorySize getJobManagerHeapMemory(Configuration configuration) {
		if (configuration.containsKey(JobManagerOptions.JOB_MANAGER_HEAP_MEMORY.key())) {
			return MemorySize.parse(configuration.getString(JobManagerOptions.JOB_MANAGER_HEAP_MEMORY));
		} else if (configuration.containsKey(JobManagerOptions.JOB_MANAGER_HEAP_MEMORY_MB.key())) {
			return MemorySize.parse(configuration.getInteger(JobManagerOptions.JOB_MANAGER_HEAP_MEMORY_MB) + ""m"");
		} else {
			//use default value
			return MemorySize.parse(configuration.getString(JobManagerOptions.JOB_MANAGER_HEAP_MEMORY));
		}
	}"
"protected boolean markOffline(Computer c, OfflineCause oc) {
        if(isIgnored() || c.isTemporarilyOffline()) return false; // noop

        c.setTemporarilyOffline(true, oc);

        // notify the admin
        MonitorMarkedNodeOffline no = AdministrativeMonitor.all().get(MonitorMarkedNodeOffline.class);
        if(no!=null)
            no.active = true;
        return true;
    }"
"public ColumnFamilyOptions getColumnOptions() {
		// initial options from pre-defined profile
		ColumnFamilyOptions opt = getPredefinedOptions().createColumnOptions();

		// add user-defined options, if specified
		if (optionsFactory != null) {
			opt = optionsFactory.createColumnOptions(opt);
		}

		return opt;
	}"
"public static Pair<INDArray, INDArray> mergeFeatures(@NonNull INDArray[] featuresToMerge,
                    INDArray[] featureMasksToMerge) {
        Preconditions.checkNotNull(featuresToMerge[0], ""Encountered null feature array when merging"");
        int rankFeatures = featuresToMerge[0].rank();

        switch (rankFeatures) {
            case 2:
                return DataSetUtil.merge2d(featuresToMerge, featureMasksToMerge);
            case 3:
                return DataSetUtil.mergeTimeSeries(featuresToMerge, featureMasksToMerge);
            case 4:
                return DataSetUtil.merge4d(featuresToMerge, featureMasksToMerge);
            default:
                throw new IllegalStateException(""Cannot merge examples: features rank must be in range 2 to 4""
                                + "" inclusive. First example features shape: ""
                                + Arrays.toString(featuresToMerge[0].shape()));
        }
    }"
"private void useRoundRobinLists(
      List<DropEntry> newDropList, List<BackendAddressGroup> newBackendAddrList,
      @Nullable GrpclbClientLoadRecorder loadRecorder) {
    logger.log(
        ChannelLogLevel.INFO, ""Using RR list={0}, drop={1}"", newBackendAddrList, newDropList);
    HashMap<List<EquivalentAddressGroup>, Subchannel> newSubchannelMap =
        new HashMap<>();
    List<BackendEntry> newBackendList = new ArrayList<>();

    switch (mode) {
      case ROUND_ROBIN:
        for (BackendAddressGroup backendAddr : newBackendAddrList) {
          EquivalentAddressGroup eag = backendAddr.getAddresses();
          List<EquivalentAddressGroup> eagAsList = Collections.singletonList(eag);
          Subchannel subchannel = newSubchannelMap.get(eagAsList);
          if (subchannel == null) {
            subchannel = subchannels.get(eagAsList);
            if (subchannel == null) {
              subchannel = subchannelPool.takeOrCreateSubchannel(
                  eag, createSubchannelAttrs(), this);
              subchannel.requestConnection();
            }
            newSubchannelMap.put(eagAsList, subchannel);
          }
          BackendEntry entry;
          // Only picks with tokens are reported to LoadRecorder
          if (backendAddr.getToken() == null) {
            entry = new BackendEntry(subchannel);
          } else {
            entry = new BackendEntry(subchannel, loadRecorder, backendAddr.getToken());
          }
          newBackendList.add(entry);
        }
        // Close Subchannels whose addresses have been delisted
        for (Entry<List<EquivalentAddressGroup>, Subchannel> entry : subchannels.entrySet()) {
          List<EquivalentAddressGroup> eagList = entry.getKey();
          if (!newSubchannelMap.containsKey(eagList)) {
            subchannelPool.returnSubchannel(entry.getValue());
          }
        }
        subchannels = Collections.unmodifiableMap(newSubchannelMap);
        break;
      case PICK_FIRST:
        List<EquivalentAddressGroup> eagList = new ArrayList<>();
        // Because for PICK_FIRST, we create a single Subchannel for all addresses, we have to
        // attach the tokens to the EAG attributes and use TokenAttachingLoadRecorder to put them on
        // headers.
        //
        // The PICK_FIRST code path doesn't cache Subchannels.
        for (BackendAddressGroup bag : newBackendAddrList) {
          EquivalentAddressGroup origEag = bag.getAddresses();
          Attributes eagAttrs = origEag.getAttributes();
          if (bag.getToken() != null) {
            eagAttrs = eagAttrs.toBuilder()
                .set(GrpclbConstants.TOKEN_ATTRIBUTE_KEY, bag.getToken()).build();
          }
          eagList.add(new EquivalentAddressGroup(origEag.getAddresses(), eagAttrs));
        }
        Subchannel subchannel;
        if (subchannels.isEmpty()) {
          subchannel =
              helper.createSubchannel(CreateSubchannelArgs.newBuilder()
                  .setAddresses(eagList)
                  .setAttributes(createSubchannelAttrs())
                  .setStateListener(this)
                  .build());
        } else {
          checkState(subchannels.size() == 1, ""Unexpected Subchannel count: %s"", subchannels);
          subchannel = subchannels.values().iterator().next();
          helper.updateSubchannelAddresses(subchannel, eagList);
        }
        subchannels = Collections.singletonMap(eagList, subchannel);
        newBackendList.add(
            new BackendEntry(subchannel, new TokenAttachingTracerFactory(loadRecorder)));
        break;
      default:
        throw new AssertionError(""Missing case for "" + mode);
    }

    dropList = Collections.unmodifiableList(newDropList);
    backendList = Collections.unmodifiableList(newBackendList);
  }"
"public static <T> RuntimeTypeAdapterFactory<T> of(Class<T> baseType, String typeFieldName, boolean maintainType) {
    return new RuntimeTypeAdapterFactory<T>(baseType, typeFieldName, maintainType);
  }"
"@SneakyThrows
    public static byte[] verifyJwsSignature(final Key signingKey, final byte[] value) {
        val asString = new String(value, StandardCharsets.UTF_8);
        return verifyJwsSignature(signingKey, asString);
    }"
"@Override
  @Deprecated
  public NettyChannelBuilder usePlaintext(boolean skipNegotiation) {
    if (skipNegotiation) {
      negotiationType(NegotiationType.PLAINTEXT);
    } else {
      negotiationType(NegotiationType.PLAINTEXT_UPGRADE);
    }
    return this;
  }"
"public static void removeTemporaryType(int type) {
		Integer typeInteger = type;
		if (DEFAULT_TEMPORARY_HISTORY_TYPES.contains(typeInteger)) {
			return;
		}
		synchronized (TEMPORARY_HISTORY_TYPES) {
			TEMPORARY_HISTORY_TYPES.remove(typeInteger);
		}
	}"
"public static <T> void sortReverse(List<T> list, Comparator<? super T> c) {
		Collections.sort(list, Collections.reverseOrder(c));
	}"
"public static <K,V> Map<K,List<V>> groupByKey(List<Pair<K,V>> listInput) {
        Map<K,List<V>> ret = new HashMap<>();
        for(Pair<K,V> pair : listInput) {
            List<V> currList = ret.get(pair.getFirst());
            if(currList == null) {
                currList = new ArrayList<>();
                ret.put(pair.getFirst(),currList);
            }

            currList.add(pair.getSecond());
        }

        return ret;
    }"
"public static void zipExtractSingleFile(File zipFile, File destination, String pathInZip) throws IOException {
        try (ZipFile zf = new ZipFile(zipFile); InputStream is = new BufferedInputStream(zf.getInputStream(zf.getEntry(pathInZip)));
             OutputStream os = new BufferedOutputStream(new FileOutputStream(destination))) {
            IOUtils.copy(is, os);
        }
    }"
"protected static boolean locateMatchingCredentialType(final Authentication authentication, final String credentialClassType) {
        return StringUtils.isNotBlank(credentialClassType) && authentication.getCredentials()
            .stream()
            .anyMatch(e -> e.getCredentialClass().getName().matches(credentialClassType));
    }"
"public static File zip(File zipFile, Charset charset, boolean withSrcDir, File... srcFiles) throws UtilException {
		validateFiles(zipFile, srcFiles);

		try (ZipOutputStream out = getZipOutputStream(zipFile, charset)) {
			String srcRootDir;
			for (File srcFile : srcFiles) {
				if(null == srcFile) {
					continue;
				}
				// 如果只是压缩一个文件，则需要截取该文件的父目录
				srcRootDir = srcFile.getCanonicalPath();
				if (srcFile.isFile() || withSrcDir) {
					//若是文件，则将父目录完整路径都截取掉；若设置包含目录，则将上级目录全部截取掉，保留本目录名
					srcRootDir = srcFile.getCanonicalFile().getParentFile().getCanonicalPath();
				}
				// 调用递归压缩方法进行目录或文件压缩
				zip(srcFile, srcRootDir, out);
				out.flush();
			}
		} catch (IOException e) {
			throw new UtilException(e);
		}
		return zipFile;
	}"
"@GetMapping(""/sp/{client}/metadata"")
    public ResponseEntity<String> getServiceProviderMetadataByName(@PathVariable(""client"") final String client) {
        val saml2Client = (SAML2Client) builtClients.findClient(client);
        if (saml2Client != null) {
            return getSaml2ClientServiceProviderMetadataResponseEntity(saml2Client);
        }
        return getNotAcceptableResponseEntity();
    }"
"public void setlocFreq(int[][] ints) {
        for (int i = 0; i < ints.length; i++) {
            if (ints[i][0] > 0) {
                flag = true;
                break;
            }
        }
        locFreq = ints;
    }"
"static long[/*nsplits*/][/*nchunks*/] computeEspcPerSplit(long[] espc, long len, double[] ratios) {
    assert espc.length>0 && espc[0] == 0;
    assert espc[espc.length-1] == len;
    long[] partSizes = partitione(len, ratios); // Split of whole vector
    int nparts = ratios.length+1;
    long[][] r = new long[nparts][espc.length]; // espc for each partition
    long nrows = 0;
    long start = 0;
    for (int p=0,c=0; p<nparts; p++) {
      int nc = 0; // number of chunks for this partition
      for(;c<espc.length-1 && (espc[c+1]-start) <= partSizes[p];c++) r[p][++nc] = espc[c+1]-start;
      if (r[p][nc] < partSizes[p]) r[p][++nc] = partSizes[p]; // last item in espc contains number of rows
      r[p] = Arrays.copyOf(r[p], nc+1);
      // Transfer rest of lines to the next part
      nrows = nrows-partSizes[p];
      start += partSizes[p];
    }
    return r;
  }"
"public static String findMainClass(JarFile jarFile, String classesLocation)
			throws IOException {
		return doWithMainClasses(jarFile, classesLocation, MainClass::getName);
	}"
"@CheckReturnValue
    public static <T> T spy(T object) {
        return MOCKITO_CORE.mock((Class<T>) object.getClass(), withSettings()
                .spiedInstance(object)
                .defaultAnswer(CALLS_REAL_METHODS));
    }"
"static Frame uniqueValuesBy(Frame fr, int columnIndex) {
    Vec vec0 = fr.vec(columnIndex);
    Vec v;
    if (vec0.isCategorical()) {
      v = Vec.makeSeq(0, (long) vec0.domain().length, true);
      v.setDomain(vec0.domain());
      DKV.put(v);
    } else {
      UniqTask t = new UniqTask().doAll(vec0);
      int nUniq = t._uniq.size();
      final AstGroup.G[] uniq = t._uniq.keySet().toArray(new AstGroup.G[nUniq]);
      v = Vec.makeZero(nUniq, vec0.get_type());
      new MRTask() {
        @Override
        public void map(Chunk c) {
          int start = (int) c.start();
          for (int i = 0; i < c._len; ++i) c.set(i, uniq[i + start]._gs[0]);
        }
      }.doAll(v);
    }
    return new Frame(v);
  }"
"public static void main(String[] args) throws Exception {

		final ParameterTool params = ParameterTool.fromArgs(args);

		// set up the execution environment
		final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();

		// make parameters available in the web interface
		env.getConfig().setGlobalJobParameters(params);

		// get input data
		DataSet<String> text;
		if (params.has(""input"")) {
			// read the text file from given input path
			text = env.readTextFile(params.get(""input""));
		} else {
			// get default test text data
			System.out.println(""Executing WordCount example with default input data set."");
			System.out.println(""Use --input to specify file input."");
			text = WordCountData.getDefaultTextLineDataSet(env);
		}

		DataSet<Tuple2<String, Integer>> counts =
				// split up the lines in pairs (2-tuples) containing: (word,1)
				text.flatMap(new Tokenizer())
				// group by the tuple field ""0"" and sum up tuple field ""1""
				.groupBy(0)
				.sum(1);

		// emit result
		if (params.has(""output"")) {
			counts.writeAsCsv(params.get(""output""), ""\n"", "" "");
			// execute program
			env.execute(""WordCount Example"");
		} else {
			System.out.println(""Printing result to stdout. Use --output to specify output path."");
			counts.print();
		}

	}"
"public List<AbstractPanel> getPanels(PanelType panelType) {
		validateNotNull(panelType, ""panelType"");

		List<AbstractPanel> panels = new ArrayList<>();
		switch (panelType) {
		case SELECT:
			panels.addAll(getTabbedSelect().getPanels());
			break;
		case STATUS:
			panels.addAll(getTabbedStatus().getPanels());
			break;
		case WORK:
			panels.addAll(getTabbedWork().getPanels());
			break;
		default:
			break;
		}
		return panels;
	}"
"public static long getOffsetUnsafe(DataBuffer shapeInformation, int dim0, int dim1, int dim2) {
        long offset = 0;
        int size_0 = sizeUnsafe(shapeInformation, 0);
        int size_1 = sizeUnsafe(shapeInformation, 1);
        int size_2 = sizeUnsafe(shapeInformation, 2);
        if (dim0 >= size_0 || dim1 >= size_1 || dim2 >= size_2)
            throw new IllegalArgumentException(""Invalid indices: cannot get ["" + dim0 + "","" + dim1 + "","" + dim2
                    + ""] from a "" + Arrays.toString(shape(shapeInformation)) + "" NDArray"");

        if (size_0 != 1)
            offset += dim0 * strideUnsafe(shapeInformation, 0, 3);
        if (size_1 != 1)
            offset += dim1 * strideUnsafe(shapeInformation, 1, 3);
        if (size_2 != 1)
            offset += dim2 * strideUnsafe(shapeInformation, 2, 3);

        return offset;
    }"
"public static String readString(URL url, String charset) throws IORuntimeException {
		if (url == null) {
			throw new NullPointerException(""Empty url provided!"");
		}

		InputStream in = null;
		try {
			in = url.openStream();
			return IoUtil.read(in, charset);
		} catch (IOException e) {
			throw new IORuntimeException(e);
		} finally {
			IoUtil.close(in);
		}
	}"
"StringBuilder printLine(StringBuilder sb ) {
      if( _pid== NO_PARENT) return sb.append(""[root]"");
      DecidedNode parent = _tree.decided(_pid);
      parent.printLine(sb).append("" to "");
      return parent.printChild(sb,_nid);
    }"
"public static void writeString(DataOutput out, String s) throws IOException {
        if (s != null) {
            byte[] buffer = s.getBytes(""UTF-8"");
            int len = buffer.length;
            out.writeInt(len);
            out.write(buffer, 0, len);
        } else {
            out.writeInt(-1);
        }
    }"
"public final boolean isResolved() {
		return getPathParameters().stream().filter(MessageParameter::isMandatory).allMatch(MessageParameter::isResolved)
			&& getQueryParameters().stream().filter(MessageParameter::isMandatory).allMatch(MessageParameter::isResolved);
	}"
"@Override
    public void memcpy(DataBuffer dstBuffer, DataBuffer srcBuffer) {
        CudaContext context = (CudaContext) AtomicAllocator.getInstance().getDeviceContext().getContext();

        if (dstBuffer instanceof CompressedDataBuffer && !(srcBuffer instanceof CompressedDataBuffer)) {
            // destination is compressed, source isn't
            AllocationPoint srcPoint = AtomicAllocator.getInstance().getAllocationPoint(srcBuffer);
            long size = srcBuffer.getElementSize() * srcBuffer.length();
            if (!srcPoint.isActualOnHostSide()) {
                // copying device -> host

                AtomicAllocator.getInstance().synchronizeHostData(srcBuffer);

                // Pointer src = AtomicAllocator.getInstance().getPointer(srcBuffer, context);

                // NativeOpsHolder.getInstance().getDeviceNativeOps().memcpyAsync(dstBuffer.addressPointer(), src, size, 2, context.getSpecialStream());
                // context.syncSpecialStream();

            } // else {
              // copying host -> host
            Pointer src = AtomicAllocator.getInstance().getHostPointer(srcBuffer);

            Pointer.memcpy(dstBuffer.addressPointer(), src, size);
            // }

        } else if (!(dstBuffer instanceof CompressedDataBuffer) && srcBuffer instanceof CompressedDataBuffer) {
            // destination is NOT compressed, source is compressed
            AllocationPoint dstPoint = AtomicAllocator.getInstance().getAllocationPoint(dstBuffer);
            long size = srcBuffer.getElementSize() * srcBuffer.length();

            Pointer.memcpy(dstBuffer.addressPointer(), srcBuffer.addressPointer(), size);
            dstPoint.tickHostWrite();

        } else if (dstBuffer instanceof CompressedDataBuffer && srcBuffer instanceof CompressedDataBuffer) {
            // both buffers are compressed, just fire memcpy


            Pointer.memcpy(dstBuffer.addressPointer(), srcBuffer.addressPointer(),
                            srcBuffer.length() * srcBuffer.getElementSize());
        } else {
            // both buffers are NOT compressed
            AtomicAllocator.getInstance().memcpy(dstBuffer, srcBuffer);
        }
    }"
"public static OutputStreamAndPath createEntropyAware(
			FileSystem fs,
			Path path,
			WriteMode writeMode) throws IOException {

		// check and possibly inject entropy into the path
		final EntropyInjectingFileSystem efs = getEntropyFs(fs);
		final Path processedPath = efs == null ? path : resolveEntropy(path, efs, true);

		// create the stream on the original file system to let the safety net
		// take its effect
		final FSDataOutputStream out = fs.create(processedPath, writeMode);
		return new OutputStreamAndPath(out, processedPath);
	}"
"private static Filter<InstanceField> nullField() {
        return new Filter<InstanceField>() {
            public boolean isOut(InstanceField instanceField) {
                return instanceField.isNull();
            }
        };
    }"
"private ModelMetrics makeModelMetrics(SharedTreeModel model, Frame fr, Frame adaptedFr, Frame preds) {
    ModelMetrics mm;
    if (model._output.nclasses() == 2 && _computeGainsLift) {
      assert preds != null : ""Predictions were pre-created"";
      mm = _mb.makeModelMetrics(model, fr, adaptedFr, preds);
    } else {
      boolean calculatePreds = preds == null && model._parms._distribution == DistributionFamily.huber;
      // FIXME: PUBDEV-4992 we should avoid doing full scoring!
      if (calculatePreds) {
        Log.warn(""Going to calculate predictions from scratch. This can be expensive for large models! See PUBDEV-4992"");
        preds = model.score(fr);
      }
      mm = _mb.makeModelMetrics(model, fr, null, preds);
      if (calculatePreds && (preds != null))
        preds.remove();
    }
    return mm;
  }"
"public byte[] toBytes() throws IOException {
        ByteArrayOutputStream out = new ByteArrayOutputStream();
        // 0. write command number
        out.write(getCommand());
        // 1. write 4 bytes bin-log position to start at
        ByteHelper.writeUnsignedIntLittleEndian(binlogPosition, out);
        // 2. write 2 bytes bin-log flags
        int binlog_flags = 0;
        binlog_flags |= BINLOG_SEND_ANNOTATE_ROWS_EVENT;
        out.write(binlog_flags);
        out.write(0x00);
        // 3. write 4 bytes server id of the slave
        ByteHelper.writeUnsignedIntLittleEndian(this.slaveServerId, out);
        // 4. write bin-log file name if necessary
        if (StringUtils.isNotEmpty(this.binlogFileName)) {
            out.write(this.binlogFileName.getBytes());
        }
        return out.toByteArray();
    }"
"public static MetricQueryService createMetricQueryService(
		RpcService rpcService,
		ResourceID resourceID,
		long maximumFrameSize) {

		String endpointId = resourceID == null
			? METRIC_QUERY_SERVICE_NAME
			: METRIC_QUERY_SERVICE_NAME + ""_"" + resourceID.getResourceIdString();

		return new MetricQueryService(rpcService, endpointId, maximumFrameSize);
	}"
"public static Class<? extends Servlet> createServlet(String className) {
    try {
      return Class.forName(className).asSubclass(Servlet.class);
    } catch (ClassNotFoundException e) {
      log.warning(""The specified class : "" + className + "" cannot be instantiated "" +
          e.getMessage());
    }
    return null;
  }"
"public static void pressImage(Image srcImage, File outFile, Image pressImg, int x, int y, float alpha) throws IORuntimeException {
		write(pressImage(srcImage, pressImg, x, y, alpha), outFile);
	}"
"public <R> SingleOutputStreamOperator<R> apply(AllWindowFunction<T, R, W> function) {
		String callLocation = Utils.getCallLocationName();
		function = input.getExecutionEnvironment().clean(function);
		TypeInformation<R> resultType = getAllWindowFunctionReturnType(function, getInputType());
		return apply(new InternalIterableAllWindowFunction<>(function), resultType, callLocation);
	}"
"private static <T> boolean newPojoSerializerIsCompatibleAfterMigration(
			PojoSerializer<T> newPojoSerializer,
			IntermediateCompatibilityResult<T> fieldSerializerCompatibility,
			IntermediateCompatibilityResult<T> preExistingRegistrationsCompatibility,
			LinkedOptionalMap<Field, TypeSerializerSnapshot<?>> fieldSerializerSnapshots) {
		return newPojoHasNewOrRemovedFields(fieldSerializerSnapshots, newPojoSerializer)
			|| fieldSerializerCompatibility.isCompatibleAfterMigration()
			|| preExistingRegistrationsCompatibility.isCompatibleAfterMigration();
	}"
"public String remove(String group, Object key) {
		return this.groupedMap.remove(group, Convert.toStr(key));
	}"
"public TableMetaTSDB build(String destination, String springXml) {
        return TableMetaTSDBBuilder.build(destination, springXml);
    }"
"public <E> void addComboField(int tabIndex, String fieldLabel, ComboBoxModel<E> comboBoxModel, boolean editable) {
		validateTabbed(tabIndex);
		JComboBox<E> field = new JComboBox<>(comboBoxModel);
		field.setEditable(editable);
		this.addField(this.tabPanels.get(tabIndex), this.tabOffsets.get(tabIndex), fieldLabel, field, field, 0.0D);
		this.incTabOffset(tabIndex);
	}"
"public Evaluation evaluate(DataSetIterator iterator, List<String> labelsList, int topN) {
        if (layers == null || !(getOutputLayer() instanceof IOutputLayer)) {
            throw new IllegalStateException(""Cannot evaluate network with no output layer"");
        }
        if (labelsList == null) {
            try {
                labelsList = iterator.getLabels();
            } catch (Throwable t){ }    //Ignore, maybe UnsupportedOperationException etc
        }

        Layer outputLayer = getOutputLayer();
        if(getLayerWiseConfigurations().isValidateOutputLayerConfig()){
            OutputLayerUtil.validateOutputLayerForClassifierEvaluation(outputLayer.conf().getLayer(), Evaluation.class);
        }

        Evaluation e = new org.deeplearning4j.eval.Evaluation(labelsList, topN);
        doEvaluation(iterator, e);

        return e;
    }"
"public static Set<Policy> policies(Config config) {
    LruWindowTinyLfuSettings settings = new LruWindowTinyLfuSettings(config);
    return settings.percentMain().stream()
        .map(percentMain -> new LruWindowTinyLfuPolicy(percentMain, settings))
        .collect(toSet());
  }"
"public List<AbstractPanel> getPanels() {
        List<AbstractPanel> panels = new ArrayList<>();
        for (Component component : fullTabList) {
            if (component instanceof AbstractPanel) {
                panels.add((AbstractPanel) component);
            }
        }
        return panels;
    }"
"public static List<ParameterSpace> getUniqueObjects(List<ParameterSpace> allLeaves) {
        List<ParameterSpace> unique = new ArrayList<>();
        for (ParameterSpace p : allLeaves) {
            //This isn't especially efficient, but small number of parameters in general means it's fine
            boolean found = false;
            for (ParameterSpace q : unique) {
                if (p == q) {
                    found = true;
                }
            }
            if (!found) {
                unique.add(p);
            }
        }

        return unique;
    }"
"private static @Nullable
    User getOrCreateById(@Nonnull String id, @Nonnull String fullName, boolean create) {
        User u = AllUsers.get(id);
        if (u == null && (create || UserIdMapper.getInstance().isMapped(id))) {
            u = new User(id, fullName);
            AllUsers.put(id, u);
            if (!id.equals(fullName) && !UserIdMapper.getInstance().isMapped(id)) {
                try {
                    u.save();
                } catch (IOException x) {
                    LOGGER.log(Level.WARNING, ""Failed to save user configuration for "" + id, x);
                }
            }
        }
        return u;
    }"
"public Object nextMeta() throws JSONException {
		char c;
		char q;
		do {
			c = next();
		} while (Character.isWhitespace(c));
		switch (c) {
			case 0:
				throw syntaxError(""Misshaped meta tag"");
			case '<':
				return XML.LT;
			case '>':
				return XML.GT;
			case '/':
				return XML.SLASH;
			case '=':
				return XML.EQ;
			case '!':
				return XML.BANG;
			case '?':
				return XML.QUEST;
			case '""':
			case '\'':
				q = c;
				for (;;) {
					c = next();
					if (c == 0) {
						throw syntaxError(""Unterminated string"");
					}
					if (c == q) {
						return Boolean.TRUE;
					}
				}
			default:
				for (;;) {
					c = next();
					if (Character.isWhitespace(c)) {
						return Boolean.TRUE;
					}
					switch (c) {
						case 0:
						case '<':
						case '>':
						case '/':
						case '=':
						case '!':
						case '?':
						case '""':
						case '\'':
							back();
							return Boolean.TRUE;
					}
				}
		}
	}"
"private boolean notifyListenerRequestSend(HttpMessage httpMessage) {
		ProxyListener listener = null;
		List<ProxyListener> listenerList = parentServer.getListenerList();
		for (int i=0;i<listenerList.size();i++) {
			listener = listenerList.get(i);
			try {
			    if (! listener.onHttpRequestSend(httpMessage)) {
			    	return false;
			    }
			} catch (Exception e) {
				log.error(""An error occurred while notifying listener:"", e);
			}
		}
		return true;
	}"
"private float calculateModuleSizeOneWay(ResultPoint pattern, ResultPoint otherPattern) {
    float moduleSizeEst1 = sizeOfBlackWhiteBlackRunBothWays((int) pattern.getX(),
        (int) pattern.getY(),
        (int) otherPattern.getX(),
        (int) otherPattern.getY());
    float moduleSizeEst2 = sizeOfBlackWhiteBlackRunBothWays((int) otherPattern.getX(),
        (int) otherPattern.getY(),
        (int) pattern.getX(),
        (int) pattern.getY());
    if (Float.isNaN(moduleSizeEst1)) {
      return moduleSizeEst2 / 7.0f;
    }
    if (Float.isNaN(moduleSizeEst2)) {
      return moduleSizeEst1 / 7.0f;
    }
    // Average them, and divide by 7 since we've counted the width of 3 black modules,
    // and 1 white and 1 black module on either side. Ergo, divide sum by 14.
    return (moduleSizeEst1 + moduleSizeEst2) / 14.0f;
  }"
"@Nullable
	private static EntropyInjectingFileSystem getEntropyFs(FileSystem fs) {
		if (fs instanceof EntropyInjectingFileSystem) {
			return (EntropyInjectingFileSystem) fs;
		}
		else if (fs instanceof SafetyNetWrapperFileSystem) {
			FileSystem delegate = ((SafetyNetWrapperFileSystem) fs).getWrappedDelegate();
			if (delegate instanceof EntropyInjectingFileSystem) {
				return (EntropyInjectingFileSystem) delegate;
			}
			else {
				return null;
			}
		}
		else {
			return null;
		}
	}"
"public static BigDecimal round(BigDecimal number, int scale) {
		return round(number, scale, RoundingMode.HALF_UP);
	}"
"public String runHTMLSuite(
    String browser,
    String startURL,
    String suiteURL,
    File outputFile,
    long timeoutInSeconds,
    String userExtensions) throws IOException {
    File parent = outputFile.getParentFile();
    if (parent != null && !parent.exists()) {
      parent.mkdirs();
    }
    if (outputFile.exists() && !outputFile.canWrite()) {
      throw new IOException(""Can't write to outputFile: "" + outputFile.getAbsolutePath());
    }
    long timeoutInMs = 1000L * timeoutInSeconds;
    if (timeoutInMs < 0) {
      log.warning(""Looks like the timeout overflowed, so resetting it to the maximum."");
      timeoutInMs = Long.MAX_VALUE;
    }

    WebDriver driver = null;
    try {
      driver = createDriver(browser);
      URL suiteUrl = determineSuiteUrl(startURL, suiteURL);

      driver.get(suiteUrl.toString());
      Selenium selenium = new WebDriverBackedSelenium(driver, startURL);
      selenium.setTimeout(String.valueOf(timeoutInMs));
      if (userExtensions != null) {
        selenium.setExtensionJs(userExtensions);
      }
      List<WebElement> allTables = driver.findElements(By.id(""suiteTable""));
      if (allTables.isEmpty()) {
        throw new RuntimeException(""Unable to find suite table: "" + driver.getPageSource());
      }
      Results results = new CoreTestSuite(suiteUrl.toString()).run(driver, selenium, new URL(startURL));

      HTMLTestResults htmlResults = results.toSuiteResult();
      try (Writer writer = Files.newBufferedWriter(outputFile.toPath())) {
        htmlResults.write(writer);
      }

      return results.isSuccessful() ? ""PASSED"" : ""FAILED"";
    } finally {
      if (server != null) {
        try {
          server.stop();
        } catch (Exception e) {
          // Nothing sane to do. Log the error and carry on
          log.log(Level.INFO, ""Exception shutting down server. You may ignore this."", e);
        }
      }

      if (driver != null) {
        driver.quit();
      }
    }
  }"
"public DatabaseAccessConfiguration swap(final DataSource dataSource) {
        DataSourcePropertyProvider provider = DataSourcePropertyProviderLoader.getProvider(dataSource);
        try {
            String url = (String) findGetterMethod(dataSource, provider.getURLPropertyName()).invoke(dataSource);
            String username = (String) findGetterMethod(dataSource, provider.getUsernamePropertyName()).invoke(dataSource);
            String password = (String) findGetterMethod(dataSource, provider.getPasswordPropertyName()).invoke(dataSource);
            return new DatabaseAccessConfiguration(url, username, password);
        } catch (final ReflectiveOperationException ex) {
            throw new ShardingException(""Cannot swap data source type: `%s`, please provide an implementation from SPI `%s`"", 
                    dataSource.getClass().getName(), DataSourcePropertyProvider.class.getName());
        }
    }"
"public void suspend(Throwable suspensionCause) {

		assertRunningInJobMasterMainThread();

		if (state.isTerminalState()) {
			// stay in a terminal state
			return;
		} else if (transitionState(state, JobStatus.SUSPENDED, suspensionCause)) {
			initFailureCause(suspensionCause);

			// make sure no concurrent local actions interfere with the cancellation
			incrementGlobalModVersion();

			// cancel ongoing scheduling action
			if (schedulingFuture != null) {
				schedulingFuture.cancel(false);
			}
			final ArrayList<CompletableFuture<Void>> executionJobVertexTerminationFutures = new ArrayList<>(verticesInCreationOrder.size());

			for (ExecutionJobVertex ejv: verticesInCreationOrder) {
				executionJobVertexTerminationFutures.add(ejv.suspend());
			}

			final ConjunctFuture<Void> jobVerticesTerminationFuture = FutureUtils.waitForAll(executionJobVertexTerminationFutures);

			checkState(jobVerticesTerminationFuture.isDone(), ""Suspend needs to happen atomically"");

			jobVerticesTerminationFuture.whenComplete(
				(Void ignored, Throwable throwable) -> {
					if (throwable != null) {
						LOG.debug(""Could not properly suspend the execution graph."", throwable);
					}

					onTerminalState(state);
					LOG.info(""Job {} has been suspended."", getJobID());
				});
		} else {
			throw new IllegalStateException(String.format(""Could not suspend because transition from %s to %s failed."", state, JobStatus.SUSPENDED));
		}
	}"
"@SuppressWarnings({""cast"", ""unchecked""})
    public static <A, B> Weigher<? super Map<A, B>> map() {
        return MapWeigher.INSTANCE;
    }"
"@NonNull
  public Caffeine<K, V> recordStats() {
    requireState(this.statsCounterSupplier == null, ""Statistics recording was already set"");
    statsCounterSupplier = ENABLED_STATS_COUNTER_SUPPLIER;
    return this;
  }"
"protected static void validateSameType(String opName, boolean numericalOnly, SDVariable... vars) {
        if (vars.length == 0)
            return;
        if (vars.length == 1) {
            if (numericalOnly) {
                validateNumerical(opName, vars[0]);
            }
        } else {
            DataType first = vars[0].dataType();
            if (numericalOnly)
                validateNumerical(opName, vars[0]);
            for (int i = 1; i < vars.length; i++) {
                if (first != vars[i].dataType()) {
                    String[] names = new String[vars.length];
                    DataType[] dtypes = new DataType[vars.length];
                    for (int j = 0; j < vars.length; j++) {
                        names[j] = vars[j].getVarName();
                        dtypes[j] = vars[j].dataType();
                    }
                    throw new IllegalStateException(""Cannot perform operation \"""" + opName + ""\"" to variables with different datatypes:"" +
                            "" Variable names "" + Arrays.toString(names) + "", datatypes "" + Arrays.toString(dtypes));
                }
            }
        }
    }"
"private Set<DataSegment> refreshSegmentsForDataSource(final String dataSource, final Set<DataSegment> segments)
      throws IOException
  {
    log.debug(""Refreshing metadata for dataSource[%s]."", dataSource);

    final long startTime = System.currentTimeMillis();

    // Segment id -> segment object.
    final Map<String, DataSegment> segmentMap = Maps.uniqueIndex(segments, segment -> segment.getId().toString());

    final Set<DataSegment> retVal = new HashSet<>();
    final Sequence<SegmentAnalysis> sequence = runSegmentMetadataQuery(
        queryLifecycleFactory,
        Iterables.limit(segments, MAX_SEGMENTS_PER_QUERY),
        escalator.createEscalatedAuthenticationResult()
    );

    Yielder<SegmentAnalysis> yielder = Yielders.each(sequence);

    try {
      while (!yielder.isDone()) {
        final SegmentAnalysis analysis = yielder.get();
        final DataSegment segment = segmentMap.get(analysis.getId());

        if (segment == null) {
          log.warn(""Got analysis for segment[%s] we didn't ask for, ignoring."", analysis.getId());
        } else {
          synchronized (lock) {
            final RowSignature rowSignature = analysisToRowSignature(analysis);
            log.debug(""Segment[%s] has signature[%s]."", segment.getId(), rowSignature);
            final Map<DataSegment, AvailableSegmentMetadata> dataSourceSegments =
                segmentMetadataInfo.get(segment.getDataSource());
            if (dataSourceSegments == null) {
              log.warn(""No segment map found with datasource[%s], skipping refresh"", segment.getDataSource());
            } else {
              final AvailableSegmentMetadata segmentMetadata = dataSourceSegments.get(segment);
              if (segmentMetadata == null) {
                log.warn(
                    ""No segment[%s] found, skipping refresh"",
                    segment.getId()
                );
              } else {
                final AvailableSegmentMetadata updatedSegmentMetadata = AvailableSegmentMetadata
                    .from(segmentMetadata)
                    .withRowSignature(rowSignature)
                    .withNumRows(analysis.getNumRows())
                    .build();
                dataSourceSegments.put(segment, updatedSegmentMetadata);
                setAvailableSegmentMetadata(segment, updatedSegmentMetadata);
                retVal.add(segment);
              }
            }
          }
        }

        yielder = yielder.next(null);
      }
    }
    finally {
      yielder.close();
    }

    log.info(
        ""Refreshed metadata for dataSource[%s] in %,d ms (%d segments queried, %d segments left)."",
        dataSource,
        System.currentTimeMillis() - startTime,
        retVal.size(),
        segments.size() - retVal.size()
    );

    return retVal;
  }"
"public static int bkdrHash(String str) {
		int seed = 131; // 31 131 1313 13131 131313 etc..
		int hash = 0;

		for (int i = 0; i < str.length(); i++) {
			hash = (hash * seed) + str.charAt(i);
		}

		return hash & 0x7FFFFFFF;
	}"
"@PublicEvolving
	public SingleOutputStreamOperator<T> forceNonParallel() {
		transformation.setParallelism(1);
		transformation.setMaxParallelism(1);
		nonParallel = true;
		return this;
	}"
"public List<T> values(final int state)
   {
      final List<T> list = sharedList.stream().filter(e -> e.getState() == state).collect(Collectors.toList());
      Collections.reverse(list);
      return list;
   }"
"private void setResponseHeader(final RequestContext context) {
        val credential = WebUtils.getCredential(context);

        if (credential == null) {
            LOGGER.debug(""No credential was provided. No response header set."");
            return;
        }

        val response = WebUtils.getHttpServletResponseFromExternalWebflowContext(context);
        val spnegoCredentials = (SpnegoCredential) credential;
        val nextToken = spnegoCredentials.getNextToken();
        if (nextToken != null) {
            LOGGER.debug(""Obtained output token: [{}]"", new String(nextToken, Charset.defaultCharset()));
            response.setHeader(SpnegoConstants.HEADER_AUTHENTICATE, (this.ntlm
                ? SpnegoConstants.NTLM : SpnegoConstants.NEGOTIATE)
                + ' ' + EncodingUtils.encodeBase64(nextToken));
        } else {
            LOGGER.debug(""Unable to obtain the output token required."");
        }

        if (spnegoCredentials.getPrincipal() == null && this.send401OnAuthenticationFailure) {
            LOGGER.debug(""Setting HTTP Status to 401"");
            response.setStatus(HttpServletResponse.SC_UNAUTHORIZED);
        }
    }"
"protected void addToExecInputs(boolean isConstOrPh, VarId inputVar, VarId forVariable) {
        if (!subgraph.contains(forVariable.getVariable()))
            return;     //Not needed to calculate requested outputs, so no need to record it's inputs

        if (isConstOrPh) {
            //Mark that outVar needs to use placeholder/constant (same regardless of frame/iter)
            if (!execConstInputs.containsKey(forVariable.getVariable()))
                execConstInputs.put(forVariable.getVariable(), new HashSet<String>());
            execConstInputs.get(forVariable.getVariable()).add(inputVar.getVariable());
        } else {
            //Mark that outVar needs this specific executedVar (i.e., specific frame/iteration)
            //However, in the case of enter nodes, they are available for ALL iterations (used in loop conditions, for example)
            Variable v = sameDiff.getVariables().get(inputVar.getVariable());
            boolean isEnter = sameDiff.getVariableOutputFunction(v.getVariable().getVarName()) instanceof Enter;

            if(isEnter){
                VarId iter0 = forVariable;
                if(iter0.getIteration() != 0){
                    iter0 = newVarId(iter0.getVariable(), iter0.getFrame(), 0, forVariable.getParentFrame());
                }

                Variable var = sameDiff.getVariables().get(inputVar.getVariable());
                Enter e = (Enter) sameDiff.getOps().get(var.getOutputOfOp()).getOp();
                if(e.isConstant()){
                    //For enter nodes that are constants, we want iteration 0 in all frames in the heirarchy
                    //For example, const -> Enter(a) -> Enter(b) -> op; in this case, the input to Op (at any frame/iteration) should should
                    // be the constant value - which is recorded as (frame=""a"",iter=0,parent=(frame=""b"",iter=0))
                    iter0.setParentFrame(iter0.getParentFrame().clone());
                    FrameIter toZero = iter0.getParentFrame();
                    while(toZero != null){
                        toZero.setIteration(0);
                        toZero = toZero.getParentFrame();
                    }
                }

                if(!execInputsAllIter.containsKey(iter0))
                    execInputsAllIter.put(iter0, new HashSet<VarId>());
                execInputsAllIter.get(iter0).add(inputVar);
            } else {
                //Most variables
                if (!execInputs.containsKey(forVariable))
                    execInputs.put(forVariable, new HashSet<VarId>());
                execInputs.get(forVariable).add(inputVar);
            }
        }
    }"
"public void elementChanged(E element) {
		int idx = getIndexOf(element);
		if (idx < 0) {
			return;
		}
		super.fireContentsChanged(this, idx, idx);
	}"
"@Override
	public void clear() {
		try {
			backend.db.delete(columnFamily, writeOptions, serializeCurrentKeyWithGroupAndNamespace());
		} catch (RocksDBException e) {
			throw new FlinkRuntimeException(""Error while removing entry from RocksDB"", e);
		}
	}"
"public static void write(OutputStream out, Charset charset, boolean isCloseOut, Object... contents) throws IORuntimeException {
		OutputStreamWriter osw = null;
		try {
			osw = getWriter(out, charset);
			for (Object content : contents) {
				if (content != null) {
					osw.write(Convert.toStr(content, StrUtil.EMPTY));
					osw.flush();
				}
			}
		} catch (IOException e) {
			throw new IORuntimeException(e);
		} finally {
			if (isCloseOut) {
				close(osw);
			}
		}
	}"
"public static String dirname(String path)
    {
        int index = path.lastIndexOf('/');
        if (index == -1) return path;
        return path.substring(0, index + 1);
    }"
"public void format(PatriciaTrie<V> trie, File file) throws FileNotFoundException {
        format(trie, file, false);
    }"
"protected int getInt(String key, int defaultValue) {
        try {
            return getConfig().getInt(key, defaultValue);
        } catch (ConversionException e) {
            logConversionException(key, e);
        }
        return defaultValue;
    }"
"public char[] getRawURIReference() {
        if (_fragment == null) { 
            return _uri;
        }
        if (_uri == null) { 
            return _fragment;
        }
        // if _uri != null &&  _fragment != null
        String uriReference = new String(_uri) + ""#"" + new String(_fragment);
        return uriReference.toCharArray();
    }"
"protected void performOutgoingBehavior(ExecutionEntity execution,
                                           boolean checkConditions,
                                           boolean throwExceptionIfExecutionStuck) {
        Context.getAgenda().planTakeOutgoingSequenceFlowsOperation(execution,
                                                                   true);
    }"
"public final String getFixString(final int pos, final int len, String charsetName) {
        if (pos + len > limit || pos < 0) throw new IllegalArgumentException(""limit excceed: ""
                                                                             + (pos < 0 ? pos : (pos + len)));

        final int from = origin + pos;
        final int end = from + len;
        byte[] buf = buffer;
        int found = from;
        for (; (found < end) && buf[found] != '\0'; found++)
            /* empty loop */;

        try {
            return new String(buf, from, found - from, charsetName);
        } catch (UnsupportedEncodingException e) {
            throw new IllegalArgumentException(""Unsupported encoding: "" + charsetName, e);
        }
    }"
"@Override
    public Collection<String> wordsNearestSum(Collection<String> positive, Collection<String> negative, int top) {
        throw new UnsupportedOperationException(""Method isn't implemented. Please use usual Word2Vec implementation"");
    }"
"private static void scaleDownFive(Slice decimal, int fiveScale, Slice result)
    {
        while (true) {
            int powerFive = Math.min(fiveScale, MAX_POWER_OF_FIVE_INT);
            fiveScale -= powerFive;

            int divisor = POWERS_OF_FIVES_INT[powerFive];
            divide(decimal, divisor, result);
            decimal = result;

            if (fiveScale == 0) {
                return;
            }
        }
    }"
"private void addContender(EmbeddedLeaderElectionService service, LeaderContender contender) {
		synchronized (lock) {
			checkState(!shutdown, ""leader election service is shut down"");
			checkState(!service.running, ""leader election service is already started"");

			try {
				if (!allLeaderContenders.add(service)) {
					throw new IllegalStateException(""leader election service was added to this service multiple times"");
				}

				service.contender = contender;
				service.running = true;

				updateLeader().whenComplete((aVoid, throwable) -> {
					if (throwable != null) {
						fatalError(throwable);
					}
				});
			}
			catch (Throwable t) {
				fatalError(t);
			}
		}
	}"
"private static AWSCredentialsProvider getCredentialsProvider(final Properties configProps, final String configPrefix) {
		CredentialProvider credentialProviderType;
		if (!configProps.containsKey(configPrefix)) {
			if (configProps.containsKey(AWSConfigConstants.accessKeyId(configPrefix))
				&& configProps.containsKey(AWSConfigConstants.secretKey(configPrefix))) {
				// if the credential provider type is not specified, but the Access Key ID and Secret Key are given, it will default to BASIC
				credentialProviderType = CredentialProvider.BASIC;
			} else {
				// if the credential provider type is not specified, it will default to AUTO
				credentialProviderType = CredentialProvider.AUTO;
			}
		} else {
			credentialProviderType = CredentialProvider.valueOf(configProps.getProperty(configPrefix));
		}

		switch (credentialProviderType) {
			case ENV_VAR:
				return new EnvironmentVariableCredentialsProvider();

			case SYS_PROP:
				return new SystemPropertiesCredentialsProvider();

			case PROFILE:
				String profileName = configProps.getProperty(
						AWSConfigConstants.profileName(configPrefix), null);
				String profileConfigPath = configProps.getProperty(
						AWSConfigConstants.profilePath(configPrefix), null);
				return (profileConfigPath == null)
					? new ProfileCredentialsProvider(profileName)
					: new ProfileCredentialsProvider(profileConfigPath, profileName);

			case BASIC:
				return new AWSCredentialsProvider() {
					@Override
					public AWSCredentials getCredentials() {
						return new BasicAWSCredentials(
							configProps.getProperty(AWSConfigConstants.accessKeyId(configPrefix)),
							configProps.getProperty(AWSConfigConstants.secretKey(configPrefix)));
					}

					@Override
					public void refresh() {
						// do nothing
					}
				};

			case ASSUME_ROLE:
				final AWSSecurityTokenService baseCredentials = AWSSecurityTokenServiceClientBuilder.standard()
						.withCredentials(getCredentialsProvider(configProps, AWSConfigConstants.roleCredentialsProvider(configPrefix)))
						.withRegion(configProps.getProperty(AWSConfigConstants.AWS_REGION))
						.build();
				return new STSAssumeRoleSessionCredentialsProvider.Builder(
						configProps.getProperty(AWSConfigConstants.roleArn(configPrefix)),
						configProps.getProperty(AWSConfigConstants.roleSessionName(configPrefix)))
						.withExternalId(configProps.getProperty(AWSConfigConstants.externalId(configPrefix)))
						.withStsClient(baseCredentials)
						.build();

			default:
			case AUTO:
				return new DefaultAWSCredentialsProviderChain();
		}
	}"
"@Override
  public List<WebElement> findElements() {
    SlowLoadingElementList list = new SlowLoadingElementList(clock, timeOutInSeconds);
    try {
      return list.get().getElements();
    } catch (NoSuchElementError e) {
      return new ArrayList<>();
    }
  }"
"public static int indexOfIgnoreCaseAscii(final CharSequence str, final CharSequence searchStr, int startPos) {
        if (str == null || searchStr == null) {
            return INDEX_NOT_FOUND;
        }
        if (startPos < 0) {
            startPos = 0;
        }
        int searchStrLen = searchStr.length();
        final int endLimit = str.length() - searchStrLen + 1;
        if (startPos > endLimit) {
            return INDEX_NOT_FOUND;
        }
        if (searchStrLen == 0) {
            return startPos;
        }
        for (int i = startPos; i < endLimit; i++) {
            if (regionMatchesAscii(str, true, i, searchStr, 0, searchStrLen)) {
                return i;
            }
        }
        return INDEX_NOT_FOUND;
    }"
"@Bean Reporter<Span> reporter(
      Sender sender,
      @Value(""${zipkin.self-tracing.message-timeout:1}"") int messageTimeout,
      CollectorMetrics metrics) {
    return AsyncReporter.builder(sender)
        .messageTimeout(messageTimeout, TimeUnit.SECONDS)
        .metrics(new ReporterMetricsAdapter(metrics.forTransport(""local"")))
        .build();
  }"
"@Nonnull
    public static <T> List<T> filter( @Nonnull List<?> base, @Nonnull Class<T> type ) {
        return filter((Iterable)base,type);
    }"
"public static void mergeHadoopConf(JobConf jobConf) {
		// we have to load the global configuration here, because the HadoopInputFormatBase does not
		// have access to a Flink configuration object
		org.apache.flink.configuration.Configuration flinkConfiguration = GlobalConfiguration.loadConfiguration();

		Configuration hadoopConf = getHadoopConfiguration(flinkConfiguration);
		for (Map.Entry<String, String> e : hadoopConf) {
			if (jobConf.get(e.getKey()) == null) {
				jobConf.set(e.getKey(), e.getValue());
			}
		}
	}"
"@Override
  public final <ReqT, RespT> ServerMethodDefinition<?, ?> wrapMethodDefinition(
      ServerMethodDefinition<ReqT, RespT> oMethodDef) {
    ServerInterceptor binlogInterceptor =
        getServerInterceptor(oMethodDef.getMethodDescriptor().getFullMethodName());
    if (binlogInterceptor == null) {
      return oMethodDef;
    }
    MethodDescriptor<byte[], byte[]> binMethod =
        BinaryLogProvider.toByteBufferMethod(oMethodDef.getMethodDescriptor());
    ServerMethodDefinition<byte[], byte[]> binDef =
        InternalServerInterceptors.wrapMethod(oMethodDef, binMethod);
    ServerCallHandler<byte[], byte[]> binlogHandler =
        InternalServerInterceptors.interceptCallHandlerCreate(
            binlogInterceptor, binDef.getServerCallHandler());
    return ServerMethodDefinition.create(binMethod, binlogHandler);
  }"
"public static ParserRuleContext getFirstChildNode(final ParserRuleContext node, final RuleName ruleName) {
        Optional<ParserRuleContext> result = findFirstChildNode(node, ruleName);
        Preconditions.checkState(result.isPresent());
        return result.get();
    }"
"public void init(String path, String charset) throws IOException {
		BufferedReader reader = FileUtil.getReader(path, charset);
		try {
			String line;
			while(true) {
				line = reader.readLine();
				if(line == null) {
					break;
				}
				this.add(line);
			}
		}finally {
			IoUtil.close(reader);
		}
	}"
"public void writeData(int streamId, boolean outFinished, Buffer buffer, long byteCount)
      throws IOException {
    if (byteCount == 0) { // Empty data frames are not flow-controlled.
      writer.data(outFinished, streamId, buffer, 0);
      return;
    }

    while (byteCount > 0) {
      int toWrite;
      synchronized (Http2Connection.this) {
        try {
          while (bytesLeftInWriteWindow <= 0) {
            // Before blocking, confirm that the stream we're writing is still open. It's possible
            // that the stream has since been closed (such as if this write timed out.)
            if (!streams.containsKey(streamId)) {
              throw new IOException(""stream closed"");
            }
            Http2Connection.this.wait(); // Wait until we receive a WINDOW_UPDATE.
          }
        } catch (InterruptedException e) {
          Thread.currentThread().interrupt(); // Retain interrupted status.
          throw new InterruptedIOException();
        }

        toWrite = (int) Math.min(byteCount, bytesLeftInWriteWindow);
        toWrite = Math.min(toWrite, writer.maxDataLength());
        bytesLeftInWriteWindow -= toWrite;
      }

      byteCount -= toWrite;
      writer.data(outFinished && byteCount == 0, streamId, buffer, toWrite);
    }
  }"
"@ExperimentalApi(""https://github.com/grpc/grpc-java/issues/1712"")
  public static ServerServiceDefinition useInputStreamMessages(
      final ServerServiceDefinition serviceDef) {
    final MethodDescriptor.Marshaller<InputStream> marshaller =
        new MethodDescriptor.Marshaller<InputStream>() {
      @Override
      public InputStream stream(final InputStream value) {
        return value;
      }

      @Override
      public InputStream parse(final InputStream stream) {
        if (stream.markSupported()) {
          return stream;
        } else {
          return new BufferedInputStream(stream);
        }
      }
    };

    return useMarshalledMessages(serviceDef, marshaller);
  }"
"private boolean waitForPermission(final long nanosToWait) {
        waitingThreads.incrementAndGet();
        long deadline = currentNanoTime() + nanosToWait;
        boolean wasInterrupted = false;
        while (currentNanoTime() < deadline && !wasInterrupted) {
            long sleepBlockDuration = deadline - currentNanoTime();
            parkNanos(sleepBlockDuration);
            wasInterrupted = Thread.interrupted();
        }
        waitingThreads.decrementAndGet();
        if (wasInterrupted) {
            currentThread().interrupt();
        }
        return !wasInterrupted;
    }"
"@View(name = ""by_principal"",
        map = ""function(doc) { if (doc.principal && doc.deviceFingerprint && doc.recordDate) { emit(doc.principal, doc) } }"")
    public List<CouchDbMultifactorAuthenticationTrustRecord> findByPrincipal(final String principal) {
        val view = createQuery(""by_principal"").key(principal);
        return db.queryView(view, CouchDbMultifactorAuthenticationTrustRecord.class);
    }"
"private ZapTable getTableExtension() {
		if (tableExt == null) {
			tableExt = new ZapTable() {

				private static final long serialVersionUID = 1L;

				@Override
				protected AutoScrollAction createAutoScrollAction() {
					return null;
				}
			};
			tableExt.setAutoScrollOnNewValues(false);
			tableExt.setModel(getExtensionModel());
			tableExt.setRowHeight(DisplayUtils.getScaledSize(18));
			tableExt.getColumnModel().getColumn(0).setPreferredWidth(DisplayUtils.getScaledSize(70));
			tableExt.getColumnModel().getColumn(1).setPreferredWidth(DisplayUtils.getScaledSize(70));
			tableExt.getColumnModel().getColumn(2).setPreferredWidth(DisplayUtils.getScaledSize(120));
			tableExt.getColumnModel().getColumn(3).setPreferredWidth(DisplayUtils.getScaledSize(220));
			tableExt.setSortOrder(3, SortOrder.ASCENDING);
			
			ListSelectionListener sl = new ListSelectionListener() {

				@Override
				public void valueChanged(ListSelectionEvent arg0) {
	        		int selectedRow = tableExt.getSelectedRow();
	        		if (selectedRow > -1) {
	        			Extension ext = getExtensionModel().getExtension(tableExt.convertRowIndexToModel(selectedRow));
	        			if (ext != null) {
	        				try {
								extName.setText(ext.getUIName());
								boolean addOnExtension = ext.getAddOn() != null;
								addOnNameLabel.setVisible(addOnExtension);
								addOnName.setVisible(addOnExtension);
								addOnName.setText(addOnExtension ? ext.getAddOn().getName() : """");
								extDescription.setText(ext.getDescription());
								if (ext.getAuthor() != null) {
									extAuthor.setText(ext.getAuthor());
								} else {
									extAuthor.setText("""");
								}
								if (ext.getURL() != null) {
									extURL.setText(ext.getURL().toString());
									getUrlLaunchButton().setEnabled(true);
								} else {
									extURL.setText("""");
									getUrlLaunchButton().setEnabled(false);
								}
							} catch (Exception e) {
								// Just to be safe
								log.error(e.getMessage(), e);
							}
	        			}
	        		}
				}};
			
			tableExt.getSelectionModel().addListSelectionListener(sl);
			tableExt.setColumnControlVisible(true);
		}
		return tableExt;
	}"
"private void pruneExpiredQueries()
    {
        if (expirationQueue.size() <= maxQueryHistory) {
            return;
        }

        int count = 0;
        // we're willing to keep full info for up to maxQueryHistory queries
        for (T query : expirationQueue) {
            if (expirationQueue.size() - count <= maxQueryHistory) {
                break;
            }
            query.pruneInfo();
            count++;
        }
    }"
"static boolean needLoad(String moduleLoadList, String moduleName) {
        String[] activatedModules = StringUtils.splitWithCommaOrSemicolon(moduleLoadList);
        boolean match = false;
        for (String activatedModule : activatedModules) {
            if (StringUtils.ALL.equals(activatedModule)) {
                match = true;
            } else if (activatedModule.equals(moduleName)) {
                match = true;
            } else if (match && (activatedModule.equals(""!"" + moduleName)
                || activatedModule.equals(""-"" + moduleName))) {
                match = false;
                break;
            }
        }
        return match;
    }"
"public void shutdown() {
		// remove all of our temp directories
		for (File path : paths) {
			try {
				if (path != null) {
					if (path.exists()) {
						FileUtils.deleteDirectory(path);
						LOG.info(""I/O manager removed spill file directory {}"", path.getAbsolutePath());
					}
				}
			} catch (Throwable t) {
				LOG.error(""IOManager failed to properly clean up temp file directory: "" + path, t);
			}
		}
	}"
"@Deprecated
  public final OkHttpChannelBuilder enableKeepAlive(boolean enable) {
    if (enable) {
      return keepAliveTime(DEFAULT_KEEPALIVE_TIME_NANOS, TimeUnit.NANOSECONDS);
    } else {
      return keepAliveTime(KEEPALIVE_TIME_NANOS_DISABLED, TimeUnit.NANOSECONDS);
    }
  }"
"private int checkLoopback(Pipeline pipeline, RowData rowData) {
        // 检查channel_info字段
        // 首先检查下after记录，从无变有的过程，一般出现在事务头
        Column infokColumn = getColumnIgnoreCase(rowData.getAfterColumnsList(), pipeline.getParameters()
            .getSystemMarkTableInfo());

        // 匹配对应的channelInfo，如果以_SYNC结尾，则认为需要忽略
        if (infokColumn != null && StringUtils.endsWithIgnoreCase(infokColumn.getValue(), RETL_CLIENT_FLAG)) {
            return 1;
        }

        // 匹配对应的channelInfo，如果相同，则认为需要忽略，并返回2，代表需要进行回环补救check机制，因为这个变更也是otter系统产生的
        if (infokColumn != null
            && StringUtils.equalsIgnoreCase(infokColumn.getValue(), pipeline.getParameters().getChannelInfo())) {
            return 2;
        }

        infokColumn = getColumnIgnoreCase(rowData.getBeforeColumnsList(), pipeline.getParameters()
            .getSystemMarkTableInfo());
        // 匹配对应的channelInfo，如果以_SYNC结尾，则认为需要忽略
        if (infokColumn != null && StringUtils.endsWithIgnoreCase(infokColumn.getValue(), RETL_CLIENT_FLAG)) {
            return 1;
        }

        // 匹配对应的channelInfo，如果相同，则认为需要忽略，并返回2，代表需要进行回环补救check机制，因为这个变更也是otter系统产生的
        if (infokColumn != null
            && StringUtils.equalsIgnoreCase(infokColumn.getValue(), pipeline.getParameters().getChannelInfo())) {
            return 2;
        }

        // 检查channel_id字段
        Column markColumn = getColumnIgnoreCase(rowData.getAfterColumnsList(), pipeline.getParameters()
            .getSystemMarkTableColumn());
        // 匹配对应的channel id
        if (markColumn != null && pipeline.getChannelId().equals(Long.parseLong(markColumn.getValue()))) {
            return 2;
        }

        markColumn = getColumnIgnoreCase(rowData.getBeforeColumnsList(), pipeline.getParameters()
            .getSystemMarkTableColumn());
        if (markColumn != null && pipeline.getChannelId().equals(Long.parseLong(markColumn.getValue()))) {
            return 2;
        }

        return 0;
    }"
"public Iterator<InternalRow> rowIterator() {
    final int maxRows = numRows;
    final MutableColumnarRow row = new MutableColumnarRow(columns);
    return new Iterator<InternalRow>() {
      int rowId = 0;

      @Override
      public boolean hasNext() {
        return rowId < maxRows;
      }

      @Override
      public InternalRow next() {
        if (rowId >= maxRows) {
          throw new NoSuchElementException();
        }
        row.rowId = rowId++;
        return row;
      }

      @Override
      public void remove() {
        throw new UnsupportedOperationException();
      }
    };
  }"
"public static void copy(AsciiString src, ByteBuf dst) {
        copy(src, 0, dst, src.length());
    }"
"public final ParseSetup getFinalSetup(Key[] inputKeys, ParseSetup demandedSetup) {
    ParserProvider pp = ParserService.INSTANCE.getByInfo(_parse_type);
    if (pp != null) {
      ParseSetup ps = pp.createParserSetup(inputKeys, demandedSetup);
      if (demandedSetup._decrypt_tool != null)
        ps._decrypt_tool = demandedSetup._decrypt_tool;
      ps.setSkippedColumns(demandedSetup.getSkippedColumns());
      ps.setParseColumnIndices(demandedSetup.getNumberColumns(), demandedSetup.getSkippedColumns()); // final consistent check between skipped_columns and parse_columns_indices
      return ps;
    }

    throw new H2OIllegalArgumentException(""Unknown parser configuration! Configuration="" + this);
  }"
"public Future submit(Runnable call) {
        Assert.notNull(this.factory, ""No factory specified"");
        return executor.submit(call);
    }"
"public String skipParentheses(final SQLStatement sqlStatement) {
        StringBuilder result = new StringBuilder("""");
        int count = 0;
        if (Symbol.LEFT_PAREN == lexer.getCurrentToken().getType()) {
            final int beginPosition = lexer.getCurrentToken().getEndPosition();
            result.append(Symbol.LEFT_PAREN.getLiterals());
            lexer.nextToken();
            while (true) {
                if (equalAny(Symbol.QUESTION)) {
                    sqlStatement.setParametersIndex(sqlStatement.getParametersIndex() + 1);
                }
                if (Assist.END == lexer.getCurrentToken().getType() || (Symbol.RIGHT_PAREN == lexer.getCurrentToken().getType() && 0 == count)) {
                    break;
                }
                if (Symbol.LEFT_PAREN == lexer.getCurrentToken().getType()) {
                    count++;
                } else if (Symbol.RIGHT_PAREN == lexer.getCurrentToken().getType()) {
                    count--;
                }
                lexer.nextToken();
            }
            result.append(lexer.getInput().substring(beginPosition, lexer.getCurrentToken().getEndPosition()));
            lexer.nextToken();
        }
        return result.toString();
    }"
"public static String digitToChinese(Number n) {
		if(null == n) {
			return ""零"";
		}
		return NumberChineseFormater.format(n.doubleValue(), true, true);
	}"
"public static String notAllNullParameterCheck(String parameterName, Set<EntityColumn> columnSet) {
        StringBuilder sql = new StringBuilder();
        sql.append(""<bind name=\""notAllNullParameterCheck\"" value=\""@tk.mybatis.mapper.util.OGNL@notAllNullParameterCheck("");
        sql.append(parameterName).append("", '"");
        StringBuilder fields = new StringBuilder();
        for (EntityColumn column : columnSet) {
            if (fields.length() > 0) {
                fields.append("","");
            }
            fields.append(column.getProperty());
        }
        sql.append(fields);
        sql.append(""')\""/>"");
        return sql.toString();
    }"
"public static boolean hasSetter(Class<?> clazz) {
		if (ClassUtil.isNormalClass(clazz)) {
			final Method[] methods = clazz.getMethods();
			for (Method method : methods) {
				if (method.getParameterTypes().length == 1 && method.getName().startsWith(""set"")) {
					// 检测包含标准的setXXX方法即视为标准的JavaBean
					return true;
				}
			}
		}
		return false;
	}"
"public void doProgressiveLog( StaplerRequest req, StaplerResponse rsp) throws IOException {
        getLogText().doProgressText(req, rsp);
    }"
"public final Pair<String, Double> predictBest(String[] context)
    {
        List<Pair<String, Double>> resultList = predict(context);
        double bestP = -1.0;
        Pair<String, Double> bestPair = null;
        for (Pair<String, Double> pair : resultList)
        {
            if (pair.getSecond() > bestP)
            {
                bestP = pair.getSecond();
                bestPair = pair;
            }
        }

        return bestPair;
    }"
"public static void error(Log log, Throwable e, String format, Object... arguments) {
		if (false == log(log, Level.ERROR, e, format, arguments)) {
			log.error(e, format, arguments);
		}
	}"
"public static void checkState(boolean b, String msg, long arg1, long arg2, long arg3, long arg4) {
        if (!b) {
            throwStateEx(msg, arg1, arg2, arg3, arg4);
        }
    }"
"protected boolean getBooleanMethodParam(String methodName, String paramKey, boolean defaultValue) {
        if (CommonUtils.isEmpty(configContext)) {
            return defaultValue;
        }
        Boolean o = (Boolean) configContext.get(buildMethodKey(methodName, paramKey));
        if (o == null) {
            o = (Boolean) configContext.get(paramKey);
            return o == null ? defaultValue : o;
        } else {
            return o;
        }
    }"
"boolean connectionFailed(IOException e) {
    // Any future attempt to connect using this strategy will be a fallback attempt.
    isFallback = true;

    if (!isFallbackPossible) {
      return false;
    }

    // If there was a protocol problem, don't recover.
    if (e instanceof ProtocolException) {
      return false;
    }

    // If there was an interruption or timeout (SocketTimeoutException), don't recover.
    // For the socket connect timeout case we do not try the same host with a different
    // ConnectionSpec: we assume it is unreachable.
    if (e instanceof InterruptedIOException) {
      return false;
    }

    // Look for known client-side or negotiation errors that are unlikely to be fixed by trying
    // again with a different connection spec.
    if (e instanceof SSLHandshakeException) {
      // If the problem was a CertificateException from the X509TrustManager, do not retry.
      if (e.getCause() instanceof CertificateException) {
        return false;
      }
    }
    if (e instanceof SSLPeerUnverifiedException) {
      // e.g. a certificate pinning error.
      return false;
    }

    // Retry for all other SSL failures.
    return e instanceof SSLException;
  }"
"private SymbolStatsEstimate normalizeSymbolStats(Symbol symbol, SymbolStatsEstimate symbolStats, PlanNodeStatsEstimate stats, TypeProvider types)
    {
        if (symbolStats.isUnknown()) {
            return SymbolStatsEstimate.unknown();
        }

        double outputRowCount = stats.getOutputRowCount();
        checkArgument(outputRowCount > 0, ""outputRowCount must be greater than zero: %s"", outputRowCount);
        double distinctValuesCount = symbolStats.getDistinctValuesCount();
        double nullsFraction = symbolStats.getNullsFraction();

        if (!isNaN(distinctValuesCount)) {
            Type type = requireNonNull(types.get(symbol), () -> ""type is missing for symbol "" + symbol);
            double maxDistinctValuesByLowHigh = maxDistinctValuesByLowHigh(symbolStats, type);
            if (distinctValuesCount > maxDistinctValuesByLowHigh) {
                distinctValuesCount = maxDistinctValuesByLowHigh;
            }

            if (distinctValuesCount > outputRowCount) {
                distinctValuesCount = outputRowCount;
            }

            double nonNullValues = outputRowCount * (1 - nullsFraction);
            if (distinctValuesCount > nonNullValues) {
                double difference = distinctValuesCount - nonNullValues;
                distinctValuesCount -= difference / 2;
                nonNullValues += difference / 2;
                nullsFraction = 1 - nonNullValues / outputRowCount;
            }
        }

        if (distinctValuesCount == 0.0) {
            return SymbolStatsEstimate.zero();
        }

        return SymbolStatsEstimate.buildFrom(symbolStats)
                .setDistinctValuesCount(distinctValuesCount)
                .setNullsFraction(nullsFraction)
                .build();
    }"
"public static List<Tuple2<TypeSerializer<?>, TypeSerializerSnapshot<?>>> readSerializersAndConfigsWithResilience(
			DataInputView in,
			ClassLoader userCodeClassLoader) throws IOException {

		int numSerializersAndConfigSnapshots = in.readInt();

		int[] offsets = new int[numSerializersAndConfigSnapshots * 2];

		for (int i = 0; i < numSerializersAndConfigSnapshots; i++) {
			offsets[i * 2] = in.readInt();
			offsets[i * 2 + 1] = in.readInt();
		}

		int totalBytes = in.readInt();
		byte[] buffer = new byte[totalBytes];
		in.readFully(buffer);

		List<Tuple2<TypeSerializer<?>, TypeSerializerSnapshot<?>>> serializersAndConfigSnapshots =
			new ArrayList<>(numSerializersAndConfigSnapshots);

		TypeSerializer<?> serializer;
		TypeSerializerSnapshot<?> configSnapshot;
		try (
			ByteArrayInputStreamWithPos bufferWithPos = new ByteArrayInputStreamWithPos(buffer);
			DataInputViewStreamWrapper bufferWrapper = new DataInputViewStreamWrapper(bufferWithPos)) {

			for (int i = 0; i < numSerializersAndConfigSnapshots; i++) {

				bufferWithPos.setPosition(offsets[i * 2]);
				serializer = tryReadSerializer(bufferWrapper, userCodeClassLoader, true);

				bufferWithPos.setPosition(offsets[i * 2 + 1]);

				configSnapshot = TypeSerializerSnapshotSerializationUtil.readSerializerSnapshot(
						bufferWrapper, userCodeClassLoader, serializer);

				if (serializer instanceof LegacySerializerSnapshotTransformer) {
					configSnapshot = transformLegacySnapshot(serializer, configSnapshot);
				}

				serializersAndConfigSnapshots.add(new Tuple2<>(serializer, configSnapshot));
			}
		}

		return serializersAndConfigSnapshots;
	}"
"public void mkDirs(String dir) {
		final String[] dirs = StrUtil.trim(dir).split(""[\\\\/]+"");

		final String now = pwd();
		if(dirs.length > 0 && StrUtil.isEmpty(dirs[0])) {
			//首位为空，表示以/开头
			this.cd(StrUtil.SLASH);
		}
		for (int i = 0; i < dirs.length; i++) {
			if (StrUtil.isNotEmpty(dirs[i])) {
				if (false == cd(dirs[i])) {
					//目录不存在时创建
					mkdir(dirs[i]);
					cd(dirs[i]);
				}
			}
		}
		// 切换回工作目录
		cd(now);
	}"
"public void add(String property, JsonElement value) {
    members.put(property, value == null ? JsonNull.INSTANCE : value);
  }"
"static String paren(LabelOperatorPrecedence op, Label l) {
        if (op.compareTo(l.precedence())<0)
            return '('+l.getExpression()+')';
        return l.getExpression();
    }"
"public TerminEventData await(Long pipelineId) throws InterruptedException {
        Assert.notNull(pipelineId);
        TerminMonitor terminMonitor = ArbitrateFactory.getInstance(pipelineId, TerminMonitor.class);
        Long processId = terminMonitor.waitForProcess(); // 符合条件的processId
        if (logger.isDebugEnabled()) {
            logger.debug(""## await pipeline[{}] processId[{}] is termin"", pipelineId, processId);
        }

        // 根据pipelineId+processId构造对应的path
        String path = StagePathUtils.getTermin(pipelineId, processId);

        try {
            byte[] data = zookeeper.readData(path);
            return JsonUtils.unmarshalFromByte(data, TerminEventData.class);
        } catch (ZkNoNodeException e) {
            logger.error(""pipeline[{}] processId[{}] is process"", pipelineId, processId);
            terminMonitor.ack(processId); // modify for 2012-09-08, 发生主备切换时，await会进入死循环，针对NoNode后直接从内存队列中移除
            return await(pipelineId); // 再取下一个节点
        } catch (ZkException e) {
            throw new ArbitrateException(""Termin_await"", e);
        }
    }"
"private boolean isNextCharacterEscapedQuote(String nextLine, boolean inQuotes, int i) {
        return inQuotes  // we are in quotes, therefore there can be escaped quotes in here.
                && nextLine.length() > (i + 1)  // there is indeed another character to check.
                && nextLine.charAt(i + 1) == quotechar;
    }"
"public static void keyPressWithAlt(int key) {
		robot.keyPress(KeyEvent.VK_ALT);
		robot.keyPress(key);
		robot.keyRelease(key);
		robot.keyRelease(KeyEvent.VK_ALT);
		delay();
	}"
"public static <K, V> Map<K, V> notEmpty(Map<K, V> map) throws IllegalArgumentException {
		return notEmpty(map, ""[Assertion failed] - this map must not be empty; it must contain at least one entry"");
	}"
"protected Assertion buildSamlAssertion(final RequestAbstractType authnRequest,
                                           final HttpServletRequest request,
                                           final HttpServletResponse response,
                                           final Object casAssertion,
                                           final SamlRegisteredService service,
                                           final SamlRegisteredServiceServiceProviderMetadataFacade adaptor,
                                           final String binding,
                                           final MessageContext messageContext) {
        return samlResponseBuilderConfigurationContext.getSamlProfileSamlAssertionBuilder()
            .build(authnRequest, request, response, casAssertion, service, adaptor, binding, messageContext);
    }"
"public CompositeReactiveHealthIndicator timeoutStrategy(long timeout,
			Health timeoutHealth) {
		this.timeout = timeout;
		this.timeoutHealth = (timeoutHealth != null) ? timeoutHealth
				: Health.unknown().build();
		return this;
	}"
"public static JavaPairRDD<Long, List<Writable>> restoreMapFile(String path, JavaSparkContext sc) {
        Configuration c = new Configuration();
        c.set(FileInputFormat.INPUT_DIR, FilenameUtils.normalize(path, true));
        JavaPairRDD<LongWritable, RecordWritable> pairRDD =
                        sc.newAPIHadoopRDD(c, SequenceFileInputFormat.class, LongWritable.class, RecordWritable.class);

        return pairRDD.mapToPair(new RecordLoadPairFunction());
    }"
"public String getStr(String key, String group, String defaultValue) {
		final String value = getByGroup(key, group);
		if (StrUtil.isBlank(value)) {
			return defaultValue;
		}
		return value;
	}"
"public static KeyFactory getKeyFactory(String algorithm) {
		final Provider provider = GlobalBouncyCastleProvider.INSTANCE.getProvider();

		KeyFactory keyFactory;
		try {
			keyFactory = (null == provider) //
					? KeyFactory.getInstance(getMainAlgorithm(algorithm)) //
					: KeyFactory.getInstance(getMainAlgorithm(algorithm), provider);
		} catch (NoSuchAlgorithmException e) {
			throw new CryptoException(e);
		}
		return keyFactory;
	}"
"@Override
	public synchronized void deleteAllUrlsForType(int type) throws DatabaseException {
    	try {
			psDeleteAllUrlsForType.setInt(1, type);
			psDeleteAllUrlsForType.executeUpdate();
		} catch (SQLException e) {
			throw new DatabaseException(e);
		}
    }"
"@RequirePOST
    public HttpRedirect doQuietDown(@QueryParameter boolean block, @QueryParameter int timeout) throws InterruptedException, IOException {
        synchronized (this) {
            checkPermission(ADMINISTER);
            isQuietingDown = true;
        }
        if (block) {
            long waitUntil = timeout;
            if (timeout > 0) waitUntil += System.currentTimeMillis();
            while (isQuietingDown
                   && (timeout <= 0 || System.currentTimeMillis() < waitUntil)
                   && !RestartListener.isAllReady()) {
                Thread.sleep(TimeUnit.SECONDS.toMillis(1));
            }
        }
        return new HttpRedirect(""."");
    }"
"static boolean load(String path, AhoCorasickDoubleArrayTrie<String> trie)
    {
        return load(path, trie, false);
    }"
"private static HttpEntityEnclosingRequestBase completeRequest(
      final HttpEntityEnclosingRequestBase request,
      final List<Pair<String, String>> params) throws UnsupportedEncodingException {
    if (request != null) {
      if (null != params && !params.isEmpty()) {
        final List<NameValuePair> formParams = params.stream()
            .map(pair -> new BasicNameValuePair(pair.getFirst(), pair.getSecond()))
            .collect(Collectors.toList());
        final HttpEntity entity = new UrlEncodedFormEntity(formParams, ""UTF-8"");
        request.setEntity(entity);
      }
    }
    return request;
  }"
"public static DataSource createDataSource(final Map<String, DataSource> dataSourceMap, final ShardingRuleConfiguration shardingRuleConfig,
                                              final Properties props, final OrchestrationConfiguration orchestrationConfig) throws SQLException {
        if (null == shardingRuleConfig || shardingRuleConfig.getTableRuleConfigs().isEmpty()) {
            return createDataSource(orchestrationConfig);
        }
        ShardingDataSource shardingDataSource = new ShardingDataSource(dataSourceMap, new ShardingRule(shardingRuleConfig, dataSourceMap.keySet()), props);
        return new OrchestrationShardingDataSource(shardingDataSource, orchestrationConfig);
    }"
"public static LinkedHashSet<String> yearAndQuarter(long startDate, long endDate) {
		LinkedHashSet<String> quarters = new LinkedHashSet<>();
		final Calendar cal = calendar(startDate);
		while (startDate <= endDate) {
			// 如果开始时间超出结束时间，让结束时间为开始时间，处理完后结束循环
			quarters.add(yearAndQuarter(cal));

			cal.add(Calendar.MONTH, 3);
			startDate = cal.getTimeInMillis();
		}

		return quarters;
	}"
"@Override
    public void attachThreadToDevice(Thread thread, Integer deviceId) {
        attachThreadToDevice(thread.getId(), deviceId);
    }"
"public void addDefaultKryoSerializer(Class<?> type, Class<? extends Serializer<?>> serializerClass) {
		if (type == null || serializerClass == null) {
			throw new NullPointerException(""Cannot register null class or serializer."");
		}
		defaultKryoSerializerClasses.put(type, serializerClass);
	}"
"public static Throwable get(Throwable serThrowable, ClassLoader loader) {
		if (serThrowable instanceof SerializedThrowable) {
			return ((SerializedThrowable) serThrowable).deserializeError(loader);
		} else {
			return serThrowable;
		}
	}"
"public static <TERM> Iterable<Map<TERM, Double>> tfs(Iterable<Collection<TERM>> documents, TfType type)
    {
        List<Map<TERM, Double>> tfs = new ArrayList<Map<TERM, Double>>();
        for (Collection<TERM> document : documents)
        {
            tfs.add(tf(document, type));
        }
        return tfs;
    }"
"private static boolean canDiscoverItem(@Nonnull final String fullName) {
        final Jenkins jenkins = Jenkins.getInstance();

        // Fast check to avoid security context switches
        Item item = null;
        try {
            item = jenkins.getItemByFullName(fullName);
        } catch (AccessDeniedException ex) {
            // ignore, we will fall-back later
        }
        if (item != null) {
            return true;
        }
          
        // Probably it failed due to the missing Item.DISCOVER
        // We try to retrieve the job using SYSTEM user and to check permissions manually.
        final Authentication userAuth = Jenkins.getAuthentication();
        try (ACLContext acl = ACL.as(ACL.SYSTEM)) {
            final Item itemBySystemUser = jenkins.getItemByFullName(fullName);
            if (itemBySystemUser == null) {
                return false;
            }

            // To get the item existence fact, a user needs Item.DISCOVER for the item
            // and Item.READ for all container folders.
            boolean canDiscoverTheItem = itemBySystemUser.hasPermission(userAuth, Item.DISCOVER);
            if (canDiscoverTheItem) {
                ItemGroup<?> current = itemBySystemUser.getParent();
                do {
                    if (current instanceof Item) {
                        final Item i = (Item) current;
                        current = i.getParent();
                        if (!i.hasPermission(userAuth, Item.READ)) {
                            canDiscoverTheItem = false;
                        }
                    } else {
                        current = null;
                    }
                } while (canDiscoverTheItem && current != null);
            }
            return canDiscoverTheItem;
        }
    }"
"@Override
	public final void flatMap(IN value, Collector<OUT> out) throws Exception {
		for (Iterator<OUT> iter = flatMap(value); iter.hasNext(); ) {
			out.collect(iter.next());
		}
	}"
"@POST
  @Path(""/db/{authorizerName}/roles/{roleName}/permissions"")
  @Produces(MediaType.APPLICATION_JSON)
  @Consumes(MediaType.APPLICATION_JSON)
  @ResourceFilters(BasicSecurityResourceFilter.class)
  public Response setRolePermissions(
      @Context HttpServletRequest req,
      @PathParam(""authorizerName"") final String authorizerName,
      @PathParam(""roleName"") String roleName,
      List<ResourceAction> permissions
  )
  {
    return resourceHandler.setRolePermissions(authorizerName, roleName, permissions);
  }"
"@PublicEvolving
	@Deprecated
	public <R, ACC> SingleOutputStreamOperator<R> fold(ACC initialValue, FoldFunction<T, ACC> foldFunction, ProcessWindowFunction<ACC, R, K, W> windowFunction) {
		if (foldFunction instanceof RichFunction) {
			throw new UnsupportedOperationException(""FoldFunction can not be a RichFunction."");
		}

		TypeInformation<ACC> foldResultType = TypeExtractor.getFoldReturnTypes(foldFunction, input.getType(),
				Utils.getCallLocationName(), true);

		TypeInformation<R> windowResultType = getProcessWindowFunctionReturnType(windowFunction, foldResultType, Utils.getCallLocationName());

		return fold(initialValue, foldFunction, windowFunction, foldResultType, windowResultType);
	}"
"protected RegisteredService getRegisteredServiceFromFile(final File file) {
        val fileName = file.getName();
        if (fileName.startsWith(""."")) {
            LOGGER.trace(""[{}] starts with ., ignoring"", fileName);
            return null;
        }
        if (Arrays.stream(getExtensions()).noneMatch(fileName::endsWith)) {
            LOGGER.trace(""[{}] doesn't end with valid extension, ignoring"", fileName);
            return null;
        }
        val matcher = this.serviceFileNamePattern.matcher(fileName);
        if (matcher.find()) {
            val serviceId = matcher.group(2);
            if (NumberUtils.isCreatable(serviceId)) {
                val id = Long.parseLong(serviceId);
                return findServiceById(id);
            }
            val serviceName = matcher.group(1);
            return findServiceByExactServiceName(serviceName);
        }
        LOGGER.warn(""Provided file [{}} does not match the recommended service definition file pattern [{}]"",
            file.getName(),
            this.serviceFileNamePattern.pattern());
        return null;
    }"
"public static String maskString(String input, String key) {
        String output = input;
        Map<String, Object> stringConfig = (Map<String, Object>) config.get(MASK_TYPE_STRING);
        if (stringConfig != null) {
            Map<String, Object> keyConfig = (Map<String, Object>) stringConfig.get(key);
            if (keyConfig != null) {
                Set<String> patterns = keyConfig.keySet();
                for (String pattern : patterns) {
                    output = output.replaceAll(pattern, (String) keyConfig.get(pattern));
                }
            }
        }
        return output;
    }"
"public static String signParams(SymmetricCrypto crypto, Map<?, ?> params, String separator, String keyValueSeparator, boolean isIgnoreNull) {
		if (MapUtil.isEmpty(params)) {
			return null;
		}
		String paramsStr = MapUtil.join(MapUtil.sort(params), separator, keyValueSeparator, isIgnoreNull);
		return crypto.encryptHex(paramsStr);
	}"
"private void initialize() {
		this.setLayout(new CardLayout());
		this.setName(buildName(getContextIndex()));
		this.setLayout(new GridBagLayout());
		this.setBorder(new EmptyBorder(2, 2, 2, 2));

		this.add(new JLabel(LABEL_DESCRIPTION), LayoutHelper.getGBC(0, 0, 1, 1.0D));

		// Method type combo box
		this.add(new JLabel(FIELD_LABEL_TYPE_SELECT),
				LayoutHelper.getGBC(0, 1, 1, 1.0D, new Insets(20, 0, 5, 5)));
		this.add(getAuthenticationMethodsComboBox(), LayoutHelper.getGBC(0, 2, 1, 1.0D));

		// Method config panel container
		this.add(getConfigContainerPanel(), LayoutHelper.getGBC(0, 3, 1, 1.0d, new Insets(10, 0, 10, 0)));

		// Logged In/Out indicators
		this.add(new JLabel(FIELD_LABEL_LOGGED_IN_INDICATOR), LayoutHelper.getGBC(0, 4, 1, 1.0D));
		this.add(getLoggedInIndicaterRegexField(), LayoutHelper.getGBC(0, 5, 1, 1.0D));
		this.add(new JLabel(FIELD_LABEL_LOGGED_OUT_INDICATOR), LayoutHelper.getGBC(0, 6, 1, 1.0D));
		this.add(getLoggedOutIndicaterRegexField(), LayoutHelper.getGBC(0, 7, 1, 1.0D));

		// Padding
		this.add(new JLabel(), LayoutHelper.getGBC(0, 99, 1, 1.0D, 1.0D));
	}"
"public static void carryWithRequest(RpcInvokeContext context, SofaRequest request) {
        if (context != null) {
            Map<String, String> requestBaggage = context.getAllRequestBaggage();
            if (CommonUtils.isNotEmpty(requestBaggage)) { // 需要透传
                request.addRequestProp(RemotingConstants.RPC_REQUEST_BAGGAGE, requestBaggage);
            }
        }
    }"
"private void writeObject(ObjectOutputStream out) throws IOException {
		super.write(out);
		out.writeUTF(mapredInputFormat.getClass().getName());
		out.writeUTF(keyClass.getName());
		out.writeUTF(valueClass.getName());
		jobConf.write(out);
	}"
"public void visitAroundMethod(Object declaringType,
                                  Object returnType,
                                  Object genericReturnType,
                                  Map<String, Object> returnTypeGenericTypes,
                                  String methodName,
                                  Map<String, Object> argumentTypes,
                                  Map<String, AnnotationMetadata> argumentAnnotationMetadata,
                                  Map<String, Map<String, Object>> genericTypes,
                                  AnnotationMetadata annotationMetadata) {

        // to make dispatch to this method more efficient and annotation metadata accurate also generate an executable method
        visitExecutableMethod(
            declaringType,
            returnType,
            genericReturnType,
            returnTypeGenericTypes,
            methodName,
            argumentTypes,
            argumentAnnotationMetadata,
            genericTypes,
            annotationMetadata);

        List<Object> argumentTypeList = new ArrayList<>(argumentTypes.values());
        int argumentCount = argumentTypes.size();
        Type returnTypeObject = getTypeReference(returnType);
        boolean isPrimitive = isPrimitive(returnType);
        boolean isVoidReturn = isPrimitive && returnTypeObject.equals(Type.VOID_TYPE);
        final Type declaringTypeReference = getTypeReference(declaringType);
        MethodRef methodKey = new MethodRef(methodName, argumentTypeList, returnTypeObject);
        if (isProxyTarget) {
            // if the target class is being proxied then the method will be looked up from the parent bean definition.
            // Therefore no need to generate a bridge
            if (!proxyTargetMethods.contains(methodKey)) {
                int index = proxyMethodCount++;
                proxyTargetMethods.add(methodKey);
                buildMethodOverride(returnType, methodName, index, argumentTypeList, argumentCount, isVoidReturn);
            }
        } else if (!proxiedMethodsRefSet.contains(methodKey)) {
            int index = proxyMethodCount++;
            // if the target is not being proxied then we generate a subclass where only the proxied methods are overridden
            // Each overridden method calls super.blah(..) thus maintaining class semantics better and providing smaller more efficient
            // proxies

            String methodProxyShortName = ""$$proxy"" + index;
            String bridgeName = ""$$access"" + index;
            String methodExecutorClassName = proxyFullName + methodProxyShortName;

            List<Object> bridgeArguments = new ArrayList<>();
            bridgeArguments.add(proxyFullName);
            bridgeArguments.addAll(argumentTypeList);
            String bridgeDesc = getMethodDescriptor(returnType, bridgeArguments);

            ExecutableMethodWriter executableMethodWriter = new ExecutableMethodWriter(
                proxyFullName, methodExecutorClassName, methodProxyShortName, isInterface, annotationMetadata) {
                @Override
                protected void buildInvokeMethod(Type declaringTypeObject, String methodName, Object returnType, Collection<Object> argumentTypes, GeneratorAdapter invokeMethodVisitor) {
                    // load this
                    invokeMethodVisitor.loadThis();
                    // first argument to static bridge is reference to parent
                    invokeMethodVisitor.getField(methodType, FIELD_PARENT, proxyType);
                    // now remaining arguments
                    for (int i = 0; i < argumentTypeList.size(); i++) {
                        invokeMethodVisitor.loadArg(1);
                        invokeMethodVisitor.push(i);
                        invokeMethodVisitor.visitInsn(AALOAD);
                        AopProxyWriter.pushCastToType(invokeMethodVisitor, argumentTypeList.get(i));
                    }
                    invokeMethodVisitor.visitMethodInsn(INVOKESTATIC, proxyInternalName, bridgeName, bridgeDesc, false);
                    if (isVoidReturn) {
                        invokeMethodVisitor.visitInsn(ACONST_NULL);
                    } else {
                        AopProxyWriter.pushBoxPrimitiveIfNecessary(returnType, invokeMethodVisitor);
                    }
                    invokeMethodVisitor.visitInsn(ARETURN);
                    invokeMethodVisitor.visitMaxs(AbstractClassFileWriter.DEFAULT_MAX_STACK, 1);
                    invokeMethodVisitor.visitEnd();
                }

            };
            executableMethodWriter.makeInner(proxyInternalName, classWriter);
            executableMethodWriter.visitMethod(declaringType, returnType, genericReturnType, returnTypeGenericTypes, methodName, argumentTypes, argumentAnnotationMetadata, genericTypes);

            proxiedMethods.add(executableMethodWriter);
            proxiedMethodsRefSet.add(methodKey);
            String overrideDescriptor = buildMethodOverride(returnType, methodName, index, argumentTypeList, argumentCount, isVoidReturn);

            // now build a bridge to invoke the original method
            MethodVisitor bridgeWriter = classWriter.visitMethod(ACC_STATIC | ACC_SYNTHETIC,
                bridgeName, bridgeDesc, null, null);
            GeneratorAdapter bridgeGenerator = new GeneratorAdapter(bridgeWriter, ACC_STATIC + ACC_SYNTHETIC, bridgeName, bridgeDesc);
            for (int i = 0; i < bridgeArguments.size(); i++) {
                bridgeGenerator.loadArg(i);
            }

            bridgeWriter.visitMethodInsn(INVOKESPECIAL, declaringTypeReference.getInternalName(), methodName, overrideDescriptor, false);
            pushReturnValue(bridgeWriter, returnType);
            bridgeWriter.visitMaxs(DEFAULT_MAX_STACK, 1);
            bridgeWriter.visitEnd();
        }
    }"
"@Override
  public Long ttl(final byte[] key) {
    checkIsInMultiOrPipeline();
    client.ttl(key);
    return client.getIntegerReply();
  }"
"@Override
	public final void initializeState(FunctionInitializationContext context) throws Exception {

		OperatorStateStore stateStore = context.getOperatorStateStore();

		ListState<Tuple2<KafkaTopicPartition, Long>> oldRoundRobinListState =
			stateStore.getSerializableListState(DefaultOperatorStateBackend.DEFAULT_OPERATOR_STATE_NAME);

		this.unionOffsetStates = stateStore.getUnionListState(new ListStateDescriptor<>(
				OFFSETS_STATE_NAME,
				TypeInformation.of(new TypeHint<Tuple2<KafkaTopicPartition, Long>>() {})));

		if (context.isRestored() && !restoredFromOldState) {
			restoredState = new TreeMap<>(new KafkaTopicPartition.Comparator());

			// migrate from 1.2 state, if there is any
			for (Tuple2<KafkaTopicPartition, Long> kafkaOffset : oldRoundRobinListState.get()) {
				restoredFromOldState = true;
				unionOffsetStates.add(kafkaOffset);
			}
			oldRoundRobinListState.clear();

			if (restoredFromOldState && discoveryIntervalMillis != PARTITION_DISCOVERY_DISABLED) {
				throw new IllegalArgumentException(
					""Topic / partition discovery cannot be enabled if the job is restored from a savepoint from Flink 1.2.x."");
			}

			// populate actual holder for restored state
			for (Tuple2<KafkaTopicPartition, Long> kafkaOffset : unionOffsetStates.get()) {
				restoredState.put(kafkaOffset.f0, kafkaOffset.f1);
			}

			LOG.info(""Setting restore state in the FlinkKafkaConsumer: {}"", restoredState);
		} else {
			LOG.info(""No restore state for FlinkKafkaConsumer."");
		}
	}"
"public void append(final byte[] b, final int off, final int len) {
        if (b == null) {
            return;
        }
        if ((off < 0) || (off > b.length) || (len < 0) ||
                ((off + len) < 0) || ((off + len) > b.length)) {
            throw new IndexOutOfBoundsException(""off: ""+off+"" len: ""+len+"" b.length: ""+b.length);
        }
        if (len == 0) {
            return;
        }
        final int oldlen = this.len;
        final int newlen = oldlen + len;
        if (newlen > this.array.length) {
            expand(newlen);
        }
        for (int i1 = off, i2 = oldlen; i2 < newlen; i1++, i2++) {
            this.array[i2] = (char) (b[i1] & 0xff);
        }
        this.len = newlen;
    }"
"public static void sendNotModified(ChannelHandlerContext ctx) {
		FullHttpResponse response = new DefaultFullHttpResponse(HTTP_1_1, NOT_MODIFIED);
		setDateHeader(response);

		// close the connection as soon as the error message is sent.
		ctx.writeAndFlush(response).addListener(ChannelFutureListener.CLOSE);
	}"
"public static void removeTopSeparators(JPopupMenu popupMenu) {
        while (popupMenu.getComponentCount() > 0 && isPopupMenuSeparator(popupMenu.getComponent(0))) {
            popupMenu.remove(0);
        }
    }"
"static SecretKeySpec readSecretKey(DecryptionSetup ds) {
    Keyed<?> ksObject = DKV.getGet(ds._keystore_id);
    ByteVec ksVec = (ByteVec) (ksObject instanceof Frame ? ((Frame) ksObject).vec(0) : ksObject);
    InputStream ksStream = ksVec.openStream(null /*job key*/);
    try {
      KeyStore keystore = KeyStore.getInstance(ds._keystore_type);
      keystore.load(ksStream, ds._password);

      if (! keystore.containsAlias(ds._key_alias)) {
        throw new IllegalArgumentException(""Alias for key not found"");
      }

      java.security.Key key = keystore.getKey(ds._key_alias, ds._password);
      return new SecretKeySpec(key.getEncoded(), key.getAlgorithm());
    } catch (GeneralSecurityException e) {
      throw new RuntimeException(""Unable to load key "" + ds._key_alias + "" from keystore "" + ds._keystore_id, e);
    } catch (IOException e) {
      throw new RuntimeException(""Failed to read keystore "" + ds._keystore_id, e);
    }
  }"
"public boolean receiveAcknowledgeMessage(AcknowledgeCheckpoint message) throws CheckpointException {
		if (shutdown || message == null) {
			return false;
		}

		if (!job.equals(message.getJob())) {
			LOG.error(""Received wrong AcknowledgeCheckpoint message for job {}: {}"", job, message);
			return false;
		}

		final long checkpointId = message.getCheckpointId();

		synchronized (lock) {
			// we need to check inside the lock for being shutdown as well, otherwise we
			// get races and invalid error log messages
			if (shutdown) {
				return false;
			}

			final PendingCheckpoint checkpoint = pendingCheckpoints.get(checkpointId);

			if (checkpoint != null && !checkpoint.isDiscarded()) {

				switch (checkpoint.acknowledgeTask(message.getTaskExecutionId(), message.getSubtaskState(), message.getCheckpointMetrics())) {
					case SUCCESS:
						LOG.debug(""Received acknowledge message for checkpoint {} from task {} of job {}."",
							checkpointId, message.getTaskExecutionId(), message.getJob());

						if (checkpoint.isFullyAcknowledged()) {
							completePendingCheckpoint(checkpoint);
						}
						break;
					case DUPLICATE:
						LOG.debug(""Received a duplicate acknowledge message for checkpoint {}, task {}, job {}."",
							message.getCheckpointId(), message.getTaskExecutionId(), message.getJob());
						break;
					case UNKNOWN:
						LOG.warn(""Could not acknowledge the checkpoint {} for task {} of job {}, "" +
								""because the task's execution attempt id was unknown. Discarding "" +
								""the state handle to avoid lingering state."", message.getCheckpointId(),
							message.getTaskExecutionId(), message.getJob());

						discardSubtaskState(message.getJob(), message.getTaskExecutionId(), message.getCheckpointId(), message.getSubtaskState());

						break;
					case DISCARDED:
						LOG.warn(""Could not acknowledge the checkpoint {} for task {} of job {}, "" +
							""because the pending checkpoint had been discarded. Discarding the "" +
								""state handle tp avoid lingering state."",
							message.getCheckpointId(), message.getTaskExecutionId(), message.getJob());

						discardSubtaskState(message.getJob(), message.getTaskExecutionId(), message.getCheckpointId(), message.getSubtaskState());
				}

				return true;
			}
			else if (checkpoint != null) {
				// this should not happen
				throw new IllegalStateException(
						""Received message for discarded but non-removed checkpoint "" + checkpointId);
			}
			else {
				boolean wasPendingCheckpoint;

				// message is for an unknown checkpoint, or comes too late (checkpoint disposed)
				if (recentPendingCheckpoints.contains(checkpointId)) {
					wasPendingCheckpoint = true;
					LOG.warn(""Received late message for now expired checkpoint attempt {} from "" +
						""{} of job {}."", checkpointId, message.getTaskExecutionId(), message.getJob());
				}
				else {
					LOG.debug(""Received message for an unknown checkpoint {} from {} of job {}."",
						checkpointId, message.getTaskExecutionId(), message.getJob());
					wasPendingCheckpoint = false;
				}

				// try to discard the state so that we don't have lingering state lying around
				discardSubtaskState(message.getJob(), message.getTaskExecutionId(), message.getCheckpointId(), message.getSubtaskState());

				return wasPendingCheckpoint;
			}
		}
	}"
"public static void setScriptVar(ScriptContext context, String key, String value) {
		setScriptVarImpl(getScriptName(context), key, value);
	}"
"public void addRequestPanelDisplayedMessageChangedListener(DisplayedMessageChangedListener messageChangedListener){
        if (requestPanelDisplayedMessageChangedListener == null) {
            requestPanelDisplayedMessageChangedListener = createList();
        }
        requestPanelDisplayedMessageChangedListener.add(messageChangedListener);
    }"
"protected Collection<Authentication> getChainedAuthentications(final Map<String, Object> model) {
        val assertion = getAssertionFrom(model);
        val chainedAuthentications = assertion.getChainedAuthentications();
        return chainedAuthentications.stream().limit(chainedAuthentications.size() - 1).collect(Collectors.toList());
    }"
"public boolean anyMatched(String[] requestPathTokens) {
		Map<String, String> pathParams = new HashMap<>();
		for (PathPattern pattern : routes.keySet()) {
			if (pattern.match(requestPathTokens, pathParams)) {
				return true;
			}

			// Reset for the next loop
			pathParams.clear();
		}

		return false;
	}"
"public static boolean isFromOrSuppressedThrowable(Throwable throwable, Class<? extends Throwable> exceptionClass, boolean checkCause) {
		return convertFromOrSuppressedThrowable(throwable, exceptionClass, checkCause) != null;
	}"
"public final long getUlong48() {
        if (position + 5 >= origin + limit) throw new IllegalArgumentException(""limit excceed: ""
                                                                               + (position - origin + 5));

        byte[] buf = buffer;
        return ((long) (0xff & buf[position++])) | ((long) (0xff & buf[position++]) << 8)
               | ((long) (0xff & buf[position++]) << 16) | ((long) (0xff & buf[position++]) << 24)
               | ((long) (0xff & buf[position++]) << 32) | ((long) (0xff & buf[position++]) << 40);
    }"
"@SuppressWarnings(""unchecked"")
	public static <K, V> Map<K, V> fieldValueAsMap(Iterator<?> iter, String fieldNameForKey, String fieldNameForValue) {
		final Map<K, V> result = new HashMap<>();
		if (null != iter) {
			Object value;
			while (iter.hasNext()) {
				value = iter.next();
				result.put((K) ReflectUtil.getFieldValue(value, fieldNameForKey), (V) ReflectUtil.getFieldValue(value, fieldNameForValue));
			}
		}
		return result;
	}"
"@Override
  public Long move(final byte[] key, final int dbIndex) {
    checkIsInMultiOrPipeline();
    client.move(key, dbIndex);
    return client.getIntegerReply();
  }"
"public static Long getGeneratedKeyOfLong(PreparedStatement ps) throws SQLException {
		ResultSet rs = null;
		try {
			rs = ps.getGeneratedKeys();
			Long generatedKey = null;
			if (rs != null && rs.next()) {
				try {
					generatedKey = rs.getLong(1);
				} catch (SQLException e) {
					// 自增主键不为数字或者为Oracle的rowid，跳过
				}
			}
			return generatedKey;
		} catch (SQLException e) {
			throw e;
		} finally {
			DbUtil.close(rs);
		}
	}"
"private static byte[] typeConvert(MappingConfig.ColumnItem columnItem, MappingConfig.HbaseMapping hbaseMapping,
                                      Object value) {
        if (value == null) {
            return null;
        }
        byte[] bytes = null;
        if (columnItem == null || columnItem.getType() == null || """".equals(columnItem.getType())) {
            if (MappingConfig.Mode.STRING == hbaseMapping.getMode()) {
                bytes = Bytes.toBytes(value.toString());
            } else if (MappingConfig.Mode.NATIVE == hbaseMapping.getMode()) {
                bytes = TypeUtil.toBytes(value);
            } else if (MappingConfig.Mode.PHOENIX == hbaseMapping.getMode()) {
                PhType phType = PhType.getType(value.getClass());
                bytes = PhTypeUtil.toBytes(value, phType);
            }
        } else {
            if (hbaseMapping.getMode() == MappingConfig.Mode.STRING) {
                bytes = Bytes.toBytes(value.toString());
            } else if (hbaseMapping.getMode() == MappingConfig.Mode.NATIVE) {
                Type type = Type.getType(columnItem.getType());
                bytes = TypeUtil.toBytes(value, type);
            } else if (hbaseMapping.getMode() == MappingConfig.Mode.PHOENIX) {
                PhType phType = PhType.getType(columnItem.getType());
                bytes = PhTypeUtil.toBytes(value, phType);
            }
        }
        return bytes;
    }"
"void putAll(BitArray array) {
    assert data.length == array.data.length : ""BitArrays must be of equal length when merging"";
    long bitCount = 0;
    for (int i = 0; i < data.length; i++) {
      data[i] |= array.data[i];
      bitCount += Long.bitCount(data[i]);
    }
    this.bitCount = bitCount;
  }"
"public SDVariable prod(String name, SDVariable x, int... dimensions) {
        return prod(name, x, false, dimensions);
    }"
"public double calculateAverageAUC() {
        assertIndex(0);

        double sum = 0.0;
        for (int i = 0; i < underlying.length; i++) {
            sum += calculateAUC(i);
        }

        return sum / underlying.length;
    }"
"public Object answer(InvocationOnMock invocation) {
        if (isToStringMethod(invocation.getMethod())) {
            Object mock = invocation.getMock();
            MockName name = MockUtil.getMockName(mock);
            if (name.isDefault()) {
                return ""Mock for "" + MockUtil.getMockSettings(mock).getTypeToMock().getSimpleName() + "", hashCode: "" + mock.hashCode();
            } else {
                return name.toString();
            }
        } else if (isCompareToMethod(invocation.getMethod())) {
            //see issue 184.
            //mocks by default should return 0 if references are the same, otherwise some other value because they are not the same. Hence we return 1 (anything but 0 is good).
            //Only for compareTo() method by the Comparable interface
            return invocation.getMock() == invocation.getArgument(0) ? 0 : 1;
        }

        Class<?> returnType = invocation.getMethod().getReturnType();
        return returnValueFor(returnType);
    }"
"public void close() throws IOException {
        if (!closed) {
            this.finish();
            this.buffer.close();
            out.close();
            closed = true;
        }
    }"
"public void addBuffer(ReadableBuffer buffer) {
    if (!(buffer instanceof CompositeReadableBuffer)) {
      buffers.add(buffer);
      readableBytes += buffer.readableBytes();
      return;
    }

    CompositeReadableBuffer compositeBuffer = (CompositeReadableBuffer) buffer;
    while (!compositeBuffer.buffers.isEmpty()) {
      ReadableBuffer subBuffer = compositeBuffer.buffers.remove();
      buffers.add(subBuffer);
    }
    readableBytes += compositeBuffer.readableBytes;
    compositeBuffer.readableBytes = 0;
    compositeBuffer.close();
  }"
"public static void closeAllQuietly(Iterable<? extends AutoCloseable> closeables) {
		if (null != closeables) {
			for (AutoCloseable closeable : closeables) {
				closeQuietly(closeable);
			}
		}
	}"
"@Override
    public InputType getOutputType(InputType... inputType) throws InvalidKerasConfigurationException {
        if (inputType.length > 1)
            throw new InvalidKerasConfigurationException(
                    ""Keras RepeatVector layer accepts only one input (received "" + inputType.length + "")"");
        return this.getRepeatVectorLayer().getOutputType(-1, inputType[0]);
    }"
"@Restricted(NoExternalUse.class)
    public static String getDisplayName(Task t) {
        try {
            return t.getDisplayName();
        } catch (RuntimeException | Error x) {
            LOGGER.log(Level.WARNING, ""failed to find displayName of "" + t, x);
            return t.toString();
        }
    }"
"private void disposeSavepoint(ClusterClient<?> clusterClient, String savepointPath) throws FlinkException {
		Preconditions.checkNotNull(savepointPath, ""Missing required argument: savepoint path. "" +
			""Usage: bin/flink savepoint -d <savepoint-path>"");

		logAndSysout(""Disposing savepoint '"" + savepointPath + ""'."");

		final CompletableFuture<Acknowledge> disposeFuture = clusterClient.disposeSavepoint(savepointPath);

		logAndSysout(""Waiting for response..."");

		try {
			disposeFuture.get(clientTimeout.toMillis(), TimeUnit.MILLISECONDS);
		} catch (Exception e) {
			throw new FlinkException(""Disposing the savepoint '"" + savepointPath + ""' failed."", e);
		}

		logAndSysout(""Savepoint '"" + savepointPath + ""' disposed."");
	}"
"protected static void checkNormal(String configKey, String configValue) throws SofaRpcRuntimeException {
        checkPattern(configKey, configValue, NORMAL, ""only allow a-zA-Z0-9 '-' '_' '.'"");
    }"
"public static <C extends Callable<T>, T> T call(Class<C> cls, ApplicationContext ctx, String... args) {
        return CommandLine.call(cls, new MicronautFactory(ctx), args);
    }"
"public static void main(String[] args) throws Exception {
    parseArgs(args);

    GenMunger rawMunger;
    rawMunger = (hex.genmodel.GenMunger) Class.forName(assemblyClassName).newInstance();

    BufferedReader input = new BufferedReader(new FileReader(inputCSVFileName));
    BufferedWriter output = new BufferedWriter(new FileWriter(outputCSVFileName));

    // Emit outputCSV column names.
    String[] rawHeader = rawMunger.outNames();
    StringBuilder header = new StringBuilder();
    for(int i=0;i<rawHeader.length;++i) {
      header.append(""\"""").append(rawHeader[i]).append(""\"""");
      if( i < rawHeader.length - 1 ) header.append("","");
    }
    output.write(header.toString());
    output.write(""\n"");

    // Loop over inputCSV one row at a time.
    int lineNum = 0;
    String line;
    try {
      while ((line = input.readLine()) != null) {
        lineNum++;

        // skip the header.
        if (lineNum == 1)
          continue;

        // Parse the CSV line.  Somewhat handles quoted commas.  But this ain't no parser test!
        RowData row;
        try {
          row = parseDataRow(line, rawMunger);
        } catch( NumberFormatException nfe) {
          nfe.printStackTrace();
          System.out.println(""Failed to parse row: "" + lineNum );
          throw new RuntimeException();
        }
        RowData mungedRow = rawMunger.fit(row);

        for(int i=0; i<rawMunger.outNames().length;++i) {
          Object val = mungedRow==null?Double.NaN:mungedRow.get(rawMunger.outNames()[i]);
          if( val instanceof Double ) output.write(String.valueOf(val));
          else                        output.write(""\"""" + val + ""\"""");
          if( i < rawMunger.outNames().length - 1) output.write("","");
        }
        output.write(""\n"");
      }
    }
    catch (Exception e) {
      System.out.println(""Caught exception on line "" + lineNum);
      System.out.println("""");
      e.printStackTrace();
      System.exit(1);
    }
    finally {

      // Clean up.
      output.close();
      input.close();
    }

    // Predictions were successfully generated.  Calling program can now compare them with something.
    System.exit(0);
  }"
"@Restricted(NoExternalUse.class) // called from newJob_button-bar view
    @SuppressWarnings(""unused"") // called from newJob_button-bar view
    public boolean isAddToCurrentView() {
        synchronized(this) {
            return !jobNames.isEmpty() || // There are already items in this view specified by name
                    (jobFilters.isEmpty() && includePattern == null) // No other way to include items is used
                    ;
        }
    }"
"public void deleteAllAlerts() {
        for(int i = 0; i < getChildCount(); i++) {
            ((SiteNode) getChildAt(i)).deleteAllAlerts();
        }

        if (!alerts.isEmpty()) {
            alerts.clear();
            highestAlert = null;
            calculateHighestAlert = false;
        	if (this.siteMap != null) {
        		// Deleting alert might affect the nodes visibility in a filtered tree
        		siteMap.applyFilter(this);
        	}
            nodeChanged();
        }
    }"
"int write(final ByteBuf buffer, int offset, int length) {
        int index = buffer.forEachByte(offset, length, writeProcessor);
        return index == -1 ? length : index - offset;
    }"
"public void hideColumn(Object columnName) {
		if (columnName == null) {
			return;
		}

		for (int i = 0; i < columnModel.getColumnCount(); i++) {
			TableColumn column = columnModel.getColumn(i);

			if (columnName.equals(column.getHeaderValue())) {
				hideColumn(column);
				break;
			}
		}
	}"
"@PublicEvolving
	public <ACC, V, R> SingleOutputStreamOperator<R> aggregate(
			AggregateFunction<T, ACC, V> aggregateFunction,
			ProcessAllWindowFunction<V, R, W> windowFunction,
			TypeInformation<ACC> accumulatorType,
			TypeInformation<V> aggregateResultType,
			TypeInformation<R> resultType) {

		checkNotNull(aggregateFunction, ""aggregateFunction"");
		checkNotNull(windowFunction, ""windowFunction"");
		checkNotNull(accumulatorType, ""accumulatorType"");
		checkNotNull(aggregateResultType, ""aggregateResultType"");
		checkNotNull(resultType, ""resultType"");

		if (aggregateFunction instanceof RichFunction) {
			throw new UnsupportedOperationException(""This aggregate function cannot be a RichFunction."");
		}

		//clean the closures
		windowFunction = input.getExecutionEnvironment().clean(windowFunction);
		aggregateFunction = input.getExecutionEnvironment().clean(aggregateFunction);

		final String callLocation = Utils.getCallLocationName();
		final String udfName = ""AllWindowedStream."" + callLocation;

		final String opName;
		final KeySelector<T, Byte> keySel = input.getKeySelector();

		OneInputStreamOperator<T, R> operator;

		if (evictor != null) {
			@SuppressWarnings({""unchecked"", ""rawtypes""})
			TypeSerializer<StreamRecord<T>> streamRecordSerializer =
					(TypeSerializer<StreamRecord<T>>) new StreamElementSerializer(
							input.getType().createSerializer(getExecutionEnvironment().getConfig()));

			ListStateDescriptor<StreamRecord<T>> stateDesc =
					new ListStateDescriptor<>(""window-contents"", streamRecordSerializer);

			opName = ""TriggerWindow("" + windowAssigner + "", "" + stateDesc + "", "" + trigger + "", "" + evictor + "", "" + udfName + "")"";

			operator = new EvictingWindowOperator<>(windowAssigner,
					windowAssigner.getWindowSerializer(getExecutionEnvironment().getConfig()),
					keySel,
					input.getKeyType().createSerializer(getExecutionEnvironment().getConfig()),
					stateDesc,
					new InternalAggregateProcessAllWindowFunction<>(aggregateFunction, windowFunction),
					trigger,
					evictor,
					allowedLateness,
					lateDataOutputTag);

		} else {
			AggregatingStateDescriptor<T, ACC, V> stateDesc = new AggregatingStateDescriptor<>(
					""window-contents"",
					aggregateFunction,
					accumulatorType.createSerializer(getExecutionEnvironment().getConfig()));

			opName = ""TriggerWindow("" + windowAssigner + "", "" + stateDesc + "", "" + trigger + "", "" + udfName + "")"";

			operator = new WindowOperator<>(
					windowAssigner,
					windowAssigner.getWindowSerializer(getExecutionEnvironment().getConfig()),
					keySel,
					input.getKeyType().createSerializer(getExecutionEnvironment().getConfig()),
					stateDesc,
					new InternalSingleValueProcessAllWindowFunction<>(windowFunction),
					trigger,
					allowedLateness,
					lateDataOutputTag);
		}

		return input.transform(opName, resultType, operator).forceNonParallel();
	}"
"@Restricted(NoExternalUse.class)
    public static @Nonnull <T> T getNearestAncestorOfTypeOrThrow(@Nonnull StaplerRequest request, @Nonnull Class<T> clazz) {
        T t = request.findAncestorObject(clazz);
        if (t == null) {
            throw new IllegalArgumentException(""No ancestor of type "" + clazz.getName() + "" in the request"");
        }
        return t;
    }"
"public static String getString(final LdapEntry entry, final String attribute, final String nullValue) {
        val attr = entry.getAttribute(attribute);
        if (attr == null) {
            return nullValue;
        }

        val v = attr.isBinary()
            ? new String(attr.getBinaryValue(), StandardCharsets.UTF_8)
            : attr.getStringValue();

        if (StringUtils.isNotBlank(v)) {
            return v;
        }
        return nullValue;
    }"
"public static INDArray symmetricGeneralizedEigenvalues(INDArray A, INDArray B) {
        Preconditions.checkArgument(A.isMatrix() && A.isSquare(), ""Argument A must be a square matrix: has shape %s"", A.shape());
        Preconditions.checkArgument(B.isMatrix() && B.isSquare(), ""Argument B must be a square matrix: has shape %s"", B.shape());
        INDArray W = Nd4j.create(A.rows());

        A = InvertMatrix.invert(B, false).mmuli(A);
        Nd4j.getBlasWrapper().syev('V', 'L', A, W);
        return W;
    }"
"public static <T> List<T> sub(List<T> list, int start, int end, int step) {
		if (list == null || list.isEmpty()) {
			return null;
		}

		final int size = list.size();
		if (start < 0) {
			start += size;
		}
		if (end < 0) {
			end += size;
		}
		if (start == size) {
			return new ArrayList<>(0);
		}
		if (start > end) {
			int tmp = start;
			start = end;
			end = tmp;
		}
		if (end > size) {
			if (start >= size) {
				return new ArrayList<>(0);
			}
			end = size;
		}

		if (step <= 1) {
			return list.subList(start, end);
		}

		final List<T> result = new ArrayList<>();
		for (int i = start; i < end; i += step) {
			result.add(list.get(i));
		}
		return result;
	}"
"static void validateChecksum(int expectedChecksum, ByteBuf data, int offset, int length) {
        final int actualChecksum = calculateChecksum(data, offset, length);
        if (actualChecksum != expectedChecksum) {
            throw new DecompressionException(
                    ""mismatching checksum: "" + Integer.toHexString(actualChecksum) +
                            "" (expected: "" + Integer.toHexString(expectedChecksum) + ')');
        }
    }"
"public static Version getVersionForDimensions(int numRows, int numColumns) throws FormatException {
    if ((numRows & 0x01) != 0 || (numColumns & 0x01) != 0) {
      throw FormatException.getFormatInstance();
    }

    for (Version version : VERSIONS) {
      if (version.symbolSizeRows == numRows && version.symbolSizeColumns == numColumns) {
        return version;
      }
    }

    throw FormatException.getFormatInstance();
  }"
"@GuardedBy(""evictionLock"")
  void climb() {
    if (!evicts()) {
      return;
    }

    determineAdjustment();
    demoteFromMainProtected();
    long amount = adjustment();
    if (amount == 0) {
      return;
    } else if (amount > 0) {
      increaseWindow();
    } else {
      decreaseWindow();
    }
  }"
"public static void send(MailAccount mailAccount, Collection<String> tos, Collection<String> ccs, Collection<String> bccs, String subject, String content, boolean isHtml, File... files) {
		final Mail mail = Mail.create(mailAccount);
		
		//可选抄送人
		if(CollUtil.isNotEmpty(ccs)) {
			mail.setCcs(ccs.toArray(new String[ccs.size()]));
		}
		//可选密送人
		if(CollUtil.isNotEmpty(bccs)) {
			mail.setBccs(bccs.toArray(new String[bccs.size()]));
		}
		
		mail.setTos(tos.toArray(new String[tos.size()]));
		mail.setTitle(subject);
		mail.setContent(content);
		mail.setHtml(isHtml);
		mail.setFiles(files);
		
		mail.send();
	}"
"@Override
  public final ColumnarMap getMap(int rowId) {
    if (isNullAt(rowId)) return null;
    return new ColumnarMap(getChild(0), getChild(1), getArrayOffset(rowId), getArrayLength(rowId));
  }"
"public static DataType getDtypeFromContext() {
        try {
            lock.readLock().lock();

            if (dtype == null) {
                lock.readLock().unlock();
                lock.writeLock().lock();

                if (dtype == null)
                    dtype = getDtypeFromContext(Nd4jContext.getInstance().getConf().getProperty(""dtype""));

                lock.writeLock().unlock();
                lock.readLock().lock();
            }

            return dtype;
        } finally {
            lock.readLock().unlock();
        }
    }"
"@View(name = ""by_username"", map = ""function(doc) { if(doc.username){ emit(doc.username, doc) } }"")
    public CouchDbProfileDocument findByUsername(final String username) {
        return queryView(""by_username"", username).stream().findFirst().orElse(null);
    }"
"@Override
	public void declineCheckpoint(DeclineCheckpoint decline) {
		final CheckpointCoordinator checkpointCoordinator = executionGraph.getCheckpointCoordinator();

		if (checkpointCoordinator != null) {
			getRpcService().execute(() -> {
				try {
					checkpointCoordinator.receiveDeclineMessage(decline);
				} catch (Exception e) {
					log.error(""Error in CheckpointCoordinator while processing {}"", decline, e);
				}
			});
		} else {
			String errorMessage = ""Received DeclineCheckpoint message for job {} with no CheckpointCoordinator"";
			if (executionGraph.getState() == JobStatus.RUNNING) {
				log.error(errorMessage, jobGraph.getJobID());
			} else {
				log.debug(errorMessage, jobGraph.getJobID());
			}
		}
	}"
"public void setParallelism(int parallelism) {
		Preconditions.checkArgument(
				parallelism > 0 || parallelism == ExecutionConfig.PARALLELISM_DEFAULT,
				""The parallelism must be at least one, or ExecutionConfig.PARALLELISM_DEFAULT (use system default)."");
		this.parallelism = parallelism;
	}"
"@Override protected double[] score0(double[] data, double[] preds, double offset, int ntrees) {
    super.score0(data, preds, offset, ntrees);
    int N = _output._ntrees;
    if (_output.nclasses() == 1) { // regression - compute avg over all trees
      if (N>=1) preds[0] /= N;
    } else { // classification
      if (_output.nclasses() == 2 && binomialOpt()) {
        if (N>=1) {
          preds[1] /= N; //average probability
        }
        preds[2] = 1. - preds[1];
      } else {
        double sum = MathUtils.sum(preds);
        if (sum > 0) MathUtils.div(preds, sum);
      }
    }
    return preds;
  }"
"public SDVariable eq(SDVariable x, SDVariable y) {
        return eq(null, x, y);
    }"
"public WebServiceTemplateBuilder setMarshaller(Marshaller marshaller) {
		return new WebServiceTemplateBuilder(this.detectHttpMessageSender,
				this.interceptors, this.internalCustomizers, this.customizers,
				this.messageSenders, marshaller, this.unmarshaller,
				this.destinationProvider, this.transformerFactoryClass,
				this.messageFactory);
	}"
"public List<RejectedCallable> describe() {
        List<RejectedCallable> l = new ArrayList<>();
        for (Class c : get()) {
            if (!whitelist.contains(c.getName()))
                l.add(new RejectedCallable(c));
        }
        return l;
    }"
"@Override
    public InputType getOutputType(InputType... inputType) throws InvalidKerasConfigurationException {
        if (inputType.length > 1)
            throw new InvalidKerasConfigurationException(
                    ""Keras separable convolution 2D layer accepts only one input (received "" + inputType.length + "")"");
        return this.getSeparableConvolution2DLayer().getOutputType(-1, inputType[0]);
    }"
"public static void scale(InputStream srcStream, OutputStream destStream, int width, int height, Color fixedColor) throws IORuntimeException {
		scale(read(srcStream), getImageOutputStream(destStream), width, height, fixedColor);
	}"
"public static ApproximateHistogram fromBytes(byte[] bytes)
  {
    ByteBuffer buf = ByteBuffer.wrap(bytes);
    return fromBytes(buf);
  }"
"public KQueueDatagramChannelConfig setReusePort(boolean reusePort) {
        try {
            ((KQueueDatagramChannel) channel).socket.setReusePort(reusePort);
            return this;
        } catch (IOException e) {
            throw new ChannelException(e);
        }
    }"
"public static long end(String key) {
		long duration = getTimer(key).duration();
		localTimerMap.get().remove(key);
		return duration;
	}"
"public URLNormalizer secureScheme() {
        Matcher m = PATTERN_SCHEMA.matcher(url);
        if (m.find()) {
            String schema = m.group(1);
            if (""http"".equalsIgnoreCase(schema)) {
                url = m.replaceFirst(schema + ""s$2"");
            }
        }
        return this;
    }"
"@Deprecated
    public static SslContext newClientContext(
            SslProvider provider, File certChainFile, TrustManagerFactory trustManagerFactory) throws SSLException {
        return newClientContext(provider, certChainFile, trustManagerFactory, null, IdentityCipherSuiteFilter.INSTANCE,
                null, 0, 0);
    }"
"@Override
	public CompletableFuture<JobResult> requestJobResult(@Nonnull JobID jobId) {
		return pollResourceAsync(
			() -> {
				final JobMessageParameters messageParameters = new JobMessageParameters();
				messageParameters.jobPathParameter.resolve(jobId);
				return sendRequest(
					JobExecutionResultHeaders.getInstance(),
					messageParameters);
			});
	}"
"@JsonIgnore
    public String getId() {
        if (instanceId != null && !instanceId.isEmpty()) {
            return instanceId;
        } else if (dataCenterInfo instanceof UniqueIdentifier) {
            String uniqueId = ((UniqueIdentifier) dataCenterInfo).getId();
            if (uniqueId != null && !uniqueId.isEmpty()) {
                return uniqueId;
            }
        }
        return hostName;
    }"
"public INDArray asMatrix(BufferedImage image, boolean flipChannels) throws IOException {
        if (converter == null) {
            converter = new OpenCVFrameConverter.ToMat();
        }
        return asMatrix(converter.convert(converter2.getFrame(image, 1.0, flipChannels)));
    }"
"public void setDefaultAlertThreshold(AlertThreshold alertThreshold) {
		if (alertThreshold == null || alertThreshold == AlertThreshold.DEFAULT) {
			throw new IllegalArgumentException(""Parameter alertThreshold must not be null or DEFAULT."");
		}
		this.defaultAlertThreshold = alertThreshold;
	}"
"public static void error(Log log, String format, Object... arguments) {
		error(log, null, format, arguments);
	}"
"public ExcelReader addHeaderAlias(String header, String alias) {
		this.headerAlias.put(header, alias);
		return this;
	}"
"public Rowtime watermarksPeriodicBounded(long delay) {
		internalProperties.putString(ROWTIME_WATERMARKS_TYPE, ROWTIME_WATERMARKS_TYPE_VALUE_PERIODIC_BOUNDED);
		internalProperties.putLong(ROWTIME_WATERMARKS_DELAY, delay);
		return this;
	}"
"protected final int nextStringEndPos(byte[] bytes, int startPos, int limit, byte[] delimiter) {
		int endPos = startPos;

		final int delimLimit = limit - delimiter.length + 1;

		while (endPos < limit) {
			if (endPos < delimLimit && delimiterNext(bytes, endPos, delimiter)) {
				break;
			}
			endPos++;
		}

		if (endPos == startPos) {
			setErrorState(ParseErrorState.EMPTY_COLUMN);
			return -1;
		}
		return endPos;
	}"
"public void printInitialStatusUpdates()
    {
        long lastPrint = System.nanoTime();
        try {
            WarningsPrinter warningsPrinter = new ConsoleWarningsPrinter(console);
            while (client.isRunning()) {
                try {
                    // exit status loop if there is pending output
                    if (client.currentData().getData() != null) {
                        return;
                    }

                    // check if time to update screen
                    boolean update = nanosSince(lastPrint).getValue(SECONDS) >= 0.5;

                    // check for keyboard input
                    int key = readKey();
                    if (key == CTRL_P) {
                        client.cancelLeafStage();
                    }
                    else if (key == CTRL_C) {
                        updateScreen(warningsPrinter);
                        update = false;
                        client.close();
                    }
                    else if (toUpperCase(key) == 'D') {
                        debug = !debug;
                        console.resetScreen();
                        update = true;
                    }

                    // update screen
                    if (update) {
                        updateScreen(warningsPrinter);
                        lastPrint = System.nanoTime();
                    }

                    // fetch next results (server will wait for a while if no data)
                    client.advance();
                }
                catch (RuntimeException e) {
                    log.debug(e, ""error printing status"");
                    if (debug) {
                        e.printStackTrace(out);
                    }
                }
            }
        }
        finally {
            console.resetScreen();
        }
    }"
"public List<Condition> findConditions(final Column column) {
        List<Condition> result = new LinkedList<>();
        for (AndCondition each : andConditions) {
            result.addAll(Collections2.filter(each.getConditions(), new Predicate<Condition>() {
                
                @Override
                public boolean apply(final Condition input) {
                    return input.getColumn().equals(column);
                }
            }));
        }
        return result;
    }"
"@Deprecated
    public static ParagraphVectors readParagraphVectorsFromText(@NonNull File file) {
        try (FileInputStream fis = new FileInputStream(file)) {
            return readParagraphVectorsFromText(fis);
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    }"
"public String join(String separator, final String keyValueSeparator) {
		return MapUtil.join(this.map, separator, keyValueSeparator);
	}"
"public static boolean containsAllContentEqualsIgnoreCase(Collection<CharSequence> a, Collection<CharSequence> b) {
        for (CharSequence v : b) {
            if (!containsContentEqualsIgnoreCase(a, v)) {
                return false;
            }
        }
        return true;
    }"
"public DefaultMapping createMappingToSubflowState(final String name, final String value, final boolean required, final Class type) {
        val parser = this.flowBuilderServices.getExpressionParser();
        val source = parser.parseExpression(value, new FluentParserContext());
        val target = parser.parseExpression(name, new FluentParserContext());
        val mapping = new DefaultMapping(source, target);
        mapping.setRequired(required);
        val typeConverter = new RuntimeBindingConversionExecutor(type, this.flowBuilderServices.getConversionService());
        mapping.setTypeConverter(typeConverter);
        return mapping;
    }"
"public boolean isAuthenticated(HttpMessage msg) {
		if (msg == null || msg.getResponseBody() == null) {
			return false;
		}
		// Assume logged in if nothing was set up
		if (loggedInIndicatorPattern == null && loggedOutIndicatorPattern == null) {
			try {
				Stats.incCounter(SessionStructure.getHostName(msg), AUTH_STATE_NO_INDICATOR_STATS);
			} catch (URIException e) {
				// Ignore
			}
			if (View.isInitialised()) {
				// Let the user know this
				View.getSingleton()
						.getOutputPanel()
						.append(Constant.messages.getString(""authentication.output.indicatorsNotSet"", msg
								.getRequestHeader().getURI())
								+ ""\n"");
			}
			return true;
		}

		String body = msg.getResponseBody().toString();
		String header = msg.getResponseHeader().toString();

		if (loggedInIndicatorPattern != null
				&& (loggedInIndicatorPattern.matcher(body).find() || loggedInIndicatorPattern.matcher(header)
						.find())) {
			// Looks like we're authenticated
			try {
				Stats.incCounter(SessionStructure.getHostName(msg), AUTH_STATE_LOGGED_IN_STATS);
			} catch (URIException e) {
				// Ignore
			}
			return true;
		}

		if (loggedOutIndicatorPattern != null && !loggedOutIndicatorPattern.matcher(body).find()
				&& !loggedOutIndicatorPattern.matcher(header).find()) {
			// Cant find the unauthenticated indicator, assume we're authenticated but record as unknown
			try {
				Stats.incCounter(SessionStructure.getHostName(msg), AUTH_STATE_UNKNOWN_STATS);
			} catch (URIException e) {
				// Ignore
			}
			return true;
		}
		// Not looking good...
		try {
			Stats.incCounter(SessionStructure.getHostName(msg), AUTH_STATE_LOGGED_OUT_STATS);
		} catch (URIException e) {
			// Ignore
		}
		return false;
	}"
"public void init(Long nid) {
        String path = ManagePathUtils.getNode(nid);

        try {
            zookeeper.create(path, new byte[0], CreateMode.EPHEMERAL);// 创建为临时节点
        } catch (ZkException e) {
            throw new ArbitrateException(""Node_init"", nid.toString(), e);
        }
    }"
"private static Set<String> excludeFromTfImportCoverage(){
        List<String> list = Arrays.asList(
                ""Reverse"",      //Can be excluded because ""Reverse_v2"" is synonym that TF uses with tf.reverse(...); ReverseV2 is also Java op that is synonym for same op
                ""LogSigmoid"",    //Not in ops.proto. Have tests for tf.log_sigmoid, but can't test LogSigmoid op directly: tf.log_sigmoid actually just uses ""y = -tf.nn.softplus(-x)"" - i.e., 3 separate ops :/
                ""HardSigmoid"",   //Also implemented as python, NOT a single native op
                ""SpaceToBatch"", //Old name - SpaceToBatchNd is used in practice (inc. for tf.space_to_batch)
                ""BatchToSpace"", //Old name - BatchToSpaceNd is used in practice
                ""Pad"",          //As far as I can tell: Only PadV2 and MirrorPad are used in practice
                ""TopK"",         //TopKV2 used
                ""InTopK"",       //InTopKV2 used
                ""BatchMatrixDeterminant"",   //Deprecated in favor of ""MatrixDeterminant""
                ""BatchMatrixDiagPart"",      //Deprecated in favor of ""MatrixDiagPart""
                ""BatchMatrixDiag"",          //Deprecated in favor of ""MatrixDiag""
                ""BatchMatrixBandPart"",      //Deprecated in favor of ""MatrixBandPart""
                ""BatchMatrixInverse"",       //Deprecated in favor of ""MatrixInverse""
                ""BatchMatrixSetDiag"",       //Deprecated in favor of ""MatrixSetDiag""
                ""BatchMatrixSolve"",         //Deprecated in favor of ""MatrixSolve""
                ""BatchMatrixSolveLs"",       //Deprecated in favor of ""MatrixSolveLs""
                ""BatchMatrixTriangularSolve"",   //Deprecated in favor of ""MatrixTriangularSolve""
                ""BatchSelfAdjointEig"",      //Deprecated in favor of ""SelfAdjointEigV2""
                ""BatchSelfAdjointEigV2"",    //Deprecated in favor of ""SelfAdjointEigV2""
                ""BatchSvd"",                 //Deprecated in favor of ""Svd""

                //All of the following ops - not available in TF (can't find them) - op mapping is wrong?
                //TODO: Check these and remove the import mapping from the Java classes if they are indeed bad
                ""HardTanh"",
                ""Swish"",
                ""RDiv"",
                ""DivScalar"",
                ""LogX"",
                ""RationalTanh"",
                ""absargmax"",
                ""absargmin"",
                ""entropy_shannon"",   //This is a thing, but quite different from our op: https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/contrib/bayesflow/entropy/entropy_shannon
                ""count_zero""



        );

        return new HashSet<>(list);
    }"
"@Override
	public byte[] encrypt(byte[] data, KeyType keyType) {
		final Key key = getKeyByType(keyType);
		final int inputLen = data.length;
		final int maxBlockSize = this.encryptBlockSize < 0 ? inputLen : this.encryptBlockSize;

		lock.lock();
		try (ByteArrayOutputStream out = new ByteArrayOutputStream();) {
			cipher.init(Cipher.ENCRYPT_MODE, key);
			int offSet = 0;
			byte[] cache;
			// 剩余长度
			int remainLength = inputLen;
			// 对数据分段加密
			while (remainLength > 0) {
				cache = cipher.doFinal(data, offSet, Math.min(remainLength, maxBlockSize));
				out.write(cache, 0, cache.length);

				offSet += maxBlockSize;
				remainLength = inputLen - offSet;
			}
			return out.toByteArray();
		} catch (Exception e) {
			throw new CryptoException(e);
		} finally {
			lock.unlock();
		}
	}"
"public void release(String pathInZooKeeper) throws Exception {
		final String path = normalizePath(pathInZooKeeper);

		try {
			client.delete().forPath(getLockPath(path));
		} catch (KeeperException.NoNodeException ignored) {
			// we have never locked this node
		} catch (Exception e) {
			throw new Exception(""Could not release the lock: "" + getLockPath(pathInZooKeeper) + '.', e);
		}
	}"
"public static <S, D> D map(S source, Class<D> destinationClass) {
		return mapper.map(source, destinationClass);
	}"
"public static void drain(InputStream in) throws IOException {
        org.apache.commons.io.IOUtils.copy(in, new NullStream());
        in.close();
    }"
"public void poke4BE(final int offset, final long n) {
        if (offset < super.count) {
            buf[offset + 0] = (byte) ((n & 0xff000000) >> 24);
            buf[offset + 1] = (byte) ((n & 0xff0000) >> 16);
            buf[offset + 2] = (byte) ((n & 0xff00) >> 8);
            buf[offset + 3] = (byte) (n & 0xff);
        }
    }"
"HttpRedirectionValidator getRedirectionValidator() {
        if (redirectionValidator == null) {
            redirectionValidator = redirection -> {
                if (!nodeInScope(redirection.getEscapedURI())) {
                    if (log.isDebugEnabled()) {
                        log.debug(""Skipping redirection out of scan's scope: "" + redirection);
                    }
                    return false;
                }
                return true;
            };
        }
        return redirectionValidator;
    }"
"public void tryAdd(AbstractCheckpointStats checkpoint) {
		// Don't add in progress checkpoints as they will be replaced by their
		// completed/failed version eventually.
		if (cache != null && checkpoint != null && !checkpoint.getStatus().isInProgress()) {
			cache.put(checkpoint.getCheckpointId(), checkpoint);
		}
	}"
"@Override
    public void clearRegistry() {
        overriddenInstanceStatusMap.clear();
        recentCanceledQueue.clear();
        recentRegisteredQueue.clear();
        recentlyChangedQueue.clear();
        registry.clear();
    }"
"public static Rational binomial(Rational n, BigInteger m) {
        if (m.compareTo(BigInteger.ZERO) == 0) {
            return Rational.ONE;
        }
        Rational bin = n;
        for (BigInteger i = BigInteger.valueOf(2); i.compareTo(m) != 1; i = i.add(BigInteger.ONE)) {
            bin = bin.multiply(n.subtract(i.subtract(BigInteger.ONE))).divide(i);
        }
        return bin;
    }"
"public CallOptions withWaitForReady() {
    CallOptions newOptions = new CallOptions(this);
    newOptions.waitForReady = Boolean.TRUE;
    return newOptions;
  }"
"public static void writeLine(BufferedWriter bw, String... params) throws IOException
    {
        for (int i = 0; i < params.length - 1; i++)
        {
            bw.write(params[i]);
            bw.write('\t');
        }
        bw.write(params[params.length - 1]);
    }"
"public SDVariable uniform(String name, double min, double max, long... shape) {
        SDVariable ret = f().randomUniform(min, max, shape);
        return updateVariableNameAndReference(ret, name);
    }"
"public static SslContextBuilder forServer(InputStream keyCertChainInputStream, InputStream keyInputStream) {
        return new SslContextBuilder(true).keyManager(keyCertChainInputStream, keyInputStream);
    }"
"public int execute(String sql, Object... params) throws SQLException {
		Connection conn = null;
		try {
			conn = this.getConnection();
			return SqlExecutor.execute(conn, sql, params);
		} catch (SQLException e) {
			throw e;
		} finally {
			this.closeConnection(conn);
		}
	}"
"private void highlightAll() {
		HighlighterManager highlighter = HighlighterManager.getInstance();
		
		LinkedList<HighlightSearchEntry> highlights = highlighter.getHighlights();
		for (HighlightSearchEntry entry: highlights) {
			highlightEntryParser(entry);
		}
	}"
"public <T> List<T> toList(Class<T> elementType) {
		return JSONConverter.toList(this, elementType);
	}"
"public static String createHtmlSequencePlots(String title, Schema schema, List<List<Writable>> sequence)
                    throws Exception {
        Configuration cfg = new Configuration(new Version(2, 3, 23));

        // Where do we load the templates from:
        cfg.setClassForTemplateLoading(HtmlSequencePlotting.class, ""/templates/"");

        // Some other recommended settings:
        cfg.setIncompatibleImprovements(new Version(2, 3, 23));
        cfg.setDefaultEncoding(""UTF-8"");
        cfg.setLocale(Locale.US);
        cfg.setTemplateExceptionHandler(TemplateExceptionHandler.RETHROW_HANDLER);


        Map<String, Object> input = new HashMap<>();
        input.put(""pagetitle"", title);

        ObjectMapper ret = new ObjectMapper();
        ret.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);
        ret.configure(SerializationFeature.FAIL_ON_EMPTY_BEANS, false);
        ret.configure(MapperFeature.SORT_PROPERTIES_ALPHABETICALLY, true);
        ret.enable(SerializationFeature.INDENT_OUTPUT);

        List<DivObject> divs = new ArrayList<>();
        List<String> divNames = new ArrayList<>();

        //First: create table for schema
        int n = schema.numColumns();
        String[][] table = new String[n / 2 + n % 2][6]; //Number, name, type; 2 columns

        List<ColumnMetaData> meta = schema.getColumnMetaData();
        for (int i = 0; i < meta.size(); i++) {
            int o = i % 2;
            table[i / 2][o * 3] = String.valueOf(i);
            table[i / 2][o * 3 + 1] = meta.get(i).getName();
            table[i / 2][o * 3 + 2] = meta.get(i).getColumnType().toString();
        }

        for (int i = 0; i < table.length; i++) {
            for (int j = 0; j < table[i].length; j++) {
                if (table[i][j] == null) {
                    table[i][j] = """";
                }
            }
        }


        RenderableComponentTable rct = new RenderableComponentTable.Builder().table(table)
                        .header(""#"", ""Name"", ""Type"", ""#"", ""Name"", ""Type"").backgroundColor(""#FFFFFF"")
                        .headerColor(""#CCCCCC"").colWidthsPercent(8, 30, 12, 8, 30, 12).border(1).padLeftPx(4)
                        .padRightPx(4).build();
        divs.add(new DivObject(""tablesource"", ret.writeValueAsString(rct)));

        //Create the plots
        double[] x = new double[sequence.size()];
        for (int i = 0; i < x.length; i++) {
            x[i] = i;
        }

        for (int i = 0; i < n; i++) {
            double[] lineData;
            switch (meta.get(i).getColumnType()) {
                case Integer:
                case Long:
                case Double:
                case Float:
                case Time:
                    lineData = new double[sequence.size()];
                    for (int j = 0; j < lineData.length; j++) {
                        lineData[j] = sequence.get(j).get(i).toDouble();
                    }
                    break;
                case Categorical:
                    //This is a quick-and-dirty way to plot categorical variables as a line chart
                    List<String> stateNames = ((CategoricalMetaData) meta.get(i)).getStateNames();
                    lineData = new double[sequence.size()];
                    for (int j = 0; j < lineData.length; j++) {
                        String state = sequence.get(j).get(i).toString();
                        int idx = stateNames.indexOf(state);
                        lineData[j] = idx;
                    }
                    break;
                case Bytes:
                case String:
                case Boolean:
                default:
                    //Skip
                    continue;
            }

            String name = meta.get(i).getName();

            String chartTitle = ""Column: \"""" + name + ""\"" - Column Type: "" + meta.get(i).getColumnType();
            if (meta.get(i).getColumnType() == ColumnType.Categorical) {
                List<String> stateNames = ((CategoricalMetaData) meta.get(i)).getStateNames();
                StringBuilder sb = new StringBuilder(chartTitle);
                sb.append("" - ("");
                for (int j = 0; j < stateNames.size(); j++) {
                    if (j > 0) {
                        sb.append("", "");
                    }
                    sb.append(j).append(""="").append(stateNames.get(j));
                }
                sb.append("")"");
                chartTitle = sb.toString();
            }

            RenderableComponentLineChart lc = new RenderableComponentLineChart.Builder().title(chartTitle)
                            .addSeries(name, x, lineData).build();

            String divname = ""plot_"" + i;

            divs.add(new DivObject(divname, ret.writeValueAsString(lc)));
            divNames.add(divname);
        }

        input.put(""divs"", divs);
        input.put(""divnames"", divNames);

        //Current date/time, UTC
        DateTimeFormatter formatter = DateTimeFormat.forPattern(""YYYY-MM-dd HH:mm:ss zzz"").withZone(DateTimeZone.UTC);
        long currTime = System.currentTimeMillis();
        String dateTime = formatter.print(currTime);
        input.put(""datetime"", dateTime);

        Template template = cfg.getTemplate(""sequenceplot.ftl"");

        //Process template to String
        Writer stringWriter = new StringWriter();
        template.process(input, stringWriter);

        return stringWriter.toString();
    }"
"public TwoDimTable fillImpl(TwoDimTable impl) {
    final int rows = data[0].length;
    assert(rows == rowcount);
    final int cols = data.length+1;
    String tableHeader = name;
    String tableDescription = description;
    String colHeaderForRowHeaders = columns[0].name;
    String[] rowHeaders = new String[rows];
    for (int r=0; r<rows; ++r) {
      rowHeaders[r] = (String)data[0][r].get();
    }
    String[] colHeaders = new String[cols];
    colHeaders[0] = """";
    for (int c=1; c<cols; ++c) {
      colHeaders[c] = columns[c].description;
    }
    String[] colTypes = new String[cols];
    colTypes[0] = """";
    for (int c=1; c<cols; ++c) {
      colTypes[c] = columns[c].type;
    }
    String[] colFormats = new String[cols];
    colFormats[0] = ""%s"";
    for (int c=1; c<cols; ++c) {
      colFormats[c] = columns[c].format;
    }
    String[][] strCellValues = new String[rows][cols];
    double[][] dblCellValues = new double[rows][cols];
    for (int r=0; r<data[0].length; ++r) {
      for (int c=0; c<data.length; ++c) {
        try {
          if (columns[c].format.equals(""string"")) {  // switch(String) is not java1.6 compliant!
            strCellValues[r][c] = (String)data[c][r].get();
          }
          else if (columns[c].format.equals(""double"")) {
            dblCellValues[r][c] = (Double)data[c][r].get();
          }
          else if (columns[c].format.equals(""float"")) {
            dblCellValues[r][c] = (Float)data[c][r].get();
          }
          else if (columns[c].format.equals(""int"")) {
            dblCellValues[r][c] = (Integer)data[c][r].get();
          }
          else if (columns[c].format.equals(""long"")) {
            dblCellValues[r][c] = (Long)data[c][r].get();
          }
          else throw H2O.fail();
        } catch (ClassCastException e) {
          throw new RuntimeException(e);
        }
      }
    }
    return new TwoDimTable(tableHeader, tableDescription, rowHeaders, colHeaders, colTypes, colFormats, colHeaderForRowHeaders, strCellValues, dblCellValues);
  }"
"public static RowTypeInfo projectFields(RowTypeInfo rowType, int[] fieldMapping) {
		TypeInformation[] fieldTypes = new TypeInformation[fieldMapping.length];
		String[] fieldNames = new String[fieldMapping.length];
		for (int i = 0; i < fieldMapping.length; i++) {
			fieldTypes[i] = rowType.getTypeAt(fieldMapping[i]);
			fieldNames[i] = rowType.getFieldNames()[fieldMapping[i]];
		}
		return new RowTypeInfo(fieldTypes, fieldNames);
	}"
"private static void registerMiddlewareHandler(Object handler) {
		if(handler instanceof MiddlewareHandler) {
			// register the middleware handler if it is enabled.
			if(((MiddlewareHandler) handler).isEnabled()) {
				((MiddlewareHandler) handler).register();
			}
		}
	}"
"@Override
  public NettyChannelBuilder keepAliveTime(long keepAliveTime, TimeUnit timeUnit) {
    checkArgument(keepAliveTime > 0L, ""keepalive time must be positive"");
    keepAliveTimeNanos = timeUnit.toNanos(keepAliveTime);
    keepAliveTimeNanos = KeepAliveManager.clampKeepAliveTimeInNanos(keepAliveTimeNanos);
    if (keepAliveTimeNanos >= AS_LARGE_AS_INFINITE) {
      // Bump keepalive time to infinite. This disables keepalive.
      keepAliveTimeNanos = KEEPALIVE_TIME_NANOS_DISABLED;
    }
    return this;
  }"
"public static void rotate(Image image, int degree, ImageOutputStream out) throws IORuntimeException {
		writeJpg(rotate(image, degree), out);
	}"
"private KvStateRegistryListener getKvStateRegistryListener(JobID jobId) {
		// first check whether we are running the legacy code which registers
		// a single listener under HighAvailabilityServices.DEFAULT_JOB_ID
		KvStateRegistryListener listener = listeners.get(HighAvailabilityServices.DEFAULT_JOB_ID);

		if (listener == null) {
			listener = listeners.get(jobId);
		}
		return listener;
	}"
"static boolean getDataMaskBit(int maskPattern, int x, int y) {
    int intermediate;
    int temp;
    switch (maskPattern) {
      case 0:
        intermediate = (y + x) & 0x1;
        break;
      case 1:
        intermediate = y & 0x1;
        break;
      case 2:
        intermediate = x % 3;
        break;
      case 3:
        intermediate = (y + x) % 3;
        break;
      case 4:
        intermediate = ((y / 2) + (x / 3)) & 0x1;
        break;
      case 5:
        temp = y * x;
        intermediate = (temp & 0x1) + (temp % 3);
        break;
      case 6:
        temp = y * x;
        intermediate = ((temp & 0x1) + (temp % 3)) & 0x1;
        break;
      case 7:
        temp = y * x;
        intermediate = ((temp % 3) + ((y + x) & 0x1)) & 0x1;
        break;
      default:
        throw new IllegalArgumentException(""Invalid mask pattern: "" + maskPattern);
    }
    return intermediate == 0;
  }"
"public Entity setFieldNames(String... fieldNames) {
		if (ArrayUtil.isNotEmpty(fieldNames)) {
			this.fieldNames = CollectionUtil.newHashSet(fieldNames);
		}
		return this;
	}"
"@SuppressWarnings(""WeakerAccess"")
    @Internal
    protected final Collection getBeansOfTypeForField(BeanResolutionContext resolutionContext, BeanContext context, FieldInjectionPoint injectionPoint) {
        return resolveBeanWithGenericsForField(resolutionContext, injectionPoint, (beanType, qualifier) -> {
                    boolean hasNoGenerics = !injectionPoint.getType().isArray() && injectionPoint.asArgument().getTypeVariables().isEmpty();
                    if (hasNoGenerics) {
                        return ((DefaultBeanContext) context).getBean(resolutionContext, beanType, qualifier);
                    } else {
                        return ((DefaultBeanContext) context).getBeansOfType(resolutionContext, beanType, qualifier);
                    }

                }
        );
    }"
"public static String getRealClientIpAddr(final Map<String, String> httpHeaders,
      final String remoteAddr) {

    // If some upstream device added an X-Forwarded-For header
    // use it for the client ip
    // This will support scenarios where load balancers or gateways
    // front the Azkaban web server and a changing Ip address invalidates the session

    String clientIp = httpHeaders.getOrDefault(X_FORWARDED_FOR_HEADER, null);
    if (clientIp == null) {
      clientIp = remoteAddr;
    } else {
      // header can contain comma separated list of upstream servers - get the first one
      final String[] ips = clientIp.split("","");
      clientIp = ips[0];
    }

    // Strip off port and only get IP address
    final String[] parts = clientIp.split("":"");
    clientIp = parts[0];

    return clientIp;
  }"
"private static Props loadConfigurationFromAzkabanHome() {
    final String azkabanHome = System.getenv(""AZKABAN_HOME"");

    if (azkabanHome == null) {
      logger.error(""AZKABAN_HOME not set. Will try default."");
      return null;
    }
    if (!new File(azkabanHome).isDirectory() || !new File(azkabanHome).canRead()) {
      logger.error(azkabanHome + "" is not a readable directory."");
      return null;
    }

    final File confPath = new File(azkabanHome, Constants.DEFAULT_CONF_PATH);
    if (!confPath.exists() || !confPath.isDirectory() || !confPath.canRead()) {
      logger.error(azkabanHome + "" does not contain a readable conf directory."");
      return null;
    }

    return loadAzkabanConfigurationFromDirectory(confPath);
  }"
"private static float calcLearningRate(float initLearningRate, int epochs, long totalProcessed, long vocabWordCount) {
    float rate = initLearningRate * (1 - totalProcessed / (float) (epochs * vocabWordCount + 1));
    if (rate < initLearningRate * LEARNING_RATE_MIN_FACTOR) rate = initLearningRate * LEARNING_RATE_MIN_FACTOR;
    return rate;
  }"
"@Override
    public boolean deleteStatusOverride(String appName, String id,
                                        InstanceStatus newStatus,
                                        String lastDirtyTimestamp,
                                        boolean isReplication) {
        try {
            read.lock();
            STATUS_OVERRIDE_DELETE.increment(isReplication);
            Map<String, Lease<InstanceInfo>> gMap = registry.get(appName);
            Lease<InstanceInfo> lease = null;
            if (gMap != null) {
                lease = gMap.get(id);
            }
            if (lease == null) {
                return false;
            } else {
                lease.renew();
                InstanceInfo info = lease.getHolder();

                // Lease is always created with its instance info object.
                // This log statement is provided as a safeguard, in case this invariant is violated.
                if (info == null) {
                    logger.error(""Found Lease without a holder for instance id {}"", id);
                }

                InstanceStatus currentOverride = overriddenInstanceStatusMap.remove(id);
                if (currentOverride != null && info != null) {
                    info.setOverriddenStatus(InstanceStatus.UNKNOWN);
                    info.setStatusWithoutDirty(newStatus);
                    long replicaDirtyTimestamp = 0;
                    if (lastDirtyTimestamp != null) {
                        replicaDirtyTimestamp = Long.valueOf(lastDirtyTimestamp);
                    }
                    // If the replication's dirty timestamp is more than the existing one, just update
                    // it to the replica's.
                    if (replicaDirtyTimestamp > info.getLastDirtyTimestamp()) {
                        info.setLastDirtyTimestamp(replicaDirtyTimestamp);
                    }
                    info.setActionType(ActionType.MODIFIED);
                    recentlyChangedQueue.add(new RecentlyChangedItem(lease));
                    info.setLastUpdatedTimestamp();
                    invalidateCache(appName, info.getVIPAddress(), info.getSecureVipAddress());
                }
                return true;
            }
        } finally {
            read.unlock();
        }
    }"
"public static synchronized void persistInstallStatus(List<UpdateCenterJob> installingPlugins) {
        File installingPluginsFile = getInstallingPluginsFile();
	if(installingPlugins == null || installingPlugins.isEmpty()) {
		installingPluginsFile.delete();
		return;
	}
	LOGGER.fine(""Writing install state to: "" + installingPluginsFile.getAbsolutePath());
	Map<String,String> statuses = new HashMap<>();
	for(UpdateCenterJob j : installingPlugins) {
		if(j instanceof InstallationJob && j.getCorrelationId() != null) { // only include install jobs with a correlation id (directly selected)
			InstallationJob ij = (InstallationJob)j;
			InstallationStatus status = ij.status;
			String statusText = status.getType();
			if(status instanceof Installing) { // flag currently installing plugins as pending
				statusText = ""Pending"";
			}
			statuses.put(ij.plugin.name, statusText);
		}
	}
        try {
		String installingPluginXml = new XStream().toXML(statuses);
            FileUtils.write(installingPluginsFile, installingPluginXml);
        } catch (IOException e) {
            LOGGER.log(SEVERE, ""Failed to save "" + installingPluginsFile.getAbsolutePath(), e);
        }
    }"
"public static ValidationResult validateDataSets(JavaSparkContext sc, String path, int[] featuresShape, int[] labelsShape) {
        return validateDataSets(sc, path, true, false, featuresShape, labelsShape);
    }"
"public static StringBuilder append(Date date, StringBuilder sb) {
        return formatter().append0(checkNotNull(date, ""date""), checkNotNull(sb, ""sb""));
    }"
"public List<ZuulFilter> putFiltersForClasses(String[] classNames) throws Exception
    {
        List<ZuulFilter> newFilters = new ArrayList<>();
        for (String className : classNames)
        {
            newFilters.add(putFilterForClassName(className));
        }
        return newFilters;
    }"
"public static long readUnsignedIntLittleEndian(byte[] data, int index) {
        long result = (long) (data[index] & 0xFF) | (long) ((data[index + 1] & 0xFF) << 8)
                      | (long) ((data[index + 2] & 0xFF) << 16) | (long) ((data[index + 3] & 0xFF) << 24);
        return result;
    }"
"public String[] getTypeArr() {
		List<String> list = new ArrayList<>();
		From index = null;
		for (int i = 0; i < from.size(); i++) {
			index = from.get(i);
			if (index.getType() != null && index.getType().trim().length() > 0) {
				list.add(index.getType());
			}
		}
		if (list.size() == 0) {
			return null;
		}

		return list.toArray(new String[list.size()]);
	}"
"public HttpHeaders add(HttpHeaders headers) {
        if (headers == null) {
            throw new NullPointerException(""headers"");
        }
        for (Map.Entry<String, String> e: headers) {
            add(e.getKey(), e.getValue());
        }
        return this;
    }"
"private Response<SearchResult> searchForServiceById(final Long id) throws LdapException {
        val filter = LdapUtils.newLdaptiveSearchFilter(this.searchFilter,
            LdapUtils.LDAP_SEARCH_FILTER_DEFAULT_PARAM_NAME, CollectionUtils.wrap(id.toString()));
        return LdapUtils.executeSearchOperation(this.connectionFactory, this.baseDn, filter);
    }"
"public List<Map.Entry<K, Float>> nearest(K key, int size)
    {
        Vector vector = storage.get(key);
        if (vector == null)
        {
            return Collections.emptyList();
        }
        return nearest(key, vector, size);
    }"
"private static synchronized SplitWord initCRFModel(KV<String, SplitWord> kv) {
        try {
            if (kv.getV() != null) {
                return kv.getV();
            }

            long start = System.currentTimeMillis();
            LOG.debug(""begin init crf model!"");
            try (InputStream is = PathToStream.stream(kv.getK())) {
                SplitWord crfSplitWord = new SplitWord(Model.load(CRFModel.class, is));
                kv.setV(crfSplitWord);
                LOG.info(""load crf use time:"" + (System.currentTimeMillis() - start) + "" path is : "" + kv.getK());
                return crfSplitWord;
            }
        } catch (Exception e) {
            LOG.error(kv + "" load err "" + e.getMessage());
            return null;
        }
    }"
"public static TaskManagerServicesConfiguration fromConfiguration(
			Configuration configuration,
			long maxJvmHeapMemory,
			InetAddress remoteAddress,
			boolean localCommunication) {
		final String[] tmpDirs = ConfigurationUtils.parseTempDirectories(configuration);
		String[] localStateRootDir = ConfigurationUtils.parseLocalStateDirectories(configuration);
		if (localStateRootDir.length == 0) {
			// default to temp dirs.
			localStateRootDir = tmpDirs;
		}

		boolean localRecoveryMode = configuration.getBoolean(CheckpointingOptions.LOCAL_RECOVERY);

		final NetworkEnvironmentConfiguration networkConfig = NetworkEnvironmentConfiguration.fromConfiguration(
			configuration,
			maxJvmHeapMemory,
			localCommunication,
			remoteAddress);

		final QueryableStateConfiguration queryableStateConfig = QueryableStateConfiguration.fromConfiguration(configuration);

		boolean preAllocateMemory = configuration.getBoolean(TaskManagerOptions.MANAGED_MEMORY_PRE_ALLOCATE);

		long timerServiceShutdownTimeout = AkkaUtils.getTimeout(configuration).toMillis();

		final RetryingRegistrationConfiguration retryingRegistrationConfiguration = RetryingRegistrationConfiguration.fromConfiguration(configuration);

		return new TaskManagerServicesConfiguration(
			remoteAddress,
			tmpDirs,
			localStateRootDir,
			localRecoveryMode,
			networkConfig,
			queryableStateConfig,
			ConfigurationParserUtils.getSlot(configuration),
			ConfigurationParserUtils.getManagedMemorySize(configuration),
			ConfigurationParserUtils.getMemoryType(configuration),
			preAllocateMemory,
			ConfigurationParserUtils.getManagedMemoryFraction(configuration),
			timerServiceShutdownTimeout,
			retryingRegistrationConfiguration,
			ConfigurationUtils.getSystemResourceMetricsProbingInterval(configuration));
	}"
"public UTF8String trim(UTF8String trimString) {
    if (trimString != null) {
      return trimLeft(trimString).trimRight(trimString);
    } else {
      return null;
    }
  }"
"public static NodeList getNodeListByXPath(String expression, Object source) {
		return (NodeList) getByXPath(expression, source, XPathConstants.NODESET);
	}"
"public static void writeVocabCache(@NonNull VocabCache<VocabWord> vocabCache, @NonNull File file)
            throws IOException {
        try (FileOutputStream fos = new FileOutputStream(file)) {
            writeVocabCache(vocabCache, fos);
        }
    }"
"synchronized List<AstPrimitive> getAllPrims() {
    List<AstPrimitive> prims = new ArrayList<>();
    for (AstPrimitive prim : _loader) {
      prims.add(prim);
    }
    return prims;
  }"
"public static Date addMinutes(@NotNull final Date date, int amount) {
		return DateUtils.addMinutes(date, amount);
	}"
"public static WebApplicationService getService(final List<ArgumentExtractor> argumentExtractors, final HttpServletRequest request) {
        return argumentExtractors
            .stream()
            .map(argumentExtractor -> argumentExtractor.extractService(request))
            .filter(Objects::nonNull)
            .findFirst()
            .orElse(null);
    }"
"public void setInput(long seed, final int[] numIds, final double[] nums, final int numcat, final int[] cats, int mb) {
      Arrays.fill(_a[mb].raw(), 0f);

      // random projection from fullN down to max_categorical_features
      if (params._max_categorical_features < _dinfo.fullN() - _dinfo._nums) {
        assert(nums.length == _dinfo._nums);
        final int M = nums.length + params._max_categorical_features;
//        final boolean random_projection = false;
//        final boolean hash_trick = true;
//        if (random_projection) {
//          final int N = _dinfo.fullN();
//          assert (_a.size() == M);
//
//          // sparse random projection
//          for (int i = 0; i < M; ++i) {
//            for (int c = 0; c < numcat; ++c) {
//              int j = cats[c];
//              Random rng = RandomUtils.getRNG(params._seed + i * N + j);
//              double val = 0;
//              final float rnd = rng.nextFloat();
//              if (rnd < 1. / 6.) val = Math.sqrt(3);
//              if (rnd > 5. / 6.) val = -Math.sqrt(3);
//              _a.add(i, 1f * val);
//            }
//            Random rng = RandomUtils.getRNG(params._seed + i*N + _dinfo.numStart());
//            for (int n = 0; n < nums.length; ++n) {
//              double val = 0;
//              final float rnd = rng.nextFloat();
//              if (rnd < 1. / 6.) val = Math.sqrt(3);
//              if (rnd > 5. / 6.) val = - Math.sqrt(3);
//              _a.set(i, (Double.isNaN(nums[n]) ? 0f /*Always do MeanImputation during scoring*/ : nums[n]) * val);
//            }
//          }
//        } else if (hash_trick) {
          // Use hash trick for categorical features
          assert (_a[mb].size() == M);
          // hash N-nums.length down to M-nums.length = cM (#categorical slots - always use all numerical features)
          final int cM = params._max_categorical_features;

          assert (_a[mb].size() == M);
          MurmurHash murmur = MurmurHash.getInstance();
          for (int i = 0; i < numcat; ++i) {
            ByteBuffer buf = ByteBuffer.allocate(4);
            int hashval = murmur.hash(buf.putInt(cats[i]).array(), 4, (int)params._seed); // turn horizontalized categorical integer into another integer, based on seed
            _a[mb].add(Math.abs(hashval % cM), 1f); // restrict to limited range
          }
          for (int i = 0; i < nums.length; ++i)
            _a[mb].set(cM + i, Double.isNaN(nums[i]) ? 0f /*Always do MeanImputation during scoring*/ : nums[i]);
//        }
      } else {
        assert(_a[mb].size() == _dinfo.fullN());
        for (int i = 0; i < numcat; ++i) {
          if(cats[i] >= 0) {
            _a[mb].set(cats[i], 1f); // one-hot encode categoricals
          }
        }
        if (numIds != null) {
          //sparse
          for (int i = 0; i < numIds.length; ++i)
            _a[mb].set(numIds[i], Double.isNaN(nums[i]) ? 0f /*Always do MeanImputation during scoring*/ : nums[i]);
        } else {
          //dense
          for (int i = 0; i < nums.length; ++i)
            _a[mb].set(_dinfo.numStart() + i, Double.isNaN(nums[i]) ? 0f /*Always do MeanImputation during scoring*/ : nums[i]);
        }
      }

      // Input Dropout
      if (_dropout == null) return;
      if (params._autoencoder && params._input_dropout_ratio > 0) {
        // copy input into _origa -- needed for reconstruction error
        System.arraycopy(_a[mb].raw(), 0, _origa[mb].raw(), 0, _a[mb].raw().length);
      }
      seed += params._seed + 0x1337B4BE;
      _dropout.randomlySparsifyActivation(_a[mb], seed);
    }"
"public static Object wrap(Object object, boolean ignoreNullValue) {
		if (object == null) {
			return ignoreNullValue ? null : JSONNull.NULL;
		}
		if (object instanceof JSON //
				|| JSONNull.NULL.equals(object) //
				|| object instanceof JSONString //
				|| object instanceof CharSequence //
				|| object instanceof Number //
				|| ObjectUtil.isBasicType(object) //
		) {
			return object;
		}

		try {
			// JSONArray
			if (object instanceof Iterable || ArrayUtil.isArray(object)) {
				return new JSONArray(object, ignoreNullValue);
			}
			// JSONObject
			if (object instanceof Map) {
				return new JSONObject(object, ignoreNullValue);
			}

			// 日期类型原样保存，便于格式化
			if (object instanceof Date || object instanceof Calendar) {
				return object;
			}
			if (object instanceof Calendar) {
				return ((Calendar) object).getTimeInMillis();
			}
			// 枚举类保存其字符串形式（4.0.2新增）
			if (object instanceof Enum) {
				return object.toString();
			}

			// Java内部类不做转换
			final Class<?> objectClass = object.getClass();
			final Package objectPackage = objectClass.getPackage();
			final String objectPackageName = objectPackage != null ? objectPackage.getName() : """";
			if (objectPackageName.startsWith(""java."") || objectPackageName.startsWith(""javax."") || objectClass.getClassLoader() == null) {
				return object.toString();
			}

			// 默认按照JSONObject对待
			return new JSONObject(object, ignoreNullValue);
		} catch (Exception exception) {
			return null;
		}
	}"
"public static void write(HttpServletResponse response, String text, String contentType) {
		response.setContentType(contentType);
		Writer writer = null;
		try {
			writer = response.getWriter();
			writer.write(text);
			writer.flush();
		} catch (IOException e) {
			throw new UtilException(e);
		} finally {
			IoUtil.close(writer);
		}
	}"
"public void setImageAssetDelegate(
      @SuppressWarnings(""NullableProblems"") ImageAssetDelegate assetDelegate) {
    this.imageAssetDelegate = assetDelegate;
    if (imageAssetManager != null) {
      imageAssetManager.setDelegate(assetDelegate);
    }
  }"
"@Override public byte[] load(Value v) {
    long start_io_ms = System.currentTimeMillis();
    byte[] b = MemoryManager.malloc1(v._max);
    Key k = v._key;
    long skip = 0;
    // Skip offset based on chunk number
    if(k._kb[0] == Key.CHK)
      skip = FileVec.chunkOffset(k); // The offset
    // Too complicate matters, S3 likes to reset connections when H2O hits it
    // too hard.  We ""fix"" this by just trying again, assuming we're getting
    // hit with a bogus resource limit (H2O doing a parse looks like a DDOS to
    // Amazon S3).
    S3ObjectInputStream s = null;

    while( true ) {             // Loop, in case we get premature EOF's
      try {
        long start_ns = System.nanoTime(); // Blocking i/o call timing - without counting repeats
        s = getObjectForKey(k, skip, v._max).getObjectContent();
        ByteStreams.readFully(s, b); // delegate work to Google (it reads the byte buffer in a cycle as we did)
        assert v.isPersisted();
//        TimeLine.record_IOclose(start_ns, start_io_ms, 1/* read */, v._max, Value.S3);
        return b;
        // Explicitly ignore the following exceptions but
        // fail on the rest IOExceptions
      } catch( EOFException e ) {
        ignoreAndWait(e, false);
      } catch( SocketTimeoutException e ) {
        ignoreAndWait(e, false);
      } catch( IOException e ) {
        ignoreAndWait(e, true);
      } finally {
        try {
          if( s != null ) s.close();
        } catch( IOException e ) {}
      }
    }
  }"
"public static boolean isDefaultJDKValid(Node n) {
        try {
            TaskListener listener = new StreamTaskListener(new NullStream());
            Launcher launcher = n.createLauncher(listener);
            return launcher.launch().cmds(""java"",""-fullversion"").stdout(listener).join()==0;
        } catch (IOException | InterruptedException e) {
            return false;
        }
    }"
"public static AssertionError createArgumentsAreDifferentException(String message, String wanted, String actual) {
        return factory.create(message, wanted, actual);
    }"
"public void setMaxPageSize(final int maxPageSize) {
		if (maxPageSize <= 0) {
			throw new IllegalArgumentException(""Parameter maxPageSize must be greater than zero."");
		}
		if (this.maxPageSize == maxPageSize) {
			return;
		}
		int oldMaxPageSize = this.maxPageSize;
		setMaxPageSizeWithoutPageChanges(maxPageSize);

		int rowCount = getRowCount();
		if (rowCount > 0) {
			if (maxPageSize > oldMaxPageSize) {
				schedule(dataOffset);
			} else if (data.size() > maxPageSize) {
				final List<T> shrunkData = data.subList(0, maxPageSize);

				EventQueue.invokeLater(new Runnable() {

					@Override
					public void run() {
						setData(dataOffset, new ArrayList<>(shrunkData));
					}
				});
			}
		}

	}"
"public String path() {
    /* build the fully qualified url with all query parameters */
    StringBuilder path = new StringBuilder();
    if (this.target != null) {
      path.append(this.target);
    }
    if (this.uriTemplate != null) {
      path.append(this.uriTemplate.toString());
    }
    if (path.length() == 0) {
      /* no path indicates the root uri */
      path.append(""/"");
    }
    return path.toString();

  }"
"static int parseInt(String key, @Nullable String value) {
    requireArgument((value != null) && !value.isEmpty(), ""value of key %s was omitted"", key);
    try {
      return Integer.parseInt(value);
    } catch (NumberFormatException e) {
      throw new IllegalArgumentException(String.format(
          ""key %s value was set to %s, must be an integer"", key, value), e);
    }
  }"
"public void endMethod() throws IOException {
    Scope popped = popScope();
    if (popped == Scope.NON_ABSTRACT_METHOD) {
      indent();
      out.write(""}\n"");
    } else if (popped != Scope.ABSTRACT_METHOD) {
      throw new IllegalStateException();
    }
  }"
"public void schedulePrune(long delay) {
		this.pruneJobFuture = GlobalPruneTimer.INSTANCE.schedule(new Runnable() {
			@Override
			public void run() {
				prune();
			}
		}, delay);
	}"
"private long convertToBytes(DataSize size, int defaultValue) {
		if (size != null && !size.isNegative()) {
			return size.toBytes();
		}
		return defaultValue;
	}"
"public static <T> Entity parseWithUnderlineCase(T bean) {
		return create(null).parseBean(bean, true, true);
	}"
"private synchronized Long getMinTransformedProcessId() {
        if (!CollectionUtils.isEmpty(progress)) {
            Long processId = Collections.min(progress.keySet());
            StageProgress stage = progress.get(processId);
            // stage可能为空，针对select未完成时，对应的值就为null
            if (stage != null && stage != nullProgress && stage.getStage().isTransform()) {
                return processId;
            }
        }

        return null;
    }"
"public List<URL> getAllLibraries() {
		List<URL> libs = new ArrayList<URL>(this.extractedTempLibraries.size() + 1);

		if (jarFile != null) {
			libs.add(jarFile);
		}
		for (File tmpLib : this.extractedTempLibraries) {
			try {
				libs.add(tmpLib.getAbsoluteFile().toURI().toURL());
			}
			catch (MalformedURLException e) {
				throw new RuntimeException(""URL is invalid. This should not happen."", e);
			}
		}

		return libs;
	}"
"public static byte setBooleanToByte(byte modifiers, int i, boolean bool) {
        boolean old = getBooleanFromByte(modifiers, i);
        if (old && !bool) { // true-->false
            return (byte) (modifiers - (1 << i));
        } else if (!old && bool) { // false-->true
            return (byte) (modifiers + (1 << i));
        }
        return modifiers;
    }"
"public void repackage(File destination, Libraries libraries) throws IOException {
		repackage(destination, libraries, null);
	}"
"private static org.rythmengine.RythmEngine createEngine(TemplateConfig config) {
		if (null == config) {
			config = new TemplateConfig();
		}
		
		final Properties props = new Properties();
		final String path = config.getPath();
		if (null != path) {
			props.put(""home.template"", path);
		}

		final org.rythmengine.RythmEngine engine = new org.rythmengine.RythmEngine(props);
		return engine;
	}"
"public static Short max(Short a, Short b) {
		return a >= b ? a : b;
	}"
"public StubbedInvocationMatcher addAnswer(Answer answer, boolean isConsecutive, Strictness stubbingStrictness) {
        Invocation invocation = invocationForStubbing.getInvocation();
        mockingProgress().stubbingCompleted();
        if (answer instanceof ValidableAnswer) {
            ((ValidableAnswer) answer).validateFor(invocation);
        }

        synchronized (stubbed) {
            if (isConsecutive) {
                stubbed.getFirst().addAnswer(answer);
            } else {
                Strictness effectiveStrictness = stubbingStrictness != null ? stubbingStrictness : this.mockStrictness;
                stubbed.addFirst(new StubbedInvocationMatcher(answer, invocationForStubbing, effectiveStrictness));
            }
            return stubbed.getFirst();
        }
    }"
"public Cell getCell(int x, int y, boolean isCreateIfNotExist) {
		final Row row = isCreateIfNotExist ? RowUtil.getOrCreateRow(this.sheet, y) : this.sheet.getRow(y);
		if (null != row) {
			return isCreateIfNotExist ? CellUtil.getOrCreateCell(row, x) : row.getCell(x);
		}
		return null;
	}"
"public static INDArray pca(INDArray A, int nDims, boolean normalize) {
        INDArray factor = pca_factor(A, nDims, normalize);
        return A.mmul(factor);
    }"
"public static void log(Object obj) {
		if (obj instanceof Throwable) {
			Throwable e = (Throwable) obj;
			log(e, e.getMessage());
		} else {
			log(""{}"", obj);
		}
	}"
"public static Session create(SessionStore sessionStore, HttpRequest<?> request) {
        Session session = sessionStore.newSession();
        request.getAttributes().put(HttpSessionFilter.SESSION_ATTRIBUTE, session);
        return session;
    }"
"private void addAtIndex(int index, PropertySource<?> propertySource) {
        removeIfPresent(propertySource);
        this.propertySourceList.add(index, propertySource);
    }"
"private static <T> ConfigOption<T> prefixOption(ConfigOption<T> option, String prefix) {
		String key = prefix + option.key();

		List<FallbackKey> deprecatedKeys;
		if (option.hasFallbackKeys()) {
			deprecatedKeys = new ArrayList<>();
			for (FallbackKey dk : option.fallbackKeys()) {
				deprecatedKeys.add(createDeprecatedKey(prefix + dk.getKey()));
			}
		} else {
			deprecatedKeys = Collections.emptyList();
		}

		FallbackKey[] deprecated = deprecatedKeys.toArray(new FallbackKey[0]);
		return new ConfigOption<>(key,
			option.description(),
			option.defaultValue(),
			deprecated);
	}"
"private void initConnecton() {
		this.httpConnection = HttpConnection.create(URLUtil.toUrlForHttp(this.url, this.urlHandler), this.proxy)//
				.setMethod(this.method)//
				.setHttpsInfo(this.hostnameVerifier, this.ssf)//
				.setConnectTimeout(this.connectionTimeout)//
				.setReadTimeout(this.readTimeout)//
				// 自定义Cookie
				.setCookie(this.cookie)
				// 定义转发
				.setInstanceFollowRedirects(this.maxRedirectCount > 0 ? true : false)
				// 覆盖默认Header
				.header(this.headers, true);

		// 是否禁用缓存
		if (this.isDisableCache) {
			this.httpConnection.disableCache();
		}
	}"
"public OtpErlangObject[] elements() {
        if (arity() == 0) {
            return NO_ELEMENTS;
        }
        final OtpErlangObject[] res = new OtpErlangObject[arity()];
        System.arraycopy(elems, 0, res, 0, res.length);
        return res;
    }"
"@Internal
	public static void initializeSafetyNetForThread() {
		SafetyNetCloseableRegistry oldRegistry = REGISTRIES.get();

		checkState(null == oldRegistry, ""Found an existing FileSystem safety net for this thread: %s "" +
				""This may indicate an accidental repeated initialization, or a leak of the"" +
				""(Inheritable)ThreadLocal through a ThreadPool."", oldRegistry);

		SafetyNetCloseableRegistry newRegistry = new SafetyNetCloseableRegistry();
		REGISTRIES.set(newRegistry);
	}"
"public static JavaRDD<List<List<Writable>>> zeroMeanUnitVarianceSequence(Schema schema,
                    JavaRDD<List<List<Writable>>> sequence, List<String> excludeColumns) {
        DataRowsFacade frame = DataFrames.toDataFrameSequence(schema, sequence);
        if (excludeColumns == null)
            excludeColumns = Arrays.asList(DataFrames.SEQUENCE_UUID_COLUMN, DataFrames.SEQUENCE_INDEX_COLUMN);
        else {
            excludeColumns = new ArrayList<>(excludeColumns);
            excludeColumns.add(DataFrames.SEQUENCE_UUID_COLUMN);
            excludeColumns.add(DataFrames.SEQUENCE_INDEX_COLUMN);
        }
        frame = zeromeanUnitVariance(frame, excludeColumns);
        return DataFrames.toRecordsSequence(frame).getSecond();
    }"
"public Map<String, Link> resolveLinks(String requestUrl) {
		String normalizedUrl = normalizeRequestUrl(requestUrl);
		Map<String, Link> links = new LinkedHashMap<>();
		links.put(""self"", new Link(normalizedUrl));
		for (ExposableEndpoint<?> endpoint : this.endpoints) {
			if (endpoint instanceof ExposableWebEndpoint) {
				collectLinks(links, (ExposableWebEndpoint) endpoint, normalizedUrl);
			}
			else if (endpoint instanceof PathMappedEndpoint) {
				String rootPath = ((PathMappedEndpoint) endpoint).getRootPath();
				Link link = createLink(normalizedUrl, rootPath);
				links.put(endpoint.getEndpointId().toLowerCaseString(), link);
			}
		}
		return links;
	}"
"@Override
  protected void reserveInternal(int newCapacity) {
    int oldCapacity = (nulls == 0L) ? 0 : capacity;
    if (isArray() || type instanceof MapType) {
      this.lengthData =
          Platform.reallocateMemory(lengthData, oldCapacity * 4L, newCapacity * 4L);
      this.offsetData =
          Platform.reallocateMemory(offsetData, oldCapacity * 4L, newCapacity * 4L);
    } else if (type instanceof ByteType || type instanceof BooleanType) {
      this.data = Platform.reallocateMemory(data, oldCapacity, newCapacity);
    } else if (type instanceof ShortType) {
      this.data = Platform.reallocateMemory(data, oldCapacity * 2L, newCapacity * 2L);
    } else if (type instanceof IntegerType || type instanceof FloatType ||
        type instanceof DateType || DecimalType.is32BitDecimalType(type)) {
      this.data = Platform.reallocateMemory(data, oldCapacity * 4L, newCapacity * 4L);
    } else if (type instanceof LongType || type instanceof DoubleType ||
        DecimalType.is64BitDecimalType(type) || type instanceof TimestampType) {
      this.data = Platform.reallocateMemory(data, oldCapacity * 8L, newCapacity * 8L);
    } else if (childColumns != null) {
      // Nothing to store.
    } else {
      throw new RuntimeException(""Unhandled "" + type);
    }
    this.nulls = Platform.reallocateMemory(nulls, oldCapacity, newCapacity);
    Platform.setMemory(nulls + oldCapacity, (byte)0, newCapacity - oldCapacity);
    capacity = newCapacity;
  }"
"private boolean containsKey(K key, int keyGroupIndex, N namespace) {

		checkKeyNamespacePreconditions(key, namespace);

		Map<N, Map<K, S>> namespaceMap = getMapForKeyGroup(keyGroupIndex);

		if (namespaceMap == null) {
			return false;
		}

		Map<K, S> keyedMap = namespaceMap.get(namespace);

		return keyedMap != null && keyedMap.containsKey(key);
	}"
"public static Pattern createPattern(final String pattern, final int flags) {
        if (pattern == null) {
            LOGGER.debug(""Pattern cannot be null"");
            return MATCH_NOTHING_PATTERN;
        }
        try {
            return Pattern.compile(pattern, flags);
        } catch (final PatternSyntaxException exception) {
            LOGGER.debug(""Pattern [{}] is not a valid regex."", pattern);
            return MATCH_NOTHING_PATTERN;
        }
    }"
"private Status statusFromTrailers(Metadata trailers) {
    Status status = trailers.get(InternalStatus.CODE_KEY);
    if (status != null) {
      return status.withDescription(trailers.get(InternalStatus.MESSAGE_KEY));
    }
    // No status; something is broken. Try to provide a resonanable error.
    if (headersReceived) {
      return Status.UNKNOWN.withDescription(""missing GRPC status in response"");
    }
    Integer httpStatus = trailers.get(HTTP2_STATUS);
    if (httpStatus != null) {
      status = GrpcUtil.httpStatusToGrpcStatus(httpStatus);
    } else {
      status = Status.INTERNAL.withDescription(""missing HTTP status code"");
    }
    return status.augmentDescription(
        ""missing GRPC status, inferred error from HTTP status code"");
  }"
"public void setUsers(List<User> users) {
		users.forEach(u -> validateNonNull(u));
		this.users = new ArrayList<>(users);
	}"
"@Incubating
    public static <T, A> Answer<T> answer(Answer1<T, A> answer) {
        return toAnswer(answer);
    }"
"private String getText(Element element) {
		try {
			for (int i = 0; i < element.getChildNodes().getLength(); i++) {
				Node node = element.getChildNodes().item(i);
				if (node.getNodeType() == Node.TEXT_NODE) {
					return node.getNodeValue();
				}
			}
		} catch (Exception e) {
		}
		return """";

	}"
"public void addAll(Configuration other, String prefix) {
		final StringBuilder bld = new StringBuilder();
		bld.append(prefix);
		final int pl = bld.length();

		synchronized (this.confData) {
			synchronized (other.confData) {
				for (Map.Entry<String, Object> entry : other.confData.entrySet()) {
					bld.setLength(pl);
					bld.append(entry.getKey());
					this.confData.put(bld.toString(), entry.getValue());
				}
			}
		}
	}"
"public SDVariable addVariable(SDVariable variable) {
        Preconditions.checkState(variable.getSameDiff() == this, ""Samediff instance must be the same."");

        if (variables.containsKey(variable.getVarName()) && !variables.get(variable.getVarName()).getVariable().equals(variable)) {
            throw new IllegalArgumentException(""Variable already found with variable opName "" + variable.getVarName());
        }

        Preconditions.checkState(variable.getSameDiff() == this, ""Same diff instance for variable must be the same!"");
        variables.put(variable.getVarName(), Variable.builder().name(variable.getVarName()).variable(variable).build());
        return variable;
    }"
"@Override
  public OperationHandle getSchemas(SessionHandle sessionHandle, String catalogName,
      String schemaName)
          throws HiveSQLException {
    try {
      TGetSchemasReq req = new TGetSchemasReq(sessionHandle.toTSessionHandle());
      req.setCatalogName(catalogName);
      req.setSchemaName(schemaName);
      TGetSchemasResp resp = cliService.GetSchemas(req);
      checkStatus(resp.getStatus());
      TProtocolVersion protocol = sessionHandle.getProtocolVersion();
      return new OperationHandle(resp.getOperationHandle(), protocol);
    } catch (HiveSQLException e) {
      throw e;
    } catch (Exception e) {
      throw new HiveSQLException(e);
    }
  }"
"@Restricted(DoNotUse.class) // WebOnly
    public HttpResponse doRestartStatus() throws IOException {
        JSONObject response = new JSONObject();
        Jenkins jenkins = Jenkins.get();
        response.put(""restartRequired"", jenkins.getUpdateCenter().isRestartRequiredForCompletion());
        response.put(""restartSupported"", jenkins.getLifecycle().canRestart());
        return HttpResponses.okJSON(response);
    }"
"public static void putRegisteredService(final RequestContext context, final RegisteredService registeredService) {
        context.getFlowScope().put(PARAMETER_REGISTERED_SERVICE, registeredService);
    }"
"public int execute(final String user, final List<String> command) throws IOException {
    log.info(""Command: "" + command);
    final Process process = new ProcessBuilder()
        .command(constructExecuteAsCommand(user, command))
        .inheritIO()
        .start();

    int exitCode;
    try {
      exitCode = process.waitFor();
    } catch (final InterruptedException e) {
      log.error(e.getMessage(), e);
      exitCode = 1;
    }
    return exitCode;
  }"
"@Override
   public void setHealthCheckRegistry(Object healthCheckRegistry)
   {
      boolean isAlreadySet = getHealthCheckRegistry() != null;
      super.setHealthCheckRegistry(healthCheckRegistry);

      HikariPool p = pool;
      if (p != null) {
         if (isAlreadySet) {
            throw new IllegalStateException(""HealthCheckRegistry can only be set one time"");
         }
         else {
            p.setHealthCheckRegistry(super.getHealthCheckRegistry());
         }
      }
   }"
"@SuppressWarnings(""unchecked"")
	public <T> SqlBuilder in(String field, T... values) {
		sql.append(wrapper.wrap(field)).append("" IN "").append(""("").append(ArrayUtil.join(values, StrUtil.COMMA)).append("")"");
		return this;
	}"
"@Deprecated
	@PublicEvolving
	public Integer getIntCounterResult(String accumulatorName) {
		Object result = this.accumulatorResults.get(accumulatorName).getUnchecked();
		if (result == null) {
			return null;
		}
		if (!(result instanceof Integer)) {
			throw new ClassCastException(""Requested result of the accumulator '"" + accumulatorName
							+ ""' should be Integer but has type "" + result.getClass());
		}
		return (Integer) result;
	}"
"protected void teardown() throws Exception {
    logger.fine(""shutting down channels"");
    for (ManagedChannel channel : channels) {
      channel.shutdown();
    }
    logger.fine(""shutting down server"");
    server.shutdown();
    if (!server.awaitTermination(5, TimeUnit.SECONDS)) {
      logger.warning(""Failed to shutdown server"");
    }
    logger.fine(""server shut down"");
    for (ManagedChannel channel : channels) {
      if (!channel.awaitTermination(1, TimeUnit.SECONDS)) {
        logger.warning(""Failed to shutdown client"");
      }
    }
    logger.fine(""channels shut down"");
  }"
"public static Thread addShutdownHook(
		final AutoCloseable service,
		final String serviceName,
		final Logger logger) {

		checkNotNull(service);
		checkNotNull(logger);

		final Thread shutdownHook = new Thread(() -> {
			try {
				service.close();
			} catch (Throwable t) {
				logger.error(""Error during shutdown of {} via JVM shutdown hook."", serviceName, t);
			}
		}, serviceName + "" shutdown hook"");

		return addShutdownHookThread(shutdownHook, serviceName, logger) ? shutdownHook : null;
	}"
"public ParameterTool mergeWith(ParameterTool other) {
		final Map<String, String> resultData = new HashMap<>(data.size() + other.data.size());
		resultData.putAll(data);
		resultData.putAll(other.data);

		final ParameterTool ret = new ParameterTool(resultData);

		final HashSet<String> requestedParametersLeft = new HashSet<>(data.keySet());
		requestedParametersLeft.removeAll(unrequestedParameters);

		final HashSet<String> requestedParametersRight = new HashSet<>(other.data.keySet());
		requestedParametersRight.removeAll(other.unrequestedParameters);

		ret.unrequestedParameters.removeAll(requestedParametersLeft);
		ret.unrequestedParameters.removeAll(requestedParametersRight);

		return ret;
	}"
"public static byte[] intArrayToBytes(Collection<Integer> values)
    {
        ByteBuffer buffer = ByteBuffer.allocate(values.size() * Integer.BYTES);
        for (int value : values) {
            buffer.putInt(value);
        }
        return buffer.array();
    }"
"protected JComboBox<AuthenticationMethodType> getAuthenticationMethodsComboBox() {
		if (authenticationMethodsComboBox == null) {
			Vector<AuthenticationMethodType> methods = new Vector<>(extension.getAuthenticationMethodTypes());
			authenticationMethodsComboBox = new JComboBox<>(methods);
			authenticationMethodsComboBox.setSelectedItem(null);

			// Prepare the listener for the change of selection
			authenticationMethodsComboBox.addItemListener(new ItemListener() {

				@Override
				public void itemStateChanged(ItemEvent e) {
					if (e.getStateChange() == ItemEvent.SELECTED && !e.getItem().equals(shownMethodType)) {
						log.debug(""Selected new Authentication type: "" + e.getItem());

						AuthenticationMethodType type = ((AuthenticationMethodType) e.getItem());
						if (shownMethodType == null || type.getAuthenticationCredentialsType() != shownMethodType
								.getAuthenticationCredentialsType()) {

							if (needsConfirm && !confirmAndResetUsersCredentials(type)) {
								log.debug(""Cancelled change of authentication type."");

								authenticationMethodsComboBox.setSelectedItem(shownMethodType);
								return;
							}
						}
						resetLoggedInOutIndicators();

						// If no authentication method was previously selected or it's a different
						// class, create a new authentication method object
						if (selectedAuthenticationMethod == null
								|| !type.isTypeForMethod(selectedAuthenticationMethod)) {
							selectedAuthenticationMethod = type.createAuthenticationMethod(getContextIndex());
						}

						// Show the configuration panel
						changeMethodConfigPanel(type);
						if (type.hasOptionsPanel()) {
							shownConfigPanel.bindMethod(selectedAuthenticationMethod, getAuthenticationIndicatorsPanel());
						}
					}
				}
			});
		}
		return authenticationMethodsComboBox;
	}"
"public static MemorySegment allocateUnpooledOffHeapMemory(int size, Object owner) {
		ByteBuffer memory = ByteBuffer.allocateDirect(size);
		return wrapPooledOffHeapMemory(memory, owner);
	}"
"@Deprecated
    @Nonnull
    public List<Action> getActions() {
        //this double checked synchronization is only safe if the field 'actions' is volatile
        if (actions == null) {
            synchronized (this) {
                if (actions == null) {
                    actions = new CopyOnWriteArrayList<>();
                }
            }
        }
        return actions;
    }"
"@Override
	public final byte get(int index) {
		final long pos = address + index;
		if (index >= 0 && pos < addressLimit) {
			return UNSAFE.getByte(heapMemory, pos);
		}
		else if (address > addressLimit) {
			throw new IllegalStateException(""segment has been freed"");
		}
		else {
			// index is in fact invalid
			throw new IndexOutOfBoundsException();
		}
	}"
"@Nonnull
  private DruidConnection getDruidConnection(final String connectionId)
  {
    final DruidConnection connection = connections.get(connectionId);

    if (connection == null) {
      throw new NoSuchConnectionException(connectionId);
    }

    return connection.sync(
        exec.schedule(
            () -> {
              log.debug(""Connection[%s] timed out."", connectionId);
              closeConnection(new ConnectionHandle(connectionId));
            },
            new Interval(DateTimes.nowUtc(), config.getConnectionIdleTimeout()).toDurationMillis(),
            TimeUnit.MILLISECONDS
        )
    );
  }"
"private void readBody(InputStream in) throws IORuntimeException {
		if (ignoreBody) {
			return;
		}

		int contentLength = Convert.toInt(header(Header.CONTENT_LENGTH), 0);
		final FastByteArrayOutputStream out = contentLength > 0 ? new FastByteArrayOutputStream(contentLength) : new FastByteArrayOutputStream();
		try {
			IoUtil.copy(in, out);
		} catch (IORuntimeException e) {
			if (e.getCause() instanceof EOFException || StrUtil.containsIgnoreCase(e.getMessage(), ""Premature EOF"")) {
				// 忽略读取HTTP流中的EOF错误
			} else {
				throw e;
			}
		}
		this.bodyBytes = out.toByteArray();
	}"
"public SDVariable matchConditionCount(SDVariable in, Condition condition, boolean keepDims, int... dimensions) {
        return new MatchCondition(sameDiff(), in, condition, keepDims, dimensions).outputVariable();
    }"
"public void addAuthToken(ClientRequest request, String token) {
        if(token != null && !token.startsWith(""Bearer "")) {
            if(token.toUpperCase().startsWith(""BEARER "")) {
                // other cases of Bearer
                token = ""Bearer "" + token.substring(7);
            } else {
                token = ""Bearer "" + token;
            }
        }
        request.getRequestHeaders().put(Headers.AUTHORIZATION, token);
    }"
"private JPanel getJPanel1() {
		if (jPanel1 == null) {
			jLabel2 = new JLabel();
			GridBagConstraints gridBagConstraints8 = new GridBagConstraints();
			GridBagConstraints gridBagConstraints7 = new GridBagConstraints();
			GridBagConstraints gridBagConstraints9 = new GridBagConstraints();
			jPanel1 = new JPanel();
			jPanel1.setLayout(new GridBagLayout());
			gridBagConstraints7.gridx = 1;
			gridBagConstraints7.gridy = 0;
			gridBagConstraints7.insets = new java.awt.Insets(5,5,5,5);
			gridBagConstraints7.anchor = java.awt.GridBagConstraints.EAST;
			gridBagConstraints8.gridx = 2;
			gridBagConstraints8.gridy = 0;
			gridBagConstraints8.insets = new java.awt.Insets(5,5,5,5);
			gridBagConstraints8.anchor = java.awt.GridBagConstraints.EAST;
			jLabel2.setText("" "");
			gridBagConstraints9.anchor = java.awt.GridBagConstraints.EAST;
			gridBagConstraints9.fill = java.awt.GridBagConstraints.HORIZONTAL;
			gridBagConstraints9.insets = new java.awt.Insets(5,2,5,2);
			gridBagConstraints9.weightx = 1.0D;
			gridBagConstraints9.gridx = 0;
			gridBagConstraints9.gridy = 0;
			jPanel1.add(jLabel2, gridBagConstraints9);
			jPanel1.add(getBtnOK(), gridBagConstraints7);
			jPanel1.add(getBtnCancel(), gridBagConstraints8);
		}
		return jPanel1;
	}"
"public void init(INDArray parameters, boolean cloneParametersArray) {
        if (initCalled)
            return;

        DataType netDtype = getConfiguration().getDataType();
        if(parameters != null && parameters.dataType() != netDtype){
            if(cloneParametersArray){
                try(MemoryWorkspace ws = Nd4j.getWorkspaceManager().scopeOutOfWorkspaces()) {
                    parameters = parameters.castTo(netDtype);
                }
            } else {
                throw new IllegalStateException(""Error initializing network: Network datatype is set to "" + netDtype
                        + "" but provided array has datatype "" + parameters.dataType() + "" with cloneParametersArray argument"" +
                        "" set to false. Cannot initialize net with specified datatype array if that array does not match network datatype"");
            }
        }

        if (configuration.getTrainingWorkspaceMode() == null)
            configuration.setTrainingWorkspaceMode(WorkspaceMode.NONE);

        if (configuration.getInferenceWorkspaceMode() == null)
            configuration.setInferenceWorkspaceMode(WorkspaceMode.NONE);

        if (configuration.getCacheMode() == null)
            configuration.setCacheMode(CacheMode.NONE);

        OneTimeLogger.info(log, ""Starting ComputationGraph with WorkspaceModes set to [training: {}; inference: {}], cacheMode set to [{}]"",
                configuration.getTrainingWorkspaceMode(), configuration.getInferenceWorkspaceMode(), configuration.getCacheMode());

        //First: build topological ordering, based on configuration. Used for forward pass, backprop and order of parameters/gradients
        GraphIndices indices = calculateIndices();
        topologicalOrder = indices.getTopologicalSortOrder();

        //Initialization: create the GraphVertex objects, based on configuration structure
        Map<String, org.deeplearning4j.nn.conf.graph.GraphVertex> configVertexMap = configuration.getVertices();

        //Names of all of the (data) inputs to the ComputationGraph
        List<String> networkInputNames = configuration.getNetworkInputs();

        //Inputs for each layer and GraphNode:
        Map<String, List<String>> vertexInputs = configuration.getVertexInputs();
        this.vertices = new GraphVertex[networkInputNames.size() + configuration.getVertices().size()];

        //All names: inputs, layers and graph nodes (index to name map)
        Map<String, Integer> allNamesReverse = new HashMap<>();

        //Create network input vertices:
        int vertexNumber = 0;
        for (String name : networkInputNames) {
            GraphVertex gv = new InputVertex(this, name, vertexNumber, null, netDtype); //Output vertices: set later
            allNamesReverse.put(name, vertexNumber);
            vertices[vertexNumber++] = gv;
        }

        //Go through layers, and work out total number of parameters. Then allocate full parameters array
        long numParams = 0;
        long[] numParamsForVertex = new long[topologicalOrder.length];
        int i = 0;
        for (; i < configuration.getNetworkInputs().size(); i++) {
            numParamsForVertex[i] = 0; //No parameters for input vertices
        }
        for(; i<topologicalOrder.length; i++ ){
            String name = indices.getIdxToName().get(i);
            org.deeplearning4j.nn.conf.graph.GraphVertex n = configVertexMap.get(name);
            numParamsForVertex[i] = n.numParams(true);
            numParams += numParamsForVertex[i];
        }

        boolean initializeParams;
        if (parameters != null) {
            if (!parameters.isRowVectorOrScalar())
                throw new IllegalArgumentException(""Invalid parameters: should be a row vector"");
            if (parameters.length() != numParams)
                throw new IllegalArgumentException(""Invalid parameters: expected length "" + numParams + "", got length ""
                        + parameters.length());

            if (cloneParametersArray)
                flattenedParams = parameters.dup();
            else
                flattenedParams = parameters;

            initializeParams = false;
        } else if(numParams > 0){
            flattenedParams = Nd4j.create(netDtype, 1, numParams);
            initializeParams = true;
        } else {
            flattenedParams = null;
            initializeParams = false;
        }

        //Set RNG seed, for repeatability between initializations when set
        if (initializeParams) {
            Nd4j.getRandom().setSeed(conf().getSeed());
        }

        //Given the topological ordering: work out the subset of the parameters array used for each layer
        // Then extract out for use when initializing the Layers
        INDArray[] paramsViewForVertex = new INDArray[topologicalOrder.length];
        long paramOffsetSoFar = 0;
        i = 0;
        for (int vertexIdx : topologicalOrder) {
            long nParamsThisVertex = numParamsForVertex[vertexIdx];
            if (nParamsThisVertex != 0) {
                paramsViewForVertex[vertexIdx] = flattenedParams.get(NDArrayIndex.interval(0,0,true),
                        NDArrayIndex.interval(paramOffsetSoFar, paramOffsetSoFar + nParamsThisVertex));
            }
            i++;
            paramOffsetSoFar += nParamsThisVertex;
        }


        int numLayers = 0;
        List<Layer> tempLayerList = new ArrayList<>();
        defaultConfiguration.clearVariables();
        List<String> variables = defaultConfiguration.variables(false);
        i = configuration.getNetworkInputs().size();
        for(; i<topologicalOrder.length; i++ ){
            String name = indices.getIdxToName().get(i);
            org.deeplearning4j.nn.conf.graph.GraphVertex n = configVertexMap.get(name);

            GraphVertex gv = n.instantiate(this, name, vertexNumber, paramsViewForVertex[vertexNumber],
                    initializeParams, netDtype);

            if(gv == null){
                throw new IllegalStateException(""Encountered null layer/vertex during initialization for layer \"""" + name +
                        ""\"": "" + n.getClass().getSimpleName() + "" initialization returned null layer/vertex?"");
            }

            if (gv.hasLayer()) {
                numLayers++;
                Layer l = gv.getLayer();
                tempLayerList.add(l);
                List<String> layerVariables = l.conf().variables();
                if (layerVariables != null) {
                    for (String s : layerVariables) {
                        variables.add(gv.getVertexName() + ""_"" + s);
                    }
                }
            }

            allNamesReverse.put(name, vertexNumber);
            vertices[vertexNumber++] = gv;
        }
        layers = tempLayerList.toArray(new Layer[numLayers]);

        //Create the lookup table, so we can find vertices easily by name
        verticesMap = new HashMap<>();
        for (GraphVertex gv : vertices) {
            verticesMap.put(gv.getVertexName(), gv);
        }

        //Now: do another pass to set the input and output indices, for each vertex
        // These indices are used during forward and backward passes
        //To get output indices: need to essentially build the graph in reverse...
        Map<String, List<String>> verticesOutputTo = new HashMap<>(); //Key: vertex. Values: vertices that this node is an input for
        for (GraphVertex gv : vertices) {
            String vertexName = gv.getVertexName();
            List<String> vertexInputNames;
            vertexInputNames = vertexInputs.get(vertexName);

            if (vertexInputNames == null)
                continue;

            //Build reverse network structure:
            for (String s : vertexInputNames) {
                List<String> list = verticesOutputTo.get(s);
                if (list == null) {
                    list = new ArrayList<>();
                    verticesOutputTo.put(s, list);
                }
                list.add(vertexName); //Edge: s -> vertexName
            }
        }


        for (GraphVertex gv : vertices) {
            String vertexName = gv.getVertexName();
            int vertexIndex = gv.getVertexIndex();
            List<String> vertexInputNames;
            vertexInputNames = vertexInputs.get(vertexName);

            if (vertexInputNames == null)
                continue;

            VertexIndices[] inputIndices = new VertexIndices[vertexInputNames.size()];
            for (int j = 0; j < vertexInputNames.size(); j++) {
                String inName = vertexInputNames.get(j);
                int inputVertexIndex = allNamesReverse.get(inName);

                //Here: we have x -> gv connection
                //gv might have multiple inputs, not just x
                //Need to know which input x is
                int inputNumber = vertexInputs.get(vertexName).indexOf(inName);

                if (inputNumber == -1)
                    throw new IllegalStateException(""Could not find vertex "" + vertexIndex + "" in the list of inputs ""
                            + ""for vertex "" + gv.getVertexName() + ""; error in graph structure?"");

                inputIndices[j] = new VertexIndices(inputVertexIndex, inputNumber);
            }

            gv.setInputVertices(inputIndices);
        }

        //Handle the outputs for this vertex
        for (GraphVertex gv : vertices) {
            String vertexName = gv.getVertexName();

            List<String> thisVertexOutputsTo = verticesOutputTo.get(vertexName);

            if (thisVertexOutputsTo == null || thisVertexOutputsTo.isEmpty())
                continue; //Output vertex
            VertexIndices[] outputIndices = new VertexIndices[thisVertexOutputsTo.size()];
            int j = 0;
            for (String s : new HashSet<>(thisVertexOutputsTo)) {
                //First, we have gv -> s
                //Which input in s does gv connect to? s may in general have multiple inputs...
                List<String> nextVertexInputNames = vertexInputs.get(s);

                for (int k = 0; k < nextVertexInputNames.size(); k++) {
                    if(vertexName.equals(nextVertexInputNames.get(k))){
                        int outputVertexIndex = allNamesReverse.get(s);
                        outputIndices[j++] = new VertexIndices(outputVertexIndex, k);
                    }
                }
            }
            gv.setOutputVertices(outputIndices);
        }

        //Mark any output vertices as outputs:
        for (String s : configuration.getNetworkOutputs()) {
            GraphVertex gv = verticesMap.get(s);
            gv.setOutputVertex(true);
        }

        // now we init solver & optimizer
        if (solver == null) {
            try (MemoryWorkspace wsO = Nd4j.getMemoryManager().scopeOutOfWorkspaces()) {
                solver = new Solver.Builder().configure(conf()).listeners(getListeners()).model(this).build();
                solver.initOptimizer();
            }
        }

        //Mark which layers can safely modify their input in-place. This is a performance optimization for
        // dropout and similar operations.
        // Safe when the input is: (a) it's not a graph input, and (b) isn't shared by any other layers/vertices

        Map<String,List<String>> seenAsInputTo = new HashMap<>();
        for(Map.Entry<String,List<String>> entry : configuration.getVertexInputs().entrySet()){
            for(String s : entry.getValue() ){
                if (!seenAsInputTo.containsKey(s)) {
                    seenAsInputTo.put(s, new ArrayList<String>());
                }
                List<String> seen = seenAsInputTo.get(s);
                seen.add(entry.getKey());
            }
        }

        for(Layer l : layers){
            String layerName = l.conf().getLayer().getLayerName();
            List<String> inputs = configuration.getVertexInputs().get(layerName);
            String in = inputs.get(0);  //For now: layers should have exactly 1 input

            if(configuration.getNetworkInputs().contains(in)){
                //TODO When is it safe to NOT allow input modifucation? It's not always safe...
                // For example dropout + iterating over List<MultiDataSet> that is used for multiple epochs...
                continue;
            }

            List<String> seen = seenAsInputTo.get(in);
            if(seen.size() == 1){
                l.allowInputModification(true);
            } else {
                //For the count > 1 case, we can work out if it's the last one in the topological order... at which point,
                // it should be safe to use
                int thisIdx = indices.getNameToIdx().get(layerName);
                int thisTopoPos = ArrayUtils.indexOf(indices.getTopologicalSortOrder(), thisIdx);
                int maxTopoPosition = -1;
                for(String s : seen){
                    int idx = indices.getNameToIdx().get(s);
                    int topoPos = ArrayUtils.indexOf(indices.getTopologicalSortOrder(), idx);
                    maxTopoPosition = Math.max(maxTopoPosition, topoPos);
                }

                if(thisTopoPos == maxTopoPosition){
                    //Last one in the topo sort... all other layers have already consumed this input by the time this layer's
                    // forward pass is done
                    l.allowInputModification(true);
                }   //Otherwise: keep default of false
            }
        }

        synchronizeIterEpochCounts();
        initCalled = true;
    }"
"public static <T> TreeSet<T> newSortedSet(@Nullable Comparator<? super T> comparator) {
		return Sets.newTreeSet(comparator);
	}"
"public static int getUsableLocalPort(int minPort, int maxPort) {
		for (int i = minPort; i <= maxPort; i++) {
			if (isUsableLocalPort(RandomUtil.randomInt(minPort, maxPort + 1))) {
				return i;
			}
		}

		throw new UtilException(""Could not find an available port in the range [{}, {}] after {} attempts"", minPort, maxPort, maxPort - minPort);
	}"
"public static boolean bitGet(MemorySegment[] segments, int baseOffset, int index) {
		int offset = baseOffset + ((index & BIT_BYTE_POSITION_MASK) >>> 3);
		byte current = getByte(segments, offset);
		return (current & (1 << (index & BIT_BYTE_INDEX_MASK))) != 0;
	}"
"private MethodDeclaration generateStaticFillValuesMethod(EclipseNode tdParent, String builderClassName, TypeParameter[] typeParams, java.util.List<BuilderFieldData> builderFields, ASTNode source) {
		MethodDeclaration out = new MethodDeclaration(((CompilationUnitDeclaration) tdParent.top().get()).compilationResult);
		out.selector = FILL_VALUES_STATIC_METHOD_NAME;
		out.bits |= ECLIPSE_DO_NOT_TOUCH_FLAG;
		out.modifiers = ClassFileConstants.AccPrivate | ClassFileConstants.AccStatic;
		out.returnType = TypeReference.baseTypeReference(TypeIds.T_void, 0);
		
		TypeReference[] wildcards = new TypeReference[] {new Wildcard(Wildcard.UNBOUND), new Wildcard(Wildcard.UNBOUND)};
		TypeReference builderType = new ParameterizedSingleTypeReference(builderClassName.toCharArray(), mergeToTypeReferences(typeParams, wildcards), 0, 0);
		Argument builderArgument = new Argument(BUILDER_VARIABLE_NAME, 0, builderType, Modifier.FINAL);
		TypeReference parentArgument = createTypeReferenceWithTypeParameters(tdParent.getName(), typeParams);
		out.arguments = new Argument[] {new Argument(INSTANCE_VARIABLE_NAME, 0, parentArgument, Modifier.FINAL), builderArgument};

		// Add type params if there are any.
		if (typeParams.length > 0) out.typeParameters = copyTypeParams(typeParams, source);

		List<Statement> body = new ArrayList<Statement>();

		// Call the builder's setter methods to fill the values from the instance.
		for (BuilderFieldData bfd : builderFields) {
			MessageSend exec = createSetterCallWithInstanceValue(bfd, tdParent, source);
			body.add(exec);
		}
		
		out.statements = body.isEmpty() ? null : body.toArray(new Statement[0]);
		
		return out;
	}"
"public static ComputeEngineChannelBuilder forAddress(String name, int port) {
    return forTarget(GrpcUtil.authorityFromHostAndPort(name, port));
  }"
"public KvStateID registerKvState(
			JobID jobId,
			JobVertexID jobVertexId,
			KeyGroupRange keyGroupRange,
			String registrationName,
			InternalKvState<?, ?, ?> kvState) {

		KvStateID kvStateId = new KvStateID();

		if (registeredKvStates.putIfAbsent(kvStateId, new KvStateEntry<>(kvState)) == null) {
			final KvStateRegistryListener listener = getKvStateRegistryListener(jobId);

			if (listener != null) {
				listener.notifyKvStateRegistered(
					jobId,
					jobVertexId,
					keyGroupRange,
					registrationName,
					kvStateId);
			}

			return kvStateId;
		} else {
			throw new IllegalStateException(
					""State \"""" + registrationName + "" \""(id="" + kvStateId + "") appears registered although it should not."");
		}
	}"
"public void set(long index, Slice value)
    {
        updateRetainedSize(index, value);
        array.set(index, value);
    }"
"public static Charset getCharset(HttpMessage message, Charset defaultCharset) {
        CharSequence contentTypeValue = message.headers().get(HttpHeaderNames.CONTENT_TYPE);
        if (contentTypeValue != null) {
            return getCharset(contentTypeValue, defaultCharset);
        } else {
            return defaultCharset;
        }
    }"
"public static Optional<String> getSessionId(String uri) {
    int sessionIndex = uri.indexOf(""/session/"");
    if (sessionIndex != -1) {
      sessionIndex += ""/session/"".length();
      int nextSlash = uri.indexOf(""/"", sessionIndex);
      if (nextSlash != -1) {
        return Optional.of(uri.substring(sessionIndex, nextSlash));
      }
      return Optional.of(uri.substring(sessionIndex));
    }
    return Optional.empty();
  }"
"public final AlertDialog initiateScan(Collection<String> desiredBarcodeFormats, int cameraId) {
    Intent intentScan = new Intent(BS_PACKAGE + "".SCAN"");
    intentScan.addCategory(Intent.CATEGORY_DEFAULT);

    // check which types of codes to scan for
    if (desiredBarcodeFormats != null) {
      // set the desired barcode types
      StringBuilder joinedByComma = new StringBuilder();
      for (String format : desiredBarcodeFormats) {
        if (joinedByComma.length() > 0) {
          joinedByComma.append(',');
        }
        joinedByComma.append(format);
      }
      intentScan.putExtra(""SCAN_FORMATS"", joinedByComma.toString());
    }

    // check requested camera ID
    if (cameraId >= 0) {
      intentScan.putExtra(""SCAN_CAMERA_ID"", cameraId);
    }

    String targetAppPackage = findTargetAppPackage(intentScan);
    if (targetAppPackage == null) {
      return showDownloadDialog();
    }
    intentScan.setPackage(targetAppPackage);
    intentScan.addFlags(Intent.FLAG_ACTIVITY_CLEAR_TOP);
    intentScan.addFlags(FLAG_NEW_DOC);
    attachMoreExtras(intentScan);
    startActivityForResult(intentScan, REQUEST_CODE);
    return null;
  }"
"@Override
	public void createTable(ObjectPath tablePath, CatalogBaseTable table, boolean ignoreIfExists)
		throws TableAlreadyExistException, DatabaseNotExistException {
		checkNotNull(tablePath);
		checkNotNull(table);

		if (!databaseExists(tablePath.getDatabaseName())) {
			throw new DatabaseNotExistException(catalogName, tablePath.getDatabaseName());
		}

		if (tableExists(tablePath)) {
			if (!ignoreIfExists) {
				throw new TableAlreadyExistException(catalogName, tablePath);
			}
		} else {
			tables.put(tablePath, table.copy());

			if ((table instanceof CatalogTable) && ((CatalogTable) table).isPartitioned()) {
				partitions.put(tablePath, new LinkedHashMap<>());
			}
		}
	}"
"public void setMinFrame(final int minFrame) {
    if (composition == null) {
      lazyCompositionTasks.add(new LazyCompositionTask() {
        @Override
        public void run(LottieComposition composition) {
          setMinFrame(minFrame);
        }
      });
      return;
    }
    animator.setMinFrame(minFrame);
  }"
"public long[] getLongs(int rowId, int count) {
    long[] res = new long[count];
    for (int i = 0; i < count; i++) {
      res[i] = getLong(rowId + i);
    }
    return res;
  }"
"public void checkSkipReadForFixLengthPart(AbstractPagedInputView source) throws IOException {
		// skip if there is no enough size.
		// Note: Use currentSegmentLimit instead of segmentSize.
		int available = source.getCurrentSegmentLimit() - source.getCurrentPositionInSegment();
		if (available < getSerializedRowFixedPartLength()) {
			source.advance();
		}
	}"
"public static Layout forFile(File file) {
		if (file == null) {
			throw new IllegalArgumentException(""File must not be null"");
		}
		String lowerCaseFileName = file.getName().toLowerCase(Locale.ENGLISH);
		if (lowerCaseFileName.endsWith("".jar"")) {
			return new Jar();
		}
		if (lowerCaseFileName.endsWith("".war"")) {
			return new War();
		}
		if (file.isDirectory() || lowerCaseFileName.endsWith("".zip"")) {
			return new Expanded();
		}
		throw new IllegalStateException(""Unable to deduce layout for '"" + file + ""'"");
	}"
"public static List<Row> stdDevMeanColumns(DataRowsFacade data, String... columns) {
        return aggregate(data, columns, new String[] {""stddev"", ""mean""});
    }"
"public static String rowToString(JSONArray ja) {
    StringBuilder sb = new StringBuilder();
    for (int i = 0; i < ja.length(); i += 1) {
      if (i > 0) {
        sb.append(',');
      }
      Object o = ja.opt(i);
      if (o != null) {
        String s = o.toString();
        if (s.length() > 0 && (s.indexOf(',') >= 0 || s.indexOf('\n') >= 0 || s.indexOf('\r') >= 0 || s.indexOf(0) >= 0 || s.charAt(0) == '""')) {
          sb.append('""');
          int length = s.length();
          for (int j = 0; j < length; j += 1) {
            char c = s.charAt(j);
            if (c >= ' ' && c != '""') {
              sb.append(c);
            }
          }
          sb.append('""');
        } else {
          sb.append(s);
        }
      }
    }
    sb.append('\n');
    return sb.toString();
  }"
"public static WSFederationRequest of(final HttpServletRequest request) {
        val wtrealm = request.getParameter(WSFederationConstants.WTREALM);
        val wreply = request.getParameter(WSFederationConstants.WREPLY);
        val wreq = request.getParameter(WSFederationConstants.WREQ);
        val wctx = request.getParameter(WSFederationConstants.WCTX);
        val wfresh = request.getParameter(WSFederationConstants.WREFRESH);
        val whr = request.getParameter(WSFederationConstants.WHR);
        val wresult = request.getParameter(WSFederationConstants.WRESULT);
        val relayState = request.getParameter(WSFederationConstants.RELAY_STATE);
        val samlResponse = request.getParameter(WSFederationConstants.SAML_RESPONSE);
        val state = request.getParameter(WSFederationConstants.STATE);
        val code = request.getParameter(WSFederationConstants.CODE);
        val wa = request.getParameter(WSFederationConstants.WA);
        val wauth = StringUtils.defaultIfBlank(request.getParameter(WSFederationConstants.WAUTH), ""default"");
        return new WSFederationRequest(wtrealm, wreply, wctx, wfresh, whr, wresult,
            relayState, samlResponse, state, code, wa, wauth, wreq);
    }"
"public Class<?>[] getClasses(String name, Class<?>... defaultValue) {
        String[] classnames = getStrings(name);
        if (classnames == null)
            return defaultValue;
        try {
            Class<?>[] classes = new Class<?>[classnames.length];
            for (int i = 0; i < classnames.length; i++) {
                classes[i] = getClassByName(classnames[i]);
            }
            return classes;
        } catch (ClassNotFoundException e) {
            throw new RuntimeException(e);
        }
    }"
"public static Word2Vec fromPair(Pair<InMemoryLookupTable, VocabCache> pair) {
        Word2Vec vectors = new Word2Vec();
        vectors.setLookupTable(pair.getFirst());
        vectors.setVocab(pair.getSecond());
        vectors.setModelUtils(new BasicModelUtils());
        return vectors;
    }"
"protected void reportAllElementKeyGroups() {

		Preconditions.checkState(partitioningSource.length >= numberOfElements);

		for (int i = 0; i < numberOfElements; ++i) {
			int keyGroup = KeyGroupRangeAssignment.assignToKeyGroup(
				keyExtractorFunction.extractKeyFromElement(partitioningSource[i]), totalKeyGroups);
			reportKeyGroupOfElementAtIndex(i, keyGroup);
		}
	}"
"@Override
    public void shuffle(List<INDArray> arrays, Random rnd, List<int[]> dimensions) {
        // no dimension - no shuffle
        if (dimensions == null || dimensions.size() == 0)
            throw new RuntimeException(""Dimension can't be null or 0-length"");

        if (arrays == null || arrays.size() == 0)
            throw new RuntimeException(""No input arrays provided"");

        if (dimensions.size() > 1 && arrays.size() != dimensions.size())
            throw new IllegalStateException(""Number of dimensions do not match number of arrays to shuffle"");

        Nd4j.getExecutioner().push();

        // first we build TAD for input array and dimensions

        AtomicAllocator allocator = AtomicAllocator.getInstance();

        CudaContext context = null;

        for (int x = 0; x < arrays.size(); x++) {
            context = allocator.getFlowController().prepareAction(arrays.get(x));
        }

        val zero = arrays.get(0);
        int tadLength = 1;
        if (zero.rank() > 1)
            for (int i = 0; i < dimensions.get(0).length; i++) {
                tadLength *= zero.shape()[dimensions.get(0)[i]];
            }

        val numTads = zero.length() / tadLength;

        val map = ArrayUtil.buildInterleavedVector(rnd, (int) numTads);

        val shuffle = new CudaIntDataBuffer(map);

        val shuffleMap = allocator.getPointer(shuffle, context);

        val extras = new PointerPointer(null, // not used
                        context.getOldStream(), allocator.getDeviceIdPointer());


        long[] hPointers = new long[arrays.size()];
        long[] xPointers = new long[arrays.size()];
        long[] xShapes = new long[arrays.size()];
        long[] tadShapes = new long[arrays.size()];
        long[] tadOffsets = new long[arrays.size()];

        for (int i = 0; i < arrays.size(); i++) {
            val array = arrays.get(i);

            val x = AtomicAllocator.getInstance().getPointer(array, context);
            val xShapeInfo = AtomicAllocator.getInstance().getPointer(array.shapeInfoDataBuffer(), context);


            val tadManager = Nd4j.getExecutioner().getTADManager();

            int[] dimension = dimensions.size() > 1 ? dimensions.get(i) : dimensions.get(0);

            val tadBuffers = tadManager.getTADOnlyShapeInfo(array, dimension);

//            log.info(""Original shape: {}; dimension: {}; TAD shape: {}"", array.shapeInfoDataBuffer().asInt(), dimension, tadBuffers.getFirst().asInt());

            val tadShapeInfo = AtomicAllocator.getInstance().getPointer(tadBuffers.getFirst(), context);

            val offsets = tadBuffers.getSecond();

            if (zero.rank() != 1 && offsets.length() != numTads)
                throw new ND4JIllegalStateException(""Can't symmetrically shuffle arrays with non-equal number of TADs"");

            val tadOffset = AtomicAllocator.getInstance().getPointer(offsets, context);

            hPointers[i] = AtomicAllocator.getInstance().getHostPointer(array.shapeInfoDataBuffer()).address();
            xPointers[i] = x.address();
            xShapes[i] = xShapeInfo.address();
            tadShapes[i] = tadShapeInfo.address();
            tadOffsets[i] = tadOffset.address();
        }


        val hostPointers = new LongPointer(hPointers);
        val hosthost = new PointerPointerWrapper(hostPointers);
        val tempX = new CudaDoubleDataBuffer(arrays.size());
        val tempShapes = new CudaDoubleDataBuffer(arrays.size());
        val tempTAD = new CudaDoubleDataBuffer(arrays.size());
        val tempOffsets = new CudaDoubleDataBuffer(arrays.size());

        AtomicAllocator.getInstance().memcpyBlocking(tempX, new LongPointer(xPointers), xPointers.length * 8, 0);
        AtomicAllocator.getInstance().memcpyBlocking(tempShapes, new LongPointer(xShapes), xPointers.length * 8, 0);
        AtomicAllocator.getInstance().memcpyBlocking(tempTAD, new LongPointer(tadShapes), xPointers.length * 8, 0);
        AtomicAllocator.getInstance().memcpyBlocking(tempOffsets, new LongPointer(tadOffsets), xPointers.length * 8, 0);

        nativeOps.shuffle(extras,
                            null,
                            hosthost,
                            new PointerPointer(allocator.getPointer(tempX, context)),
                            new PointerPointer(allocator.getPointer(tempShapes, context)),
                            null,
                            null,
                            new PointerPointer(allocator.getPointer(tempX, context)),
                            new PointerPointer(allocator.getPointer(tempShapes, context)), arrays.size(),
                            (IntPointer) shuffleMap, new PointerPointer(allocator.getPointer(tempTAD, context)),
                            new PointerPointer(allocator.getPointer(tempOffsets, context)));

        for (int f = 0; f < arrays.size(); f++) {
            allocator.getFlowController().registerAction(context, arrays.get(f));
        }


        // just to keep reference
        shuffle.address();
        hostPointers.address();

        tempX.dataType();
        tempShapes.dataType();
        tempOffsets.dataType();
        tempTAD.dataType();
    }"
"@SuppressWarnings(""unchecked"")
	private Map<String, Object> safeSerialize(ObjectMapper mapper, Object bean,
			String prefix) {
		try {
			return new HashMap<>(mapper.convertValue(bean, Map.class));
		}
		catch (Exception ex) {
			return new HashMap<>(Collections.singletonMap(""error"",
					""Cannot serialize '"" + prefix + ""'""));
		}
	}"
"@Override
    public final void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
        try {
            onChannelReadComplete(ctx);
        } finally {
            parentReadInProgress = false;
            tail = head = null;
            // We always flush as this is what Http2ConnectionHandler does for now.
            flush0(ctx);
        }
        channelReadComplete0(ctx);
    }"
"public List<String> asLabels() {
        List<String> labels = new ArrayList<>();
        for (T element : getElements()) {
            labels.add(element.getLabel());
        }
        return labels;
    }"
"public static S3RecoverableFsDataOutputStream newStream(
			final RecoverableMultiPartUpload upload,
			final FunctionWithException<File, RefCountedFile, IOException> tmpFileCreator,
			final long userDefinedMinPartSize) throws IOException {

		checkArgument(userDefinedMinPartSize >= S3_MULTIPART_MIN_PART_SIZE);

		final RefCountedBufferingFileStream fileStream = boundedBufferingFileStream(tmpFileCreator, Optional.empty());

		return new S3RecoverableFsDataOutputStream(
				upload,
				tmpFileCreator,
				fileStream,
				userDefinedMinPartSize,
				0L);
	}"
"private void ajaxIsFlowLocked(final Project project,
      final HashMap<String, Object> ret, final HttpServletRequest req)
      throws ServletException {
    final String flowName = getParam(req, FLOW_NAME_PARAM);

    final Flow flow = project.getFlow(flowName);
    if (flow == null) {
      ret.put(ERROR_PARAM,
          ""Flow "" + flowName + "" not found in project "" + project.getName());
      return;
    }

    ret.put(FLOW_ID_PARAM, flow.getId());
    ret.put(FLOW_IS_LOCKED_PARAM, flow.isLocked());
  }"
"private static void validateEntity(Entity entity) throws DbRuntimeException {
		if (null == entity) {
			throw new DbRuntimeException(""Entity is null !"");
		}
		if (StrUtil.isBlank(entity.getTableName())) {
			throw new DbRuntimeException(""Entity`s table name is null !"");
		}
		if (entity.isEmpty()) {
			throw new DbRuntimeException(""No filed and value in this entity !"");
		}
	}"
"public void notifyOfError(Throwable error) {
		if (error != null && this.error == null) {
			this.error = error;

			// this should wake up any blocking calls
			try {
				connectedSocket.close();
			} catch (Throwable ignored) {}
			try {
				socket.close();
			} catch (Throwable ignored) {}
		}
	}"
"public boolean isExtendCommonMapper(Class<?> mapperInterface) {
        for (Class<?> mapperClass : registerClass) {
            if (mapperClass.isAssignableFrom(mapperInterface)) {
                return true;
            }
        }
        //通过 @RegisterMapper 注解自动注册的功能
        return hasRegisterMapper(mapperInterface);
    }"
"public ByteBuffer next(ByteBuffer inBytes) throws GeneralSecurityException {
    Preconditions.checkState(!isFinished(), ""Handshake has already finished."");
    HandshakerReq.Builder req =
        HandshakerReq.newBuilder()
            .setNext(
                NextHandshakeMessageReq.newBuilder()
                    .setInBytes(ByteString.copyFrom(inBytes.duplicate()))
                    .build());
    HandshakerResp resp;
    try {
      resp = handshakerStub.send(req.build());
    } catch (IOException | InterruptedException e) {
      throw new GeneralSecurityException(e);
    }
    handleResponse(resp);
    inBytes.position(inBytes.position() + resp.getBytesConsumed());
    return resp.getOutFrames().asReadOnlyByteBuffer();
  }"
"@Override
    public void initialize(Configuration conf, InputSplit split) throws IOException, InterruptedException {
        this.setConf(conf);
        this.setTrimStrings(conf.getBoolean(TRIM_STRINGS, trimStrings));
        this.setResultSetType(conf.getInt(JDBC_RESULTSET_TYPE, resultSetType));

        String jdbcUrl = conf.get(JDBC_URL);
        String driverClassName = conf.get(JDBC_DRIVER_CLASS_NAME);
        // url and driver must be both unset or both present
        if (jdbcUrl == null ^ driverClassName == null) {
            throw new IllegalArgumentException(
                ""Both jdbc url and driver class name must be provided in order to configure JDBCRecordReader's datasource"");
        }
        // Both set, initialiaze the datasource
        else if (jdbcUrl != null) {
            // FIXME : find a way to read wildcard properties from conf in order to fill the third argument bellow
            this.dataSource = new DriverDataSource(jdbcUrl, driverClassName, new Properties(), conf.get(JDBC_USERNAME),
                conf.get(JDBC_PASSWORD));
        }
        this.initializeJdbc();
    }"
"@Benchmark
  @BenchmarkMode(Mode.SampleTime)
  @OutputTimeUnit(TimeUnit.NANOSECONDS)
  public CallOptions withOption() {
    CallOptions opts = CallOptions.DEFAULT;
    for (int i = 0; i < customOptions.size(); i++) {
      opts = opts.withOption(customOptions.get(i), ""value"");
    }
    return opts;
  }"
"private static String getValue(JSONTokener x) throws JSONException {
    char c;
    char q;
    StringBuffer sb;
    do {
      c = x.next();
    } while (c == ' ' || c == '\t');
    switch (c) {
    case 0:
      return null;
    case '""':
    case '\'':
      q = c;
      sb = new StringBuffer();
      for (;;) {
        c = x.next();
        if (c == q) {
          break;
        }
        if (c == 0 || c == '\n' || c == '\r') {
          throw x.syntaxError(""Missing close quote '"" + q + ""'."");
        }
        sb.append(c);
      }
      return sb.toString();
    case ',':
      x.back();
      return """";
    default:
      x.back();
      return x.nextTo(',');
    }
  }"
"private static void registerMorse(Character abc, String dict) {
		alphabets.put(Integer.valueOf(abc), dict);
		dictionaries.put(dict, Integer.valueOf(abc));
	}"
"private static <T, K> org.apache.flink.api.common.operators.SingleInputOperator<?, T, ?> translateSelectorFunctionReducer(
		SelectorFunctionKeys<T, ?> rawKeys,
		ReduceFunction<T> function,
		TypeInformation<T> inputType,
		String name,
		Operator<T> input,
		int parallelism,
		CombineHint hint) {
		@SuppressWarnings(""unchecked"")
		final SelectorFunctionKeys<T, K> keys = (SelectorFunctionKeys<T, K>) rawKeys;

		TypeInformation<Tuple2<K, T>> typeInfoWithKey = KeyFunctions.createTypeWithKey(keys);
		Operator<Tuple2<K, T>> keyedInput = KeyFunctions.appendKeyExtractor(input, keys);

		PlanUnwrappingReduceOperator<T, K> reducer = new PlanUnwrappingReduceOperator<>(function, keys, name, inputType, typeInfoWithKey);
		reducer.setInput(keyedInput);
		reducer.setParallelism(parallelism);
		reducer.setCombineHint(hint);

		return KeyFunctions.appendKeyRemover(reducer, keys);
	}"
"public Actions moveByOffset(int xOffset, int yOffset) {
    if (isBuildingActions()) {
      action.addAction(new MoveToOffsetAction(jsonMouse, null, xOffset, yOffset));
    }

    return tick(
        defaultMouse.createPointerMove(Duration.ofMillis(200), Origin.pointer(), xOffset, yOffset));
  }"
"public static void createFileBatchesLocal(File inputDirectory, String[] extensions, boolean recursive, File outputDirectory, int batchSize) throws IOException {
        if(!outputDirectory.exists())
            outputDirectory.mkdirs();
        //Local version
        List<File> c = new ArrayList<>(FileUtils.listFiles(inputDirectory, extensions, recursive));
        Collections.shuffle(c);

        //Construct file batch
        List<String> list = new ArrayList<>();
        List<byte[]> bytes = new ArrayList<>();
        for (int i = 0; i < c.size(); i++) {
            list.add(c.get(i).toURI().toString());
            bytes.add(FileUtils.readFileToByteArray(c.get(i)));

            if (list.size() == batchSize) {
                process(list, bytes, outputDirectory);
            }
        }
        if (list.size() > 0) {
            process(list, bytes, outputDirectory);
        }
    }"
"public static int mode(File f) throws PosixException {
        if(Functions.isWindows())   return -1;
        try {
            if (Util.NATIVE_CHMOD_MODE) {
                return PosixAPI.jnr().stat(f.getPath()).mode();
            } else {
                return Util.permissionsToMode(Files.getPosixFilePermissions(fileToPath(f)));
            }
        } catch (IOException cause) {
            PosixException e = new PosixException(""Unable to get file permissions"", null);
            e.initCause(cause);
            throw e;
        }
    }"
"@RequestMapping(path = SamlIdPConstants.ENDPOINT_SAML2_SSO_PROFILE_REDIRECT, method = {RequestMethod.HEAD})
    public void handleSaml2ProfileSsoRedirectHeadRequest(final HttpServletResponse response,
                                                         final HttpServletRequest request) {
        LOGGER.info(""Endpoint [{}] called with HTTP HEAD returning 400 Bad Request"", SamlIdPConstants.ENDPOINT_SAML2_SSO_PROFILE_REDIRECT);
        response.setStatus(HttpServletResponse.SC_BAD_REQUEST);
    }"
"public void parseText(char[] text, IHit<V> processor)
    {
        int position = 1;
        int currentState = 0;
        for (char c : text)
        {
            currentState = getState(currentState, c);
            int[] hitArray = output[currentState];
            if (hitArray != null)
            {
                for (int hit : hitArray)
                {
                    processor.hit(position - l[hit], position, v[hit]);
                }
            }
            ++position;
        }
    }"
"@Nullable
  public static DimFilter toFilter(
      final PlannerContext plannerContext,
      final DruidQuerySignature querySignature,
      final RexNode expression
  )
  {
    final SqlKind kind = expression.getKind();

    if (kind == SqlKind.IS_TRUE || kind == SqlKind.IS_NOT_FALSE) {
      return toFilter(
          plannerContext,
          querySignature,
          Iterables.getOnlyElement(((RexCall) expression).getOperands())
      );
    } else if (kind == SqlKind.IS_FALSE || kind == SqlKind.IS_NOT_TRUE) {
      return new NotDimFilter(
          toFilter(
              plannerContext,
              querySignature,
              Iterables.getOnlyElement(((RexCall) expression).getOperands())
          )
      );
    } else if (kind == SqlKind.CAST && expression.getType().getSqlTypeName() == SqlTypeName.BOOLEAN) {
      // Calcite sometimes leaves errant, useless cast-to-booleans inside filters. Strip them and continue.
      return toFilter(plannerContext, querySignature, Iterables.getOnlyElement(((RexCall) expression).getOperands()));
    } else if (kind == SqlKind.AND
               || kind == SqlKind.OR
               || kind == SqlKind.NOT) {
      final List<DimFilter> filters = new ArrayList<>();
      for (final RexNode rexNode : ((RexCall) expression).getOperands()) {
        final DimFilter nextFilter = toFilter(
            plannerContext,
            querySignature,
            rexNode
        );
        if (nextFilter == null) {
          return null;
        }
        filters.add(nextFilter);
      }

      if (kind == SqlKind.AND) {
        return new AndDimFilter(filters);
      } else if (kind == SqlKind.OR) {
        return new OrDimFilter(filters);
      } else {
        assert kind == SqlKind.NOT;
        return new NotDimFilter(Iterables.getOnlyElement(filters));
      }
    } else {
      // Handle filter conditions on everything else.
      return toLeafFilter(plannerContext, querySignature, expression);
    }
  }"
"public OtpErlangObject read_compressed() throws OtpErlangDecodeException {
        final int tag = read1skip_version();

        if (tag != OtpExternal.compressedTag) {
            throw new OtpErlangDecodeException(
                    ""Wrong tag encountered, expected ""
                            + OtpExternal.compressedTag + "", got "" + tag);
        }

        final int size = read4BE();
        final byte[] abuf = new byte[size];
        final java.util.zip.InflaterInputStream is = new java.util.zip.InflaterInputStream(
                this, new java.util.zip.Inflater(), size);
        int curPos = 0;
        try {
            int curRead;
            while (curPos < size
                    && (curRead = is.read(abuf, curPos, size - curPos)) != -1) {
                curPos += curRead;
            }
            if (curPos != size) {
                throw new OtpErlangDecodeException(""Decompression gave ""
                        + curPos + "" bytes, not "" + size);
            }
        } catch (final IOException e) {
            throw new OtpErlangDecodeException(""Cannot read from input stream"");
        }

        @SuppressWarnings(""resource"")
        final OtpInputStream ois = new OtpInputStream(abuf, flags);
        return ois.read_any();
    }"
"public static float[] getFloatData(INDArray buf) {
        if (buf.data().dataType() != DataType.FLOAT)
            throw new IllegalArgumentException(""Float data must be obtained from a float buffer"");

        if (buf.data().allocationMode() == DataBuffer.AllocationMode.HEAP) {
            return buf.data().asFloat();
        } else {
            float[] ret = new float[(int) buf.length()];
            INDArray linear = buf.reshape(-1);

            for (int i = 0; i < buf.length(); i++)
                ret[i] = linear.getFloat(i);
            return ret;
        }
    }"
"public DataSink<String> writeAsFormattedText(String filePath, WriteMode writeMode, TextFormatter<T> formatter) {
		return map(new FormattingMapper<>(clean(formatter))).writeAsText(filePath, writeMode);
	}"
"public void setReasonVariantsDisabled(String reason) {
        reasonVariantsDisabled = Objects.requireNonNull(reason);

        labelReasonVariantsDisabled.setText(reasonVariantsDisabled);
        if (reasonVariantsDisabled.isEmpty() && labelReasonVariantsDisabled.isVisible()) {
            labelReasonVariantsDisabled.setVisible(false);
        }
    }"
"public static void main(String[] args) throws Exception {

		final ParameterTool params = ParameterTool.fromArgs(args);

		if (!params.has(""lineitem"") && !params.has(""customer"") && !params.has(""orders"")) {
			System.err.println(""  This program expects data from the TPC-H benchmark as input data."");
			System.err.println(""  Due to legal restrictions, we can not ship generated data."");
			System.out.println(""  You can find the TPC-H data generator at http://www.tpc.org/tpch/."");
			System.out.println(""  Usage: TPCHQuery3 --lineitem <path> --customer <path> --orders <path> [--output <path>]"");
			return;
		}

		final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();

		env.getConfig().setGlobalJobParameters(params);

		// get input data
		DataSet<Lineitem> lineitems = getLineitemDataSet(env, params.get(""lineitem""));
		DataSet<Customer> customers = getCustomerDataSet(env, params.get(""customer""));
		DataSet<Order> orders = getOrdersDataSet(env, params.get(""orders""));

		// Filter market segment ""AUTOMOBILE""
		customers = customers.filter(
								new FilterFunction<Customer>() {
									@Override
									public boolean filter(Customer c) {
										return c.getMktsegment().equals(""AUTOMOBILE"");
									}
								});

		// Filter all Orders with o_orderdate < 12.03.1995
		orders = orders.filter(
							new FilterFunction<Order>() {
								private final DateFormat format = new SimpleDateFormat(""yyyy-MM-dd"");
								private final Date date = format.parse(""1995-03-12"");

								@Override
								public boolean filter(Order o) throws ParseException {
									return format.parse(o.getOrderdate()).before(date);
								}
							});

		// Filter all Lineitems with l_shipdate > 12.03.1995
		lineitems = lineitems.filter(
								new FilterFunction<Lineitem>() {
									private final DateFormat format = new SimpleDateFormat(""yyyy-MM-dd"");
									private final Date date = format.parse(""1995-03-12"");

									@Override
									public boolean filter(Lineitem l) throws ParseException {
										return format.parse(l.getShipdate()).after(date);
									}
								});

		// Join customers with orders and package them into a ShippingPriorityItem
		DataSet<ShippingPriorityItem> customerWithOrders =
				customers.join(orders).where(0).equalTo(1)
							.with(
								new JoinFunction<Customer, Order, ShippingPriorityItem>() {
									@Override
									public ShippingPriorityItem join(Customer c, Order o) {
										return new ShippingPriorityItem(o.getOrderKey(), 0.0, o.getOrderdate(),
												o.getShippriority());
									}
								});

		// Join the last join result with Lineitems
		DataSet<ShippingPriorityItem> result =
				customerWithOrders.join(lineitems).where(0).equalTo(0)
									.with(
											new JoinFunction<ShippingPriorityItem, Lineitem, ShippingPriorityItem>() {
												@Override
												public ShippingPriorityItem join(ShippingPriorityItem i, Lineitem l) {
													i.setRevenue(l.getExtendedprice() * (1 - l.getDiscount()));
													return i;
												}
											})
								// Group by l_orderkey, o_orderdate and o_shippriority and compute revenue sum
								.groupBy(0, 2, 3)
								.aggregate(Aggregations.SUM, 1);

		// emit result
		if (params.has(""output"")) {
			result.writeAsCsv(params.get(""output""), ""\n"", ""|"");
			// execute program
			env.execute(""TPCH Query 3 Example"");
		} else {
			System.out.println(""Printing result to stdout. Use --output to specify output path."");
			result.print();
		}

	}"
"private static void reflectionAppend(final Object object, final Class<?> clazz, final HashCodeBuilder builder, final boolean useTransients,
            final String[] excludeFields) {
        if (isRegistered(object)) {
            return;
        }
        try {
            register(object);
            final Field[] fields = clazz.getDeclaredFields();
            AccessibleObject.setAccessible(fields, true);
            for (final Field field : fields) {
                if (false == ArrayUtil.contains(excludeFields, field.getName())
                    && (field.getName().indexOf('$') == -1)
                    && (useTransients || !Modifier.isTransient(field.getModifiers()))
                    && (!Modifier.isStatic(field.getModifiers()))) {
                    try {
                        final Object fieldValue = field.get(object);
                        builder.append(fieldValue);
                    } catch (final IllegalAccessException e) {
                        // this can't happen. Would get a Security exception instead
                        // throw a runtime exception in case the impossible happens.
                        throw new InternalError(""Unexpected IllegalAccessException"");
                    }
                }
            }
        } finally {
            unregister(object);
        }
    }"
"public Future<Pair<String, INDArray>> inferVectorBatched(@NonNull LabelledDocument document) {
        if (countSubmitted == null)
            initInference();

        if (this.vocab == null || this.vocab.numWords() == 0)
            reassignExistingModel();

        // we block execution until queued amount of documents gets below acceptable level, to avoid memory exhaust
        while (countSubmitted.get() - countFinished.get() > 1024) {
            ThreadUtils.uncheckedSleep(50);
        }

        InferenceCallable callable = new InferenceCallable(vocab, tokenizerFactory, document);
        Future<Pair<String, INDArray>> future = inferenceExecutor.submit(callable);
        countSubmitted.incrementAndGet();

        return future;
    }"
"@Override public void dinvoke( H2ONode sender ) {
    _h2o = sender;
    Key k = _key;
    _key = null;          // Not part of the return result
    assert k.home();      // Gets are always from home (less we do replication)
    // Shipping a result?  Track replicas so we can invalidate.  There's a
    // narrow race on a moving K/V mapping tracking this Value just as it gets
    // deleted - in which case, simply retry for another Value.
    do  _val = Value.STORE_get(k); // The return result
    while( _val != null && !_val.setReplica(sender) );
    tryComplete();
  }"
"public synchronized byte[] response(byte[] token) {
    try {
      return saslServer != null ? saslServer.evaluateResponse(token) : new byte[0];
    } catch (SaslException e) {
      throw Throwables.propagate(e);
    }
  }"
"@Override
    public Header getResponseFooter(String footerName) {
        if (footerName == null) {
            return null;
        } else {
            return getResponseTrailerHeaderGroup().getCondensedHeader(footerName);
        }
    }"
"public static File generate(String content, int width, int height, File targetFile) {
		final BufferedImage image = generate(content, width, height);
		ImgUtil.write(image, targetFile);
		return targetFile;
	}"
"public static int[] sampleOOBRows(int nrows, float rate, Random sampler, int[] oob) {
    int oobcnt = 0; // Number of oob rows
    Arrays.fill(oob, 0);
    for(int row = 0; row < nrows; row++) {
      if (sampler.nextFloat() >= rate) { // it is out-of-bag row
        oob[1+oobcnt++] = row;
        if (1+oobcnt>=oob.length) oob = Arrays.copyOf(oob, Math.round(1.2f*nrows+0.5f)+2);
      }
    }
    oob[0] = oobcnt;
    return oob;
  }"
"private void recordCounterAndTimer(MixinMetric mixinMetric, RpcAbstractLookoutModel model) {
        Counter totalCounter = mixinMetric.counter(""total_count"");
        Timer totalTimer = mixinMetric.timer(""total_time"");

        Long elapsedTime = model.getElapsedTime();

        totalCounter.inc();
        if (elapsedTime != null) {
            totalTimer.record(elapsedTime, TimeUnit.MILLISECONDS);
        }

        if (!model.getSuccess()) {
            Counter failCounter = mixinMetric.counter(""fail_count"");
            Timer failTimer = mixinMetric.timer(""fail_time"");

            failCounter.inc();
            if (elapsedTime != null) {
                failTimer.record(elapsedTime, TimeUnit.MILLISECONDS);
            }
        }
    }"
"public static Collection<?> toCollection(Class<?> collectionType, Class<?> elementType, Object value) {
		return new CollectionConverter(collectionType, elementType).convert(value, null);
	}"
"public static Column std(DataRowsFacade dataFrame, String columnName) {
        return functions.sqrt(var(dataFrame, columnName));
    }"
"static ConfigurationPropertyName adapt(CharSequence name, char separator,
			Function<CharSequence, CharSequence> elementValueProcessor) {
		Assert.notNull(name, ""Name must not be null"");
		if (name.length() == 0) {
			return EMPTY;
		}
		Elements elements = new ElementsParser(name, separator)
				.parse(elementValueProcessor);
		if (elements.getSize() == 0) {
			return EMPTY;
		}
		return new ConfigurationPropertyName(elements);
	}"
"public AnnotationValueBuilder<T> member(String name, boolean bool) {
        values.put(name, bool);
        return this;
    }"
"private static void mapToXml(Document doc, Element element, Map<?, ?> data) {
		Element filedEle;
		Object key;
		for (Entry<?, ?> entry : data.entrySet()) {
			key = entry.getKey();
			if (null != key) {
				// key作为标签名
				filedEle = doc.createElement(key.toString());
				element.appendChild(filedEle);
				final Object value = entry.getValue();
				// value作为标签内的值。
				if (null != value) {
					if (value instanceof Map) {
						// 如果值依旧为map，递归继续
						mapToXml(doc, filedEle, (Map<?, ?>) value);
						element.appendChild(filedEle);
					} else {
						filedEle.appendChild(doc.createTextNode(value.toString()));
					}
				}
			}
		}
	}"
"@Override
    public void info(String format, Object arg) {
        if (logger.isInfoEnabled()) {
            FormattingTuple ft = MessageFormatter.format(format, arg);
            logger.info(ft.getMessage(), ft.getThrowable());
        }
    }"
"@Exported
    public List<AbstractProject> getTiedJobs() {
        List<AbstractProject> r = new ArrayList<>();
        for (AbstractProject<?,?> p : Jenkins.getInstance().allItems(AbstractProject.class)) {
            if(p instanceof TopLevelItem && this.equals(p.getAssignedLabel()))
                r.add(p);
        }
        r.sort(Items.BY_FULL_NAME);
        return r;
    }"
"@Override
  public void notifyManager() {
    logger.debug(String.format(""Notifying Manager for %s"", this.getClass().getName()));
    try {
      this.metricManager.reportMetric(this);
    } catch (final Throwable ex) {
      logger.error(
          String.format(""Metric Manager is not set for %s metric"", this.getClass().getName()), ex);
    }
  }"
"public DomainNameMappingBuilder<V> add(String hostname, V output) {
        map.put(checkNotNull(hostname, ""hostname""), checkNotNull(output, ""output""));
        return this;
    }"
"public static int utf8Length(String string) {
        CharacterIterator iter = new StringCharacterIterator(string);
        char ch = iter.first();
        int size = 0;
        while (ch != CharacterIterator.DONE) {
            if ((ch >= 0xD800) && (ch < 0xDC00)) {
                // surrogate pair?
                char trail = iter.next();
                if ((trail > 0xDBFF) && (trail < 0xE000)) {
                    // valid pair
                    size += 4;
                } else {
                    // invalid pair
                    size += 3;
                    iter.previous(); // rewind one
                }
            } else if (ch < 0x80) {
                size++;
            } else if (ch < 0x800) {
                size += 2;
            } else {
                // ch < 0x10000, that is, the largest char value
                size += 3;
            }
            ch = iter.next();
        }
        return size;
    }"
"public static Set<Integer> getApplicableHistoryTypes() {
		Set<Integer> allApplicableTypes = new HashSet<Integer>();
		allApplicableTypes.addAll(PluginPassiveScanner.getDefaultHistoryTypes());
		if (!optedInHistoryTypes.isEmpty()) {
			allApplicableTypes.addAll(optedInHistoryTypes);
		}
		return allApplicableTypes;
	}"
"private static void zip(File file, String srcRootDir, ZipOutputStream out) throws UtilException {
		if (file == null) {
			return;
		}

		final String subPath = FileUtil.subPath(srcRootDir, file); // 获取文件相对于压缩文件夹根目录的子路径
		if (file.isDirectory()) {// 如果是目录，则压缩压缩目录中的文件或子目录
			final File[] files = file.listFiles();
			if (ArrayUtil.isEmpty(files) && StrUtil.isNotEmpty(subPath)) {
				// 加入目录，只有空目录时才加入目录，非空时会在创建文件时自动添加父级目录
				addDir(subPath, out);
			}
			// 压缩目录下的子文件或目录
			for (File childFile : files) {
				zip(childFile, srcRootDir, out);
			}
		} else {// 如果是文件或其它符号，则直接压缩该文件
			addFile(file, subPath, out);
		}
	}"
"public static void main(String[] args) throws Exception {

		ParameterTool params = ParameterTool.fromArgs(args);

		final int numPages = params.getInt(""numPages"", PageRankData.getNumberOfPages());
		final int maxIterations = params.getInt(""iterations"", 10);

		// set up execution environment
		final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();

		// make the parameters available to the web ui
		env.getConfig().setGlobalJobParameters(params);

		// get input data
		DataSet<Long> pagesInput = getPagesDataSet(env, params);
		DataSet<Tuple2<Long, Long>> linksInput = getLinksDataSet(env, params);

		// assign initial rank to pages
		DataSet<Tuple2<Long, Double>> pagesWithRanks = pagesInput.
				map(new RankAssigner((1.0d / numPages)));

		// build adjacency list from link input
		DataSet<Tuple2<Long, Long[]>> adjacencyListInput =
				linksInput.groupBy(0).reduceGroup(new BuildOutgoingEdgeList());

		// set iterative data set
		IterativeDataSet<Tuple2<Long, Double>> iteration = pagesWithRanks.iterate(maxIterations);

		DataSet<Tuple2<Long, Double>> newRanks = iteration
				// join pages with outgoing edges and distribute rank
				.join(adjacencyListInput).where(0).equalTo(0).flatMap(new JoinVertexWithEdgesMatch())
				// collect and sum ranks
				.groupBy(0).aggregate(SUM, 1)
				// apply dampening factor
				.map(new Dampener(DAMPENING_FACTOR, numPages));

		DataSet<Tuple2<Long, Double>> finalPageRanks = iteration.closeWith(
				newRanks,
				newRanks.join(iteration).where(0).equalTo(0)
				// termination condition
				.filter(new EpsilonFilter()));

		// emit result
		if (params.has(""output"")) {
			finalPageRanks.writeAsCsv(params.get(""output""), ""\n"", "" "");
			// execute program
			env.execute(""Basic Page Rank Example"");
		} else {
			System.out.println(""Printing result to stdout. Use --output to specify output path."");
			finalPageRanks.print();
		}
	}"
"public static SlidingProcessingTimeWindows of(Time size, Time slide) {
		return new SlidingProcessingTimeWindows(size.toMilliseconds(), slide.toMilliseconds(), 0);
	}"
"public static boolean isValidEmailAddress(final String email) {
    if (email == null) {
      return false;
    }

    boolean result = true;
    try {
      final InternetAddress emailAddr = new InternetAddress(email);
      emailAddr.validate();
    } catch (final AddressException ex) {
      result = false;
    }
    return result;
  }"
"public static void sendText(String to, String subject, String content, File... files) {
		send(to, subject, content, false, files);
	}"
"public static Request create(HttpMethod httpMethod,
                               String url,
                               Map<String, Collection<String>> headers,
                               Body body) {
    return new Request(httpMethod, url, headers, body);
  }"
"@Deprecated
    public static void clear() {
        if (ExtensionList.lookup(AllUsers.class).isEmpty()) {
            return;
        }
        UserIdMapper.getInstance().clear();
        AllUsers.clear();
    }"
"public static UserExecutorConfiguration of(ExecutorType type) {
        ArgumentUtils.check(""type"", type).notNull();
        UserExecutorConfiguration configuration = new UserExecutorConfiguration();
        configuration.type = type;
        return configuration;
    }"
"public static long vectorsPerSlice(INDArray arr) {
        if (arr.rank() > 2) {
            return ArrayUtil.prodLong(new long[] {arr.size(-1), arr.size(-2)});
        }

        return arr.slices();
    }"
"public void load(String filePath, ControlOverrides overrides) {
        try {
            config = new ZapXmlConfiguration(filePath);
            if (overrides != null) {
                for (Entry<String,String> entry : overrides.getOrderedConfigs().entrySet()) {
                	logger.info(""Setting config "" + entry.getKey() + "" = "" + entry.getValue() + 
                			"" was "" + config.getString(entry.getKey()));
                	config.setProperty(entry.getKey(), entry.getValue());
                }
            }
            parse();
        } catch (Exception e) {
            logger.error(e.getMessage(), e);
        }
	}"
"public void fireHttpSessionUpdated(final HttpSession session) {
		if (View.isInitialised() && !EventQueue.isDispatchThread()) {
			EventQueue.invokeLater(new Runnable() {

				@Override
				public void run() {
					fireHttpSessionUpdated(session);
				}
			});

			return;
		}

		int index = sessions.indexOf(session);
		fireTableRowsUpdated(index, index);
	}"
"protected void createAuthenticationWarningMessagesView(final Flow flow) {
        val state = createViewState(flow, CasWebflowConstants.STATE_ID_SHOW_AUTHN_WARNING_MSGS, ""casLoginMessageView"");

        val setAction = createSetAction(""requestScope.messages"", ""messageContext.allMessages"");
        state.getEntryActionList().add(setAction);
        createTransitionForState(state, CasWebflowConstants.TRANSITION_ID_PROCEED, CasWebflowConstants.STATE_ID_PROCEED_FROM_AUTHENTICATION_WARNINGS_VIEW);

        val proceedAction = createActionState(flow, CasWebflowConstants.STATE_ID_PROCEED_FROM_AUTHENTICATION_WARNINGS_VIEW);
        proceedAction.getActionList().add(createEvaluateAction(CasWebflowConstants.ACTION_ID_SEND_TICKET_GRANTING_TICKET));
        createStateDefaultTransition(proceedAction, CasWebflowConstants.STATE_ID_SERVICE_CHECK);
    }"
"public RMatGraph<T> setNoise(boolean noiseEnabled, float noise) {
		Preconditions.checkArgument(noise >= 0.0f && noise <= 2.0f,
			""RMat parameter noise must be non-negative and less than or equal to 2.0"");

		this.noiseEnabled = noiseEnabled;
		this.noise = noise;

		return this;
	}"
"public void forwardNewSessionRequestAndUpdateRegistry(TestSession session)
      throws NewSessionException {
    try (NewSessionPayload payload = NewSessionPayload.create(
        ImmutableMap.of(""desiredCapabilities"", session.getRequestedCapabilities()))) {
      StringBuilder json = new StringBuilder();
      payload.writeTo(json);
      request.setBody(json.toString());
      session.forward(getRequest(), getResponse(), true);
    } catch (IOException e) {
      //log.warning(""Error forwarding the request "" + e.getMessage());
      throw new NewSessionException(""Error forwarding the request "" + e.getMessage(), e);
    }
  }"
"private void configureMetricReports() throws MetricException {
    final Props props = getAzkabanProps();
    if (props != null && props.getBoolean(""executor.metric.reports"", false)) {
      logger.info(""Starting to configure Metric Reports"");
      final MetricReportManager metricManager = MetricReportManager.getInstance();
      final IMetricEmitter metricEmitter = new InMemoryMetricEmitter(props);
      metricManager.addMetricEmitter(metricEmitter);

      logger.info(""Adding number of failed flow metric"");
      metricManager.addMetric(new NumFailedFlowMetric(metricManager, props
          .getInt(METRIC_INTERVAL
                  + NumFailedFlowMetric.NUM_FAILED_FLOW_METRIC_NAME,
              props.getInt(METRIC_INTERVAL + ""default""))));

      logger.info(""Adding number of failed jobs metric"");
      metricManager.addMetric(new NumFailedJobMetric(metricManager, props
          .getInt(METRIC_INTERVAL
                  + NumFailedJobMetric.NUM_FAILED_JOB_METRIC_NAME,
              props.getInt(METRIC_INTERVAL + ""default""))));

      logger.info(""Adding number of running Jobs metric"");
      metricManager.addMetric(new NumRunningJobMetric(metricManager, props
          .getInt(METRIC_INTERVAL
                  + NumRunningJobMetric.NUM_RUNNING_JOB_METRIC_NAME,
              props.getInt(METRIC_INTERVAL + ""default""))));

      logger.info(""Adding number of running flows metric"");
      metricManager.addMetric(new NumRunningFlowMetric(this.runnerManager,
          metricManager, props.getInt(METRIC_INTERVAL
              + NumRunningFlowMetric.NUM_RUNNING_FLOW_METRIC_NAME,
          props.getInt(METRIC_INTERVAL + ""default""))));

      logger.info(""Adding number of queued flows metric"");
      metricManager.addMetric(new NumQueuedFlowMetric(this.runnerManager,
          metricManager, props.getInt(METRIC_INTERVAL
              + NumQueuedFlowMetric.NUM_QUEUED_FLOW_METRIC_NAME,
          props.getInt(METRIC_INTERVAL + ""default""))));

      logger.info(""Completed configuring Metric Reports"");
    }

  }"
"public BinaryString substring(final int start, final int until) {
		ensureMaterialized();
		if (until <= start || start >= sizeInBytes) {
			return EMPTY_UTF8;
		}
		if (inFirstSegment()) {
			MemorySegment segment = segments[0];
			int i = 0;
			int c = 0;
			while (i < sizeInBytes && c < start) {
				i += numBytesForFirstByte(segment.get(i + offset));
				c += 1;
			}

			int j = i;
			while (i < sizeInBytes && c < until) {
				i += numBytesForFirstByte(segment.get(i + offset));
				c += 1;
			}

			if (i > j) {
				byte[] bytes = new byte[i - j];
				segment.get(offset + j, bytes, 0, i - j);
				return fromBytes(bytes);
			} else {
				return EMPTY_UTF8;
			}
		} else {
			return substringSlow(start, until);
		}
	}"
"F getDateInstance(final int dateStyle, final TimeZone timeZone, final Locale locale) {
		return getDateTimeInstance(Integer.valueOf(dateStyle), null, timeZone, locale);
	}"
"protected void addMetadataFiltersToMetadataResolver(final AbstractMetadataResolver metadataProvider, final List<MetadataFilter> metadataFilterList) {
        val metadataFilterChain = new MetadataFilterChain();
        metadataFilterChain.setFilters(metadataFilterList);

        LOGGER.debug(""Metadata filter chain initialized with [{}] filters"", metadataFilterList.size());
        metadataProvider.setMetadataFilter(metadataFilterChain);
    }"
"protected RegisteredService getRegisteredServiceForConsent(final RequestContext requestContext, final Service service) {
        val serviceToUse = this.authenticationRequestServiceSelectionStrategies.resolveService(service);
        val registeredService = this.servicesManager.findServiceBy(serviceToUse);
        RegisteredServiceAccessStrategyUtils.ensureServiceAccessIsAllowed(service, registeredService);
        return registeredService;
    }"
"public static ApplicationContext run(Class[] classes, String... args) {
        return new Micronaut()
            .classes(classes)
            .args(args)
            .start();
    }"
"@Override
    public void disconnect() {
        if (kafkaConsumer != null) {
            kafkaConsumer.close();
            kafkaConsumer = null;
        }
        if (kafkaConsumer2 != null) {
            kafkaConsumer2.close();
            kafkaConsumer2 = null;
        }

        connected = false;
    }"
"public static void removeDuplicatesFromOutputDirectory(File outputDirectory,
			File originDirectory) {
		if (originDirectory.isDirectory()) {
			for (String name : originDirectory.list()) {
				File targetFile = new File(outputDirectory, name);
				if (targetFile.exists() && targetFile.canWrite()) {
					if (!targetFile.isDirectory()) {
						targetFile.delete();
					}
					else {
						FileUtils.removeDuplicatesFromOutputDirectory(targetFile,
								new File(originDirectory, name));
					}
				}
			}
		}
	}"
"private ScheduledExecutorService initializeHouseKeepingExecutorService()
   {
      if (config.getScheduledExecutor() == null) {
         final ThreadFactory threadFactory = Optional.ofNullable(config.getThreadFactory()).orElseGet(() -> new DefaultThreadFactory(poolName + "" housekeeper"", true));
         final ScheduledThreadPoolExecutor executor = new ScheduledThreadPoolExecutor(1, threadFactory, new ThreadPoolExecutor.DiscardPolicy());
         executor.setExecuteExistingDelayedTasksAfterShutdownPolicy(false);
         executor.setRemoveOnCancelPolicy(true);
         return executor;
      }
      else {
         return config.getScheduledExecutor();
      }
   }"
"@SuppressWarnings(""unused"")
    @UsedByGeneratedCode
    public static Map<String, Object> internMapOf(Object... values) {
        if (values == null || values.length == 0) {
            return Collections.emptyMap();
        }
        int len = values.length;
        if (len % 2 != 0) {
            throw new IllegalArgumentException(""Number of arguments should be an even number representing the keys and values"");
        }

        // if the length is 2 then only a single annotation is defined, so tried use internal pool
        if (len == 2) {
            Object value = values[1];
            if (value == Collections.EMPTY_MAP) {
                String key = values[0].toString().intern();
                return INTERN_MAP_POOL.computeIfAbsent(key, s ->
                        Collections.singletonMap(s, Collections.emptyMap())
                );
            } else {
                return StringUtils.internMapOf(values);
            }

        } else {
            return StringUtils.internMapOf(values);
        }
    }"
"public static Set<String> getRequiredFields(Query query)
  {
    Set<String> dimensions = new HashSet<>();
    Set<String> dimsInFilter = null == query.getFilter() ? new HashSet<String>() : query.getFilter().getRequiredColumns();
    dimensions.addAll(dimsInFilter);

    if (query instanceof TopNQuery) {
      TopNQuery q = (TopNQuery) query;
      dimensions.addAll(extractFieldsFromAggregations(q.getAggregatorSpecs()));
      dimensions.add(q.getDimensionSpec().getDimension());
    } else if (query instanceof TimeseriesQuery) {
      TimeseriesQuery q = (TimeseriesQuery) query;
      dimensions.addAll(extractFieldsFromAggregations(q.getAggregatorSpecs()));
    } else if (query instanceof GroupByQuery) {
      GroupByQuery q = (GroupByQuery) query;
      dimensions.addAll(extractFieldsFromAggregations(q.getAggregatorSpecs()));
      for (DimensionSpec spec : q.getDimensions()) {
        String dim = spec.getDimension();
        dimensions.add(dim);
      }
    } else {
      throw new UnsupportedOperationException(""Method getRequeiredFields only support TopNQuery/TimeseriesQuery/GroupByQuery"");
    }
    return dimensions;
  }"
"public Word2VecPrediction predictWord2Vec(RowData data) throws PredictException {
    validateModelCategory(ModelCategory.WordEmbedding);

    if (! (m instanceof WordEmbeddingModel))
      throw new PredictException(""Model is not of the expected type, class = "" + m.getClass().getSimpleName());
    final WordEmbeddingModel weModel = (WordEmbeddingModel) m;
    final int vecSize = weModel.getVecSize();

    HashMap<String, float[]> embeddings = new HashMap<>(data.size());
    for (String wordKey : data.keySet()) {
      Object value = data.get(wordKey);
      if (value instanceof String) {
        String word = (String) value;
        embeddings.put(wordKey, weModel.transform0(word, new float[vecSize]));
      }
    }

    Word2VecPrediction p = new Word2VecPrediction();
    p.wordEmbeddings = embeddings;

    return p;

  }"
"public ConditionalMultibind<T> addConditionBinding(
      String property,
      Predicate<String> condition,
      T target
  )
  {
    if (matchCondition(property, condition)) {
      multibinder.addBinding().toInstance(target);
    }
    return this;
  }"
"private synchronized void maybeRun() {
        if (inprogress==null && pending!=null) {
            base.submit(new Callable<Void>() {
                @Override
                public Void call() throws Exception {
                    synchronized (AtmostOneTaskExecutor.this) {
                        // everyone who submits after this should form a next batch
                        inprogress = pending;
                        pending = null;
                    }

                    try {
                        inprogress.set(task.call());
                    } catch (Throwable t) {
                        LOGGER.log(Level.WARNING, null, t);
                        inprogress.setException(t);
                    } finally {
                        synchronized (AtmostOneTaskExecutor.this) {
                            // if next one is pending, get that scheduled
                            inprogress = null;
                            maybeRun();
                        }
                    }
                    return null;
                }
            });
        }
    }"
"public static Optional<MultifactorAuthenticationProvider> getMultifactorAuthenticationProviderById(final String providerId,
                                                                                                       final ApplicationContext context) {
        return getAvailableMultifactorAuthenticationProviders(context).values()
            .stream()
            .filter(p -> p.matches(providerId))
            .findFirst();
    }"
"private static String normalizePath(final Service service) {
        var path = service.getId();
        path = StringUtils.substringBefore(path, ""?"");
        path = StringUtils.substringBefore(path, "";"");
        path = StringUtils.substringBefore(path, ""#"");
        return path;
    }"
"@ReadOperation
    public Set<? extends MultifactorAuthenticationTrustRecord> devices() {
        val onOrAfter = expireRecordsByDate();
        return this.mfaTrustEngine.get(onOrAfter);
    }"
"@CheckForNull
    public static String fixEmpty(@CheckForNull String s) {
        if(s==null || s.length()==0)    return null;
        return s;
    }"
"protected int doWriteSingle(ChannelOutboundBuffer in) throws Exception {
        // The outbound buffer contains only one message or it contains a file region.
        Object msg = in.current();
        if (msg instanceof ByteBuf) {
            return writeBytes(in, (ByteBuf) msg);
        } else if (msg instanceof DefaultFileRegion) {
            return writeDefaultFileRegion(in, (DefaultFileRegion) msg);
        } else if (msg instanceof FileRegion) {
            return writeFileRegion(in, (FileRegion) msg);
        } else if (msg instanceof SpliceOutTask) {
            if (!((SpliceOutTask) msg).spliceOut()) {
                return WRITE_STATUS_SNDBUF_FULL;
            }
            in.remove();
            return 1;
        } else {
            // Should never reach here.
            throw new Error();
        }
    }"
"public static <T> List<LocalProperty<T>> normalizeAndPrune(List<? extends LocalProperty<T>> localProperties)
    {
        return normalize(localProperties).stream()
                .filter(Optional::isPresent)
                .map(Optional::get)
                .collect(Collectors.toList());
    }"
"Node<E> last() {
        restartFromTail:
        for (;;)
            for (Node<E> t = tail, p = t, q;;) {
                if ((q = p.next) != null &&
                    (q = (p = q).next) != null)
                    // Check for tail updates every other hop.
                    // If p == q, we are sure to follow tail instead.
                    p = (t != (t = tail)) ? t : q;
                else if (p == t
                         // It is possible that p is NEXT_TERMINATOR,
                         // but if so, the CAS is guaranteed to fail.
                         || casTail(t, p))
                    return p;
                else
                    continue restartFromTail;
            }
    }"
"private Plan getPlan() throws ProgramInvocationException {
		if (this.plan == null) {
			Thread.currentThread().setContextClassLoader(this.userCodeClassLoader);
			this.plan = createPlanFromProgram(this.program, this.args);
		}

		return this.plan;
	}"
"public CouchDbSamlIdPMetadataDocument getOne() {
        val view = createQuery(""all"").limit(1);
        return db.queryView(view, CouchDbSamlIdPMetadataDocument.class).stream().findFirst().orElse(null);
    }"
"public void showINDArray(
			int mtLv,
			String itemCode,
			INDArray INDA,
			int digits,
			int r_End_I,
			int c_End_I
			) {
		//
		showINDArray( mtLv, itemCode, INDA, digits, r_End_I, c_End_I, false );
	}"
"private boolean checkFreeSlotAt(final long sequence) {
        final long wrapPoint = sequence - bufferSize;
        if (wrapPoint > flushSequence.get()) { // 刚好追上一轮
            return false;
        } else {
            return true;
        }
    }"
"protected HttpRequest addAuthHeader(HttpRequest request) {
        if (authToken != null) {
            request.header(""authorization"", ""Bearer "" + authToken);
        }

        return request;
    }"
"public static DatabaseType getDatabaseType(final String url) {
        switch (getDriverClassName(url)) {
            case ""com.mysql.cj.jdbc.Driver"":
            case ""com.mysql.jdbc.Driver"":
                return DatabaseType.MySQL;
            case ""org.postgresql.Driver"":
                return DatabaseType.PostgreSQL;
            case ""oracle.jdbc.driver.OracleDriver"":
                return DatabaseType.Oracle;
            case ""com.microsoft.sqlserver.jdbc.SQLServerDriver"":
                return DatabaseType.SQLServer;
            case ""org.h2.Driver"":
                return DatabaseType.H2;
            default:
                throw new ShardingException(""Cannot resolve JDBC url `%s`"", url);
        }
    }"
"@Restricted(NoExternalUse.class)
    public User createAccountFromSetupWizard(StaplerRequest req) throws IOException, AccountCreationFailedException {
        checkPermission(Jenkins.ADMINISTER);
        SignupInfo si = validateAccountCreationForm(req, false);
        if (!si.errors.isEmpty()) {
            String messages = getErrorMessages(si);
            throw new AccountCreationFailedException(messages);
        } else {
            return createAccount(si);
        }
    }"
"public <T> List<T> read(int headerRowIndex, int startRowIndex, Class<T> beanType) {
		return read(headerRowIndex, startRowIndex, Integer.MAX_VALUE, beanType);
	}"
"public static double divide(long numerator, long denominator, int scale) {
        BigDecimal numeratorBd = new BigDecimal(numerator);
        BigDecimal denominatorBd = new BigDecimal(denominator);
        return numeratorBd.divide(denominatorBd, scale, BigDecimal.ROUND_HALF_UP).doubleValue();
    }"
"public int getInt(int index) throws JSONException {
    Object o = get(index);
    return o instanceof Number ? ((Number) o).intValue() : (int) getDouble(index);
  }"
"public static Certificate readX509Certificate(InputStream in, char[] password, String alias) {
		return readCertificate(X509, in, password, alias);
	}"
"@Override
  public OperationHandle getTables(SessionHandle sessionHandle,
      String catalogName, String schemaName, String tableName, List<String> tableTypes)
          throws HiveSQLException {
    OperationHandle opHandle = sessionManager.getSession(sessionHandle)
        .getTables(catalogName, schemaName, tableName, tableTypes);
    LOG.debug(sessionHandle + "": getTables()"");
    return opHandle;
  }"
"@SafeVarargs
	public static <T> List<T> sortPageAll(int pageNo, int pageSize, Comparator<T> comparator, Collection<T>... colls) {
		final List<T> list = new ArrayList<>(pageNo * pageSize);
		for (Collection<T> coll : colls) {
			list.addAll(coll);
		}
		if (null != comparator) {
			Collections.sort(list, comparator);
		}

		return page(pageNo, pageSize, list);
	}"
"public int getExitCode() {
		int exitCode = 0;
		for (ExitCodeGenerator generator : this.generators) {
			try {
				int value = generator.getExitCode();
				if (value > 0 && value > exitCode || value < 0 && value < exitCode) {
					exitCode = value;
				}
			}
			catch (Exception ex) {
				exitCode = (exitCode != 0) ? exitCode : 1;
				ex.printStackTrace();
			}
		}
		return exitCode;
	}"
"public boolean shouldSkip(@Nullable String contentType, @Nullable Integer contentLength) {
        if (contentType == null) {
            return true;
        }
        return !MediaType.isTextBased(contentType) || (contentLength != null && contentLength >= 0 && contentLength < compressionThreshold);
    }"
"public SDVariable one(String name, org.nd4j.linalg.api.buffer.DataType dataType, int... shape) {
        return var(name, new ConstantInitScheme('f', 1.0), dataType, ArrayUtil.toLongArray(shape));
    }"
"@Override
  public OperationHandle executeStatement(SessionHandle sessionHandle, String statement,
      Map<String, String> confOverlay) throws HiveSQLException {
    return cliService.executeStatement(sessionHandle, statement, confOverlay);
  }"
"@Override
	public byte[] decrypt(byte[] data, KeyType keyType) throws CryptoException {
		if (KeyType.PrivateKey != keyType) {
			throw new IllegalArgumentException(""Decrypt is only support by private key"");
		}
		ckeckKey(keyType);

		lock.lock();
		final SM2Engine engine = getEngine();
		try {
			engine.init(false, getCipherParameters(keyType));
			return engine.processBlock(data, 0, data.length);
		} finally {
			lock.unlock();
		}
	}"
"public static StackTraceElement getStackTraceElement(int i) {
		StackTraceElement[] stackTrace = getStackTrace();
		if (i < 0) {
			i += stackTrace.length;
		}
		return stackTrace[i];
	}"
"public void triggerCheckpointOnBarrier(CheckpointMetaData checkpointMetaData, CheckpointOptions checkpointOptions, CheckpointMetrics checkpointMetrics) throws Exception {
		throw new UnsupportedOperationException(String.format(""triggerCheckpointOnBarrier not supported by %s"", this.getClass().getName()));
	}"
"public static Object complement(Object arg) throws NoSuchMethodException {
        int code = typeCode(arg);
        if (code <= INT) {
            return boxToInteger(~unboxCharOrInt(arg, code));
        }
        if (code <= LONG) {
            return boxToLong(~unboxCharOrLong(arg, code));
        }
        throw new NoSuchMethodException();
    }"
"private RelBuilder createSelectDistinct(RelBuilder relBuilder,
			Aggregate aggregate, List<Integer> argList, int filterArg,
			Map<Integer, Integer> sourceOf) {
		relBuilder.push(aggregate.getInput());
		final List<Pair<RexNode, String>> projects = new ArrayList<>();
		final List<RelDataTypeField> childFields =
				relBuilder.peek().getRowType().getFieldList();
		for (int i : aggregate.getGroupSet()) {
			sourceOf.put(i, projects.size());
			projects.add(RexInputRef.of2(i, childFields));
		}
		if (filterArg >= 0) {
			sourceOf.put(filterArg, projects.size());
			projects.add(RexInputRef.of2(filterArg, childFields));
		}
		for (Integer arg : argList) {
			if (filterArg >= 0) {
				// Implement
				//   agg(DISTINCT arg) FILTER $f
				// by generating
				//   SELECT DISTINCT ... CASE WHEN $f THEN arg ELSE NULL END AS arg
				// and then applying
				//   agg(arg)
				// as usual.
				//
				// It works except for (rare) agg functions that need to see null
				// values.
				final RexBuilder rexBuilder = aggregate.getCluster().getRexBuilder();
				final RexInputRef filterRef = RexInputRef.of(filterArg, childFields);
				final Pair<RexNode, String> argRef = RexInputRef.of2(arg, childFields);
				RexNode condition =
						rexBuilder.makeCall(SqlStdOperatorTable.CASE, filterRef,
								argRef.left,
								rexBuilder.ensureType(argRef.left.getType(),
										rexBuilder.makeCast(argRef.left.getType(),
												rexBuilder.constantNull()),
										true));
				sourceOf.put(arg, projects.size());
				projects.add(Pair.of(condition, ""i$"" + argRef.right));
				continue;
			}
			if (sourceOf.get(arg) != null) {
				continue;
			}
			sourceOf.put(arg, projects.size());
			projects.add(RexInputRef.of2(arg, childFields));
		}
		relBuilder.project(Pair.left(projects), Pair.right(projects));

		// Get the distinct values of the GROUP BY fields and the arguments
		// to the agg functions.
		relBuilder.push(
				aggregate.copy(aggregate.getTraitSet(), relBuilder.build(), false,
						ImmutableBitSet.range(projects.size()),
						null, com.google.common.collect.ImmutableList.<AggregateCall>of()));
		return relBuilder;
	}"
"static InstallState getNextInstallState(InstallState current) {
        List<Function<Provider<InstallState>,InstallState>> installStateFilterChain = new ArrayList<>();
        for (InstallStateFilter setupExtension : InstallStateFilter.all()) {
            installStateFilterChain.add(next -> setupExtension.getNextInstallState(current, next));
        }
        // Terminal condition: getNextState() on the current install state
        installStateFilterChain.add(input -> {
            // Initially, install state is unknown and 
            // needs to be determined
            if (current == null || InstallState.UNKNOWN.equals(current)) {
                return getDefaultInstallState();
            }
            Map<InstallState, InstallState> states = new HashMap<>();
            {
                states.put(InstallState.CONFIGURE_INSTANCE, InstallState.INITIAL_SETUP_COMPLETED);
                states.put(InstallState.CREATE_ADMIN_USER, InstallState.CONFIGURE_INSTANCE);
                states.put(InstallState.INITIAL_PLUGINS_INSTALLING, InstallState.CREATE_ADMIN_USER);
                states.put(InstallState.INITIAL_SECURITY_SETUP, InstallState.NEW);
                states.put(InstallState.RESTART, InstallState.RUNNING);
                states.put(InstallState.UPGRADE, InstallState.INITIAL_SETUP_COMPLETED);
                states.put(InstallState.DOWNGRADE, InstallState.INITIAL_SETUP_COMPLETED);
                states.put(InstallState.INITIAL_SETUP_COMPLETED, InstallState.RUNNING);
            }
            return states.get(current);
        });
        
        ProviderChain<InstallState> chain = new ProviderChain<>(installStateFilterChain.iterator());
        return chain.get();
    }"
"protected boolean sendSingleLogoutMessage(final SingleLogoutRequest request, final SingleLogoutMessage logoutMessage) {
        val logoutService = request.getService();
        LOGGER.trace(""Preparing logout request for [{}] to [{}]"", logoutService.getId(), request.getLogoutUrl());
        val msg = getLogoutHttpMessageToSend(request, logoutMessage);
        LOGGER.debug(""Prepared logout message to send is [{}]. Sending..."", msg);
        val result = sendMessageToEndpoint(msg, request, logoutMessage);
        logoutService.setLoggedOutAlready(result);
        return result;
    }"
"public static void validateOutputLayer(String layerName, Layer layer){
        IActivation activation;
        ILossFunction loss;
        long nOut;
        boolean isLossLayer = false;
        if (layer instanceof BaseOutputLayer && !(layer instanceof OCNNOutputLayer)) {
            activation = ((BaseOutputLayer) layer).getActivationFn();
            loss = ((BaseOutputLayer) layer).getLossFn();
            nOut = ((BaseOutputLayer) layer).getNOut();
        } else if (layer instanceof LossLayer) {
            activation = ((LossLayer) layer).getActivationFn();
            loss = ((LossLayer) layer).getLossFn();
            nOut = ((LossLayer) layer).getNOut();
            isLossLayer = true;
        } else if (layer instanceof RnnLossLayer) {
            activation = ((RnnLossLayer) layer).getActivationFn();
            loss = ((RnnLossLayer) layer).getLossFn();
            nOut = ((RnnLossLayer) layer).getNOut();
            isLossLayer = true;
        } else if (layer instanceof CnnLossLayer) {
            activation = ((CnnLossLayer) layer).getActivationFn();
            loss = ((CnnLossLayer) layer).getLossFn();
            nOut = ((CnnLossLayer) layer).getNOut();
            isLossLayer = true;
        } else {
            //Not an output layer
            return;
        }
        OutputLayerUtil.validateOutputLayerConfiguration(layerName, nOut, isLossLayer, activation, loss);
    }"
"@SneakyThrows
    protected String getBackupMetadataFilenamePrefix(final AbstractResource metadataResource, final SamlRegisteredService service) {
        val mdFileName = metadataResource.getFilename();
        if (StringUtils.isBlank(mdFileName)) {
            throw new FileNotFoundException(""Unable to determine filename for "" + metadataResource);
        }
        val fileName = service.getMetadataLocation();
        val sha = DigestUtils.sha(fileName);
        LOGGER.trace(""Metadata backup file for metadata location [{}] is linked to [{}]"", fileName, sha);
        return sha;
    }"
"public void serializeToPagesWithoutLength(
			BinaryRow record,
			AbstractPagedOutputView out) throws IOException {
		int remainSize = record.getSizeInBytes();
		int posInSegOfRecord = record.getOffset();
		int segmentSize = record.getSegments()[0].size();
		for (MemorySegment segOfRecord : record.getSegments()) {
			int nWrite = Math.min(segmentSize - posInSegOfRecord, remainSize);
			assert nWrite > 0;
			out.write(segOfRecord, posInSegOfRecord, nWrite);

			// next new segment.
			posInSegOfRecord = 0;
			remainSize -= nWrite;
			if (remainSize == 0) {
				break;
			}
		}
		checkArgument(remainSize == 0);
	}"
"protected synchronized Thread start(boolean forceRestart) {
        if (!forceRestart && isFixingActive()) {
            fixThread.interrupt();
        }

        if (forceRestart || !isFixingActive()) {
            fixThread = new FixThread();
            fixThread.start();
        }
        return fixThread;
    }"
"public static HttpResponse executeGet(final String url,
                                          final String basicAuthUsername,
                                          final String basicAuthPassword,
                                          final Map<String, Object> parameters) {
        try {
            return executeGet(url, basicAuthUsername, basicAuthPassword, parameters, new HashMap<>());
        } catch (final Exception e) {
            LOGGER.error(e.getMessage(), e);
        }
        return null;
    }"
"public String extractPathWithinPattern(String pattern, String path) {
        String[] patternParts = tokenize(pattern);
        String[] pathParts = tokenize(path);

        StringBuilder builder = new StringBuilder();

        // Add any path parts that have a wildcarded pattern part.
        int puts = 0;
        for (int i = 0; i < patternParts.length; i++) {
            String patternPart = patternParts[i];
            if ((patternPart.indexOf('*') > -1 || patternPart.indexOf('?') > -1) && pathParts.length >= i + 1) {
                if (puts > 0 || (i == 0 && !pattern.startsWith(pathSeparator))) {
                    builder.append(pathSeparator);
                }
                builder.append(pathParts[i]);
                puts++;
            }
        }

        // Append any trailing path parts.
        for (int i = patternParts.length; i < pathParts.length; i++) {
            if (puts > 0 || i > 0) {
                builder.append(pathSeparator);
            }
            builder.append(pathParts[i]);
        }

        return builder.toString();
    }"
"ValFrame addGlobals(Frame fr) {
    _ses.addGlobals(fr);
    return new ValFrame(new Frame(fr._names.clone(), fr.vecs().clone()));
  }"
"public static INDArray initWeights(double fanIn, double fanOut, long[] shape, WeightInit initScheme,
                                       Distribution dist, INDArray paramView) {
        return initWeights(fanIn, fanOut, shape, initScheme, dist, DEFAULT_WEIGHT_INIT_ORDER, paramView);
    }"
"public static <A extends Annotation> AnnotationValues<A> createAnnotation(Class<A> type, JCAnnotation anno, final JavacNode node) {
		Map<String, AnnotationValue> values = new HashMap<String, AnnotationValue>();
		List<JCExpression> arguments = anno.getArguments();
		
		for (JCExpression arg : arguments) {
			String mName;
			JCExpression rhs;
			java.util.List<String> raws = new ArrayList<String>();
			java.util.List<Object> guesses = new ArrayList<Object>();
			java.util.List<Object> expressions = new ArrayList<Object>();
			final java.util.List<DiagnosticPosition> positions = new ArrayList<DiagnosticPosition>();
			
			if (arg instanceof JCAssign) {
				JCAssign assign = (JCAssign) arg;
				mName = assign.lhs.toString();
				rhs = assign.rhs;
			} else {
				rhs = arg;
				mName = ""value"";
			}
			
			if (rhs instanceof JCNewArray) {
				List<JCExpression> elems = ((JCNewArray) rhs).elems;
				for (JCExpression inner : elems) {
					raws.add(inner.toString());
					expressions.add(inner);
					if (inner instanceof JCAnnotation) {
						try {
							@SuppressWarnings(""unchecked"")
							Class<A> innerClass = (Class<A>) Class.forName(inner.type.toString());
							
							guesses.add(createAnnotation(innerClass, (JCAnnotation) inner, node));
						} catch (ClassNotFoundException ex) {
							guesses.add(calculateGuess(inner));
						}
					} else {
						guesses.add(calculateGuess(inner));
					}
					positions.add(inner.pos());
				}
			} else {
				raws.add(rhs.toString());
				expressions.add(rhs);
				if (rhs instanceof JCAnnotation) {
					try {
						@SuppressWarnings(""unchecked"")
						Class<A> innerClass = (Class<A>) Class.forName(rhs.type.toString());
						
						guesses.add(createAnnotation(innerClass, (JCAnnotation) rhs, node));
					} catch (ClassNotFoundException ex) {
						guesses.add(calculateGuess(rhs));
					}
				} else {
					guesses.add(calculateGuess(rhs));
				}
				positions.add(rhs.pos());
			}
			
			values.put(mName, new AnnotationValue(node, raws, expressions, guesses, true) {
				@Override public void setError(String message, int valueIdx) {
					if (valueIdx < 0) node.addError(message);
					else node.addError(message, positions.get(valueIdx));
				}
				
				@Override public void setWarning(String message, int valueIdx) {
					if (valueIdx < 0) node.addWarning(message);
					else node.addWarning(message, positions.get(valueIdx));
				}
			});
		}
		
		for (Method m : type.getDeclaredMethods()) {
			if (!Modifier.isPublic(m.getModifiers())) continue;
			String name = m.getName();
			if (!values.containsKey(name)) {
				values.put(name, new AnnotationValue(node, new ArrayList<String>(), new ArrayList<Object>(), new ArrayList<Object>(), false) {
					@Override public void setError(String message, int valueIdx) {
						node.addError(message);
					}
					@Override public void setWarning(String message, int valueIdx) {
						node.addWarning(message);
					}
				});
			}
		}
		
		return new AnnotationValues<A>(type, values, node);
	}"
"public static File getTempDir(){
        String p = System.getProperty(ND4JSystemProperties.ND4J_TEMP_DIR_PROPERTY);
        if(p == null || p.isEmpty()){
            return new File(System.getProperty(""java.io.tmpdir""));
        } else {
            return new File(p);
        }
    }"
"public static <K, V> CounterMap<K, V> parallelCounterMap() {
        CounterMap<K, V> totalWords = new CounterMap<>();
        return totalWords;
    }"
"public static String normalizePath(String path) {
		if (Platforms.FILE_PATH_SEPARATOR_CHAR == Platforms.WINDOWS_FILE_PATH_SEPARATOR_CHAR
				&& StringUtils.indexOf(path, Platforms.LINUX_FILE_PATH_SEPARATOR_CHAR) != -1) {
			return StringUtils.replaceChars(path, Platforms.LINUX_FILE_PATH_SEPARATOR_CHAR,
					Platforms.WINDOWS_FILE_PATH_SEPARATOR_CHAR);
		}
		return path;

	}"
"Node<K, V> findByEntry(Entry<?, ?> entry) {
    Node<K, V> mine = findByObject(entry.getKey());
    boolean valuesEqual = mine != null && equal(mine.value, entry.getValue());
    return valuesEqual ? mine : null;
  }"
"public AggregateOperator<T> sum (int field) {
		return this.aggregate (Aggregations.SUM, field, Utils.getCallLocationName());
	}"
"@SuppressWarnings({""unchecked""})
    public static <T> Iterator<T> cast(Iterator<? extends T> itr) {
        return (Iterator)itr;
    }"
"public static String[] partitionCommandLine(final String command) {
    final ArrayList<String> commands = new ArrayList<>();

    int index = 0;

    StringBuffer buffer = new StringBuffer(command.length());

    boolean isApos = false;
    boolean isQuote = false;
    while (index < command.length()) {
      final char c = command.charAt(index);

      switch (c) {
        case ' ':
          if (!isQuote && !isApos) {
            final String arg = buffer.toString();
            buffer = new StringBuffer(command.length() - index);
            if (arg.length() > 0) {
              commands.add(arg);
            }
          } else {
            buffer.append(c);
          }
          break;
        case '\'':
          if (!isQuote) {
            isApos = !isApos;
          } else {
            buffer.append(c);
          }
          break;
        case '""':
          if (!isApos) {
            isQuote = !isQuote;
          } else {
            buffer.append(c);
          }
          break;
        default:
          buffer.append(c);
      }

      index++;
    }

    if (buffer.length() > 0) {
      final String arg = buffer.toString();
      commands.add(arg);
    }

    return commands.toArray(new String[commands.size()]);
  }"
"private int[] getAllFlatKeys(String[] fieldExpressions) {

		int[] allKeys = null;

		for (String keyExp : fieldExpressions) {
			Keys.ExpressionKeys<T> ek = new Keys.ExpressionKeys<>(keyExp, this.type);
			int[] flatKeys = ek.computeLogicalKeyPositions();

			if (allKeys == null) {
				allKeys = flatKeys;
			} else {
				// check for duplicates
				for (int key1 : flatKeys) {
					for (int key2 : allKeys) {
						if (key1 == key2) {
							throw new InvalidProgramException(""Duplicate fields in field expression "" + keyExp);
						}
					}
				}
				// append flat keys
				int oldLength = allKeys.length;
				int newLength = oldLength + flatKeys.length;
				allKeys = Arrays.copyOf(allKeys, newLength);
				System.arraycopy(flatKeys, 0, allKeys, oldLength, flatKeys.length);
			}
		}

		return allKeys;
	}"
"private boolean matchQueryParams(MultiValueMap<String, String> registeredRedirectUriQueryParams,
									 MultiValueMap<String, String> requestedRedirectUriQueryParams) {


		Iterator<String> iter = registeredRedirectUriQueryParams.keySet().iterator();
		while (iter.hasNext()) {
			String key = iter.next();
			List<String> registeredRedirectUriQueryParamsValues = registeredRedirectUriQueryParams.get(key);
			List<String> requestedRedirectUriQueryParamsValues = requestedRedirectUriQueryParams.get(key);

			if (!registeredRedirectUriQueryParamsValues.equals(requestedRedirectUriQueryParamsValues)) {
				return false;
			}
		}

		return true;
	}"
"protected ClassLoader createClassLoader(List<Archive> archives) throws Exception {
		List<URL> urls = new ArrayList<>(archives.size());
		for (Archive archive : archives) {
			urls.add(archive.getUrl());
		}
		return createClassLoader(urls.toArray(new URL[0]));
	}"
"public void resumeTransfer() {
        final ChannelHandlerContext ctx = this.ctx;
        if (ctx == null) {
            return;
        }
        if (ctx.executor().inEventLoop()) {
            resumeTransfer0(ctx);
        } else {
            // let the transfer resume on the next event loop round
            ctx.executor().execute(new Runnable() {

                @Override
                public void run() {
                    resumeTransfer0(ctx);
                }
            });
        }
    }"
"private void encodeFromStreamExtra(Intent intent) throws WriterException {
    format = BarcodeFormat.QR_CODE;
    Bundle bundle = intent.getExtras();
    if (bundle == null) {
      throw new WriterException(""No extras"");
    }
    Uri uri = bundle.getParcelable(Intent.EXTRA_STREAM);
    if (uri == null) {
      throw new WriterException(""No EXTRA_STREAM"");
    }
    byte[] vcard;
    String vcardString;
    try (InputStream stream = activity.getContentResolver().openInputStream(uri)) {
      if (stream == null) {
        throw new WriterException(""Can't open stream for "" + uri);
      }
      ByteArrayOutputStream baos = new ByteArrayOutputStream();
      byte[] buffer = new byte[2048];
      int bytesRead;
      while ((bytesRead = stream.read(buffer)) > 0) {
        baos.write(buffer, 0, bytesRead);
      }
      vcard = baos.toByteArray();
      vcardString = new String(vcard, 0, vcard.length, StandardCharsets.UTF_8);
    } catch (IOException ioe) {
      throw new WriterException(ioe);
    }
    Log.d(TAG, ""Encoding share intent content:"");
    Log.d(TAG, vcardString);
    Result result = new Result(vcardString, vcard, null, BarcodeFormat.QR_CODE);
    ParsedResult parsedResult = ResultParser.parseResult(result);
    if (!(parsedResult instanceof AddressBookParsedResult)) {
      throw new WriterException(""Result was not an address"");
    }
    encodeQRCodeContents((AddressBookParsedResult) parsedResult);
    if (contents == null || contents.isEmpty()) {
      throw new WriterException(""No content to encode"");
    }
  }"
"protected void initializeHelper(DataType dataType){
        String backend = Nd4j.getExecutioner().getEnvironmentInformation().getProperty(""backend"");
        if(""CUDA"".equalsIgnoreCase(backend)) {
            try {
                helper = Class.forName(""org.deeplearning4j.nn.layers.dropout.CudnnDropoutHelper"")
                        .asSubclass(DropoutHelper.class).getConstructor(DataType.class).newInstance(dataType);
                log.debug(""CudnnDropoutHelper successfully initialized"");
                if (!helper.checkSupported()) {
                    helper = null;
                }
            } catch (Throwable t) {
                if (!(t instanceof ClassNotFoundException)) {
                    log.warn(""Could not initialize CudnnDropoutHelper"", t);
                }
                //Unlike other layers, don't warn here about CuDNN not found - if the user has any other layers that can
                // benefit from them cudnn, they will get a warning from those
            }
        }
        initializedHelper = true;
    }"
"static void registerDefaultValues(AnnotationClassValue<?> annotation, Map<String, Object> defaultValues) {
        if (defaultValues != null) {
            registerDefaultValues(annotation.getName(), defaultValues);
        }
        registerAnnotationType(annotation);
    }"
"private void grow(int size) {
		if (this.value.length < size) {
			char[] value = new char[ Math.max(this.value.length * 3 / 2, size)];
			System.arraycopy(this.value, 0, value, 0, this.len);
			this.value = value;
		}
	}"
"private <X> DataSource<X> fromParallelCollection(SplittableIterator<X> iterator, TypeInformation<X> type, String callLocationName) {
		return new DataSource<>(this, new ParallelIteratorInputFormat<>(iterator), type, callLocationName);
	}"
"public static BloomKFilter deserialize(InputStream in) throws IOException
  {
    if (in == null) {
      throw new IOException(""Input stream is null"");
    }

    try {
      DataInputStream dataInputStream = new DataInputStream(in);
      int numHashFunc = dataInputStream.readByte();
      int bitsetArrayLen = dataInputStream.readInt();
      long[] data = new long[bitsetArrayLen];
      for (int i = 0; i < bitsetArrayLen; i++) {
        data[i] = dataInputStream.readLong();
      }
      return new BloomKFilter(data, numHashFunc);
    }
    catch (RuntimeException e) {
      IOException io = new IOException(""Unable to deserialize BloomKFilter"");
      io.initCause(e);
      throw io;
    }
  }"
"protected @Nonnull <T> T createBean(@Nullable BeanResolutionContext resolutionContext, @Nonnull Class<T> beanType, @Nullable Qualifier<T> qualifier) {
        ArgumentUtils.requireNonNull(""beanType"", beanType);

        Optional<BeanDefinition<T>> concreteCandidate = findConcreteCandidate(beanType, qualifier, true, false);
        if (concreteCandidate.isPresent()) {
            BeanDefinition<T> candidate = concreteCandidate.get();
            if (resolutionContext == null) {
                resolutionContext = new DefaultBeanResolutionContext(this, candidate);
            }
            T createBean = doCreateBean(resolutionContext, candidate, qualifier, false, null);
            if (createBean == null) {
                throw new NoSuchBeanException(beanType);
            }
            return createBean;
        }
        throw new NoSuchBeanException(beanType);
    }"
"@Override
    public boolean modelRecordWithBLOBsClassGenerated(TopLevelClass topLevelClass, IntrospectedTable introspectedTable) {
        processEntityClass(topLevelClass, introspectedTable);
        return false;
    }"
"protected final void writeln(String s, boolean escapeNewlines) {
    assert tmpfile != null : ""No text file is currently being written"";
    tmpfile.append(escapeNewlines ? StringEscapeUtils.escapeNewlines(s) : s);
    tmpfile.append('\n');
  }"
"public static String getNaturalName(String name) {
        name = getShortName(name);

        if (isBlank(name)) {
            return name;
        }

        if (name.length() == 1) {
            return name.toUpperCase();
        } else {
            StringBuilder sb = new StringBuilder();
            sb.append(name.charAt(name.length() - 1));
            //Traversing the string in reverse order
            for (int i = name.length() - 2; i > 0; i--) {
                char currChar = name.charAt(i);
                char prevChar = name.charAt(i - 1);
                char nextChar = name.charAt(i + 1);

                boolean isCurrentCharLowerCase = Character.isLowerCase(currChar);
                boolean isPrevCharLowerCase = Character.isLowerCase(prevChar);
                boolean isNextCharLowerCase = Character.isLowerCase(nextChar);

                if (isCurrentCharLowerCase != isPrevCharLowerCase && !isCurrentCharLowerCase) {
                    sb.append(currChar + "" "");
                } else if (isCurrentCharLowerCase == isPrevCharLowerCase && !isCurrentCharLowerCase && isNextCharLowerCase) {
                    sb.append(currChar + "" "");
                } else {
                    sb.append(currChar);
                }
            }
            //The first character of the string is always in Upper case
            sb.append(Character.toUpperCase(name.charAt(0)));
            return sb.reverse().toString();
        }
    }"
"private AbstractInterfaceConfig getRegisterConfig(ConsumerConfig config) {
        String url = ZookeeperRegistryHelper.convertConsumerToUrl(config);
        String addr = url.substring(0, url.indexOf(""?""));
        for (Map.Entry<ConsumerConfig, String> consumerUrl : consumerUrls.entrySet()) {
            if (consumerUrl.getValue().contains(addr)) {
                return consumerUrl.getKey();
            }
        }
        return null;
    }"
"@Override
	public void deleteTagsForHistoryID (long historyId) throws DatabaseException {
    	SqlPreparedStatementWrapper psDeleteTagsForHistoryId = null;
        try {
        	psDeleteTagsForHistoryId = DbSQL.getSingleton().getPreparedStatement(""tag.ps.deletetagsforhid"");
			psDeleteTagsForHistoryId.getPs().setLong(1, historyId);
			psDeleteTagsForHistoryId.getPs().execute();
		} catch (SQLException e) {
			throw new DatabaseException(e);
		} finally {
			DbSQL.getSingleton().releasePreparedStatement(psDeleteTagsForHistoryId);
		}
    }"
"public synchronized void setException(Throwable ex) {
    if(_ex == null) {
      _ex = AutoBuffer.javaSerializeWritePojo(((ex instanceof DistributedException) ? (DistributedException) ex : new DistributedException(ex,false /* don't want this setException(ex) call in the stacktrace */)));
    }
  }"
"@Override
    public INDArray get(INDArrayIndex... indexes) {

        sort();

        if (indexes.length == 1 && indexes[0] instanceof NDArrayIndexAll || (indexes.length == 2 && (isRowVector()
                        && indexes[0] instanceof PointIndex && indexes[0].offset() == 0
                        && indexes[1] instanceof NDArrayIndexAll
                        || isColumnVector() && indexes[1] instanceof PointIndex && indexes[0].offset() == 0
                                        && indexes[0] instanceof NDArrayIndexAll)))
            return this;

        throw new UnsupportedOperationException(""Not implemented"");
    }"
"static Optional<Class<? extends Annotation>> getRegisteredAnnotationType(String name) {
        final Class<? extends Annotation> type = ANNOTATION_TYPES.get(name);
        if (type != null) {
            return Optional.of(type);
        }
        return Optional.empty();
    }"
"public void waitUntilAllReceived(int timeout) throws ExternalFrameConfirmationException {
        try {
            byte flag = ExternalFrameConfirmationCheck.getConfirmation(ab, timeout);
            assert (flag == ExternalFrameHandler.CONFIRM_READING_DONE);
        } catch (TimeoutException ex) {
            throw new ExternalFrameConfirmationException(""Timeout for confirmation exceeded!"");
        } catch (InterruptedException e) {
            throw new ExternalFrameConfirmationException(""Confirmation thread interrupted!"");
        } catch (ExecutionException e) {
            throw new ExternalFrameConfirmationException(""Confirmation failed!"");
        }
    }"
"@Override
    public void preProcess(DataSet toPreProcess) {
        for (DataSetPreProcessor preProcessor : preProcessors) {
            preProcessor.preProcess(toPreProcess);
        }
    }"
"public DataSet<Tuple2<K, LongValue>> getDegrees() {
		return outDegrees()
			.union(inDegrees()).name(""In- and out-degree"")
			.groupBy(0).sum(1).name(""Sum"");
	}"
"public void setStatusRequestDenied(final Response response, final String description) {
        response.setStatus(this.samlObjectBuilder.newStatus(StatusCode.REQUEST_DENIED, description));
    }"
"public SDVariable larg() {
        val args = args();
        if(args == null || args.length == 0)
            throw new ND4JIllegalStateException(""No arguments found."");
        return args()[0];
    }"
"@Override
	public Collection<?> convert(Object value, Collection<?> defaultValue) throws IllegalArgumentException {
		Collection<?> result = null;
		try {
			result = convertInternal(value);
		} catch (RuntimeException e) {
			return defaultValue;
		}
		return ((null == result) ? defaultValue : result);
	}"
"public static AlertRiskTableCellItem getItemForRisk(final int risk) {
        if (risk == -1) {
            return NO_RISK_CELL_ITEM;
        }

        AlertRiskTableCellItem alertCelLItem = values.get(risk);
        if (alertCelLItem == null) {
            return UNDEFINED_RISK_CELL_ITEM;
        }
        return alertCelLItem;
    }"
"public static void copy(String in, Writer out) throws IOException {
        assert in != null : ""No input String specified"";
        assert out != null : ""No output Writer specified"";

        try {
            out.write(in);
        } finally {
            try {
                out.close();
            } catch (IOException ex) {
            }
        }
    }"
"private long getHashPositionOfElement(Block block, int position)
    {
        checkArgument(!block.isNull(position), ""position is null"");
        int length = block.getSliceLength(position);
        long hashPosition = getMaskedHash(block.hash(position, 0, length));
        while (true) {
            int blockPosition = blockPositionByHash.get(hashPosition);
            if (blockPosition == EMPTY_SLOT) {
                // Doesn't have this element
                return hashPosition;
            }
            else if (elementBlock.getSliceLength(blockPosition) == length && block.equals(position, 0, elementBlock, blockPosition, 0, length)) {
                // Already has this element
                return hashPosition;
            }

            hashPosition = getMaskedHash(hashPosition + 1);
        }
    }"
"public void validateWhitelisted(Props props) {
    String id = null;
    if (props.containsKey(PROXY_USER_KEY)) {
      id = props.get(PROXY_USER_KEY);
      Preconditions.checkArgument(
          !StringUtils.isEmpty(id), PROXY_USER_KEY + "" is required."");
    } else if (props.containsKey(CommonJobProperties.SUBMIT_USER)) {
      id = props.get(CommonJobProperties.SUBMIT_USER);
      Preconditions.checkArgument(!StringUtils.isEmpty(id),
          CommonJobProperties.SUBMIT_USER + "" is required."");
    } else {
      throw new IllegalArgumentException(
          ""Property neither has "" + PROXY_USER_KEY + "" nor "" + CommonJobProperties.SUBMIT_USER);
    }
    validateWhitelisted(id);
  }"
"public static CharsetDecoder decoder(Charset charset) {
        checkNotNull(charset, ""charset"");

        Map<Charset, CharsetDecoder> map = InternalThreadLocalMap.get().charsetDecoderCache();
        CharsetDecoder d = map.get(charset);
        if (d != null) {
            d.reset().onMalformedInput(CodingErrorAction.REPLACE).onUnmappableCharacter(CodingErrorAction.REPLACE);
            return d;
        }

        d = decoder(charset, CodingErrorAction.REPLACE, CodingErrorAction.REPLACE);
        map.put(charset, d);
        return d;
    }"
"public static void toWriter(String templateFileName, VelocityContext context, Writer writer) {
		assertInit();

		final Template template = Velocity.getTemplate(templateFileName);
		merge(template, context, writer);
	}"
"public static Class<?> getMapperClass(String msId) {
        if (msId.indexOf(""."") == -1) {
            throw new MapperException(""当前MappedStatement的id="" + msId + "",不符合MappedStatement的规则!"");
        }
        String mapperClassStr = msId.substring(0, msId.lastIndexOf("".""));
        //由于一个接口中的每个方法都会进行下面的操作，因此缓存
        Class<?> mapperClass = (Class<?>) CLASS_CACHE.getObject(mapperClassStr);
        if(mapperClass != null){
            return mapperClass;
        }
        ClassLoader[] classLoader = getClassLoaders();

        for (ClassLoader cl : classLoader) {
            if (null != cl) {
                try {
                    mapperClass = Class.forName(mapperClassStr, true, cl);
                    if (mapperClass != null) {
                        break;
                    }
                } catch (ClassNotFoundException e) {
                    // we'll ignore this until all class loaders fail to locate the class
                }
            }
        }
        if (mapperClass == null) {
            throw new MapperException(""class loaders failed to locate the class "" + mapperClassStr);
        }
        CLASS_CACHE.putObject(mapperClassStr, mapperClass);
        return mapperClass;
    }"
"public static void registerQueueLengthMetrics(MetricGroup group, SingleInputGate gate) {
		InputGateMetrics metrics = new InputGateMetrics(gate);

		group.gauge(""totalQueueLen"", metrics.getTotalQueueLenGauge());
		group.gauge(""minQueueLen"", metrics.getMinQueueLenGauge());
		group.gauge(""maxQueueLen"", metrics.getMaxQueueLenGauge());
		group.gauge(""avgQueueLen"", metrics.getAvgQueueLenGauge());
	}"
"@Override
    public InputType getOutputType(InputType... inputType) throws InvalidKerasConfigurationException {
        if (inputType.length > 1)
            throw new InvalidKerasConfigurationException(
                    ""Keras Subsampling 1D layer accepts only one input (received "" + inputType.length + "")"");
        return this.getSubsampling1DLayer().getOutputType(-1, inputType[0]);
    }"
"public static CsvWriter getWriter(File file, Charset charset, boolean isAppend) {
		return new CsvWriter(file, charset, isAppend);
	}"
"public static void printProgress(char showChar, int len) {
		print(""{}{}"", CharUtil.CR, StrUtil.repeat(showChar, len));
	}"
"public void traverse(JavacASTVisitor visitor) {
		switch (this.getKind()) {
		case COMPILATION_UNIT:
			visitor.visitCompilationUnit(this, (JCCompilationUnit) get());
			ast.traverseChildren(visitor, this);
			visitor.endVisitCompilationUnit(this, (JCCompilationUnit) get());
			break;
		case TYPE:
			visitor.visitType(this, (JCClassDecl) get());
			ast.traverseChildren(visitor, this);
			visitor.endVisitType(this, (JCClassDecl) get());
			break;
		case FIELD:
			visitor.visitField(this, (JCVariableDecl) get());
			ast.traverseChildren(visitor, this);
			visitor.endVisitField(this, (JCVariableDecl) get());
			break;
		case METHOD:
			visitor.visitMethod(this, (JCMethodDecl) get());
			ast.traverseChildren(visitor, this);
			visitor.endVisitMethod(this, (JCMethodDecl) get());
			break;
		case INITIALIZER:
			visitor.visitInitializer(this, (JCBlock) get());
			ast.traverseChildren(visitor, this);
			visitor.endVisitInitializer(this, (JCBlock) get());
			break;
		case ARGUMENT:
			JCMethodDecl parentMethod = (JCMethodDecl) up().get();
			visitor.visitMethodArgument(this, (JCVariableDecl) get(), parentMethod);
			ast.traverseChildren(visitor, this);
			visitor.endVisitMethodArgument(this, (JCVariableDecl) get(), parentMethod);
			break;
		case LOCAL:
			visitor.visitLocal(this, (JCVariableDecl) get());
			ast.traverseChildren(visitor, this);
			visitor.endVisitLocal(this, (JCVariableDecl) get());
			break;
		case STATEMENT:
			visitor.visitStatement(this, get());
			ast.traverseChildren(visitor, this);
			visitor.endVisitStatement(this, get());
			break;
		case ANNOTATION:
			switch (up().getKind()) {
			case TYPE:
				visitor.visitAnnotationOnType((JCClassDecl) up().get(), this, (JCAnnotation) get());
				break;
			case FIELD:
				visitor.visitAnnotationOnField((JCVariableDecl) up().get(), this, (JCAnnotation) get());
				break;
			case METHOD:
				visitor.visitAnnotationOnMethod((JCMethodDecl) up().get(), this, (JCAnnotation) get());
				break;
			case ARGUMENT:
				JCVariableDecl argument = (JCVariableDecl) up().get();
				JCMethodDecl method = (JCMethodDecl) up().up().get();
				visitor.visitAnnotationOnMethodArgument(argument, method, this, (JCAnnotation) get());
				break;
			case LOCAL:
				visitor.visitAnnotationOnLocal((JCVariableDecl) up().get(), this, (JCAnnotation) get());
				break;
			case TYPE_USE:
				visitor.visitAnnotationOnTypeUse(up().get(), this, (JCAnnotation) get());
				break;
			default:
				throw new AssertionError(""Annotion not expected as child of a "" + up().getKind());
			}
			break;
		case TYPE_USE:
			visitor.visitTypeUse(this, get());
			ast.traverseChildren(visitor, this);
			visitor.endVisitTypeUse(this, get());
			break;
		default:
			throw new AssertionError(""Unexpected kind during node traversal: "" + getKind());
		}
	}"
"public boolean addPassiveScanner(PassiveScanner passiveScanner) {
        if (passiveScanner == null) {
            throw new IllegalArgumentException(""Parameter passiveScanner must not be null."");
        }

        if (passiveScanner instanceof PluginPassiveScanner) {
            return addPluginPassiveScannerImpl((PluginPassiveScanner) passiveScanner);
        }
        return addPassiveScannerImpl(passiveScanner);
    }"
"@Override
    public void fit(DataSetIterator iterator) {
        try{
            fitHelper(iterator);
        } catch (OutOfMemoryError e){
            CrashReportingUtil.writeMemoryCrashDump(this, e);
            throw e;
        }
    }"
"public static String getShortName(String className) {
        int i = className.lastIndexOf(""."");
        if (i > -1) {
            className = className.substring(i + 1, className.length());
        }
        return className;
    }"
"private static void onDataRead(ChannelHandlerContext ctx, Http2DataFrame data) throws Exception {
        if (data.isEndStream()) {
            sendResponse(ctx, data.content());
        } else {
            // We do not send back the response to the remote-peer, so we need to release it.
            data.release();
        }
    }"
"public CassandraSink<IN> setParallelism(int parallelism) {
		if (useDataStreamSink) {
			getSinkTransformation().setParallelism(parallelism);
		} else {
			getStreamTransformation().setParallelism(parallelism);
		}
		return this;
	}"
"public boolean triggerCheckpoint(CheckpointMetaData checkpointMetaData, CheckpointOptions checkpointOptions, boolean advanceToEndOfEventTime) throws Exception {
		throw new UnsupportedOperationException(String.format(""triggerCheckpoint not supported by %s"", this.getClass().getName()));
	}"
"@Bean
	public javax.ws.rs.core.Application jerseyApplication(Environment environment,
			ResourceLoader resourceLoader) {

		ClassPathScanningCandidateComponentProvider provider = new ClassPathScanningCandidateComponentProvider(
				false, environment);

		// Filter to include only classes that have a particular annotation.
		//
		provider.addIncludeFilter(new AnnotationTypeFilter(Path.class));
		provider.addIncludeFilter(new AnnotationTypeFilter(Provider.class));

		// Find classes in Eureka packages (or subpackages)
		//
		Set<Class<?>> classes = new HashSet<>();
		for (String basePackage : EUREKA_PACKAGES) {
			Set<BeanDefinition> beans = provider.findCandidateComponents(basePackage);
			for (BeanDefinition bd : beans) {
				Class<?> cls = ClassUtils.resolveClassName(bd.getBeanClassName(),
						resourceLoader.getClassLoader());
				classes.add(cls);
			}
		}

		// Construct the Jersey ResourceConfig
		Map<String, Object> propsAndFeatures = new HashMap<>();
		propsAndFeatures.put(
				// Skip static content used by the webapp
				ServletContainer.PROPERTY_WEB_PAGE_CONTENT_REGEX,
				EurekaConstants.DEFAULT_PREFIX + ""/(fonts|images|css|js)/.*"");

		DefaultResourceConfig rc = new DefaultResourceConfig(classes);
		rc.setPropertiesAndFeatures(propsAndFeatures);

		return rc;
	}"
"public final SidACL newInheritingACL(final SidACL parent) {
        final SidACL child = this;
        return new SidACL() {
            protected Boolean hasPermission(Sid p, Permission permission) {
                Boolean b = child.hasPermission(p, permission);
                if(b!=null) return b;
                return parent.hasPermission(p,permission);
            }
        };
    }"
"public void timeCollectionsStreaming(int reps) throws IOException {
    for (int i=0; i<reps; ++i) {
      StringReader reader = new StringReader(json);
      JsonReader jr = new JsonReader(reader);
      jr.beginArray();
      List<BagOfPrimitives> bags = new ArrayList<BagOfPrimitives>();
      while(jr.hasNext()) {
        jr.beginObject();
        long longValue = 0;
        int intValue = 0;
        boolean booleanValue = false;
        String stringValue = null;
        while(jr.hasNext()) {
          String name = jr.nextName();
          if (name.equals(""longValue"")) {
            longValue = jr.nextLong();
          } else if (name.equals(""intValue"")) {
            intValue = jr.nextInt();
          } else if (name.equals(""booleanValue"")) {
            booleanValue = jr.nextBoolean();
          } else if (name.equals(""stringValue"")) {
            stringValue = jr.nextString();
          } else {
            throw new IOException(""Unexpected name: "" + name);
          }
        }
        jr.endObject();
        bags.add(new BagOfPrimitives(longValue, intValue, booleanValue, stringValue));
      }
      jr.endArray();
    }
  }"
"public static boolean isRowVectorShape(IntBuffer shapeInfo) {
        int rank = Shape.rank(shapeInfo);
        IntBuffer shape = Shape.shapeOf(shapeInfo);
        return (rank == 2 && shape.get(0) == 1) || rank == 1;

    }"
"private static DimFilter buildTimeFloorFilter(
      final String column,
      final Granularity granularity,
      final SqlKind operatorKind,
      final long rhsMillis
  )
  {
    final BoundRefKey boundRefKey = new BoundRefKey(column, null, StringComparators.NUMERIC);
    final Interval rhsInterval = granularity.bucket(DateTimes.utc(rhsMillis));

    // Is rhs aligned on granularity boundaries?
    final boolean rhsAligned = rhsInterval.getStartMillis() == rhsMillis;

    return getBoundTimeDimFilter(operatorKind, boundRefKey, rhsInterval, rhsAligned);
  }"
"private JButton getBtnAdd() {
		if (btnAdd == null) {
			btnAdd = new JButton();
			btnAdd.setText(Constant.messages.getString(""history.managetags.button.add""));
			btnAdd.setMinimumSize(new java.awt.Dimension(75,30));
			btnAdd.setPreferredSize(new java.awt.Dimension(75,30));
			btnAdd.setMaximumSize(new java.awt.Dimension(100,40));
			btnAdd.addActionListener(new java.awt.event.ActionListener() { 

				@Override
				public void actionPerformed(java.awt.event.ActionEvent e) {
					addTag(getTxtTagAdd().getSelectedItem().toString());
					getTxtTagAdd().setSelectedIndex(0);
				}
			});

		}
		return btnAdd;
	}"
"private void handleGetMetricHistory(final int executorId, final HttpServletRequest req,
      final HashMap<String, Object> ret, final User user) throws IOException,
      ServletException {
    try {
      final Map<String, Object> result =
          this.execManagerAdapter.callExecutorStats(executorId,
              ConnectorParams.STATS_GET_METRICHISTORY, getAllParams(req));
      if (result.containsKey(ConnectorParams.RESPONSE_ERROR)) {
        ret.put(ConnectorParams.RESPONSE_ERROR,
            result.get(ConnectorParams.RESPONSE_ERROR).toString());
      } else {
        ret.put(""data"", result.get(""data""));
      }
    } catch (final ExecutorManagerException ex) {
      logger.error(ex.getMessage(), ex);
      ret.put(""error"", ""Failed to fetch metric history"");
    }
  }"
"public static <T> Collection<T> union(Collection<T> coll1, Collection<T> coll2) {
		final ArrayList<T> list = new ArrayList<>();
		if (isEmpty(coll1)) {
			list.addAll(coll2);
		} else if (isEmpty(coll2)) {
			list.addAll(coll1);
		} else {
			final Map<T, Integer> map1 = countMap(coll1);
			final Map<T, Integer> map2 = countMap(coll2);
			final Set<T> elts = newHashSet(coll2);
			elts.addAll(coll1);
			int m;
			for (T t : elts) {
				m = Math.max(Convert.toInt(map1.get(t), 0), Convert.toInt(map2.get(t), 0));
				for (int i = 0; i < m; i++) {
					list.add(t);
				}
			}
		}
		return list;
	}"
"public @CheckForNull FilePath getWorkspaceRoot() {
        FilePath r = getRootPath();
        if(r==null) return null;
        return r.child(WORKSPACE_ROOT);
    }"
"public boolean isCompatibleWith(DeweyNumber other) {
		if (length() > other.length()) {
			// prefix case
			for (int i = 0; i < other.length(); i++) {
				if (other.deweyNumber[i] != deweyNumber[i]) {
					return false;
				}
			}

			return true;
		} else if (length() == other.length()) {
			// check init digits for equality
			int lastIndex = length() - 1;
			for (int i = 0; i < lastIndex; i++) {
				if (other.deweyNumber[i] != deweyNumber[i]) {
					return false;
				}
			}

			// check that the last digit is greater or equal
			return deweyNumber[lastIndex] >= other.deweyNumber[lastIndex];
		} else {
			return false;
		}
	}"
"public static ExpectedCondition<List<WebElement>> visibilityOfAllElements(
    final List<WebElement> elements) {
    return new ExpectedCondition<List<WebElement>>() {
      @Override
      public List<WebElement> apply(WebDriver driver) {
        for (WebElement element : elements) {
          if (!element.isDisplayed()) {
            return null;
          }
        }
        return elements.size() > 0 ? elements : null;
      }

      @Override
      public String toString() {
        return ""visibility of all "" + elements;
      }
    };
  }"
"@Override
    public INDArray valueArrayOf(int[] shape, double value) {
        INDArray ret = Nd4j.createUninitialized(shape, Nd4j.order());
        ret.assign(value);
        return ret;
    }"
"public void afterPropertiesSet() throws Exception {
		Assert.notNull(authenticationEntryPoint, ""authenticationEntryPoint must be specified"");
		Assert.notNull(portResolver, ""portResolver must be specified"");
		Assert.notNull(authenticationTrustResolver, ""authenticationTrustResolver must be specified"");
	}"
"protected void checkErroneous() throws Exception {
		Exception e = asyncException;
		if (e != null) {
			// prevent double throwing
			asyncException = null;
			throw new Exception(""Failed to send data to Kafka: "" + e.getMessage(), e);
		}
	}"
"String findSparkSubmit() {
    String script = isWindows() ? ""spark-submit.cmd"" : ""spark-submit"";
    return join(File.separator, builder.getSparkHome(), ""bin"", script);
  }"
"public String attachToGetConnectorAddress() throws Exception {
		VirtualMachine vm = null;

		// 1. attach vm
		vm = VirtualMachine.attach(pid);

		try {
			// 2. 检查smartAgent是否已启动
			Properties agentProps = vm.getAgentProperties();
			String address = (String) agentProps.get(LOCAL_CONNECTOR_ADDRESS_PROP);

			if (address != null) {
				return address;
			}

			// 3. 未启动，尝试启动
			String home = vm.getSystemProperties().getProperty(""java.home"");

			// Normally in ${java.home}/jre/lib/management-agent.jar but might
			// be in ${java.home}/lib in build environments.

			String agentPath = home + File.separator + ""jre"" + File.separator + ""lib"" + File.separator
					+ ""management-agent.jar"";
			File f = new File(agentPath);
			if (!f.exists()) {
				agentPath = home + File.separator + ""lib"" + File.separator + ""management-agent.jar"";
				f = new File(agentPath);
				if (!f.exists()) {
					throw new IOException(""Management agent not found"");
				}
			}

			agentPath = f.getCanonicalPath();
			vm.loadAgent(agentPath, ""com.sun.management.jmxremote"");

			// 4. 再次获取connector address
			agentProps = vm.getAgentProperties();
			address = (String) agentProps.get(LOCAL_CONNECTOR_ADDRESS_PROP);

			if (address == null) {
				throw new IOException(""Fails to find connector address"");
			}

			return address;
		} finally {
			vm.detach();
		}
	}"
"protected void finalizeProfileResponse(final AccessToken accessTokenTicket, final Map<String, Object> map, final Principal principal) {
        val service = accessTokenTicket.getService();
        val registeredService = servicesManager.findServiceBy(service);
        if (registeredService instanceof OAuthRegisteredService) {
            val oauth = (OAuthRegisteredService) registeredService;
            map.put(OAuth20Constants.CLIENT_ID, oauth.getClientId());
            map.put(CasProtocolConstants.PARAMETER_SERVICE, service.getId());
        }
    }"
"public static Executor apply(final Executor executor, final EventExecutor eventExecutor) {
        ObjectUtil.checkNotNull(executor, ""executor"");
        ObjectUtil.checkNotNull(eventExecutor, ""eventExecutor"");
        return new Executor() {
            @Override
            public void execute(final Runnable command) {
                executor.execute(apply(command, eventExecutor));
            }
        };
    }"
"public int levenshteinDistance(UTF8String other) {
    // Implementation adopted from org.apache.common.lang3.StringUtils.getLevenshteinDistance

    int n = numChars();
    int m = other.numChars();

    if (n == 0) {
      return m;
    } else if (m == 0) {
      return n;
    }

    UTF8String s, t;

    if (n <= m) {
      s = this;
      t = other;
    } else {
      s = other;
      t = this;
      int swap;
      swap = n;
      n = m;
      m = swap;
    }

    int[] p = new int[n + 1];
    int[] d = new int[n + 1];
    int[] swap;

    int i, i_bytes, j, j_bytes, num_bytes_j, cost;

    for (i = 0; i <= n; i++) {
      p[i] = i;
    }

    for (j = 0, j_bytes = 0; j < m; j_bytes += num_bytes_j, j++) {
      num_bytes_j = numBytesForFirstByte(t.getByte(j_bytes));
      d[0] = j + 1;

      for (i = 0, i_bytes = 0; i < n; i_bytes += numBytesForFirstByte(s.getByte(i_bytes)), i++) {
        if (s.getByte(i_bytes) != t.getByte(j_bytes) ||
              num_bytes_j != numBytesForFirstByte(s.getByte(i_bytes))) {
          cost = 1;
        } else {
          cost = (ByteArrayMethods.arrayEquals(t.base, t.offset + j_bytes, s.base,
              s.offset + i_bytes, num_bytes_j)) ? 0 : 1;
        }
        d[i + 1] = Math.min(Math.min(d[i] + 1, p[i + 1] + 1), p[i] + cost);
      }

      swap = p;
      p = d;
      d = swap;
    }

    return p[n];
  }"
"public static PostgreSQLBinaryProtocolValue getBinaryProtocolValue(final PostgreSQLColumnType columnType) {
        Preconditions.checkArgument(BINARY_PROTOCOL_VALUES.containsKey(columnType), ""Cannot find PostgreSQL type '%s' in column type when process binary protocol value"", columnType);
        return BINARY_PROTOCOL_VALUES.get(columnType);
    }"
"private static void setContentTypeHeader(HttpResponse response, File file) {
        MimetypesFileTypeMap mimeTypesMap = new MimetypesFileTypeMap();
        response.headers().set(HttpHeaderNames.CONTENT_TYPE, mimeTypesMap.getContentType(file.getPath()));
    }"
"private static boolean isValidHeaderMagic(OrcDataSource source)
            throws IOException
    {
        byte[] headerMagic = new byte[MAGIC.length()];
        source.readFully(0, headerMagic);

        return MAGIC.equals(Slices.wrappedBuffer(headerMagic));
    }"
"public Throwable unwrap() {
		Throwable cause = getCause();
		return (cause instanceof WrappingRuntimeException) ? ((WrappingRuntimeException) cause).unwrap() : cause;
	}"
"public void train(JavaRDD<String> corpusRDD) throws Exception {
        log.info(""Start training ..."");

        if (workers > 0)
            corpusRDD.repartition(workers);

        // SparkContext
        final JavaSparkContext sc = new JavaSparkContext(corpusRDD.context());

        // Pre-defined variables
        Map<String, Object> tokenizerVarMap = getTokenizerVarMap();
        Map<String, Object> word2vecVarMap = getWord2vecVarMap();

        // Variables to fill in train
        final JavaRDD<AtomicLong> sentenceWordsCountRDD;
        final JavaRDD<List<VocabWord>> vocabWordListRDD;
        final JavaPairRDD<List<VocabWord>, Long> vocabWordListSentenceCumSumRDD;
        final VocabCache<VocabWord> vocabCache;
        final JavaRDD<Long> sentenceCumSumCountRDD;
        int maxRep = 1;

        // Start Training //
        //////////////////////////////////////
        log.info(""Tokenization and building VocabCache ..."");
        // Processing every sentence and make a VocabCache which gets fed into a LookupCache
        Broadcast<Map<String, Object>> broadcastTokenizerVarMap = sc.broadcast(tokenizerVarMap);
        TextPipeline pipeline = new TextPipeline(corpusRDD, broadcastTokenizerVarMap);
        pipeline.buildVocabCache();
        pipeline.buildVocabWordListRDD();

        // Get total word count and put into word2vec variable map
        word2vecVarMap.put(""totalWordCount"", pipeline.getTotalWordCount());

        // 2 RDDs: (vocab words list) and (sentence Count).Already cached
        sentenceWordsCountRDD = pipeline.getSentenceCountRDD();
        vocabWordListRDD = pipeline.getVocabWordListRDD();

        // Get vocabCache and broad-casted vocabCache
        Broadcast<VocabCache<VocabWord>> vocabCacheBroadcast = pipeline.getBroadCastVocabCache();
        vocabCache = vocabCacheBroadcast.getValue();

        log.info(""Vocab size: {}"", vocabCache.numWords());

        //////////////////////////////////////
        log.info(""Building Huffman Tree ..."");
        // Building Huffman Tree would update the code and point in each of the vocabWord in vocabCache
        /*
        We don't need to build tree here, since it was built earlier, at TextPipeline.buildVocabCache() call.
        
        Huffman huffman = new Huffman(vocabCache.vocabWords());
        huffman.build();
        huffman.applyIndexes(vocabCache);
        */
        //////////////////////////////////////
        log.info(""Calculating cumulative sum of sentence counts ..."");
        sentenceCumSumCountRDD = new CountCumSum(sentenceWordsCountRDD).buildCumSum();

        //////////////////////////////////////
        log.info(""Mapping to RDD(vocabWordList, cumulative sentence count) ..."");
        vocabWordListSentenceCumSumRDD =
                        vocabWordListRDD.zip(sentenceCumSumCountRDD).setName(""vocabWordListSentenceCumSumRDD"");

        /////////////////////////////////////
        log.info(""Broadcasting word2vec variables to workers ..."");
        Broadcast<Map<String, Object>> word2vecVarMapBroadcast = sc.broadcast(word2vecVarMap);
        Broadcast<double[]> expTableBroadcast = sc.broadcast(expTable);



        /////////////////////////////////////
        log.info(""Training word2vec sentences ..."");
        FlatMapFunction firstIterFunc =
                        new FirstIterationFunction(word2vecVarMapBroadcast, expTableBroadcast, vocabCacheBroadcast);
        @SuppressWarnings(""unchecked"")
        JavaRDD<Pair<VocabWord, INDArray>> indexSyn0UpdateEntryRDD =
                        vocabWordListSentenceCumSumRDD.mapPartitions(firstIterFunc).map(new MapToPairFunction());

        // Get all the syn0 updates into a list in driver
        List<Pair<VocabWord, INDArray>> syn0UpdateEntries = indexSyn0UpdateEntryRDD.collect();

        // Instantiate syn0
        INDArray syn0 = Nd4j.zeros(vocabCache.numWords(), layerSize);

        // Updating syn0 first pass: just add vectors obtained from different nodes
        log.info(""Averaging results..."");
        Map<VocabWord, AtomicInteger> updates = new HashMap<>();
        Map<Long, Long> updaters = new HashMap<>();
        for (Pair<VocabWord, INDArray> syn0UpdateEntry : syn0UpdateEntries) {
            syn0.getRow(syn0UpdateEntry.getFirst().getIndex()).addi(syn0UpdateEntry.getSecond());

            // for proper averaging we need to divide resulting sums later, by the number of additions
            if (updates.containsKey(syn0UpdateEntry.getFirst())) {
                updates.get(syn0UpdateEntry.getFirst()).incrementAndGet();
            } else
                updates.put(syn0UpdateEntry.getFirst(), new AtomicInteger(1));

            if (!updaters.containsKey(syn0UpdateEntry.getFirst().getVocabId())) {
                updaters.put(syn0UpdateEntry.getFirst().getVocabId(), syn0UpdateEntry.getFirst().getAffinityId());
            }
        }

        // Updating syn0 second pass: average obtained vectors
        for (Map.Entry<VocabWord, AtomicInteger> entry : updates.entrySet()) {
            if (entry.getValue().get() > 1) {
                if (entry.getValue().get() > maxRep)
                    maxRep = entry.getValue().get();
                syn0.getRow(entry.getKey().getIndex()).divi(entry.getValue().get());
            }
        }

        long totals = 0;

        log.info(""Finished calculations..."");


        vocab = vocabCache;
        InMemoryLookupTable<VocabWord> inMemoryLookupTable = new InMemoryLookupTable<VocabWord>();
        Environment env = EnvironmentUtils.buildEnvironment();
        env.setNumCores(maxRep);
        env.setAvailableMemory(totals);
        update(env, Event.SPARK);
        inMemoryLookupTable.setVocab(vocabCache);
        inMemoryLookupTable.setVectorLength(layerSize);
        inMemoryLookupTable.setSyn0(syn0);
        lookupTable = inMemoryLookupTable;
        modelUtils.init(lookupTable);
    }"
"public void statusUpdate(final String asgName, final ASGStatus newStatus) {
        long expiryTime = System.currentTimeMillis() + maxProcessingDelayMs;
        nonBatchingDispatcher.process(
                asgName,
                new AsgReplicationTask(targetHost, Action.StatusUpdate, asgName, newStatus) {
                    public EurekaHttpResponse<?> execute() {
                        return replicationClient.statusUpdate(asgName, newStatus);
                    }
                },
                expiryTime
        );
    }"
"public static void setLong(MemorySegment[] segments, int offset, long value) {
		if (inFirstSegment(segments, offset, 8)) {
			segments[0].putLong(offset, value);
		} else {
			setLongMultiSegments(segments, offset, value);
		}
	}"
"public void setCacheMode(CacheMode mode) {
        if (mode == null)
            mode = CacheMode.NONE;

        for (Layer layer : layers) {
            layer.setCacheMode(mode);
        }
    }"
"public static Slice getDiskRangeSlice(DiskRange diskRange, Map<DiskRange, byte[]> buffers)
    {
        for (Entry<DiskRange, byte[]> bufferEntry : buffers.entrySet()) {
            DiskRange bufferRange = bufferEntry.getKey();
            byte[] buffer = bufferEntry.getValue();
            if (bufferRange.contains(diskRange)) {
                int offset = toIntExact(diskRange.getOffset() - bufferRange.getOffset());
                return Slices.wrappedBuffer(buffer, offset, diskRange.getLength());
            }
        }
        throw new IllegalStateException(""No matching buffer for disk range"");
    }"
"static FormattingTuple format(String messagePattern, Object arg) {
        return arrayFormat(messagePattern, new Object[]{arg});
    }"
"protected Event finalizeResponseEvent(final RequestContext requestContext, final WebApplicationService service, final Response response) {
        WebUtils.putServiceResponseIntoRequestScope(requestContext, response);
        WebUtils.putServiceOriginalUrlIntoRequestScope(requestContext, service);
        val eventId = getFinalResponseEventId(service, response, requestContext);
        return new EventFactorySupport().event(this, eventId);
    }"
"public String put(String group, String key, String value) {
		return this.groupedMap.put(group, key, value);
	}"
"public synchronized URL addPath(Path path, Path remoteFile) throws IOException, MalformedURLException {
		if (paths.containsKey(remoteFile)) {
			throw new IllegalArgumentException(""duplicate path registered"");
		}
		if (remoteFile.isAbsolute()) {
			throw new IllegalArgumentException(""not expecting an absolute path"");
		}
		URL fileURL = new URL(baseURL, remoteFile.toString());
		router.addAny(fileURL.getPath(), new VirtualFileServerHandler(path));

		paths.put(remoteFile, fileURL);

		return fileURL;
	}"
"public int build(Set<Map.Entry<String, V>> entrySet)
    {
        List<String> keyList = new ArrayList<String>(entrySet.size());
        List<V> valueList = new ArrayList<V>(entrySet.size());
        for (Map.Entry<String, V> entry : entrySet)
        {
            keyList.add(entry.getKey());
            valueList.add(entry.getValue());
        }

        return build(keyList, valueList);
    }"
"public static Channel interceptForward(Channel channel, ClientInterceptor... interceptors) {
    return interceptForward(channel, Arrays.asList(interceptors));
  }"
"public static boolean isHostIp(String ip) {
        InetAddress localAddress = null;
        try {
            localAddress = InetAddress.getLocalHost();
            if (localAddress.isLoopbackAddress() || isValidHostAddress(localAddress)
                && (localAddress.getHostAddress().equals(ip) || localAddress.getHostName().equals(ip))) {
                return true;
            }
        } catch (Throwable e) {
            logger.warn(""Failed to retriving local host ip address, try scan network card ip address. cause: ""
                        + e.getMessage());
        }

        try {
            Enumeration<NetworkInterface> interfaces = NetworkInterface.getNetworkInterfaces();
            if (interfaces != null) {
                while (interfaces.hasMoreElements()) {
                    try {
                        NetworkInterface network = interfaces.nextElement();
                        Enumeration<InetAddress> addresses = network.getInetAddresses();
                        if (addresses != null) {
                            while (addresses.hasMoreElements()) {
                                try {
                                    InetAddress address = addresses.nextElement();
                                    if (address.isLoopbackAddress() || isValidHostAddress(address) && address.getHostAddress().equals(ip)) {
                                        return true;
                                    }
                                } catch (Throwable e) {
                                    logger.warn(""Failed to retriving network card ip address. cause:"" + e.getMessage());
                                }
                            }
                        }
                    } catch (Throwable e) {
                        logger.warn(""Failed to retriving network card ip address. cause:"" + e.getMessage());
                    }
                }
            }
        } catch (Throwable e) {
            logger.warn(""Failed to retriving network card ip address. cause:"" + e.getMessage());
        }

        return false;
    }"
"public void setLoggedOutIndicatorPattern(String loggedOutIndicatorPattern) {
		if (loggedOutIndicatorPattern == null || loggedOutIndicatorPattern.trim().length() == 0) {
			this.loggedOutIndicatorPattern = null;
		} else {
			this.loggedOutIndicatorPattern = Pattern.compile(loggedOutIndicatorPattern);
		}
	}"
"@Nonnull
    public UserDetails loadUserByUsername(String idOrFullName) throws UsernameNotFoundException, DataAccessException, ExecutionException {
        Boolean exists = existenceCache.getIfPresent(idOrFullName);
        if(exists != null && !exists) {
            throw new UsernameNotFoundException(String.format(""\""%s\"" does not exist"", idOrFullName));
        } else {
            try {
                return detailsCache.get(idOrFullName, new Retriever(idOrFullName));
            } catch (ExecutionException | UncheckedExecutionException e) {
                if (e.getCause() instanceof UsernameNotFoundException) {
                    throw ((UsernameNotFoundException)e.getCause());
                } else if (e.getCause() instanceof DataAccessException) {
                    throw ((DataAccessException)e.getCause());
                } else {
                    throw e;
                }
            }
        }
    }"
"@SuppressWarnings(""unchecked"")
	public static <T> Bindable<T> ofInstance(T instance) {
		Assert.notNull(instance, ""Instance must not be null"");
		Class<T> type = (Class<T>) instance.getClass();
		return of(type).withExistingValue(instance);
	}"
"protected String digestAndEncodeWithSalt(final MessageDigest md) {
        val sanitizedSalt = StringUtils.replace(salt, ""\n"", "" "");
        val digested = md.digest(sanitizedSalt.getBytes(StandardCharsets.UTF_8));
        return EncodingUtils.encodeBase64(digested, false);
    }"
"@Override public boolean send(String text) {
    if (text == null) throw new NullPointerException(""text == null"");
    return send(ByteString.encodeUtf8(text), OPCODE_TEXT);
  }"
"public int getInteger(String key, int defaultValue) {
		Object o = getRawValue(key);
		if (o == null) {
			return defaultValue;
		}

		return convertToInt(o, defaultValue);
	}"
"@SuppressWarnings(""EqualsBetweenInconvertibleTypes"")
	public byte[] getBytes(String key, byte[] defaultValue) {

		Object o = getRawValue(key);
		if (o == null) {
			return defaultValue;
		}
		else if (o.getClass().equals(byte[].class)) {
			return (byte[]) o;
		}
		else {
			LOG.warn(""Configuration cannot evaluate value {} as a byte[] value"", o);
			return defaultValue;
		}
	}"
"private byte[] encrypt(byte[] in, int inOff, int inLen) {
		// 加密数据
		byte[] c2 = new byte[inLen];
		System.arraycopy(in, inOff, c2, 0, c2.length);

		final ECMultiplier multiplier = createBasePointMultiplier();

		byte[] c1;
		ECPoint kPB;
		BigInteger k;
		do {
			k = nextK();
			// 产生随机数计算出曲线点C1
			c1 = multiplier.multiply(ecParams.getG(), k).normalize().getEncoded(false);
			kPB = ((ECPublicKeyParameters) ecKey).getQ().multiply(k).normalize();
			kdf(kPB, c2);
		} while (notEncrypted(c2, in, inOff));

		// 杂凑值，效验数据
		byte[] c3 = new byte[digest.getDigestSize()];

		addFieldElement(kPB.getAffineXCoord());
		this.digest.update(in, inOff, inLen);
		addFieldElement(kPB.getAffineYCoord());

		this.digest.doFinal(c3, 0);

		// 按照对应模式输出结果
		switch (mode) {
		case C1C3C2:
			return Arrays.concatenate(c1, c3, c2);
		default:
			return Arrays.concatenate(c1, c2, c3);
		}
	}"
"int flags(int id) {
    int result = 0;
    if (isPersisted(id)) result |= Settings.PERSISTED;
    if (persistValue(id)) result |= Settings.PERSIST_VALUE;
    return result;
  }"
"public static boolean addShutdownHookThread(
		final Thread shutdownHook,
		final String serviceName,
		final Logger logger) {

		checkNotNull(shutdownHook);
		checkNotNull(logger);

		try {
			// Add JVM shutdown hook to call shutdown of service
			Runtime.getRuntime().addShutdownHook(shutdownHook);
			return true;
		} catch (IllegalStateException e) {
			// JVM is already shutting down. no need to do our work
		} catch (Throwable t) {
			logger.error(""Cannot register shutdown hook that cleanly terminates {}."", serviceName, t);
		}
		return false;
	}"
"public SDVariable constant(String name, float value) {
        try(MemoryWorkspace ws = Nd4j.getMemoryManager().scopeOutOfWorkspaces()) {
            return constant(name, Nd4j.scalar(value));
        }
    }"
"public <P extends Plugin> List<P> getPlugins(Class<P> clazz) {
        List<P> result = new ArrayList<>();
        for (PluginWrapper w: pluginManager.getPlugins(clazz)) {
            result.add((P)w.getPlugin());
        }
        return Collections.unmodifiableList(result);
    }"
"@Override
  public void onException(Throwable failureCause) {
    Preconditions.checkNotNull(failureCause, ""failureCause"");
    Status status = Status.UNAVAILABLE.withCause(failureCause);
    startGoAway(0, ErrorCode.INTERNAL_ERROR, status);
  }"
"public void reconnect(final JobID jobId) {
		Preconditions.checkNotNull(jobId, ""JobID must not be null."");

		final Tuple2<LeaderRetrievalService, JobManagerLeaderListener> jobLeaderService = jobLeaderServices.get(jobId);

		if (jobLeaderService != null) {
			jobLeaderService.f1.reconnect();
		} else {
			LOG.info(""Cannot reconnect to job {} because it is not registered."", jobId);
		}
	}"
"public Subject newSubject(final NameID nameId,
                              final NameID subjectConfNameId,
                              final String recipient,
                              final ZonedDateTime notOnOrAfter,
                              final String inResponseTo,
                              final ZonedDateTime notBefore) {

        LOGGER.debug(""Building subject for NameID [{}] and recipient [{}], in response to [{}]"", nameId, recipient, inResponseTo);
        val confirmation = newSamlObject(SubjectConfirmation.class);
        confirmation.setMethod(SubjectConfirmation.METHOD_BEARER);
        val data = newSamlObject(SubjectConfirmationData.class);

        if (StringUtils.isNotBlank(recipient)) {
            data.setRecipient(recipient);
        }

        if (notOnOrAfter != null) {
            data.setNotOnOrAfter(DateTimeUtils.dateTimeOf(notOnOrAfter));
        }

        if (StringUtils.isNotBlank(inResponseTo)) {
            data.setInResponseTo(inResponseTo);

            val ip = InetAddressUtils.getByName(inResponseTo);
            if (ip != null) {
                data.setAddress(ip.getHostName());
            }

        }

        if (notBefore != null) {
            data.setNotBefore(DateTimeUtils.dateTimeOf(notBefore));
        }

        confirmation.setSubjectConfirmationData(data);

        val subject = newSamlObject(Subject.class);
        if (nameId != null) {
            subject.setNameID(nameId);

            if (subjectConfNameId != null) {
                confirmation.setNameID(subjectConfNameId);
            }
            subject.setEncryptedID(null);
            confirmation.setEncryptedID(null);
        }
        subject.getSubjectConfirmations().add(confirmation);

        LOGGER.debug(""Built subject [{}]"", subject);
        return subject;
    }"
"public void addPolicy(final ExpirationPolicy policy) {
        LOGGER.trace(""Adding expiration policy [{}] with name [{}]"", policy, policy.getName());
        this.policies.put(policy.getName(), policy);
    }"
"protected void configureSigningKey(final String signingSecretKey) {
        try {
            if (ResourceUtils.doesResourceExist(signingSecretKey)) {
                configureSigningKeyFromPrivateKeyResource(signingSecretKey);
            }
        } finally {
            if (this.signingKey == null) {
                setSigningKey(new AesKey(signingSecretKey.getBytes(StandardCharsets.UTF_8)));
                LOGGER.trace(""Created signing key instance [{}] based on provided secret key"", this.signingKey.getClass().getSimpleName());
            }
        }
    }"
"protected void validateName(String name, String typeDescription) {
        if (!APPLICATION_NAME_PATTERN.matcher(name).matches()) {
            throw new DiscoveryException(typeDescription + "" ["" + name + ""] must start with a letter, end with a letter or digit and contain only letters, digits or hyphens. Example: foo-bar"");
        }
    }"
"public static byte[] hmacSha1(byte[] input, byte[] key) {
		try {
			SecretKey secretKey = new SecretKeySpec(key, HMACSHA1_ALG);
			Mac mac = Mac.getInstance(HMACSHA1_ALG);
			mac.init(secretKey);
			return mac.doFinal(input);
		} catch (GeneralSecurityException e) {
			throw ExceptionUtil.unchecked(e);
		}
	}"
"public static Map<String,List<Writable>> getUnique(List<String> columnNames, Schema schema, JavaRDD<List<Writable>> data){
        Map<String,Set<Writable>> m = data.aggregate(null, new UniqueAddFunction(columnNames, schema), new UniqueMergeFunction());
        Map<String,List<Writable>> out = new HashMap<>();
        for(String s : m.keySet()){
            out.put(s, new ArrayList<>(m.get(s)));
        }
        return out;
    }"
"public static List<String> toLines(final File file) throws IOException {
		return Files.readAllLines(file.toPath(), Charsets.UTF_8);
	}"
"public Collection<String> getUnprotectedRootActions() {
        Set<String> names = new TreeSet<>();
        names.add(""jnlpJars""); // TODO cleaner to refactor doJnlpJars into a URA (see also JENKINS-44100)
        // TODO consider caching (expiring cache when actions changes)
        for (Action a : getActions()) {
            if (a instanceof UnprotectedRootAction) {
                String url = a.getUrlName();
                if (url == null) continue;
                names.add(url);
            }
        }
        return names;
    }"
"void set_composite_vector()
    {
        composite_.clear();
        for (Document<K> document : documents_)
        {
            composite_.add_vector(document.feature());
        }
    }"
"@SuppressWarnings(""unchecked"")
	public static <T> T[] newArray(Class<?> componentType, int newSize) {
		return (T[]) Array.newInstance(componentType, newSize);
	}"
"public static boolean string2File(File file, String data) throws IOException {
        if (!file.getParentFile().exists()) {
            file.getParentFile().mkdirs();
        }
        FileWriter writer = null;
        try {
            writer = new FileWriter(file, false);
            writer.write(data);
        } finally {
            if (writer != null) {
                writer.close();
            }
        }
        return true;
    }"
"@Deprecated
    public void setSoTimeout(int timeout)
        throws SocketException, IllegalStateException {
        this.params.setSoTimeout(timeout);
        if (this.socket != null) {
            this.socket.setSoTimeout(timeout);
        }
    }"
"public static String dateSub(long ts, int days, TimeZone tz) {
		ZoneId zoneId = tz.toZoneId();
		Instant instant = Instant.ofEpochMilli(ts);
		ZonedDateTime zdt = ZonedDateTime.ofInstant(instant, zoneId);
		long resultTs = zdt.minusDays(days).toInstant().toEpochMilli();
		return dateFormat(resultTs, DATE_FORMAT_STRING, tz);
	}"
"private String escapeSpecialChars(final String s) {
        char c;
        final StringBuffer so = new StringBuffer();

        final int len = s.length();
        for (int i = 0; i < len; i++) {
            c = s.charAt(i);

            /*
             * note that some of these escape sequences are unique to Erlang,
             * which is why the corresponding 'case' values use octal. The
             * resulting string is, of course, in Erlang format.
             */

            switch (c) {
            // some special escape sequences
            case '\b':
                so.append(""\\b"");
                break;

            case 0177:
                so.append(""\\d"");
                break;

            case 033:
                so.append(""\\e"");
                break;

            case '\f':
                so.append(""\\f"");
                break;

            case '\n':
                so.append(""\\n"");
                break;

            case '\r':
                so.append(""\\r"");
                break;

            case '\t':
                so.append(""\\t"");
                break;

            case 013:
                so.append(""\\v"");
                break;

            case '\\':
                so.append(""\\\\"");
                break;

            case '\'':
                so.append(""\\'"");
                break;

            case '\""':
                so.append(""\\\"""");
                break;

            default:
                // some other character classes
                if (c < 027) {
                    // control chars show as ""\^@"", ""\^A"" etc
                    so.append(""\\^"" + (char) ('A' - 1 + c));
                } else if (c > 126) {
                    // 8-bit chars show as \345 \344 \366 etc
                    so.append(""\\"" + Integer.toOctalString(c));
                } else {
                    // character is printable without modification!
                    so.append(c);
                }
            }
        }
        return new String(so);
    }"
"public void createBindingChoices(Binder binder, String defaultValue)
  {
    String prop = PROPERTY;
    PolyBind.createChoiceWithDefault(binder, prop, Key.get(MetadataStorageConnector.class), defaultValue);
    PolyBind.createChoiceWithDefault(binder, prop, Key.get(MetadataStorageProvider.class), defaultValue);
    PolyBind.createChoiceWithDefault(binder, prop, Key.get(SQLMetadataConnector.class), defaultValue);

    PolyBind.createChoiceWithDefault(binder, prop, Key.get(MetadataSegmentManager.class), defaultValue);
    PolyBind.createChoiceWithDefault(binder, prop, Key.get(MetadataSegmentManagerProvider.class), defaultValue);
    PolyBind.createChoiceWithDefault(binder, prop, Key.get(MetadataRuleManager.class), defaultValue);
    PolyBind.createChoiceWithDefault(binder, prop, Key.get(MetadataRuleManagerProvider.class), defaultValue);
    PolyBind.createChoiceWithDefault(binder, prop, Key.get(MetadataSegmentPublisher.class), defaultValue);
    PolyBind.createChoiceWithDefault(binder, prop, Key.get(MetadataSegmentPublisherProvider.class), defaultValue);
    PolyBind.createChoiceWithDefault(binder, prop, Key.get(IndexerMetadataStorageCoordinator.class), defaultValue);
    PolyBind.createChoiceWithDefault(binder, prop, Key.get(MetadataStorageActionHandlerFactory.class), defaultValue);
    PolyBind.createChoiceWithDefault(binder, prop, Key.get(MetadataStorageUpdaterJobHandler.class), defaultValue);
    PolyBind.createChoiceWithDefault(binder, prop, Key.get(AuditManager.class), defaultValue);
    PolyBind.createChoiceWithDefault(binder, prop, Key.get(AuditManagerProvider.class), defaultValue);
    PolyBind.createChoiceWithDefault(binder, prop, Key.get(MetadataSupervisorManager.class), defaultValue);
  }"
"public static List<Feature> parseFeatures(URL file) throws IOException {
    InputStream input = file.openStream();
    try {
      Reader reader = new InputStreamReader(input, Charset.forName(""UTF-8""));
      try {
        FeatureDatabase.Builder database = FeatureDatabase.newBuilder();
        JsonFormat.parser().merge(reader, database);
        return database.getFeatureList();
      } finally {
        reader.close();
      }
    } finally {
      input.close();
    }
  }"
"public static boolean isJsonArray(String str) {
		if (StrUtil.isBlank(str)) {
			return false;
		}
		return StrUtil.isWrap(str.trim(), '[', ']');
	}"
"public static Boolean toBooleanObject(String str) {
		return str != null ? Boolean.valueOf(str) : null;
	}"
"protected ClientTransportConfig providerToClientConfig(ProviderInfo providerInfo) {
        return new ClientTransportConfig()
            .setConsumerConfig(consumerConfig)
            .setProviderInfo(providerInfo)
            .setContainer(consumerConfig.getProtocol())
            .setConnectTimeout(consumerConfig.getConnectTimeout())
            .setInvokeTimeout(consumerConfig.getTimeout())
            .setDisconnectTimeout(consumerConfig.getDisconnectTimeout())
            .setConnectionNum(consumerConfig.getConnectionNum())
            .setChannelListeners(consumerConfig.getOnConnect());
    }"
"public OtpErlangObject receive() throws IOException, OtpErlangExit,
            OtpAuthException {
        try {
            return receiveMsg().getMsg();
        } catch (final OtpErlangDecodeException e) {
            close();
            throw new IOException(e.getMessage());
        }
    }"
"public static DateTime offset(Date date, DateField dateField, int offset) {
		Calendar cal = Calendar.getInstance();
		cal.setTime(date);
		cal.add(dateField.getValue(), offset);
		return new DateTime(cal.getTime());
	}"
"private void handleCompleter( CountedCompleter cc ) {
    assert cc instanceof H2OCountedCompleter;
    if( _fjtasks == null || !_fjtasks.contains(cc) )
      addCompleter((H2OCountedCompleter)cc);
    _dt.setCompleter(null);
  }"
"private static String[] getAttributeValues(final RDNSequence rdnSequence, final AttributeType attribute) {
        val values = new ArrayList<String>();
        for (val rdn : rdnSequence.backward()) {
            for (val attr : rdn.getAttributes()) {
                if (attr.getType().equals(attribute)) {
                    values.add(attr.getValue());
                }
            }
        }
        return values.toArray(ArrayUtils.EMPTY_STRING_ARRAY);
    }"
"public void startLifeCycle(Extension ext) throws DatabaseException, DatabaseUnsupportedException {
        ext.init();
        ext.databaseOpen(model.getDb());
        ext.initModel(model);
        ext.initXML(model.getSession(), model.getOptionsParam());
        ext.initView(view);
        
        ExtensionHook extHook = new ExtensionHook(model, view);
        extensionHooks.put(ext, extHook);
        try {
            ext.hook(extHook);

            hookContextDataFactories(ext, extHook);
            hookApiImplementors(ext, extHook);

            if (view != null) {
                // no need to hook view if no GUI
                hookView(ext, view, extHook);
                hookMenu(view, extHook);
            }
            
            hookOptions(extHook);
            hookProxies(extHook);
            ext.optionsLoaded();
            ext.postInit();
        } catch (Exception e) {
            logExtensionInitError(ext, e);
        }
        
        ext.start();

        Proxy proxy = Control.getSingleton().getProxy();
        hookProxyListeners(proxy, extHook.getProxyListenerList());
        hookOverrideMessageProxyListeners(proxy, extHook.getOverrideMessageProxyListenerList());
        hookPersistentConnectionListeners(proxy, extHook.getPersistentConnectionListener());
        hookConnectRequestProxyListeners(proxy, extHook.getConnectRequestProxyListeners());

        if (view != null) {
            hookSiteMapListeners(view.getSiteTreePanel(), extHook.getSiteMapListenerList());
        }
    }"
"@Override
    protected Collection<String> loadBundledPlugins() {
        // this is used in tests, when we want to override the default bundled plugins with .jpl (or .hpl) versions
        if (SystemProperties.getString(""hudson.bundled.plugins"") != null) {
            return Collections.emptySet();
        }

        try {
            return loadPluginsFromWar(""/WEB-INF/plugins"");
        } finally {
            loadDetachedPlugins();
        }
    }"
"public static FilterChain buildConsumerChain(ConsumerConfig<?> consumerConfig, FilterInvoker lastFilter) {
        return new FilterChain(selectActualFilters(consumerConfig, CONSUMER_AUTO_ACTIVES), lastFilter, consumerConfig);
    }"
"@View(name = ""by_token"", map = ""function(doc) { if(doc.token && doc.userId) { emit(doc.token, doc) } }"")
    public List<CouchDbGoogleAuthenticatorToken> findByToken(final Integer otp) {
        return queryView(""by_token"", otp);
    }"
"public static String sanitizeDefaultPort(String url) {
        int afterSchemeIndex = url.indexOf(""://"");
        if(afterSchemeIndex < 0) {
            return url;
        }
        String scheme = url.substring(0, afterSchemeIndex);
        int fromIndex = scheme.length() + 3;
        //Let's see if it is an IPv6 Address
        int ipv6StartIndex = url.indexOf('[', fromIndex);
        if (ipv6StartIndex > 0) {
            fromIndex = url.indexOf(']', ipv6StartIndex);
        }
        int portIndex = url.indexOf(':', fromIndex);
        if(portIndex >= 0) {
            int port = Integer.parseInt(url.substring(portIndex + 1));
            if(isDefaultPort(port, scheme)) {
                return url.substring(0, portIndex);
            }
        }
        return url;
    }"
"private void initializeUnknownCategoricalsPerColumn(GenModel model) {
    unknownCategoricalsPerColumn = new ConcurrentHashMap<>();

    for (int i = 0; i < model.getNumCols(); i++) {
      String[] domainValues = model.getDomainValues(i);
      if (domainValues != null) {
        unknownCategoricalsPerColumn.put(model.getNames()[i], new AtomicLong());
      }
    }

    unknownCategoricalsPerColumn = Collections.unmodifiableMap(unknownCategoricalsPerColumn);
  }"
"public static Map<String, String[]> splitMap(Map<String, String[]> src, double rate)
    {
        assert 0 <= rate && rate <= 1;
        Map<String, String[]> output = new TreeMap<String, String[]>();
        for (Map.Entry<String, String[]> entry : src.entrySet())
        {
            String[][] array = spiltArray(entry.getValue(), rate);
            output.put(entry.getKey(), array[0]);
            entry.setValue(array[1]);
        }

        return output;
    }"
"public List<HistoricVariableInstance> executeList(CommandContext commandContext, Map<String, Object> parameterMap, int firstResult, int maxResults) {
    return commandContext.getHistoricVariableInstanceEntityManager().findHistoricVariableInstancesByNativeQuery(parameterMap, firstResult, maxResults);
  }"
"@Override
	public void addBufferConsumer(BufferConsumer bufferConsumer, int subpartitionIndex) throws IOException {
		checkNotNull(bufferConsumer);

		ResultSubpartition subpartition;
		try {
			checkInProduceState();
			subpartition = subpartitions[subpartitionIndex];
		}
		catch (Exception ex) {
			bufferConsumer.close();
			throw ex;
		}

		if (subpartition.add(bufferConsumer)) {
			notifyPipelinedConsumers();
		}
	}"
"private void goingAway(Status status) {
    lifecycleManager.notifyShutdown(status);
    final Status goAwayStatus = lifecycleManager.getShutdownStatus();
    final int lastKnownStream = connection().local().lastStreamKnownByPeer();
    try {
      connection().forEachActiveStream(new Http2StreamVisitor() {
        @Override
        public boolean visit(Http2Stream stream) throws Http2Exception {
          if (stream.id() > lastKnownStream) {
            NettyClientStream.TransportState clientStream = clientStream(stream);
            if (clientStream != null) {
              clientStream.transportReportStatus(
                  goAwayStatus, RpcProgress.REFUSED, false, new Metadata());
            }
            stream.close();
          }
          return true;
        }
      });
    } catch (Http2Exception e) {
      throw new RuntimeException(e);
    }
  }"
"public String toJson(JsonElement jsonElement) {
    StringWriter writer = new StringWriter();
    toJson(jsonElement, writer);
    return writer.toString();
  }"
"public void run(String[] args) throws Exception {
    ServerConfiguration.Builder configBuilder = ServerConfiguration.newBuilder();
    ServerConfiguration config;
    try {
      config = configBuilder.build(args);
    } catch (Exception e) {
      System.out.println(e.getMessage());
      configBuilder.printUsage();
      return;
    }

    final Server server = newServer(config);
    server.start();

    System.out.println(""QPS Server started on "" + config.address);

    Runtime.getRuntime().addShutdownHook(new Thread() {
      @Override
      @SuppressWarnings(""CatchAndPrintStackTrace"")
      public void run() {
        try {
          System.out.println(""QPS Server shutting down"");
          server.shutdown();
        } catch (Exception e) {
          e.printStackTrace();
        }
      }
    });
    server.awaitTermination();
  }"
"private Map<String, Object> toAggsMap(Map<String, Aggregation> fields) throws SqlParseException {
		Map<String, Object> result = new HashMap<>();
		for (Entry<String, Aggregation> entry : fields.entrySet()) {
			result.put(entry.getKey(), covenValue(entry.getValue()));
		}
		return result;
	}"
"public long misses() {
        Lock readerLock = context.ctxLock.readLock();
        readerLock.lock();
        try {
            return SSLContext.sessionMisses(context.ctx);
        } finally {
            readerLock.unlock();
        }
    }"
"void flush(ByteBuf out) {
        final int bitCount = this.bitCount;

        if (bitCount > 0) {
            final long bitBuffer = this.bitBuffer;
            final int shiftToRight = 64 - bitCount;

            if (bitCount <= 8) {
                out.writeByte((int) (bitBuffer >>> shiftToRight << 8 - bitCount));
            } else if (bitCount <= 16) {
                out.writeShort((int) (bitBuffer >>> shiftToRight << 16 - bitCount));
            } else if (bitCount <= 24) {
                out.writeMedium((int) (bitBuffer >>> shiftToRight << 24 - bitCount));
            } else {
                out.writeInt((int) (bitBuffer >>> shiftToRight << 32 - bitCount));
            }
        }
    }"
"private static void requestAndSetOffsetsFromKafka(
			SimpleConsumer consumer,
			List<KafkaTopicPartitionState<TopicAndPartition>> partitionStates,
			Map<TopicAndPartition, PartitionOffsetRequestInfo> partitionToRequestInfo) throws IOException {
		int retries = 0;
		OffsetResponse response;
		while (true) {
			kafka.javaapi.OffsetRequest request = new kafka.javaapi.OffsetRequest(
				partitionToRequestInfo, kafka.api.OffsetRequest.CurrentVersion(), consumer.clientId());
			response = consumer.getOffsetsBefore(request);

			if (response.hasError()) {
				StringBuilder exception = new StringBuilder();
				for (KafkaTopicPartitionState<TopicAndPartition> part : partitionStates) {
					short code;
					if ((code = response.errorCode(part.getTopic(), part.getPartition())) != ErrorMapping.NoError()) {
						exception.append(""\nException for topic="").append(part.getTopic())
							.append("" partition="").append(part.getPartition()).append("": "")
							.append(ExceptionUtils.stringifyException(ErrorMapping.exceptionFor(code)));
					}
				}
				if (++retries >= 3) {
					throw new IOException(""Unable to get last offset for partitions "" + partitionStates + "": ""
						+ exception.toString());
				} else {
					LOG.warn(""Unable to get last offset for partitions: Exception(s): {}"", exception);
				}
			} else {
				break; // leave retry loop
			}
		}

		for (KafkaTopicPartitionState<TopicAndPartition> part: partitionStates) {
			// there will be offsets only for partitions that were requested for
			if (partitionToRequestInfo.containsKey(part.getKafkaPartitionHandle())) {
				final long offset = response.offsets(part.getTopic(), part.getPartition())[0];

				// the offset returned is that of the next record to fetch. because our state reflects the latest
				// successfully emitted record, we subtract one
				part.setOffset(offset - 1);
			}
		}
	}"
"public static @Nonnull User getOrCreateByIdOrFullName(@Nonnull String idOrFullName) {
        return get(idOrFullName, true, Collections.emptyMap());
    }"
"private ArtemisMode deduceMode() {
		if (this.properties.getEmbedded().isEnabled()
				&& ClassUtils.isPresent(EMBEDDED_JMS_CLASS, null)) {
			return ArtemisMode.EMBEDDED;
		}
		return ArtemisMode.NATIVE;
	}"
"public static double subtract(double minuend, double reduction) {
        BigDecimal minuendBd = new BigDecimal(Double.toString(minuend));
        BigDecimal reductionBd = new BigDecimal(Double.toString(reduction));
        return minuendBd.subtract(reductionBd).doubleValue();
    }"
"public void windowUpdateRatio(Http2Stream stream, float ratio) throws Http2Exception {
        assert ctx != null && ctx.executor().inEventLoop();
        checkValidRatio(ratio);
        FlowState state = state(stream);
        state.windowUpdateRatio(ratio);
        state.writeWindowUpdateIfNeeded();
    }"
"public static Object instantiate(String type, ClassLoader classLoader) {
        try {
            return ClassUtils.forName(type, classLoader)
                .flatMap(InstantiationUtils::tryInstantiate)
                .orElseThrow(() -> new InstantiationException(""No class found for name: "" + type));
        } catch (Throwable e) {
            throw new InstantiationException(""Could not instantiate type ["" + type + ""]: "" + e.getMessage(), e);
        }
    }"
"public static <K, V> LinkedHashMap<K, V> sortByEntry(Map<K, V> map, Comparator<Map.Entry<K, V>> comparator) {
		return sortToMap(map.entrySet(), comparator);
	}"
"public void set(int idx) {
    idx -= _bitoff;
    assert (idx >= 0 && idx < _nbits): ""Must have ""+_bitoff+"" <= idx <= "" + (_bitoff+_nbits-1) + "": "" + idx;
    _val[_byteoff+(idx >> 3)] |= ((byte)1 << (idx & 7));
  }"
"protected void shiftRight(int start, int end)
  {
    float prevVal = positions[start];
    long prevCnt = bins[start];

    for (int i = start + 1; i <= end; ++i) {
      float tmpVal = positions[i];
      long tmpCnt = bins[i];

      positions[i] = prevVal;
      bins[i] = prevCnt;

      prevVal = tmpVal;
      prevCnt = tmpCnt;
    }
  }"
"private static boolean endsWith(byte[] subject, byte[] suffix) {
    int start = subject.length - suffix.length;
    if (start < 0) {
      return false;
    }
    for (int i = start; i < subject.length; i++) {
      if (subject[i] != suffix[i - start]) {
        return false;
      }
    }
    return true;
  }"
"private Map<String, PropertyType> buildPropertyTypes(Class<?> clazz) {
        Map<String, PropertyType> r = new HashMap<>();
        for (Field f : clazz.getFields())
            r.put(f.getName(),new PropertyType(f));

        for (Method m : clazz.getMethods())
            if(m.getName().startsWith(""get""))
                r.put(Introspector.decapitalize(m.getName().substring(3)),new PropertyType(m));

        return r;
    }"
"@SuppressWarnings(""unused"")
    @Internal
    @UsedByGeneratedCode
    protected static void registerAnnotationDefaults(String annotation, Map<String, Object> defaultValues) {
        AnnotationMetadataSupport.registerDefaultValues(annotation, defaultValues);
    }"
"@Deprecated
    public static boolean uninstallAddOnFiles(AddOn addOn, AddOnUninstallationProgressCallback callback) {
        return uninstallAddOnFiles(addOn, callback, null);
    }"
"private boolean updateMemoryReservation()
    {
        // Operator/driver will be blocked on memory after we call localUserMemoryContext.setBytes().
        // If memory is not available, once we return, this operator will be blocked until memory is available.
        long memorySizeInBytes = groupByHash.map(GroupByHash::getEstimatedSize).orElse(0L) + partitionRowCount.sizeOf();
        localUserMemoryContext.setBytes(memorySizeInBytes);
        // If memory is not available, inform the caller that we cannot proceed for allocation.
        return operatorContext.isWaitingForMemory().isDone();
    }"
"public static boolean isInVpc(InstanceInfo instanceInfo) {
        if (instanceInfo.getDataCenterInfo() instanceof AmazonInfo) {
            AmazonInfo info = (AmazonInfo) instanceInfo.getDataCenterInfo();
            String vpcId = info.get(AmazonInfo.MetaDataKey.vpcId);
            return !isNullOrEmpty(vpcId);
        }

        return false;
    }"
"private static ZipOutputStream getZipOutputStream(File zipFile, Charset charset) {
		return getZipOutputStream(FileUtil.getOutputStream(zipFile), charset);
	}"
"public static DescriptorExtensionList<Publisher,Descriptor<Publisher>> all() {
        return Jenkins.getInstance().<Publisher,Descriptor<Publisher>>getDescriptorList(Publisher.class);
    }"
"private Ordering<Row> getRowOrderingForPushDown(
      final boolean granular,
      final DefaultLimitSpec limitSpec
  )
  {
    final boolean sortByDimsFirst = getContextSortByDimsFirst();

    final List<String> orderedFieldNames = new ArrayList<>();
    final Set<Integer> dimsInOrderBy = new HashSet<>();
    final List<Boolean> needsReverseList = new ArrayList<>();
    final List<ValueType> dimensionTypes = new ArrayList<>();
    final List<StringComparator> comparators = new ArrayList<>();

    for (OrderByColumnSpec orderSpec : limitSpec.getColumns()) {
      boolean needsReverse = orderSpec.getDirection() != OrderByColumnSpec.Direction.ASCENDING;
      int dimIndex = OrderByColumnSpec.getDimIndexForOrderBy(orderSpec, dimensions);
      if (dimIndex >= 0) {
        DimensionSpec dim = dimensions.get(dimIndex);
        orderedFieldNames.add(dim.getOutputName());
        dimsInOrderBy.add(dimIndex);
        needsReverseList.add(needsReverse);
        final ValueType type = dimensions.get(dimIndex).getOutputType();
        dimensionTypes.add(type);
        comparators.add(orderSpec.getDimensionComparator());
      }
    }

    for (int i = 0; i < dimensions.size(); i++) {
      if (!dimsInOrderBy.contains(i)) {
        orderedFieldNames.add(dimensions.get(i).getOutputName());
        needsReverseList.add(false);
        final ValueType type = dimensions.get(i).getOutputType();
        dimensionTypes.add(type);
        comparators.add(StringComparators.LEXICOGRAPHIC);
      }
    }

    final Comparator<Row> timeComparator = getTimeComparator(granular);

    if (timeComparator == null) {
      return Ordering.from(
          new Comparator<Row>()
          {
            @Override
            public int compare(Row lhs, Row rhs)
            {
              return compareDimsForLimitPushDown(
                  orderedFieldNames,
                  needsReverseList,
                  dimensionTypes,
                  comparators,
                  lhs,
                  rhs
              );
            }
          }
      );
    } else if (sortByDimsFirst) {
      return Ordering.from(
          new Comparator<Row>()
          {
            @Override
            public int compare(Row lhs, Row rhs)
            {
              final int cmp = compareDimsForLimitPushDown(
                  orderedFieldNames,
                  needsReverseList,
                  dimensionTypes,
                  comparators,
                  lhs,
                  rhs
              );
              if (cmp != 0) {
                return cmp;
              }

              return timeComparator.compare(lhs, rhs);
            }
          }
      );
    } else {
      return Ordering.from(
          new Comparator<Row>()
          {
            @Override
            public int compare(Row lhs, Row rhs)
            {
              final int timeCompare = timeComparator.compare(lhs, rhs);

              if (timeCompare != 0) {
                return timeCompare;
              }

              return compareDimsForLimitPushDown(
                  orderedFieldNames,
                  needsReverseList,
                  dimensionTypes,
                  comparators,
                  lhs,
                  rhs
              );
            }
          }
      );
    }
  }"
"private static void run(String[] args) {
		try {
			LOG.debug(""All environment variables: {}"", ENV);

			final String currDir = ENV.get(Environment.PWD.key());
			LOG.info(""Current working Directory: {}"", currDir);

			final Configuration configuration = GlobalConfiguration.loadConfiguration(currDir);

			//TODO provide path.
			FileSystem.initialize(configuration, PluginUtils.createPluginManagerFromRootFolder(Optional.empty()));

			setupConfigurationAndInstallSecurityContext(configuration, currDir, ENV);

			final String containerId = ENV.get(YarnResourceManager.ENV_FLINK_CONTAINER_ID);
			Preconditions.checkArgument(containerId != null,
				""ContainerId variable %s not set"", YarnResourceManager.ENV_FLINK_CONTAINER_ID);

			SecurityUtils.getInstalledContext().runSecured((Callable<Void>) () -> {
				TaskManagerRunner.runTaskManager(configuration, new ResourceID(containerId));
				return null;
			});
		}
		catch (Throwable t) {
			final Throwable strippedThrowable = ExceptionUtils.stripException(t, UndeclaredThrowableException.class);
			// make sure that everything whatever ends up in the log
			LOG.error(""YARN TaskManager initialization failed."", strippedThrowable);
			System.exit(INIT_ERROR_EXIT_CODE);
		}
	}"
"private void advanceTime(NFAState nfaState, long timestamp) throws Exception {
		try (SharedBufferAccessor<IN> sharedBufferAccessor = partialMatches.getAccessor()) {
			Collection<Tuple2<Map<String, List<IN>>, Long>> timedOut =
					nfa.advanceTime(sharedBufferAccessor, nfaState, timestamp);
			if (!timedOut.isEmpty()) {
				processTimedOutSequences(timedOut);
			}
		}
	}"
"public Graph<K, VV, EV> addEdges(List<Edge<K, EV>> newEdges) {

		DataSet<Edge<K, EV>> newEdgesDataSet = this.context.fromCollection(newEdges);

		DataSet<Edge<K, EV>> validNewEdges = this.getVertices().join(newEdgesDataSet)
				.where(0).equalTo(0)
				.with(new JoinVerticesWithEdgesOnSrc<>()).name(""Join with source"")
				.join(this.getVertices()).where(1).equalTo(0)
				.with(new JoinWithVerticesOnTrg<>()).name(""Join with target"");

		return Graph.fromDataSet(this.vertices, this.edges.union(validNewEdges), this.context);
	}"
"@SuppressWarnings(""unchecked"")
	public static <T> Object insert(Object array, int index, T... newElements) {
		if (isEmpty(newElements)) {
			return array;
		}
		if(isEmpty(array)) {
			return newElements;
		}
		
		final int len = length(array);
		if (index < 0) {
			index = (index % len) + len;
		}
		
		final T[] result = newArray(array.getClass().getComponentType(), Math.max(len, index) + newElements.length);
		System.arraycopy(array, 0, result, 0, Math.min(len, index));
		System.arraycopy(newElements, 0, result, index, newElements.length);
		if (index < len) {
			System.arraycopy(array, index, result, index + newElements.length, len - index);
		}
		return result;
	}"
"public PythonWindowedStream count_window(long size, long slide) {
		return new PythonWindowedStream<GlobalWindow>(this.stream.countWindow(size, slide));
	}"
"private Pipeline doToModel(PipelineDO pipelineDo) {
        Pipeline pipeline = new Pipeline();
        try {
            pipeline.setId(pipelineDo.getId());
            pipeline.setName(pipelineDo.getName());
            pipeline.setParameters(pipelineDo.getParameters());
            pipeline.setDescription(pipelineDo.getDescription());
            pipeline.setGmtCreate(pipelineDo.getGmtCreate());
            pipeline.setGmtModified(pipelineDo.getGmtModified());
            pipeline.setChannelId(pipelineDo.getChannelId());
            pipeline.getParameters().setMainstemClientId(pipeline.getId().shortValue());

            // 组装DatamediaPair
            List<DataMediaPair> pairs = dataMediaPairService.listByPipelineId(pipelineDo.getId());
            Collections.sort(pairs, new DataMediaPairComparable());
            pipeline.setPairs(pairs);

            // 组装Node
            List<PipelineNodeRelationDO> relations = pipelineNodeRelationDao.listByPipelineIds(pipelineDo.getId());

            List<Long> totalNodeIds = new ArrayList<Long>();

            for (PipelineNodeRelationDO relation : relations) {
                Long nodeId = relation.getNodeId();
                if (!totalNodeIds.contains(nodeId)) {
                    totalNodeIds.add(nodeId);
                }
            }

            List<Node> totalNodes = nodeService.listByIds(totalNodeIds.toArray(new Long[totalNodeIds.size()]));
            List<Node> selectNodes = new ArrayList<Node>();
            List<Node> extractNodes = new ArrayList<Node>();
            List<Node> loadNodes = new ArrayList<Node>();

            for (Node node : totalNodes) {
                for (PipelineNodeRelationDO relation : relations) {
                    if (node.getId().equals(relation.getNodeId())) {
                        if (relation.getLocation().isSelect()) {
                            selectNodes.add(node);
                        } else if (relation.getLocation().isExtract()) {
                            extractNodes.add(node);
                        } else if (relation.getLocation().isLoad()) {
                            loadNodes.add(node);
                        }
                    }
                }
            }

            pipeline.setSelectNodes(selectNodes);
            pipeline.setExtractNodes(extractNodes);
            pipeline.setLoadNodes(loadNodes);

        } catch (Exception e) {
            logger.error(""ERROR ## change the pipeline Do to Model has an exception"");
            throw new ManagerException(e);
        }

        return pipeline;
    }"
"@Override
    public String getNewTicketId(final String prefix) {
        val artifact = getSAMLArtifactType();
        return prefix + '-' + artifact.base64Encode();
    }"
"public int startScan(Target target, User user, Object[] customConfigurations) {
		return startScan(createDisplayName(target, customConfigurations), target, user, customConfigurations);
	}"
"@Override
    public void destroy() {
        executor.shutdownNow();
        try {
            dataSource.close();
        } catch (Exception e) {
            logger.error(e.getMessage(), e);
        }
    }"
"public String[] getInterfaces() {
        int index = header + 6;
        int n = readUnsignedShort(index);
        String[] interfaces = new String[n];
        if (n > 0) {
            char[] buf = new char[maxStringLength];
            for (int i = 0; i < n; ++i) {
                index += 2;
                interfaces[i] = readClass(index, buf);
            }
        }
        return interfaces;
    }"
"public static void copyDir(@NotNull Path from, @NotNull Path to) throws IOException {
		Validate.isTrue(isDirExists(from), ""%s is not exist or not a dir"", from);
		Validate.notNull(to);
		makesureDirExists(to);

		try (DirectoryStream<Path> dirStream = Files.newDirectoryStream(from)) {
			for (Path path : dirStream) {
				copy(path, to.resolve(path.getFileName()));
			}
		}
	}"
"public ApiListingBuilder produces(Set<String> mediaTypes) {
    if (mediaTypes != null) {
      this.produces = new HashSet<>(mediaTypes);
    }
    return this;
  }"
"public static Pair<INDArray,int[]> pullLastTimeSteps(INDArray pullFrom, INDArray mask){
        //Then: work out, from the mask array, which time step of activations we want, extract activations
        //Also: record where they came from (so we can do errors later)
        int[] fwdPassTimeSteps;
        INDArray out;
        if (mask == null) {

            // FIXME: int cast
            //No mask array -> extract same (last) column for all
            int lastTS = (int) pullFrom.size(2) - 1;
            out = pullFrom.get(NDArrayIndex.all(), NDArrayIndex.all(), NDArrayIndex.point(lastTS));
            fwdPassTimeSteps = null; //Null -> last time step for all examples
        } else {
            val outShape = new long[] {pullFrom.size(0), pullFrom.size(1)};
            out = Nd4j.create(outShape);

            //Want the index of the last non-zero entry in the mask array
            INDArray lastStepArr = BooleanIndexing.lastIndex(mask, Conditions.epsNotEquals(0.0), 1);
            fwdPassTimeSteps = lastStepArr.data().asInt();

            //Now, get and assign the corresponding subsets of 3d activations:
            for (int i = 0; i < fwdPassTimeSteps.length; i++) {
                //TODO can optimize using reshape + pullRows
                out.putRow(i, pullFrom.get(NDArrayIndex.point(i), NDArrayIndex.all(),
                        NDArrayIndex.point(fwdPassTimeSteps[i])));
            }
        }

        return new Pair<>(out, fwdPassTimeSteps);
    }"
"@SuppressWarnings({ ""unchecked"" })
    /* package */<T> HystrixCachedObservable<T> get(String cacheKey) {
        ValueCacheKey key = getRequestCacheKey(cacheKey);
        if (key != null) {
            ConcurrentHashMap<ValueCacheKey, HystrixCachedObservable<?>> cacheInstance = requestVariableForCache.get(concurrencyStrategy);
            if (cacheInstance == null) {
                throw new IllegalStateException(""Request caching is not available. Maybe you need to initialize the HystrixRequestContext?"");
            }
            /* look for the stored value */
            return (HystrixCachedObservable<T>) cacheInstance.get(key);
        }
        return null;
    }"
"@Override
    public void tagLocation(INDArray array, Location location) {
        if (location == Location.HOST)
            AtomicAllocator.getInstance().getAllocationPoint(array).tickHostWrite();
        else if (location == Location.DEVICE)
            AtomicAllocator.getInstance().getAllocationPoint(array).tickDeviceWrite();
        else if (location == Location.EVERYWHERE) {
            AtomicAllocator.getInstance().getAllocationPoint(array).tickDeviceWrite();
            AtomicAllocator.getInstance().getAllocationPoint(array).tickHostRead();
        }
    }"
"private static <T> T extractSingleton(Collection<T> collection) {
		if (collection == null || collection.isEmpty()) {
			return null;
		}

		if (collection.size() == 1) {
			return collection.iterator().next();
		} else {
			throw new IllegalStateException(""Expected singleton collection, but found size: "" + collection.size());
		}
	}"
"@ShellMethod(key = ""jasypt-list-algorithms"", value = ""List alogrithms you can use with Jasypt for property encryption"")
    public void listAlgorithms(@ShellOption(value = {""includeBC""},
        help = ""Include Bouncy Castle provider"") final boolean includeBC) {
        if (includeBC) {
            if (Security.getProvider(BouncyCastleProvider.PROVIDER_NAME) == null) {
                Security.addProvider(new BouncyCastleProvider());
            }
        } else {
            Security.removeProvider(BouncyCastleProvider.PROVIDER_NAME);
        }
        val providers = Security.getProviders();
        LOGGER.info(""Loaded providers: "");
        for (val provider : providers) {
            LOGGER.info(""Provider: [{}] [{}]"", provider.getName(), provider.getClass().getName());
        }
        val pbeAlgos = AlgorithmRegistry.getAllPBEAlgorithms();
        LOGGER.info(""==== JASYPT Password Based Encryption Algorithms ====\n"");
        for (val pbeAlgo : pbeAlgos) {
            LOGGER.info(pbeAlgo.toString());
        }
    }"
"@Deprecated
    public Postcard build(String path, String group) {
        return _ARouter.getInstance().build(path, group);
    }"
"public boolean isMatching(ResourceProfile required) {

		if (required == UNKNOWN) {
			return true;
		}

		if (cpuCores >= required.getCpuCores() &&
				heapMemoryInMB >= required.getHeapMemoryInMB() &&
				directMemoryInMB >= required.getDirectMemoryInMB() &&
				nativeMemoryInMB >= required.getNativeMemoryInMB() &&
				networkMemoryInMB >= required.getNetworkMemoryInMB()) {
			for (Map.Entry<String, Resource> resource : required.extendedResources.entrySet()) {
				if (!extendedResources.containsKey(resource.getKey()) ||
						!extendedResources.get(resource.getKey()).getResourceAggregateType().equals(resource.getValue().getResourceAggregateType()) ||
						extendedResources.get(resource.getKey()).getValue() < resource.getValue().getValue()) {
					return false;
				}
			}
			return true;
		}
		return false;
	}"
"static int parseEtcResolverFirstNdots(File etcResolvConf) throws IOException {
        FileReader fr = new FileReader(etcResolvConf);
        BufferedReader br = null;
        try {
            br = new BufferedReader(fr);
            String line;
            while ((line = br.readLine()) != null) {
                if (line.startsWith(OPTIONS_ROW_LABEL)) {
                    int i = line.indexOf(NDOTS_LABEL);
                    if (i >= 0) {
                        i += NDOTS_LABEL.length();
                        final int j = line.indexOf(' ', i);
                        return Integer.parseInt(line.substring(i, j < 0 ? line.length() : j));
                    }
                    break;
                }
            }
        } finally {
            if (br == null) {
                fr.close();
            } else {
                br.close();
            }
        }
        return DEFAULT_NDOTS;
    }"
"public static DateTime offsetSecond(Date date, int offset) {
		return offset(date, DateField.SECOND, offset);
	}"
"private SqlNode registerFrom(
		SqlValidatorScope parentScope,
		SqlValidatorScope usingScope,
		boolean register,
		final SqlNode node,
		SqlNode enclosingNode,
		String alias,
		SqlNodeList extendList,
		boolean forceNullable,
		final boolean lateral) {
		final SqlKind kind = node.getKind();

		SqlNode expr;
		SqlNode newExpr;

		// Add an alias if necessary.
		SqlNode newNode = node;
		if (alias == null) {
			switch (kind) {
				case IDENTIFIER:
				case OVER:
					alias = deriveAlias(node, -1);
					if (alias == null) {
						alias = deriveAlias(node, nextGeneratedId++);
					}
					if (shouldExpandIdentifiers()) {
						newNode = SqlValidatorUtil.addAlias(node, alias);
					}
					break;

				case SELECT:
				case UNION:
				case INTERSECT:
				case EXCEPT:
				case VALUES:
				case UNNEST:
				case OTHER_FUNCTION:
				case COLLECTION_TABLE:
				case MATCH_RECOGNIZE:

					// give this anonymous construct a name since later
					// query processing stages rely on it
					alias = deriveAlias(node, nextGeneratedId++);
					if (shouldExpandIdentifiers()) {
						// Since we're expanding identifiers, we should make the
						// aliases explicit too, otherwise the expanded query
						// will not be consistent if we convert back to SQL, e.g.
						// ""select EXPR$1.EXPR$2 from values (1)"".
						newNode = SqlValidatorUtil.addAlias(node, alias);
					}
					break;
			}
		}

		if (lateral) {
			SqlValidatorScope s = usingScope;
			while (s instanceof JoinScope) {
				s = ((JoinScope) s).getUsingScope();
			}
			final SqlNode node2 = s != null ? s.getNode() : node;
			final TableScope tableScope = new TableScope(parentScope, node2);
			if (usingScope instanceof ListScope) {
				for (ScopeChild child : ((ListScope) usingScope).children) {
					tableScope.addChild(child.namespace, child.name, child.nullable);
				}
			}
			parentScope = tableScope;
		}

		SqlCall call;
		SqlNode operand;
		SqlNode newOperand;

		switch (kind) {
			case AS:
				call = (SqlCall) node;
				if (alias == null) {
					alias = call.operand(1).toString();
				}
				final boolean needAlias = call.operandCount() > 2;
				expr = call.operand(0);
				newExpr =
					registerFrom(
						parentScope,
						usingScope,
						!needAlias,
						expr,
						enclosingNode,
						alias,
						extendList,
						forceNullable,
						lateral);
				if (newExpr != expr) {
					call.setOperand(0, newExpr);
				}

				// If alias has a column list, introduce a namespace to translate
				// column names. We skipped registering it just now.
				if (needAlias) {
					registerNamespace(
						usingScope,
						alias,
						new AliasNamespace(this, call, enclosingNode),
						forceNullable);
				}
				return node;
			case MATCH_RECOGNIZE:
				registerMatchRecognize(parentScope, usingScope,
					(SqlMatchRecognize) node, enclosingNode, alias, forceNullable);
				return node;
			case TABLESAMPLE:
				call = (SqlCall) node;
				expr = call.operand(0);
				newExpr =
					registerFrom(
						parentScope,
						usingScope,
						true,
						expr,
						enclosingNode,
						alias,
						extendList,
						forceNullable,
						lateral);
				if (newExpr != expr) {
					call.setOperand(0, newExpr);
				}
				return node;

			case JOIN:
				final SqlJoin join = (SqlJoin) node;
				final JoinScope joinScope =
					new JoinScope(parentScope, usingScope, join);
				scopes.put(join, joinScope);
				final SqlNode left = join.getLeft();
				final SqlNode right = join.getRight();
				final boolean rightIsLateral = isLateral(right);
				boolean forceLeftNullable = forceNullable;
				boolean forceRightNullable = forceNullable;
				switch (join.getJoinType()) {
					case LEFT:
						forceRightNullable = true;
						break;
					case RIGHT:
						forceLeftNullable = true;
						break;
					case FULL:
						forceLeftNullable = true;
						forceRightNullable = true;
						break;
				}
				final SqlNode newLeft =
					registerFrom(
						parentScope,
						joinScope,
						true,
						left,
						left,
						null,
						null,
						forceLeftNullable,
						lateral);
				if (newLeft != left) {
					join.setLeft(newLeft);
				}
				final SqlNode newRight =
					registerFrom(
						parentScope,
						joinScope,
						true,
						right,
						right,
						null,
						null,
						forceRightNullable,
						lateral);
				if (newRight != right) {
					join.setRight(newRight);
				}
				registerSubQueries(joinScope, join.getCondition());
				final JoinNamespace joinNamespace = new JoinNamespace(this, join);
				registerNamespace(null, null, joinNamespace, forceNullable);
				return join;

			case IDENTIFIER:
				final SqlIdentifier id = (SqlIdentifier) node;
				final IdentifierNamespace newNs =
					new IdentifierNamespace(
						this, id, extendList, enclosingNode,
						parentScope);
				registerNamespace(register ? usingScope : null, alias, newNs,
					forceNullable);
				if (tableScope == null) {
					tableScope = new TableScope(parentScope, node);
				}
				tableScope.addChild(newNs, alias, forceNullable);
				if (extendList != null && extendList.size() != 0) {
					return enclosingNode;
				}
				return newNode;

			case LATERAL:
				return registerFrom(
					parentScope,
					usingScope,
					register,
					((SqlCall) node).operand(0),
					enclosingNode,
					alias,
					extendList,
					forceNullable,
					true);

			case COLLECTION_TABLE:
				call = (SqlCall) node;
				operand = call.operand(0);
				newOperand =
					registerFrom(
						parentScope,
						usingScope,
						register,
						operand,
						enclosingNode,
						alias,
						extendList,
						forceNullable, lateral);
				if (newOperand != operand) {
					call.setOperand(0, newOperand);
				}
				scopes.put(node, parentScope);
				return newNode;

			case UNNEST:
				if (!lateral) {
					return registerFrom(parentScope, usingScope, register, node,
						enclosingNode, alias, extendList, forceNullable, true);
				}
				// fall through
			case SELECT:
			case UNION:
			case INTERSECT:
			case EXCEPT:
			case VALUES:
			case WITH:
			case OTHER_FUNCTION:
				if (alias == null) {
					alias = deriveAlias(node, nextGeneratedId++);
				}
				registerQuery(
					parentScope,
					register ? usingScope : null,
					node,
					enclosingNode,
					alias,
					forceNullable);
				return newNode;

			case OVER:
				if (!shouldAllowOverRelation()) {
					throw Util.unexpected(kind);
				}
				call = (SqlCall) node;
				final OverScope overScope = new OverScope(usingScope, call);
				scopes.put(call, overScope);
				operand = call.operand(0);
				newOperand =
					registerFrom(
						parentScope,
						overScope,
						true,
						operand,
						enclosingNode,
						alias,
						extendList,
						forceNullable,
						lateral);
				if (newOperand != operand) {
					call.setOperand(0, newOperand);
				}

				for (ScopeChild child : overScope.children) {
					registerNamespace(register ? usingScope : null, child.name,
						child.namespace, forceNullable);
				}

				return newNode;

			case EXTEND:
				final SqlCall extend = (SqlCall) node;
				return registerFrom(parentScope,
					usingScope,
					true,
					extend.getOperandList().get(0),
					extend,
					alias,
					(SqlNodeList) extend.getOperandList().get(1),
					forceNullable,
					lateral);

			default:
				throw Util.unexpected(kind);
		}
	}"
"@SuppressWarnings(""unchecked"")
	private void register(final G gateway, final int attempt, final long timeoutMillis) {
		// eager check for canceling to avoid some unnecessary work
		if (canceled) {
			return;
		}

		try {
			log.info(""Registration at {} attempt {} (timeout={}ms)"", targetName, attempt, timeoutMillis);
			CompletableFuture<RegistrationResponse> registrationFuture = invokeRegistration(gateway, fencingToken, timeoutMillis);

			// if the registration was successful, let the TaskExecutor know
			CompletableFuture<Void> registrationAcceptFuture = registrationFuture.thenAcceptAsync(
				(RegistrationResponse result) -> {
					if (!isCanceled()) {
						if (result instanceof RegistrationResponse.Success) {
							// registration successful!
							S success = (S) result;
							completionFuture.complete(Tuple2.of(gateway, success));
						}
						else {
							// registration refused or unknown
							if (result instanceof RegistrationResponse.Decline) {
								RegistrationResponse.Decline decline = (RegistrationResponse.Decline) result;
								log.info(""Registration at {} was declined: {}"", targetName, decline.getReason());
							} else {
								log.error(""Received unknown response to registration attempt: {}"", result);
							}

							log.info(""Pausing and re-attempting registration in {} ms"", retryingRegistrationConfiguration.getRefusedDelayMillis());
							registerLater(gateway, 1, retryingRegistrationConfiguration.getInitialRegistrationTimeoutMillis(), retryingRegistrationConfiguration.getRefusedDelayMillis());
						}
					}
				},
				rpcService.getExecutor());

			// upon failure, retry
			registrationAcceptFuture.whenCompleteAsync(
				(Void v, Throwable failure) -> {
					if (failure != null && !isCanceled()) {
						if (ExceptionUtils.stripCompletionException(failure) instanceof TimeoutException) {
							// we simply have not received a response in time. maybe the timeout was
							// very low (initial fast registration attempts), maybe the target endpoint is
							// currently down.
							if (log.isDebugEnabled()) {
								log.debug(""Registration at {} ({}) attempt {} timed out after {} ms"",
									targetName, targetAddress, attempt, timeoutMillis);
							}

							long newTimeoutMillis = Math.min(2 * timeoutMillis, retryingRegistrationConfiguration.getMaxRegistrationTimeoutMillis());
							register(gateway, attempt + 1, newTimeoutMillis);
						}
						else {
							// a serious failure occurred. we still should not give up, but keep trying
							log.error(""Registration at {} failed due to an error"", targetName, failure);
							log.info(""Pausing and re-attempting registration in {} ms"", retryingRegistrationConfiguration.getErrorDelayMillis());

							registerLater(gateway, 1, retryingRegistrationConfiguration.getInitialRegistrationTimeoutMillis(), retryingRegistrationConfiguration.getErrorDelayMillis());
						}
					}
				},
				rpcService.getExecutor());
		}
		catch (Throwable t) {
			completionFuture.completeExceptionally(t);
			cancel();
		}
	}"
"public void setSearchLocation(String searchLocation) {
        ResourceLoader resourceLoader = getDefaultResourceLoader();
        patchMatchingResolver = new PathMatchingResourcePatternResolver(resourceLoader);
        initializeForSearchLocation(searchLocation);
    }"
"@SuppressLint(""RestrictedApi"")
    public static void hideStatusBar(Context context) {
        if (Jzvd.TOOL_BAR_EXIST) {
            JZUtils.getWindow(context).setFlags(WindowManager.LayoutParams.FLAG_FULLSCREEN, WindowManager.LayoutParams.FLAG_FULLSCREEN);
        }
    }"
"protected String getWarnMessageFromCookie(final HttpServletRequest request) {
    final Cookie cookie = getCookieByName(request, AZKABAN_WARN_MESSAGE);

    if (cookie == null) {
      return null;
    }
    return cookie.getValue();
  }"
"public static boolean isModifed(File file, long lastModifyTime) {
		if (null == file || false == file.exists()) {
			return true;
		}
		return file.lastModified() != lastModifyTime;
	}"
"void removeComputer(final Computer computer) {
        Queue.withLock(new Runnable() {
            @Override
            public void run() {
                Map<Node,Computer> computers = getComputerMap();
                for (Map.Entry<Node, Computer> e : computers.entrySet()) {
                    if (e.getValue() == computer) {
                        computers.remove(e.getKey());
                        computer.onRemoved();
                        return;
                    }
                }
            }
        });
    }"
"public static Long getLong(Map<?, ?> map, Object key) {
		return get(map, key, Long.class);
	}"
"public static String getSIntA( int... intA ) {
		//
		String Info = """";
		//
		if ( intA == null ) return ""?"";
		if ( intA.length == 0 ) return ""?"";
		//
		for ( int K = 0; K < intA.length; K ++ ) {
			//
            Info += ( Info.isEmpty() )? """" : "", "";
			Info += BTools.getSInt( intA[ K ] );
		}
		//
		return Info;
	}"
"public int setTraceLevel(final int level) {
        final int oldLevel = traceLevel;

        // pin the value
        int theLevel = level;
        if (level < 0) {
            theLevel = 0;
        } else if (level > 4) {
            theLevel = 4;
        }

        traceLevel = theLevel;

        return oldLevel;
    }"
"public <T> HystrixRequestVariable<T> getRequestVariable(final HystrixRequestVariableLifecycle<T> rv) {
        return new HystrixLifecycleForwardingRequestVariable<T>(rv);
    }"
"public MockResponse setChunkedBody(String body, int maxChunkSize) {
    return setChunkedBody(new Buffer().writeUtf8(body), maxChunkSize);
  }"
"private void addIfAccept(String className) {
		if(StrUtil.isBlank(className)) {
			return;
		}
		int classLen = className.length();
		int packageLen = this.packageName.length();
		if(classLen == packageLen) {
			//类名和包名长度一致，用户可能传入的包名是类名
			if(className.equals(this.packageName)) {
				addIfAccept(loadClass(className));
			}
		} else if(classLen > packageLen){
			//检查类名是否以指定包名为前缀，包名后加.（避免类似于cn.hutool.A和cn.hutool.ATest这类类名引起的歧义）
			if(className.startsWith(this.packageNameWithDot)) {
				addIfAccept(loadClass(className));
			}
		}
	}"
"@Deprecated
	public void setInput(Operator<IN>... input) {
		this.input = Operator.createUnionCascade(null, input);
	}"
"public SDVariable norm2(String name, SDVariable x, int... dimensions) {
        return norm2(name, x, false, dimensions);
    }"
"@Override
    public List<String> getKeywords(List<Term> termList, int size)
    {
        clear();
        add(termList);
        Collection<TermFrequency> topN = top(size);
        List<String> r = new ArrayList<String>(topN.size());
        for (TermFrequency termFrequency : topN)
        {
            r.add(termFrequency.getTerm());
        }
        return r;
    }"
"public @CheckForNull R get() {
        Holder<R> h = holder; // capture
        return h!=null ? h.get() : null;
    }"
"public static double mul(float v1, float v2) {
		return mul(Float.toString(v1), Float.toString(v2)).doubleValue();
	}"
"public static int optimalNumOfBits(long inputEntries, double fpp) {
		int numBits = (int) (-inputEntries * Math.log(fpp) / (Math.log(2) * Math.log(2)));
		return numBits;
	}"
"public Long getFileSize() {
        Long fileSize = 0L;
        if (items.size() != 0) {
            for (TableStat item : items) {
                fileSize += item.getFileSize();
            }
        }
        return fileSize;
    }"
"public final void commitInternalOffsetsToKafka(
			Map<KafkaTopicPartition, Long> offsets,
			@Nonnull KafkaCommitCallback commitCallback) throws Exception {
		// Ignore sentinels. They might appear here if snapshot has started before actual offsets values
		// replaced sentinels
		doCommitInternalOffsetsToKafka(filterOutSentinels(offsets), commitCallback);
	}"
"public static boolean isTCLUnsafe(final DatabaseType databaseType, final TokenType tokenType, final LexerEngine lexerEngine) {
        if (DefaultKeyword.SET.equals(tokenType) || DatabaseType.SQLServer.equals(databaseType) && DefaultKeyword.IF.equals(tokenType)) {
            lexerEngine.skipUntil(DefaultKeyword.TRANSACTION, DefaultKeyword.AUTOCOMMIT, DefaultKeyword.IMPLICIT_TRANSACTIONS);
            if (!lexerEngine.isEnd()) {
                return true;
            }
        }
        return false;
    }"
"public static InputStream decompress(final InputStream in, final String fileName) throws IOException
  {
    if (fileName.endsWith(GZ_SUFFIX)) {
      return gzipInputStream(in);
    } else if (fileName.endsWith(BZ2_SUFFIX)) {
      return new BZip2CompressorInputStream(in, true);
    } else if (fileName.endsWith(XZ_SUFFIX)) {
      return new XZCompressorInputStream(in, true);
    } else if (fileName.endsWith(SNAPPY_SUFFIX)) {
      return new FramedSnappyCompressorInputStream(in);
    } else if (fileName.endsWith(ZSTD_SUFFIX)) {
      return new ZstdCompressorInputStream(in);
    } else if (fileName.endsWith(ZIP_SUFFIX)) {
      // This reads the first file in the archive.
      final ZipInputStream zipIn = new ZipInputStream(in, StandardCharsets.UTF_8);
      try {
        final ZipEntry nextEntry = zipIn.getNextEntry();
        if (nextEntry == null) {
          zipIn.close();

          // No files in the archive - return an empty stream.
          return new ByteArrayInputStream(new byte[0]);
        }
        return zipIn;
      }
      catch (IOException e) {
        try {
          zipIn.close();
        }
        catch (IOException e2) {
          e.addSuppressed(e2);
        }
        throw e;
      }
    } else {
      return in;
    }
  }"
"public static ExpectedCondition<List<WebElement>> presenceOfNestedElementsLocatedBy(
    final By parent,
    final By childLocator) {
    return new ExpectedCondition<List<WebElement>>() {

      @Override
      public List<WebElement> apply(WebDriver driver) {
        List<WebElement> allChildren = driver.findElement(parent).findElements(childLocator);

        return allChildren.isEmpty() ? null : allChildren;
      }

      @Override
      public String toString() {
        return String.format(""visibility of element located by %s -> %s"", parent, childLocator);
      }
    };
  }"
"@SuppressWarnings(""deprecation"")
    public boolean removeAction(@Nullable Action a) {
        if (a == null) {
            return false;
        }
        // CopyOnWriteArrayList does not support Iterator.remove, so need to do it this way:
        return getActions().removeAll(Collections.singleton(a));
    }"
"public <C extends IClient<?, ?>> C getClient(String name, Class<C> clientClass) {
		return getInstance(name, clientClass);
	}"
"public static ClassLoader getClassLoader() {
		ClassLoader classLoader = getContextClassLoader();
		if (classLoader == null) {
			classLoader = ClassLoaderUtil.class.getClassLoader();
			if (null == classLoader) {
				classLoader = ClassLoader.getSystemClassLoader();
			}
		}
		return classLoader;
	}"
"public static DataSource getJndiDsWithLog(String jndiName) {
		try {
			return getJndiDs(jndiName);
		} catch (DbRuntimeException e) {
			log.error(e.getCause(), ""Find JNDI datasource error!"");
		}
		return null;
	}"
"public static String formatSystemProperties(Configuration jvmArgs) {
		StringBuilder sb = new StringBuilder();
		for(Map.Entry<String,String> entry : jvmArgs.toMap().entrySet()) {
			if(sb.length() > 0) {
				sb.append("" "");
			}
			boolean quoted = entry.getValue().contains("" "");
			if(quoted) {
				sb.append(""\"""");
			}
			sb.append(""-D"").append(entry.getKey()).append('=').append(entry.getValue());
			if(quoted) {
				sb.append(""\"""");
			}
		}
		return sb.toString();
	}"
"public int getProgressPercentage()  {
        // Implemented using node counts...
        if (isRunning()) {
            int progress = (hProcess.getTestCurrentCount(plugin) * 100) / hProcess.getTestTotalCount();
            // Make sure not return 100 (or more) if still running...
            // That might happen if more nodes are being scanned that the ones enumerated at the beginning.
            return progress >= 100 ? 99 : progress;
        } else if (isCompleted() || isSkipped()) {
            return 100;        
            
        } else {
            return 0;
        }
    }"
"public WebElement augment(RemoteWebElement element) {
    // TODO(simon): We should really add a ""SelfDescribing"" interface for this
    RemoteWebDriver parent = (RemoteWebDriver) element.getWrappedDriver();
    if (parent == null) {
      return element;
    }

    return create(parent, elementAugmentors, element);
  }"
"public static synchronized void unSubscribe(String key, RpcConfigListener listener) {
        List<RpcConfigListener> listeners = CFG_LISTENER.get(key);
        if (listeners != null) {
            listeners.remove(listener);
            if (listeners.size() == 0) {
                CFG_LISTENER.remove(key);
            }
        }
    }"
"public void setNote(String note) {
       try {
           staticTableHistory.updateNote(historyId, note);
           httpMessageCachedData.setNote(note != null && note.length() > 0);
           notifyEvent(HistoryReferenceEventPublisher.EVENT_NOTE_SET);
       } catch (DatabaseException e) {
           log.error(e.getMessage(), e);
       }
       
   }"
"protected List<Rule> parsePattern() {
		final DateFormatSymbols symbols = new DateFormatSymbols(locale);
		final List<Rule> rules = new ArrayList<>();

		final String[] ERAs = symbols.getEras();
		final String[] months = symbols.getMonths();
		final String[] shortMonths = symbols.getShortMonths();
		final String[] weekdays = symbols.getWeekdays();
		final String[] shortWeekdays = symbols.getShortWeekdays();
		final String[] AmPmStrings = symbols.getAmPmStrings();

		final int length = pattern.length();
		final int[] indexRef = new int[1];

		for (int i = 0; i < length; i++) {
			indexRef[0] = i;
			final String token = parseToken(pattern, indexRef);
			i = indexRef[0];

			final int tokenLen = token.length();
			if (tokenLen == 0) {
				break;
			}

			Rule rule;
			final char c = token.charAt(0);

			switch (c) {
				case 'G': // era designator (text)
					rule = new TextField(Calendar.ERA, ERAs);
					break;
				case 'y': // year (number)
				case 'Y': // week year
					if (tokenLen == 2) {
						rule = TwoDigitYearField.INSTANCE;
					} else {
						rule = selectNumberRule(Calendar.YEAR, tokenLen < 4 ? 4 : tokenLen);
					}
					if (c == 'Y') {
						rule = new WeekYear((NumberRule) rule);
					}
					break;
				case 'M': // month in year (text and number)
					if (tokenLen >= 4) {
						rule = new TextField(Calendar.MONTH, months);
					} else if (tokenLen == 3) {
						rule = new TextField(Calendar.MONTH, shortMonths);
					} else if (tokenLen == 2) {
						rule = TwoDigitMonthField.INSTANCE;
					} else {
						rule = UnpaddedMonthField.INSTANCE;
					}
					break;
				case 'd': // day in month (number)
					rule = selectNumberRule(Calendar.DAY_OF_MONTH, tokenLen);
					break;
				case 'h': // hour in am/pm (number, 1..12)
					rule = new TwelveHourField(selectNumberRule(Calendar.HOUR, tokenLen));
					break;
				case 'H': // hour in day (number, 0..23)
					rule = selectNumberRule(Calendar.HOUR_OF_DAY, tokenLen);
					break;
				case 'm': // minute in hour (number)
					rule = selectNumberRule(Calendar.MINUTE, tokenLen);
					break;
				case 's': // second in minute (number)
					rule = selectNumberRule(Calendar.SECOND, tokenLen);
					break;
				case 'S': // millisecond (number)
					rule = selectNumberRule(Calendar.MILLISECOND, tokenLen);
					break;
				case 'E': // day in week (text)
					rule = new TextField(Calendar.DAY_OF_WEEK, tokenLen < 4 ? shortWeekdays : weekdays);
					break;
				case 'u': // day in week (number)
					rule = new DayInWeekField(selectNumberRule(Calendar.DAY_OF_WEEK, tokenLen));
					break;
				case 'D': // day in year (number)
					rule = selectNumberRule(Calendar.DAY_OF_YEAR, tokenLen);
					break;
				case 'F': // day of week in month (number)
					rule = selectNumberRule(Calendar.DAY_OF_WEEK_IN_MONTH, tokenLen);
					break;
				case 'w': // week in year (number)
					rule = selectNumberRule(Calendar.WEEK_OF_YEAR, tokenLen);
					break;
				case 'W': // week in month (number)
					rule = selectNumberRule(Calendar.WEEK_OF_MONTH, tokenLen);
					break;
				case 'a': // am/pm marker (text)
					rule = new TextField(Calendar.AM_PM, AmPmStrings);
					break;
				case 'k': // hour in day (1..24)
					rule = new TwentyFourHourField(selectNumberRule(Calendar.HOUR_OF_DAY, tokenLen));
					break;
				case 'K': // hour in am/pm (0..11)
					rule = selectNumberRule(Calendar.HOUR, tokenLen);
					break;
				case 'X': // ISO 8601
					rule = Iso8601_Rule.getRule(tokenLen);
					break;
				case 'z': // time zone (text)
					if (tokenLen >= 4) {
						rule = new TimeZoneNameRule(timeZone, locale, TimeZone.LONG);
					} else {
						rule = new TimeZoneNameRule(timeZone, locale, TimeZone.SHORT);
					}
					break;
				case 'Z': // time zone (value)
					if (tokenLen == 1) {
						rule = TimeZoneNumberRule.INSTANCE_NO_COLON;
					} else if (tokenLen == 2) {
						rule = Iso8601_Rule.ISO8601_HOURS_COLON_MINUTES;
					} else {
						rule = TimeZoneNumberRule.INSTANCE_COLON;
					}
					break;
				case '\'': // literal text
					final String sub = token.substring(1);
					if (sub.length() == 1) {
						rule = new CharacterLiteral(sub.charAt(0));
					} else {
						rule = new StringLiteral(sub);
					}
					break;
				default:
					throw new IllegalArgumentException(""Illegal pattern component: "" + token);
			}

			rules.add(rule);
		}

		return rules;
	}"
"private static Invoker getInvoker(HttpMessageContainer httpMessageContainer) {
        Invoker invoker;
        switch (httpMessageContainer.getName()) {
        // TODO Allow to inject the HTTP fuzz component
        case ""History Table"":
            invoker = Invoker.HISTORY_PANEL;
            break;
        case ""treeSite"":
            invoker = Invoker.SITES_PANEL;
            break;
        case AlertPanel.ALERT_TREE_PANEL_NAME:
            invoker = Invoker.ALERTS_PANEL;
            break;
        case SearchPanel.HTTP_MESSAGE_CONTAINER_NAME:
            invoker = Invoker.SEARCH_PANEL;
            break;
        case SpiderPanel.HTTP_MESSAGE_CONTAINER_NAME:
            invoker = Invoker.SPIDER_PANEL;
            break;
        case ActiveScanPanel.MESSAGE_CONTAINER_NAME:
            invoker = Invoker.ACTIVE_SCANNER_PANEL;
            break;
        case ""ForcedBrowseMessageContainer"":
            invoker = Invoker.FORCED_BROWSE_PANEL;
            break;
        case ""fuzz.httpfuzzerResultsContentPanel"":
            invoker = Invoker.FUZZER_PANEL;
            break;
        default:
            invoker = Invoker.UNKNOWN;
        }
        return invoker;
    }"
"private static long[] transformCountsToOffsets(
      long[] counts, long numRecords, long outputOffset, long bytesPerRecord,
      boolean desc, boolean signed) {
    assert counts.length == 256;
    int start = signed ? 128 : 0;  // output the negative records first (values 129-255).
    if (desc) {
      long pos = numRecords;
      for (int i = start; i < start + 256; i++) {
        pos -= counts[i & 0xff];
        counts[i & 0xff] = outputOffset + pos * bytesPerRecord;
      }
    } else {
      long pos = 0;
      for (int i = start; i < start + 256; i++) {
        long tmp = counts[i & 0xff];
        counts[i & 0xff] = outputOffset + pos * bytesPerRecord;
        pos += tmp;
      }
    }
    return counts;
  }"
"protected void increaseRefreshInterval() {
		refreshInterval = Math.min(REFRESH_INTERVALS.size() - 1, refreshInterval + 1);

		// reset view
		resetAllParts();

		synchronized (refreshThread) {
			refreshThread.notify();
		}
	}"
"private void initialize() {
        this.setTitle(Constant.messages.getString(""edit.find.title""));
        this.infoLabel = new JLabel(Constant.messages.getString(""edit.find.label.notfound""));
        this.infoLabel.setVisible(false);
        this.setContentPane(getJPanel());
        centreDialog();
        txtFind.requestFocus();
        this.getRootPane().setDefaultButton(btnFind);
        pack();
        this.setVisible(true);
	}"
"@Override
  public void cancel(final Status reason) {
    checkNotNull(reason, ""reason"");
    boolean delegateToRealStream = true;
    ClientStreamListener listenerToClose = null;
    synchronized (this) {
      // If realStream != null, then either setStream() or cancel() has been called
      if (realStream == null) {
        realStream = NoopClientStream.INSTANCE;
        delegateToRealStream = false;

        // If listener == null, then start() will later call listener with 'error'
        listenerToClose = listener;
        error = reason;
      }
    }
    if (delegateToRealStream) {
      delayOrExecute(new Runnable() {
        @Override
        public void run() {
          realStream.cancel(reason);
        }
      });
    } else {
      if (listenerToClose != null) {
        listenerToClose.closed(reason, new Metadata());
      }
      drainPendingCalls();
    }
  }"
"@SuppressWarnings(""NarrowingCompoundAssignment"")
  private String hexAV() {
    if (pos + 4 >= length) {
      // encoded byte array  must be not less then 4 c
      throw new IllegalStateException(""Unexpected end of DN: "" + dn);
    }

    beg = pos; // store '#' position
    pos++;
    while (true) {

      // check for end of attribute value
      // looks for space and component separators
      if (pos == length || chars[pos] == '+' || chars[pos] == ','
          || chars[pos] == ';') {
        end = pos;
        break;
      }

      if (chars[pos] == ' ') {
        end = pos;
        pos++;
        // skip trailing space chars before comma or semicolon.
        // (compatibility with RFC 1779)
        for (; pos < length && chars[pos] == ' '; pos++) {
        }
        break;
      } else if (chars[pos] >= 'A' && chars[pos] <= 'F') {
        chars[pos] += 32; //to low case
      }

      pos++;
    }

    // verify length of hex string
    // encoded byte array  must be not less then 4 and must be even number
    int hexLen = end - beg; // skip first '#' char
    if (hexLen < 5 || (hexLen & 1) == 0) {
      throw new IllegalStateException(""Unexpected end of DN: "" + dn);
    }

    // get byte encoding from string representation
    byte[] encoded = new byte[hexLen / 2];
    for (int i = 0, p = beg + 1; i < encoded.length; p += 2, i++) {
      encoded[i] = (byte) getByte(p);
    }

    return new String(chars, beg, hexLen);
  }"
"public static Map<String, String> buildJobContextInfoMap(final Event event,
      final String server) {

    if (event.getRunner() instanceof JobRunner) {
      final JobRunner jobRunner = (JobRunner) event.getRunner();
      final ExecutableNode node = jobRunner.getNode();
      final EventData eventData = event.getData();
      final String projectName = node.getParentFlow().getProjectName();
      final String flowName = node.getParentFlow().getFlowId();
      final String executionId =
          String.valueOf(node.getParentFlow().getExecutionId());
      final String jobId = node.getId();

      final Map<String, String> result = new HashMap<>();
      result.put(CONTEXT_SERVER_TOKEN, server);
      result.put(CONTEXT_PROJECT_TOKEN, projectName);
      result.put(CONTEXT_FLOW_TOKEN, flowName);
      result.put(CONTEXT_EXECUTION_ID_TOKEN, executionId);
      result.put(CONTEXT_JOB_TOKEN, jobId);
      result.put(CONTEXT_JOB_STATUS_TOKEN, eventData.getStatus().name().toLowerCase());

      /*
       * if (node.getStatus() == Status.SUCCEEDED || node.getStatus() ==
       * Status.FAILED) { result.put(JOB_STATUS_TOKEN,
       * node.getStatus().name().toLowerCase()); } else if (node.getStatus() ==
       * Status.PREPARING) { result.put(JOB_STATUS_TOKEN, ""started""); }
       */

      return result;

    } else {
      throw new IllegalArgumentException(""Provided event is not a job event"");
    }
  }"
"public ChromeOptions setExperimentalOption(String name, Object value) {
    experimentalOptions.put(checkNotNull(name), value);
    return this;
  }"
"public FileAppender flush() {
		try(PrintWriter pw = writer.getPrintWriter(true)){
			for (String str : list) {
				pw.print(str);
				if (isNewLineMode) {
					pw.println();
				}
			}
		}
		list.clear();
		return this;
	}"
"public void setValue(String name, int value) {
        byte[] data = new byte[4];
        data[0] = (byte) (value & 0xff);
        data[1] = (byte) ((value >> 8) & 0xff);
        data[2] = (byte) ((value >> 16) & 0xff);
        data[3] = (byte) ((value >> 24) & 0xff);

        check(Advapi32.INSTANCE.RegSetValueEx(handle, name, 0, WINNT.REG_DWORD, data, data.length));
    }"
"private <IN1, IN2, OUT> Collection<Integer> transformTwoInputTransform(TwoInputTransformation<IN1, IN2, OUT> transform) {

		Collection<Integer> inputIds1 = transform(transform.getInput1());
		Collection<Integer> inputIds2 = transform(transform.getInput2());

		// the recursive call might have already transformed this
		if (alreadyTransformed.containsKey(transform)) {
			return alreadyTransformed.get(transform);
		}

		List<Integer> allInputIds = new ArrayList<>();
		allInputIds.addAll(inputIds1);
		allInputIds.addAll(inputIds2);

		String slotSharingGroup = determineSlotSharingGroup(transform.getSlotSharingGroup(), allInputIds);

		streamGraph.addCoOperator(
				transform.getId(),
				slotSharingGroup,
				transform.getCoLocationGroupKey(),
				transform.getOperator(),
				transform.getInputType1(),
				transform.getInputType2(),
				transform.getOutputType(),
				transform.getName());

		if (transform.getStateKeySelector1() != null || transform.getStateKeySelector2() != null) {
			TypeSerializer<?> keySerializer = transform.getStateKeyType().createSerializer(env.getConfig());
			streamGraph.setTwoInputStateKey(transform.getId(), transform.getStateKeySelector1(), transform.getStateKeySelector2(), keySerializer);
		}

		streamGraph.setParallelism(transform.getId(), transform.getParallelism());
		streamGraph.setMaxParallelism(transform.getId(), transform.getMaxParallelism());

		for (Integer inputId: inputIds1) {
			streamGraph.addEdge(inputId,
					transform.getId(),
					1
			);
		}

		for (Integer inputId: inputIds2) {
			streamGraph.addEdge(inputId,
					transform.getId(),
					2
			);
		}

		return Collections.singleton(transform.getId());
	}"
"public void setInput(INDArray input) {
        this.input = input;
        if (this.layers == null) {
            init();
        }
        if (input != null) {
            if (input.length() == 0)
                throw new IllegalArgumentException(
                        ""Invalid input: length 0 (shape: "" + Arrays.toString(input.shape()) + "")"");

            // FIXME: int cast
            setInputMiniBatchSize((int) input.size(0));
        }
    }"
"public static String hexDecode(final char[] data) {
        try {
            val result = Hex.decodeHex(data);
            return new String(result, StandardCharsets.UTF_8);
        } catch (final Exception e) {
            return null;
        }
    }"
"public List<Protos.Resource> takeRanges(String resourceName, int amount, Set<String> roles) {
		if (LOG.isDebugEnabled()) {
			LOG.debug(""Allocating {} {}"", amount, resourceName);
		}

		List<Protos.Resource> result = new ArrayList<>(1);
		for (ListIterator<Protos.Resource> i = resources.listIterator(); i.hasNext();) {
			if (amount <= 0) {
				break;
			}

			// take from next available range resource that is unreserved or reserved for an applicable role
			Protos.Resource available = i.next();
			if (!resourceName.equals(available.getName()) || !available.hasRanges()) {
				continue;
			}
			if (!UNRESERVED_ROLE.equals(available.getRole()) && !roles.contains(available.getRole())) {
				continue;
			}

			List<Protos.Value.Range> takenRanges = new ArrayList<>();
			List<Protos.Value.Range> remainingRanges = new ArrayList<>(available.getRanges().getRangeList());
			for (ListIterator<Protos.Value.Range> j = remainingRanges.listIterator(); j.hasNext();) {
				if (amount <= 0) {
					break;
				}

				// take from next available range (note: ranges are inclusive)
				Protos.Value.Range availableRange = j.next();
				long amountToTake = Math.min(availableRange.getEnd() - availableRange.getBegin() + 1, amount);
				Protos.Value.Range takenRange = availableRange.toBuilder().setEnd(availableRange.getBegin() + amountToTake - 1).build();
				amount -= amountToTake;
				takenRanges.add(takenRange);

				// keep remaining range (if any)
				long remaining = availableRange.getEnd() - takenRange.getEnd();
				if (remaining > 0) {
					j.set(availableRange.toBuilder().setBegin(takenRange.getEnd() + 1).build());
				}
				else {
					j.remove();
				}
			}
			Protos.Resource taken = available.toBuilder().setRanges(Protos.Value.Ranges.newBuilder().addAllRange(takenRanges)).build();
			if (LOG.isDebugEnabled()) {
				LOG.debug(""Taking {} from {}"", Utils.toString(taken.getRanges()), Utils.toString(available));
			}
			result.add(taken);

			// keep remaining ranges (if any)
			if (remainingRanges.size() > 0) {
				i.set(available.toBuilder().setRanges(Protos.Value.Ranges.newBuilder().addAllRange(remainingRanges)).build());
			}
			else {
				i.remove();
			}
		}

		if (LOG.isDebugEnabled()) {
			LOG.debug(""Allocated: {}, unsatisfied: {}"", Utils.toString(result), amount);
		}
		return result;
	}"
"public Base64NDArrayBody toArray(BatchCSVRecord batch) throws IOException {
        List<List<Writable>> converted =  execute(toArrowWritables(toArrowColumnsString(
                bufferAllocator,transformProcess.getInitialSchema(),
                batch.getRecordsAsString()),
                transformProcess.getInitialSchema()),transformProcess);

        ArrowWritableRecordBatch arrowRecordBatch = (ArrowWritableRecordBatch) converted;
        INDArray convert = ArrowConverter.toArray(arrowRecordBatch);
        return new Base64NDArrayBody(Nd4jBase64.base64String(convert));
    }"
"protected void registerLoggedException(Throwable exception) {
		SpringBootExceptionHandler handler = getSpringBootExceptionHandler();
		if (handler != null) {
			handler.registerLoggedException(exception);
		}
	}"
"@Override
  public void saveParam(BackendModel m, String param_path) {
    ((DeepwaterCaffeModel) m).saveParam(param_path);
  }"
"public void setTomcatConnectorCustomizers(
			Collection<? extends TomcatConnectorCustomizer> tomcatConnectorCustomizers) {
		Assert.notNull(tomcatConnectorCustomizers,
				""TomcatConnectorCustomizers must not be null"");
		this.tomcatConnectorCustomizers = new ArrayList<>(tomcatConnectorCustomizers);
	}"
"public static SXSSFWorkbook createSXSSFBook(InputStream in, String password, boolean closeAfterRead) {
		return toSXSSFBook(createBook(in, password, closeAfterRead));
	}"
"public static void deleteRecursively(File file, FilenameFilter filter) throws IOException {
    if (file == null) { return; }

    // On Unix systems, use operating system command to run faster
    // If that does not work out, fallback to the Java IO way
    if (SystemUtils.IS_OS_UNIX && filter == null) {
      try {
        deleteRecursivelyUsingUnixNative(file);
        return;
      } catch (IOException e) {
        logger.warn(""Attempt to delete using native Unix OS command failed for path = {}. "" +
                        ""Falling back to Java IO way"", file.getAbsolutePath(), e);
      }
    }

    deleteRecursivelyUsingJavaIO(file, filter);
  }"
"private static RowData parseDataRow(String line, GenMunger munger) {
      if( line.isEmpty() || line.equals("""") )
        return null;
      String[] inputData = line.split("",(?=([^\""]*\""[^\""]*\"")*[^\""]*$)|(,)"", -1);
      for(int i=0;i<inputData.length;++i)
        inputData[i]=inputData[i]==null?"""":inputData[i];
    if( inputData.length != munger.inNames().length )
      return null;
    return munger.fillDefault(inputData);
  }"
"@SuppressWarnings(""unchecked"")
    private void readObject(java.io.ObjectInputStream s)
        throws IOException, ClassNotFoundException {
        // Don't call defaultReadObject()
        ObjectInputStream.GetField oisFields = s.readFields();
        final Segment<K,V>[] oisSegments = (Segment<K,V>[])oisFields.get(""segments"", null);

        final int ssize = oisSegments.length;
        if (ssize < 1 || ssize > MAX_SEGMENTS
            || (ssize & (ssize-1)) != 0 ) {
          throw new java.io.InvalidObjectException(""Bad number of segments:""
                                                   + ssize);
        }
        int sshift = 0, ssizeTmp = ssize;
        while (ssizeTmp > 1) {
            ++sshift;
            ssizeTmp >>>= 1;
        }
        UNSAFE.putIntVolatile(this, SEGSHIFT_OFFSET, 32 - sshift);
        UNSAFE.putIntVolatile(this, SEGMASK_OFFSET, ssize - 1);
        UNSAFE.putObjectVolatile(this, SEGMENTS_OFFSET, oisSegments);

        // set hashMask
        UNSAFE.putIntVolatile(this, HASHSEED_OFFSET, randomHashSeed(this));

        // Re-initialize segments to be minimally sized, and let grow.
        int cap = MIN_SEGMENT_TABLE_CAPACITY;
        final Segment<K,V>[] segments = this.segments;
        for (int k = 0; k < segments.length; ++k) {
            Segment<K,V> seg = segments[k];
            if (seg != null) {
                seg.threshold = (int)(cap * seg.loadFactor);
                seg.table = new HashEntry[cap];
            }
        }

        // Read the keys and values, and put the mappings in the table
        for (;;) {
            K key = (K) s.readObject();
            V value = (V) s.readObject();
            if (key == null) {
              break;
            }
            put(key, value);
        }
    }"
"private static void vectorSwap(PagesIndex pagesIndex, int from, int l, int s)
    {
        for (int i = 0; i < s; i++, from++, l++) {
            pagesIndex.swap(from, l);
        }
    }"
"public MockResponse addHeader(String name, Object value) {
    headers.add(name, String.valueOf(value));
    return this;
  }"
"@Override
    public void indicateProgress(int number) {
        verifySystemOut();
        progressIndicatorActive = true;
        String currMsg = lastMessage;
        try {
            if (isAnsiEnabled()) {
                updateStatus(currMsg + ' ' + number);
            } else {
                out.print("".."");
                out.print(number);
            }
        } finally {
            lastMessage = currMsg;
        }
    }"
"public ProviderStatus getStatus() {
        if (status == ProviderStatus.WARMING_UP) {
            if (System.currentTimeMillis() > (Long) getDynamicAttr(ProviderInfoAttrs.ATTR_WARM_UP_END_TIME)) {
                // 如果已经过了预热时间，恢复为正常
                status = ProviderStatus.AVAILABLE;
                setDynamicAttr(ProviderInfoAttrs.ATTR_WARM_UP_END_TIME, null);
            }
        }
        return status;
    }"
"protected List<PropertySource> readPropertySourceListFromFiles(String files) {
        List<PropertySource> propertySources = new ArrayList<>();
        Collection<PropertySourceLoader> propertySourceLoaders = getPropertySourceLoaders();
        Optional<Collection<String>> filePathList = Optional.ofNullable(files)
            .filter(value -> !value.isEmpty())
            .map(value -> value.split(FILE_SEPARATOR))
            .map(Arrays::asList)
            .map(Collections::unmodifiableList);

        filePathList.ifPresent(list -> {
            if (!list.isEmpty()) {
                list.forEach(filePath -> {
                    if (!propertySourceLoaders.isEmpty()) {
                        String extension = NameUtils.extension(filePath);
                        String fileName = NameUtils.filename(filePath);
                        Optional<PropertySourceLoader> propertySourceLoader = Optional.ofNullable(loaderByFormatMap.get(extension));
                        if (propertySourceLoader.isPresent()) {
                            if (LOG.isDebugEnabled()) {
                                LOG.debug(""Reading property sources from loader: {}"", propertySourceLoader);
                            }
                            readPropertySourceFromLoader(fileName, filePath, propertySourceLoader.get(), propertySources);
                        } else {
                            throw new ConfigurationException(""Unsupported properties file format: "" + fileName);
                        }
                    }
                });
            }
        });
        return propertySources;
    }"
"public static DateTime parseDate(String dateString) {
		dateString = normalize(dateString);
		return parse(dateString, DatePattern.NORM_DATE_FORMAT);
	}"
"public static byte getOrderAsByte() {
        if (ByteOrder.nativeOrder().equals(ByteOrder.BIG_ENDIAN))
            return org.nd4j.graph.ByteOrder.BE;
        else
            return org.nd4j.graph.ByteOrder.LE;
    }"
"private void closeAllOperators() throws Exception {
		// We need to close them first to last, since upstream operators in the chain might emit
		// elements in their close methods.
		StreamOperator<?>[] allOperators = operatorChain.getAllOperators();
		for (int i = allOperators.length - 1; i >= 0; i--) {
			StreamOperator<?> operator = allOperators[i];
			if (operator != null) {
				operator.close();
			}
		}
	}"
"@Override
    public CoOccurrenceWeight<T> nextObject() {
        String line = iterator.nextSentence();
        if (line == null || line.isEmpty()) {
            return null;
        }
        String[] strings = line.split("" "");

        CoOccurrenceWeight<T> object = new CoOccurrenceWeight<>();
        object.setElement1(vocabCache.elementAtIndex(Integer.valueOf(strings[0])));
        object.setElement2(vocabCache.elementAtIndex(Integer.valueOf(strings[1])));
        object.setWeight(Double.parseDouble(strings[2]));

        return object;
    }"
"public long uploadStream(
      ManagedBuffer meta,
      ManagedBuffer data,
      RpcResponseCallback callback) {
    if (logger.isTraceEnabled()) {
      logger.trace(""Sending RPC to {}"", getRemoteAddress(channel));
    }

    long requestId = requestId();
    handler.addRpcRequest(requestId, callback);

    RpcChannelListener listener = new RpcChannelListener(requestId, callback);
    channel.writeAndFlush(new UploadStream(requestId, meta, data)).addListener(listener);

    return requestId;
  }"
"public static URI toURI(String location) throws UtilException {
		try {
			return new URI(location.replace("" "", ""%20""));
		} catch (URISyntaxException e) {
			throw new UtilException(e);
		}
	}"
"public void hideColumn(TableColumn column) {
		if (columnModel.getColumnCount() == 1) {
			return;
		}

		// Ignore changes to the TableColumnModel made by the TableColumnManager

		columnModel.removeColumnModelListener(this);
		columnModel.removeColumn(column);
		columnModel.addColumnModelListener(this);
	}"
"public <E> void addComboField(int tabIndex, String fieldLabel, ComboBoxModel<E> comboBoxModel) {
		addComboField(tabIndex, fieldLabel, comboBoxModel, false);
	}"
"public void setProxyChainName(String proxyChainName) {
	    if (proxyChainName == null) {
	        return;
	    }
		this.proxyChainName = proxyChainName.trim();
		if (proxyChainName.isEmpty()) {
			setUseProxyChain(false);
		}
		getConfig().setProperty(PROXY_CHAIN_NAME, this.proxyChainName);
	}"
"public static Tag outcome(ClientHttpResponse response) {
		try {
			if (response != null) {
				HttpStatus statusCode = response.getStatusCode();
				if (statusCode.is1xxInformational()) {
					return OUTCOME_INFORMATIONAL;
				}
				if (statusCode.is2xxSuccessful()) {
					return OUTCOME_SUCCESS;
				}
				if (statusCode.is3xxRedirection()) {
					return OUTCOME_REDIRECTION;
				}
				if (statusCode.is4xxClientError()) {
					return OUTCOME_CLIENT_ERROR;
				}
				if (statusCode.is5xxServerError()) {
					return OUTCOME_SERVER_ERROR;
				}
			}
			return OUTCOME_UNKNOWN;
		}
		catch (IOException | IllegalArgumentException ex) {
			return OUTCOME_UNKNOWN;
		}
	}"
"public SDVariable shape(String name, SDVariable input) {
        SDVariable ret = f().shape(input);
        return updateVariableNameAndReference(ret, name);
    }"
"private static InetSocketAddress overrideProxy(String proxyHostPort) {
    if (proxyHostPort == null) {
      return null;
    }

    String[] parts = proxyHostPort.split("":"", 2);
    int port = 80;
    if (parts.length > 1) {
      port = Integer.parseInt(parts[1]);
    }
    log.warning(
        ""Detected GRPC_PROXY_EXP and will honor it, but this feature will ""
            + ""be removed in a future release. Use the JVM flags ""
            + ""\""-Dhttps.proxyHost=HOST -Dhttps.proxyPort=PORT\"" to set the https proxy for ""
            + ""this JVM."");
    return new InetSocketAddress(parts[0], port);
  }"
"public static void noSpace(String string) throws JSONException {
    int i, length = string.length();
    if (length == 0) {
      throw new JSONException(""Empty string."");
    }
    for (i = 0; i < length; i += 1) {
      if (Character.isWhitespace(string.charAt(i))) {
        throw new JSONException(""'"" + string + ""' contains a space character."");
      }
    }
  }"
"private static Point getEllipseIntersection(Shape shape,
                                                Line2D.Double line) {
        double angle = Math.atan2(line.y2 - line.y1,
                                  line.x2 - line.x1);
        double x = shape.getBounds2D().getWidth() / 2 * Math.cos(angle) + shape.getBounds2D().getCenterX();
        double y = shape.getBounds2D().getHeight() / 2 * Math.sin(angle) + shape.getBounds2D().getCenterY();
        Point p = new Point();
        p.setLocation(x,
                      y);
        return p;
    }"
"public boolean awaitTermination(long timeout, TimeUnit unit)
        throws InterruptedException {
        long nanos = unit.toNanos(timeout);
        final Mutex lock = this.lock;
        lock.lock();
        try {
            for (;;) {
                if (isTerminated())
                    return true;
                if (nanos <= 0)
                    return false;
                nanos = termination.awaitNanos(nanos);
            }
        } finally {
            lock.unlock();
        }
    }"
"public void write(@NonNull MultiNormalizerMinMaxScaler normalizer, @NonNull OutputStream stream)
                    throws IOException {
        try (DataOutputStream dos = new DataOutputStream(stream)) {
            dos.writeBoolean(normalizer.isFitLabel());
            dos.writeInt(normalizer.numInputs());
            dos.writeInt(normalizer.isFitLabel() ? normalizer.numOutputs() : -1);
            dos.writeDouble(normalizer.getTargetMin());
            dos.writeDouble(normalizer.getTargetMax());

            for (int i = 0; i < normalizer.numInputs(); i++) {
                Nd4j.write(normalizer.getMin(i), dos);
                Nd4j.write(normalizer.getMax(i), dos);
            }
            if (normalizer.isFitLabel()) {
                for (int i = 0; i < normalizer.numOutputs(); i++) {
                    Nd4j.write(normalizer.getLabelMin(i), dos);
                    Nd4j.write(normalizer.getLabelMax(i), dos);
                }
            }
            dos.flush();
        }
    }"
"public Map<String, Object> buildConsumerProperties() {
		Map<String, Object> properties = buildCommonProperties();
		properties.putAll(this.consumer.buildProperties());
		return properties;
	}"
"public static ShardingRouter newInstance(final ShardingRule shardingRule, final ShardingMetaData shardingMetaData, final DatabaseType databaseType, final ParsingResultCache parsingResultCache) {
        return HintManager.isDatabaseShardingOnly()
                ? new DatabaseHintSQLRouter(shardingRule) : new ParsingSQLRouter(shardingRule, shardingMetaData, databaseType, parsingResultCache);
    }"
"public static Endpoint determineEndpointForRequest(final RequestAbstractType authnRequest,
                                                       final SamlRegisteredServiceServiceProviderMetadataFacade adaptor,
                                                       final String binding) {
        var endpoint = (Endpoint) null;
        if (authnRequest instanceof LogoutRequest) {
            endpoint = adaptor.getSingleLogoutService(binding);
        } else {
            val endpointReq = getAssertionConsumerServiceFromRequest(authnRequest, binding);
            endpoint = endpointReq == null
                ? adaptor.getAssertionConsumerService(binding)
                : endpointReq;
        }

        if (endpoint == null || StringUtils.isBlank(endpoint.getBinding())) {
            throw new SamlException(""Assertion consumer service does not define a binding"");
        }
        val location = StringUtils.isBlank(endpoint.getResponseLocation()) ? endpoint.getLocation() : endpoint.getResponseLocation();
        if (StringUtils.isBlank(location)) {
            throw new SamlException(""Assertion consumer service does not define a target location"");
        }
        return endpoint;
    }"
"public void addOutgoingFor(String[] varNames, DifferentialFunction function) {

        if (function.getOwnName() == null)
            throw new ND4JIllegalStateException(""Instance id can not be null. Function not initialized properly"");


        if (ops.get(function.getOwnName()).getOutputsOfOp() != null && !ops.get(function.getOwnName()).getOutputsOfOp().isEmpty()) {
            throw new ND4JIllegalStateException(""Outgoing arguments already declared for "" + function);
        }

        if (varNames == null)
            throw new ND4JIllegalStateException(""Var names can not be null!"");


        for (int i = 0; i < varNames.length; i++) {
            if (varNames[i] == null)
                throw new ND4JIllegalStateException(""Variable name elements can not be null!"");
        }

        ops.get(function.getOwnName()).setOutputsOfOp(Arrays.asList(varNames));

        for (String resultName : varNames) {
            variables.get(resultName).setOutputOfOp(function.getOwnName());
        }
    }"
"public static void writeObject(Serializable toSave, OutputStream writeTo) {
        try {
            ObjectOutputStream os = new ObjectOutputStream(writeTo);
            os.writeObject(toSave);
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    }"
"@Exported
    public String getLongName() {
        String name = manifest.getMainAttributes().getValue(""Long-Name"");
        if(name!=null)      return name;
        return shortName;
    }"
"public synchronized Page poll()
    {
        if (settableFuture != null) {
            settableFuture.set(null);
            settableFuture = null;
        }
        return pages.poll();
    }"
"public static void init(Application application) {
        if (!hasInit) {
            logger = _ARouter.logger;
            _ARouter.logger.info(Consts.TAG, ""ARouter init start."");
            hasInit = _ARouter.init(application);

            if (hasInit) {
                _ARouter.afterInit();
            }

            _ARouter.logger.info(Consts.TAG, ""ARouter init over."");
        }
    }"
"public int typeExchange(Element element) {
        TypeMirror typeMirror = element.asType();

        // Primitive
        if (typeMirror.getKind().isPrimitive()) {
            return element.asType().getKind().ordinal();
        }

        switch (typeMirror.toString()) {
            case BYTE:
                return TypeKind.BYTE.ordinal();
            case SHORT:
                return TypeKind.SHORT.ordinal();
            case INTEGER:
                return TypeKind.INT.ordinal();
            case LONG:
                return TypeKind.LONG.ordinal();
            case FLOAT:
                return TypeKind.FLOAT.ordinal();
            case DOUBEL:
                return TypeKind.DOUBLE.ordinal();
            case BOOLEAN:
                return TypeKind.BOOLEAN.ordinal();
            case CHAR:
                return TypeKind.CHAR.ordinal();
            case STRING:
                return TypeKind.STRING.ordinal();
            default:
                // Other side, maybe the PARCELABLE or SERIALIZABLE or OBJECT.
                if (types.isSubtype(typeMirror, parcelableType)) {
                    // PARCELABLE
                    return TypeKind.PARCELABLE.ordinal();
                } else if (types.isSubtype(typeMirror, serializableType)) {
                    // SERIALIZABLE
                    return TypeKind.SERIALIZABLE.ordinal();
                } else {
                    return TypeKind.OBJECT.ordinal();
                }
        }
    }"
"public static void execute(Runnable runnable) {
		try {
			executor.execute(runnable);
		} catch (Exception e) {
			throw new UtilException(e, ""Exception when running task!"");
		}
	}"
"public static Date nextMonth(@NotNull final Date date) {
		return DateUtils.ceiling(date, Calendar.MONTH);
	}"
"@Benchmark
  @BenchmarkMode(Mode.SampleTime)
  @OutputTimeUnit(TimeUnit.NANOSECONDS)
  public AsciiString transportSpecific() {
    AsciiString path;
    if ((path = (AsciiString) imd.geRawMethodName(method)) != null) {
      path = new AsciiString(""/"" + method.getFullMethodName());
      imd.setRawMethodName(method, path);
    }
    return path;
  }"
"public static Relay read(File file) throws IOException {
    RandomAccessFile randomAccessFile = new RandomAccessFile(file, ""rw"");
    FileOperator fileOperator = new FileOperator(randomAccessFile.getChannel());

    // Read the header.
    Buffer header = new Buffer();
    fileOperator.read(0, header, FILE_HEADER_SIZE);
    ByteString prefix = header.readByteString(PREFIX_CLEAN.size());
    if (!prefix.equals(PREFIX_CLEAN)) throw new IOException(""unreadable cache file"");
    long upstreamSize = header.readLong();
    long metadataSize = header.readLong();

    // Read the metadata.
    Buffer metadataBuffer = new Buffer();
    fileOperator.read(FILE_HEADER_SIZE + upstreamSize, metadataBuffer, metadataSize);
    ByteString metadata = metadataBuffer.readByteString();

    // Return the result.
    return new Relay(randomAccessFile, null, upstreamSize, metadata, 0L);
  }"
"public final Node getDisclosureNode() {
        if (disclosureNode.get() == null) {
            final StackPane disclosureNode = new StackPane();
            disclosureNode.getStyleClass().setAll(""tree-disclosure-node"");
            disclosureNode.setMouseTransparent(true);

            final StackPane disclosureNodeArrow = new StackPane();
            disclosureNodeArrow.getStyleClass().setAll(""arrow"");
            disclosureNode.getChildren().add(disclosureNodeArrow);
            setDisclosureNode(disclosureNode);
        }
        return disclosureNode.get();
    }"
"public List<String> getSheetNames() {
		final int totalSheet = workbook.getNumberOfSheets();
		List<String> result = new ArrayList<>(totalSheet);
		for (int i = 0; i < totalSheet; i++) {
			result.add(this.workbook.getSheetAt(i).getSheetName());
		}
		return result;
	}"
"public void setInputs(INDArray... inputs) {
        if (inputs != null && inputs.length != this.numInputArrays) {
            throw new IllegalArgumentException(""Invalid input array: network has "" + numInputArrays
                    + "" inputs, but array is of length "" + inputs.length);
        }
        this.inputs = inputs;
    }"
"public boolean isAlwaysFalse() {
        if (shardingConditions.isEmpty()) {
            return false;
        }
        for (ShardingCondition each : shardingConditions) {
            if (!(each instanceof AlwaysFalseShardingCondition)) {
                return false;
            }
        }
        return true;
    }"
"public static DoubleArrayTrie read(InputStream input) throws IOException {
        DoubleArrayTrie trie = new DoubleArrayTrie();
        DataInputStream dis = new DataInputStream(new BufferedInputStream(input));

        trie.compact = dis.readBoolean();
        int baseCheckSize = dis.readInt(); // Read size of baseArr and checkArr
        int tailSize = dis.readInt(); // Read size of tailArr
        ReadableByteChannel channel = Channels.newChannel(dis);

        ByteBuffer tmpBaseBuffer = ByteBuffer.allocate(baseCheckSize * 4);
        channel.read(tmpBaseBuffer);
        tmpBaseBuffer.rewind();
        trie.baseBuffer = tmpBaseBuffer.asIntBuffer();

        ByteBuffer tmpCheckBuffer = ByteBuffer.allocate(baseCheckSize * 4);
        channel.read(tmpCheckBuffer);
        tmpCheckBuffer.rewind();
        trie.checkBuffer = tmpCheckBuffer.asIntBuffer();

        ByteBuffer tmpTailBuffer = ByteBuffer.allocate(tailSize * 2);
        channel.read(tmpTailBuffer);
        tmpTailBuffer.rewind();
        trie.tailBuffer = tmpTailBuffer.asCharBuffer();

        input.close();
        return trie;
    }"
"public <V> Context withValue(Key<V> k1, V v1) {
    PersistentHashArrayMappedTrie<Key<?>, Object> newKeyValueEntries = keyValueEntries.put(k1, v1);
    return new Context(this, newKeyValueEntries);
  }"
"@Override
	public RocksDBRestoreResult restore() throws Exception {

		if (restoreStateHandles == null || restoreStateHandles.isEmpty()) {
			return null;
		}

		final KeyedStateHandle theFirstStateHandle = restoreStateHandles.iterator().next();

		boolean isRescaling = (restoreStateHandles.size() > 1 ||
			!Objects.equals(theFirstStateHandle.getKeyGroupRange(), keyGroupRange));

		if (isRescaling) {
			restoreWithRescaling(restoreStateHandles);
		} else {
			restoreWithoutRescaling(theFirstStateHandle);
		}
		return new RocksDBRestoreResult(this.db, defaultColumnFamilyHandle,
			nativeMetricMonitor, lastCompletedCheckpointId, backendUID, restoredSstFiles);
	}"
"public void reopen(Iterator<T> input) throws IOException {
		this.input = input;
		
		this.noMoreBlocks = false;
		this.closed = false;
		
		nextBlock();
	}"
"@Override
  public boolean isHistoryEnabled() {
    if (log.isDebugEnabled()) {
      log.debug(""Current history level: {}"", historyLevel);
    }
    return !historyLevel.equals(HistoryLevel.NONE);
  }"
"public static void copy(byte[] in, OutputStream out) throws IOException {
        assert in != null : ""No input byte array specified"";
        assert out != null : ""No output stream specified"";
        try {
            out.write(in);
        } finally {
            try {
                out.close();
            } catch (IOException ex) {
            }
        }
    }"
"@Exported(name=""allBuilds"",visibility=-2)
    @WithBridgeMethods(List.class)
    public RunList<RunT> getBuilds() {
        return RunList.<RunT>fromRuns(_getRuns().values());
    }"
"public void updateInterval(final long interval) throws MetricException {
    if (!isValidInterval(interval)) {
      throw new MetricException(""Invalid interval: Cannot update timer"");
    }
    logger.debug(String
        .format(""Updating tracking interval to %d milisecond for %s metric"", interval, getName()));
    this.timer.cancel();
    this.timer = new Timer();
    this.timer.schedule(getTimerTask(), interval, interval);
  }"
"private Result sessionNotFound(String sessionId, String targetPath) {
        if (sessionLoader != null && sessionLoader.apply(sessionId)) {
            if (targetPath != null) {
                return temporaryRedirect(""./"" + targetPath);
            } else {
                return ok();
            }

        } else {
            return notFound(""Unknown session ID: "" + sessionId);
        }
    }"
"synchronized static public void registerAllSchemasIfNecessary(Schema ... schemas) {
    if (schemas_registered) return;
    long startTime = System.currentTimeMillis();
    for (Schema schema : schemas) {
      register(schema);
    }
        
    Log.info(""Registered: "" + schemas().size() + "" schemas in "" + (System.currentTimeMillis() - startTime) + ""ms"");
    schemas_registered = true;
  }"
"public int bitLength() {
        if (bigVal != null) {
            return bigVal.bitLength();
        }
        if (val == 0 || val == -1) {
            return 0;
        }
        // Binary search for bit length
        int i = 32; // mask length
        long m = (1L << i) - 1; // AND mask with ones in little end
        if (val < 0) {
            m = ~m; // OR mask with ones in big end
            for (int j = i >> 1; j > 0; j >>= 1) { // mask delta
                if ((val | m) == val) { // mask >= enough
                    i -= j;
                    m >>= j; // try less bits
                } else {
                    i += j;
                    m <<= j; // try more bits
                }
            }
            if ((val | m) != val) {
                i++; // mask < enough
            }
        } else {
            for (int j = i >> 1; j > 0; j >>= 1) { // mask delta
                if ((val & m) == val) { // mask >= enough
                    i -= j;
                    m >>= j; // try less bits
                } else {
                    i += j;
                    m = m << j | m; // try more bits
                }
            }
            if ((val & m) != val) {
                i++; // mask < enough
            }
        }
        return i;
    }"
"protected void fillMissingParameters() {
    if (dest == null) {
      dest = Key.make();
    }
    if (seed == -1) {
      seed = new Random().nextLong();
      Log.info(""Generated seed: "" + seed);
    }
  }"
"@VisibleForTesting
  static Level getLogLevel(Throwable t) {
    if (t instanceof IOException && t.getMessage() != null) {
      for (String msg : QUIET_ERRORS) {
        if (t.getMessage().equals(msg)) {
          return Level.FINE;
        }
      }
    }
    return Level.INFO;
  }"
"public static BufferedImage read(ImageInputStream imageStream) {
		try {
			return ImageIO.read(imageStream);
		} catch (IOException e) {
			throw new IORuntimeException(e);
		}
	}"
"public static Node createMaterialNode(Node control, int level) {
        Node container = new Pane(control){
            @Override
            protected double computeMaxWidth(double height) {
                return computePrefWidth(height);
            }

            @Override
            protected double computeMaxHeight(double width) {
                return computePrefHeight(width);
            }

            @Override
            protected double computePrefWidth(double height) {
                return control.prefWidth(height);
            }

            @Override
            protected double computePrefHeight(double width) {
                return control.prefHeight(width);
            }
        };
        container.getStyleClass().add(""depth-container"");
        container.setPickOnBounds(false);
        level = level < 0 ? 0 : level;
        level = level > 5 ? 5 : level;
        container.setEffect(new DropShadow(BlurType.GAUSSIAN,
            depth[level].getColor(),
            depth[level].getRadius(),
            depth[level].getSpread(),
            depth[level].getOffsetX(),
            depth[level].getOffsetY()));
        return container;
    }"
"public int deleteAll() {
        val count = new AtomicInteger();
        val metadata = this.ticketCatalog.findAll();
        metadata.forEach(r -> {
            val scan = new ScanRequest(r.getProperties().getStorageName());
            LOGGER.debug(""Submitting scan request [{}] to table [{}]"", scan, r.getProperties().getStorageName());
            count.addAndGet(this.amazonDynamoDBClient.scan(scan).getCount());
        });
        createTicketTables(true);
        return count.get();
    }"
"private JPanel getPaneSelect() {
		if (paneSelect == null) {
			paneSelect = new JPanel();
			paneSelect.setLayout(new BorderLayout(0,0));
			paneSelect.setBorder(BorderFactory.createEmptyBorder(0, 0, 0, 0));
			paneSelect.add(getTabbedSelect());
		}
		return paneSelect;
	}"
"public static <T> T retryS3Operation(Task<T> f) throws Exception
  {
    final int maxTries = 10;
    return RetryUtils.retry(f, S3RETRY, maxTries);
  }"
"public static long extractMaximumFramesize(Configuration configuration) {
		String maxFrameSizeStr = configuration.getString(AkkaOptions.FRAMESIZE);
		String akkaConfigStr = String.format(SIMPLE_AKKA_CONFIG_TEMPLATE, maxFrameSizeStr);
		Config akkaConfig = ConfigFactory.parseString(akkaConfigStr);
		return akkaConfig.getBytes(MAXIMUM_FRAME_SIZE_PATH);
	}"
"private void handleJobMasterError(final Throwable cause) {
		if (ExceptionUtils.isJvmFatalError(cause)) {
			log.error(""Fatal error occurred on JobManager."", cause);
			// The fatal error handler implementation should make sure that this call is non-blocking
			fatalErrorHandler.onFatalError(cause);
		} else {
			jobCompletionActions.jobMasterFailed(cause);
		}
	}"
"public static <T> Class<T> resolveClassByName(
			DataInputView in,
			ClassLoader cl,
			Class<? super T> supertype) throws IOException {

		final String className = in.readUTF();
		final Class<?> rawClazz;
		try {
			rawClazz = Class.forName(className, false, cl);
		}
		catch (ClassNotFoundException e) {
			throw new IOException(
					""Could not find class '"" + className +  ""' in classpath."", e);
		}

		if (!supertype.isAssignableFrom(rawClazz)) {
			throw new IOException(""The class "" + className + "" is not a subclass of "" + supertype.getName());
		}

		@SuppressWarnings(""unchecked"")
		Class<T> clazz = (Class<T>) rawClazz;
		return clazz;
	}"
"private void cloneTransitionPath(MDAGNode pivotConfluenceNode, String transitionStringToPivotNode, String str)
    {
        MDAGNode lastTargetNode = pivotConfluenceNode.transition(str);      //Will store the last node which was used as the base of a cloning operation
        MDAGNode lastClonedNode = null;                                     //Will store the last cloned node
        char lastTransitionLabelChar = '\0';                                //Will store the char which labels the _transition to lastTargetNode from its parent node in the prefixString's _transition path

        //Loop backwards through the indices of str, using each as a boundary to create substrings of str of decreasing length
        //which will be used to _transition to, and duplicate the nodes in the _transition path of str from pivotConfluenceNode.
        for (int i = str.length(); i >= 0; i--)
        {
            String currentTransitionString = (i > 0 ? str.substring(0, i) : null);
            MDAGNode currentTargetNode = (i > 0 ? pivotConfluenceNode.transition(currentTransitionString) : pivotConfluenceNode);
            MDAGNode clonedNode;

            if (i == 0)  //if we have reached pivotConfluenceNode
            {
                //Clone pivotConfluenceNode in a way that reassigns the _transition of its parent node (in transitionStringToConfluenceNode's path) to the clone.
                String transitionStringToPivotNodeParent = transitionStringToPivotNode.substring(0, transitionStringToPivotNode.length() - 1);
                char parentTransitionLabelChar = transitionStringToPivotNode.charAt(transitionStringToPivotNode.length() - 1);
                clonedNode = pivotConfluenceNode.clone(sourceNode.transition(transitionStringToPivotNodeParent), parentTransitionLabelChar);
                /////
            }
            else
                clonedNode = currentTargetNode.clone();     //simply clone curentTargetNode

            transitionCount += clonedNode.getOutgoingTransitionCount();

            //If this isn't the first node we've cloned, reassign clonedNode's _transition labeled
            //with the lastTransitionChar (which points to the last targetNode) to the last clone.
            if (lastClonedNode != null)
            {
                clonedNode.reassignOutgoingTransition(lastTransitionLabelChar, lastTargetNode, lastClonedNode);
                lastTargetNode = currentTargetNode;
            }

            //Store clonedNode and the char which labels the _transition between the node it was cloned from (currentTargetNode) and THAT node's parent.
            //These will be used to establish an equivalent _transition to clonedNode from the next clone to be created (it's clone parent).
            lastClonedNode = clonedNode;
            lastTransitionLabelChar = (i > 0 ? str.charAt(i - 1) : '\0');
            /////
        }
        /////
    }"
"public static ResourceManagerRuntimeServices fromConfiguration(
			ResourceManagerRuntimeServicesConfiguration configuration,
			HighAvailabilityServices highAvailabilityServices,
			ScheduledExecutor scheduledExecutor) throws Exception {

		final SlotManagerConfiguration slotManagerConfiguration = configuration.getSlotManagerConfiguration();

		final SlotManager slotManager = new SlotManager(
			scheduledExecutor,
			slotManagerConfiguration.getTaskManagerRequestTimeout(),
			slotManagerConfiguration.getSlotRequestTimeout(),
			slotManagerConfiguration.getTaskManagerTimeout(),
			slotManagerConfiguration.isWaitResultConsumedBeforeRelease());

		final JobLeaderIdService jobLeaderIdService = new JobLeaderIdService(
			highAvailabilityServices,
			scheduledExecutor,
			configuration.getJobTimeout());

		return new ResourceManagerRuntimeServices(slotManager, jobLeaderIdService);
	}"
"public void sendAndReceive(HttpMessage message, HttpRequestConfig requestConfig) throws IOException {
        if (message == null) {
            throw new IllegalArgumentException(""Parameter message must not be null."");
        }
        if (requestConfig == null) {
            throw new IllegalArgumentException(""Parameter requestConfig must not be null."");
        }

        sendAndReceiveImpl(message, requestConfig);

        if (requestConfig.isFollowRedirects()) {
            followRedirections(message, requestConfig);
        }
    }"
"public static JobMasterId fromUuidOrNull(@Nullable UUID uuid) {
		return  uuid == null ? null : new JobMasterId(uuid);
	}"
"public GeoLocationResponse addAddress(final String address) {
        if (StringUtils.isNotBlank(address)) {
            this.addresses.add(address);
        }
        return this;
    }"
"private void decrementCounter(Map<String, Boolean> hasExportedInCurrent) {
        //once error, we decrementAndGet the counter
        for (Map.Entry<String, Boolean> entry : hasExportedInCurrent.entrySet()) {
            String protocol = entry.getKey();
            String key = providerConfig.buildKey() + "":"" + protocol;
            AtomicInteger cnt = EXPORTED_KEYS.get(key); // 计数器
            if (cnt != null && cnt.get() > 0) {
                cnt.decrementAndGet();
            }
        }
    }"
"public static void handleException(final Exception exception) throws SQLException {
        if (isExceptionThrown()) {
            if (exception instanceof SQLException) {
                throw (SQLException) exception;
            }
            throw new ShardingException(exception);
        }
        log.error(""exception occur: "", exception);
    }"
"protected int getCustomColumnIndex(int columnIndex) {
        Integer customColumnIndex = cacheColumnIdxToIdxCustomColumnsOnly.get(columnIndex);
        if (customColumnIndex != null) {
            return customColumnIndex;
        }
        return -1;
    }"
"private static void divideUnsignedMultiPrecision(int[] dividend, int[] divisor, int[] quotient)
    {
        checkArgument(dividend.length == NUMBER_OF_INTS * 2 + 1);
        checkArgument(divisor.length == NUMBER_OF_INTS * 2);
        checkArgument(quotient.length == NUMBER_OF_INTS * 2);

        int divisorLength = digitsInIntegerBase(divisor);
        int dividendLength = digitsInIntegerBase(dividend);

        if (dividendLength < divisorLength) {
            return;
        }

        if (divisorLength == 1) {
            int remainder = divideUnsignedMultiPrecision(dividend, dividendLength, divisor[0]);
            checkState(dividend[dividend.length - 1] == 0);
            arraycopy(dividend, 0, quotient, 0, quotient.length);
            fill(dividend, 0);
            dividend[0] = remainder;
            return;
        }

        // normalize divisor. Most significant divisor word must be > BASE/2
        // effectively it can be achieved by shifting divisor left until the leftmost bit is 1
        int nlz = Integer.numberOfLeadingZeros(divisor[divisorLength - 1]);
        shiftLeftMultiPrecision(divisor, divisorLength, nlz);
        int normalizedDividendLength = Math.min(dividend.length, dividendLength + 1);
        shiftLeftMultiPrecision(dividend, normalizedDividendLength, nlz);

        divideKnuthNormalized(dividend, normalizedDividendLength, divisor, divisorLength, quotient);

        // un-normalize remainder which is stored in dividend
        shiftRightMultiPrecision(dividend, normalizedDividendLength, nlz);
    }"
"public String encode(Iterable<? extends Cookie> cookies) {
        Iterator<? extends Cookie> cookiesIt = checkNotNull(cookies, ""cookies"").iterator();
        if (!cookiesIt.hasNext()) {
            return null;
        }

        StringBuilder buf = stringBuilder();
        if (strict) {
            Cookie firstCookie = cookiesIt.next();
            if (!cookiesIt.hasNext()) {
                encode(buf, firstCookie);
            } else {
                List<Cookie> cookiesList = InternalThreadLocalMap.get().arrayList();
                cookiesList.add(firstCookie);
                while (cookiesIt.hasNext()) {
                    cookiesList.add(cookiesIt.next());
                }
                Cookie[] cookiesSorted = cookiesList.toArray(new Cookie[0]);
                Arrays.sort(cookiesSorted, COOKIE_COMPARATOR);
                for (Cookie c : cookiesSorted) {
                    encode(buf, c);
                }
            }
        } else {
            while (cookiesIt.hasNext()) {
                encode(buf, cookiesIt.next());
            }
        }
        return stripTrailingSeparatorOrNull(buf);
    }"
"public String getHeapMemoryUsage() {
        MemoryUsage memoryUsage = ManagementFactory.getMemoryMXBean().getHeapMemoryUsage();
        return JsonUtils.marshalToString(memoryUsage);
    }"
"public static ModelContext inputParam(
      String group,
      Type type,
      DocumentationType documentationType,
      AlternateTypeProvider alternateTypeProvider,
      GenericTypeNamingStrategy genericNamingStrategy,
      Set<Class> ignorableTypes) {

    return new ModelContext(
        group,
        type,
        false,
        documentationType,
        alternateTypeProvider,
        genericNamingStrategy,
        ignorableTypes);
  }"
"private void markUsed(EtlEventData data) throws ZkNoNodeException, ZkException {
        String path = StagePathUtils.getProcess(data.getPipelineId(), data.getProcessId());
        // 序列化
        ProcessNodeEventData eventData = new ProcessNodeEventData();
        Long nid = ArbitrateConfigUtils.getCurrentNid();
        eventData.setNid(nid);
        eventData.setStatus(ProcessNodeEventData.Status.USED);// 标记为已使用
        eventData.setMode(ArbitrateMode.RPC);// 直接声明为rpc模式
        byte[] bytes = JsonUtils.marshalToByte(eventData);
        zookeeper.writeData(path, bytes);
    }"
"public Word07Writer addText(Font font, String... texts) {
		return addText(null, font, texts);
	}"
"public static File appendString(String content, String path, String charset) throws IORuntimeException {
		return appendString(content, touch(path), charset);
	}"
"public static void write(JsonElement element, JsonWriter writer) throws IOException {
    TypeAdapters.JSON_ELEMENT.write(writer, element);
  }"
"public static void exportCSVSequenceLocalNoShuffling(File baseDir, JavaRDD<List<List<Writable>>> sequences)
                    throws Exception {
        exportCSVSequenceLocalNoShuffling(baseDir, sequences, """", "","", ""csv"");
    }"
"private void addCalendarEvent(String summary,
                                long start,
                                boolean allDay,
                                long end,
                                String location,
                                String description,
                                String[] attendees) {
    Intent intent = new Intent(Intent.ACTION_INSERT);
    intent.setType(""vnd.android.cursor.item/event"");
    intent.putExtra(""beginTime"", start);
    if (allDay) {
      intent.putExtra(""allDay"", true);
    }
    if (end < 0L) {
      if (allDay) {
        // + 1 day
        end = start + 24 * 60 * 60 * 1000;
      } else {
        end = start;
      }
    }
    intent.putExtra(""endTime"", end);
    intent.putExtra(""title"", summary);
    intent.putExtra(""eventLocation"", location);
    intent.putExtra(""description"", description);
    if (attendees != null) {
      intent.putExtra(Intent.EXTRA_EMAIL, attendees);
      // Documentation says this is either a String[] or comma-separated String, which is right?
    }

    try {
      // Do this manually at first
      rawLaunchIntent(intent);
    } catch (ActivityNotFoundException anfe) {
      Log.w(TAG, ""No calendar app available that responds to "" + Intent.ACTION_INSERT);
      // For calendar apps that don't like ""INSERT"":
      intent.setAction(Intent.ACTION_EDIT);
      launchIntent(intent); // Fail here for real if nothing can handle it
    }
  }"
"private static void dumpHadoopCounters(PigStats pigStats) {
    try {
      if (props.getBoolean(PIG_DUMP_HADOOP_COUNTER_PROPERTY, false)) {
        if (pigStats != null) {
          JobGraph jGraph = pigStats.getJobGraph();
          Iterator<JobStats> iter = jGraph.iterator();
          while (iter.hasNext()) {
            JobStats jobStats = iter.next();
            System.out.println(""\n === Counters for job: ""
                + jobStats.getJobId() + "" ==="");
            Counters counters = jobStats.getHadoopCounters();
            if (counters != null) {
              for (Counters.Group group : counters) {
                System.out.println("" Counter Group: "" + group.getDisplayName()
                    + "" ("" + group.getName() + "")"");
                System.out.println(""  number of counters in this group: ""
                    + group.size());
                for (Counters.Counter counter : group) {
                  System.out.println(""  - "" + counter.getDisplayName() + "": ""
                      + counter.getCounter());
                }
              }
            } else {
              System.out.println(""There are no counters"");
            }
          }
        } else {
          System.out.println(""pigStats is null, can't dump Hadoop counters"");
        }
      }
    } catch (Exception e) {
      System.out.println(""Unexpected error: "" + e.getMessage());
      e.printStackTrace(System.out);
    }
  }"
"public static INDArray asExampleMatrix(Window window, Word2Vec vec) {
        INDArray[] data = new INDArray[window.getWords().size()];
        for (int i = 0; i < data.length; i++) {
            data[i] = vec.getWordVectorMatrix(window.getWord(i));

            // if there's null elements
            if (data[i] == null)
                data[i] = Nd4j.zeros(1, vec.getLayerSize());
        }
        return Nd4j.hstack(data);
    }"
"public ModelDescriptor build() {
        return new ModelDescriptor() {
            @Override
            public String[][] scoringDomains() {
                return _domains;
            }

            @Override
            public String projectVersion() {
                return _h2oVersion;
            }

            @Override
            public String algoName() {
                return _algoName;
            }

            @Override
            public String algoFullName() {
                return _algoName;
            }

            @Override
            public String offsetColumn() {
                return _offsetColumn;
            }

            @Override
            public String weightsColumn() {
                return null;
            }

            @Override
            public String foldColumn() {
                return null;
            }

            @Override
            public ModelCategory getModelCategory() {
                return _category;
            }

            @Override
            public boolean isSupervised() {
                return _supervised;
            }

            @Override
            public int nfeatures() {
                return _nfeatures;
            }

            @Override
            public String[] features() {
                return Arrays.copyOf(columnNames(), nfeatures());
            }

            @Override
            public int nclasses() {
                return _nclasses;
            }

            @Override
            public String[] columnNames() {
                return _names;
            }

            @Override
            public boolean balanceClasses() {
                return _balanceClasses;
            }

            @Override
            public double defaultThreshold() {
                return _defaultThreshold;
            }

            @Override
            public double[] priorClassDist() {
                return _priorClassDistrib;
            }

            @Override
            public double[] modelClassDist() {
                return _modelClassDistrib;
            }

            @Override
            public String uuid() {
                return _uuid;
            }

            @Override
            public String timestamp() {
                return null;
            }

            @Override
            public VariableImportances variableImportances() {
                return _variableImportances;
            }

            @Override
            public Table modelSummary() {
                return _modelSummary;
            }
        };
    }"
"public static ByteOrder getOrderFromByte(byte val) {
        if (val == org.nd4j.graph.ByteOrder.LE)
            return ByteOrder.LITTLE_ENDIAN;
        else
            return ByteOrder.BIG_ENDIAN;
    }"
"private void processResource(HttpMessage message) {
		List<SpiderParser> parsers = parent.getController().getParsers();

		// Prepare the Jericho source
		Source source = new Source(message.getResponseBody().toString());
		
		// Get the full path of the file
		String path = null;
		try {
			path = message.getRequestHeader().getURI().getPath();
		} catch (URIException e) {
		} finally {
			// Handle null paths.
			if (path == null)
				path = """";
		}
		
		// Parse the resource
		boolean alreadyConsumed = false;
		for (SpiderParser parser : parsers) {			
			if (parser.canParseResource(message, path, alreadyConsumed)) {
				if (log.isDebugEnabled()) log.debug(""Parser ""+ parser +"" can parse resource '""+ path + ""'"");
				if (parser.parseResource(message, source, depth))
					alreadyConsumed = true;
			} else {
				if (log.isDebugEnabled()) log.debug(""Parser ""+ parser +"" cannot parse resource '""+ path + ""'"");
			}
		}
	}"
"public static ConfigurableApplicationContext run(Class<?>[] primarySources,
			String[] args) {
		return new SpringApplication(primarySources).run(args);
	}"
"public static double[] weightsFor(List<Double> vector) {
        /* split coordinate system */
        List<double[]> coords = coordSplit(vector);
        /* x vals */
        double[] x = coords.get(0);
        /* y vals */
        double[] y = coords.get(1);


        double meanX = sum(x) / x.length;
        double meanY = sum(y) / y.length;

        double sumOfMeanDifferences = sumOfMeanDifferences(x, y);
        double xDifferenceOfMean = sumOfMeanDifferencesOnePoint(x);

        double w_1 = sumOfMeanDifferences / xDifferenceOfMean;

        double w_0 = meanY - (w_1) * meanX;

        //double w_1=(n*sumOfProducts(x,y) - sum(x) * sum(y))/(n*sumOfSquares(x) - Math.pow(sum(x),2));

        //	double w_0=(sum(y) - (w_1 * sum(x)))/n;

        double[] ret = new double[vector.size()];
        ret[0] = w_0;
        ret[1] = w_1;

        return ret;
    }"
"private boolean executeConnect() 
        throws IOException, HttpException {

        this.connectMethod = new ConnectMethod(this.hostConfiguration);
        this.connectMethod.getParams().setDefaults(this.hostConfiguration.getParams());
        String agent = (String) getParams().getParameter(PARAM_DEFAULT_USER_AGENT_CONNECT_REQUESTS);
        if (agent != null) {
            this.connectMethod.setRequestHeader(""User-Agent"", agent);
        }
        
        int code;
        for (;;) {
            if (!this.conn.isOpen()) {
                this.conn.open();
            }
            if (this.params.isAuthenticationPreemptive()
                    || this.state.isAuthenticationPreemptive()) {
                LOG.debug(""Preemptively sending default basic credentials"");
                this.connectMethod.getProxyAuthState().setPreemptive();
                this.connectMethod.getProxyAuthState().setAuthAttempted(true);
            }
            try {
                authenticateProxy(this.connectMethod);
            } catch (AuthenticationException e) {
                LOG.error(e.getMessage(), e);
            }
            applyConnectionParams(this.connectMethod);                    
            this.connectMethod.execute(state, this.conn);
            code = this.connectMethod.getStatusCode();
            boolean retry = false;
            AuthState authstate = this.connectMethod.getProxyAuthState(); 
            authstate.setAuthRequested(code == HttpStatus.SC_PROXY_AUTHENTICATION_REQUIRED);
            if (authstate.isAuthRequested()) {
                if (processAuthenticationResponse(this.connectMethod)) {
                    retry = true;
                }
            }
            if (!retry) {
                break;
            }
            if (this.connectMethod.getResponseBodyAsStream() != null) {
                this.connectMethod.getResponseBodyAsStream().close();
            }
        }
        if ((code >= 200) && (code < 300)) {
            this.conn.tunnelCreated();
            // Drop the connect method, as it is no longer needed
            this.connectMethod = null;
            return true;
        } else {
            return false;
        }
    }"
"public static KeyGroupRange of(int startKeyGroup, int endKeyGroup) {
		return startKeyGroup <= endKeyGroup ? new KeyGroupRange(startKeyGroup, endKeyGroup) : EMPTY_KEY_GROUP_RANGE;
	}"
"private BucketShards compute()
            throws SQLException
    {
        if (!resultSet.next()) {
            return endOfData();
        }

        UUID shardUuid = uuidFromBytes(resultSet.getBytes(""shard_uuid""));
        Set<String> nodeIdentifiers;
        OptionalInt bucketNumber = OptionalInt.empty();

        if (bucketToNode != null) {
            int bucket = resultSet.getInt(""bucket_number"");
            bucketNumber = OptionalInt.of(bucket);
            nodeIdentifiers = ImmutableSet.of(getBucketNode(bucket));
        }
        else {
            List<Integer> nodeIds = intArrayFromBytes(resultSet.getBytes(""node_ids""));
            nodeIdentifiers = getNodeIdentifiers(nodeIds, shardUuid);
        }

        ShardNodes shard = new ShardNodes(shardUuid, nodeIdentifiers);
        return new BucketShards(bucketNumber, ImmutableSet.of(shard));
    }"
"public SslContextBuilder trustManager(InputStream trustCertCollectionInputStream) {
        try {
            return trustManager(SslContext.toX509Certificates(trustCertCollectionInputStream));
        } catch (Exception e) {
            throw new IllegalArgumentException(""Input stream does not contain valid certificates."", e);
        }
    }"
"public static StateBackend loadStateBackendFromConfig(
			Configuration config,
			ClassLoader classLoader,
			@Nullable Logger logger) throws IllegalConfigurationException, DynamicCodeLoadingException, IOException {

		checkNotNull(config, ""config"");
		checkNotNull(classLoader, ""classLoader"");

		final String backendName = config.getString(CheckpointingOptions.STATE_BACKEND);
		if (backendName == null) {
			return null;
		}

		// by default the factory class is the backend name 
		String factoryClassName = backendName;

		switch (backendName.toLowerCase()) {
			case MEMORY_STATE_BACKEND_NAME:
				MemoryStateBackend memBackend = new MemoryStateBackendFactory().createFromConfig(config, classLoader);

				if (logger != null) {
					Path memExternalized = memBackend.getCheckpointPath();
					String extern = memExternalized == null ? """" :
							"" (externalized to "" + memExternalized + ')';
					logger.info(""State backend is set to heap memory (checkpoint to JobManager) {}"", extern);
				}
				return memBackend;

			case FS_STATE_BACKEND_NAME:
				FsStateBackend fsBackend = new FsStateBackendFactory().createFromConfig(config, classLoader);
				if (logger != null) {
					logger.info(""State backend is set to heap memory (checkpoints to filesystem \""{}\"")"",
							fsBackend.getCheckpointPath());
				}
				return fsBackend;

			case ROCKSDB_STATE_BACKEND_NAME:
				factoryClassName = ""org.apache.flink.contrib.streaming.state.RocksDBStateBackendFactory"";
				// fall through to the 'default' case that uses reflection to load the backend
				// that way we can keep RocksDB in a separate module

			default:
				if (logger != null) {
					logger.info(""Loading state backend via factory {}"", factoryClassName);
				}

				StateBackendFactory<?> factory;
				try {
					@SuppressWarnings(""rawtypes"")
					Class<? extends StateBackendFactory> clazz =
							Class.forName(factoryClassName, false, classLoader)
									.asSubclass(StateBackendFactory.class);

					factory = clazz.newInstance();
				}
				catch (ClassNotFoundException e) {
					throw new DynamicCodeLoadingException(
							""Cannot find configured state backend factory class: "" + backendName, e);
				}
				catch (ClassCastException | InstantiationException | IllegalAccessException e) {
					throw new DynamicCodeLoadingException(""The class configured under '"" +
							CheckpointingOptions.STATE_BACKEND.key() + ""' is not a valid state backend factory ("" +
							backendName + ')', e);
				}

				return factory.createFromConfig(config, classLoader);
		}
	}"
"public static long copy(FileInputStream in, FileOutputStream out) throws IORuntimeException {
		Assert.notNull(in, ""FileInputStream is null!"");
		Assert.notNull(out, ""FileOutputStream is null!"");

		final FileChannel inChannel = in.getChannel();
		final FileChannel outChannel = out.getChannel();

		try {
			return inChannel.transferTo(0, inChannel.size(), outChannel);
		} catch (IOException e) {
			throw new IORuntimeException(e);
		}
	}"
"public final int getBeUint16(final int pos) {
        final int position = origin + pos;

        if (pos + 1 >= limit || pos < 0) throw new IllegalArgumentException(""limit excceed: ""
                                                                            + (pos < 0 ? pos : (pos + 1)));

        byte[] buf = buffer;
        return (0xff & buf[position + 1]) | ((0xff & buf[position]) << 8);
    }"
"public Statistics columnMaxLength(String columnName, Integer maxLen) {
		this.columnStats
			.computeIfAbsent(columnName, column -> new HashMap<>())
			.put(MAX_LENGTH, String.valueOf(maxLen));
		return this;
	}"
"public static List<DataMediaPair> findDataMediaPairByMediaId(Pipeline pipeline, Long tid) {
        Assert.notNull(pipeline);
        List<DataMediaPair> pairs = new ArrayList<DataMediaPair>();
        for (DataMediaPair pair : pipeline.getPairs()) {
            if (pair.getSource().getId().equals(tid)) {
                pairs.add(pair);
            } else if (pair.getTarget().getId().equals(tid)) {
                pairs.add(pair);
            }
        }

        return pairs;
    }"
"public final <T> ResourceLeakDetector<T> newResourceLeakDetector(Class<T> resource) {
        return newResourceLeakDetector(resource, ResourceLeakDetector.SAMPLING_INTERVAL);
    }"
"public List<PluginWrapper> getPlugins(Class<? extends Plugin> pluginSuperclass) {
        List<PluginWrapper> result = new ArrayList<>();
        for (PluginWrapper p : getPlugins()) {
            if(pluginSuperclass.isInstance(p.getPlugin()))
                result.add(p);
        }
        return Collections.unmodifiableList(result);
    }"
"public static StructType fromSchemaSequence(Schema schema) {
        StructField[] structFields = new StructField[schema.numColumns() + 2];

        structFields[0] = new StructField(SEQUENCE_UUID_COLUMN, DataTypes.StringType, false, Metadata.empty());
        structFields[1] = new StructField(SEQUENCE_INDEX_COLUMN, DataTypes.IntegerType, false, Metadata.empty());

        for (int i = 0; i < schema.numColumns(); i++) {
            switch (schema.getColumnTypes().get(i)) {
                case Double:
                    structFields[i + 2] =
                                    new StructField(schema.getName(i), DataTypes.DoubleType, false, Metadata.empty());
                    break;
                case Integer:
                    structFields[i + 2] =
                                    new StructField(schema.getName(i), DataTypes.IntegerType, false, Metadata.empty());
                    break;
                case Long:
                    structFields[i + 2] =
                                    new StructField(schema.getName(i), DataTypes.LongType, false, Metadata.empty());
                    break;
                case Float:
                    structFields[i + 2] =
                                    new StructField(schema.getName(i), DataTypes.FloatType, false, Metadata.empty());
                    break;
                default:
                    throw new IllegalStateException(
                                    ""This api should not be used with strings , binary data or ndarrays. This is only for columnar data"");
            }
        }
        return new StructType(structFields);
    }"
"protected byte[] sign(final byte[] value) {
        if (this.signingKey == null) {
            return value;
        }
        if (""RSA"".equalsIgnoreCase(this.signingKey.getAlgorithm())) {
            return EncodingUtils.signJwsRSASha512(this.signingKey, value);
        }
        return EncodingUtils.signJwsHMACSha512(this.signingKey, value);

    }"
"public <T> T fromJson(Reader json, Class<T> classOfT) throws JsonSyntaxException, JsonIOException {
    JsonReader jsonReader = newJsonReader(json);
    Object object = fromJson(jsonReader, classOfT);
    assertFullConsumption(object, jsonReader);
    return Primitives.wrap(classOfT).cast(object);
  }"
"public <T> T getInterface(ScriptWrapper script, Class<T> class1) throws ScriptException, IOException {
	
		ClassLoader previousContextClassLoader = Thread.currentThread().getContextClassLoader();
		Thread.currentThread().setContextClassLoader(ExtensionFactory.getAddOnLoader());
		try {
			T iface = script.getInterface(class1);
			
			if (iface != null) {
				// the script wrapper has overriden the usual scripting mechanism
				return iface;
			}
		} finally {
			Thread.currentThread().setContextClassLoader(previousContextClassLoader);
		}
		
		if (script.isRunableStandalone()) {
			return null;
		}

		Invocable invocable = invokeScript(script);
		if (invocable != null) {
			return invocable.getInterface(class1);
		}
		return null;

	}"
"public Object convert(Class type, Object value) {
        if (value == null) {
            if (useDefault) {
                return (defaultValue);
            } else {
                throw new ConversionException(""No value specified"");
            }
        }

        if (value instanceof java.sql.Date && java.sql.Date.class.equals(type)) {
            return value;
        } else if (value instanceof java.sql.Time && java.sql.Time.class.equals(type)) {
            return value;
        } else if (value instanceof java.sql.Timestamp && java.sql.Timestamp.class.equals(type)) {
            return value;
        } else {
            try {
                if (java.sql.Date.class.equals(type)) {
                    return new java.sql.Date(convertTimestamp2TimeMillis(value.toString()));
                } else if (java.sql.Time.class.equals(type)) {
                    return new java.sql.Time(convertTimestamp2TimeMillis(value.toString()));
                } else if (java.sql.Timestamp.class.equals(type)) {
                    return new java.sql.Timestamp(convertTimestamp2TimeMillis(value.toString()));
                } else {
                    return new Timestamp(convertTimestamp2TimeMillis(value.toString()));
                }
            } catch (Exception e) {
                throw new ConversionException(""Value format invalid: "" + e.getMessage(), e);
            }
        }

    }"
"public static void removeLibrary(String key) {
        if (key.startsWith(DicLibrary.DEFAULT)) {
            DicLibrary.remove(key);
        } else if (key.startsWith(StopLibrary.DEFAULT)) {
            StopLibrary.remove(key);
        } else if (key.startsWith(SynonymsLibrary.DEFAULT)) {
            SynonymsLibrary.remove(key);
        } else if (key.startsWith(AmbiguityLibrary.DEFAULT)) {
            AmbiguityLibrary.remove(key);
        } else if (key.startsWith(CrfLibrary.DEFAULT)) {
            CrfLibrary.remove(key);
        } else {
            throw new LibraryException(key + "" type err must start with dic,stop,ambiguity,synonyms"");
        }
        ENV.remove(key);
    }"
"public final long getUlong56() {
        if (position + 6 >= origin + limit) throw new IllegalArgumentException(""limit excceed: ""
                                                                               + (position - origin + 6));

        byte[] buf = buffer;
        return ((long) (0xff & buf[position++])) | ((long) (0xff & buf[position++]) << 8)
               | ((long) (0xff & buf[position++]) << 16) | ((long) (0xff & buf[position++]) << 24)
               | ((long) (0xff & buf[position++]) << 32) | ((long) (0xff & buf[position++]) << 40)
               | ((long) (0xff & buf[position++]) << 48);
    }"
"public void getFeature(int lat, int lon) {
    info(""*** GetFeature: lat={0} lon={1}"", lat, lon);

    Point request = Point.newBuilder().setLatitude(lat).setLongitude(lon).build();

    Feature feature;
    try {
      feature = blockingStub.getFeature(request);
      if (testHelper != null) {
        testHelper.onMessage(feature);
      }
    } catch (StatusRuntimeException e) {
      warning(""RPC failed: {0}"", e.getStatus());
      if (testHelper != null) {
        testHelper.onRpcError(e);
      }
      return;
    }
    if (RouteGuideUtil.exists(feature)) {
      info(""Found feature called \""{0}\"" at {1}, {2}"",
          feature.getName(),
          RouteGuideUtil.getLatitude(feature.getLocation()),
          RouteGuideUtil.getLongitude(feature.getLocation()));
    } else {
      info(""Found no feature at {0}, {1}"",
          RouteGuideUtil.getLatitude(feature.getLocation()),
          RouteGuideUtil.getLongitude(feature.getLocation()));
    }
  }"
"protected Map<String, List<Object>> getPrincipalAttributesFromReleasePolicy(final Principal p, final Service service, final RegisteredService registeredService) {
        if (registeredService != null && registeredService.getAccessStrategy().isServiceAccessAllowed()) {
            LOGGER.debug(""Located service [{}] in the registry. Attempting to resolve attributes for [{}]"", registeredService, p.getId());
            if (registeredService.getAttributeReleasePolicy() == null) {
                LOGGER.debug(""No attribute release policy is defined for [{}]. Returning default principal attributes"", service.getId());
                return p.getAttributes();
            }
            return registeredService.getAttributeReleasePolicy().getAttributes(p, service, registeredService);
        }
        LOGGER.debug(""Could not locate service [{}] in the registry."", service.getId());
        throw new UnauthorizedServiceException(UnauthorizedServiceException.CODE_UNAUTHZ_SERVICE);
    }"
"public static String getPasswordResetToken(final RequestContext requestContext) {
        val flowScope = requestContext.getFlowScope();
        return flowScope.getString(FLOWSCOPE_PARAMETER_NAME_TOKEN);
    }"
"public SDVariable hardTanh(String name, SDVariable in) {
        validateFloatingPoint(""hard Tanh"", in);
        SDVariable result = f().hardTanh(in);
        return updateVariableNameAndReference(result, name);
    }"
"@VisibleForTesting
  public static <T> Iterable<T> getCandidatesViaServiceLoader(Class<T> klass, ClassLoader cl) {
    Iterable<T> i = ServiceLoader.load(klass, cl);
    // Attempt to load using the context class loader and ServiceLoader.
    // This allows frameworks like http://aries.apache.org/modules/spi-fly.html to plug in.
    if (!i.iterator().hasNext()) {
      i = ServiceLoader.load(klass);
    }
    return i;
  }"
"@CheckForNull
    public static String getWin32ErrorMessage(Throwable e) {
        String msg = e.getMessage();
        if(msg!=null) {
            Matcher m = errorCodeParser.matcher(msg);
            if(m.matches()) {
                try {
                    ResourceBundle rb = ResourceBundle.getBundle(""/hudson/win32errors"");
                    return rb.getString(""error""+m.group(1));
                } catch (Exception ignored) {
                    // silently recover from resource related failures
                }
            }
        }

        if(e.getCause()!=null)
            return getWin32ErrorMessage(e.getCause());
        return null; // no message
    }"
"@PublicEvolving
	public WindowedStream<T, K, W> allowedLateness(Time lateness) {
		final long millis = lateness.toMilliseconds();
		checkArgument(millis >= 0, ""The allowed lateness cannot be negative."");

		this.allowedLateness = millis;
		return this;
	}"
"private void removeContender(EmbeddedLeaderElectionService service) {
		synchronized (lock) {
			// if the service was not even started, simply do nothing
			if (!service.running || shutdown) {
				return;
			}

			try {
				if (!allLeaderContenders.remove(service)) {
					throw new IllegalStateException(""leader election service does not belong to this service"");
				}

				// stop the service
				service.contender = null;
				service.running = false;
				service.isLeader = false;

				// if that was the current leader, unset its status
				if (currentLeaderConfirmed == service) {
					currentLeaderConfirmed = null;
					currentLeaderSessionId = null;
					currentLeaderAddress = null;
				}
				if (currentLeaderProposed == service) {
					currentLeaderProposed = null;
					currentLeaderSessionId = null;
				}

				updateLeader().whenComplete((aVoid, throwable) -> {
					if (throwable != null) {
						fatalError(throwable);
					}
				});
			}
			catch (Throwable t) {
				fatalError(t);
			}
		}
	}"
"public static TransformProcess fromJson(String json) {
        try {
            return JsonMappers.getMapper().readValue(json, TransformProcess.class);
        } catch (IOException e) {
            //TODO proper exception message
            throw new RuntimeException(e);
        }
    }"
"protected synchronized void notifyListenersSpiderProgress(int percentageComplete, int numberCrawled,
			int numberToCrawl) {
		for (SpiderListener l : listeners) {
			l.spiderProgress(percentageComplete, numberCrawled, numberToCrawl);
		}
	}"
"@Nullable
  static Long getTimeoutFromMethodConfig(Map<String, ?> methodConfig) {
    if (!methodConfig.containsKey(METHOD_CONFIG_TIMEOUT_KEY)) {
      return null;
    }
    String rawTimeout = getString(methodConfig, METHOD_CONFIG_TIMEOUT_KEY);
    try {
      return parseDuration(rawTimeout);
    } catch (ParseException e) {
      throw new RuntimeException(e);
    }
  }"
"private static MemoryManager createMemoryManager(
			TaskManagerServicesConfiguration taskManagerServicesConfiguration,
			long freeHeapMemoryWithDefrag,
			long maxJvmHeapMemory) throws Exception {
		// computing the amount of memory to use depends on how much memory is available
		// it strictly needs to happen AFTER the network stack has been initialized

		// check if a value has been configured
		long configuredMemory = taskManagerServicesConfiguration.getConfiguredMemory();

		MemoryType memType = taskManagerServicesConfiguration.getMemoryType();

		final long memorySize;

		boolean preAllocateMemory = taskManagerServicesConfiguration.isPreAllocateMemory();

		if (configuredMemory > 0) {
			if (preAllocateMemory) {
				LOG.info(""Using {} MB for managed memory."" , configuredMemory);
			} else {
				LOG.info(""Limiting managed memory to {} MB, memory will be allocated lazily."" , configuredMemory);
			}
			memorySize = configuredMemory << 20; // megabytes to bytes
		} else {
			// similar to #calculateNetworkBufferMemory(TaskManagerServicesConfiguration tmConfig)
			float memoryFraction = taskManagerServicesConfiguration.getMemoryFraction();

			if (memType == MemoryType.HEAP) {
				// network buffers allocated off-heap -> use memoryFraction of the available heap:
				long relativeMemSize = (long) (freeHeapMemoryWithDefrag * memoryFraction);
				if (preAllocateMemory) {
					LOG.info(""Using {} of the currently free heap space for managed heap memory ({} MB)."" ,
						memoryFraction , relativeMemSize >> 20);
				} else {
					LOG.info(""Limiting managed memory to {} of the currently free heap space ({} MB), "" +
						""memory will be allocated lazily."" , memoryFraction , relativeMemSize >> 20);
				}
				memorySize = relativeMemSize;
			} else if (memType == MemoryType.OFF_HEAP) {
				// The maximum heap memory has been adjusted according to the fraction (see
				// calculateHeapSizeMB(long totalJavaMemorySizeMB, Configuration config)), i.e.
				// maxJvmHeap = jvmTotalNoNet - jvmTotalNoNet * memoryFraction = jvmTotalNoNet * (1 - memoryFraction)
				// directMemorySize = jvmTotalNoNet * memoryFraction
				long directMemorySize = (long) (maxJvmHeapMemory / (1.0 - memoryFraction) * memoryFraction);
				if (preAllocateMemory) {
					LOG.info(""Using {} of the maximum memory size for managed off-heap memory ({} MB)."" ,
						memoryFraction, directMemorySize >> 20);
				} else {
					LOG.info(""Limiting managed memory to {} of the maximum memory size ({} MB),"" +
						"" memory will be allocated lazily."", memoryFraction, directMemorySize >> 20);
				}
				memorySize = directMemorySize;
			} else {
				throw new RuntimeException(""No supported memory type detected."");
			}
		}

		// now start the memory manager
		final MemoryManager memoryManager;
		try {
			memoryManager = new MemoryManager(
				memorySize,
				taskManagerServicesConfiguration.getNumberOfSlots(),
				taskManagerServicesConfiguration.getNetworkConfig().networkBufferSize(),
				memType,
				preAllocateMemory);
		} catch (OutOfMemoryError e) {
			if (memType == MemoryType.HEAP) {
				throw new Exception(""OutOfMemory error ("" + e.getMessage() +
					"") while allocating the TaskManager heap memory ("" + memorySize + "" bytes)."", e);
			} else if (memType == MemoryType.OFF_HEAP) {
				throw new Exception(""OutOfMemory error ("" + e.getMessage() +
					"") while allocating the TaskManager off-heap memory ("" + memorySize +
					"" bytes).Try increasing the maximum direct memory (-XX:MaxDirectMemorySize)"", e);
			} else {
				throw e;
			}
		}
		return memoryManager;
	}"
"@CheckReturnValue
    public static <T> T mock(Class<T> classToMock) {
        return mock(classToMock, withSettings());
    }"
"public void upload(String trainingDir, String apiKey, String algorithmId) {
        JSONObject json = new JSONObject().put(""training_dir"", trainingDir).put(""api_key"", apiKey).put(""algorithm_id"",
                        algorithmId);

        uploadPost(json);
    }"
"public static void assertNoWorkspacesOpen(String msg, boolean allowScopedOut) throws ND4JWorkspaceException {
        if (Nd4j.getWorkspaceManager().anyWorkspaceActiveForCurrentThread()) {

            MemoryWorkspace currWs = Nd4j.getMemoryManager().getCurrentWorkspace();
            if(allowScopedOut && (currWs == null || currWs instanceof DummyWorkspace))
                return; //Open WS but we've scoped out

            List<MemoryWorkspace> l = Nd4j.getWorkspaceManager().getAllWorkspacesForCurrentThread();
            List<String> workspaces = new ArrayList<>(l.size());
            for (MemoryWorkspace ws : l) {
                if(ws.isScopeActive()) {
                    workspaces.add(ws.getId());
                }
            }
            throw new ND4JWorkspaceException(msg + "" - Open/active workspaces: "" + workspaces);
        }
    }"
"public static void destory(Long pipelineId) {
        Map<Class, Object> resources = cache.remove(pipelineId);
        if (resources != null) {
            Collection collection = resources.values();
            for (Object obj : collection) {
                if (obj instanceof ArbitrateLifeCycle) {
                    ArbitrateLifeCycle lifeCycle = (ArbitrateLifeCycle) obj;
                    lifeCycle.destory();// 调用销毁方法
                }
            }
        }
    }"
"public V get(String key)
    {
        int index = exactMatchSearch(key);
        if (index >= 0)
        {
            return v[index];
        }

        return null;
    }"
"public static void delete(String key, String word) {

        Forest dic = get(key);
        if (dic != null) {
            Library.removeWord(dic, word);
        }
    }"
"static void validateIfWritable(TypeInformation<?> typeInfo, Type type) {
		try {
			// try to load the writable type info

			Class<?> writableTypeInfoClass = Class
					.forName(HADOOP_WRITABLE_TYPEINFO_CLASS, false, typeInfo.getClass().getClassLoader());

			if (writableTypeInfoClass.isAssignableFrom(typeInfo.getClass())) {
				// this is actually a writable type info
				// check if the type is a writable
				if (!(type instanceof Class && isHadoopWritable((Class<?>) type))) {
					throw new InvalidTypesException(HADOOP_WRITABLE_CLASS + "" type expected."");
				}

				// check writable type contents
				Class<?> clazz = (Class<?>) type;
				if (typeInfo.getTypeClass() != clazz) {
					throw new InvalidTypesException(""Writable type '""
							+ typeInfo.getTypeClass().getCanonicalName() + ""' expected but was '""
							+ clazz.getCanonicalName() + ""'."");
				}
			}
		}
		catch (ClassNotFoundException e) {
			// class not present at all, so cannot be that type info
			// ignore
		}
	}"
"public static int count(String keyword, String srcText)
    {
        int count = 0;
        int leng = srcText.length();
        int j = 0;
        for (int i = 0; i < leng; i++)
        {
            if (srcText.charAt(i) == keyword.charAt(j))
            {
                j++;
                if (j == keyword.length())
                {
                    count++;
                    j = 0;
                }
            }
            else
            {
                i = i - j;// should rollback when not match
                j = 0;
            }
        }

        return count;
    }"
"private ContextGeneralPanel getContextGeneralPanel(Context context) {
        for (AbstractParamPanel panel : contextPanels) {
            if (panel instanceof ContextGeneralPanel) {
                ContextGeneralPanel contextGeneralPanel = (ContextGeneralPanel) panel;
                if (contextGeneralPanel.getContextIndex() == context.getIndex()) {
                    return contextGeneralPanel;
                }
            }
        }
        return null;
    }"
"public static <T> List<Optional<LocalProperty<T>>> match(List<LocalProperty<T>> actuals, List<LocalProperty<T>> desired)
    {
        // After normalizing actuals, each symbol should only appear once
        PeekingIterator<LocalProperty<T>> actualIterator = peekingIterator(normalizeAndPrune(actuals).iterator());

        Set<T> constants = new HashSet<>();
        boolean consumeMoreActuals = true;
        List<Optional<LocalProperty<T>>> result = new ArrayList<>(desired.size());
        for (LocalProperty<T> desiredProperty : desired) {
            while (consumeMoreActuals && actualIterator.hasNext() && desiredProperty.isSimplifiedBy(actualIterator.peek())) {
                constants.addAll(actualIterator.next().getColumns());
            }
            Optional<LocalProperty<T>> simplifiedDesired = desiredProperty.withConstants(constants);
            consumeMoreActuals &= !simplifiedDesired.isPresent(); // Only continue processing actuals if all previous desired properties were fully satisfied
            result.add(simplifiedDesired);
        }
        return result;
    }"
"public void doSuggestOpenSearch(StaplerRequest req, StaplerResponse rsp, @QueryParameter String q) throws IOException, ServletException {
        rsp.setContentType(Flavor.JSON.contentType);
        DataWriter w = Flavor.JSON.createDataWriter(null, rsp);
        w.startArray();
        w.value(q);

        w.startArray();
        for (SuggestedItem item : getSuggestions(req, q))
            w.value(item.getPath());
        w.endArray();
        w.endArray();
    }"
"public void syncFromStorage()
  {
    giant.lock();

    try {
      // Load stuff from taskStorage first. If this fails, we don't want to lose all our locks.
      final Set<String> storedActiveTasks = new HashSet<>();
      final List<Pair<Task, TaskLock>> storedLocks = new ArrayList<>();
      for (final Task task : taskStorage.getActiveTasks()) {
        storedActiveTasks.add(task.getId());
        for (final TaskLock taskLock : taskStorage.getLocks(task.getId())) {
          storedLocks.add(Pair.of(task, taskLock));
        }
      }
      // Sort locks by version, so we add them back in the order they were acquired.
      final Ordering<Pair<Task, TaskLock>> byVersionOrdering = new Ordering<Pair<Task, TaskLock>>()
      {
        @Override
        public int compare(Pair<Task, TaskLock> left, Pair<Task, TaskLock> right)
        {
          // The second compare shouldn't be necessary, but, whatever.
          return ComparisonChain.start()
                                .compare(left.rhs.getVersion(), right.rhs.getVersion())
                                .compare(left.lhs.getId(), right.lhs.getId())
                                .result();
        }
      };
      running.clear();
      activeTasks.clear();
      activeTasks.addAll(storedActiveTasks);
      // Bookkeeping for a log message at the end
      int taskLockCount = 0;
      for (final Pair<Task, TaskLock> taskAndLock : byVersionOrdering.sortedCopy(storedLocks)) {
        final Task task = taskAndLock.lhs;
        final TaskLock savedTaskLock = taskAndLock.rhs;
        if (savedTaskLock.getInterval().toDurationMillis() <= 0) {
          // ""Impossible"", but you never know what crazy stuff can be restored from storage.
          log.warn(""WTF?! Got lock[%s] with empty interval for task: %s"", savedTaskLock, task.getId());
          continue;
        }

        // Create a new taskLock if it doesn't have a proper priority,
        // so that every taskLock in memory has the priority.
        final TaskLock savedTaskLockWithPriority = savedTaskLock.getPriority() == null
                                      ? TaskLock.withPriority(savedTaskLock, task.getPriority())
                                      : savedTaskLock;

        final TaskLockPosse taskLockPosse = createOrFindLockPosse(task, savedTaskLockWithPriority);
        if (taskLockPosse != null) {
          taskLockPosse.addTask(task);

          final TaskLock taskLock = taskLockPosse.getTaskLock();

          if (savedTaskLockWithPriority.getVersion().equals(taskLock.getVersion())) {
            taskLockCount++;
            log.info(
                ""Reacquired lock[%s] for task: %s"",
                taskLock,
                task.getId()
            );
          } else {
            taskLockCount++;
            log.info(
                ""Could not reacquire lock on interval[%s] version[%s] (got version[%s] instead) for task: %s"",
                savedTaskLockWithPriority.getInterval(),
                savedTaskLockWithPriority.getVersion(),
                taskLock.getVersion(),
                task.getId()
            );
          }
        } else {
          throw new ISE(
              ""Could not reacquire lock on interval[%s] version[%s] for task: %s"",
              savedTaskLockWithPriority.getInterval(),
              savedTaskLockWithPriority.getVersion(),
              task.getId()
          );
        }
      }
      log.info(
          ""Synced %,d locks for %,d activeTasks from storage (%,d locks ignored)."",
          taskLockCount,
          activeTasks.size(),
          storedLocks.size() - taskLockCount
      );
    }
    finally {
      giant.unlock();
    }
  }"
"public Mapper createMapperToSubflowState(final List<DefaultMapping> mappings) {
        val inputMapper = new DefaultMapper();
        mappings.forEach(inputMapper::addMapping);
        return inputMapper;
    }"
"public String getUsername() {
        final String username = basicJdbcConfiguration.getConfiguredUsername();
        if (calculatedUsername == null || StringUtils.hasText(username)) {
            calculatedUsername = username;
            if (!StringUtils.hasText(calculatedUsername) && JdbcDatabaseManager.isEmbedded(basicJdbcConfiguration.getDriverClassName())) {
                calculatedUsername = ""sa"";
            }
        }

        return calculatedUsername;
    }"
"private GridItemLauncher buildLauncher(String[] args) {
    if (Arrays.asList(args).contains(""-htmlSuite"")) {
      out.println(Joiner.on(""\n"").join(
          ""Download the Selenium HTML Runner from http://www.seleniumhq.org/download/ and"",
          ""use that to run your HTML suite.""));
      return null;
    }

    String role = ""standalone"";

    for (int i = 0; i < args.length; i++) {
      if (args[i].startsWith(""-role="")) {
        role = args[i].substring(""-role="".length());
      } else if (args[i].equals(""-role"")) {
        i++;  // Increment, because we're going to need this.
        if (i < args.length) {
          role = args[i];
        } else {
          role = null;  // Will cause us to print the usage information.
        }
      }
    }

    GridRole gridRole = GridRole.get(role);
    if (gridRole == null || LAUNCHERS.get(gridRole) == null) {
      printInfoAboutRoles(role);
      return null;
    }

    return LAUNCHERS.get(gridRole);
  }"
"public static void next(HttpServerExchange httpServerExchange, String execName, Boolean returnToOrigFlow)
			throws Exception {
		String currentChainId = httpServerExchange.getAttachment(CHAIN_ID);
		Integer currentNextIndex = httpServerExchange.getAttachment(CHAIN_SEQ);

		httpServerExchange.putAttachment(CHAIN_ID, execName);
		httpServerExchange.putAttachment(CHAIN_SEQ, 0);

		next(httpServerExchange);

		// return to current flow.
		if (returnToOrigFlow) {
			httpServerExchange.putAttachment(CHAIN_ID, currentChainId);
			httpServerExchange.putAttachment(CHAIN_SEQ, currentNextIndex);
			next(httpServerExchange);
		}
	}"
"@Override
    public List<MetricFamilySamples> collect() {
        final GaugeMetricFamily stats = new GaugeMetricFamily(
                name,
                ""Bulkhead Stats"",
                asList(""name"", ""param""));

        for (Bulkhead bulkhead : bulkheadsSupplier.get()) {

            final Bulkhead.Metrics metrics = bulkhead.getMetrics();

            stats.addMetric(
                    asList(bulkhead.getName(), ""available_concurrent_calls""),
                    metrics.getAvailableConcurrentCalls());
        }

        return singletonList(stats);
    }"
"@Override
    public Class<?> getProxyClass() {
        if (proxyClass != null) {
            return proxyClass;
        }
        if (generic) {
            return GenericService.class;
        }
        try {
            if (StringUtils.isNotBlank(interfaceId)) {
                this.proxyClass = ClassUtils.forName(interfaceId);
                if (!proxyClass.isInterface()) {
                    throw ExceptionUtils.buildRuntime(""consumer.interface"",
                        interfaceId, ""interfaceId must set interface class, not implement class"");
                }
            } else {
                throw ExceptionUtils.buildRuntime(""consumer.interface"",
                    ""null"", ""interfaceId must be not null"");
            }
        } catch (RuntimeException t) {
            throw new IllegalStateException(t.getMessage(), t);
        }
        return proxyClass;
    }"
"public static List<String> toLines(Class<?> contextClass, String resourceName) throws IOException {
		return Resources.readLines(Resources.getResource(contextClass, resourceName), Charsets.UTF_8);
	}"
"protected Connection createConnection(Socket socket, InputStream inputStream,
			OutputStream outputStream) throws IOException {
		return new Connection(socket, inputStream, outputStream);
	}"
"@Override
    public void subscribe(ClientIdentity clientIdentity) throws CanalServerException {
        checkStart(clientIdentity.getDestination());

        CanalInstance canalInstance = canalInstances.get(clientIdentity.getDestination());
        if (!canalInstance.getMetaManager().isStart()) {
            canalInstance.getMetaManager().start();
        }

        canalInstance.getMetaManager().subscribe(clientIdentity); // 执行一下meta订阅

        Position position = canalInstance.getMetaManager().getCursor(clientIdentity);
        if (position == null) {
            position = canalInstance.getEventStore().getFirstPosition();// 获取一下store中的第一条
            if (position != null) {
                canalInstance.getMetaManager().updateCursor(clientIdentity, position); // 更新一下cursor
            }
            logger.info(""subscribe successfully, {} with first position:{} "", clientIdentity, position);
        } else {
            logger.info(""subscribe successfully, use last cursor position:{} "", clientIdentity, position);
        }

        // 通知下订阅关系变化
        canalInstance.subscribeChange(clientIdentity);
    }"
"public void write_pid(OtpErlangPid pid) {
	write1(pid.tag());
	write_atom(pid.node());
	write4BE(pid.id());
	write4BE(pid.serial());
	switch (pid.tag()) {
	case OtpExternal.pidTag:
	    write1(pid.creation());
	    break;
	case OtpExternal.newPidTag:
	    write4BE(pid.creation());
	    break;
	default:
	    throw new AssertionError(""Invalid pid tag "" + pid.tag());
	}
    }"
"@SuppressWarnings({""OptionalIsPresent"", ""unchecked""})
    protected void registerDefaultConverters() {

        // wrapper to primitive array converters
        addConverter(Double[].class, double[].class, (object, targetType, context) -> {
            double[] doubles = new double[object.length];
            for (int i = 0; i < object.length; i++) {
                Double aDouble = object[i];
                if (aDouble != null) {
                    doubles[i] = aDouble;
                }
            }
            return Optional.of(doubles);
        });
        addConverter(Integer[].class, int[].class, (object, targetType, context) -> {
            int[] integers = new int[object.length];
            for (int i = 0; i < object.length; i++) {
                Integer o = object[i];
                if (o != null) {
                    integers[i] = o;
                }
            }
            return Optional.of(integers);
        });

        // Object -> List
        addConverter(Object.class, List.class, (object, targetType, context) -> {
            Optional<Argument<?>> firstTypeVariable = context.getFirstTypeVariable();
            Argument<?> argument = firstTypeVariable.orElse(Argument.OBJECT_ARGUMENT);
            Optional converted = DefaultConversionService.this.convert(object, context.with(argument));
            if (converted.isPresent()) {
                return Optional.of(Collections.singletonList(converted.get()));
            }
            return Optional.empty();
        });

        // String -> Class
        addConverter(CharSequence.class, Class.class, (object, targetType, context) -> {
            ClassLoader classLoader = targetType.getClassLoader();
            if (classLoader == null) {
                classLoader = DefaultConversionService.class.getClassLoader();
            }
            return ClassUtils.forName(object.toString(), classLoader);
        });

        // AnnotationClassValue -> Class
        addConverter(AnnotationClassValue.class, Class.class, (object, targetType, context) -> object.getType());
        addConverter(AnnotationClassValue.class, Object.class, (object, targetType, context) -> {
            if (targetType.equals(Class.class)) {
                return object.getType();
            } else {
                if (CharSequence.class.isAssignableFrom(targetType)) {
                    return Optional.of(object.getName());
                } else {
                    Optional i = object.getInstance();
                    if (i.isPresent() && targetType.isInstance(i.get())) {
                        return i;
                    }
                    return Optional.empty();
                }
            }
        });
        addConverter(AnnotationClassValue[].class, Class.class, (object, targetType, context) -> {
            if (object.length > 0) {
                final AnnotationClassValue o = object[0];
                if (o != null) {
                    return o.getType();
                }
            }
            return Optional.empty();
        });
        addConverter(AnnotationClassValue[].class, Class[].class, (object, targetType, context) -> {
            List<Class> classes = new ArrayList<>(object.length);
            for (AnnotationClassValue<?> annotationClassValue : object) {
                if (annotationClassValue != null) {
                    final Optional<? extends Class<?>> type = annotationClassValue.getType();
                    if (type.isPresent()) {
                        classes.add(type.get());
                    }
                }
            }
            return Optional.of(classes.toArray(new Class[0]));
        });

        // URI -> URL
        addConverter(URI.class, URL.class, uri -> {
            try {
                return uri.toURL();
            } catch (MalformedURLException e) {
                return null;
            }
        });

        // InputStream -> String
        addConverter(InputStream.class, String.class, (object, targetType, context) -> {
            BufferedReader reader = new BufferedReader(new InputStreamReader(object));
            try {
                return Optional.of(IOUtils.readText(reader));
            } catch (IOException e) {
                context.reject(e);
                return Optional.empty();
            }
        });

        // String -> byte[]
        addConverter(CharSequence.class, byte[].class, (object, targetType, context) -> Optional.of(object.toString().getBytes(context.getCharset())));
        addConverter(Integer.class, byte[].class, (object, targetType, context) -> Optional.of(ByteBuffer.allocate(Integer.BYTES).putInt(object).array()));
        addConverter(Character.class, byte[].class, (object, targetType, context) -> Optional.of(ByteBuffer.allocate(Integer.BYTES).putChar(object).array()));
        addConverter(Long.class, byte[].class, (object, targetType, context) -> Optional.of(ByteBuffer.allocate(Long.BYTES).putLong(object).array()));
        addConverter(Short.class, byte[].class, (object, targetType, context) -> Optional.of(ByteBuffer.allocate(Short.BYTES).putShort(object).array()));
        addConverter(Double.class, byte[].class, (object, targetType, context) -> Optional.of(ByteBuffer.allocate(Double.BYTES).putDouble(object).array()));
        addConverter(Float.class, byte[].class, (object, targetType, context) -> Optional.of(ByteBuffer.allocate(Float.BYTES).putFloat(object).array()));

        // InputStream -> Number
        addConverter(InputStream.class, Number.class, (object, targetType, context) -> {
            Optional<String> convert = DefaultConversionService.this.convert(object, String.class, context);
            if (convert.isPresent()) {
                return convert.flatMap(val -> DefaultConversionService.this.convert(val, targetType, context));
            }
            return Optional.empty();
        });

        // Reader -> String
        addConverter(Reader.class, String.class, (object, targetType, context) -> {
            BufferedReader reader = object instanceof BufferedReader ? (BufferedReader) object : new BufferedReader(object);
            try {
                return Optional.of(IOUtils.readText(reader));
            } catch (IOException e) {
                context.reject(e);
                return Optional.empty();
            }
        });

        // String -> File
        addConverter(CharSequence.class, File.class, (object, targetType, context) -> Optional.of(new File(object.toString())));

        // String[] -> Enum
        addConverter(String[].class, Enum.class, (object, targetType, context) -> {
            if (object == null || object.length == 0) {
                return Optional.empty();
            }

            StringJoiner joiner = new StringJoiner("""");
            for (String string : object) {
                joiner.add(string);
            }
            final String val = joiner.toString();
            return convert(val, targetType, context);
        });

        addConverter(String[].class, CharSequence.class, (object, targetType, context) -> {
            if (object == null || object.length == 0) {
                return Optional.empty();
            }

            StringJoiner joiner = new StringJoiner("""");
            for (String string : object) {
                joiner.add(string);
            }
            return convert(joiner.toString(), targetType, context);
        });

        // CharSequence -> Long for bytes
        addConverter(CharSequence.class, Number.class, new ReadableBytesTypeConverter());

        // CharSequence -> Date
        addConverter(
            CharSequence.class,
            Date.class,
            (object, targetType, context) -> {
                try {
                    SimpleDateFormat format = resolveFormat(context);
                    return Optional.of(format.parse(object.toString()));
                } catch (ParseException e) {
                    context.reject(object, e);
                    return Optional.empty();
                }
            }
        );

        // Date -> CharSequence
        addConverter(
                Date.class,
                CharSequence.class,
                (object, targetType, context) -> {
                    SimpleDateFormat format = resolveFormat(context);
                    return Optional.of(format.format(object));
                }
        );

        // String -> Path
        addConverter(
                CharSequence.class,
                Path.class, (object, targetType, context) -> {
                    if (StringUtils.isEmpty(object)) {
                        return Optional.empty();
                    }
                    try {
                        return Optional.ofNullable(Paths.get(object.toString()));
                    } catch (Exception e) {
                        context.reject(""Invalid path ["" + object + "" ]: "" + e.getMessage(), e);
                        return Optional.empty();
                    }
                });

        // String -> Integer
        addConverter(CharSequence.class, Integer.class, (CharSequence object, Class<Integer> targetType, ConversionContext context) -> {
            try {
                Integer converted = Integer.valueOf(object.toString());
                return Optional.of(converted);
            } catch (NumberFormatException e) {
                context.reject(object, e);
                return Optional.empty();
            }
        });

        // String -> BigInteger
        addConverter(CharSequence.class, BigInteger.class, (CharSequence object, Class<BigInteger> targetType, ConversionContext context) -> {
            try {
                BigInteger converted = new BigInteger(object.toString());
                return Optional.of(converted);
            } catch (NumberFormatException e) {
                context.reject(object, e);
                return Optional.empty();
            }
        });

        // String -> Float
        addConverter(CharSequence.class, Float.class, (CharSequence object, Class<Float> targetType, ConversionContext context) -> {
            try {
                Float converted = Float.valueOf(object.toString());
                return Optional.of(converted);
            } catch (NumberFormatException e) {
                context.reject(object, e);
                return Optional.empty();
            }
        });

        // String -> Double
        addConverter(CharSequence.class, Double.class, (CharSequence object, Class<Double> targetType, ConversionContext context) -> {
            try {
                Double converted = Double.valueOf(object.toString());
                return Optional.of(converted);
            } catch (NumberFormatException e) {
                context.reject(object, e);
                return Optional.empty();
            }
        });

        // String -> Long
        addConverter(CharSequence.class, Long.class, (CharSequence object, Class<Long> targetType, ConversionContext context) -> {
            try {
                Long converted = Long.valueOf(object.toString());
                return Optional.of(converted);
            } catch (NumberFormatException e) {
                context.reject(object, e);
                return Optional.empty();
            }
        });

        // String -> Short
        addConverter(CharSequence.class, Short.class, (CharSequence object, Class<Short> targetType, ConversionContext context) -> {
            try {
                Short converted = Short.valueOf(object.toString());
                return Optional.of(converted);
            } catch (NumberFormatException e) {
                context.reject(object, e);
                return Optional.empty();
            }
        });

        // String -> Byte
        addConverter(CharSequence.class, Byte.class, (CharSequence object, Class<Byte> targetType, ConversionContext context) -> {
            try {
                Byte converted = Byte.valueOf(object.toString());
                return Optional.of(converted);
            } catch (NumberFormatException e) {
                context.reject(object, e);
                return Optional.empty();
            }
        });

        // String -> BigDecimal
        addConverter(CharSequence.class, BigDecimal.class, (CharSequence object, Class<BigDecimal> targetType, ConversionContext context) -> {
            try {
                BigDecimal converted = new BigDecimal(object.toString());
                return Optional.of(converted);
            } catch (NumberFormatException e) {
                context.reject(object, e);
                return Optional.empty();
            }
        });

        // String -> Boolean
        addConverter(CharSequence.class, Boolean.class, (CharSequence object, Class<Boolean> targetType, ConversionContext context) -> {
            String booleanString = object.toString().toLowerCase(Locale.ENGLISH);
            switch (booleanString) {
                case ""yes"":
                case ""y"":
                case ""on"":
                case ""true"":
                    return Optional.of(Boolean.TRUE);
                default:
                    return Optional.of(Boolean.FALSE);
            }
        });

        // String -> URL
        addConverter(CharSequence.class, URL.class, (CharSequence object, Class<URL> targetType, ConversionContext context) -> {
            try {
                String spec = object.toString();
                if (!spec.contains(""://"")) {
                    spec = ""http://"" + spec;
                }
                return Optional.of(new URL(spec));
            } catch (MalformedURLException e) {
                context.reject(object, e);
                return Optional.empty();
            }
        });

        // String -> URI
        addConverter(CharSequence.class, URI.class, (CharSequence object, Class<URI> targetType, ConversionContext context) -> {
            try {
                return Optional.of(new URI(object.toString()));
            } catch (URISyntaxException e) {
                context.reject(object, e);
                return Optional.empty();
            }
        });

        // String -> Locale
        addConverter(CharSequence.class, Locale.class, (CharSequence object, Class<Locale> targetType, ConversionContext context) -> {
            try {
                return Optional.of(Locale.forLanguageTag(object.toString().replace('_', '-')));
            } catch (IllegalArgumentException e) {
                context.reject(object, e);
                return Optional.empty();
            }
        });

        // String -> UUID
        addConverter(CharSequence.class, UUID.class, (CharSequence object, Class<UUID> targetType, ConversionContext context) -> {
            try {
                return Optional.of(UUID.fromString(object.toString()));
            } catch (IllegalArgumentException e) {
                context.reject(object, e);
                return Optional.empty();
            }
        });

        // String -> Currency
        addConverter(CharSequence.class, Currency.class, (CharSequence object, Class<Currency> targetType, ConversionContext context) -> {
            try {
                return Optional.of(Currency.getInstance(object.toString()));
            } catch (IllegalArgumentException e) {
                context.reject(object, e);
                return Optional.empty();
            }
        });

        // String -> TimeZone
        addConverter(CharSequence.class, TimeZone.class, (CharSequence object, Class<TimeZone> targetType, ConversionContext context) -> Optional.of(TimeZone.getTimeZone(object.toString())));

        // String -> Charset
        addConverter(CharSequence.class, Charset.class, (CharSequence object, Class<Charset> targetType, ConversionContext context) -> {
            try {
                return Optional.of(Charset.forName(object.toString()));
            } catch (IllegalCharsetNameException | UnsupportedCharsetException e) {
                context.reject(object, e);
                return Optional.empty();
            }
        });

        // String -> Character
        addConverter(CharSequence.class, Character.class, (CharSequence object, Class<Character> targetType, ConversionContext context) -> {
            String str = object.toString();
            if (str.length() == 1) {
                return Optional.of(str.charAt(0));
            } else {
                return Optional.empty();
            }
        });

        // String -> Array
        addConverter(CharSequence.class, Object[].class, (CharSequence object, Class<Object[]> targetType, ConversionContext context) -> {
            if (object instanceof AnnotationClassValue && targetType.equals(AnnotationClassValue[].class)) {
                AnnotationClassValue[] array = new AnnotationClassValue[1];
                array[0] = (AnnotationClassValue) object;
                return Optional.of(array);
            }

            String str = object.toString();
            String[] strings = str.split("","");
            Class<?> componentType = ReflectionUtils.getWrapperType(targetType.getComponentType());
            Object newArray = Array.newInstance(componentType, strings.length);
            for (int i = 0; i < strings.length; i++) {
                String string = strings[i];
                Optional<?> converted = convert(string, componentType);
                if (converted.isPresent()) {
                    Array.set(newArray, i, converted.get());
                }
            }
            return Optional.of((Object[]) newArray);
        });

        // String -> Int Array
        addConverter(CharSequence.class, int[].class, (CharSequence object, Class<int[]> targetType, ConversionContext context) -> {
            String str = object.toString();
            String[] strings = str.split("","");
            Object newArray = Array.newInstance(int.class, strings.length);
            for (int i = 0; i < strings.length; i++) {
                String string = strings[i];
                Optional<?> converted = convert(string, int.class);
                if (converted.isPresent()) {
                    Array.set(newArray, i, converted.get());
                }
            }
            return Optional.of((int[]) newArray);
        });

        // Object[] -> String[]
        addConverter(Object[].class, String[].class, (Object[] object, Class<String[]> targetType, ConversionContext context) -> {
            String[] strings = new String[object.length];
            for (int i = 0; i < object.length; i++) {
                Object o = object[i];
                if (o != null) {
                    strings[i] = o.toString();
                }
            }
            return Optional.of(strings);
        });

        // String -> Enum
        addConverter(CharSequence.class, Enum.class, (CharSequence object, Class<Enum> targetType, ConversionContext context) -> {
            String stringValue = object.toString();
            try {
                Enum val = Enum.valueOf(targetType, stringValue);
                return Optional.of(val);
            } catch (IllegalArgumentException e) {
                try {
                    Enum val = Enum.valueOf(targetType, NameUtils.environmentName(stringValue));
                    return Optional.of(val);
                } catch (Exception e1) {
                    context.reject(object, e);
                    return Optional.empty();
                }
            }
        });

        // Object -> String
        addConverter(Object.class, String.class, (Object object, Class<String> targetType, ConversionContext context) -> Optional.of(object.toString()));

        // Number -> Number
        addConverter(Number.class, Number.class, (Number object, Class<Number> targetType, ConversionContext context) -> {
            Class targetNumberType = ReflectionUtils.getWrapperType(targetType);
            if (targetNumberType.isInstance(object)) {
                return Optional.of(object);
            }
            if (targetNumberType == Integer.class) {
                return Optional.of(object.intValue());
            }
            if (targetNumberType == Long.class) {
                return Optional.of(object.longValue());
            }
            if (targetNumberType == Short.class) {
                return Optional.of(object.shortValue());
            }
            if (targetNumberType == Byte.class) {
                return Optional.of(object.byteValue());
            }
            if (targetNumberType == Float.class) {
                return Optional.of(object.floatValue());
            }
            if (targetNumberType == Double.class) {
                return Optional.of(object.doubleValue());
            } 
            if (targetNumberType == BigInteger.class) {
                if (object instanceof BigDecimal) {
                    return Optional.of(((BigDecimal) object).toBigInteger());
                }
                return Optional.of(BigInteger.valueOf(object.longValue()));
            }
            if (targetNumberType == BigDecimal.class) {
                return Optional.of(new BigDecimal(object.toString()));
            }
            return Optional.empty();
        });

        // String -> List/Iterable
        addConverter(CharSequence.class, Iterable.class, (CharSequence object, Class<Iterable> targetType, ConversionContext context) -> {
            Optional<Argument<?>> typeVariable = context.getFirstTypeVariable();
            Argument<?> componentType = typeVariable.orElse(Argument.OBJECT_ARGUMENT);
            ConversionContext newContext = context.with(componentType);

            Class<?> targetComponentType = ReflectionUtils.getWrapperType(componentType.getType());
            String[] strings = object.toString().split("","");
            List list = new ArrayList();
            for (String string : strings) {
                Optional converted = convert(string, targetComponentType, newContext);
                if (converted.isPresent()) {
                    list.add(converted.get());
                }
            }
            return CollectionUtils.convertCollection((Class) targetType, list);
        });

        // Optional handling
        addConverter(Object.class, Optional.class, (object, targetType, context) -> {
            Optional<Argument<?>> typeVariable = context.getFirstTypeVariable();
            Argument<?> componentType = typeVariable.orElse(Argument.OBJECT_ARGUMENT);
            Class<?> targetComponentType = ReflectionUtils.getWrapperType(componentType.getType());

            ConversionContext newContext = context.with(componentType);
            Optional converted = convert(object, targetComponentType, newContext);
            if (converted.isPresent()) {
                return Optional.of(converted);
            }
            return Optional.of(Optional.empty());
        });

        addConverter(Object.class, OptionalInt.class, (object, targetType, context) -> {
            Optional<Integer> converted = convert(object, Integer.class, context);
            return converted.map(integer -> Optional.of(OptionalInt.of(integer))).orElseGet(() -> Optional.of(OptionalInt.empty()));
        });

        addConverter(Object.class, OptionalLong.class, (object, targetType, context) -> {
            Optional<Long> converted = convert(object, Long.class, context);
            return converted.map(longValue -> Optional.of(OptionalLong.of(longValue))).orElseGet(() -> Optional.of(OptionalLong.empty()));
        });

        // Iterable -> String
        addConverter(Iterable.class, String.class, (object, targetType, context) -> Optional.of(CollectionUtils.toString(object)));

        // Iterable -> Iterable (inner type conversion)
        addConverter(Iterable.class, Iterable.class, (object, targetType, context) -> {
            if (ConvertibleValues.class.isAssignableFrom(targetType)) {
                if (object instanceof ConvertibleValues) {
                    return Optional.of(object);
                }
                return Optional.empty();
            }
            Optional<Argument<?>> typeVariable = context.getFirstTypeVariable();
            Argument<?> componentType = typeVariable.orElse(Argument.OBJECT_ARGUMENT);
            Class<?> targetComponentType = ReflectionUtils.getWrapperType(componentType.getType());

            ConversionContext newContext = context.with(componentType);
            if (targetType.isInstance(object)) {
                if (targetComponentType == Object.class) {
                    return Optional.of(object);
                }
                List list = new ArrayList();
                for (Object o : object) {
                    Optional converted = convert(o, targetComponentType, newContext);
                    if (converted.isPresent()) {
                        list.add(converted.get());
                    }
                }
                return CollectionUtils.convertCollection((Class) targetType, list);
            }
            targetComponentType = Object.class;
            List list = new ArrayList();
            for (Object o : object) {
                Optional<?> converted = convert(o, targetComponentType, newContext);
                if (converted.isPresent()) {
                    list.add(converted.get());
                }
            }
            return CollectionUtils.convertCollection((Class) targetType, list);
        });

        // Object[] -> String
        addConverter(Object[].class, String.class, (object, targetType, context) -> Optional.of(ArrayUtils.toString(object)));

        // Object[] -> Object[] (inner type conversion)
        addConverter(Object[].class, Object[].class, (object, targetType, context) -> {
            Class<?> targetComponentType = targetType.getComponentType();
            List results = new ArrayList();
            for (Object o : object) {
                Optional<?> converted = convert(o, targetComponentType, context);
                if (converted.isPresent()) {
                    results.add(converted.get());
                }
            }
            return Optional.of(results.toArray((Object[]) Array.newInstance(targetComponentType, results.size())));
        });

        // Iterable -> Object[]
        addConverter(Iterable.class, Object[].class, (object, targetType, context) -> {
            Class<?> targetComponentType = targetType.getComponentType();
            List results = new ArrayList();
            for (Object o : object) {
                Optional<?> converted = convert(o, targetComponentType, context);
                if (converted.isPresent()) {
                    results.add(converted.get());
                }
            }
            return Optional.of(results.toArray((Object[]) Array.newInstance(targetComponentType, results.size())));
        });

        addConverter(Object[].class, Iterable.class, (object, targetType, context) ->
            convert(Arrays.asList(object), targetType, context)
        );

        addConverter(Object.class, Object[].class, (object, targetType, context) -> {
            Class<?> targetComponentType = targetType.getComponentType();
            Optional<?> converted = convert(object, targetComponentType);
            if (converted.isPresent()) {

                Object[] result = (Object[]) Array.newInstance(targetComponentType, 1);
                result[0] = converted.get();
                return Optional.of(result);
            }

            return Optional.empty();
        });

        // Map -> Map (inner type conversion)
        addConverter(Map.class, Map.class, (object, targetType, context) -> {
            Argument<?> keyArgument = context.getTypeVariable(""K"").orElse(Argument.of(String.class, ""K""));
            boolean isProperties = targetType.equals(Properties.class);
            Argument<?> valArgument = context.getTypeVariable(""V"").orElseGet(() -> {
                if (isProperties) {
                    return Argument.of(String.class, ""V"");
                }
                return Argument.of(Object.class, ""V"");
            });
            Class keyType = keyArgument.getType();
            Class valueType = valArgument.getType();
            ConversionContext keyContext = context.with(keyArgument);
            ConversionContext valContext = context.with(valArgument);

            Map newMap = isProperties ? new Properties() : new LinkedHashMap();

            for (Object o : object.entrySet()) {
                Map.Entry entry = (Map.Entry) o;
                Object key = entry.getKey();
                Object value = entry.getValue();
                if (!keyType.isInstance(key)) {
                    Optional convertedKey = convert(key, keyType, keyContext);
                    if (convertedKey.isPresent()) {
                        key = convertedKey.get();
                    } else {
                        continue;
                    }
                }
                if (!valueType.isInstance(value) || Map.class.isAssignableFrom(valueType)) {
                    Optional converted = convert(value, valueType, valContext);
                    if (converted.isPresent()) {
                        value = converted.get();
                    } else {
                        continue;
                    }
                }
                newMap.put(key, value);
            }
            return Optional.of(newMap);
        });

        addConverter(Map.class, ConvertibleValues.class, (object, targetType, context) -> Optional.of(new ConvertibleValuesMap<Object>(object)));

        // Micronaut ByteBuffer -> byte for streamed results from HTTP clients
        addConverter(io.micronaut.core.io.buffer.ByteBuffer.class, byte[].class, (object, targetType, context) -> {
            byte[] result = object.toByteArray();
            ((ReferenceCounted) object).release();
            return Optional.of(result);
        });

    }"
"public static BasicCredential buildCredentialForMetadataSignatureValidation(final Resource resource) throws Exception {
        try {
            val x509FactoryBean = new BasicX509CredentialFactoryBean();
            x509FactoryBean.setCertificateResource(resource);
            x509FactoryBean.afterPropertiesSet();
            return x509FactoryBean.getObject();
        } catch (final Exception e) {
            LOGGER.trace(e.getMessage(), e);

            LOGGER.debug(""Credential cannot be extracted from [{}] via X.509. Treating it as a public key to locate credential..."", resource);
            val credentialFactoryBean = new BasicResourceCredentialFactoryBean();
            credentialFactoryBean.setPublicKeyInfo(resource);
            credentialFactoryBean.afterPropertiesSet();
            return credentialFactoryBean.getObject();
        }
    }"
"@Override
    public String getSchema(FileSystem fs, Path path) {
        String schema = null;
        try {
            Reader orcReader = OrcFile.createReader(fs, path);
            schema = orcReader.getObjectInspector().getTypeName();
        } catch (IOException e) {
            logger
                .warn(""Cannot get schema for file: "" + path.toUri().getPath());
            return null;
        }

        return schema;
    }"
"public static Condition in(String name, Object... values) {
        List<Condition> conditions = new ArrayList<Condition>();
        for (Object value : values) {
            conditions.add(eq(name, value));
        }
        return or(conditions.toArray(new Condition[conditions.size()]));
    }"
"public static FileUtils.FileCopyResult gzip(final File inFile, final File outFile, Predicate<Throwable> shouldRetry)
  {
    gzip(Files.asByteSource(inFile), Files.asByteSink(outFile), shouldRetry);
    return new FileUtils.FileCopyResult(outFile);
  }"
"private MetaHolder createCopy(MetaHolder source, ExecutionType executionType) {
        return MetaHolder.builder()
                .obj(source.getObj())
                .method(source.getMethod())
                .ajcMethod(source.getAjcMethod())
                .fallbackExecutionType(source.getFallbackExecutionType())
                .extendedFallback(source.isExtendedFallback())
                .extendedParentFallback(source.isExtendedParentFallback())
                .executionType(executionType)
                .args(source.getArgs())
                .observable(source.isObservable())
                .observableExecutionMode(source.getObservableExecutionMode())
                .defaultCollapserKey(source.getDefaultCollapserKey())
                .defaultCommandKey(source.getDefaultCommandKey())
                .defaultGroupKey(source.getDefaultGroupKey())
                .defaultThreadPoolKey(source.getDefaultThreadPoolKey())
                .defaultProperties(source.getDefaultProperties().orNull())
                .hystrixCollapser(source.getHystrixCollapser())
                .hystrixCommand(source.getHystrixCommand()).build();
    }"
"public List<IWord> getWordList()
    {
        List<IWord> wordList = new LinkedList<IWord>();
        for (Sentence sentence : sentenceList)
        {
            wordList.addAll(sentence.wordList);
        }
        return wordList;
    }"
"static byte[] validIpV4ToBytes(String ip) {
        int i;
        return new byte[] {
                ipv4WordToByte(ip, 0, i = ip.indexOf('.', 1)),
                ipv4WordToByte(ip, i + 1, i = ip.indexOf('.', i + 2)),
                ipv4WordToByte(ip, i + 1, i = ip.indexOf('.', i + 2)),
                ipv4WordToByte(ip, i + 1, ip.length())
        };
    }"
"@Override
    public void close() {
        if (trainingArchive != null && trainingArchive != weightsArchive) {
            trainingArchive.close();
            trainingArchive = null;
        }
        if (weightsArchive != null) {
            weightsArchive.close();
            weightsArchive = null;
        }
    }"
"public static boolean isAsteriskForm(URI uri) {
        return ""*"".equals(uri.getPath()) &&
                uri.getScheme() == null && uri.getSchemeSpecificPart() == null &&
                uri.getHost() == null && uri.getAuthority() == null && uri.getQuery() == null &&
                uri.getFragment() == null;
    }"
"@Override
	public boolean cd(String directory) {
		if (StrUtil.isBlank(directory)) {
			// 当前目录
			return true;
		}
		try {
			channel.cd(directory.replaceAll(""\\\\"", ""/""));
			return true;
		} catch (SftpException e) {
			return false;
		}
	}"
"public int getFrequency(String from, String to)
    {
        return getFrequency(convert(from), convert(to));
    }"
"public static IUpdater mapOptimizer(Map<String, Object> optimizerConfig)
            throws UnsupportedKerasConfigurationException, InvalidKerasConfigurationException {

        if (!optimizerConfig.containsKey(""class_name"")) {
            throw new InvalidKerasConfigurationException(""Optimizer config does not contain a name field."");
        }
        String optimizerName = (String) optimizerConfig.get(""class_name"");

        if (!optimizerConfig.containsKey(""config""))
            throw new InvalidKerasConfigurationException(""Field config missing from layer config"");
        Map<String, Object> optimizerParameters = (Map<String, Object>) optimizerConfig.get(""config"");

        IUpdater dl4jOptimizer;


        switch (optimizerName) {
            case ""Adam"": {
                double lr = (double) optimizerParameters.get(""lr"");
                double beta1 = (double) optimizerParameters.get(""beta_1"");
                double beta2 = (double) optimizerParameters.get(""beta_2"");
                double epsilon = (double) optimizerParameters.get(""epsilon"");
                double decay = (double) optimizerParameters.get(""decay"");

                dl4jOptimizer = new Adam.Builder()
                        .beta1(beta1).beta2(beta2)
                        .epsilon(epsilon).learningRate(lr)
                        .learningRateSchedule(new InverseSchedule(ScheduleType.ITERATION, 1, decay, 1))
                        .build();
                break;
            }
            case ""Adadelta"": {
                double rho = (double) optimizerParameters.get(""rho"");
                double epsilon = (double) optimizerParameters.get(""epsilon"");
                // double decay = (double) optimizerParameters.get(""decay""); No decay in DL4J Adadelta

                dl4jOptimizer = new AdaDelta.Builder()
                        .epsilon(epsilon).rho(rho)
                        .build();
                break;
            }
            case ""Adgrad"": {
                double lr = (double) optimizerParameters.get(""lr"");
                double epsilon = (double) optimizerParameters.get(""epsilon"");
                double decay = (double) optimizerParameters.get(""decay"");

                dl4jOptimizer = new AdaGrad.Builder()
                        .epsilon(epsilon).learningRate(lr)
                        .learningRateSchedule(new InverseSchedule(ScheduleType.ITERATION, 1, decay, 1))
                        .build();
                break;
            }
            case ""Adamax"": {
                double lr = (double) optimizerParameters.get(""lr"");
                double beta1 = (double) optimizerParameters.get(""beta_1"");
                double beta2 = (double) optimizerParameters.get(""beta_2"");
                double epsilon = (double) optimizerParameters.get(""epsilon"");

                dl4jOptimizer = new AdaMax(lr, beta1, beta2, epsilon);
                break;
            }
            case ""Nadam"": {
                double lr = (double) optimizerParameters.get(""lr"");
                double beta1 = (double) optimizerParameters.get(""beta_1"");
                double beta2 = (double) optimizerParameters.get(""beta_2"");
                double epsilon = (double) optimizerParameters.get(""epsilon"");
                double scheduleDecay = (double) optimizerParameters.get(""schedule_decay"");

                dl4jOptimizer = new Nadam.Builder()
                        .beta1(beta1).beta2(beta2)
                        .epsilon(epsilon).learningRate(lr)
                        .learningRateSchedule(new InverseSchedule(ScheduleType.ITERATION, 1,
                                scheduleDecay, 1))
                        .build();
                break;
            }
            case ""SGD"": {
                double lr = (double) optimizerParameters.get(""lr"");
                double momentum = 0.0;
                try {
                    momentum = (double) optimizerParameters.get(""epsilon"");
                } catch (Exception e) {
                    log.warn(""couldn't read momentum parameter"");
                }

                double decay = (double) optimizerParameters.get(""decay"");

                dl4jOptimizer = new Nesterovs.Builder()
                        .momentum(momentum).learningRate(lr)
                        .learningRateSchedule(new InverseSchedule(ScheduleType.ITERATION, 1, decay, 1))
                        .build();
                break;
            }
            case ""RMSprop"": {
                double lr = (double) optimizerParameters.get(""lr"");
                double rho = (double) optimizerParameters.get(""rho"");
                double epsilon = (double) optimizerParameters.get(""epsilon"");
                double decay = (double) optimizerParameters.get(""decay"");

                dl4jOptimizer = new RmsProp.Builder()
                        .epsilon(epsilon).rmsDecay(rho).learningRate(lr)
                        .learningRateSchedule(new InverseSchedule(ScheduleType.ITERATION, 1, decay, 1))
                        .build();
                break;
            }
            default:
                throw new UnsupportedKerasConfigurationException(""Optimizer with name "" + optimizerName + ""can not be"" +
                        ""matched to a DL4J optimizer. Note that custom TFOptimizers are not supported by model import"");
        }

        return dl4jOptimizer;

    }"
"protected Terminal createTerminal() {
        terminal = TerminalFactory.create();
        if (isWindows()) {
            terminal.setEchoEnabled(true);
        }
        return terminal;
    }"
"public int getNumOccupiedMemorySegments() {
		// either the number of memory segments, or one for spilling
		final int numPartitionBuffers = this.partitionBuffers != null ?
			this.partitionBuffers.length : this.buildSideWriteBuffer.getNumOccupiedMemorySegments();
		return numPartitionBuffers + numOverflowSegments;
	}"
"private ResultPoint[] detectSolid1(ResultPoint[] cornerPoints) {
    // 0  2
    // 1  3
    ResultPoint pointA = cornerPoints[0];
    ResultPoint pointB = cornerPoints[1];
    ResultPoint pointC = cornerPoints[3];
    ResultPoint pointD = cornerPoints[2];

    int trAB = transitionsBetween(pointA, pointB);
    int trBC = transitionsBetween(pointB, pointC);
    int trCD = transitionsBetween(pointC, pointD);
    int trDA = transitionsBetween(pointD, pointA);

    // 0..3
    // :  :
    // 1--2
    int min = trAB;
    ResultPoint[] points = {pointD, pointA, pointB, pointC};
    if (min > trBC) {
      min = trBC;
      points[0] = pointA;
      points[1] = pointB;
      points[2] = pointC;
      points[3] = pointD;
    }
    if (min > trCD) {
      min = trCD;
      points[0] = pointB;
      points[1] = pointC;
      points[2] = pointD;
      points[3] = pointA;
    }
    if (min > trDA) {
      points[0] = pointC;
      points[1] = pointD;
      points[2] = pointA;
      points[3] = pointB;
    }

    return points;
  }"
"@Override
    public Class<?> getProxyClass() {
        if (proxyClass != null) {
            return proxyClass;
        }
        try {
            if (StringUtils.isNotBlank(interfaceId)) {
                this.proxyClass = ClassUtils.forName(interfaceId);
                if (!proxyClass.isInterface()) {
                    throw ExceptionUtils.buildRuntime(""service.interfaceId"",
                        interfaceId, ""interfaceId must set interface class, not implement class"");
                }
            } else {
                throw ExceptionUtils.buildRuntime(""service.interfaceId"",
                    ""null"", ""interfaceId must be not null"");
            }
        } catch (SofaRpcRuntimeException e) {
            throw e;
        } catch (Throwable e) {
            throw new SofaRpcRuntimeException(e.getMessage(), e);
        }
        return proxyClass;
    }"
"private void sendNotModified(ChannelHandlerContext ctx) {
        FullHttpResponse response = new DefaultFullHttpResponse(HTTP_1_1, NOT_MODIFIED);
        setDateHeader(response);

        this.sendAndCleanupConnection(ctx, response);
    }"
"private static Url parseUrl(final String spec) {
		final Url url = new Url();
		int startIndex = 0;
		int endIndex = spec.length();

		// Section 2.4.1: Parsing the Fragment Identifier
		//
		// If the parse string contains a crosshatch ""#"" character, then the
		// substring after the first (left-most) crosshatch ""#"" and up to the
		// end of the parse string is the <fragment> identifier. If the
		// crosshatch is the last character, or no crosshatch is present, then
		// the fragment identifier is empty. The matched substring, including
		// the crosshatch character, is removed from the parse string before
		// continuing.
		//
		// Note that the fragment identifier is not considered part of the URL.
		// However, since it is often attached to the URL, parsers must be able
		// to recognize and set aside fragment identifiers as part of the
		// process.
		final int crosshatchIndex = indexOf(spec, '#', startIndex, endIndex);

		if (crosshatchIndex >= 0) {
			url.fragment_ = spec.substring(crosshatchIndex + 1, endIndex);
			endIndex = crosshatchIndex;
		}
		// Section 2.4.2: Parsing the Scheme
		//
		// If the parse string contains a colon "":"" after the first character
		// and before any characters not allowed as part of a scheme name (i.e.,
		// any not an alphanumeric, plus ""+"", period ""."", or hyphen ""-""), the
		// <scheme> of the URL is the substring of characters up to but not
		// including the first colon. These characters and the colon are then
		// removed from the parse string before continuing.
		final int colonIndex = indexOf(spec, ':', startIndex, endIndex);

		if (colonIndex > 0) {
			final String scheme = spec.substring(startIndex, colonIndex);
			if (isValidScheme(scheme)) {
				url.scheme_ = scheme;
				startIndex = colonIndex + 1;
			}
		}

		// Section 2.4.3: Parsing the Network Location/Login
		//
		// If the parse string begins with a double-slash ""//"", then the
		// substring of characters after the double-slash and up to, but not
		// including, the next slash ""/"" character is the network location/login
		// (<net_loc>) of the URL. If no trailing slash ""/"" is present, the
		// entire remaining parse string is assigned to <net_loc>. The double-
		// slash and <net_loc> are removed from the parse string before
		// continuing.
		//
		// Note: We also accept a question mark ""?"" or a semicolon "";"" character as
		// delimiters for the network location/login (<net_loc>) of the URL.
		final int locationStartIndex;
		int locationEndIndex;

		if (spec.startsWith(""//"", startIndex)) {
			locationStartIndex = startIndex + 2;
			locationEndIndex = indexOf(spec, '/', locationStartIndex, endIndex);
			if (locationEndIndex >= 0) {
				startIndex = locationEndIndex;
			}
		} else {
			locationStartIndex = -1;
			locationEndIndex = -1;
		}
		// Section 2.4.4: Parsing the Query Information
		//
		// If the parse string contains a question mark ""?"" character, then the
		// substring after the first (left-most) question mark ""?"" and up to the
		// end of the parse string is the <query> information. If the question
		// mark is the last character, or no question mark is present, then the
		// query information is empty. The matched substring, including the
		// question mark character, is removed from the parse string before
		// continuing.
		final int questionMarkIndex = indexOf(spec, '?', startIndex, endIndex);

		if (questionMarkIndex >= 0) {
			if ((locationStartIndex >= 0) && (locationEndIndex < 0)) {
				// The substring of characters after the double-slash and up to, but not
				// including, the question mark ""?"" character is the network location/login
				// (<net_loc>) of the URL.
				locationEndIndex = questionMarkIndex;
				startIndex = questionMarkIndex;
			}
			url.query_ = spec.substring(questionMarkIndex + 1, endIndex);
			endIndex = questionMarkIndex;
		}
		// Section 2.4.5: Parsing the Parameters
		//
		// If the parse string contains a semicolon "";"" character, then the
		// substring after the first (left-most) semicolon "";"" and up to the end
		// of the parse string is the parameters (<params>). If the semicolon
		// is the last character, or no semicolon is present, then <params> is
		// empty. The matched substring, including the semicolon character, is
		// removed from the parse string before continuing.
		final int semicolonIndex = indexOf(spec, ';', startIndex, endIndex);

		if (semicolonIndex >= 0) {
			if ((locationStartIndex >= 0) && (locationEndIndex < 0)) {
				// The substring of characters after the double-slash and up to, but not
				// including, the semicolon "";"" character is the network location/login
				// (<net_loc>) of the URL.
				locationEndIndex = semicolonIndex;
				startIndex = semicolonIndex;
			}
			url.parameters_ = spec.substring(semicolonIndex + 1, endIndex);
			endIndex = semicolonIndex;
		}

		// Section 2.4.6: Parsing the Path
		//
		// After the above steps, all that is left of the parse string is the URL <path> and the
		// slash ""/"" that may precede it. Even though the initial slash is not part of the URL path,
		// the parser must remember whether or not it was present so that later processes can
		// differentiate between relative and absolute paths. Often this is done by simply storing
		// the preceding slash along with the path.
		if ((locationStartIndex >= 0) && (locationEndIndex < 0)) {
			// The entire remaining parse string is assigned to the network location/login
			// (<net_loc>) of the URL.
			locationEndIndex = endIndex;
		} else if (startIndex < endIndex) {
			url.path_ = spec.substring(startIndex, endIndex);
		}
		// Set the network location/login (<net_loc>) of the URL.
		if ((locationStartIndex >= 0) && (locationEndIndex >= 0)) {
			url.location_ = spec.substring(locationStartIndex, locationEndIndex);
		}

		return url;
	}"
"public void modify(DataMediaSource dataMediaSource) {
        Assert.assertNotNull(dataMediaSource);

        try {
            DataMediaSourceDO dataMediaSourceDo = modelToDo(dataMediaSource);
            if (dataMediaSourceDao.checkUnique(dataMediaSourceDo)) {
                dataMediaSourceDao.update(dataMediaSourceDo);
            } else {
                String exceptionCause = ""exist the same name source in the database."";
                logger.warn(""WARN ## "" + exceptionCause);
                throw new RepeatConfigureException(exceptionCause);
            }
        } catch (RepeatConfigureException rce) {
            throw rce;
        } catch (Exception e) {
            logger.error(""ERROR ## modify dataMediaSource has an exception!"");
            throw new ManagerException(e);
        }
    }"
"@Deprecated
    public Cipher encrypt() {
        try {
            Cipher cipher = Secret.getCipher(KEY_ALGORITHM);
            cipher.init(Cipher.ENCRYPT_MODE, getKey());
            return cipher;
        } catch (GeneralSecurityException e) {
            throw new AssertionError(e);
        }
    }"
"public static int hashBytes(MemorySegment segment, int offset, int lengthInBytes) {
		return hashBytes(segment, offset, lengthInBytes, DEFAULT_SEED);
	}"
"private Point getMatrixCenter() {

    ResultPoint pointA;
    ResultPoint pointB;
    ResultPoint pointC;
    ResultPoint pointD;

    //Get a white rectangle that can be the border of the matrix in center bull's eye or
    try {

      ResultPoint[] cornerPoints = new WhiteRectangleDetector(image).detect();
      pointA = cornerPoints[0];
      pointB = cornerPoints[1];
      pointC = cornerPoints[2];
      pointD = cornerPoints[3];

    } catch (NotFoundException e) {

      // This exception can be in case the initial rectangle is white
      // In that case, surely in the bull's eye, we try to expand the rectangle.
      int cx = image.getWidth() / 2;
      int cy = image.getHeight() / 2;
      pointA = getFirstDifferent(new Point(cx + 7, cy - 7), false, 1, -1).toResultPoint();
      pointB = getFirstDifferent(new Point(cx + 7, cy + 7), false, 1, 1).toResultPoint();
      pointC = getFirstDifferent(new Point(cx - 7, cy + 7), false, -1, 1).toResultPoint();
      pointD = getFirstDifferent(new Point(cx - 7, cy - 7), false, -1, -1).toResultPoint();

    }

    //Compute the center of the rectangle
    int cx = MathUtils.round((pointA.getX() + pointD.getX() + pointB.getX() + pointC.getX()) / 4.0f);
    int cy = MathUtils.round((pointA.getY() + pointD.getY() + pointB.getY() + pointC.getY()) / 4.0f);

    // Redetermine the white rectangle starting from previously computed center.
    // This will ensure that we end up with a white rectangle in center bull's eye
    // in order to compute a more accurate center.
    try {
      ResultPoint[] cornerPoints = new WhiteRectangleDetector(image, 15, cx, cy).detect();
      pointA = cornerPoints[0];
      pointB = cornerPoints[1];
      pointC = cornerPoints[2];
      pointD = cornerPoints[3];
    } catch (NotFoundException e) {
      // This exception can be in case the initial rectangle is white
      // In that case we try to expand the rectangle.
      pointA = getFirstDifferent(new Point(cx + 7, cy - 7), false, 1, -1).toResultPoint();
      pointB = getFirstDifferent(new Point(cx + 7, cy + 7), false, 1, 1).toResultPoint();
      pointC = getFirstDifferent(new Point(cx - 7, cy + 7), false, -1, 1).toResultPoint();
      pointD = getFirstDifferent(new Point(cx - 7, cy - 7), false, -1, -1).toResultPoint();
    }

    // Recompute the center of the rectangle
    cx = MathUtils.round((pointA.getX() + pointD.getX() + pointB.getX() + pointC.getX()) / 4.0f);
    cy = MathUtils.round((pointA.getY() + pointD.getY() + pointB.getY() + pointC.getY()) / 4.0f);

    return new Point(cx, cy);
  }"
"public void setContent(Node content) {
        this.content = content;
        if (drawers.size() > 0) {
            drawers.get(0).setContent(content);
        } else {
            getChildren().add(this.content);
        }
    }"
"protected boolean shouldCloseConnection(HttpConnection conn) {
        // Connection must be closed due to an abnormal circumstance 
        if (isConnectionCloseForced()) {
            LOG.debug(""Should force-close connection."");
            return true;
        }

        Header connectionHeader = null;
        // In case being connected via a proxy server
        if (!conn.isTransparent()) {
            // Check for 'proxy-connection' directive
            connectionHeader = responseHeaders.getFirstHeader(""proxy-connection"");
        }
        // In all cases Check for 'connection' directive
        // some non-complaint proxy servers send it instread of
        // expected 'proxy-connection' directive
        if (connectionHeader == null) {
            connectionHeader = responseHeaders.getFirstHeader(""connection"");
        }
        // In case the response does not contain any explict connection
        // directives, check whether the request does
        if (connectionHeader == null) {
            connectionHeader = requestHeaders.getFirstHeader(""connection"");
        }
        if (connectionHeader != null) {
            if (connectionHeader.getValue().equalsIgnoreCase(""close"")) {
                if (LOG.isDebugEnabled()) {
                    LOG.debug(""Should close connection in response to directive: "" 
                        + connectionHeader.getValue());
                }
                return true;
            } else if (connectionHeader.getValue().equalsIgnoreCase(""keep-alive"")) {
                if (LOG.isDebugEnabled()) {
                    LOG.debug(""Should NOT close connection in response to directive: "" 
                        + connectionHeader.getValue());
                }
                return false;
            } else {
                if (LOG.isDebugEnabled()) {
                    LOG.debug(""Unknown directive: "" + connectionHeader.toExternalForm());
                }
            }
        }
        LOG.debug(""Resorting to protocol version default close connection policy"");
        // missing or invalid connection header, do the default
        if (this.effectiveVersion.greaterEquals(HttpVersion.HTTP_1_1)) {
            if (LOG.isDebugEnabled()) {
                LOG.debug(""Should NOT close connection, using "" + this.effectiveVersion.toString());
            }
        } else {
            if (LOG.isDebugEnabled()) {
                LOG.debug(""Should close connection, using "" + this.effectiveVersion.toString());
            }
        }
        return this.effectiveVersion.lessEquals(HttpVersion.HTTP_1_0);
    }"
"@ExperimentalApi(""https://github.com/grpc/grpc-java/issues/1704"")
  public Set<String> getAdvertisedMessageEncodings() {
    Set<String> advertisedDecompressors = new HashSet<>(decompressors.size());
    for (Entry<String, DecompressorInfo> entry : decompressors.entrySet()) {
      if (entry.getValue().advertised) {
        advertisedDecompressors.add(entry.getKey());
      }
    }
    return Collections.unmodifiableSet(advertisedDecompressors);
  }"
"private static void autoUnmarshalEligible(HierarchicalStreamReader reader,
                                              Object o) {
        try {
            String nodeName = reader.getNodeName();
            Class c = o.getClass();
            Field f = null;
            try {
                f = c.getDeclaredField(nodeName);
            } catch (NoSuchFieldException e) {
                UNMARSHALL_ERROR_COUNTER.increment();
            }
            if (f == null) {
                return;
            }
            Annotation annotation = f.getAnnotation(Auto.class);
            if (annotation == null) {
                return;
            }
            f.setAccessible(true);

            String value = reader.getValue();
            Class returnClass = f.getType();
            if (value != null) {
                if (!String.class.equals(returnClass)) {

                    Method method = returnClass.getDeclaredMethod(""valueOf"",
                            java.lang.String.class);
                    Object valueObject = method.invoke(returnClass, value);
                    f.set(o, valueObject);
                } else {
                    f.set(o, value);

                }
            }
        } catch (Throwable th) {
            logger.error(""Error in unmarshalling the object:"", th);
        }
    }"
"public static Field getRequiredField(Class type, String name) {
        try {
            return type.getDeclaredField(name);
        } catch (NoSuchFieldException e) {
            Optional<Field> field = findField(type, name);
            return field.orElseThrow(() -> new NoSuchFieldError(""No field '"" + name + ""' found for type: "" + type.getName()));
        }
    }"
"@ReadOperation(produces = {ActuatorMediaType.V2_JSON, ""application/vnd.cas.services+yaml"", MediaType.APPLICATION_JSON_VALUE})
    public RegisteredService fetchService(@Selector final String id) {
        if (NumberUtils.isDigits(id)) {
            return this.servicesManager.findServiceBy(Long.parseLong(id));
        }
        return this.servicesManager.findServiceBy(id);
    }"
"public <T extends VoidMessage> void addPrecursor(@NonNull Class<T> cls, @NonNull MessageCallable<T> callable) {
        precursors.put(cls.getCanonicalName(), callable);
    }"
"@SuppressWarnings(""unused"")
    private File prepareFile(FileBatch fileBatch) {
        // 处理构造对应的文件url
        String dirname = buildFileName(fileBatch.getIdentity(), ClassUtils.getShortClassName(fileBatch.getClass()));
        File dir = new File(downloadDir, dirname);
        NioUtils.create(dir, false, 3);// 创建父目录
        // 压缩对应的文件数据
        List<FileData> fileDatas = fileBatch.getFiles();

        for (FileData fileData : fileDatas) {
            String namespace = fileData.getNameSpace();
            String path = fileData.getPath();
            boolean isLocal = StringUtils.isBlank(namespace);
            String entryName = null;
            if (true == isLocal) {
                entryName = FilenameUtils.getPath(path) + FilenameUtils.getName(path);
            } else {
                entryName = namespace + File.separator + path;
            }

            InputStream input = retrive(fileBatch.getIdentity(), fileData);
            if (input == null) {
                continue;
            }
            File entry = new File(dir, entryName);
            NioUtils.create(entry.getParentFile(), false, retry);// 尝试创建父路径
            FileOutputStream output = null;
            try {
                output = new FileOutputStream(entry);
                NioUtils.copy(input, output);// 输出到压缩流中
            } catch (Exception e) {
                throw new PipeException(""prepareFile error for file["" + entry.getPath() + ""]"");
            } finally {
                IOUtils.closeQuietly(output);
            }
        }

        return dir;
    }"
"public static org.apache.hadoop.fs.Path toHadoopPath(Path path) {
		return new org.apache.hadoop.fs.Path(path.toUri());
	}"
"public static MapBlock fromKeyValueBlock(
            Optional<boolean[]> mapIsNull,
            int[] offsets,
            Block keyBlock,
            Block valueBlock,
            MapType mapType,
            MethodHandle keyBlockNativeEquals,
            MethodHandle keyNativeHashCode,
            MethodHandle keyBlockHashCode)
    {
        validateConstructorArguments(0, offsets.length - 1, mapIsNull.orElse(null), offsets, keyBlock, valueBlock, mapType.getKeyType(), keyBlockNativeEquals, keyNativeHashCode);

        int mapCount = offsets.length - 1;

        return createMapBlockInternal(
                0,
                mapCount,
                mapIsNull,
                offsets,
                keyBlock,
                valueBlock,
                new HashTables(Optional.empty(), keyBlock.getPositionCount() * HASH_MULTIPLIER),
                mapType.getKeyType(),
                keyBlockNativeEquals,
                keyNativeHashCode,
                keyBlockHashCode);
    }"
"public static byte[] nextBytes() {
		final ByteBuffer bb = ByteBuffer.wrap(new byte[12]);
		bb.putInt((int) DateUtil.currentSeconds());// 4位
		bb.putInt(machine);// 4位
		bb.putInt(nextInc.getAndIncrement());// 4位

		return bb.array();
	}"
"public static List<TopLevelItemDescriptor> all(Authentication a, ItemGroup c) {
        List<TopLevelItemDescriptor> result = new ArrayList<>();
        ACL acl;
        if (c instanceof AccessControlled) {
            acl = ((AccessControlled) c).getACL();
        } else {
            // fall back to root
            acl = Jenkins.getInstance().getACL();
        }
        for (TopLevelItemDescriptor d: all()) {
            if (acl.hasCreatePermission(a, c, d) && d.isApplicableIn(c)) {
                result.add(d);
            }
        }
        return result;
    }"
"@Override
    public Record nextRecord() {
        Object[] next = iter.next();
        invokeListeners(next);

        URI location;
        try {
            location = new URI(conn.getMetaData().getURL());
        } catch (SQLException | URISyntaxException e) {
            throw new IllegalStateException(""Could not get sql connection metadata"", e);
        }

        List<Object> params = new ArrayList<>();
        if (metadataIndices != null) {
            for (int index : metadataIndices) {
                params.add(next[index]);
            }
        }
        RecordMetaDataJdbc rmd = new RecordMetaDataJdbc(location, this.metadataQuery, params, getClass());

        return new org.datavec.api.records.impl.Record(toWritable(next), rmd);
    }"
"@Nullable
    Object resolveTypeReference(Element element) {
        if (element instanceof TypeElement) {
            TypeElement typeElement = (TypeElement) element;
            return resolveTypeReferenceForTypeElement(typeElement);
        }
        return null;
    }"
"public Integer actualMaximumSize() {
        final int coreSize = coreSize().get();
        final int maximumSize = maximumSize().get();
        if (getAllowMaximumSizeToDivergeFromCoreSize().get()) {
            if (coreSize > maximumSize) {
                return coreSize;
            } else {
                return maximumSize;
            }
        } else {
            return coreSize;
        }
    }"
"void valueStrength(String key, @Nullable String value, Strength strength) {
    requireArgument(value == null, ""%s does not take a value"", key);
    requireArgument(valueStrength == null, ""%s was already set to %s"", key, valueStrength);
    valueStrength = strength;
  }"
"private static boolean containsDelimiter(String string) {
		final char[] charArray = string.toCharArray();
		for (char c : charArray) {
			if (isDelimiter(c)) {
				return true;
			}
		}
		return false;
	}"
"protected QuadTree findIndex(INDArray coordinates) {

        // Compute the sector for the coordinates
        boolean left = (coordinates.getDouble(0) <= (boundary.getX() + boundary.getHw() / 2));
        boolean top = (coordinates.getDouble(1) <= (boundary.getY() + boundary.getHh() / 2));

        // top left
        QuadTree index = getNorthWest();
        if (left) {
            // left side
            if (!top) {
                // bottom left
                index = getSouthWest();
            }
        } else {
            // right side
            if (top) {
                // top right
                index = getNorthEast();
            } else {
                // bottom right
                index = getSouthEast();

            }
        }

        return index;
    }"
"protected T getRowObject(int rowIndex) {
		int pageIndex = rowIndex - dataOffset;
		if (pageIndex >= 0 && pageIndex < data.size()) {
			return data.get(pageIndex);
		}
		return null;
	}"
"public EpollMode getEpollMode() {
        return ((AbstractEpollChannel) channel).isFlagSet(Native.EPOLLET)
                ? EpollMode.EDGE_TRIGGERED : EpollMode.LEVEL_TRIGGERED;
    }"
"public final @CheckForNull QueueTaskFuture<RunT> scheduleBuild2(int quietPeriod, Action... actions) {
        Queue.Item i = scheduleBuild2(quietPeriod, Arrays.asList(actions));
        return i != null ? (QueueTaskFuture) i.getFuture() : null;
    }"
"@Nonnull
    public String getDescription() {
        Stapler stapler = Stapler.getCurrent();
        if (stapler != null) {
            try {
                WebApp webapp = WebApp.getCurrent();
                MetaClass meta = webapp.getMetaClass(this);
                Script s = meta.loadTearOff(JellyClassTearOff.class).findScript(""newInstanceDetail"");
                if (s == null) {
                    return """";
                }
                DefaultScriptInvoker dsi = new DefaultScriptInvoker();
                StringWriter sw = new StringWriter();
                XMLOutput xml = dsi.createXMLOutput(sw, true);
                dsi.invokeScript(Stapler.getCurrentRequest(), Stapler.getCurrentResponse(), s, this, xml);
                return sw.toString();
            } catch (Exception e) {
                LOGGER.log(Level.WARNING, null, e);
                return """";
            }
        } else {
            return """";
        }
    }"
"public static Builder setContentTypeHeaders(boolean isBinaryTransportEnabled, Builder requestBuilder)
    {
        if (isBinaryTransportEnabled) {
            return requestBuilder
                    .setHeader(CONTENT_TYPE, APPLICATION_JACKSON_SMILE)
                    .setHeader(ACCEPT, APPLICATION_JACKSON_SMILE);
        }
        return requestBuilder
                .setHeader(CONTENT_TYPE, JSON_UTF_8.toString())
                .setHeader(ACCEPT, JSON_UTF_8.toString());
    }"
"private static String escape(char c) {
		switch (c) {
		case '\b':
			return ""\\b"";
		case '\t':
			return ""\\t"";
		case '\n':
			return ""\\n"";
		case '\f':
			return ""\\f"";
		case '\r':
			return ""\\r"";
		default:
			if (c < StrUtil.C_SPACE || //
					(c >= '\u0080' && c <= '\u00a0') || //
					(c >= '\u2000' && c <= '\u2010') || //
					(c >= '\u2028' && c <= '\u202F') || //
					(c >= '\u2066' && c <= '\u206F')//
			) {
				return HexUtil.toUnicodeHex(c);
			} else {
				return Character.toString(c);
			}
		}
	}"
"private String getMapResultString(Map result) {
        StringBuilder sb = new StringBuilder();
        Iterator<Entry> i = result.entrySet().iterator();
        if (!i.hasNext()) {
            return ""{}"";
        }
        sb.append('{');
        for (;;) {
            Entry e = i.next();
            Object key = e.getKey();
            Object value = e.getValue();
            // 注意: 修改为getResultString(e)进行递归处理
            sb.append(key == this ? ""(this Map)"" : getResultString(key));
            sb.append('=');
            // 注意: 修改为getResultString(e)进行递归处理
            sb.append(value == this ? ""(this Map)"" : getResultString(value));
            if (!i.hasNext()) {
                return sb.append('}').toString();
            }
            sb.append("", "");
        }
    }"
"public Channel onFindChannel(FindChannelEvent event) {
        Assert.notNull(event);
        Long channelId = event.getChannelId();
        Long pipelineId = event.getPipelineId();
        Channel channel = null;
        if (channelId != null) {
            channel = channelService.findById(channelId);
        } else {
            Assert.notNull(pipelineId);
            channel = channelService.findByPipelineId(pipelineId);
        }

        return channel;
    }"
"@DeleteMapping(path = ""/instances/{id}"")
    public Mono<ResponseEntity<Void>> unregister(@PathVariable String id) {
        LOGGER.debug(""Unregister instance with ID '{}'"", id);
        return registry.deregister(InstanceId.of(id))
                       .map(v -> ResponseEntity.noContent().<Void>build())
                       .defaultIfEmpty(ResponseEntity.notFound().build());
    }"
"boolean decodeHuffmanData(final Bzip2HuffmanStageDecoder huffmanDecoder) {
        final Bzip2BitReader reader = this.reader;
        final byte[] bwtBlock = this.bwtBlock;
        final byte[] huffmanSymbolMap = this.huffmanSymbolMap;
        final int streamBlockSize = this.bwtBlock.length;
        final int huffmanEndOfBlockSymbol = this.huffmanEndOfBlockSymbol;
        final int[] bwtByteCounts = this.bwtByteCounts;
        final Bzip2MoveToFrontTable symbolMTF = this.symbolMTF;

        int bwtBlockLength = this.bwtBlockLength;
        int repeatCount = this.repeatCount;
        int repeatIncrement = this.repeatIncrement;
        int mtfValue = this.mtfValue;

        for (;;) {
            if (!reader.hasReadableBits(HUFFMAN_DECODE_MAX_CODE_LENGTH)) {
                this.bwtBlockLength = bwtBlockLength;
                this.repeatCount = repeatCount;
                this.repeatIncrement = repeatIncrement;
                this.mtfValue = mtfValue;
                return false;
            }
            final int nextSymbol = huffmanDecoder.nextSymbol();

            if (nextSymbol == HUFFMAN_SYMBOL_RUNA) {
                repeatCount += repeatIncrement;
                repeatIncrement <<= 1;
            } else if (nextSymbol == HUFFMAN_SYMBOL_RUNB) {
                repeatCount += repeatIncrement << 1;
                repeatIncrement <<= 1;
            } else {
                if (repeatCount > 0) {
                    if (bwtBlockLength + repeatCount > streamBlockSize) {
                        throw new DecompressionException(""block exceeds declared block size"");
                    }
                    final byte nextByte = huffmanSymbolMap[mtfValue];
                    bwtByteCounts[nextByte & 0xff] += repeatCount;
                    while (--repeatCount >= 0) {
                        bwtBlock[bwtBlockLength++] = nextByte;
                    }

                    repeatCount = 0;
                    repeatIncrement = 1;
                }

                if (nextSymbol == huffmanEndOfBlockSymbol) {
                    break;
                }

                if (bwtBlockLength >= streamBlockSize) {
                    throw new DecompressionException(""block exceeds declared block size"");
                }

                mtfValue = symbolMTF.indexToFront(nextSymbol - 1) & 0xff;

                final byte nextByte = huffmanSymbolMap[mtfValue];
                bwtByteCounts[nextByte & 0xff]++;
                bwtBlock[bwtBlockLength++] = nextByte;
            }
        }
        this.bwtBlockLength = bwtBlockLength;
        initialiseInverseBWT();
        return true;
    }"
"private long getRndPositiveLong() {
  	   	long rnd = Long.MIN_VALUE;
  	   	while (rnd == Long.MIN_VALUE) {
  	  	   	rnd = staticRandomGenerator.nextLong();
  	   	}
    	return Math.abs(rnd);
    }"
"@Override
	protected void flush() {
		// The Kafka 0.8 producer doesn't support flushing, we wait here
		// until all pending records are confirmed
		synchronized (pendingRecordsLock) {
			while (pendingRecords > 0) {
				try {
					pendingRecordsLock.wait();
				} catch (InterruptedException e) {
					// this can be interrupted when the Task has been cancelled.
					// by throwing an exception, we ensure that this checkpoint doesn't get confirmed
					throw new RuntimeException(""Flushing got interrupted while checkpointing"", e);
				}
			}
		}
	}"
"protected boolean hasStereotype(Element element, Class<? extends Annotation> stereotype) {
        return hasStereotype(element, stereotype.getName());
    }"
"static int getRecommendedMinimumErrorCorrectionLevel(int n) throws WriterException {
    if (n <= 0) {
      throw new IllegalArgumentException(""n must be > 0"");
    }
    if (n <= 40) {
      return 2;
    }
    if (n <= 160) {
      return 3;
    }
    if (n <= 320) {
      return 4;
    }
    if (n <= 863) {
      return 5;
    }
    throw new WriterException(""No recommendation possible"");
  }"
"public HttpResponse doShowUpgradeWizard() throws Exception {
        Jenkins.getInstance().checkPermission(Jenkins.ADMINISTER);
        HttpSession session = Stapler.getCurrentRequest().getSession(true);
        session.setAttribute(SHOW_UPGRADE_WIZARD_FLAG, true);
        return HttpResponses.redirectToContextRoot();
    }"
"public SDVariable avgPooling3d(SDVariable input, Pooling3DConfig pooling3DConfig) {
        pooling3DConfig.setType(Pooling3D.Pooling3DType.AVG);
        return pooling3d(input, pooling3DConfig);
    }"
"@Override
    public List<DataSet> dataSetBatches(int num) {
        List<List<DataSet>> list = Lists.partition(asList(), num);
        List<DataSet> ret = new ArrayList<>();
        for (List<DataSet> l : list)
            ret.add(DataSet.merge(l));
        return ret;

    }"
"@Override protected void setupLocal(){
//    long start = System.currentTimeMillis();
    assert(_localmodel == null);
    _localmodel = _sharedmodel;
    _sharedmodel = null;
    _localmodel.set_processed_local(0);
    final int weightIdx =_fr.find(_localmodel.get_params()._weights_column);
    final int respIdx =_fr.find(_localmodel.get_params()._response_column);
    final int batchSize = _localmodel.get_params()._mini_batch_size;

//    long nativetime = 0;
    DeepWaterIterator iter = null;
    long seed = 0xDECAF + 0xD00D * _localmodel.get_processed_global();
    Random rng = RandomUtils.getRNG(seed);

    if (_fr.numRows()>Integer.MAX_VALUE) {
      throw H2O.unimpl(""Need to implement batching into int-sized chunks."");
    }
    int len = (int)_fr.numRows();
    int j=0;
    Futures fs = new Futures();
    ArrayList trainLabels = new ArrayList<>();
    ArrayList trainData = new ArrayList<>();

    try {
      // Binary data (Images/Documents/etc.)
      if (_localmodel.get_params()._problem_type == DeepWaterParameters.ProblemType.image ||
          _localmodel.get_params()._problem_type == DeepWaterParameters.ProblemType.text) {
        int dataIdx = 0; //must be the first column //FIXME
        Log.debug(""Using column "" + _fr.name(dataIdx) + "" for "" +
            ((_localmodel.get_params()._problem_type == DeepWaterParameters.ProblemType.image) ? ""path to image data""
                :((_localmodel.get_params()._problem_type == DeepWaterParameters.ProblemType.text) ? ""text data""
                : ""path to arbitrary bytes"")));
        // full passes over the data
        BufferedString bs = new BufferedString();
        int fullpasses = (int)_useFraction; // Example: train_samples_per_iteration = 4700, and train.numRows()=1000 -> _useFraction = 4.7 -> fullpasses = 4
        while (j++ < fullpasses) {
          for (int i=0; i<_fr.numRows(); ++i) {
            double weight = weightIdx == -1 ? 1 : _fr.vec(weightIdx).at(i);
            if (weight == 0)
              continue;
            BufferedString file = _fr.vec(dataIdx).atStr(bs, i);
            if (file!=null)
              trainData.add(file.toString());
            float response = (float) _fr.vec(respIdx).at(i);
            trainLabels.add(response);
          }
        }

        // fractional passes // 0.7
        while (trainData.size() < _useFraction*len || trainData.size() % batchSize != 0) {
          assert(_shuffle);
          int i = rng.nextInt(len);
          double weight = weightIdx == -1 ? 1 : _fr.vec(weightIdx).at(i);
          if (weight == 0)
            continue;
          BufferedString file = _fr.vec(dataIdx).atStr(bs, i);
          if (file!=null)
            trainData.add(file.toString());
          float response = (float) _fr.vec(respIdx).at(i);
          trainLabels.add(response);
        }
      }

      // Numeric data (H2O Frame full with numeric columns)
      else if (_localmodel.get_params()._problem_type == DeepWaterParameters.ProblemType.dataset) {
        double mul = _localmodel._dataInfo._normRespMul!=null ? _localmodel._dataInfo._normRespMul[0] : 1;
        double sub = _localmodel._dataInfo._normRespSub!=null ? _localmodel._dataInfo._normRespSub[0] : 0;

        // full passes over the data
        int fullpasses = (int) _useFraction;
        while (j++ < fullpasses) {
          for (int i = 0; i < _fr.numRows(); ++i) {
            double weight = weightIdx == -1 ? 1 : _fr.vec(weightIdx).at(i);
            if (weight == 0)
              continue;
            float response = (float)((_fr.vec(respIdx).at(i) - sub) / mul);
            trainData.add(i);
            trainLabels.add(response);
          }
        }

        // fractional passes
        while (trainData.size() < _useFraction * len || trainData.size() % batchSize != 0) {
          int i = rng.nextInt(len);
          double weight = weightIdx == -1 ? 1 : _fr.vec(weightIdx).at(i);
          if (weight == 0)
            continue;
          float response = (float)((_fr.vec(respIdx).at(i) - sub) / mul);
          trainData.add(i);
          trainLabels.add(response);
        }
      }

      // shuffle the (global) list
      if (_shuffle) {
        rng.setSeed(seed);
        Collections.shuffle(trainLabels, rng);
        rng.setSeed(seed);
        Collections.shuffle(trainData, rng);
      }
      if (_localmodel.get_params()._problem_type == DeepWaterParameters.ProblemType.image) {
        iter = new DeepWaterImageIterator(trainData, trainLabels, _localmodel._meanData, batchSize, _localmodel._width, _localmodel._height, _localmodel._channels, _localmodel.get_params()._cache_data);
      }
      else if (_localmodel.get_params()._problem_type == DeepWaterParameters.ProblemType.dataset) {
        assert (_localmodel._dataInfo != null);
        iter = new DeepWaterDatasetIterator(trainData, trainLabels, _localmodel._dataInfo, batchSize, _localmodel.get_params()._cache_data);
      }
      else if (_localmodel.get_params()._problem_type == DeepWaterParameters.ProblemType.text) {
        iter = new DeepWaterTextIterator(trainData, trainLabels, batchSize, 56/*FIXME*/, _localmodel.get_params()._cache_data);
      }

      NativeTrainTask ntt;
      while (iter.Next(fs) && !_job.isStopping()) {
//        if (ntt != null) nativetime += ntt._timeInMillis;
        long n = _localmodel.get_processed_total();

//        if(!_localmodel.get_params()._quiet_mode)
//          Log.info(""Trained "" + n + "" samples. Training on "" + Arrays.toString(((DeepWaterImageIterator)iter).getFiles()));

        _localmodel._backend.setParameter(_localmodel.getModel().get(), ""learning_rate"", _localmodel.get_params().learningRate((double) n));
        _localmodel._backend.setParameter(_localmodel.getModel().get(), ""momentum"", _localmodel.get_params().momentum((double) n));

        //fork off GPU work, but let the iterator.Next() wait on completion before swapping again
        //System.err.println(""data: "" + Arrays.toString(iter.getData()));
        /*
        float[] preds = _localmodel._backend.predict(_localmodel._model, iter.getData());
        if (Float.isNaN(ArrayUtils.sum(preds))) {
          Log.err(DeepWaterModel.unstable_msg);
          throw new UnsupportedOperationException(DeepWaterModel.unstable_msg);
        }
        */
//        System.err.println(""pred: "" + Arrays.toString(preds));
        ntt = new NativeTrainTask(_localmodel._backend, _localmodel.getModel().get(), iter.getData(), iter.getLabel());
        fs.add(H2O.submitTask(ntt));
        _localmodel.add_processed_local(iter._batch_size);
      }
      fs.blockForPending();
//      nativetime += ntt._timeInMillis;
    } catch (IOException e) {
      e.printStackTrace(); //gracefully continue if we can't find files etc.
    }
//    long end = System.currentTimeMillis();
//    if (!_localmodel.get_params()._quiet_mode) {
//      Log.info(""Time for one iteration: "" + PrettyPrint.msecs(end - start, true));
//      Log.info(""Time for native training : "" + PrettyPrint.msecs(nativetime, true));
//    }
  }"
"public Layer getOutputLayer() {
        Layer ret = getLayers()[getLayers().length - 1];
        if (ret instanceof FrozenLayerWithBackprop) {
            ret = ((FrozenLayerWithBackprop) ret).getInsideLayer();
        }
        return ret;
    }"
"private void closeBlock(ByteBuf out) {
        final Bzip2BlockCompressor blockCompressor = this.blockCompressor;
        if (!blockCompressor.isEmpty()) {
            blockCompressor.close(out);
            final int blockCRC = blockCompressor.crc();
            streamCRC = (streamCRC << 1 | streamCRC >>> 31) ^ blockCRC;
        }
    }"
"public static PropertyDescriptor[] getPropertyDescriptors(Class<?> clazz) throws BeanException {
		BeanInfo beanInfo;
		try {
			beanInfo = Introspector.getBeanInfo(clazz);
		} catch (IntrospectionException e) {
			throw new BeanException(e);
		}
		return ArrayUtil.filter(beanInfo.getPropertyDescriptors(), new Filter<PropertyDescriptor>() {
			@Override
			public boolean accept(PropertyDescriptor t) {
				// 过滤掉getClass方法
				return false == ""class"".equals(t.getName());
			}
		});
	}"
"private int partition(double[] a, int[] indexes, int left, int right) {
        int i = left - 1;
        int j = right;
        while (true) {
            while (a[indexes[++i]] < a[indexes[right]]); // find item on left to swap, a[right] acts as sentinel
            while (a[indexes[right]] < a[indexes[--j]]) { // find item on right to swap
                if (j == left)
                    break; // don't go out-of-bounds
            }
            if (i >= j)
                break; // check if pointers cross
            swap(a, indexes, i, j); // swap two elements into place
        }
        swap(a, indexes, i, right); // swap with partition element
        return i;
    }"
"public List<Entity> find(Entity where) throws SQLException {
		return find(where.getFieldNames(), where, EntityListHandler.create());
	}"
"protected void initEurekaServerContext() throws Exception {
        EurekaServerConfig eurekaServerConfig = new DefaultEurekaServerConfig();

        // For backward compatibility
        JsonXStream.getInstance().registerConverter(new V1AwareInstanceInfoConverter(), XStream.PRIORITY_VERY_HIGH);
        XmlXStream.getInstance().registerConverter(new V1AwareInstanceInfoConverter(), XStream.PRIORITY_VERY_HIGH);

        logger.info(""Initializing the eureka client..."");
        logger.info(eurekaServerConfig.getJsonCodecName());
        ServerCodecs serverCodecs = new DefaultServerCodecs(eurekaServerConfig);

        ApplicationInfoManager applicationInfoManager = null;

        if (eurekaClient == null) {
            EurekaInstanceConfig instanceConfig = isCloud(ConfigurationManager.getDeploymentContext())
                    ? new CloudInstanceConfig()
                    : new MyDataCenterInstanceConfig();
            
            applicationInfoManager = new ApplicationInfoManager(
                    instanceConfig, new EurekaConfigBasedInstanceInfoProvider(instanceConfig).get());
            
            EurekaClientConfig eurekaClientConfig = new DefaultEurekaClientConfig();
            eurekaClient = new DiscoveryClient(applicationInfoManager, eurekaClientConfig);
        } else {
            applicationInfoManager = eurekaClient.getApplicationInfoManager();
        }

        PeerAwareInstanceRegistry registry;
        if (isAws(applicationInfoManager.getInfo())) {
            registry = new AwsInstanceRegistry(
                    eurekaServerConfig,
                    eurekaClient.getEurekaClientConfig(),
                    serverCodecs,
                    eurekaClient
            );
            awsBinder = new AwsBinderDelegate(eurekaServerConfig, eurekaClient.getEurekaClientConfig(), registry, applicationInfoManager);
            awsBinder.start();
        } else {
            registry = new PeerAwareInstanceRegistryImpl(
                    eurekaServerConfig,
                    eurekaClient.getEurekaClientConfig(),
                    serverCodecs,
                    eurekaClient
            );
        }

        PeerEurekaNodes peerEurekaNodes = getPeerEurekaNodes(
                registry,
                eurekaServerConfig,
                eurekaClient.getEurekaClientConfig(),
                serverCodecs,
                applicationInfoManager
        );

        serverContext = new DefaultEurekaServerContext(
                eurekaServerConfig,
                serverCodecs,
                registry,
                peerEurekaNodes,
                applicationInfoManager
        );

        EurekaServerContextHolder.initialize(serverContext);

        serverContext.initialize();
        logger.info(""Initialized server context"");

        // Copy registry from neighboring eureka node
        int registryCount = registry.syncUp();
        registry.openForTraffic(applicationInfoManager, registryCount);

        // Register all monitoring statistics.
        EurekaMonitors.registerAllStats();
    }"
"public static <T> PatternStream<T> pattern(
			DataStream<T> input,
			Pattern<T, ?> pattern,
			EventComparator<T> comparator) {
		final PatternStream<T> stream = new PatternStream<>(input, pattern);
		return stream.withComparator(comparator);
	}"
"public static void writeStringToFile(String path, String toWrite, SparkContext sc) throws IOException {
        FileSystem fileSystem = FileSystem.get(sc.hadoopConfiguration());
        try (BufferedOutputStream bos = new BufferedOutputStream(fileSystem.create(new Path(path)))) {
            bos.write(toWrite.getBytes(""UTF-8""));
        }
    }"
"private static SortedSet<QueryParameter> createSortedParameters(final String queryString) {
		if (queryString == null || queryString.isEmpty()) {
			return null;
		}

		final String[] pairs = queryString.split(""&"");
		final SortedSet<QueryParameter> params = new TreeSet<>();

		for (final String pair : pairs) {
			if (pair.length() == 0) {
				continue;
			}

			String[] tokens = pair.split(""="", 2);
			switch (tokens.length) {
			case 1:
				if (pair.charAt(0) == '=') {
					params.add(new QueryParameter("""", tokens[0]));
				} else {
					params.add(new QueryParameter(tokens[0], """"));
				}
				break;
			case 2:
				params.add(new QueryParameter(tokens[0], tokens[1]));
				break;
			}
		}
		return params;
	}"
"private static <T> void generateProxyClass(Class<T> primaryInterface, String superClassName, String methodBody) throws Exception
   {
      String newClassName = superClassName.replaceAll(""(.+)\\.(\\w+)"", ""$1.Hikari$2"");

      CtClass superCt = classPool.getCtClass(superClassName);
      CtClass targetCt = classPool.makeClass(newClassName, superCt);
      targetCt.setModifiers(Modifier.FINAL);

      System.out.println(""Generating "" + newClassName);

      targetCt.setModifiers(Modifier.PUBLIC);

      // Make a set of method signatures we inherit implementation for, so we don't generate delegates for these
      Set<String> superSigs = new HashSet<>();
      for (CtMethod method : superCt.getMethods()) {
         if ((method.getModifiers() & Modifier.FINAL) == Modifier.FINAL) {
            superSigs.add(method.getName() + method.getSignature());
         }
      }

      Set<String> methods = new HashSet<>();
      for (Class<?> intf : getAllInterfaces(primaryInterface)) {
         CtClass intfCt = classPool.getCtClass(intf.getName());
         targetCt.addInterface(intfCt);
         for (CtMethod intfMethod : intfCt.getDeclaredMethods()) {
            final String signature = intfMethod.getName() + intfMethod.getSignature();

            // don't generate delegates for methods we override
            if (superSigs.contains(signature)) {
               continue;
            }

            // Ignore already added methods that come from other interfaces
            if (methods.contains(signature)) {
               continue;
            }

            // Track what methods we've added
            methods.add(signature);

            // Clone the method we want to inject into
            CtMethod method = CtNewMethod.copy(intfMethod, targetCt, null);

            String modifiedBody = methodBody;

            // If the super-Proxy has concrete methods (non-abstract), transform the call into a simple super.method() call
            CtMethod superMethod = superCt.getMethod(intfMethod.getName(), intfMethod.getSignature());
            if ((superMethod.getModifiers() & Modifier.ABSTRACT) != Modifier.ABSTRACT && !isDefaultMethod(intf, intfMethod)) {
               modifiedBody = modifiedBody.replace(""((cast) "", """");
               modifiedBody = modifiedBody.replace(""delegate"", ""super"");
               modifiedBody = modifiedBody.replace(""super)"", ""super"");
            }

            modifiedBody = modifiedBody.replace(""cast"", primaryInterface.getName());

            // Generate a method that simply invokes the same method on the delegate
            if (isThrowsSqlException(intfMethod)) {
               modifiedBody = modifiedBody.replace(""method"", method.getName());
            }
            else {
               modifiedBody = ""{ return ((cast) delegate).method($$); }"".replace(""method"", method.getName()).replace(""cast"", primaryInterface.getName());
            }

            if (method.getReturnType() == CtClass.voidType) {
               modifiedBody = modifiedBody.replace(""return"", """");
            }

            method.setBody(modifiedBody);
            targetCt.addMethod(method);
         }
      }

      targetCt.getClassFile().setMajorVersion(ClassFile.JAVA_8);
      targetCt.writeFile(genDirectory + ""target/classes"");
   }"
"public void putFunctionForId(String id, DifferentialFunction function) {
        if (ops.containsKey(id) && ops.get(id).getOp() == null) {
            throw new ND4JIllegalStateException(""Function by id already exists!"");
        } else if (function instanceof SDVariable) {
            throw new ND4JIllegalStateException(""Function must not be a variable!"");
        }

        if(ops.containsKey(id)){

        } else {
            ops.put(id, SameDiffOp.builder().name(id).op(function).build());
        }
    }"
"private void overrideLocalCanalConfig(String content) {
        try (FileWriter writer = new FileWriter(CommonUtils.getConfPath() + ""canal.properties"")) {
            writer.write(content);
            writer.flush();
        } catch (Exception e) {
            logger.error(e.getMessage(), e);
        }
    }"
"public static String resolve(String originalHost) {
        String currentHost = originalHost;
        if (isLocalOrIp(currentHost)) {
            return originalHost;
        }
        try {
            String targetHost = null;
            do {
                Attributes attrs = getDirContext().getAttributes(currentHost, new String[]{A_RECORD_TYPE, CNAME_RECORD_TYPE});
                Attribute attr = attrs.get(A_RECORD_TYPE);
                if (attr != null) {
                    targetHost = attr.get().toString();
                }
                attr = attrs.get(CNAME_RECORD_TYPE);
                if (attr != null) {
                    currentHost = attr.get().toString();
                } else {
                    targetHost = currentHost;
                }

            } while (targetHost == null);
            return targetHost;
        } catch (NamingException e) {
            logger.warn(""Cannot resolve eureka server address {}; returning original value {}"", currentHost, originalHost, e);
            return originalHost;
        }
    }"
"protected String resolveSpanName(HttpRequest<?> request) {
        Optional<String> route = request.getAttribute(HttpAttributes.URI_TEMPLATE, String.class);
        return route.map(s -> request.getMethod() + "" "" + s).orElse(request.getMethod() + "" "" + request.getPath());
    }"
"public void pinVisiblePanels() {
		if (layout == Layout.FULL) {
			getTabbedFull().pinVisibleTabs();
		} else {
			getTabbedSelect().pinVisibleTabs();
			getTabbedWork().pinVisibleTabs();
			getTabbedStatus().pinVisibleTabs();
		}
	}"
"public HttpRequest body(String body, String contentType) {
		body(StrUtil.bytes(body, this.charset));
		this.form = null; // 当使用body时，停止form的使用
		contentLength((null != body ? body.length() : 0));

		if (null != contentType) {
			// Content-Type自定义设置
			this.contentType(contentType);
		} else {
			// 在用户未自定义的情况下自动根据内容判断
			contentType = HttpUtil.getContentTypeByRequestBody(body);
			if (null != contentType && ContentType.isDefault(this.header(Header.CONTENT_TYPE))) {
				if (null != this.charset) {
					// 附加编码信息
					contentType = ContentType.build(contentType, this.charset);
				}
				this.contentType(contentType);
			}
		}

		// 判断是否为rest请求
		if (StrUtil.containsAnyIgnoreCase(contentType, ""json"", ""xml"")) {
			this.isRest = true;
		}
		return this;
	}"
"public SqlBuilder select(boolean isDistinct, String... fields) {
		return select(isDistinct, Arrays.asList(fields));
	}"
"public static <K, V> LFUCache<K, V> newLFUCache(int capacity, long timeout){
		return new LFUCache<K, V>(capacity, timeout);
	}"
"public static ComputationGraph load(File f, boolean loadUpdater) throws IOException {
        return ModelSerializer.restoreComputationGraph(f, loadUpdater);
    }"
"public static Set<Policy> policies(Config config, EvictionPolicy policy) {
    BasicSettings settings = new BasicSettings(config);
    return settings.admission().stream().map(admission ->
      new FrequentlyUsedPolicy(admission, policy, config)
    ).collect(toSet());
  }"
"@VisibleForTesting
    String[] findClassNames(AbstractConfiguration config) {

        // Find individually-specified filter classes.
        String[] filterClassNamesStrArray = config.getStringArray(""zuul.filters.classes"");
        Stream<String> classNameStream = Arrays.stream(filterClassNamesStrArray)
                .map(String::trim)
                .filter(blank.negate());

        // Find filter classes in specified packages.
        String[] packageNamesStrArray = config.getStringArray(""zuul.filters.packages"");
        ClassPath cp;
        try {
            cp = ClassPath.from(this.getClass().getClassLoader());
        }
        catch (IOException e) {
            throw new RuntimeException(""Error attempting to read classpath to find filters!"", e);
        }
        Stream<String> packageStream = Arrays.stream(packageNamesStrArray)
                .map(String::trim)
                .filter(blank.negate())
                .flatMap(packageName -> cp.getTopLevelClasses(packageName).stream())
                .map(ClassPath.ClassInfo::load)
                .filter(ZuulFilter.class::isAssignableFrom)
                .map(Class::getCanonicalName);


        String[] filterClassNames = Stream.concat(classNameStream, packageStream).toArray(String[]::new);
        if (filterClassNames.length != 0) {
            LOG.info(""Using filter classnames: "");
            for (String location : filterClassNames) {
                LOG.info(""  "" + location);
            }
        }

        return filterClassNames;
    }"
"public static Set<Annotation> getAllAnnotations(final Class<?> cls) {
		List<Class<?>> allTypes = ClassUtil.getAllSuperclasses(cls);
		allTypes.addAll(ClassUtil.getAllInterfaces(cls));
		allTypes.add(cls);

		Set<Annotation> anns = new HashSet<Annotation>();
		for (Class<?> type : allTypes) {
			anns.addAll(Arrays.asList(type.getDeclaredAnnotations()));
		}

		Set<Annotation> superAnnotations = new HashSet<Annotation>();
		for (Annotation ann : anns) {
			getSuperAnnotations(ann.annotationType(), superAnnotations);
		}

		anns.addAll(superAnnotations);

		return anns;
	}"
"public static File zip(File zipFile, String[] paths, InputStream[] ins) throws UtilException {
		return zip(zipFile, paths, ins, DEFAULT_CHARSET);
	}"
"protected ByteBuf allocateBuffer(ChannelHandlerContext ctx, @SuppressWarnings(""unused"") I msg,
                               boolean preferDirect) throws Exception {
        if (preferDirect) {
            return ctx.alloc().ioBuffer();
        } else {
            return ctx.alloc().heapBuffer();
        }
    }"
"protected SofaRpcException convertToRpcException(Exception e) {
        SofaRpcException exception;
        if (e instanceof SofaRpcException) {
            exception = (SofaRpcException) e;
        }
        // 超时
        else if (e instanceof InvokeTimeoutException) {
            exception = new SofaTimeOutException(e);
        }
        // 服务器忙
        else if (e instanceof InvokeServerBusyException) {
            exception = new SofaRpcException(RpcErrorType.SERVER_BUSY, e);
        }
        // 序列化
        else if (e instanceof SerializationException) {
            boolean isServer = ((SerializationException) e).isServerSide();
            exception = isServer ? new SofaRpcException(RpcErrorType.SERVER_SERIALIZE, e)
                : new SofaRpcException(RpcErrorType.CLIENT_SERIALIZE, e);
        }
        // 反序列化
        else if (e instanceof DeserializationException) {
            boolean isServer = ((DeserializationException) e).isServerSide();
            exception = isServer ? new SofaRpcException(RpcErrorType.SERVER_DESERIALIZE, e)
                : new SofaRpcException(RpcErrorType.CLIENT_DESERIALIZE, e);
        }
        // 长连接断连
        else if (e instanceof ConnectionClosedException) {
            exception = new SofaRpcException(RpcErrorType.CLIENT_NETWORK, e);
        }
        // 客户端发送失败
        else if (e instanceof InvokeSendFailedException) {
            exception = new SofaRpcException(RpcErrorType.CLIENT_NETWORK, e);
        }
        // 服务端未知异常
        else if (e instanceof InvokeServerException) {
            exception = new SofaRpcException(RpcErrorType.SERVER_UNDECLARED_ERROR, e.getCause());
        }
        // 客户端未知
        else {
            exception = new SofaRpcException(RpcErrorType.CLIENT_UNDECLARED_ERROR, e);
        }
        return exception;
    }"
"private static String credentialMD5digest(String password) {
    try {
      byte[] digest;
      synchronized (__md5Lock) {
        if (__md == null) {
          try {
            __md = MessageDigest.getInstance(""MD5"");
          } catch (Exception e) {
            throw new IllegalStateException(e);
          }
        }

        __md.reset();
        __md.update(password.getBytes(StandardCharsets.ISO_8859_1));
        digest = __md.digest();
      }

      return __TYPE + toString(digest, 16);
    } catch (Exception e) {
      throw new IllegalStateException(e);
    }
  }"
"@EventListener
    public void logServiceTicketGrantedEvent(final CasServiceTicketGrantedEvent e) {
        LOGGER.debug(CREATED_ST_MSG,
                e.getServiceTicket().getCreationTime(),
                e.getServiceTicket().getId(),
                e.getServiceTicket().getService().getId(),
                e.getTicketGrantingTicket().getAuthentication().getPrincipal().getId());
    }"
"public boolean set(final Object value) {

        AccessibilityChanger changer = new AccessibilityChanger();
        Method writeMethod = null;
        try {
            writeMethod = target.getClass().getMethod(setterName(field.getName()), field.getType());

            changer.enableAccess(writeMethod);
            writeMethod.invoke(target, value);
            return true;
        } catch (InvocationTargetException e) {
            throw new RuntimeException(""Setter '"" + writeMethod + ""' of '"" + target + ""' with value '"" + value + ""' threw exception : '"" + e.getTargetException() + ""'"", e);
        } catch (IllegalAccessException e) {
            throw new RuntimeException(""Access not authorized on field '"" + field + ""' of object '"" + target + ""' with value: '"" + value + ""'"", e);
        } catch (NoSuchMethodException e) {
            reportNoSetterFound();
        } finally {
            if(writeMethod != null) {
                changer.safelyDisableAccess(writeMethod);
            }
        }

        reportNoSetterFound();
        return false;
    }"
"static void requireState(boolean expression, String template, @Nullable Object... args) {
    if (!expression) {
      throw new IllegalStateException(String.format(template, args));
    }
  }"
"public boolean next() throws SQLException {
        boolean result = queryResult.next();
        orderValues = result ? getOrderValues() : Collections.<Comparable<?>>emptyList();
        return result;
    }"
"public static INDArray pca(INDArray A, double variance, boolean normalize) {
        INDArray factor = pca_factor(A, variance, normalize);
        return A.mmul(factor);
    }"
"public static List<String> readLines(String path, String charset) throws IORuntimeException {
		return readLines(path, charset, new ArrayList<String>());
	}"
"public void append(final CharArrayBuffer b, final int off, final int len) {
        if (b == null) {
            return;
        }
        append(b.array, off, len);
    }"
"@com.netflix.servo.annotations.Monitor(name = ""numOfElementsinASGCache"",
            description = ""Number of elements in the ASG Cache"", type = DataSourceType.GAUGE)
    public long getNumberofElementsinASGCache() {
        return asgCache.size();
    }"
"public static boolean isPrimes(int n) {
		Assert.isTrue(n > 1, ""The number must be > 1"");
		for (int i = 2; i <= Math.sqrt(n); i++) {
			if (n % i == 0) {
				return false;
			}
		}
		return true;
	}"
"public static Set<Class<?>> scanPackageBySuper(String packageName, final Class<?> superClass) {
		return ClassScaner.scanPackageBySuper(packageName, superClass);
	}"
"public void addStateChangeListener(StateChangeListener<T> stateChangeListener)
    {
        requireNonNull(stateChangeListener, ""stateChangeListener is null"");

        boolean inTerminalState;
        T currentState;
        synchronized (lock) {
            currentState = state;
            inTerminalState = isTerminalState(currentState);
            if (!inTerminalState) {
                stateChangeListeners.add(stateChangeListener);
            }
        }

        // fire state change listener with the current state
        // always fire listener callbacks from a different thread
        safeExecute(() -> stateChangeListener.stateChanged(currentState));
    }"
"public Proxy setHttpProxy(String httpProxy) {
    verifyProxyTypeCompatibility(ProxyType.MANUAL);
    this.proxyType = ProxyType.MANUAL;
    this.httpProxy = httpProxy;
    return this;
  }"
"public static <T> void writeSerializer(DataOutputView out, TypeSerializer<T> serializer) throws IOException {
		new TypeSerializerSerializationUtil.TypeSerializerSerializationProxy<>(serializer).write(out);
	}"
"public static File[] getHadoopDependencyFilesToLoad(
      List<String> hadoopDependencyCoordinates,
      ExtensionsConfig extensionsConfig
  )
  {
    final File rootHadoopDependenciesDir = new File(extensionsConfig.getHadoopDependenciesDir());
    if (rootHadoopDependenciesDir.exists() && !rootHadoopDependenciesDir.isDirectory()) {
      throw new ISE(""Root Hadoop dependencies directory [%s] is not a directory!?"", rootHadoopDependenciesDir);
    }
    final File[] hadoopDependenciesToLoad = new File[hadoopDependencyCoordinates.size()];
    int i = 0;
    for (final String coordinate : hadoopDependencyCoordinates) {
      final DefaultArtifact artifact = new DefaultArtifact(coordinate);
      final File hadoopDependencyDir = new File(rootHadoopDependenciesDir, artifact.getArtifactId());
      final File versionDir = new File(hadoopDependencyDir, artifact.getVersion());
      // find the hadoop dependency with the version specified in coordinate
      if (!hadoopDependencyDir.isDirectory() || !versionDir.isDirectory()) {
        throw new ISE(""Hadoop dependency [%s] didn't exist!?"", versionDir.getAbsolutePath());
      }
      hadoopDependenciesToLoad[i++] = versionDir;
    }
    return hadoopDependenciesToLoad;
  }"
"public synchronized ListenableFuture<?> reserve(long bytes)
    {
        checkArgument(bytes >= 0, ""bytes is negative"");

        if ((currentBytes + bytes) >= maxBytes) {
            throw exceededLocalLimit(succinctBytes(maxBytes));
        }
        currentBytes += bytes;

        return NOT_BLOCKED;
    }"
"private static String addLineNumber(String code) {
		String[] lines = code.split(""\n"");
		StringBuilder builder = new StringBuilder();
		for (int i = 0; i < lines.length; i++) {
			builder.append(""/* "").append(i + 1).append("" */"").append(lines[i]).append(""\n"");
		}
		return builder.toString();
	}"
"private void readBooleanBatch(int rowId, int num, WritableColumnVector column)
      throws IOException {
    if (column.dataType() != DataTypes.BooleanType) {
      throw constructConvertNotSupportedException(descriptor, column);
    }
    defColumn.readBooleans(
        num, column, rowId, maxDefLevel, (VectorizedValuesReader) dataColumn);
  }"
"private static JsonParserIterator<TaskStatusPlus> getTasks(
      DruidLeaderClient indexingServiceClient,
      ObjectMapper jsonMapper,
      BytesAccumulatingResponseHandler responseHandler
  )
  {
    Request request;
    try {
      request = indexingServiceClient.makeRequest(
          HttpMethod.GET,
          StringUtils.format(""/druid/indexer/v1/tasks""),
          false
      );
    }
    catch (IOException e) {
      throw new RuntimeException(e);
    }
    ListenableFuture<InputStream> future = indexingServiceClient.goAsync(
        request,
        responseHandler
    );

    final JavaType typeRef = jsonMapper.getTypeFactory().constructType(new TypeReference<TaskStatusPlus>()
    {
    });
    return new JsonParserIterator<>(
        typeRef,
        future,
        request.getUrl().toString(),
        null,
        request.getUrl().getHost(),
        jsonMapper,
        responseHandler
    );
  }"
"public JavaVisitorContext newVisitorContext() {
        return new JavaVisitorContext(
                processingEnv,
                messager,
                elementUtils,
                this,
                types,
                modelUtils,
                filer,
                visitorAttributes
        );
    }"
"public MockResponse throttleBody(long bytesPerPeriod, long period, TimeUnit unit) {
    this.throttleBytesPerPeriod = bytesPerPeriod;
    this.throttlePeriodAmount = period;
    this.throttlePeriodUnit = unit;
    return this;
  }"
"private static BufferedImage draw(BufferedImage backgroundImg, Image img, Rectangle rectangle, float alpha) {
		final Graphics2D g = backgroundImg.createGraphics();
		g.setComposite(AlphaComposite.getInstance(AlphaComposite.SRC_ATOP, alpha));
		g.drawImage(img, rectangle.x, rectangle.y, rectangle.width, rectangle.height, null); // 绘制切割后的图
		g.dispose();
		return backgroundImg;
	}"
"public static List<Integer> sequence(final int start, int end, final int step) {

        final int size = (end-start)/step;
        if(size<0)  throw new IllegalArgumentException(""List size is negative"");

        return new AbstractList<Integer>() {
            public Integer get(int index) {
                if(index<0 || index>=size)
                    throw new IndexOutOfBoundsException();
                return start+index*step;
            }

            public int size() {
                return size;
            }
        };
    }"
"public void setScanFuzzerMessages(boolean scanFuzzerMessages) {
        this.scanFuzzerMessages = scanFuzzerMessages;
        getConfig().setProperty(SCAN_FUZZER_MESSAGES_KEY, scanFuzzerMessages);
        setFuzzerOptin(scanFuzzerMessages);
    }"
"public void validate(final ValidationContext context) {
        if (!isValid()) {
            val messages = context.getMessageContext();
            messages.addMessage(new MessageBuilder()
                .error()
                .source(""token"")
                .defaultText(""Unable to accept credential with an empty or unspecified token"")
                .build());
        }
    }"
"public static Map<String, SessionLogs> getSessionLogs(Map<String, Object> rawSessionMap) {
    Map<String, SessionLogs> sessionLogsMap = new HashMap<>();
    for (Map.Entry<String, Object> entry : rawSessionMap.entrySet()) {
      String sessionId = entry.getKey();
      if (!(entry.getValue() instanceof Map)) {
        throw new InvalidArgumentException(""Expected value to be an object: "" + entry.getValue());
      }
      @SuppressWarnings(""unchecked"")
      Map<String, Object> value = (Map<String, Object>) entry.getValue();
      SessionLogs sessionLogs = SessionLogs.fromJSON(value);
      sessionLogsMap.put(sessionId, sessionLogs);
    }
    return sessionLogsMap;
  }"
"public static KerasLayer getKerasLayerFromConfig(Map<String, Object> layerConfig,
                                                     boolean enforceTrainingConfig,
                                                     KerasLayerConfiguration conf,
                                                     Map<String, Class<? extends KerasLayer>> customLayers,
                                                     Map<String, SameDiffLambdaLayer> lambdaLayers,
                                                     Map<String, ? extends KerasLayer> previousLayers
    )
            throws InvalidKerasConfigurationException, UnsupportedKerasConfigurationException {
        String layerClassName = getClassNameFromConfig(layerConfig, conf);
        if (layerClassName.equals(conf.getLAYER_CLASS_NAME_TIME_DISTRIBUTED())) {
            layerConfig = getTimeDistributedLayerConfig(layerConfig, conf);
            layerClassName = getClassNameFromConfig(layerConfig, conf);
        }

        KerasLayer layer = null;
        if (layerClassName.equals(conf.getLAYER_CLASS_NAME_ACTIVATION())) {
            layer = new KerasActivation(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_LEAKY_RELU())) {
            layer = new KerasLeakyReLU(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_MASKING())) {
            layer = new KerasMasking(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_THRESHOLDED_RELU())) {
            layer = new KerasThresholdedReLU(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_PRELU())) {
            layer = new KerasPReLU(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_DROPOUT())) {
            layer = new KerasDropout(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_SPATIAL_DROPOUT_1D())
                || layerClassName.equals(conf.getLAYER_CLASS_NAME_SPATIAL_DROPOUT_2D())
                || layerClassName.equals(conf.getLAYER_CLASS_NAME_SPATIAL_DROPOUT_3D())) {
            layer = new KerasSpatialDropout(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_ALPHA_DROPOUT())) {
            layer = new KerasAlphaDropout(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_GAUSSIAN_DROPOUT())) {
            layer = new KerasGaussianDropout(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_GAUSSIAN_NOISE())) {
            layer = new KerasGaussianNoise(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_DENSE()) ||
                layerClassName.equals(conf.getLAYER_CLASS_NAME_TIME_DISTRIBUTED_DENSE())) {
            layer = new KerasDense(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_BIDIRECTIONAL())) {
            layer = new KerasBidirectional(layerConfig, enforceTrainingConfig, previousLayers);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_LSTM())) {
            layer = new KerasLSTM(layerConfig, enforceTrainingConfig, previousLayers);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_SIMPLE_RNN())) {
            layer = new KerasSimpleRnn(layerConfig, enforceTrainingConfig, previousLayers);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_CONVOLUTION_3D())) {
            layer = new KerasConvolution3D(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_CONVOLUTION_2D())) {
            layer = new KerasConvolution2D(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_DECONVOLUTION_2D())) {
            layer = new KerasDeconvolution2D(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_CONVOLUTION_1D())) {
            layer = new KerasConvolution1D(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_ATROUS_CONVOLUTION_2D())) {
            layer = new KerasAtrousConvolution2D(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_ATROUS_CONVOLUTION_1D())) {
            layer = new KerasAtrousConvolution1D(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_DEPTHWISE_CONVOLUTION_2D())) {
            layer = new KerasDepthwiseConvolution2D(layerConfig, previousLayers, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_SEPARABLE_CONVOLUTION_2D())) {
            layer = new KerasSeparableConvolution2D(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_MAX_POOLING_3D()) ||
                layerClassName.equals(conf.getLAYER_CLASS_NAME_AVERAGE_POOLING_3D())) {
            layer = new KerasPooling3D(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_MAX_POOLING_2D()) ||
                layerClassName.equals(conf.getLAYER_CLASS_NAME_AVERAGE_POOLING_2D())) {
            layer = new KerasPooling2D(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_MAX_POOLING_1D()) ||
                layerClassName.equals(conf.getLAYER_CLASS_NAME_AVERAGE_POOLING_1D())) {
            layer = new KerasPooling1D(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_GLOBAL_AVERAGE_POOLING_1D()) ||
                layerClassName.equals(conf.getLAYER_CLASS_NAME_GLOBAL_AVERAGE_POOLING_2D()) ||
                layerClassName.equals(conf.getLAYER_CLASS_NAME_GLOBAL_AVERAGE_POOLING_3D()) ||
                layerClassName.equals(conf.getLAYER_CLASS_NAME_GLOBAL_MAX_POOLING_1D()) ||
                layerClassName.equals(conf.getLAYER_CLASS_NAME_GLOBAL_MAX_POOLING_2D()) ||
                layerClassName.equals(conf.getLAYER_CLASS_NAME_GLOBAL_MAX_POOLING_3D())) {
            layer = new KerasGlobalPooling(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_BATCHNORMALIZATION())) {
            layer = new KerasBatchNormalization(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_EMBEDDING())) {
            layer = new KerasEmbedding(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_INPUT())) {
            layer = new KerasInput(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_REPEAT())) {
            layer = new KerasRepeatVector(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_PERMUTE())) {
            layer = new KerasPermute(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_MERGE())) {
            layer = new KerasMerge(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_ADD()) ||
                layerClassName.equals(conf.getLAYER_CLASS_NAME_ADD())) {
            layer = new KerasMerge(layerConfig, ElementWiseVertex.Op.Add, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_SUBTRACT()) ||
                layerClassName.equals(conf.getLAYER_CLASS_NAME_FUNCTIONAL_SUBTRACT())) {
            layer = new KerasMerge(layerConfig, ElementWiseVertex.Op.Subtract, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_AVERAGE()) ||
                layerClassName.equals(conf.getLAYER_CLASS_NAME_FUNCTIONAL_AVERAGE())) {
            layer = new KerasMerge(layerConfig, ElementWiseVertex.Op.Average, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_MULTIPLY()) ||
                layerClassName.equals(conf.getLAYER_CLASS_NAME_FUNCTIONAL_MULTIPLY())) {
            layer = new KerasMerge(layerConfig, ElementWiseVertex.Op.Product, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_CONCATENATE()) ||
                layerClassName.equals(conf.getLAYER_CLASS_NAME_FUNCTIONAL_CONCATENATE())) {
            layer = new KerasMerge(layerConfig, null, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_FLATTEN())) {
            layer = new KerasFlatten(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_RESHAPE())) {
            layer = new KerasReshape(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_ZERO_PADDING_1D())) {
            layer = new KerasZeroPadding1D(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_ZERO_PADDING_2D())) {
            layer = new KerasZeroPadding2D(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_ZERO_PADDING_3D())) {
            layer = new KerasZeroPadding3D(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_UPSAMPLING_1D())) {
            layer = new KerasUpsampling1D(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_UPSAMPLING_2D())) {
            layer = new KerasUpsampling2D(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_CROPPING_3D())) {
            layer = new KerasCropping3D(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_CROPPING_2D())) {
            layer = new KerasCropping2D(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_CROPPING_1D())) {
            layer = new KerasCropping1D(layerConfig, enforceTrainingConfig);
        } else if (layerClassName.equals(conf.getLAYER_CLASS_NAME_LAMBDA())) {
            String lambdaLayerName = KerasLayerUtils.getLayerNameFromConfig(layerConfig, conf);
            if (!lambdaLayers.containsKey(lambdaLayerName) && !customLayers.containsKey(layerClassName)){
                throw new UnsupportedKerasConfigurationException(""No SameDiff Lambda layer found for Lambda "" +
                        ""layer "" + lambdaLayerName + "". You can register a SameDiff Lambda layer using KerasLayer."" +
                        ""registerLambdaLayer(lambdaLayerName, sameDiffLambdaLayer);"");
            }
            SameDiffLambdaLayer lambdaLayer = lambdaLayers.get(lambdaLayerName);
            if (lambdaLayer != null){
                layer = new KerasLambda(layerConfig, enforceTrainingConfig, lambdaLayer);
            }
        }
        if (layer == null){
            Class<? extends KerasLayer> customConfig = customLayers.get(layerClassName);
            if (customConfig == null)
                throw new UnsupportedKerasConfigurationException(""Unsupported keras layer type "" + layerClassName);
            try {
                Constructor constructor = customConfig.getConstructor(Map.class);
                layer = (KerasLayer) constructor.newInstance(layerConfig);
            } catch (Exception e) {
                throw new RuntimeException(e);
            }
        }
        return layer;
    }"
"public void fit(INDArray x) {
        this.data = x;
        for(int i = 0; i < numTrees; i++) {
            RPTree tree = new RPTree(data.columns(),maxSize,similarityFunction);
            tree.buildTree(x);
            trees.add(tree);
        }
    }"
"@Override
  public void closeSession(SessionHandle sessionHandle)
      throws HiveSQLException {
    sessionManager.closeSession(sessionHandle);
    LOG.debug(sessionHandle + "": closeSession()"");
  }"
"private byte[] digestWithoutSalt(InputStream data, int bufferLength) throws IOException {
		final byte[] buffer = new byte[bufferLength];
		int read;
		while ((read = data.read(buffer, 0, bufferLength)) > -1) {
			this.digest.update(buffer, 0, read);
		}
		return this.digest.digest();
	}"
"public void runMain(String[] args) {
        server = StatusServer.startServer(new InMemoryStatusStorage(), statusPort);
        if (mediaDriver == null)
            mediaDriver = MediaDriver.launchEmbedded();
        log.info(""Started media driver with aeron directory "" + mediaDriver.aeronDirectoryName());
        //cache a reference to the first listener.
        //The reason we do this is to share an updater and listener across *all* subscribers
        //This will create a shared pool of subscribers all updating the same ""server"".
        //This will simulate a shared pool but allow an accumulative effect of anything
        //like averaging we try.
        NDArrayCallback parameterServerListener = null;
        ParameterServerListener cast = null;
        for (int i = 0; i < numWorkers; i++) {
            subscriber[i] = new ParameterServerSubscriber(mediaDriver);
            //ensure reuse of aeron wherever possible
            if (aeron == null)
                aeron = Aeron.connect(getContext(mediaDriver));
            subscriber[i].setAeron(aeron);
            List<String> multiArgs = new ArrayList<>(Arrays.asList(args));
            if (multiArgs.contains(""-id"")) {
                int streamIdIdx = multiArgs.indexOf(""-id"") + 1;
                int streamId = Integer.parseInt(multiArgs.get(streamIdIdx)) + i;
                multiArgs.set(streamIdIdx, String.valueOf(streamId));
            } else if (multiArgs.contains(""--streamId"")) {
                int streamIdIdx = multiArgs.indexOf(""--streamId"") + 1;
                int streamId = Integer.parseInt(multiArgs.get(streamIdIdx)) + i;
                multiArgs.set(streamIdIdx, String.valueOf(streamId));
            }


            if (i == 0) {
                subscriber[i].run(multiArgs.toArray(new String[args.length]));
                parameterServerListener = subscriber[i].getCallback();
                cast = subscriber[i].getParameterServerListener();
            } else {
                //note that we set both the callback AND the listener here
                subscriber[i].setCallback(parameterServerListener);
                subscriber[i].setParameterServerListener(cast);
                //now run the callback initialized with this callback instead
                //in the run method it will use this reference instead of creating it
                //itself
                subscriber[i].run(multiArgs.toArray(new String[args.length]));
            }


        }

    }"
"private static int getDataport(Configuration configuration) {
		final int dataport = configuration.getInteger(TaskManagerOptions.DATA_PORT);
		ConfigurationParserUtils.checkConfigParameter(dataport >= 0, dataport, TaskManagerOptions.DATA_PORT.key(),
			""Leave config parameter empty or use 0 to let the system choose a port automatically."");

		return dataport;
	}"
"final int awaitJoin(WorkQueue joiner, ForkJoinTask<?> task) {
        int s;
        if ((s = task.status) >= 0) {
            ForkJoinTask<?> prevJoin = joiner.currentJoin;
            joiner.currentJoin = task;
            long startTime = 0L;
            for (int k = 0;;) {
                if ((s = (joiner.isEmpty() ?           // try to help
                          tryHelpStealer(joiner, task) :
                          joiner.tryRemoveAndExec(task))) == 0 &&
                    (s = task.status) >= 0) {
                    if (k == 0) {
                        startTime = System.nanoTime();
                        tryPollForAndExec(joiner, task); // check uncommon case
                    }
                    else if ((k & (MAX_HELP - 1)) == 0 &&
                             System.nanoTime() - startTime >=
                             COMPENSATION_DELAY &&
                             tryCompensate(task, null)) {
                        if (task.trySetSignal()) {
                            synchronized (task) {
                                if (task.status >= 0) {
                                    try {                // see ForkJoinTask
                                        task.wait();     //  for explanation
                                    } catch (InterruptedException ie) {
                                    }
                                }
                                else
                                    task.notifyAll();
                            }
                        }
                        long c;                          // re-activate
                        do {} while (!U.compareAndSwapLong
                                     (this, CTL, c = ctl, c + AC_UNIT));
                    }
                }
                if (s < 0 || (s = task.status) < 0) {
                    joiner.currentJoin = prevJoin;
                    break;
                }
                else if ((k++ & (MAX_HELP - 1)) == MAX_HELP >>> 1)
                    Thread.yield();                     // for politeness
            }
        }
        return s;
    }"
"static public String doubleToString(double d) {
    if (Double.isInfinite(d) || Double.isNaN(d)) {
      return ""null"";
    }

    // Shave off trailing zeros and decimal point, if possible.

    String s = Double.toString(d);
    if (s.indexOf('.') > 0 && s.indexOf('e') < 0 && s.indexOf('E') < 0) {
      while (s.endsWith(""0"")) {
        s = s.substring(0, s.length() - 1);
      }
      if (s.endsWith(""."")) {
        s = s.substring(0, s.length() - 1);
      }
    }
    return s;
  }"
"static SocketChannelUDT newConnectorChannelUDT(final TypeUDT type) {
        try {
            return SelectorProviderUDT.from(type).openSocketChannel();
        } catch (final IOException e) {
            throw new ChannelException(""failed to open a socket channel"", e);
        }
    }"
"@Deprecated
    public E set(int index, E element) {
        return responses.set(index, element);
    }"
"@Override
	public final MutableObjectIterator<T> getIterator() {
		return new MutableObjectIterator<T>()
		{
			private final int size = size();
			private int current = 0;
			
			private int currentSegment = 0;
			private int currentOffset = 0;
			
			private MemorySegment currentIndexSegment = sortIndex.get(0);

			@Override
			public T next(T target) {
				if (this.current < this.size) {
					this.current++;
					if (this.currentOffset > lastIndexEntryOffset) {
						this.currentOffset = 0;
						this.currentIndexSegment = sortIndex.get(++this.currentSegment);
					}
					
					long pointer = this.currentIndexSegment.getLong(this.currentOffset) & POINTER_MASK;
					this.currentOffset += indexEntrySize;
					
					try {
						return getRecordFromBuffer(target, pointer);
					}
					catch (IOException ioe) {
						throw new RuntimeException(ioe);
					}
				}
				else {
					return null;
				}
			}

			@Override
			public T next()
			{
				if (this.current < this.size) {
					this.current++;
					if (this.currentOffset > lastIndexEntryOffset) {
						this.currentOffset = 0;
						this.currentIndexSegment = sortIndex.get(++this.currentSegment);
					}

					long pointer = this.currentIndexSegment.getLong(this.currentOffset);
					this.currentOffset += indexEntrySize;

					try {
						return getRecordFromBuffer(pointer);
					}
					catch (IOException ioe) {
						throw new RuntimeException(ioe);
					}
				}
				else {
					return null;
				}
			}
		};
	}"
"private WeightBuckets<EventData> buildWeightBuckets(DbLoadContext context, List<EventData> datas) {
        WeightBuckets<EventData> buckets = new WeightBuckets<EventData>();
        for (EventData data : datas) {
            // 获取对应的weight
            DataMediaPair pair = ConfigHelper.findDataMediaPair(context.getPipeline(), data.getPairId());
            buckets.addItem(pair.getPushWeight(), data);
        }

        return buckets;
    }"
"public static String urlDecode(String part) {
		try {
			return URLDecoder.decode(part, Charsets.UTF_8_NAME);
		} catch (UnsupportedEncodingException e) { // NOSONAR
			// this exception is only for detecting and handling invalid inputs
			return null;
		}
	}"
"protected String resolveArtifactId() {
		if (this.artifactId != null) {
			return this.artifactId;
		}
		if (this.output != null) {
			int i = this.output.lastIndexOf('.');
			return (i != -1) ? this.output.substring(0, i) : this.output;
		}
		return null;
	}"
"public void merge(StandaloneConfiguration other) {
    if (other == null) {
      return;
    }

    if (isMergeAble(Integer.class, other.browserTimeout, browserTimeout)) {
      browserTimeout = other.browserTimeout;
    }
    if (isMergeAble(Integer.class, other.jettyMaxThreads, jettyMaxThreads)) {
      jettyMaxThreads = other.jettyMaxThreads;
    }
    if (isMergeAble(Integer.class, other.timeout, timeout)) {
      timeout = other.timeout;
    }
    // role, host, port, log, debug, version, enablePassThrough, and help are not merged,
    // they are only consumed by the immediately running process and should never affect a remote
  }"
"public Set<Map.Entry<Long,TypeV>> entrySet() {
    return new AbstractSet<Map.Entry<Long,TypeV>>() {
      public void    clear   (          ) {        NonBlockingHashMapLong.this.clear( ); }
      public int     size    (          ) { return NonBlockingHashMapLong.this.size ( ); }
      public boolean remove( final Object o ) {
        if (!(o instanceof Map.Entry)) return false;
        final Map.Entry<?,?> e = (Map.Entry<?,?>)o;
        return NonBlockingHashMapLong.this.remove(e.getKey(), e.getValue());
      }
      public boolean contains(final Object o) {
        if (!(o instanceof Map.Entry)) return false;
        final Map.Entry<?,?> e = (Map.Entry<?,?>)o;
        TypeV v = get(e.getKey());
        return v.equals(e.getValue());
      }
      public Iterator<Map.Entry<Long,TypeV>> iterator() { return new SnapshotE(); }
    };
  }"
"private static Object[] extractExtendedFeatures(Configuration configuration, int length)
    {
        Object[] featureMap = new Object[length];

        State state = configuration.state;
        Sentence sentence = configuration.sentence;

        int b0Position = 0;
        int b1Position = 0;
        int b2Position = 0;
        int s0Position = 0;

        long svr = 0; // stack right valency
        long svl = 0; // stack left valency
        long bvl = 0; // buffer left valency

        long b0w = 0;
        long b0p = 0;

        long b1w = 0;
        long b1p = 0;

        long b2w = 0;
        long b2p = 0;

        long s0w = 0;
        long s0p = 0;
        long s0l = 0;

        long bl0p = 0;
        long bl0w = 0;
        long bl0l = 0;

        long bl1w = 0;
        long bl1p = 0;
        long bl1l = 0;

        long sr0p = 0;
        long sr0w = 0;
        long sr0l = 0;

        long sh0w = 0;
        long sh0p = 0;
        long sh0l = 0;

        long sl0p = 0;
        long sl0w = 0;
        long sl0l = 0;

        long sr1w = 0;
        long sr1p = 0;
        long sr1l = 0;

        long sh1w = 0;
        long sh1p = 0;

        long sl1w = 0;
        long sl1p = 0;
        long sl1l = 0;

        long sdl = 0;
        long sdr = 0;
        long bdl = 0;

        int[] words = sentence.getWords();
        int[] tags = sentence.getTags();

        if (0 < state.bufferSize())
        {
            b0Position = state.bufferHead();
            b0w = b0Position == 0 ? 0 : words[b0Position - 1];
            b0w += 2;
            b0p = b0Position == 0 ? 0 : tags[b0Position - 1];
            b0p += 2;
            bvl = state.leftValency(b0Position);

            int leftMost = state.leftMostModifier(state.getBufferItem(0));
            if (leftMost >= 0)
            {
                bl0p = leftMost == 0 ? 0 : tags[leftMost - 1];
                bl0p += 2;
                bl0w = leftMost == 0 ? 0 : words[leftMost - 1];
                bl0w += 2;
                bl0l = state.getDependent(leftMost);
                bl0l += 2;

                int l2 = state.leftMostModifier(leftMost);
                if (l2 >= 0)
                {
                    bl1w = l2 == 0 ? 0 : words[l2 - 1];
                    bl1w += 2;
                    bl1p = l2 == 0 ? 0 : tags[l2 - 1];
                    bl1p += 2;
                    bl1l = state.getDependent(l2);
                    bl1l += 2;
                }
            }

            if (1 < state.bufferSize())
            {
                b1Position = state.getBufferItem(1);
                b1w = b1Position == 0 ? 0 : words[b1Position - 1];
                b1w += 2;
                b1p = b1Position == 0 ? 0 : tags[b1Position - 1];
                b1p += 2;

                if (2 < state.bufferSize())
                {
                    b2Position = state.getBufferItem(2);

                    b2w = b2Position == 0 ? 0 : words[b2Position - 1];
                    b2w += 2;
                    b2p = b2Position == 0 ? 0 : tags[b2Position - 1];
                    b2p += 2;
                }
            }
        }

        if (0 < state.stackSize())
        {
            s0Position = state.stackTop();
            s0w = s0Position == 0 ? 0 : words[s0Position - 1];
            s0w += 2;
            s0p = s0Position == 0 ? 0 : tags[s0Position - 1];
            s0p += 2;
            s0l = state.getDependent(s0Position);
            s0l += 2;

            svl = state.leftValency(s0Position);
            svr = state.rightValency(s0Position);

            int leftMost = state.leftMostModifier(s0Position);
            if (leftMost >= 0)
            {
                sl0p = leftMost == 0 ? 0 : tags[leftMost - 1];
                sl0p += 2;
                sl0w = leftMost == 0 ? 0 : words[leftMost - 1];
                sl0w += 2;
                sl0l = state.getDependent(leftMost);
                sl0l += 2;
            }

            int rightMost = state.rightMostModifier(s0Position);
            if (rightMost >= 0)
            {
                sr0p = rightMost == 0 ? 0 : tags[rightMost - 1];
                sr0p += 2;
                sr0w = rightMost == 0 ? 0 : words[rightMost - 1];
                sr0w += 2;
                sr0l = state.getDependent(rightMost);
                sr0l += 2;
            }

            int headIndex = state.getHead(s0Position);
            if (headIndex >= 0)
            {
                sh0w = headIndex == 0 ? 0 : words[headIndex - 1];
                sh0w += 2;
                sh0p = headIndex == 0 ? 0 : tags[headIndex - 1];
                sh0p += 2;
                sh0l = state.getDependent(headIndex);
                sh0l += 2;
            }

            if (leftMost >= 0)
            {
                int l2 = state.leftMostModifier(leftMost);
                if (l2 >= 0)
                {
                    sl1w = l2 == 0 ? 0 : words[l2 - 1];
                    sl1w += 2;
                    sl1p = l2 == 0 ? 0 : tags[l2 - 1];
                    sl1p += 2;
                    sl1l = state.getDependent(l2);
                    sl1l += 2;
                }
            }
            if (headIndex >= 0)
            {
                if (state.hasHead(headIndex))
                {
                    int h2 = state.getHead(headIndex);
                    sh1w = h2 == 0 ? 0 : words[h2 - 1];
                    sh1w += 2;
                    sh1p = h2 == 0 ? 0 : tags[h2 - 1];
                    sh1p += 2;
                }
            }
            if (rightMost >= 0)
            {
                int r2 = state.rightMostModifier(rightMost);
                if (r2 >= 0)
                {
                    sr1w = r2 == 0 ? 0 : words[r2 - 1];
                    sr1w += 2;
                    sr1p = r2 == 0 ? 0 : tags[r2 - 1];
                    sr1p += 2;
                    sr1l = state.getDependent(r2);
                    sr1l += 2;
                }
            }
        }
        int index = 0;

        long b0wp = b0p;
        b0wp |= (b0w << 8);
        long b1wp = b1p;
        b1wp |= (b1w << 8);
        long s0wp = s0p;
        s0wp |= (s0w << 8);
        long b2wp = b2p;
        b2wp |= (b2w << 8);

        /**
         * From single words
         */
        if (s0w != 1)
        {
            featureMap[index++] = s0wp;
            featureMap[index++] = s0w;
        }
        else
        {
            featureMap[index++] = null;
            featureMap[index++] = null;
        }
        featureMap[index++] = s0p;

        if (b0w != 1)
        {
            featureMap[index++] = b0wp;
            featureMap[index++] = b0w;
        }
        else
        {
            featureMap[index++] = null;
            featureMap[index++] = null;
        }
        featureMap[index++] = b0p;

        if (b1w != 1)
        {
            featureMap[index++] = b1wp;
            featureMap[index++] = b1w;
        }
        else
        {
            featureMap[index++] = null;
            featureMap[index++] = null;
        }
        featureMap[index++] = b1p;

        if (b2w != 1)
        {
            featureMap[index++] = b2wp;
            featureMap[index++] = b2w;
        }
        else
        {
            featureMap[index++] = null;
            featureMap[index++] = null;
        }
        featureMap[index++] = b2p;

        /**
         * from word pairs
         */
        if (s0w != 1 && b0w != 1)
        {
            featureMap[index++] = (s0wp << 28) | b0wp;
            featureMap[index++] = (s0wp << 20) | b0w;
            featureMap[index++] = (s0w << 28) | b0wp;
        }
        else
        {
            featureMap[index++] = null;
            featureMap[index++] = null;
            featureMap[index++] = null;
        }

        if (s0w != 1)
        {
            featureMap[index++] = (s0wp << 8) | b0p;
        }
        else
        {
            featureMap[index++] = null;
        }

        if (b0w != 1)
        {
            featureMap[index++] = (s0p << 28) | b0wp;
        }
        else
        {
            featureMap[index++] = null;
        }

        if (s0w != 1 && b0w != 1)
        {
            featureMap[index++] = (s0w << 20) | b0w;
        }
        else
        {
            featureMap[index++] = null;
        }
        featureMap[index++] = (s0p << 8) | b0p;
        featureMap[index++] = (b0p << 8) | b1p;

        /**
         * from three words
         */
        featureMap[index++] = (b0p << 16) | (b1p << 8) | b2p;
        featureMap[index++] = (s0p << 16) | (b0p << 8) | b1p;
        featureMap[index++] = (sh0p << 16) | (s0p << 8) | b0p;
        featureMap[index++] = (s0p << 16) | (sl0p << 8) | b0p;
        featureMap[index++] = (s0p << 16) | (sr0p << 8) | b0p;
        featureMap[index++] = (s0p << 16) | (b0p << 8) | bl0p;

        /**
         * distance
         */
        long distance = 0;
        if (s0Position > 0 && b0Position > 0)
            distance = Math.abs(b0Position - s0Position);
        if (s0w != 1)
        {
            featureMap[index++] = s0w | (distance << 20);
        }
        else
        {
            featureMap[index++] = null;
        }
        featureMap[index++] = s0p | (distance << 8);
        if (b0w != 1)
        {
            featureMap[index++] = b0w | (distance << 20);
        }
        else
        {
            featureMap[index++] = null;
        }
        featureMap[index++] = b0p | (distance << 8);
        if (s0w != 1 && b0w != 1)
        {
            featureMap[index++] = s0w | (b0w << 20) | (distance << 40);
        }
        else
        {
            featureMap[index++] = null;
        }
        featureMap[index++] = s0p | (b0p << 8) | (distance << 28);

        /**
         * Valency information
         */
        if (s0w != 1)
        {
            featureMap[index++] = s0w | (svr << 20);
        }
        else
        {
            featureMap[index++] = null;
        }
        featureMap[index++] = s0p | (svr << 8);
        if (s0w != 1)
        {
            featureMap[index++] = s0w | (svl << 20);
        }
        else
        {
            featureMap[index++] = null;
        }
        featureMap[index++] = s0p | (svl << 8);
        if (b0w != 1)
        {
            featureMap[index++] = b0w | (bvl << 20);
        }
        else
        {
            featureMap[index++] = null;
        }
        featureMap[index++] = b0p | (bvl << 8);

        /**
         * Unigrams
         */
        if (sh0w != 1)
        {
            featureMap[index++] = sh0w;
        }
        else
        {
            featureMap[index++] = null;
        }
        featureMap[index++] = sh0p;
        featureMap[index++] = s0l;
        if (sl0w != 1)
        {
            featureMap[index++] = sl0w;
        }
        else
        {
            featureMap[index++] = null;
        }
        featureMap[index++] = sl0p;
        featureMap[index++] = sl0l;
        if (sr0w != 1)
        {
            featureMap[index++] = sr0w;
        }
        else
        {
            featureMap[index++] = null;
        }
        featureMap[index++] = sr0p;
        featureMap[index++] = sr0l;
        if (bl0w != 1)
        {
            featureMap[index++] = bl0w;
        }
        else
        {
            featureMap[index++] = null;
        }
        featureMap[index++] = bl0p;
        featureMap[index++] = bl0l;

        /**
         * From third order features
         */
        if (sh1w != 1)
        {
            featureMap[index++] = sh1w;
        }
        else
        {
            featureMap[index++] = null;
        }
        featureMap[index++] = sh1p;
        featureMap[index++] = sh0l;
        if (sl1w != 1)
        {
            featureMap[index++] = sl1w;
        }
        else
        {
            featureMap[index++] = null;
        }
        featureMap[index++] = sl1p;
        featureMap[index++] = sl1l;
        if (sr1w != 1)
        {
            featureMap[index++] = sr1w;
        }
        else
        {
            featureMap[index++] = null;
        }
        featureMap[index++] = sr1p;
        featureMap[index++] = sr1l;
        if (bl1w != 1)
        {
            featureMap[index++] = bl1w;
        }
        else
        {
            featureMap[index++] = null;
        }
        featureMap[index++] = bl1p;
        featureMap[index++] = bl1l;
        featureMap[index++] = s0p | (sl0p << 8) | (sl1p << 16);
        featureMap[index++] = s0p | (sr0p << 8) | (sr1p << 16);
        featureMap[index++] = s0p | (sh0p << 8) | (sh1p << 16);
        featureMap[index++] = b0p | (bl0p << 8) | (bl1p << 16);

        /**
         * label set
         */
        if (s0Position >= 0)
        {
            sdl = state.leftDependentLabels(s0Position);
            sdr = state.rightDependentLabels(s0Position);
        }

        if (b0Position >= 0)
        {
            bdl = state.leftDependentLabels(b0Position);
        }

        if (s0w != 1)
        {
            featureMap[index++] = (s0w + ""|"" + sdr);
        }
        else
        {
            featureMap[index++] = null;
        }
        featureMap[index++] = (s0p + ""|"" + sdr);
        if (s0w != 1)
        {
            featureMap[index++] = s0w + ""|"" + sdl;
        }
        else
        {
            featureMap[index++] = null;
        }
        featureMap[index++] = (s0p + ""|"" + sdl);
        if (b0w != 1)
        {
            featureMap[index++] = (b0w + ""|"" + bdl);
        }
        else
        {
            featureMap[index++] = null;
        }
        featureMap[index++] = (b0p + ""|"" + bdl);
        return featureMap;
    }"
"public static void main(final String[] args) {
        new SpringApplicationBuilder(CasCommandLineShellApplication.class)
            .banner(new DefaultCasBanner())
            .bannerMode(Banner.Mode.CONSOLE)
            .logStartupInfo(true)
            .web(WebApplicationType.NONE)
            .run(args);
    }"
"private void initialize(Function<SqlTask, ?> onDone, CounterStat failedTasks)
    {
        requireNonNull(onDone, ""onDone is null"");
        requireNonNull(failedTasks, ""failedTasks is null"");
        taskStateMachine.addStateChangeListener(new StateChangeListener<TaskState>()
        {
            @Override
            public void stateChanged(TaskState newState)
            {
                if (!newState.isDone()) {
                    return;
                }

                // Update failed tasks counter
                if (newState == FAILED) {
                    failedTasks.update(1);
                }

                // store final task info
                while (true) {
                    TaskHolder taskHolder = taskHolderReference.get();
                    if (taskHolder.isFinished()) {
                        // another concurrent worker already set the final state
                        return;
                    }

                    if (taskHolderReference.compareAndSet(taskHolder, new TaskHolder(createTaskInfo(taskHolder), taskHolder.getIoStats()))) {
                        break;
                    }
                }

                // make sure buffers are cleaned up
                if (newState == FAILED || newState == ABORTED) {
                    // don't close buffers for a failed query
                    // closed buffers signal to upstream tasks that everything finished cleanly
                    outputBuffer.fail();
                }
                else {
                    outputBuffer.destroy();
                }

                try {
                    onDone.apply(SqlTask.this);
                }
                catch (Exception e) {
                    log.warn(e, ""Error running task cleanup callback %s"", SqlTask.this.taskId);
                }
            }
        });
    }"
"public <OUT> DataStreamSource<OUT> fromCollection(Collection<OUT> data, TypeInformation<OUT> typeInfo) {
		Preconditions.checkNotNull(data, ""Collection must not be null"");

		// must not have null elements and mixed elements
		FromElementsFunction.checkCollection(data, typeInfo.getTypeClass());

		SourceFunction<OUT> function;
		try {
			function = new FromElementsFunction<>(typeInfo.createSerializer(getConfig()), data);
		}
		catch (IOException e) {
			throw new RuntimeException(e.getMessage(), e);
		}
		return addSource(function, ""Collection Source"", typeInfo).setParallelism(1);
	}"
"@Nullable
  public static <T extends Enum<T>> T getEnumIfPresent(final Class<T> enumClass, final String value)
  {
    Preconditions.checkNotNull(enumClass, ""enumClass"");
    Preconditions.checkNotNull(value, ""value"");

    for (T enumValue : enumClass.getEnumConstants()) {
      if (enumValue.name().equals(value)) {
        return enumValue;
      }
    }

    return null;
  }"
"TaskDeploymentDescriptor createDeploymentDescriptor(
			ExecutionAttemptID executionId,
			LogicalSlot targetSlot,
			@Nullable JobManagerTaskRestore taskRestore,
			int attemptNumber) throws ExecutionGraphException {

		// Produced intermediate results
		List<ResultPartitionDeploymentDescriptor> producedPartitions = new ArrayList<>(resultPartitions.size());

		// Consumed intermediate results
		List<InputGateDeploymentDescriptor> consumedPartitions = new ArrayList<>(inputEdges.length);

		boolean lazyScheduling = getExecutionGraph().getScheduleMode().allowLazyDeployment();

		for (IntermediateResultPartition partition : resultPartitions.values()) {

			List<List<ExecutionEdge>> consumers = partition.getConsumers();

			if (consumers.isEmpty()) {
				//TODO this case only exists for test, currently there has to be exactly one consumer in real jobs!
				producedPartitions.add(ResultPartitionDeploymentDescriptor.from(
						partition,
						KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM,
						lazyScheduling));
			} else {
				Preconditions.checkState(1 == consumers.size(),
						""Only one consumer supported in the current implementation! Found: "" + consumers.size());

				List<ExecutionEdge> consumer = consumers.get(0);
				ExecutionJobVertex vertex = consumer.get(0).getTarget().getJobVertex();
				int maxParallelism = vertex.getMaxParallelism();
				producedPartitions.add(ResultPartitionDeploymentDescriptor.from(partition, maxParallelism, lazyScheduling));
			}
		}

		final InputChannelDeploymentDescriptor[] icddArray = new InputChannelDeploymentDescriptor[0];

		for (ExecutionEdge[] edges : inputEdges) {
			List<InputChannelDeploymentDescriptor> partitions = InputChannelDeploymentDescriptor.fromEdges(
				Arrays.asList(edges),
				lazyScheduling);

			// If the produced partition has multiple consumers registered, we
			// need to request the one matching our sub task index.
			// TODO Refactor after removing the consumers from the intermediate result partitions
			int numConsumerEdges = edges[0].getSource().getConsumers().get(0).size();

			int queueToRequest = subTaskIndex % numConsumerEdges;

			IntermediateResult consumedIntermediateResult = edges[0].getSource().getIntermediateResult();
			final IntermediateDataSetID resultId = consumedIntermediateResult.getId();
			final ResultPartitionType partitionType = consumedIntermediateResult.getResultType();

			consumedPartitions.add(new InputGateDeploymentDescriptor(resultId, partitionType, queueToRequest, partitions.toArray(icddArray)));
		}

		final Either<SerializedValue<JobInformation>, PermanentBlobKey> jobInformationOrBlobKey = getExecutionGraph().getJobInformationOrBlobKey();

		final TaskDeploymentDescriptor.MaybeOffloaded<JobInformation> serializedJobInformation;

		if (jobInformationOrBlobKey.isLeft()) {
			serializedJobInformation = new TaskDeploymentDescriptor.NonOffloaded<>(jobInformationOrBlobKey.left());
		} else {
			serializedJobInformation = new TaskDeploymentDescriptor.Offloaded<>(jobInformationOrBlobKey.right());
		}

		final Either<SerializedValue<TaskInformation>, PermanentBlobKey> taskInformationOrBlobKey;

		try {
			taskInformationOrBlobKey = jobVertex.getTaskInformationOrBlobKey();
		} catch (IOException e) {
			throw new ExecutionGraphException(
				""Could not create a serialized JobVertexInformation for "" +
					jobVertex.getJobVertexId(), e);
		}

		final TaskDeploymentDescriptor.MaybeOffloaded<TaskInformation> serializedTaskInformation;

		if (taskInformationOrBlobKey.isLeft()) {
			serializedTaskInformation = new TaskDeploymentDescriptor.NonOffloaded<>(taskInformationOrBlobKey.left());
		} else {
			serializedTaskInformation = new TaskDeploymentDescriptor.Offloaded<>(taskInformationOrBlobKey.right());
		}

		return new TaskDeploymentDescriptor(
			getJobId(),
			serializedJobInformation,
			serializedTaskInformation,
			executionId,
			targetSlot.getAllocationId(),
			subTaskIndex,
			attemptNumber,
			targetSlot.getPhysicalSlotNumber(),
			taskRestore,
			producedPartitions,
			consumedPartitions);
	}"
"public byte[] getKey() {
    if (result == null) {
      return null;
    }
    if (result.getKeyData().size() < KEY_LENGTH) {
      throw new IllegalStateException(""Could not get enough key data from the handshake."");
    }
    byte[] key = new byte[KEY_LENGTH];
    result.getKeyData().copyTo(key, 0, 0, KEY_LENGTH);
    return key;
  }"
"private void constructFailureStates()
    {
        Queue<State> queue = new LinkedBlockingDeque<State>();

        // 第一步，将深度为1的节点的failure设为根节点
        for (State depthOneState : this.rootState.getStates())
        {
            depthOneState.setFailure(this.rootState);
            queue.add(depthOneState);
        }
        this.failureStatesConstructed = true;

        // 第二步，为深度 > 1 的节点建立failure表，这是一个bfs
        while (!queue.isEmpty())
        {
            State currentState = queue.remove();

            for (Character transition : currentState.getTransitions())
            {
                State targetState = currentState.nextState(transition);
                queue.add(targetState);

                State traceFailureState = currentState.failure();
                while (traceFailureState.nextState(transition) == null)
                {
                    traceFailureState = traceFailureState.failure();
                }
                State newFailureState = traceFailureState.nextState(transition);
                targetState.setFailure(newFailureState);
                targetState.addEmit(newFailureState.emit());
            }
        }
    }"
"private static String polygonCoordinatesFromWkt(String wkt) {
        wkt = removeBrackets(wkt,2);
        String coordinates;
        boolean polygonContainsInnerHoles = wkt.contains(""("");
        if(polygonContainsInnerHoles) {
            String[] polygons = wkt.split(""\\s*\\)\\s*,\\s*\\(\\s*"");
            String[] coordinatesOfPolygons = new String[polygons.length];
            for (int i = 0; i < polygons.length; i++) {
                String polygonCoordinates = getJsonArrayFromListOfPoints(polygons[i]);
                coordinatesOfPolygons[i] = polygonCoordinates;
            }
            coordinates = Joiner.on("","").join(coordinatesOfPolygons);
        }
        else {
            coordinates = getJsonArrayFromListOfPoints(wkt);
        }
        return String.format(""[%s]"", coordinates);
    }"
"public RequestTemplate uri(String uri, boolean append) {
    /* validate and ensure that the url is always a relative one */
    if (UriUtils.isAbsolute(uri)) {
      throw new IllegalArgumentException(""url values must be not be absolute."");
    }

    if (uri == null) {
      uri = ""/"";
    } else if ((!uri.isEmpty() && !uri.startsWith(""/"") && !uri.startsWith(""{"")
        && !uri.startsWith(""?""))) {
      /* if the start of the url is a literal, it must begin with a slash. */
      uri = ""/"" + uri;
    }

    /*
     * templates may provide query parameters. since we want to manage those explicity, we will need
     * to extract those out, leaving the uriTemplate with only the path to deal with.
     */
    Matcher queryMatcher = QUERY_STRING_PATTERN.matcher(uri);
    if (queryMatcher.find()) {
      String queryString = uri.substring(queryMatcher.start() + 1);

      /* parse the query string */
      this.extractQueryTemplates(queryString, append);

      /* reduce the uri to the path */
      uri = uri.substring(0, queryMatcher.start());
    }

    int fragmentIndex = uri.indexOf('#');
    if (fragmentIndex > -1) {
      fragment = uri.substring(fragmentIndex);
      uri = uri.substring(0, fragmentIndex);
    }

    /* replace the uri template */
    if (append && this.uriTemplate != null) {
      this.uriTemplate = UriTemplate.append(this.uriTemplate, uri);
    } else {
      this.uriTemplate = UriTemplate.create(uri, !this.decodeSlash, this.charset);
    }
    return this;
  }"
"protected AuthenticationHandlerExecutionResult createResult(final ClientCredential credentials, final UserProfile profile,
                                                                final BaseClient client) throws GeneralSecurityException {
        if (profile == null) {
            throw new FailedLoginException(""Authentication did not produce a user profile for: "" + credentials);
        }

        val id = determinePrincipalIdFrom(profile, client);
        if (StringUtils.isBlank(id)) {
            throw new FailedLoginException(""No identifier found for this user profile: "" + profile);
        }
        credentials.setUserProfile(profile);
        credentials.setTypedIdUsed(isTypedIdUsed);
        val attributes = CoreAuthenticationUtils.convertAttributeValuesToMultiValuedObjects(profile.getAttributes());
        val principal = this.principalFactory.createPrincipal(id, attributes);
        LOGGER.debug(""Constructed authenticated principal [{}] based on user profile [{}]"", principal, profile);
        return finalizeAuthenticationHandlerResult(credentials, principal, profile, client);
    }"
"@Override
    public Collection<String> wordsNearest(INDArray words, int top) {
        Counter<String> distances = new Counter<>();

        for (String s : vocabCache.words()) {
            INDArray otherVec = lookupTable.vector(s);
            double sim = Transforms.cosineSim(Transforms.unitVec(words.dup()), Transforms.unitVec(otherVec.dup()));
            distances.incrementCount(s, (float) sim);
        }

        distances.keepTopNElements(top);
        return distances.keySetSorted();
    }"
"public void update(Entity entity) {
        entityCache.put(entity,
                        false); // false -> we don't store state, meaning it will always be seen as changed
        entity.setUpdated(true);
    }"
"private ReactorListener buildReactorListener() throws IOException {
        List<ReactorListener> r = Lists.newArrayList(ServiceLoader.load(InitReactorListener.class, Thread.currentThread().getContextClassLoader()));
        r.add(new ReactorListener() {
            final Level level = Level.parse( Configuration.getStringConfigParameter(""initLogLevel"", ""FINE"") );
            public void onTaskStarted(Task t) {
                LOGGER.log(level, ""Started {0}"", getDisplayName(t));
            }

            public void onTaskCompleted(Task t) {
                LOGGER.log(level, ""Completed {0}"", getDisplayName(t));
            }

            public void onTaskFailed(Task t, Throwable err, boolean fatal) {
                LOGGER.log(SEVERE, ""Failed "" + getDisplayName(t), err);
            }

            public void onAttained(Milestone milestone) {
                Level lv = level;
                String s = ""Attained ""+milestone.toString();
                if (milestone instanceof InitMilestone) {
                    lv = Level.INFO; // noteworthy milestones --- at least while we debug problems further
                    onInitMilestoneAttained((InitMilestone) milestone);
                    s = milestone.toString();
                }
                LOGGER.log(lv,s);
            }
        });
        return new ReactorListener.Aggregator(r);
    }"
"public static int dateToInternal(java.sql.Date date, TimeZone tz) {
		long ts = date.getTime() + tz.getOffset(date.getTime());
		return (int) (ts / MILLIS_PER_DAY);
	}"
"public void next() {
		newKeyGroup = false;
		newKVState = false;

		final RocksIteratorWrapper rocksIterator = currentSubIterator.getIterator();
		rocksIterator.next();

		byte[] oldKey = currentSubIterator.getCurrentKey();
		if (rocksIterator.isValid()) {

			currentSubIterator.setCurrentKey(rocksIterator.key());

			if (isDifferentKeyGroup(oldKey, currentSubIterator.getCurrentKey())) {
				heap.offer(currentSubIterator);
				currentSubIterator = heap.remove();
				newKVState = currentSubIterator.getIterator() != rocksIterator;
				detectNewKeyGroup(oldKey);
			}
		} else {
			IOUtils.closeQuietly(rocksIterator);

			if (heap.isEmpty()) {
				currentSubIterator = null;
				valid = false;
			} else {
				currentSubIterator = heap.remove();
				newKVState = true;
				detectNewKeyGroup(oldKey);
			}
		}
	}"
"public static JMXConnector connect(final String hostportOrPid, final String login, final String password)
			throws IOException {
		// ./vjmxcli.sh - 127.0.0.1:8060 gcutil
		if (hostportOrPid.contains("":"")) {
			JMXServiceURL rmiurl = new JMXServiceURL(
					""service:jmx:rmi://"" + hostportOrPid + ""/jndi/rmi://"" + hostportOrPid + ""/jmxrmi"");
			return JMXConnectorFactory.connect(rmiurl, formatCredentials(login, password));
		} else {
			// ./vjmxcli.sh - 112222 gcutil
			String localAddress = getLocalConnectorAddress(hostportOrPid);
			JMXServiceURL localRmiurl = new JMXServiceURL(localAddress);
			return JMXConnectorFactory.connect(localRmiurl);
		}
	}"
"public HistogramVisual asVisual()
  {
    float[] visualCounts = new float[bins.length - 2];
    for (int i = 0; i < visualCounts.length; ++i) {
      visualCounts[i] = (float) bins[i + 1];
    }
    return new HistogramVisual(breaks, visualCounts, new float[]{min, max});
  }"
"public void copyFrom(InputStream in) throws IOException, InterruptedException {
        try (OutputStream os = write()) {
            org.apache.commons.io.IOUtils.copy(in, os);
        }
    }"
"@Override
    public void invalidate(String appName, @Nullable String vipAddress, @Nullable String secureVipAddress) {
        for (Key.KeyType type : Key.KeyType.values()) {
            for (Version v : Version.values()) {
                invalidate(
                        new Key(Key.EntityType.Application, appName, type, v, EurekaAccept.full),
                        new Key(Key.EntityType.Application, appName, type, v, EurekaAccept.compact),
                        new Key(Key.EntityType.Application, ALL_APPS, type, v, EurekaAccept.full),
                        new Key(Key.EntityType.Application, ALL_APPS, type, v, EurekaAccept.compact),
                        new Key(Key.EntityType.Application, ALL_APPS_DELTA, type, v, EurekaAccept.full),
                        new Key(Key.EntityType.Application, ALL_APPS_DELTA, type, v, EurekaAccept.compact)
                );
                if (null != vipAddress) {
                    invalidate(new Key(Key.EntityType.VIP, vipAddress, type, v, EurekaAccept.full));
                }
                if (null != secureVipAddress) {
                    invalidate(new Key(Key.EntityType.SVIP, secureVipAddress, type, v, EurekaAccept.full));
                }
            }
        }
    }"
"public int length() {
        int length;
        if (head < tail) {
            length = hpackHeaderFields.length - tail + head;
        } else {
            length = head - tail;
        }
        return length;
    }"
"public void addControlDependency(SDVariable controlDependency){
        String cdN = controlDependency.getVarName();
        String n = this.getVarName();
        Variable v = sameDiff.getVariables().get(n);
        if(v.getControlDeps() == null)
            v.setControlDeps(new ArrayList<String>());
        if(!v.getControlDeps().contains(cdN))
            v.getControlDeps().add(cdN);

        Variable v2 = sameDiff.getVariables().get(cdN);
        if(v2.getControlDepsForVar() == null)
            v2.setControlDepsForVar(new ArrayList<String>());
        if(!v2.getControlDepsForVar().contains(n))
            v2.getControlDepsForVar().add(n);
    }"
"public static <T> TypeSerializer<T> tryReadSerializer(
			DataInputView in,
			ClassLoader userCodeClassLoader,
			boolean useDummyPlaceholder) throws IOException {

		final TypeSerializerSerializationUtil.TypeSerializerSerializationProxy<T> proxy =
			new TypeSerializerSerializationUtil.TypeSerializerSerializationProxy<>(userCodeClassLoader);

		try {
			proxy.read(in);
			return proxy.getTypeSerializer();
		} catch (UnloadableTypeSerializerException e) {
			if (useDummyPlaceholder) {
				LOG.warn(""Could not read a requested serializer. Replaced with a UnloadableDummyTypeSerializer."", e.getCause());
				return new UnloadableDummyTypeSerializer<>(e.getSerializerBytes(), e.getCause());
			} else {
				throw e;
			}
		}
	}"
"@Override
    public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) {

        if (!(msg instanceof HttpMessage || msg instanceof HttpContent)) {
            ctx.write(msg, promise);
            return;
        }

        boolean release = true;
        SimpleChannelPromiseAggregator promiseAggregator =
                new SimpleChannelPromiseAggregator(promise, ctx.channel(), ctx.executor());
        try {
            Http2ConnectionEncoder encoder = encoder();
            boolean endStream = false;
            if (msg instanceof HttpMessage) {
                final HttpMessage httpMsg = (HttpMessage) msg;

                // Provide the user the opportunity to specify the streamId
                currentStreamId = getStreamId(httpMsg.headers());

                // Convert and write the headers.
                Http2Headers http2Headers = HttpConversionUtil.toHttp2Headers(httpMsg, validateHeaders);
                endStream = msg instanceof FullHttpMessage && !((FullHttpMessage) msg).content().isReadable();
                writeHeaders(ctx, encoder, currentStreamId, httpMsg.headers(), http2Headers,
                        endStream, promiseAggregator);
            }

            if (!endStream && msg instanceof HttpContent) {
                boolean isLastContent = false;
                HttpHeaders trailers = EmptyHttpHeaders.INSTANCE;
                Http2Headers http2Trailers = EmptyHttp2Headers.INSTANCE;
                if (msg instanceof LastHttpContent) {
                    isLastContent = true;

                    // Convert any trailing headers.
                    final LastHttpContent lastContent = (LastHttpContent) msg;
                    trailers = lastContent.trailingHeaders();
                    http2Trailers = HttpConversionUtil.toHttp2Headers(trailers, validateHeaders);
                }

                // Write the data
                final ByteBuf content = ((HttpContent) msg).content();
                endStream = isLastContent && trailers.isEmpty();
                release = false;
                encoder.writeData(ctx, currentStreamId, content, 0, endStream, promiseAggregator.newPromise());

                if (!trailers.isEmpty()) {
                    // Write trailing headers.
                    writeHeaders(ctx, encoder, currentStreamId, trailers, http2Trailers, true, promiseAggregator);
                }
            }
        } catch (Throwable t) {
            onError(ctx, true, t);
            promiseAggregator.setFailure(t);
        } finally {
            if (release) {
                ReferenceCountUtil.release(msg);
            }
            promiseAggregator.doneAllocatingPromises();
        }
    }"
"public long[] getShape() {
        if (variableType == VariableType.PLACEHOLDER && getArr() == null) {
            if (shape != null)
                return shape;
            else
                return new long[0];
        }

        long[] initialShape =  sameDiff.getShapeForVarName(getVarName());
        if(initialShape == null) {
            val arr = getArr();
            if(arr != null)
                return arr.shape();
        }

        return initialShape;
    }"
"public static Pair<String, Integer> parseVariable(@NonNull String varName) {
        if (!varName.contains("":"")) {
            return Pair.pairOf(varName, 0);
        } else {
            val split = varName.split("":"");
            val index = Integer.valueOf(split[split.length - 1]);
            if (split.length == 2)
                return Pair.pairOf(split[0], index);
            else {
                val builder = new StringBuilder();
                for (int e = 0; e < split.length - 1; e++) {
                    builder.append(split[e]);

                    if (e < split.length - 2)
                        builder.append("":"");
                }

                return Pair.pairOf(builder.toString(), index);
            }
        }
    }"
"public static HttpResponseStatus valueOf(int code) {
        HttpResponseStatus status = valueOf0(code);
        return status != null ? status : new HttpResponseStatus(code);
    }"
"protected boolean shouldRegisterJspServlet() {
		return this.jsp != null && this.jsp.getRegistered() && ClassUtils
				.isPresent(this.jsp.getClassName(), getClass().getClassLoader());
	}"
"public String verifyAndExtract(String signedStr) {
    int index = signedStr.lastIndexOf(SIGNATURE);
    if (index == -1) {
      throw new IllegalArgumentException(""Invalid input sign: "" + signedStr);
    }
    String originalSignature = signedStr.substring(index + SIGNATURE.length());
    String rawValue = signedStr.substring(0, index);
    String currentSignature = getSignature(rawValue);

    if (LOG.isDebugEnabled()) {
      LOG.debug(""Signature generated for "" + rawValue + "" inside verify is "" + currentSignature);
    }
    if (!originalSignature.equals(currentSignature)) {
      throw new IllegalArgumentException(""Invalid sign, original = "" + originalSignature +
        "" current = "" + currentSignature);
    }
    return rawValue;
  }"
"public double[] getRowPackedCopy()
    {
        double[] vals = new double[m * n];
        for (int i = 0; i < m; i++)
        {
            for (int j = 0; j < n; j++)
            {
                vals[i * n + j] = A[i][j];
            }
        }
        return vals;
    }"
"public String getVarNameForFieldAndFunction(DifferentialFunction function, String fieldName) {
        return fieldVariableResolutionMapping.get(function.getOwnName(), fieldName);
    }"
"private static HashSet<String> parseExcludeRouter(List<Router> customRouters) {
        HashSet<String> excludeKeys = new HashSet<String>();
        if (CommonUtils.isNotEmpty(customRouters)) {
            for (Router router : customRouters) {
                if (router instanceof ExcludeRouter) {
                    // 存在需要排除的过滤器
                    ExcludeRouter excludeRouter = (ExcludeRouter) router;
                    String excludeName = excludeRouter.getExcludeName();
                    if (StringUtils.isNotEmpty(excludeName)) {
                        String excludeRouterName = startsWithExcludePrefix(excludeName) ? excludeName.substring(1)
                            : excludeName;
                        if (StringUtils.isNotEmpty(excludeRouterName)) {
                            excludeKeys.add(excludeRouterName);
                        }
                    }
                    customRouters.remove(router);
                }
            }
        }
        if (!excludeKeys.isEmpty()) {
            if (LOGGER.isInfoEnabled()) {
                LOGGER.info(""Find exclude routers: {}"", excludeKeys);
            }
        }
        return excludeKeys;
    }"
"public static void write(HttpServletResponse response, InputStream in, int bufferSize) {
		ServletOutputStream out = null;
		try {
			out = response.getOutputStream();
			IoUtil.copy(in, out, bufferSize);
		} catch (IOException e) {
			throw new UtilException(e);
		} finally {
			IoUtil.close(out);
			IoUtil.close(in);
		}
	}"
"public Actions contextClick(WebElement target) {
    if (isBuildingActions()) {
      action.addAction(new ContextClickAction(jsonMouse, (Locatable) target));
    }
    return moveInTicks(target, 0, 0).clickInTicks(RIGHT);
  }"
"public static <IN, OUT> CompletableFuture<OUT> thenComposeAsyncIfNotDone(
		CompletableFuture<IN> completableFuture,
		Executor executor,
		Function<? super IN, ? extends CompletionStage<OUT>> composeFun) {
		return completableFuture.isDone() ?
			completableFuture.thenCompose(composeFun) :
			completableFuture.thenComposeAsync(composeFun, executor);
	}"
"@Override
	public void setup(AbstractInvokable parent) {
		@SuppressWarnings(""unchecked"")
		final FlatMapFunction<IT, OT> mapper =
			BatchTask.instantiateUserCode(this.config, userCodeClassLoader, FlatMapFunction.class);
		this.mapper = mapper;
		FunctionUtils.setFunctionRuntimeContext(mapper, getUdfRuntimeContext());
	}"
"public void afterPropertiesSet() throws Exception {
        scheduler = new ScheduledThreadPoolExecutor(DEFAULT_POOL, new NamedThreadFactory(""Otter-Statistics-Client""),
                                                    new ThreadPoolExecutor.CallerRunsPolicy());
        scheduler.submit(new Runnable() {

            public void run() {
                doSendDelayCountEvent();
            }
        });
    }"
"public int bin( double col_data ) {
    if(Double.isNaN(col_data)) return _nbin; // NA bucket
    if (Double.isInfinite(col_data)) // Put infinity to most left/right bin
      if (col_data<0) return 0;
      else return _nbin-1;
    assert _min <= col_data && col_data < _maxEx : ""Coldata "" + col_data + "" out of range "" + this;
    // When the model is exposed to new test data, we could have data that is
    // out of range of any bin - however this binning call only happens during
    // model-building.
    int idx1;

    double pos = _hasQuantiles ? col_data : ((col_data - _min) * _step);
    if (_splitPts != null) {
      idx1 = Arrays.binarySearch(_splitPts, pos);
      if (idx1 < 0) idx1 = -idx1 - 2;
    } else {
      idx1 = (int) pos;
    }
    if (idx1 == _nbin) idx1--; // Roundoff error allows idx1 to hit upper bound, so truncate
    assert 0 <= idx1 && idx1 < _nbin : idx1 + "" "" + _nbin;
    return idx1;
  }"
"@Override
   public Connection getConnection() throws SQLException
   {
      if (isClosed()) {
         throw new SQLException(""HikariDataSource "" + this + "" has been closed."");
      }

      if (fastPathPool != null) {
         return fastPathPool.getConnection();
      }

      // See http://en.wikipedia.org/wiki/Double-checked_locking#Usage_in_Java
      HikariPool result = pool;
      if (result == null) {
         synchronized (this) {
            result = pool;
            if (result == null) {
               validate();
               LOGGER.info(""{} - Starting..."", getPoolName());
               try {
                  pool = result = new HikariPool(this);
                  this.seal();
               }
               catch (PoolInitializationException pie) {
                  if (pie.getCause() instanceof SQLException) {
                     throw (SQLException) pie.getCause();
                  }
                  else {
                     throw pie;
                  }
               }
               LOGGER.info(""{} - Start completed."", getPoolName());
            }
         }
      }

      return result.getConnection();
   }"
"public static <A> Consumer<A> uncheckedConsumer(ThrowingConsumer<A, ?> throwingConsumer) {
		return (A value) -> {
			try {
				throwingConsumer.accept(value);
			} catch (Throwable t) {
				ExceptionUtils.rethrow(t);
			}
		};
	}"
"public static void addProvidersToPathHandler(PathResourceProvider[] pathResourceProviders, PathHandler pathHandler) {
        if (pathResourceProviders != null && pathResourceProviders.length > 0) {
            for (PathResourceProvider pathResourceProvider : pathResourceProviders) {
                if (pathResourceProvider.isPrefixPath()) {
                    pathHandler.addPrefixPath(pathResourceProvider.getPath(), new ResourceHandler(pathResourceProvider.getResourceManager()));
                } else {
                    pathHandler.addExactPath(pathResourceProvider.getPath(), new ResourceHandler(pathResourceProvider.getResourceManager()));
                }
            }
        }
    }"
"@Restricted(NoExternalUse.class)
    public void writeConfigDotXml(OutputStream os) throws IOException {
        checkPermission(EXTENDED_READ);
        XmlFile configFile = getConfigFile();
        if (hasPermission(CONFIGURE)) {
            IOUtils.copy(configFile.getFile(), os);
        } else {
            String encoding = configFile.sniffEncoding();
            String xml = FileUtils.readFileToString(configFile.getFile(), encoding);
            Matcher matcher = SECRET_PATTERN.matcher(xml);
            StringBuffer cleanXml = new StringBuffer();
            while (matcher.find()) {
                if (Secret.decrypt(matcher.group(1)) != null) {
                    matcher.appendReplacement(cleanXml, "">********<"");
                }
            }
            matcher.appendTail(cleanXml);
            org.apache.commons.io.IOUtils.write(cleanXml.toString(), os, encoding);
        }
    }"
"public Postcard withParcelableArray(@Nullable String key, @Nullable Parcelable[] value) {
        mBundle.putParcelableArray(key, value);
        return this;
    }"
"@SuppressWarnings(""checkstyle:InnerAssignment"")
    public static void quickSort(final int[][] x, final long from, final long to, final IntComparator comp)
    {
        final long len = to - from;
        // Selection sort on smallest arrays
        if (len < SMALL) {
            selectionSort(x, from, to, comp);
            return;
        }
        // Choose a partition element, v
        long m = from + len / 2; // Small arrays, middle element
        if (len > SMALL) {
            long l = from;
            long n = to - 1;
            if (len > MEDIUM) { // Big arrays, pseudomedian of 9
                long s = len / 8;
                l = med3(x, l, l + s, l + 2 * s, comp);
                m = med3(x, m - s, m, m + s, comp);
                n = med3(x, n - 2 * s, n - s, n, comp);
            }
            m = med3(x, l, m, n, comp); // Mid-size, med of 3
        }
        final int v = get(x, m);
        // Establish Invariant: v* (<v)* (>v)* v*
        long a = from;
        long b = a;
        long c = to - 1;
        long d = c;
        while (true) {
            int comparison;
            while (b <= c && (comparison = comp.compare(get(x, b), v)) <= 0) {
                if (comparison == 0) {
                    swap(x, a++, b);
                }
                b++;
            }
            while (c >= b && (comparison = comp.compare(get(x, c), v)) >= 0) {
                if (comparison == 0) {
                    swap(x, c, d--);
                }
                c--;
            }
            if (b > c) {
                break;
            }
            swap(x, b++, c--);
        }
        // Swap partition elements back to middle
        long s;
        long n = to;
        s = Math.min(a - from, b - a);
        vecSwap(x, from, b - s, s);
        s = Math.min(d - c, n - d - 1);
        vecSwap(x, b, n - s, s);
        // Recursively sort non-partition-elements
        if ((s = b - a) > 1) {
            quickSort(x, from, from + s, comp);
        }
        if ((s = d - c) > 1) {
            quickSort(x, n - s, n, comp);
        }
    }"
"public static <T> T getPasswordlessAuthenticationAccount(final Event event, final Class<T> clazz) {
        return event.getAttributes().get(""passwordlessAccount"", clazz);
    }"
"public static boolean containsAll(Set<String> target, Set<String> members) {
		target = new HashSet<String>(target);
		target.retainAll(members);
		return target.size() == members.size();
	}"
"public static SearchRequest newLdaptiveSearchRequest(final String baseDn,
                                                         final SearchFilter filter,
                                                         final String[] binaryAttributes,
                                                         final String[] returnAttributes) {
        val sr = new SearchRequest(baseDn, filter);
        sr.setBinaryAttributes(binaryAttributes);
        sr.setReturnAttributes(returnAttributes);
        sr.setSearchScope(SearchScope.SUBTREE);
        return sr;
    }"
"public static ByteBuffer reallocateDirectNoCleaner(ByteBuffer buffer, int capacity) {
        assert USE_DIRECT_BUFFER_NO_CLEANER;

        int len = capacity - buffer.capacity();
        incrementMemoryCounter(len);
        try {
            return PlatformDependent0.reallocateDirectNoCleaner(buffer, capacity);
        } catch (Throwable e) {
            decrementMemoryCounter(len);
            throwException(e);
            return null;
        }
    }"
"public void schedule() {
        // randomize the scheduling so that multiple Hudson instances will write at the file at different time
        long MINUTE = 1000*60;

        Timer.get()
            .schedule(new SafeTimerTask() {
                protected void doRun() {
                    execute();
                }
            }, (random.nextInt(30) + 60) * MINUTE, TimeUnit.MILLISECONDS);
    }"
"protected void initialize(ConfigurableEnvironment environment,
			ClassLoader classLoader) {
		new LoggingSystemProperties(environment).apply();
		LogFile logFile = LogFile.get(environment);
		if (logFile != null) {
			logFile.applyToSystemProperties();
		}
		initializeEarlyLoggingLevel(environment);
		initializeSystem(environment, this.loggingSystem, logFile);
		initializeFinalLoggingLevels(environment, this.loggingSystem);
		registerShutdownHookIfNecessary(environment, this.loggingSystem);
	}"
"protected JsonWebSignature configureJsonWebSignatureForTokenSigning(final OAuthRegisteredService svc,
                                                                        final JsonWebSignature jws,
                                                                        final PublicJsonWebKey jsonWebKey) {
        LOGGER.debug(""Service [{}] is set to sign id tokens"", svc);
        jws.setKey(jsonWebKey.getPrivateKey());
        jws.setAlgorithmConstraints(AlgorithmConstraints.DISALLOW_NONE);
        if (StringUtils.isNotBlank(jsonWebKey.getKeyId())) {
            jws.setKeyIdHeaderValue(jsonWebKey.getKeyId());
        }
        LOGGER.debug(""Signing id token with key id header value [{}]"", jws.getKeyIdHeaderValue());
        jws.setAlgorithmHeaderValue(getJsonWebKeySigningAlgorithm(svc));

        LOGGER.debug(""Signing id token with algorithm [{}]"", jws.getAlgorithmHeaderValue());
        return jws;
    }"
"public static Protos.Resource scalar(String name, String role, double value) {
		checkNotNull(name);
		checkNotNull(role);
		checkNotNull(value);
		return Protos.Resource.newBuilder()
			.setName(name)
			.setType(Protos.Value.Type.SCALAR)
			.setScalar(Protos.Value.Scalar.newBuilder().setValue(value))
			.setRole(role)
			.build();
	}"
"public static int mergingCells(Sheet sheet, int firstRow, int lastRow, int firstColumn, int lastColumn, CellStyle cellStyle) {
		final CellRangeAddress cellRangeAddress = new CellRangeAddress(//
				firstRow, // first row (0-based)
				lastRow, // last row (0-based)
				firstColumn, // first column (0-based)
				lastColumn // last column (0-based)
		);

		if (null != cellStyle) {
			RegionUtil.setBorderTop(cellStyle.getBorderTopEnum(), cellRangeAddress, sheet);
			RegionUtil.setBorderRight(cellStyle.getBorderRightEnum(), cellRangeAddress, sheet);
			RegionUtil.setBorderBottom(cellStyle.getBorderBottomEnum(), cellRangeAddress, sheet);
			RegionUtil.setBorderLeft(cellStyle.getBorderLeftEnum(), cellRangeAddress, sheet);
		}
		return sheet.addMergedRegion(cellRangeAddress);
	}"
"public static KeyPair getKeyPair(String type, InputStream in, char[] password, String alias) {
		final KeyStore keyStore = readKeyStore(type, in, password);
		return getKeyPair(keyStore, password, alias);
	}"
"public static Class<?> getElementType(Iterable<?> iterable) {
		if (null != iterable) {
			final Iterator<?> iterator = iterable.iterator();
			return getElementType(iterator);
		}
		return null;
	}"
"public String nextString() throws IOException {
    int p = peeked;
    if (p == PEEKED_NONE) {
      p = doPeek();
    }
    String result;
    if (p == PEEKED_UNQUOTED) {
      result = nextUnquotedValue();
    } else if (p == PEEKED_SINGLE_QUOTED) {
      result = nextQuotedValue('\'');
    } else if (p == PEEKED_DOUBLE_QUOTED) {
      result = nextQuotedValue('""');
    } else if (p == PEEKED_BUFFERED) {
      result = peekedString;
      peekedString = null;
    } else if (p == PEEKED_LONG) {
      result = Long.toString(peekedLong);
    } else if (p == PEEKED_NUMBER) {
      result = new String(buffer, pos, peekedNumberLength);
      pos += peekedNumberLength;
    } else {
      throw new IllegalStateException(""Expected a string but was "" + peek() + locationString());
    }
    peeked = PEEKED_NONE;
    pathIndices[stackSize - 1]++;
    return result;
  }"
"private static PriorityQueue<Entry> initializeQueue(double[] values, double[] weights, int nextIndex)
    {
        checkArgument(nextIndex > 0, ""nextIndex must be > 0"");

        PriorityQueue<Entry> queue = new PriorityQueue<>(nextIndex);

        Entry right = new Entry(nextIndex - 1, values[nextIndex - 1], weights[nextIndex - 1], null);
        queue.add(right);
        for (int i = nextIndex - 2; i >= 0; i--) {
            Entry current = new Entry(i, values[i], weights[i], right);
            queue.add(current);
            right = current;
        }

        return queue;
    }"
"public final int getBeInt24() {
        if (position + 2 >= origin + limit) throw new IllegalArgumentException(""limit excceed: ""
                                                                               + (position - origin + 2));

        byte[] buf = buffer;
        return ((buf[position++]) << 16) | ((0xff & buf[position++]) << 8) | (0xff & buf[position++]);
    }"
"private String validateAndSaveReport(final HttpServletRequest req,
      final HttpServletResponse resp, final Session session) throws ServletException,
      IOException {

    final ProjectManager projectManager = this.server.getProjectManager();
    final User user = session.getUser();

    final Page page =
        newPage(req, resp, session,
            ""azkaban/viewer/reportal/reportaleditpage.vm"");
    preparePage(page, session);
    page.add(""ReportalHelper"", ReportalHelper.class);

    final boolean isEdit = hasParam(req, ""id"");
    if (isEdit) {
      page.add(""projectId"", getIntParam(req, ""id""));
    }

    Project project = null;
    final Reportal report = new Reportal();

    report.title = getParam(req, ""title"");
    report.description = getParam(req, ""description"");
    page.add(""title"", report.title);
    page.add(""description"", report.description);

    report.schedule = hasParam(req, ""schedule"");
    report.scheduleHour = getParam(req, ""schedule-hour"");
    report.scheduleMinute = getParam(req, ""schedule-minute"");
    report.scheduleAmPm = getParam(req, ""schedule-am_pm"");
    report.scheduleTimeZone = getParam(req, ""schedule-timezone"");
    report.scheduleDate = getParam(req, ""schedule-date"");
    report.scheduleRepeat = hasParam(req, ""schedule-repeat"");
    report.scheduleIntervalQuantity =
        getParam(req, ""schedule-interval-quantity"");
    report.scheduleInterval = getParam(req, ""schedule-interval"");
    report.renderResultsAsHtml = hasParam(req, ""render-results-as-html"");

    final boolean isEndSchedule = hasParam(req, ""end-schedule-date"");
    if (isEndSchedule) {
      report.endSchedule = getParam(req, ""end-schedule-date"");
    }

    page.add(""schedule"", report.schedule);
    page.add(""scheduleHour"", report.scheduleHour);
    page.add(""scheduleMinute"", report.scheduleMinute);
    page.add(""scheduleAmPm"", report.scheduleAmPm);
    page.add(""scheduleTimeZone"", report.scheduleTimeZone);
    page.add(""scheduleDate"", report.scheduleDate);
    page.add(""scheduleRepeat"", report.scheduleRepeat);
    page.add(""scheduleIntervalQuantity"", report.scheduleIntervalQuantity);
    page.add(""scheduleInterval"", report.scheduleInterval);
    page.add(""renderResultsAsHtml"", report.renderResultsAsHtml);
    page.add(""endSchedule"", report.endSchedule);
    page.add(""max_allowed_schedule_dates"", this.max_allowed_schedule_dates);
    page.add(""default_schedule_dates"", this.default_schedule_dates);

    report.accessViewer = getParam(req, ""access-viewer"");
    report.accessExecutor = getParam(req, ""access-executor"");
    report.accessOwner = getParam(req, ""access-owner"");
    page.add(""accessViewer"", report.accessViewer);
    page.add(""accessExecutor"", report.accessExecutor);

    // Adding report creator as explicit owner, if not present already
    if (report.accessOwner == null || report.accessOwner.isEmpty()) {
      report.accessOwner = user.getUserId();
    } else {
      final String[] splittedOwners = report.accessOwner.toLowerCase()
          .split(Reportal.ACCESS_LIST_SPLIT_REGEX);
      if (!Arrays.asList(splittedOwners).contains(user.getUserId())) {
        report.accessOwner = String.format(""%s,%s"", user.getUserId(),
            StringUtils.join(splittedOwners, ','));
      } else {
        report.accessOwner = StringUtils.join(splittedOwners, ',');
      }
    }

    page.add(""accessOwner"", report.accessOwner);

    report.notifications = getParam(req, ""notifications"");
    report.failureNotifications = getParam(req, ""failure-notifications"");
    page.add(""notifications"", report.notifications);
    page.add(""failureNotifications"", report.failureNotifications);

    final int numQueries = getIntParam(req, ""queryNumber"");
    page.add(""queryNumber"", numQueries);
    final List<Query> queryList = new ArrayList<>(numQueries);
    page.add(""queries"", queryList);
    report.queries = queryList;

    final List<String> errors = new ArrayList<>();
    for (int i = 0; i < numQueries; i++) {
      final Query query = new Query();

      query.title = getParam(req, ""query"" + i + ""title"");
      query.type = getParam(req, ""query"" + i + ""type"");
      query.script = getParam(req, ""query"" + i + ""script"");

      // Type check
      final ReportalType type = ReportalType.getTypeByName(query.type);
      if (type == null) {
        errors.add(""Type "" + query.type + "" is invalid."");
      }

      if (!type.checkPermission(user) && report.schedule) {
        errors.add(""You do not have permission to schedule Type "" + query.type + ""."");
      }

      queryList.add(query);
    }

    final int variables = getIntParam(req, ""variableNumber"");
    page.add(""variableNumber"", variables);
    final List<Variable> variableList = new ArrayList<>(variables);
    page.add(""variables"", variableList);
    report.variables = variableList;

    String proxyUser = null;

    for (int i = 0; i < variables; i++) {
      final Variable variable =
          new Variable(getParam(req, ""variable"" + i + ""title""), getParam(req,
              ""variable"" + i + ""name""));

      if (variable.title.isEmpty() || variable.name.isEmpty()) {
        errors.add(""Variable title and name cannot be empty."");
      }

      if (variable.title.equals(""reportal.config.reportal.execution.user"")) {
        proxyUser = variable.name;
      }

      // Validate if the session user (who interact with UI) is part of specified user.to.proxy
      // user. If not, reportal can not be saved and warn users.
      if (variable.title.equals(""reportal.config.user.to.proxy"")) {
        final String userToProxy = variable.name;
        final UserManager userManager = getApplication().getUserManager();
        if (!userManager.validateProxyUser(userToProxy, user)) {
          errors.add(""User "" + user.getUserId() + "" has no permission to add "" + userToProxy
              + "" as proxy user."");
        }
      }

      variableList.add(variable);
    }

    // Make sure title isn't empty
    if (report.title.isEmpty()) {
      errors.add(""Title must not be empty."");
    }

    // Make sure description isn't empty
    if (report.description.isEmpty()) {
      errors.add(""Description must not be empty."");
    }

    // Verify schedule and repeat
    if (report.schedule) {
      // Verify schedule time
      if (!NumberUtils.isDigits(report.scheduleHour)
          || !NumberUtils.isDigits(report.scheduleMinute)) {
        errors.add(""Schedule time is invalid."");
      }

      // Verify schedule date is not empty
      if (report.scheduleDate.isEmpty()) {
        errors.add(""Schedule date must not be empty."");
      }

      if (report.scheduleRepeat) {
        // Verify repeat interval
        if (!NumberUtils.isDigits(report.scheduleIntervalQuantity)) {
          errors.add(""Repeat interval quantity is invalid."");
        }
      }
    }

    // Empty query check
    if (numQueries <= 0) {
      errors.add(""There needs to have at least one query."");
    }

    // Validate access users
    final UserManager userManager = getApplication().getUserManager();
    final String[] accessLists =
        new String[]{report.accessViewer, report.accessExecutor,
            report.accessOwner};
    for (String accessList : accessLists) {
      if (accessList == null) {
        continue;
      }

      accessList = accessList.trim();
      if (!accessList.isEmpty()) {
        final String[] users = accessList.split(Reportal.ACCESS_LIST_SPLIT_REGEX);
        for (final String accessUser : users) {
          if (!userManager.validateUser(accessUser)) {
            errors.add(""User "" + accessUser + "" in access list is invalid."");
          }
        }
      }
    }

    // Validate proxy user
    if (proxyUser != null) {
      if (!userManager.validateProxyUser(proxyUser, user)) {
        errors.add(""User "" + user.getUserId() + "" has no permission to add "" + proxyUser
            + "" as proxy user."");
      }
      proxyUser = null;
    }

    // Validate email addresses
    final Set<String> emails =
        ReportalHelper.parseUniqueEmails(report.notifications + "",""
            + report.failureNotifications, Reportal.ACCESS_LIST_SPLIT_REGEX);
    for (final String email : emails) {
      if (!ReportalHelper.isValidEmailAddress(email)) {
        errors.add(""Invalid email address: "" + email);
        continue;
      }

      final String domain = ReportalHelper.getEmailDomain(email);
      if (this.allowedEmailDomains != null && !this.allowedEmailDomains.contains(domain)) {
        errors.add(""Email address '"" + email + ""' has an invalid domain '""
            + domain + ""'. "" + ""Valid domains are: "" + this.allowedEmailDomains);
      }
    }

    if (errors.size() > 0) {
      page.add(""errorMsgs"", errors);
      page.render();
      return null;
    }

    // Attempt to get a project object
    if (isEdit) {
      // Editing mode, load project
      final int projectId = getIntParam(req, ""id"");
      project = projectManager.getProject(projectId);
      report.loadImmutableFromProject(project);
    } else {
      // Creation mode, create project
      try {
        project =
            ReportalHelper.createReportalProject(this.server, report.title,
                report.description, user);
        report.reportalUser = user.getUserId();
        report.ownerEmail = user.getEmail();
      } catch (final Exception e) {
        e.printStackTrace();
        errors.add(""Error while creating report. "" + e.getMessage());
        page.add(""errorMsgs"", errors);
        page.render();
        return null;
      }

      // Project already exists
      if (project == null) {
        errors.add(""A Report with the same name already exists."");
        page.add(""errorMsgs"", errors);
        page.render();
        return null;
      }
    }

    if (project == null) {
      errors.add(""Internal Error: Report not found"");
      page.add(""errorMsgs"", errors);
      page.render();
      return null;
    }

    report.project = project;
    page.add(""projectId"", project.getId());

    try {
      report.createZipAndUpload(projectManager, user, this.reportalStorageUser);
    } catch (final Exception e) {
      e.printStackTrace();
      errors.add(""Error while creating Azkaban jobs. "" + e.getMessage());
      page.add(""errorMsgs"", errors);
      page.render();
      if (!isEdit) {
        try {
          projectManager.removeProject(project, user);
        } catch (final ProjectManagerException e1) {
          e1.printStackTrace();
        }
      }
      return null;
    }

    // Prepare flow
    final Flow flow = project.getFlows().get(0);
    project.getMetadata().put(""flowName"", flow.getId());

    // Set Reportal mailer
    flow.setMailCreator(ReportalMailCreator.REPORTAL_MAIL_CREATOR);

    // Create/Save schedule
    final ScheduleManager scheduleManager = this.server.getScheduleManager();
    try {
      report.updateSchedules(report, scheduleManager, user, flow);
    } catch (final ScheduleManagerException e) {
      e.printStackTrace();
      errors.add(e.getMessage());
      page.add(""errorMsgs"", errors);
      page.render();
      return null;
    }

    report.saveToProject(project);

    try {
      ReportalHelper.updateProjectNotifications(project, projectManager);
      projectManager.updateProjectSetting(project);
      projectManager
          .updateProjectDescription(project, report.description, user);
      updateProjectPermissions(project, projectManager, report, user);
      projectManager.updateFlow(project, flow);
    } catch (final ProjectManagerException e) {
      e.printStackTrace();
      errors.add(""Error while updating report. "" + e.getMessage());
      page.add(""errorMsgs"", errors);
      page.render();
      if (!isEdit) {
        try {
          projectManager.removeProject(project, user);
        } catch (final ProjectManagerException e1) {
          e1.printStackTrace();
        }
      }
      return null;
    }

    return Integer.toString(project.getId());
  }"
"public static RateLimiterExports ofSupplier(String prefix, Supplier<Iterable<RateLimiter>> rateLimitersSupplier) {
        return new RateLimiterExports(prefix, rateLimitersSupplier);
    }"
"public void calcCost(Node node)
    {
        node.cost = 0.0;
        if (alphaFloat_ != null)
        {
            float c = 0.0f;
            for (int i = 0; node.fVector.get(i) != -1; i++)
            {
                c += alphaFloat_[node.fVector.get(i) + node.y];
            }
            node.cost = costFactor_ * c;
        }
        else
        {
            double c = 0.0;
            for (int i = 0; node.fVector.get(i) != -1; i++)
            {
                c += alpha_[node.fVector.get(i) + node.y];
            }
            node.cost = costFactor_ * c;
        }
    }"
"@SuppressWarnings(""unchecked"")
	private static Tuple2<LinkedHashMap<Class<?>, Integer>, TypeSerializer<Object>[]> decomposeSubclassSerializerRegistry(
		LinkedHashMap<Class<?>, TypeSerializer<?>> subclassSerializerRegistry) {

		final LinkedHashMap<Class<?>, Integer> subclassIds = new LinkedHashMap<>(subclassSerializerRegistry.size());
		final TypeSerializer[] subclassSerializers = new TypeSerializer[subclassSerializerRegistry.size()];

		subclassSerializerRegistry.forEach((registeredSubclassClass, serializer) -> {
			int id = subclassIds.size();
			subclassIds.put(registeredSubclassClass, id);
			subclassSerializers[id] = serializer;
		});

		return Tuple2.of(subclassIds, subclassSerializers);
	}"
"private String getEntityManagerFactoryName(String beanName) {
		if (beanName.length() > ENTITY_MANAGER_FACTORY_SUFFIX.length() && StringUtils
				.endsWithIgnoreCase(beanName, ENTITY_MANAGER_FACTORY_SUFFIX)) {
			return beanName.substring(0,
					beanName.length() - ENTITY_MANAGER_FACTORY_SUFFIX.length());
		}
		return beanName;
	}"
"private static String getResultSetValue(ResultSet rs, int index, Class<?> requiredType) throws SQLException {
        if (requiredType == null) {
            return getResultSetValue(rs, index);
        }

        Object value = null;
        boolean wasNullCheck = false;

        // Explicitly extract typed value, as far as possible.
        if (String.class.equals(requiredType)) {
            value = rs.getString(index);
        } else if (boolean.class.equals(requiredType) || Boolean.class.equals(requiredType)) {
            value = Boolean.valueOf(rs.getBoolean(index));
            wasNullCheck = true;
        } else if (byte.class.equals(requiredType) || Byte.class.equals(requiredType)) {
            value = new Byte(rs.getByte(index));
            wasNullCheck = true;
        } else if (short.class.equals(requiredType) || Short.class.equals(requiredType)) {
            value = new Short(rs.getShort(index));
            wasNullCheck = true;
        } else if (int.class.equals(requiredType) || Integer.class.equals(requiredType)) {
            value = new Long(rs.getLong(index));
            wasNullCheck = true;
        } else if (long.class.equals(requiredType) || Long.class.equals(requiredType)) {
            value = rs.getBigDecimal(index);
            wasNullCheck = true;
        } else if (float.class.equals(requiredType) || Float.class.equals(requiredType)) {
            value = new Float(rs.getFloat(index));
            wasNullCheck = true;
        } else if (double.class.equals(requiredType) || Double.class.equals(requiredType)
                   || Number.class.equals(requiredType)) {
            value = new Double(rs.getDouble(index));
            wasNullCheck = true;
        } else if (java.sql.Time.class.equals(requiredType)) {
            // try {
            // value = rs.getTime(index);
            // } catch (SQLException e) {
            value = rs.getString(index);// 尝试拿为string对象，0000无法用Time表示
            // if (value == null && !rs.wasNull()) {
            // value = ""00:00:00""; //
            // mysql设置了zeroDateTimeBehavior=convertToNull，出现0值时返回为null
            // }
            // }
        } else if (java.sql.Timestamp.class.equals(requiredType) || java.sql.Date.class.equals(requiredType)) {
            // try {
            // value = convertTimestamp(rs.getTimestamp(index));
            // } catch (SQLException e) {
            // 尝试拿为string对象，0000-00-00 00:00:00无法用Timestamp 表示
            value = rs.getString(index);
            // if (value == null && !rs.wasNull()) {
            // value = ""0000:00:00 00:00:00""; //
            // mysql设置了zeroDateTimeBehavior=convertToNull，出现0值时返回为null
            // }
            // }
        } else if (BigDecimal.class.equals(requiredType)) {
            value = rs.getBigDecimal(index);
        } else if (BigInteger.class.equals(requiredType)) {
            value = rs.getBigDecimal(index);
        } else if (Blob.class.equals(requiredType)) {
            value = rs.getBlob(index);
        } else if (Clob.class.equals(requiredType)) {
            value = rs.getClob(index);
        } else if (byte[].class.equals(requiredType)) {
            try {
                byte[] bytes = rs.getBytes(index);
                if (bytes == null) {
                    value = null;
                } else {
                    value = new String(bytes, ""ISO-8859-1"");// 将binary转化为iso-8859-1的字符串
                }
            } catch (UnsupportedEncodingException e) {
                throw new SQLException(e);
            }
        } else {
            // Some unknown type desired -> rely on getObject.
            value = getResultSetValue(rs, index);
        }

        // Perform was-null check if demanded (for results that the
        // JDBC driver returns as primitives).
        if (wasNullCheck && (value != null) && rs.wasNull()) {
            value = null;
        }

        return (value == null) ? null : convertUtilsBean.convert(value);
    }"
"public static BulkheadMetrics ofBulkheadRegistry(String prefix, BulkheadRegistry bulkheadRegistry) {
        return new BulkheadMetrics(prefix, bulkheadRegistry.getAllBulkheads());
    }"
"public static <T>  List<FieldVector> toArrowColumnsTimeSeriesHelper(final BufferAllocator bufferAllocator,
                                                                        final Schema schema,
                                                                        List<List<List<T>>> dataVecRecord) {
        //time series length * number of columns
        int numRows = 0;
        for(List<List<T>> timeStep : dataVecRecord) {
            numRows += timeStep.get(0).size() * timeStep.size();
        }

        numRows /= schema.numColumns();


        List<FieldVector> ret = createFieldVectors(bufferAllocator,schema,numRows);
        Map<Integer,Integer> currIndex = new HashMap<>(ret.size());
        for(int i = 0; i < ret.size(); i++) {
            currIndex.put(i,0);
        }
        for(int i = 0; i < dataVecRecord.size(); i++) {
            List<List<T>> record = dataVecRecord.get(i);
            for(int j = 0; j < record.size(); j++) {
                List<T> curr = record.get(j);
                for(int k = 0; k < curr.size(); k++) {
                    Integer idx = currIndex.get(k);
                    FieldVector fieldVector = ret.get(k);
                    T writable = curr.get(k);
                    setValue(schema.getType(k), fieldVector, writable, idx);
                    currIndex.put(k,idx + 1);
                }
            }
        }

        return ret;
    }"
"public static Environment merge(Environment env1, Environment env2) {
		final Environment mergedEnv = new Environment();

		// merge tables
		final Map<String, TableEntry> tables = new LinkedHashMap<>(env1.getTables());
		tables.putAll(env2.getTables());
		mergedEnv.tables = tables;

		// merge functions
		final Map<String, FunctionEntry> functions = new HashMap<>(env1.getFunctions());
		functions.putAll(env2.getFunctions());
		mergedEnv.functions = functions;

		// merge execution properties
		mergedEnv.execution = ExecutionEntry.merge(env1.getExecution(), env2.getExecution());

		// merge deployment properties
		mergedEnv.deployment = DeploymentEntry.merge(env1.getDeployment(), env2.getDeployment());

		return mergedEnv;
	}"
"private void appendCondition(MappingConfig.DbMapping dbMapping, StringBuilder sql, Map<String, Integer> ctype,
                                 List<Map<String, ?>> values, Map<String, Object> d) {
        appendCondition(dbMapping, sql, ctype, values, d, null);
    }"
"public static StringDictionary load(String path, String separator)
    {
        StringDictionary dictionary = new StringDictionary(separator);
        if (dictionary.load(path)) return dictionary;
        return null;
    }"
"private static StatusRuntimeException toStatusRuntimeException(Throwable t) {
    Throwable cause = checkNotNull(t, ""t"");
    while (cause != null) {
      // If we have an embedded status, use it and replace the cause
      if (cause instanceof StatusException) {
        StatusException se = (StatusException) cause;
        return new StatusRuntimeException(se.getStatus(), se.getTrailers());
      } else if (cause instanceof StatusRuntimeException) {
        StatusRuntimeException se = (StatusRuntimeException) cause;
        return new StatusRuntimeException(se.getStatus(), se.getTrailers());
      }
      cause = cause.getCause();
    }
    return Status.UNKNOWN.withDescription(""unexpected exception"").withCause(t)
        .asRuntimeException();
  }"
"public Launcher decorateLauncher(AbstractBuild build, Launcher launcher, BuildListener listener) throws IOException, InterruptedException, RunnerAbortedException {
        return launcher;
    }"
"@Override
    public String getSecureVirtualHostName() {
        if (this.getSecurePortEnabled()) {
            return configInstance.getStringProperty(namespace + SECURE_VIRTUAL_HOSTNAME_KEY,
                    super.getSecureVirtualHostName()).get();
        } else {
            return null;
        }
    }"
"public static ShearCaptcha createShearCaptcha(int width, int height, int codeCount, int thickness) {
		return new ShearCaptcha(width, height, codeCount, thickness);
	}"
"public static TextElement text(String format, InlineElement... elements) {
		return new TextElement(format, Arrays.asList(elements));
	}"
"@Override
	public synchronized RecordTag read(long tagId) throws DatabaseException {
    	SqlPreparedStatementWrapper psRead = null;
        try {
        	psRead = DbSQL.getSingleton().getPreparedStatement(""tag.ps.read"");
			psRead.getPs().setLong(1, tagId);
			
			try (ResultSet rs = psRead.getPs().executeQuery()) {
				return build(rs);
			}
		} catch (SQLException e) {
			throw new DatabaseException(e);
		} finally {
			DbSQL.getSingleton().releasePreparedStatement(psRead);
		}
	}"
"@Override
   public PreparedStatement prepareStatement(String sql) throws SQLException
   {
      return ProxyFactory.getProxyPreparedStatement(this, trackStatement(delegate.prepareStatement(sql)));
   }"
"private void manage() throws InterruptedException
  {
    log.info(""Beginning management in %s."", config.getStartDelay());
    Thread.sleep(config.getStartDelay().getMillis());

    // Ignore return value- we'll get the IDs and futures from getKnownTasks later.
    taskRunner.restore();

    while (active) {
      giant.lock();

      try {
        // Task futures available from the taskRunner
        final Map<String, ListenableFuture<TaskStatus>> runnerTaskFutures = new HashMap<>();
        for (final TaskRunnerWorkItem workItem : taskRunner.getKnownTasks()) {
          runnerTaskFutures.put(workItem.getTaskId(), workItem.getResult());
        }
        // Attain futures for all active tasks (assuming they are ready to run).
        // Copy tasks list, as notifyStatus may modify it.
        for (final Task task : ImmutableList.copyOf(tasks)) {
          if (!taskFutures.containsKey(task.getId())) {
            final ListenableFuture<TaskStatus> runnerTaskFuture;
            if (runnerTaskFutures.containsKey(task.getId())) {
              runnerTaskFuture = runnerTaskFutures.get(task.getId());
            } else {
              // Task should be running, so run it.
              final boolean taskIsReady;
              try {
                taskIsReady = task.isReady(taskActionClientFactory.create(task));
              }
              catch (Exception e) {
                log.warn(e, ""Exception thrown during isReady for task: %s"", task.getId());
                notifyStatus(task, TaskStatus.failure(task.getId()), ""failed because of exception[%s]"", e.getClass());
                continue;
              }
              if (taskIsReady) {
                log.info(""Asking taskRunner to run: %s"", task.getId());
                runnerTaskFuture = taskRunner.run(task);
              } else {
                continue;
              }
            }
            taskFutures.put(task.getId(), attachCallbacks(task, runnerTaskFuture));
          } else if (isTaskPending(task)) {
            // if the taskFutures contain this task and this task is pending, also let the taskRunner
            // to run it to guarantee it will be assigned to run
            // see https://github.com/apache/incubator-druid/pull/6991
            taskRunner.run(task);
          }
        }
        // Kill tasks that shouldn't be running
        final Set<String> tasksToKill = Sets.difference(
            runnerTaskFutures.keySet(),
            ImmutableSet.copyOf(
                Lists.transform(
                    tasks,
                    new Function<Task, Object>()
                    {
                      @Override
                      public String apply(Task task)
                      {
                        return task.getId();
                      }
                    }
                )
            )
        );
        if (!tasksToKill.isEmpty()) {
          log.info(""Asking taskRunner to clean up %,d tasks."", tasksToKill.size());
          for (final String taskId : tasksToKill) {
            try {
              taskRunner.shutdown(
                  taskId,
                  ""task is not in runnerTaskFutures[%s]"",
                  runnerTaskFutures.keySet()
              );
            }
            catch (Exception e) {
              log.warn(e, ""TaskRunner failed to clean up task: %s"", taskId);
            }
          }
        }
        // awaitNanos because management may become necessary without this condition signalling,
        // due to e.g. tasks becoming ready when other folks mess with the TaskLockbox.
        managementMayBeNecessary.awaitNanos(MANAGEMENT_WAIT_TIMEOUT_NANOS);
      }
      finally {
        giant.unlock();
      }
    }
  }"
"JobSubmissionResult finalizeExecute() throws ProgramInvocationException {
		return client.run(detachedPlan, jarFilesToAttach, classpathsToAttach, userCodeClassLoader, savepointSettings);
	}"
"@Override
    public ModelAndView resolveException(final HttpServletRequest request,
                                         final HttpServletResponse response, final Object handler,
                                         final Exception exception) {


        if (!(exception instanceof FlowExecutionRepositoryException) || exception instanceof BadlyFormattedFlowExecutionKeyException) {
            LOGGER.debug(""Ignoring the received exception due to a type mismatch"", exception);
            return null;
        }

        val urlToRedirectTo = request.getRequestURI()
            + (request.getQueryString() != null ? '?'
            + request.getQueryString() : StringUtils.EMPTY);

        LOGGER.debug(""Error getting flow information for URL [{}]"", urlToRedirectTo, exception);
        val model = new HashMap<String, Object>();
        model.put(this.modelKey, StringEscapeUtils.escapeHtml4(exception.getMessage()));

        return new ModelAndView(new RedirectView(urlToRedirectTo), model);
    }"
"protected void checkPausedAndWait() {
		pauseLock.lock();

		// While the status is paused, keep waiting
		while (paused) {
			try {
				pausedCondition.await();
			} catch (InterruptedException e) {
			}
		}

		pauseLock.unlock();
	}"
"private static boolean isYunOS() {
        try {
            String version = System.getProperty(""ro.yunos.version"");
            String vmName = System.getProperty(""java.vm.name"");
            return (vmName != null && vmName.toLowerCase().contains(""lemur""))
                    || (version != null && version.trim().length() > 0);
        } catch (Exception ignore) {
            return false;
        }
    }"
"private int dequeue(ChannelHandlerContext ctx, int minConsume) {
        if (queue != null) {

            int consumed = 0;

            Object msg;
            while ((consumed < minConsume) || config.isAutoRead()) {
                msg = queue.poll();
                if (msg == null) {
                    break;
                }

                ++consumed;
                ctx.fireChannelRead(msg);
            }

            // We're firing a completion event every time one (or more)
            // messages were consumed and the queue ended up being drained
            // to an empty state.
            if (queue.isEmpty() && consumed > 0) {
                ctx.fireChannelReadComplete();
            }

            return consumed;
        }

        return 0;
    }"
"private ListenableFuture<ZkWorker> addWorker(final Worker worker)
  {
    log.info(""Worker[%s] reportin' for duty!"", worker.getHost());

    try {
      cancelWorkerCleanup(worker.getHost());

      final String workerStatusPath = JOINER.join(indexerZkConfig.getStatusPath(), worker.getHost());
      final PathChildrenCache statusCache = workerStatusPathChildrenCacheFactory.make(cf, workerStatusPath);
      final SettableFuture<ZkWorker> retVal = SettableFuture.create();
      final ZkWorker zkWorker = new ZkWorker(
          worker,
          statusCache,
          jsonMapper
      );

      // Add status listener to the watcher for status changes
      zkWorker.addListener(
          new PathChildrenCacheListener()
          {
            @Override
            public void childEvent(CuratorFramework client, PathChildrenCacheEvent event)
            {
              final String taskId;
              final RemoteTaskRunnerWorkItem taskRunnerWorkItem;
              synchronized (statusLock) {
                try {
                  switch (event.getType()) {
                    case CHILD_ADDED:
                    case CHILD_UPDATED:
                      taskId = ZKPaths.getNodeFromPath(event.getData().getPath());
                      final TaskAnnouncement announcement = jsonMapper.readValue(
                          event.getData().getData(), TaskAnnouncement.class
                      );

                      log.info(
                          ""Worker[%s] wrote %s status for task [%s] on [%s]"",
                          zkWorker.getWorker().getHost(),
                          announcement.getTaskStatus().getStatusCode(),
                          taskId,
                          announcement.getTaskLocation()
                      );

                      // Synchronizing state with ZK
                      statusLock.notifyAll();

                      final RemoteTaskRunnerWorkItem tmp;
                      if ((tmp = runningTasks.get(taskId)) != null) {
                        taskRunnerWorkItem = tmp;
                      } else {
                        final RemoteTaskRunnerWorkItem newTaskRunnerWorkItem = new RemoteTaskRunnerWorkItem(
                            taskId,
                            announcement.getTaskType(),
                            zkWorker.getWorker(),
                            TaskLocation.unknown(),
                            announcement.getTaskDataSource()
                        );
                        final RemoteTaskRunnerWorkItem existingItem = runningTasks.putIfAbsent(
                            taskId,
                            newTaskRunnerWorkItem
                        );
                        if (existingItem == null) {
                          log.warn(
                              ""Worker[%s] announced a status for a task I didn't know about, adding to runningTasks: %s"",
                              zkWorker.getWorker().getHost(),
                              taskId
                          );
                          taskRunnerWorkItem = newTaskRunnerWorkItem;
                        } else {
                          taskRunnerWorkItem = existingItem;
                        }
                      }

                      if (!announcement.getTaskLocation().equals(taskRunnerWorkItem.getLocation())) {
                        taskRunnerWorkItem.setLocation(announcement.getTaskLocation());
                        TaskRunnerUtils.notifyLocationChanged(listeners, taskId, announcement.getTaskLocation());
                      }

                      if (announcement.getTaskStatus().isComplete()) {
                        taskComplete(taskRunnerWorkItem, zkWorker, announcement.getTaskStatus());
                        runPendingTasks();
                      }
                      break;
                    case CHILD_REMOVED:
                      taskId = ZKPaths.getNodeFromPath(event.getData().getPath());
                      taskRunnerWorkItem = runningTasks.remove(taskId);
                      if (taskRunnerWorkItem != null) {
                        log.info(""Task[%s] just disappeared!"", taskId);
                        taskRunnerWorkItem.setResult(TaskStatus.failure(taskId));
                        TaskRunnerUtils.notifyStatusChanged(listeners, taskId, TaskStatus.failure(taskId));
                      } else {
                        log.info(""Task[%s] went bye bye."", taskId);
                      }
                      break;
                    case INITIALIZED:
                      if (zkWorkers.putIfAbsent(worker.getHost(), zkWorker) == null) {
                        retVal.set(zkWorker);
                      } else {
                        final String message = StringUtils.format(
                            ""WTF?! Tried to add already-existing worker[%s]"",
                            worker.getHost()
                        );
                        log.makeAlert(message)
                           .addData(""workerHost"", worker.getHost())
                           .addData(""workerIp"", worker.getIp())
                           .emit();
                        retVal.setException(new IllegalStateException(message));
                      }
                      runPendingTasks();
                      break;
                    case CONNECTION_SUSPENDED:
                    case CONNECTION_RECONNECTED:
                    case CONNECTION_LOST:
                      // do nothing
                  }
                }
                catch (Exception e) {
                  log.makeAlert(e, ""Failed to handle new worker status"")
                     .addData(""worker"", zkWorker.getWorker().getHost())
                     .addData(""znode"", event.getData().getPath())
                     .emit();
                }
              }
            }
          }
      );
      zkWorker.start();
      return retVal;
    }
    catch (Exception e) {
      throw new RuntimeException(e);
    }
  }"
"private javax.swing.JToolBar getPanelToolbar() {
		if (panelToolbar == null) {

			// Initialize the toolbar
			panelToolbar = new javax.swing.JToolBar();
			panelToolbar.setLayout(new java.awt.GridBagLayout());
			panelToolbar.setEnabled(true);
			panelToolbar.setFloatable(false);
			panelToolbar.setRollover(true);
			panelToolbar.setPreferredSize(new java.awt.Dimension(800, 30));
			panelToolbar.setName(""HttpSessionToolbar"");

			// Add elements
			GridBagConstraints labelGridBag = new GridBagConstraints();
			GridBagConstraints siteSelectGridBag = new GridBagConstraints();
			GridBagConstraints newSessionGridBag = new GridBagConstraints();
			GridBagConstraints emptyGridBag = new GridBagConstraints();
			GridBagConstraints optionsGridBag = new GridBagConstraints();
			GridBagConstraints exportButtonGbc = new GridBagConstraints();

			labelGridBag.gridx = 0;
			labelGridBag.gridy = 0;
			labelGridBag.insets = new java.awt.Insets(0, 0, 0, 0);
			labelGridBag.anchor = java.awt.GridBagConstraints.WEST;

			siteSelectGridBag.gridx = 1;
			siteSelectGridBag.gridy = 0;
			siteSelectGridBag.insets = new java.awt.Insets(0, 0, 0, 0);
			siteSelectGridBag.anchor = java.awt.GridBagConstraints.WEST;

			newSessionGridBag.gridx = 2;
			newSessionGridBag.gridy = 0;
			newSessionGridBag.insets = new java.awt.Insets(0, 0, 0, 0);
			newSessionGridBag.anchor = java.awt.GridBagConstraints.WEST;

			exportButtonGbc.gridx = 3;
			exportButtonGbc.gridy = 0;
			exportButtonGbc.insets = new java.awt.Insets(0, 0, 0, 0);
			exportButtonGbc.anchor = java.awt.GridBagConstraints.WEST;

			emptyGridBag.gridx = 4;
			emptyGridBag.gridy = 0;
			emptyGridBag.weightx = 1.0;
			emptyGridBag.weighty = 1.0;
			emptyGridBag.insets = new java.awt.Insets(0, 0, 0, 0);
			emptyGridBag.anchor = java.awt.GridBagConstraints.WEST;
			emptyGridBag.fill = java.awt.GridBagConstraints.HORIZONTAL;

			optionsGridBag.gridx = 5;
			optionsGridBag.gridy = 0;
			optionsGridBag.insets = new java.awt.Insets(0, 0, 0, 0);
			optionsGridBag.anchor = java.awt.GridBagConstraints.EAST;

			JLabel label = new JLabel(Constant.messages.getString(""httpsessions.toolbar.site.label""));

			panelToolbar.add(label, labelGridBag);
			panelToolbar.add(getSiteSelect(), siteSelectGridBag);
			panelToolbar.add(getNewSessionButton(), newSessionGridBag);
			panelToolbar.add(getExportButton(), exportButtonGbc);
			panelToolbar.add(getOptionsButton(), optionsGridBag);

			// Add an empty JLabel to fill the space
			panelToolbar.add(new JLabel(), emptyGridBag);
		}
		return panelToolbar;
	}"
"public final boolean nextOneRow(BitSet columns, boolean after) {
        final boolean hasOneRow = buffer.hasRemaining();

        if (hasOneRow) {
            int column = 0;

            for (int i = 0; i < columnLen; i++)
                if (columns.get(i)) {
                    column++;
                }

            if (after && partial) {
                partialBits.clear();
                long valueOptions = buffer.getPackedLong();
                int PARTIAL_JSON_UPDATES = 1;
                if ((valueOptions & PARTIAL_JSON_UPDATES) != 0) {
                    partialBits.set(1);
                    buffer.forward((jsonColumnCount + 7) / 8);
                }
            }
            nullBitIndex = 0;
            nullBits.clear();
            buffer.fillBitmap(nullBits, column);

        }
        return hasOneRow;
    }"
"public void addJob(final JobID jobId, final String defaultTargetAddress) throws Exception {
		Preconditions.checkState(JobLeaderService.State.STARTED == state, ""The service is currently not running."");

		LOG.info(""Add job {} for job leader monitoring."", jobId);

		final LeaderRetrievalService leaderRetrievalService = highAvailabilityServices.getJobManagerLeaderRetriever(
			jobId,
			defaultTargetAddress);

		JobLeaderService.JobManagerLeaderListener jobManagerLeaderListener = new JobManagerLeaderListener(jobId);

		final Tuple2<LeaderRetrievalService, JobManagerLeaderListener> oldEntry = jobLeaderServices.put(jobId, Tuple2.of(leaderRetrievalService, jobManagerLeaderListener));

		if (oldEntry != null) {
			oldEntry.f0.stop();
			oldEntry.f1.stop();
		}

		leaderRetrievalService.start(jobManagerLeaderListener);
	}"
"private static boolean isSupportedCharset(MediaType mediaType) {
        Map<String, String> parameters = mediaType.getParameters();
        if (parameters == null || parameters.isEmpty()) {
            return true;
        }
        String charset = parameters.get(""charset"");
        return charset == null
                || ""UTF-8"".equalsIgnoreCase(charset)
                || ""ISO-8859-1"".equalsIgnoreCase(charset);
    }"
"public SslContext build() throws SSLException {
        if (forServer) {
            return SslContext.newServerContextInternal(provider, sslContextProvider, trustCertCollection,
                trustManagerFactory, keyCertChain, key, keyPassword, keyManagerFactory,
                ciphers, cipherFilter, apn, sessionCacheSize, sessionTimeout, clientAuth, protocols, startTls,
                enableOcsp);
        } else {
            return SslContext.newClientContextInternal(provider, sslContextProvider, trustCertCollection,
                trustManagerFactory, keyCertChain, key, keyPassword, keyManagerFactory,
                ciphers, cipherFilter, apn, protocols, sessionCacheSize, sessionTimeout, enableOcsp);
        }
    }"
"protected <T extends SAMLObject> void prepareSamlOutboundProtocolMessageSigningHandler(final MessageContext<T> outboundContext) throws Exception {
        LOGGER.trace(""Attempting to sign the outbound SAML message..."");
        val handler = new SAMLOutboundProtocolMessageSigningHandler();
        handler.setSignErrorResponses(casProperties.getAuthn().getSamlIdp().getResponse().isSignError());
        handler.invoke(outboundContext);
        LOGGER.debug(""Signed SAML message successfully"");
    }"
"@Internal
	public static Set<Annotation> readDualForwardAnnotations(Class<?> udfClass) {

		// get readSet annotation from stub
		ForwardedFieldsFirst forwardedFields1 = udfClass.getAnnotation(ForwardedFieldsFirst.class);
		ForwardedFieldsSecond forwardedFields2 = udfClass.getAnnotation(ForwardedFieldsSecond.class);

		// get readSet annotation from stub
		NonForwardedFieldsFirst nonForwardedFields1 = udfClass.getAnnotation(NonForwardedFieldsFirst.class);
		NonForwardedFieldsSecond nonForwardedFields2 = udfClass.getAnnotation(NonForwardedFieldsSecond.class);

		ReadFieldsFirst readSet1 = udfClass.getAnnotation(ReadFieldsFirst.class);
		ReadFieldsSecond readSet2 = udfClass.getAnnotation(ReadFieldsSecond.class);

		Set<Annotation> annotations = new HashSet<Annotation>();

		if (nonForwardedFields1 != null && forwardedFields1 != null) {
			throw new InvalidProgramException(""Either "" + ForwardedFieldsFirst.class.getSimpleName() + "" or "" +
					NonForwardedFieldsFirst.class.getSimpleName() + "" can be annotated to a function, not both."");
		} else if (forwardedFields1 != null) {
			annotations.add(forwardedFields1);
		} else if (nonForwardedFields1 != null) {
			annotations.add(nonForwardedFields1);
		}

		if (forwardedFields2 != null && nonForwardedFields2 != null) {
			throw new InvalidProgramException(""Either "" + ForwardedFieldsSecond.class.getSimpleName() + "" or "" +
					NonForwardedFieldsSecond.class.getSimpleName() + "" can be annotated to a function, not both."");
		} else if (forwardedFields2 != null) {
			annotations.add(forwardedFields2);
		} else if (nonForwardedFields2 != null) {
			annotations.add(nonForwardedFields2);
		}

		if (readSet1 != null) {
			annotations.add(readSet1);
		}
		if (readSet2 != null) {
			annotations.add(readSet2);
		}

		return !annotations.isEmpty() ? annotations : null;
	}"
"@Internal
	public <R> SingleOutputStreamOperator<R> process(
			ProcessFunction<T, R> processFunction,
			TypeInformation<R> outputType) {

		ProcessOperator<T, R> operator = new ProcessOperator<>(clean(processFunction));

		return transform(""Process"", outputType, operator);
	}"
"public void iterateSample(Word2VecParam param, VocabWord w1, VocabWord w2, double alpha,
                    List<Triple<Integer, Integer, Integer>> changed) {
        if (w2 == null || w2.getIndex() < 0 || w1.getIndex() == w2.getIndex() || w1.getWord().equals(""STOP"")
                        || w2.getWord().equals(""STOP"") || w1.getWord().equals(""UNK"") || w2.getWord().equals(""UNK""))
            return;
        int vectorLength = param.getVectorLength();
        InMemoryLookupTable weights = param.getWeights();
        boolean useAdaGrad = param.isUseAdaGrad();
        double negative = param.getNegative();
        INDArray table = param.getTable();
        double[] expTable = param.getExpTable().getValue();
        double MAX_EXP = 6;
        int numWords = param.getNumWords();
        //current word vector
        INDArray l1 = weights.vector(w2.getWord());


        //error for current word and context
        INDArray neu1e = Nd4j.create(vectorLength);

        for (int i = 0; i < w1.getCodeLength(); i++) {
            int code = w1.getCodes().get(i);
            int point = w1.getPoints().get(i);

            INDArray syn1 = weights.getSyn1().slice(point);

            double dot = Nd4j.getBlasWrapper().level1().dot(syn1.length(), 1.0, l1, syn1);

            if (dot < -MAX_EXP || dot >= MAX_EXP)
                continue;

            int idx = (int) ((dot + MAX_EXP) * ((double) expTable.length / MAX_EXP / 2.0));

            //score
            double f = expTable[idx];
            //gradient
            double g = (1 - code - f) * (useAdaGrad ? w1.getGradient(i, alpha, alpha) : alpha);


            Nd4j.getBlasWrapper().level1().axpy(syn1.length(), g, syn1, neu1e);
            Nd4j.getBlasWrapper().level1().axpy(syn1.length(), g, l1, syn1);


            changed.add(new Triple<>(point, w1.getIndex(), -1));

        }


        changed.add(new Triple<>(w1.getIndex(), w2.getIndex(), -1));
        //negative sampling
        if (negative > 0) {
            int target = w1.getIndex();
            int label;
            INDArray syn1Neg = weights.getSyn1Neg().slice(target);

            for (int d = 0; d < negative + 1; d++) {
                if (d == 0) {

                    label = 1;
                } else {
                    nextRandom.set(nextRandom.get() * 25214903917L + 11);
                    // FIXME: int cast
                    target = table.getInt((int) (nextRandom.get() >> 16) % (int) table.length());
                    if (target == 0)
                        target = (int) nextRandom.get() % (numWords - 1) + 1;
                    if (target == w1.getIndex())
                        continue;
                    label = 0;
                }

                double f = Nd4j.getBlasWrapper().dot(l1, syn1Neg);
                double g;
                if (f > MAX_EXP)
                    g = useAdaGrad ? w1.getGradient(target, (label - 1), alpha) : (label - 1) * alpha;
                else if (f < -MAX_EXP)
                    g = label * (useAdaGrad ? w1.getGradient(target, alpha, alpha) : alpha);
                else
                    g = useAdaGrad ? w1
                                    .getGradient(target,
                                                    label - expTable[(int) ((f + MAX_EXP)
                                                                    * (expTable.length / MAX_EXP / 2))],
                                                    alpha)
                                    : (label - expTable[(int) ((f + MAX_EXP) * (expTable.length / MAX_EXP / 2))])
                                                    * alpha;
                Nd4j.getBlasWrapper().level1().axpy(l1.length(), g, neu1e, l1);

                Nd4j.getBlasWrapper().level1().axpy(l1.length(), g, syn1Neg, l1);

                changed.add(new Triple<>(-1, -1, label));

            }
        }


        Nd4j.getBlasWrapper().level1().axpy(l1.length(), 1.0f, neu1e, l1);


    }"
"@Override
	public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {

		if (cause instanceof TransportException) {
			notifyAllChannelsOfErrorAndClose(cause);
		}
		else {
			final SocketAddress remoteAddr = ctx.channel().remoteAddress();

			final TransportException tex;

			// Improve on the connection reset by peer error message
			if (cause instanceof IOException
					&& cause.getMessage().equals(""Connection reset by peer"")) {

				tex = new RemoteTransportException(
						""Lost connection to task manager '"" + remoteAddr + ""'. This indicates ""
								+ ""that the remote task manager was lost."", remoteAddr, cause);
			}
			else {
				SocketAddress localAddr = ctx.channel().localAddress();
				tex = new LocalTransportException(
					String.format(""%s (connection to '%s')"", cause.getMessage(), remoteAddr),
					localAddr,
					cause);
			}

			notifyAllChannelsOfErrorAndClose(tex);
		}
	}"
"public static SameDiff fromFlatBuffers(ByteBuffer bbIn) throws IOException {

        FlatGraph fg = FlatGraph.getRootAsFlatGraph(bbIn);

        int numOps = fg.nodesLength();
        int numVars = fg.variablesLength();
        List<FlatNode> ops = new ArrayList<>(numOps);
        for( int i=0; i<numOps; i++ ){
            ops.add(fg.nodes(i));
        }
        List<FlatVariable> vars = new ArrayList<>(numVars);
        for( int i = 0; i < numVars; i++) {
            vars.add(fg.variables(i));
        }

        FlatConfiguration conf = fg.configuration();

        /* Reconstruct the graph
        We'll do the reconstruction manually here, rather than using sd.var(...), so that we have more control
        over the final result.
         */

        SameDiff sd = SameDiff.create();

        //Reconstruct placeholders
        int numPlaceholders = fg.placeholdersLength();
        Set<String> ph = new LinkedHashSet<>();
        for(int i=0; i<numPlaceholders; i++ ){
            ph.add(fg.placeholders(i));
        }

        //Reconstruct variables:
        Map<Integer,SDVariable> varNodeIds = new HashMap<>();
        Map<Pair<Integer,Integer>, SDVariable> variablesByNodeAndOutNum = new HashMap<>();
        Map<String,List<SDVariable>> variablesByName = new HashMap<>();
        for(FlatVariable v : vars){
            int shapeLength = v.shapeLength();
            long[] shape = new long[shapeLength];
            for( int i = 0; i < shapeLength; i++) {
                shape[i] = v.shape(i);
            }

            String n = v.name();

            byte dtypeByte = v.dtype();
            org.nd4j.linalg.api.buffer.DataType dtype = FlatBuffersMapper.getDataTypeFromByte(dtypeByte);

            //TODO Infer this properly! Could be constant, etc.
            VariableType vt = VariableType.values()[v.variabletype()];
            SDVariable var = new SDVariable(n, vt, sd, shape, dtype, null);
            sd.variables.put(n, Variable.builder().name(n).variable(var).build());
            sd.variableNameToShape.put(n, shape);


            FlatArray fa = v.ndarray();
            if(fa != null && vt != VariableType.ARRAY){
                INDArray arr;
                try(MemoryWorkspace ws = Nd4j.getWorkspaceManager().scopeOutOfWorkspaces()) {
                    arr = Nd4j.createFromFlatArray(fa);
                }
                sd.setArrayForVariable(n, arr);
            }

            IntPair id = v.id();    //First value: node (op) id. Second: output number
            variablesByNodeAndOutNum.put(new Pair<>(id.first(), id.second()), var);

            if(!variablesByName.containsKey(n)){
                variablesByName.put(n, new ArrayList<SDVariable>());
            }

            List<SDVariable> list = variablesByName.get(n);
            list.add(var);
        }

        //Reconstruct ops:
        for(FlatNode fn : ops){
            DifferentialFunction df = FlatBuffersMapper.fromFlatNode(fn);
            String name = fn.name();
            df.setSameDiff(sd);
            df.setOwnName(name);
            if(sd.ops.containsKey(name)){
                sd.ops.get(name).setOp(df);
            } else {
                sd.ops.put(name, SameDiffOp.builder().name(name).op(df).build());
            }

            int outLength = fn.outputLength();
            int[] outs = new int[outLength];
            for( int i=0; i<outLength; i++ ){
                outs[i] = fn.output(i);
            }

            int opId = fn.id();

            //Work out inputs and outputs:
            int[] output = new int[fn.outputLength()];
            for (int i = 0; i < output.length; i++) {
                output[i] = fn.output(i);
            }
            int[] input = new int[fn.inputLength()];
            for (int i = 0; i < input.length; i++) {
                input[i] = fn.input(i);
            }
            IntPair[] inputPaired = new IntPair[fn.inputPairedLength()];
            List<Pair<Integer,Integer>> intPairList = new ArrayList<>();
            for (int i = 0; i < inputPaired.length; i++) {
                inputPaired[i] = fn.inputPaired(i);
                intPairList.add(new Pair<>(inputPaired[i].first(), inputPaired[i].second()));
            }

            String[] inputNames = new String[inputPaired.length];
            for(int i=0; i<inputPaired.length; i++ ){
                int nodeId = inputPaired[i].first();
                int nodeOutNum = inputPaired[i].second();
                SDVariable varIn = variablesByNodeAndOutNum.get(new Pair<>(nodeId, nodeOutNum));
                if(varIn == null){
                    //The variable corresponding to this op was not
                }
                inputNames[i] = varIn.getVarName();
            }
            sd.ops.get(df.getOwnName()).setInputsToOp(Arrays.asList(inputNames));

            //Record that input variables are input to this op
            for(String inName : inputNames) {
                Variable v = sd.getVariables().get(inName);
                if(v.getInputsForOp() == null){
                    v.setInputsForOp(new ArrayList<String>());
                }
                if(!v.getInputsForOp().contains(df.getOwnName())){
                    v.getInputsForOp().add(df.getOwnName());
                }
            }

            List<SDVariable> varsForOp = variablesByName.get(name);

            //Can't assume that variables for the op have all been defined. For example, if we export before execution in SameDiff
            //In theory, we can reconstruct the output variables (minus names) if we know the number of op outputs
            //And we can calculate the op outputs - in most cases - after the op has been created and parameters set
            int numOutputs = df.getNumOutputs();
            if(numOutputs <= 0){
                numOutputs = fn.outputLength();
            }

            String[] varNames = null;
            if(varsForOp != null && varsForOp.size() == numOutputs){
                varNames = new String[varsForOp.size()];
                for( int i=0; i<varNames.length; i++ ){
                    varNames[i] = varsForOp.get(i).getVarName();
                    sd.getVariables().get(varNames[i]).setOutputOfOp(df.getOwnName());
                }
                sd.ops.get(df.getOwnName()).setOutputsOfOp(Arrays.asList(varNames));
            } else {
                //We're missing some variables...
                int outputNamesLength = fn.outputNamesLength();
                varNames = new String[outputNamesLength];
                for( int i=0; i<outputNamesLength; i++ ){
                    String n = fn.outputNames(i);
                    varNames[i] = n;
                    if(!sd.variables.containsKey(n)){
                        //Need to create the variable - perhaps it wasn't exported. Note output of node -> can only be VARIABLE type
                        SDVariable var = new SDVariable(n, VariableType.VARIABLE, sd, null, null, null);
                        sd.variables.put(n, Variable.builder().name(n).variable(var).build());
                        variablesByNodeAndOutNum.put(new Pair<>(opId, i), var);
                    }
                    sd.getVariables().get(varNames[i]).setOutputOfOp(df.getOwnName());
                }
                sd.ops.get(df.getOwnName()).setOutputsOfOp(Arrays.asList(varNames));
            }

            //Check the op mapping int he variablesByNodeAndOutputNum
            //For multi-output ops, variables will have their own index, not related to the op index
            for( int i=0; i<varNames.length; i++ ){
                Pair<Integer,Integer> p = new Pair<>(opId, i);
                if(!variablesByNodeAndOutNum.containsKey(p)){
                    variablesByNodeAndOutNum.put(p, sd.getVariable(varNames[i]));
                }
            }
        }

        //Reconstruct loss variables
        if(fg.lossVariablesLength() > 0){
            for(int i=0; i<fg.lossVariablesLength(); i++ ){
                sd.addLossVariable(fg.lossVariables(i));
            }
        }

        return sd;
    }"
"private static Optional<String> findFirstManifestAttribute(File jarFile, String... attributes) throws IOException {
		if (attributes.length == 0) {
			return Optional.empty();
		}
		try (JarFile f = new JarFile(jarFile)) {
			return findFirstManifestAttribute(f, attributes);
		}
	}"
"public static boolean isSupportedType(EventListener listener) {
		for (Class<?> type : SUPPORTED_TYPES) {
			if (ClassUtils.isAssignableValue(type, listener)) {
				return true;
			}
		}
		return false;
	}"
"private void applyViewOptions(OptionsParam options) {
		if (getView() == null) {
			return;
		}

		breakPanel.setButtonsLocation(options.getViewParam().getBrkPanelViewOption());
		breakPanel.setButtonMode(options.getParamSet(BreakpointsParam.class).getButtonMode());
	}"
"public void doJson(StaplerRequest req, StaplerResponse rsp) throws IOException, ServletException {
        if (req.getParameter(""jsonp"") == null || permit(req)) {
            setHeaders(rsp);
            rsp.serveExposedBean(req,bean, req.getParameter(""jsonp"") == null ? Flavor.JSON : Flavor.JSONP);
        } else {
            rsp.sendError(HttpURLConnection.HTTP_FORBIDDEN, ""jsonp forbidden; implement jenkins.security.SecureRequester"");
        }
    }"
"@Deprecated
    public static SslContext newClientContext(
            SslProvider provider, TrustManagerFactory trustManagerFactory) throws SSLException {
        return newClientContext(provider, null, trustManagerFactory);
    }"
"private @CheckForNull Authentication retrieveAuthFromCookie(HttpServletRequest request, HttpServletResponse response, String cookieValueBase64){
        String cookieValue = decodeCookieBase64(cookieValueBase64);
        if (cookieValue == null) {
            String reason = ""Cookie token was not Base64 encoded; value was '"" + cookieValueBase64 + ""'"";
            cancelCookie(request, response, reason);
            return null;
        }
        if (logger.isDebugEnabled()) {
            logger.debug(""Remember-me cookie detected"");
        }

        String[] cookieTokens = StringUtils.delimitedListToStringArray(cookieValue, "":"");

        if (cookieTokens.length != 3) {
            cancelCookie(request, response, ""Cookie token did not contain 3 tokens separated by [:]"");
            return null;
        }

        long tokenExpiryTime;

        try {
            tokenExpiryTime = Long.parseLong(cookieTokens[1]);
        }
        catch (NumberFormatException nfe) {
            cancelCookie(request, response, ""Cookie token[1] did not contain a valid number"");
            return null;
        }

        if (isTokenExpired(tokenExpiryTime)) {
            cancelCookie(request, response, ""Cookie token[1] has expired"");
            return null;
        }

        // Check the user exists
        // Defer lookup until after expiry time checked, to
        // possibly avoid expensive lookup
        UserDetails userDetails = loadUserDetails(request, response, cookieTokens);

        if (userDetails == null) {
            cancelCookie(request, response, ""Cookie token[0] contained a username without user associated"");
            return null;
        }

        if (!isValidUserDetails(request, response, userDetails, cookieTokens)) {
            return null;
        }

        String receivedTokenSignature = cookieTokens[2];
        String expectedTokenSignature = makeTokenSignature(tokenExpiryTime, userDetails);

        boolean tokenValid = MessageDigest.isEqual(
                expectedTokenSignature.getBytes(StandardCharsets.US_ASCII),
                receivedTokenSignature.getBytes(StandardCharsets.US_ASCII)
        );
        if (!tokenValid) {
            cancelCookie(request, response, ""Cookie token[2] contained invalid signature"");
            return null;
        }

        // By this stage we have a valid token
        if (logger.isDebugEnabled()) {
            logger.debug(""Remember-me cookie accepted"");
        }

        RememberMeAuthenticationToken auth = new RememberMeAuthenticationToken(this.getKey(), userDetails,
                userDetails.getAuthorities());
        auth.setDetails(authenticationDetailsSource.buildDetails(request));

        return auth;
    }"
"Bucket getCurrentBucket() {
        long currentTime = time.getCurrentTimeInMillis();

        /* a shortcut to try and get the most common result of immediately finding the current bucket */

        /**
         * Retrieve the latest bucket if the given time is BEFORE the end of the bucket window, otherwise it returns NULL.
         * 
         * NOTE: This is thread-safe because it's accessing 'buckets' which is a LinkedBlockingDeque
         */
        Bucket currentBucket = buckets.peekLast();
        if (currentBucket != null && currentTime < currentBucket.windowStart + this.bucketSizeInMillseconds) {
            // if we're within the bucket 'window of time' return the current one
            // NOTE: We do not worry if we are BEFORE the window in a weird case of where thread scheduling causes that to occur,
            // we'll just use the latest as long as we're not AFTER the window
            return currentBucket;
        }

        /* if we didn't find the current bucket above, then we have to create one */

        /**
         * The following needs to be synchronized/locked even with a synchronized/thread-safe data structure such as LinkedBlockingDeque because
         * the logic involves multiple steps to check existence, create an object then insert the object. The 'check' or 'insertion' themselves
         * are thread-safe by themselves but not the aggregate algorithm, thus we put this entire block of logic inside synchronized.
         * 
         * I am using a tryLock if/then (http://download.oracle.com/javase/6/docs/api/java/util/concurrent/locks/Lock.html#tryLock())
         * so that a single thread will get the lock and as soon as one thread gets the lock all others will go the 'else' block
         * and just return the currentBucket until the newBucket is created. This should allow the throughput to be far higher
         * and only slow down 1 thread instead of blocking all of them in each cycle of creating a new bucket based on some testing
         * (and it makes sense that it should as well).
         * 
         * This means the timing won't be exact to the millisecond as to what data ends up in a bucket, but that's acceptable.
         * It's not critical to have exact precision to the millisecond, as long as it's rolling, if we can instead reduce the impact synchronization.
         * 
         * More importantly though it means that the 'if' block within the lock needs to be careful about what it changes that can still
         * be accessed concurrently in the 'else' block since we're not completely synchronizing access.
         * 
         * For example, we can't have a multi-step process to add a bucket, remove a bucket, then update the sum since the 'else' block of code
         * can retrieve the sum while this is all happening. The trade-off is that we don't maintain the rolling sum and let readers just iterate
         * bucket to calculate the sum themselves. This is an example of favoring write-performance instead of read-performance and how the tryLock
         * versus a synchronized block needs to be accommodated.
         */
        if (newBucketLock.tryLock()) {
            try {
                if (buckets.peekLast() == null) {
                    // the list is empty so create the first bucket
                    Bucket newBucket = new Bucket(currentTime);
                    buckets.addLast(newBucket);
                    return newBucket;
                } else {
                    // We go into a loop so that it will create as many buckets as needed to catch up to the current time
                    // as we want the buckets complete even if we don't have transactions during a period of time.
                    for (int i = 0; i < numberOfBuckets; i++) {
                        // we have at least 1 bucket so retrieve it
                        Bucket lastBucket = buckets.peekLast();
                        if (currentTime < lastBucket.windowStart + this.bucketSizeInMillseconds) {
                            // if we're within the bucket 'window of time' return the current one
                            // NOTE: We do not worry if we are BEFORE the window in a weird case of where thread scheduling causes that to occur,
                            // we'll just use the latest as long as we're not AFTER the window
                            return lastBucket;
                        } else if (currentTime - (lastBucket.windowStart + this.bucketSizeInMillseconds) > timeInMilliseconds) {
                            // the time passed is greater than the entire rolling counter so we want to clear it all and start from scratch
                            reset();
                            // recursively call getCurrentBucket which will create a new bucket and return it
                            return getCurrentBucket();
                        } else { // we're past the window so we need to create a new bucket
                            // create a new bucket and add it as the new 'last'
                            buckets.addLast(new Bucket(lastBucket.windowStart + this.bucketSizeInMillseconds));
                            // add the lastBucket values to the cumulativeSum
                            cumulativeSum.addBucket(lastBucket);
                        }
                    }
                    // we have finished the for-loop and created all of the buckets, so return the lastBucket now
                    return buckets.peekLast();
                }
            } finally {
                newBucketLock.unlock();
            }
        } else {
            currentBucket = buckets.peekLast();
            if (currentBucket != null) {
                // we didn't get the lock so just return the latest bucket while another thread creates the next one
                return currentBucket;
            } else {
                // the rare scenario where multiple threads raced to create the very first bucket
                // wait slightly and then use recursion while the other thread finishes creating a bucket
                try {
                    Thread.sleep(5);
                } catch (Exception e) {
                    // ignore
                }
                return getCurrentBucket();
            }
        }
    }"
"public SortedClassProbability[] sortByDescendingClassProbability(BinomialModelPrediction p) {
    String[] domainValues = m.getDomainValues(m.getResponseIdx());
    double[] classProbabilities = p.classProbabilities;
    return sortByDescendingClassProbability(domainValues, classProbabilities);
  }"
"@RequirePOST
    public void doDoInstall(StaplerRequest req, StaplerResponse rsp, @QueryParameter(""dir"") String _dir) throws IOException, ServletException {
        Jenkins.getInstance().checkPermission(Jenkins.ADMINISTER);

        if(installationDir!=null) {
            // installation already complete
            sendError(""Installation is already complete"",req,rsp);
            return;
        }
        if(!DotNet.isInstalled(2,0)) {
            sendError("".NET Framework 2.0 or later is required for this feature"",req,rsp);
            return;
        }

        File dir = new File(_dir).getAbsoluteFile();
        dir.mkdirs();
        if(!dir.exists()) {
            sendError(""Failed to create installation directory: ""+dir,req,rsp);
            return;
        }

        try {
            // copy files over there
            copy(req, rsp, dir, getClass().getResource(""/windows-service/jenkins.exe""),         ""jenkins.exe"");
            copy(req, rsp, dir, getClass().getResource(""/windows-service/jenkins.exe.config""),  ""jenkins.exe.config"");
            copy(req, rsp, dir, getClass().getResource(""/windows-service/jenkins.xml""),         ""jenkins.xml"");
            if(!hudsonWar.getCanonicalFile().equals(new File(dir,""jenkins.war"").getCanonicalFile()))
                copy(req, rsp, dir, hudsonWar.toURI().toURL(), ""jenkins.war"");

            // install as a service
            ByteArrayOutputStream baos = new ByteArrayOutputStream();
            StreamTaskListener task = new StreamTaskListener(baos);
            task.getLogger().println(""Installing a service"");
            int r = runElevated(new File(dir, ""jenkins.exe""), ""install"", task, dir);
            if(r!=0) {
                sendError(baos.toString(),req,rsp);
                return;
            }

            // installation was successful
            installationDir = dir;
            rsp.sendRedirect(""."");
        } catch (AbortException e) {
            // this exception is used as a signal to terminate processing. the error should have been already reported
        } catch (InterruptedException e) {
            throw new ServletException(e);
        }
    }"
"public boolean markInactive() {
		if (TaskSlotState.ACTIVE == state || TaskSlotState.ALLOCATED == state) {
			state = TaskSlotState.ALLOCATED;

			return true;
		} else {
			return false;
		}
	}"
"public static boolean degradeWeight(ProviderInfo providerInfo, int weight) {
        providerInfo.setStatus(ProviderStatus.DEGRADED);
        providerInfo.setWeight(weight);
        return true;
    }"
"public static <T extends Throwable> T convertFromOrSuppressedThrowable(Throwable throwable, Class<T> exceptionClass) {
		return convertFromOrSuppressedThrowable(throwable, exceptionClass, true);
	}"
"@Override
    public InputType getOutputType(InputType... inputType) throws InvalidKerasConfigurationException {
        if (inputType.length > 1)
            throw new InvalidKerasConfigurationException(
                    ""Keras SpatialDropout layer accepts only one input (received "" + inputType.length + "")"");
        return this.getSpatialDropoutLayer().getOutputType(-1, inputType[0]);
    }"
"public void addApiOptions(AbstractParam param) {
		// Add option parameter getters and setters via reflection
		this.param = param;
		Method[] methods = param.getClass().getDeclaredMethods();
		Arrays.sort(methods, METHOD_NAME_COMPARATOR);
		List<String> addedActions = new ArrayList<>();
		// Check for string setters (which take precedence)
		for (Method method : methods) {
			if (isIgnored(method)) {
				continue;
			}

			boolean deprecated = method.getAnnotation(Deprecated.class) != null;

			if (method.getName().startsWith(""get"") && method.getParameterTypes().length == 0) {
				ApiView view = new ApiView(GET_OPTION_PREFIX + method.getName().substring(3));
				setApiOptionDeprecated(view, deprecated);
				addApiView(view);
			}
			if (method.getName().startsWith(""is"") && method.getParameterTypes().length == 0) {
				ApiView view = new ApiView(GET_OPTION_PREFIX + method.getName().substring(2));
				setApiOptionDeprecated(view, deprecated);
				addApiView(view);
			}
			if (method.getName().startsWith(""set"") && method.getParameterTypes().length == 1 && 
					method.getParameterTypes()[0].equals(String.class)) {
				ApiAction action = new ApiAction(SET_OPTION_PREFIX + method.getName().substring(3), 
						new String[]{""String""});
				setApiOptionDeprecated(action, deprecated);
				this.addApiAction(action);
				addedActions.add(method.getName());
			}
			if (method.getName().startsWith(""add"") && method.getParameterTypes().length == 1 && 
					method.getParameterTypes()[0].equals(String.class)) {
				ApiAction action = new ApiAction(ADD_OPTION_PREFIX + method.getName().substring(3), 
						new String[]{""String""});
				setApiOptionDeprecated(action, deprecated);
				this.addApiAction(action);
				addedActions.add(method.getName());
			}
			if (method.getName().startsWith(""remove"") && method.getParameterTypes().length == 1 && 
					method.getParameterTypes()[0].equals(String.class)) {
				ApiAction action = new ApiAction(REMOVE_OPTION_PREFIX + method.getName().substring(6), 
						new String[]{""String""});
				setApiOptionDeprecated(action, deprecated);
				this.addApiAction(action);
				addedActions.add(method.getName());
			}
		}
		// Now check for non string setters
		for (Method method : methods) {
			if (isIgnored(method)) {
				continue;
			}

			boolean deprecated = method.getAnnotation(Deprecated.class) != null;

			if (method.getName().startsWith(""set"") && method.getParameterTypes().length == 1 && ! addedActions.contains(method.getName())) {
				// Non String setter
				if (method.getParameterTypes()[0].equals(Integer.class) || method.getParameterTypes()[0].equals(int.class)) {
					ApiAction action = new ApiAction(SET_OPTION_PREFIX + method.getName().substring(3),
							new String[]{""Integer""});
					setApiOptionDeprecated(action, deprecated);
					this.addApiAction(action);
					addedActions.add(method.getName());	// Just in case there are more overloads
				} else if (method.getParameterTypes()[0].equals(Boolean.class) || method.getParameterTypes()[0].equals(boolean.class)) {
					ApiAction action = new ApiAction(SET_OPTION_PREFIX + method.getName().substring(3),
							new String[]{""Boolean""});
					setApiOptionDeprecated(action, deprecated);
					this.addApiAction(action);
					addedActions.add(method.getName());	// Just in case there are more overloads
				}
			}
		}
		
	}"
"private static String getBase64EncodedString(String str) {
    ByteBuf byteBuf = null;
    ByteBuf encodedByteBuf = null;
    try {
      byteBuf = Unpooled.wrappedBuffer(str.getBytes(StandardCharsets.UTF_8));
      encodedByteBuf = Base64.encode(byteBuf);
      return encodedByteBuf.toString(StandardCharsets.UTF_8);
    } finally {
      // The release is called to suppress the memory leak error messages raised by netty.
      if (byteBuf != null) {
        byteBuf.release();
        if (encodedByteBuf != null) {
          encodedByteBuf.release();
        }
      }
    }
  }"
"public static double estimateSelectivity(
      final String dimension,
      final BitmapIndexSelector indexSelector,
      final Predicate<String> predicate
  )
  {
    Preconditions.checkNotNull(dimension, ""dimension"");
    Preconditions.checkNotNull(indexSelector, ""selector"");
    Preconditions.checkNotNull(predicate, ""predicate"");

    // Missing dimension -> match all rows if the predicate matches null; match no rows otherwise
    try (final CloseableIndexed<String> dimValues = indexSelector.getDimensionValues(dimension)) {
      if (dimValues == null || dimValues.size() == 0) {
        return predicate.apply(null) ? 1. : 0.;
      }

      // Apply predicate to all dimension values and union the matching bitmaps
      final BitmapIndex bitmapIndex = indexSelector.getBitmapIndex(dimension);
      return estimateSelectivity(
          bitmapIndex,
          IntIteratorUtils.toIntList(
              makePredicateQualifyingIndexIterable(bitmapIndex, predicate, dimValues).iterator()
          ),
          indexSelector.getNumRows()
      );
    }
    catch (IOException e) {
      throw new UncheckedIOException(e);
    }
  }"
"@Override
    public void reset(boolean shuffle) {
        this.position.set(0);
        if (shuffle) {
            logger.debug(""Calling shuffle() on entries..."");
            // https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle#The_modern_algorithm
            for (int i = order.length - 1; i > 0; i--) {
                int j = rng.nextInt(i + 1);
                int temp = order[j];
                order[j] = order[i];
                order[i] = temp;
            }
        }
    }"
"private void emitRecordWithTimestampAndPeriodicWatermark(
			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {
		@SuppressWarnings(""unchecked"")
		final KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> withWatermarksState =
				(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>) partitionState;

		// extract timestamp - this accesses/modifies the per-partition state inside the
		// watermark generator instance, so we need to lock the access on the
		// partition state. concurrent access can happen from the periodic emitter
		final long timestamp;
		//noinspection SynchronizationOnLocalVariableOrMethodParameter
		synchronized (withWatermarksState) {
			timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp);
		}

		// emit the record with timestamp, using the usual checkpoint lock to guarantee
		// atomicity of record emission and offset state update
		synchronized (checkpointLock) {
			sourceContext.collectWithTimestamp(record, timestamp);
			partitionState.setOffset(offset);
		}
	}"
"@Override
    public String getString(Object value) {
        try {
            return DATE_TIME_FORMAT.format(value);
        } catch (IllegalArgumentException ignore) {
            // There's not much that can be done.
        }
        return StringValues.TO_STRING.getString(value);
    }"
"public static List<Object> extract(Iterable<?> collection, Editor<Object> editor) {
		return extract(collection, editor, false);
	}"
"public static void sleep(long durationMillis) {
		try {
			Thread.sleep(durationMillis);
		} catch (InterruptedException e) {
			Thread.currentThread().interrupt();
		}
	}"
"protected boolean isButtonEnabledForSelectedMessages(List<HttpMessage> httpMessages) {
        for (HttpMessage httpMessage : httpMessages) {
            if (httpMessage != null && !isButtonEnabledForSelectedHttpMessage(httpMessage)) {
                return false;
            }
        }
        return true;
    }"
"private void onProbationHit(Node node) {
    node.remove();
    node.queue = PROTECTED;
    node.appendToTail(headProtected);

    protectedSize++;
    demoteProtected();
  }"
"public static double[][] getTransformedEigenvectors(DataInfo dinfo, double[][] vEigenIn) {
        Frame tempFrame = new Frame(dinfo._adaptedFrame);
        Frame eigFrame = new water.util.ArrayUtils().frame(vEigenIn);
        tempFrame.add(eigFrame);

        LinearAlgebraUtils.SMulTask stsk = new LinearAlgebraUtils.SMulTask(dinfo, eigFrame.numCols(),
                dinfo._numOffsets[dinfo._numOffsets.length - 1]);   // will allocate new memory for _atq
        double[][] eigenVecs = stsk.doAll(tempFrame)._atq;

        if (eigFrame != null) { // delete frame to prevent leak keys.
            eigFrame.delete();
        }

        // need to normalize eigenvectors after multiplication by transpose(A) so that they have unit norm
        double[][] eigenVecsTranspose = transpose(eigenVecs);   // transpose will allocate memory
        double[] eigenNormsI = new double[eigenVecsTranspose.length];
        for (int vecIndex = 0; vecIndex < eigenVecsTranspose.length; vecIndex++) {
            eigenNormsI[vecIndex] = 1.0 / l2norm(eigenVecsTranspose[vecIndex]);
        }

        return transpose(mult(eigenVecsTranspose, eigenNormsI));
    }"
"public String toJson(Object src, Type typeOfSrc) {
    StringWriter writer = new StringWriter();
    toJson(src, typeOfSrc, writer);
    return writer.toString();
  }"
"public void setUseProxyChain(boolean useProxyChain) {
        if (useProxyChain && (getProxyChainName() == null || getProxyChainName().isEmpty())) {
            return;
        }

        this.useProxyChain = useProxyChain;
        getConfig().setProperty(USE_PROXY_CHAIN_KEY, this.useProxyChain);
    }"
"public ImageWritable asWritable(File f) throws IOException {
        try (BufferedInputStream bis = new BufferedInputStream(new FileInputStream(f))) {
            Mat mat = streamToMat(bis);
            Mat image = imdecode(mat, IMREAD_ANYDEPTH | IMREAD_ANYCOLOR);
            if (image == null || image.empty()) {
                PIX pix = pixReadMem(mat.data(), mat.cols());
                if (pix == null) {
                    throw new IOException(""Could not decode image from input stream"");
                }
                image = convert(pix);
                pixDestroy(pix);
            }

            ImageWritable writable = new ImageWritable(converter.convert(image));
            return writable;
        }
    }"
"public Collection<String> getLogicTableNames(final String actualTableName) {
        Collection<String> result = new LinkedList<>();
        for (TableRule each : tableRules) {
            if (each.isExisted(actualTableName)) {
                result.add(each.getLogicTable());
            }
        }
        return result;
    }"
"public void progress(long amount) {
        Entry e = flushedEntry;
        assert e != null;
        ChannelPromise p = e.promise;
        long progress = e.progress + amount;
        e.progress = progress;
        if (p instanceof ChannelProgressivePromise) {
            ((ChannelProgressivePromise) p).tryProgress(progress, e.total);
        }
    }"
"public static CircuitBreakerMetrics ofIterable(String prefix, Iterable<CircuitBreaker> circuitBreakers) {
        return new CircuitBreakerMetrics(circuitBreakers, prefix);
    }"
"public static Props loadPropsInDir(final File dir, final String... suffixes) {
    return loadPropsInDir(null, dir, suffixes);
  }"
"private static ValidationResponseType getValidationResponseType(final HttpServletRequest request,
                                                                    final WebApplicationService service) {
        val format = request.getParameter(CasProtocolConstants.PARAMETER_FORMAT);
        final Function<String, ValidationResponseType> func = FunctionUtils.doIf(StringUtils::isNotBlank,
            t -> ValidationResponseType.valueOf(t.toUpperCase()),
            f -> service != null ? service.getFormat() : ValidationResponseType.XML);
        return func.apply(format);
    }"
"protected Principal getPrincipal(final String name, final boolean isNtlm) {
        if (this.principalWithDomainName) {
            return this.principalFactory.createPrincipal(name);
        }
        if (isNtlm) {
            if (Pattern.matches(""\\S+\\\\\\S+"", name)) {
                val splitList = Splitter.on(Pattern.compile(""\\\\"")).splitToList(name);
                if (splitList.size() == 2) {
                    return this.principalFactory.createPrincipal(splitList.get(1));
                }
            }
            return this.principalFactory.createPrincipal(name);
        }
        val splitList = Splitter.on(""@"").splitToList(name);
        return this.principalFactory.createPrincipal(splitList.get(0));
    }"
"public Snapshot resolve() throws ResolvedFailedException {
        Jenkins h = Jenkins.getInstance();
        AbstractProject<?,?> job = h.getItemByFullName(jobName, AbstractProject.class);
        if(job==null) {
            if(h.getItemByFullName(jobName)==null) {
                AbstractProject nearest = AbstractProject.findNearest(jobName);
                throw new ResolvedFailedException(Messages.WorkspaceSnapshotSCM_NoSuchJob(jobName,nearest.getFullName()));
            } else
                throw new ResolvedFailedException(Messages.WorkspaceSnapshotSCM_IncorrectJobType(jobName));
        }

        PermalinkList permalinks = job.getPermalinks();
        Permalink p = permalinks.get(permalink);
        if(p==null)
            throw new ResolvedFailedException(Messages.WorkspaceSnapshotSCM_NoSuchPermalink(permalink,jobName));

        AbstractBuild<?,?> b = (AbstractBuild<?,?>)p.resolve(job);
        if(b==null)
            throw new ResolvedFailedException(Messages.WorkspaceSnapshotSCM_NoBuild(permalink,jobName));

        WorkspaceSnapshot snapshot = b.getAction(WorkspaceSnapshot.class);
        if(snapshot==null)
            throw new ResolvedFailedException(Messages.WorkspaceSnapshotSCM_NoWorkspace(jobName,permalink));

        return new Snapshot(snapshot,b);
    }"
"@Override
	public void start() throws Exception {
		synchronized (lock) {
			if (jobExecutorService == null) {
				// create the embedded runtime
				jobExecutorServiceConfiguration = createConfiguration();

				// start it up
				jobExecutorService = createJobExecutorService(jobExecutorServiceConfiguration);
			} else {
				throw new IllegalStateException(""The local executor was already started."");
			}
		}
	}"
"public static int rsHash(String str) {
		int b = 378551;
		int a = 63689;
		int hash = 0;

		for (int i = 0; i < str.length(); i++) {
			hash = hash * a + str.charAt(i);
			a = a * b;
		}

		return hash & 0x7FFFFFFF;
	}"
"@Override
  public void close()
  {
    if (closed.compareAndSet(false, true)) {
      decrement();
    } else {
      log.warn(new ISE(""Already closed""), ""Already closed"");
    }
  }"
"public static DataSourceConfiguration getDataSourceConfiguration(final DataSource dataSource) {
        DataSourceConfiguration result = new DataSourceConfiguration(dataSource.getClass().getName());
        result.getProperties().putAll(findAllGetterProperties(dataSource));
        return result;
    }"
"@Override
    public void destroy() {
        if (timerFilterThread != null) {
            timerFilterThread.setStopped();
            timerFilterThread = null;
        }

        Filter filter = null;
        for (int i=0; i<filterFactory.getAllFilter().size(); i++) {
            // ZAP: Removed unnecessary cast.
            filter = filterFactory.getAllFilter().get(i);
            try {
                filter.destroy();
            } catch (Exception e) {}
        }
        
        
    }"
"public StringBuffer markdown(SchemaMetadata meta, boolean include_input_fields, boolean include_output_fields) {
    MarkdownBuilder builder = new MarkdownBuilder();

    builder.comment(""Preview with http://jbt.github.io/markdown-editor"");
    builder.heading1(""schema "", this.getClass().getSimpleName());
    builder.hline();
    // builder.paragraph(metadata.summary);

    // TODO: refactor with Route.markdown():

    // fields
    boolean first; // don't print the table at all if there are no rows

    try {
      if (include_input_fields) {
        first = true;
        builder.heading2(""input fields"");

        for (SchemaMetadata.FieldMetadata field_meta : meta.fields) {
          if (field_meta.direction == API.Direction.INPUT || field_meta.direction == API.Direction.INOUT) {
            if (first) {
              builder.tableHeader(""name"", ""required?"", ""level"", ""type"", ""schema?"", ""schema"", ""default"", ""description"", ""values"", ""is member of frames"", ""is mutually exclusive with"");
              first = false;
            }
            builder.tableRow(
                field_meta.name,
                String.valueOf(field_meta.required),
                field_meta.level.name(),
                field_meta.type,
                String.valueOf(field_meta.is_schema),
                field_meta.is_schema ? field_meta.schema_name : """", (null == field_meta.value ? ""(null)"" : field_meta.value.toString()), // Something better for toString()?
                field_meta.help,
                (field_meta.values == null || field_meta.values.length == 0 ? """" : Arrays.toString(field_meta.values)),
                (field_meta.is_member_of_frames == null ? ""[]"" : Arrays.toString(field_meta.is_member_of_frames)),
                (field_meta.is_mutually_exclusive_with == null ? ""[]"" : Arrays.toString(field_meta.is_mutually_exclusive_with))
            );
          }
        }
        if (first)
          builder.paragraph(""(none)"");
      }

      if (include_output_fields) {
        first = true;
        builder.heading2(""output fields"");
        for (SchemaMetadata.FieldMetadata field_meta : meta.fields) {
          if (field_meta.direction == API.Direction.OUTPUT || field_meta.direction == API.Direction.INOUT) {
            if (first) {
              builder.tableHeader(""name"", ""type"", ""schema?"", ""schema"", ""default"", ""description"", ""values"", ""is member of frames"", ""is mutually exclusive with"");
              first = false;
            }
            builder.tableRow(
                field_meta.name,
                field_meta.type,
                String.valueOf(field_meta.is_schema),
                field_meta.is_schema ? field_meta.schema_name : """",
                (null == field_meta.value ? ""(null)"" : field_meta.value.toString()), // something better than toString()?
                field_meta.help,
                (field_meta.values == null || field_meta.values.length == 0 ? """" : Arrays.toString(field_meta.values)),
                (field_meta.is_member_of_frames == null ? ""[]"" : Arrays.toString(field_meta.is_member_of_frames)),
                (field_meta.is_mutually_exclusive_with == null ? ""[]"" : Arrays.toString(field_meta.is_mutually_exclusive_with)));
          }
        }
        if (first)
          builder.paragraph(""(none)"");
      }

      // TODO: render examples and other stuff, if it's passed in
    }
    catch (Exception e) {
      IcedHashMapGeneric.IcedHashMapStringObject values = new IcedHashMapGeneric.IcedHashMapStringObject();
      values.put(""schema"", this);
      // TODO: This isn't quite the right exception type:
      throw new H2OIllegalArgumentException(""Caught exception using reflection on schema: "" + this,
          ""Caught exception using reflection on schema: "" + this + "": "" + e,
          values);
    }
    return builder.stringBuffer();
  }"
"public double calculateScoreMultiDataSet(JavaRDD<MultiDataSet> data, boolean average, int minibatchSize) {
        JavaRDD<Tuple2<Integer, Double>> rdd = data.mapPartitions(new ScoreFlatMapFunctionCGMultiDataSet(conf.toJson(),
                        sc.broadcast(network.params(false)), minibatchSize));
        //Reduce to a single tuple, with example count + sum of scores
        Tuple2<Integer, Double> countAndSumScores = rdd.reduce(new IntDoubleReduceFunction());
        if (average) {
            return countAndSumScores._2() / countAndSumScores._1();
        } else {
            return countAndSumScores._2();
        }
    }"
"@Override
    public void rot(long N, INDArray X, INDArray Y, double c, double s) {


        if (X instanceof BaseSparseNDArray) {
            BaseSparseNDArray sparseX = (BaseSparseNDArray) X;

            switch (X.data().dataType()) {
                case DOUBLE:
                    droti(N, X, sparseX.getVectorCoordinates(), Y, c, s);
                    break;
                case FLOAT:
                    sroti(N, X, sparseX.getVectorCoordinates(), Y, c, s);
                    break;
                case HALF:
                    hroti(N, X, sparseX.getVectorCoordinates(), Y, c, s);
                    break;
                default:
                    throw new UnsupportedOperationException();
            }
        } else {
            throw new UnsupportedOperationException();
        }
    }"
"public static int checkBetween(int value, int min, int max) {
		if (value < min || value > max) {
			throw new IllegalArgumentException(StrUtil.format(""Length must be between {} and {}."", min, max));
		}
		return value;
	}"
"private static void computeTreeGraph(SharedTreeSubgraph sg, SharedTreeNode node, byte[] tree, ByteBufferWrapper ab, HashMap<Integer, AuxInfo> auxMap,
                                         String names[], String[][] domains) {
        int nodeType = ab.get1U();
        int colId = ab.get2();
        if (colId == 65535) {
            float leafValue = ab.get4f();
            node.setPredValue(leafValue);
            return;
        }
        String colName = names[colId];
        node.setCol(colId, colName);

        int naSplitDir = ab.get1U();
        boolean naVsRest = naSplitDir == NsdNaVsRest;
        boolean leftward = naSplitDir == NsdNaLeft || naSplitDir == NsdLeft;
        node.setLeftward(leftward);
        node.setNaVsRest(naVsRest);

        int lmask = (nodeType & 51);
        int equal = (nodeType & 12);  // Can be one of 0, 8, 12
        assert equal != 4;  // no longer supported

        if (!naVsRest) {
            // Extract value or group to split on
            if (equal == 0) {
                // Standard float-compare test (either < or ==)
                float splitVal = ab.get4f();  // Get the float to compare
                node.setSplitValue(splitVal);
            } else {
                // Bitset test
                GenmodelBitSet bs = new GenmodelBitSet(0);
                if (equal == 8)
                    bs.fill2(tree, ab);
                else
                    bs.fill3(tree, ab);
                node.setBitset(domains[colId], bs);
            }
        }

        AuxInfo auxInfo = auxMap.get(node.getNodeNumber());

        // go RIGHT
        {
            ByteBufferWrapper ab2 = new ByteBufferWrapper(tree);
            ab2.skip(ab.position());

            switch (lmask) {
                case 0:
                    ab2.skip(ab2.get1U());
                    break;
                case 1:
                    ab2.skip(ab2.get2());
                    break;
                case 2:
                    ab2.skip(ab2.get3());
                    break;
                case 3:
                    ab2.skip(ab2.get4());
                    break;
                case 48:
                    ab2.skip(4);
                    break;  // skip the prediction
                default:
                    assert false : ""illegal lmask value "" + lmask + "" in tree "" + Arrays.toString(tree);
            }
            int lmask2 = (nodeType & 0xC0) >> 2;  // Replace leftmask with the rightmask

            SharedTreeNode newNode = sg.makeRightChildNode(node);
            newNode.setWeight(auxInfo.weightR);
            newNode.setNodeNumber(auxInfo.nidR);
            newNode.setPredValue(auxInfo.predR);
            newNode.setSquaredError(auxInfo.sqErrR);
            if ((lmask2 & 16) != 0) {
                float leafValue = ab2.get4f();
                newNode.setPredValue(leafValue);
                auxInfo.predR = leafValue;
            }
            else {
                computeTreeGraph(sg, newNode, tree, ab2, auxMap, names, domains);
            }
        }

        // go LEFT
        {
            ByteBufferWrapper ab2 = new ByteBufferWrapper(tree);
            ab2.skip(ab.position());

            if (lmask <= 3)
                ab2.skip(lmask + 1);

            SharedTreeNode newNode = sg.makeLeftChildNode(node);
            newNode.setWeight(auxInfo.weightL);
            newNode.setNodeNumber(auxInfo.nidL);
            newNode.setPredValue(auxInfo.predL);
            newNode.setSquaredError(auxInfo.sqErrL);
            if ((lmask & 16) != 0) {
                float leafValue = ab2.get4f();
                newNode.setPredValue(leafValue);
                auxInfo.predL = leafValue;
            }
            else {
                computeTreeGraph(sg, newNode, tree, ab2, auxMap, names, domains);
            }
        }
        if (node.getNodeNumber() == 0) {
          float p = (float)(((double)auxInfo.predL*(double)auxInfo.weightL + (double)auxInfo.predR*(double)auxInfo.weightR)/((double)auxInfo.weightL + (double)auxInfo.weightR));
          if (Math.abs(p) < 1e-7) p = 0;
          node.setPredValue(p);
          node.setSquaredError(auxInfo.sqErrR + auxInfo.sqErrL);
          node.setWeight(auxInfo.weightL + auxInfo.weightR);
        }
        checkConsistency(auxInfo, node);
    }"
"public ArgumentListBuilder toWindowsCommand(boolean escapeVars) {
    	ArgumentListBuilder windowsCommand = new ArgumentListBuilder().add(""cmd.exe"", ""/C"");
        boolean quoted, percent;
        for (int i = 0; i < args.size(); i++) {
            StringBuilder quotedArgs = new StringBuilder();
            String arg = args.get(i);
            quoted = percent = false;
            for (int j = 0; j < arg.length(); j++) {
                char c = arg.charAt(j);
                if (!quoted && (c == ' ' || c == '*' || c == '?' || c == ',' || c == ';')) {
                    quoted = startQuoting(quotedArgs, arg, j);
                }
                else if (c == '^' || c == '&' || c == '<' || c == '>' || c == '|') {
                    if (!quoted) quoted = startQuoting(quotedArgs, arg, j);
                    // quotedArgs.append('^'); See note in javadoc above
                }
                else if (c == '""') {
                    if (!quoted) quoted = startQuoting(quotedArgs, arg, j);
                    quotedArgs.append('""');
                }
                else if (percent && escapeVars
                         && ((c >= 'A' && c <= 'Z') || (c >= 'a' && c <= 'z'))) {
                    if (!quoted) quoted = startQuoting(quotedArgs, arg, j);
                    quotedArgs.append('""').append(c);
                    c = '""';
                }
                percent = (c == '%');
                if (quoted) quotedArgs.append(c);
            }
            if(i == 0 && quoted) quotedArgs.insert(0, '""'); else if (i == 0 && !quoted) quotedArgs.append('""');
            if (quoted) quotedArgs.append('""'); else quotedArgs.append(arg);
            
            windowsCommand.add(quotedArgs, mask.get(i));
        }
        // (comment copied from old code in hudson.tasks.Ant)
        // on Windows, executing batch file can't return the correct error code,
        // so we need to wrap it into cmd.exe.
        // double %% is needed because we want ERRORLEVEL to be expanded after
        // batch file executed, not before. This alone shows how broken Windows is...
        windowsCommand.add(""&&"").add(""exit"").add(""%%ERRORLEVEL%%\"""");
        return windowsCommand;
    }"
"private int distributeToChildren(int maxBytes, Writer writer, State state) throws Http2Exception {
        long oldTotalQueuedWeights = state.totalQueuedWeights;
        State childState = state.pollPseudoTimeQueue();
        State nextChildState = state.peekPseudoTimeQueue();
        childState.setDistributing();
        try {
            assert nextChildState == null || nextChildState.pseudoTimeToWrite >= childState.pseudoTimeToWrite :
                ""nextChildState["" + nextChildState.streamId + ""].pseudoTime("" + nextChildState.pseudoTimeToWrite +
                "") < "" + "" childState["" + childState.streamId + ""].pseudoTime("" + childState.pseudoTimeToWrite + "")"";
            int nsent = distribute(nextChildState == null ? maxBytes :
                            min(maxBytes, (int) min((nextChildState.pseudoTimeToWrite - childState.pseudoTimeToWrite) *
                                               childState.weight / oldTotalQueuedWeights + allocationQuantum, MAX_VALUE)
                               ),
                               writer,
                               childState);
            state.pseudoTime += nsent;
            childState.updatePseudoTime(state, nsent, oldTotalQueuedWeights);
            return nsent;
        } finally {
            childState.unsetDistributing();
            // Do in finally to ensure the internal flags is not corrupted if an exception is thrown.
            // The offer operation is delayed until we unroll up the recursive stack, so we don't have to remove from
            // the priority pseudoTimeQueue due to a write operation.
            if (childState.activeCountForTree != 0) {
                state.offerPseudoTimeQueue(childState);
            }
        }
    }"
"public static <K, VV, EV> Graph<K, VV, EV> fromTupleDataSet(DataSet<Tuple2<K, VV>> vertices,
			DataSet<Tuple3<K, K, EV>> edges, ExecutionEnvironment context) {

		DataSet<Vertex<K, VV>> vertexDataSet = vertices
			.map(new Tuple2ToVertexMap<>())
				.name(""Type conversion"");

		DataSet<Edge<K, EV>> edgeDataSet = edges
			.map(new Tuple3ToEdgeMap<>())
				.name(""Type conversion"");

		return fromDataSet(vertexDataSet, edgeDataSet, context);
	}"
"public static boolean checkpointsMatch(
		Collection<CompletedCheckpoint> first,
		Collection<CompletedCheckpoint> second) {
		if (first.size() != second.size()) {
			return false;
		}

		List<Tuple2<Long, JobID>> firstInterestingFields = new ArrayList<>(first.size());

		for (CompletedCheckpoint checkpoint : first) {
			firstInterestingFields.add(
				new Tuple2<>(checkpoint.getCheckpointID(), checkpoint.getJobId()));
		}

		List<Tuple2<Long, JobID>> secondInterestingFields = new ArrayList<>(second.size());

		for (CompletedCheckpoint checkpoint : second) {
			secondInterestingFields.add(
				new Tuple2<>(checkpoint.getCheckpointID(), checkpoint.getJobId()));
		}

		return firstInterestingFields.equals(secondInterestingFields);
	}"
"private static String getClassNameForLowerCaseHyphenSeparatedName(String name) {
        // Handle null and empty strings.
        if (isBlank(name)) {
            return name;
        }

        if (name.indexOf('-') == -1) {
            return name.substring(0, 1).toUpperCase() + name.substring(1);
        }

        StringBuilder buf = new StringBuilder();
        String[] tokens = name.split(""-"");
        for (String token : tokens) {
            if (token == null || token.length() == 0) {
                continue;
            }
            buf.append(token.substring(0, 1).toUpperCase())
                .append(token.substring(1));
        }
        return buf.toString();
    }"
"public static DataSource createDataSource(final Map<String, DataSource> dataSourceMap, final MasterSlaveRuleConfiguration masterSlaveRuleConfig, final Properties props) throws SQLException {
        return new MasterSlaveDataSource(dataSourceMap, masterSlaveRuleConfig, props);
    }"
"public void fit(INDArray[] inputs, INDArray[] labels, INDArray[] featureMaskArrays, INDArray[] labelMaskArrays) {
        try{
            fitHelper(inputs, labels, featureMaskArrays, labelMaskArrays);
        } catch (OutOfMemoryError e){
            CrashReportingUtil.writeMemoryCrashDump(this, e);
            throw e;
        }
    }"
"public static PrincipalNameTransformer newPrincipalNameTransformer(final PrincipalTransformationProperties p) {
        val chain = new ChainingPrincipalNameTransformer();

        if (p.getGroovy().getLocation() != null) {
            val t = new GroovyPrincipalNameTransformer(p.getGroovy().getLocation());
            chain.addTransformer(t);
        }

        if (StringUtils.isNotBlank(p.getPattern())) {
            val t = new RegexPrincipalNameTransformer(p.getPattern());
            chain.addTransformer(t);
        }

        if (StringUtils.isNotBlank(p.getPrefix()) || StringUtils.isNotBlank(p.getSuffix())) {
            val t = new PrefixSuffixPrincipalNameTransformer();
            t.setPrefix(p.getPrefix());
            t.setSuffix(p.getSuffix());
            chain.addTransformer(t);
        } else {
            chain.addTransformer(new NoOpPrincipalNameTransformer());
        }

        if (p.getCaseConversion() == PrincipalTransformationProperties.CaseConversion.UPPERCASE) {
            val t = new ConvertCasePrincipalNameTransformer();
            t.setToUpperCase(true);
            chain.addTransformer(t);
        }

        if (p.getCaseConversion() == PrincipalTransformationProperties.CaseConversion.LOWERCASE) {
            val t = new ConvertCasePrincipalNameTransformer();
            t.setToUpperCase(false);
            chain.addTransformer(t);
        }

        return chain;
    }"
"@Override
   public void setLogWriter(PrintWriter out) throws SQLException
   {
      HikariPool p = pool;
      if (p != null) {
         p.getUnwrappedDataSource().setLogWriter(out);
      }
   }"
"private int getPriority(final ExecutableFlow exflow) {
    final ExecutionOptions options = exflow.getExecutionOptions();
    int priority = ExecutionOptions.DEFAULT_FLOW_PRIORITY;
    if (options != null
        && options.getFlowParameters() != null
        && options.getFlowParameters()
        .containsKey(ExecutionOptions.FLOW_PRIORITY)) {
      try {
        priority =
            Integer.valueOf(options.getFlowParameters().get(
                ExecutionOptions.FLOW_PRIORITY));
      } catch (final NumberFormatException ex) {
        priority = ExecutionOptions.DEFAULT_FLOW_PRIORITY;
        logger.error(
            ""Failed to parse flow priority for exec_id = ""
                + exflow.getExecutionId(), ex);
      }
    }
    return priority;
  }"
"@VisibleForTesting
  ClientCallTracer newClientCallTracer(
      TagContext parentCtx, String fullMethodName) {
    return new ClientCallTracer(this, parentCtx, fullMethodName);
  }"
"@Override
	public TypeSerializerSchemaCompatibility<ArrayList<T>> resolveSchemaCompatibilityViaRedirectingToNewSnapshotClass(
			TypeSerializerConfigSnapshot<ArrayList<T>> deprecatedConfigSnapshot) {

		if (deprecatedConfigSnapshot instanceof CollectionSerializerConfigSnapshot) {
			CollectionSerializerConfigSnapshot<ArrayList<T>, T> castedLegacySnapshot =
				(CollectionSerializerConfigSnapshot<ArrayList<T>, T>) deprecatedConfigSnapshot;

			ArrayListSerializerSnapshot<T> newSnapshot = new ArrayListSerializerSnapshot<>();
			return CompositeTypeSerializerUtil.delegateCompatibilityCheckToNewSnapshot(
				this,
				newSnapshot,
				castedLegacySnapshot.getNestedSerializerSnapshots());
		}

		return TypeSerializerSchemaCompatibility.incompatible();
	}"
"public static Long toTimestamp(String dateStr, String format, TimeZone tz) {
		SimpleDateFormat formatter = FORMATTER_CACHE.get(format);
		formatter.setTimeZone(tz);
		try {
			return formatter.parse(dateStr).getTime();
		} catch (ParseException e) {
			return null;
		}
	}"
"private static void reflectionAppend(
        final Object lhs,
        final Object rhs,
        final Class<?> clazz,
        final EqualsBuilder builder,
        final boolean useTransients,
        final String[] excludeFields) {

        if (isRegistered(lhs, rhs)) {
            return;
        }

        try {
            register(lhs, rhs);
            final Field[] fields = clazz.getDeclaredFields();
            AccessibleObject.setAccessible(fields, true);
            for (int i = 0; i < fields.length && builder.isEquals; i++) {
                final Field f = fields[i];
                if (false == ArrayUtil.contains(excludeFields, f.getName())
                    && (f.getName().indexOf('$') == -1)
                    && (useTransients || !Modifier.isTransient(f.getModifiers()))
                    && (!Modifier.isStatic(f.getModifiers()))) {
                    try {
                        builder.append(f.get(lhs), f.get(rhs));
                    } catch (final IllegalAccessException e) {
                        //this can't happen. Would get a Security exception instead
                        //throw a runtime exception in case the impossible happens.
                        throw new InternalError(""Unexpected IllegalAccessException"");
                    }
                }
            }
        } finally {
            unregister(lhs, rhs);
        }
    }"
"@Override
    public boolean hasSimilarMethod(Invocation candidate) {
        String wantedMethodName = getMethod().getName();
        String candidateMethodName = candidate.getMethod().getName();

        if (!wantedMethodName.equals(candidateMethodName)) {
            return false;
        }
        if (candidate.isVerified()) {
            return false;
        }
        if (getInvocation().getMock() != candidate.getMock()) {
            return false;
        }
        if (hasSameMethod(candidate)) {
            return true;
        }

        return !argumentsMatch(candidate);
    }"
"public void addFlush() {
        // There is no need to process all entries if there was already a flush before and no new messages
        // where added in the meantime.
        //
        // See https://github.com/netty/netty/issues/2577
        Entry entry = unflushedEntry;
        if (entry != null) {
            if (flushedEntry == null) {
                // there is no flushedEntry yet, so start with the entry
                flushedEntry = entry;
            }
            do {
                flushed ++;
                if (!entry.promise.setUncancellable()) {
                    // Was cancelled so make sure we free up memory and notify about the freed bytes
                    int pending = entry.cancel();
                    decrementPendingOutboundBytes(pending, false, true);
                }
                entry = entry.next;
            } while (entry != null);

            // All flushed so reset unflushedEntry
            unflushedEntry = null;
        }
    }"
"public HttpRequest form(String name, File file) {
		return form(name, file, file.getName());
	}"
"public static Frame transpose(Frame src){
    if(src.numRows() != (int)src.numRows())
      throw H2O.unimpl();
    int nchunks = Math.max(1,src.numCols()/10000);
    long [] espc = new long[nchunks+1];
    int rpc = (src.numCols() / nchunks);
    int rem = (src.numCols() % nchunks);
    Arrays.fill(espc, rpc);
    for (int i = 0; i < rem; ++i) ++espc[i];
    long sum = 0;
    for (int i = 0; i < espc.length; ++i) {
      long s = espc[i];
      espc[i] = sum;
      sum += s;
    }
    Key key = Vec.newKey();
    int rowLayout = Vec.ESPC.rowLayout(key,espc);
    return transpose(src, new Frame(new Vec(key,rowLayout).makeZeros((int)src.numRows())));
  }"
"public void setDefaultTokens(final List<HttpSessionToken> tokens) {
		this.defaultTokens = tokens;
		
		saveDefaultTokens();
		this.defaultTokensEnabled = defaultTokens.stream()
				.filter(HttpSessionToken::isEnabled)
				.map(HttpSessionToken::getName)
				.collect(Collectors.toList());
	}"
"static public Value put( Key key, Value val, Futures fs, boolean dontCache ) {
    assert key != null;
    assert val==null || val._key == key:""non-matching keys "" + key + "" != "" + val._key;
    while( true ) {
      Value old = Value.STORE_get(key); // Raw-get: do not lazy-manifest if overwriting
      Value res = DputIfMatch(key,val,old,fs,dontCache);
      if( res == old ) return old; // PUT is globally visible now?
      if( val != null && val._key != key ) key = val._key;
    }
  }"
"public QueryPlus<T> withQueryMetrics(QueryToolChest<T, ? extends Query<T>> queryToolChest)
  {
    if (queryMetrics != null) {
      return this;
    } else {
      final QueryMetrics metrics = ((QueryToolChest) queryToolChest).makeMetrics(query);

      if (identity != null) {
        metrics.identity(identity);
      }

      return new QueryPlus<>(query, metrics, identity);
    }
  }"
"@PublicEvolving
	public DataStreamSink<T> writeAsText(String path, WriteMode writeMode) {
		TextOutputFormat<T> tof = new TextOutputFormat<>(new Path(path));
		tof.setWriteMode(writeMode);
		return writeUsingOutputFormat(tof);
	}"
"public static URLClassLoader getClassLoaderForExtension(File extension, boolean useExtensionClassloaderFirst)
  {
    return loadersMap.computeIfAbsent(
        extension,
        theExtension -> makeClassLoaderForExtension(theExtension, useExtensionClassloaderFirst)
    );
  }"
"public synchronized <T> T output(@NonNull INDArray inputs, INDArray inputMasks, INDArray labelMasks, @NonNull OutputAdapter<T> outputAdapter) {
        try (val ws = Nd4j.getWorkspaceManager().getAndActivateWorkspace(WS_ALL_LAYERS_ACT_CONFIG, WS_OUTPUT_MEM)) {
            if (outputAdapter instanceof ModelAdapter)
                return ((ModelAdapter<T>) outputAdapter).apply(this, new INDArray[]{inputs}, new INDArray[]{ inputMasks}, new INDArray[]{labelMasks});
            else
                return outputAdapter.apply(output(inputs, false, inputMasks, labelMasks, ws));
        }
    }"
"public static <K, V> Bindable<Map<K, V>> mapOf(Class<K> keyType, Class<V> valueType) {
		return of(ResolvableType.forClassWithGenerics(Map.class, keyType, valueType));
	}"
"private void push(JSONObject jo) throws JSONException {
    if (this.top >= maxdepth) {
      throw new JSONException(""Nesting too deep."");
    }
    this.stack[this.top] = jo;
    this.mode = jo == null ? 'a' : 'k';
    this.top += 1;
  }"
"private static ApiResponseSet<String> buildParamMap(String paramName, boolean mandatory) {
		Map<String, String> m = new HashMap<>();
		m.put(""name"", paramName);
		m.put(""mandatory"", mandatory ? ""true"" : ""false"");
		return new ApiResponseSet<String>(""param"", m);
	}"
"public static INDArrayIndex[] rangeOfLength(INDArrayIndex[] indexes) {
        INDArrayIndex[] indexesRet = new INDArrayIndex[indexes.length];
        for (int i = 0; i < indexes.length; i++)
            indexesRet[i] = NDArrayIndex.interval(0, indexes[i].length());
        return indexesRet;
    }"
"public static String encodeQuery(String url, Charset charset) {
		if (StrUtil.isEmpty(url)) {
			return url;
		}
		if (null == charset) {
			charset = CharsetUtil.defaultCharset();
		}
		return URLEncoder.QUERY.encode(url, charset);
	}"
"protected boolean prevalidate(String component, BitSet disallowed) {
        // prevalidate the given component by disallowed characters
        if (component == null) {
            return false; // undefined
        }
        char[] target = component.toCharArray();
        for (int i = 0; i < target.length; i++) {
            if (disallowed.get(target[i])) {
                return false;
            }
        }
        return true;
    }"
"@Override
    public Pointer allocate(long bytes, MemoryKind kind, boolean initialize) {
        Pointer ptr = NativeOpsHolder.getInstance().getDeviceNativeOps().mallocHost(bytes, 0);

        if (ptr == null || ptr.address() == 0L)
            throw new OutOfMemoryError(""Failed to allocate ["" + bytes + ""] bytes"");

        //log.info(""Allocating {} bytes at MemoryManager"", bytes);

        if (initialize)
            Pointer.memset(ptr, 0, bytes);

        return ptr;
    }"
"private INDArray readDataSet(Group fileGroup, String datasetName)
            throws UnsupportedKerasConfigurationException {
        synchronized (Hdf5Archive.LOCK_OBJECT) {
            DataSet dataset = fileGroup.openDataSet(datasetName);
            DataSpace space = dataset.getSpace();
            int nbDims = space.getSimpleExtentNdims();
            long[] dims = new long[nbDims];
            space.getSimpleExtentDims(dims);
            float[] dataBuffer;
            FloatPointer fp;
            int j;
            INDArray data;
            switch (nbDims) {
                case 5: /* 3D Convolution weights */
                    dataBuffer = new float[(int) (dims[0] * dims[1] * dims[2] * dims[3] * dims[4])];
                    fp = new FloatPointer(dataBuffer);
                    dataset.read(fp, dataType);
                    fp.get(dataBuffer);
                    data = Nd4j.create((int) dims[0], (int) dims[1], (int) dims[2], (int) dims[3], (int) dims[4]);
                    j = 0;
                    for (int i1 = 0; i1 < dims[0]; i1++)
                        for (int i2 = 0; i2 < dims[1]; i2++)
                            for (int i3 = 0; i3 < dims[2]; i3++)
                                for (int i4 = 0; i4 < dims[3]; i4++)
                                    for (int i5 = 0; i5 < dims[4]; i5++)
                                        data.putScalar(new int[] { i1, i2, i3, i4, i5 }, dataBuffer[j++]);
                    break;
                case 4: /* 2D Convolution weights */
                    dataBuffer = new float[(int) (dims[0] * dims[1] * dims[2] * dims[3])];
                    fp = new FloatPointer(dataBuffer);
                    dataset.read(fp, dataType);
                    fp.get(dataBuffer);
                    data = Nd4j.create((int) dims[0], (int) dims[1], (int) dims[2], (int) dims[3]);
                    j = 0;
                    for (int i1 = 0; i1 < dims[0]; i1++)
                        for (int i2 = 0; i2 < dims[1]; i2++)
                            for (int i3 = 0; i3 < dims[2]; i3++)
                                for (int i4 = 0; i4 < dims[3]; i4++)
                                    data.putScalar(i1, i2, i3, i4, dataBuffer[j++]);
                    break;
                case 3:
                    dataBuffer = new float[(int) (dims[0] * dims[1] * dims[2])];
                    fp = new FloatPointer(dataBuffer);
                    dataset.read(fp, dataType);
                    fp.get(dataBuffer);
                    data = Nd4j.create((int) dims[0], (int) dims[1], (int) dims[2]);
                    j = 0;
                    for (int i1 = 0; i1 < dims[0]; i1++)
                        for (int i2 = 0; i2 < dims[1]; i2++)
                            for (int i3 = 0; i3 < dims[2]; i3++)
                                data.putScalar(i1, i2, i3, dataBuffer[j++]);
                    break;
                case 2: /* Dense and Recurrent weights */
                    dataBuffer = new float[(int) (dims[0] * dims[1])];
                    fp = new FloatPointer(dataBuffer);
                    dataset.read(fp, dataType);
                    fp.get(dataBuffer);
                    data = Nd4j.create((int) dims[0], (int) dims[1]);
                    j = 0;
                    for (int i1 = 0; i1 < dims[0]; i1++)
                        for (int i2 = 0; i2 < dims[1]; i2++)
                            data.putScalar(i1, i2, dataBuffer[j++]);
                    break;
                case 1: /* Bias */
                    dataBuffer = new float[(int) dims[0]];
                    fp = new FloatPointer(dataBuffer);
                    dataset.read(fp, dataType);
                    fp.get(dataBuffer);
                    data = Nd4j.create((int) dims[0]);
                    j = 0;
                    for (int i1 = 0; i1 < dims[0]; i1++)
                        data.putScalar(i1, dataBuffer[j++]);
                    break;
                default:
                    throw new UnsupportedKerasConfigurationException(""Cannot import weights with rank "" + nbDims);
            }
            space.deallocate();
            dataset.deallocate();
            return data;
        }
    }"
"public static boolean checkPosition(Event event, LogPosition logPosition) {
        EntryPosition position = logPosition.getPostion();
        boolean result = position.getTimestamp().equals(event.getExecuteTime());

        boolean exactely = (StringUtils.isBlank(position.getJournalName()) && position.getPosition() == null);
        if (!exactely) {// 精确匹配
            result &= position.getPosition().equals(event.getPosition());
            if (result) {// short path
                result &= StringUtils.equals(event.getJournalName(), position.getJournalName());
            }
        }

        return result;
    }"
"@Override
    public boolean hasConcurrents() {
        if (concurrents > 0) {
            return true;
        }
        if (CommonUtils.isNotEmpty(methods)) {
            for (MethodConfig methodConfig : methods.values()) {
                if (methodConfig.getConcurrents() != null
                    && methodConfig.getConcurrents() > 0) {
                    return true;
                }
            }
        }
        return false;
    }"
"@SuppressWarnings(""unchecked"")
        public static <T> T decode(String base64) {
                //BASE64Decoder decoder = new BASE64Decoder();
                try {
                        //byte[]               b    = decoder.decodeBuffer(base64);
                		byte[]               b    = Base64.decode(base64);
                        ByteArrayInputStream bais = new ByteArrayInputStream(b);
                        ObjectInputStream    ois  = new ObjectInputStream(bais);
                        return (T)ois.readObject();
                } catch (IOException | ClassNotFoundException e) {
                        throw new RuntimeException(e);
                }
        }"
"public static @CheckForNull FilePathFilter current() {
        Channel ch = Channel.current();
        if (ch==null)   return null;

        return ch.getProperty(FilePathFilterAggregator.KEY);
    }"
"public static <K, V> Map<K, V> emptyMapIfNull(final Map<K, V> map) {
		return map == null ? (Map<K, V>) Collections.EMPTY_MAP : map;
	}"
"@Override
  public boolean isFlowRunning(final int projectId, final String flowId) {
    boolean isRunning = false;
    try {
      isRunning = isFlowRunningHelper(projectId, flowId,
          this.executorLoader.fetchUnfinishedFlows().values());

    } catch (final ExecutorManagerException e) {
      logger.error(
          ""Failed to check if the flow is running for project "" + projectId + "", flow "" + flowId,
          e);
    }
    return isRunning;
  }"
"@Override public TopLevelItem getItem(String name) throws AccessDeniedException {
        if (name==null)    return null;
        TopLevelItem item = items.get(name);
        if (item==null)
            return null;
        if (!item.hasPermission(Item.READ)) {
            if (item.hasPermission(Item.DISCOVER)) {
                throw new AccessDeniedException(""Please login to access job "" + name);
            }
            return null;
        }
        return item;
    }"
"private int readCorner2(int numRows, int numColumns) {
    int currentByte = 0;
    if (readModule(numRows - 3, 0, numRows, numColumns)) {
      currentByte |= 1;
    }
    currentByte <<= 1;
    if (readModule(numRows - 2, 0, numRows, numColumns)) {
      currentByte |= 1;
    }
    currentByte <<= 1;
    if (readModule(numRows - 1, 0, numRows, numColumns)) {
      currentByte |= 1;
    }
    currentByte <<= 1;
    if (readModule(0, numColumns - 4, numRows, numColumns)) {
      currentByte |= 1;
    }
    currentByte <<= 1;
    if (readModule(0, numColumns - 3, numRows, numColumns)) {
      currentByte |= 1;
    }
    currentByte <<= 1;
    if (readModule(0, numColumns - 2, numRows, numColumns)) {
      currentByte |= 1;
    }
    currentByte <<= 1;
    if (readModule(0, numColumns - 1, numRows, numColumns)) {
      currentByte |= 1;
    }
    currentByte <<= 1;
    if (readModule(1, numColumns - 1, numRows, numColumns)) {
      currentByte |= 1;
    }
    return currentByte;
  }"
"ClientStats generateLoadReport() {
    ClientStats.Builder statsBuilder =
        ClientStats.newBuilder()
        .setTimestamp(Timestamps.fromNanos(time.currentTimeNanos()))
        .setNumCallsStarted(callsStartedUpdater.getAndSet(this, 0))
        .setNumCallsFinished(callsFinishedUpdater.getAndSet(this, 0))
        .setNumCallsFinishedWithClientFailedToSend(callsFailedToSendUpdater.getAndSet(this, 0))
        .setNumCallsFinishedKnownReceived(callsFinishedKnownReceivedUpdater.getAndSet(this, 0));

    Map<String, LongHolder> localCallsDroppedPerToken = Collections.emptyMap();
    synchronized (this) {
      if (!callsDroppedPerToken.isEmpty()) {
        localCallsDroppedPerToken = callsDroppedPerToken;
        callsDroppedPerToken = new HashMap<>(localCallsDroppedPerToken.size());
      }
    }
    for (Entry<String, LongHolder> entry : localCallsDroppedPerToken.entrySet()) {
      statsBuilder.addCallsFinishedWithDrop(
          ClientStatsPerToken.newBuilder()
              .setLoadBalanceToken(entry.getKey())
              .setNumCalls(entry.getValue().num)
              .build());
    }
    return statsBuilder.build();
  }"
"public static void cancelChainedTasks(List<ChainedDriver<?, ?>> tasks) {
		for (int i = 0; i < tasks.size(); i++) {
			try {
				tasks.get(i).cancelTask();
			} catch (Throwable t) {
				// do nothing
			}
		}
	}"
"public byte[] decryptFromBcd(String data, KeyType keyType, Charset charset) {
		final byte[] dataBytes = BCD.ascToBcd(StrUtil.bytes(data, charset));
		return decrypt(dataBytes, keyType);
	}"
"@Override public String getName() {
		final char[] n;
		if (node instanceof TypeDeclaration) n = ((TypeDeclaration)node).name;
		else if (node instanceof FieldDeclaration) n = ((FieldDeclaration)node).name;
		else if (node instanceof AbstractMethodDeclaration) n = ((AbstractMethodDeclaration)node).selector;
		else if (node instanceof LocalDeclaration) n = ((LocalDeclaration)node).name;
		else n = null;
		
		return n == null ? null : new String(n);
	}"
"public static Protos.Resource ports(Protos.Value.Range... ranges) {
		return ports(UNRESERVED_ROLE, ranges);
	}"
"protected void createRealSubmitAction(final Flow flow) {
        val state = createActionState(flow, CasWebflowConstants.STATE_ID_REAL_SUBMIT, ""authenticationViaFormAction"");
        createTransitionForState(state, CasWebflowConstants.TRANSITION_ID_WARN, CasWebflowConstants.STATE_ID_WARN);
        createTransitionForState(state, CasWebflowConstants.TRANSITION_ID_SUCCESS, CasWebflowConstants.STATE_ID_CREATE_TICKET_GRANTING_TICKET);
        createTransitionForState(state, CasWebflowConstants.TRANSITION_ID_SUCCESS_WITH_WARNINGS, CasWebflowConstants.STATE_ID_SHOW_AUTHN_WARNING_MSGS);
        createTransitionForState(state, CasWebflowConstants.TRANSITION_ID_AUTHENTICATION_FAILURE, CasWebflowConstants.STATE_ID_HANDLE_AUTHN_FAILURE);
        createTransitionForState(state, CasWebflowConstants.TRANSITION_ID_ERROR, CasWebflowConstants.STATE_ID_INIT_LOGIN_FORM);
    }"
"public static Map<String, Integer> getKeywordCounts(String[] keywordArray)
    {
        Map<String, Integer> counts = new HashMap<String, Integer>();

        Integer counter;
        for (int i = 0; i < keywordArray.length; ++i)
        {
            counter = counts.get(keywordArray[i]);
            if (counter == null)
            {
                counter = 0;
            }
            counts.put(keywordArray[i], ++counter); //增加词频
        }

        return counts;
    }"
"protected InputStream readFiles() throws IOException {
    BufferedInputStream input = new BufferedInputStream(openFile(), BUFFER_SIZE);
    input.mark(100);
    try {
      return new XZInputStream(input);
    } catch (IOException e) {
      input.reset();
    }
    try {
      return new CompressorStreamFactory().createCompressorInputStream(input);
    } catch (CompressorException e) {
      input.reset();
    }
    try {
      return new ArchiveStreamFactory().createArchiveInputStream(input);
    } catch (ArchiveException e) {
      input.reset();
    }
    return input;
  }"
"protected void fail(HttpServletRequest request, HttpServletResponse response, OAuthRequestFailedException failure) throws IOException, ServletException {
		try {
			//attempt to set the last exception.
			request.getSession().setAttribute(OAUTH_FAILURE_KEY, failure);
		}
		catch (Exception e) {
			//fall through....
		}

		if (LOG.isDebugEnabled()) {
			LOG.debug(failure);
		}

		if (getOAuthFailureHandler() != null) {
			getOAuthFailureHandler().handle(request, response, failure);
		}
		else {
			throw failure;
		}
	}"
"private int getHashPositionOfElement(Block block, int position)
    {
        int hashPosition = getMaskedHash(hashPosition(elementType, block, position));
        while (true) {
            int blockPosition = blockPositionByHash.get(hashPosition);
            // Doesn't have this element
            if (blockPosition == EMPTY_SLOT) {
                return hashPosition;
            }
            // Already has this element
            else if (positionEqualsPosition(elementType, elementBlock, blockPosition, block, position)) {
                return hashPosition;
            }

            hashPosition = getMaskedHash(hashPosition + 1);
        }
    }"
"public static ApproximateHistogram fromBytesCompact(ByteBuffer buf)
  {
    short size = (short) (-1 * buf.getShort());
    byte count = buf.get();

    if (count >= 0) {
      // only exact bins
      ApproximateHistogram histogram = new ApproximateHistogram(size);
      for (int i = 0; i < count; ++i) {
        histogram.offer(buf.getFloat());
      }
      return histogram;
    } else {
      byte approxCount = (byte) (-1 * count);

      Map<Float, Long> approx = new HashMap<>();

      for (int i = 0; i < approxCount; ++i) {
        final float value = buf.getFloat();
        if (approx.containsKey(value)) {
          approx.put(value, approx.get(value) + 1);
        } else {
          approx.put(value, 1L);
        }
      }

      float min = buf.getFloat();
      float max = buf.getFloat();

      byte exactCount = buf.get();

      Map<Float, Long> exact = new HashMap<>();

      for (int i = 0; i < exactCount; ++i) {
        final float value = buf.getFloat();
        if (exact.containsKey(value)) {
          exact.put(value, exact.get(value) + 1);
        } else {
          exact.put(value, 1L);
        }
      }

      int binCount = exact.size() + approx.size();

      List<Float> pos = new ArrayList<>();
      pos.addAll(exact.keySet());
      pos.addAll(approx.keySet());
      Collections.sort(pos);

      float[] positions = new float[size];
      long[] bins = new long[size];

      for (int i = 0; i < pos.size(); ++i) {
        positions[i] = pos.get(i);
      }

      for (int i = 0; i < pos.size(); ++i) {
        final float value = pos.get(i);
        if (exact.containsKey(value)) {
          bins[i] = exact.get(value);
        } else {
          bins[i] = approx.get(value) | APPROX_FLAG_BIT;
        }
      }

      return new ApproximateHistogram(binCount, positions, bins, min, max);
    }
  }"
"public static String inflate(final byte[] bytes) {
        val inflater = new Inflater(true);
        val xmlMessageBytes = new byte[INFLATED_ARRAY_LENGTH];

        val extendedBytes = new byte[bytes.length + 1];
        System.arraycopy(bytes, 0, extendedBytes, 0, bytes.length);
        extendedBytes[bytes.length] = 0;
        inflater.setInput(extendedBytes);

        try {
            val resultLength = inflater.inflate(xmlMessageBytes);
            inflater.end();
            if (!inflater.finished()) {
                throw new RuntimeException(""buffer not large enough."");
            }
            inflater.end();
            return new String(xmlMessageBytes, 0, resultLength, StandardCharsets.UTF_8);
        } catch (final DataFormatException e) {
            return null;
        }
    }"
"public static String[] intersect(
      Comparator<? super String> comparator, String[] first, String[] second) {
    List<String> result = new ArrayList<>();
    for (String a : first) {
      for (String b : second) {
        if (comparator.compare(a, b) == 0) {
          result.add(a);
          break;
        }
      }
    }
    return result.toArray(new String[0]);
  }"
"public static InstrumentedExecutorService newCachedThreadPool(
            ThreadFactory threadFactory, MetricRegistry registry) {
        return new InstrumentedExecutorService(Executors.newCachedThreadPool(threadFactory), registry);
    }"
"void monitorChild() {
    Process proc = childProc;
    if (proc == null) {
      // Process may have already been disposed of, e.g. by calling kill().
      return;
    }

    while (proc.isAlive()) {
      try {
        proc.waitFor();
      } catch (Exception e) {
        LOG.log(Level.WARNING, ""Exception waiting for child process to exit."", e);
      }
    }

    synchronized (this) {
      if (isDisposed()) {
        return;
      }

      int ec;
      try {
        ec = proc.exitValue();
      } catch (Exception e) {
        LOG.log(Level.WARNING, ""Exception getting child process exit code, assuming failure."", e);
        ec = 1;
      }

      if (ec != 0) {
        State currState = getState();
        // Override state with failure if the current state is not final, or is success.
        if (!currState.isFinal() || currState == State.FINISHED) {
          setState(State.FAILED, true);
        }
      }

      dispose();
    }
  }"
"public ContextUserAuthManager getContextUserAuthManager(int contextId) {
		ContextUserAuthManager manager = contextManagers.get(contextId);
		if (manager == null) {
			manager = new ContextUserAuthManager(contextId);
			contextManagers.put(contextId, manager);
		}
		return manager;
	}"
"@Override
    public InputType getOutputType(InputType... inputType) throws InvalidKerasConfigurationException {
        if (inputType.length > 1)
            throw new InvalidKerasConfigurationException(
                            ""Keras LRN layer accepts only one input (received "" + inputType.length + "")"");
        return this.getLocalResponseNormalization().getOutputType(-1, inputType[0]);
    }"
"@Deprecated
    public static @Nonnull SecurityContext impersonate(@Nonnull Authentication auth) {
        SecurityContext old = SecurityContextHolder.getContext();
        SecurityContextHolder.setContext(new NonSerializableSecurityContext(auth));
        return old;
    }"
"@Override
  public ExecutionEntity createChildExecution(ExecutionEntity parentExecutionEntity) {
    ExecutionEntity childExecution = executionDataManager.create();
    inheritCommonProperties(parentExecutionEntity, childExecution);
    childExecution.setParent(parentExecutionEntity);
    childExecution.setProcessDefinitionId(parentExecutionEntity.getProcessDefinitionId());
    childExecution.setProcessDefinitionKey(parentExecutionEntity.getProcessDefinitionKey());
    childExecution.setProcessInstanceId(parentExecutionEntity.getProcessInstanceId() != null 
        ? parentExecutionEntity.getProcessInstanceId() : parentExecutionEntity.getId());
    childExecution.setParentProcessInstanceId(parentExecutionEntity.getParentProcessInstanceId());
    childExecution.setScope(false);

    // manage the bidirectional parent-child relation
    parentExecutionEntity.addChildExecution(childExecution);
    
    // Insert the child execution
    insert(childExecution, false);

    if (logger.isDebugEnabled()) {
      logger.debug(""Child execution {} created with parent {}"", childExecution, parentExecutionEntity.getId());
    }

    if (getEventDispatcher().isEnabled()) {
      getEventDispatcher().dispatchEvent(ActivitiEventBuilder.createEntityEvent(ActivitiEventType.ENTITY_CREATED, childExecution));
      getEventDispatcher().dispatchEvent(ActivitiEventBuilder.createEntityEvent(ActivitiEventType.ENTITY_INITIALIZED, childExecution));
    }

    return childExecution;
  }"
"public Expression createExpression(final String expression, final Class expectedType) {
        val parserContext = new FluentParserContext().expectResult(expectedType);
        return getSpringExpressionParser().parseExpression(expression, parserContext);
    }"
"public boolean upload(String path, String fileName, InputStream fileStream) {
		try {
			client.setFileType(FTPClient.BINARY_FILE_TYPE);
		} catch (IOException e) {
			throw new FtpException(e);
		}
		
		if(StrUtil.isNotBlank(path)) {
			mkDirs(path);
			boolean isOk = cd(path);
			if(false == isOk) {
				return false;
			}
		}
		
		try {
			return client.storeFile(fileName, fileStream);
		} catch (IOException e) {
			throw new FtpException(e);
		}
	}"
"public boolean fetch() throws IOException {
        try {
            // Fetching packet header from input.
            if (!fetch0(0, NET_HEADER_SIZE)) {
                logger.warn(""Reached end of input stream while fetching header"");
                return false;
            }

            // Fetching the first packet(may a multi-packet).
            int netlen = getUint24(PACKET_LEN_OFFSET);
            int netnum = getUint8(PACKET_SEQ_OFFSET);
            if (!fetch0(NET_HEADER_SIZE, netlen)) {
                logger.warn(""Reached end of input stream: packet #"" + netnum + "", len = "" + netlen);
                return false;
            }

            // Detecting error code.
            final int mark = getUint8(NET_HEADER_SIZE);
            if (mark != 0) {
                if (mark == 255) // error from master
                {
                    // Indicates an error, for example trying to fetch from
                    // wrong
                    // binlog position.
                    position = NET_HEADER_SIZE + 1;
                    final int errno = getInt16();
                    String sqlstate = forward(1).getFixString(SQLSTATE_LENGTH);
                    String errmsg = getFixString(limit - position);
                    throw new IOException(""Received error packet:"" + "" errno = "" + errno + "", sqlstate = "" + sqlstate
                                          + "" errmsg = "" + errmsg);
                } else if (mark == 254) {
                    // Indicates end of stream. It's not clear when this would
                    // be sent.
                    logger.warn(""Received EOF packet from server, apparent"" + "" master disconnected."");
                    return false;
                } else {
                    // Should not happen.
                    throw new IOException(""Unexpected response "" + mark + "" while fetching binlog: packet #"" + netnum
                                          + "", len = "" + netlen);
                }
            }

            // The first packet is a multi-packet, concatenate the packets.
            while (netlen == MAX_PACKET_LENGTH) {
                if (!fetch0(0, NET_HEADER_SIZE)) {
                    logger.warn(""Reached end of input stream while fetching header"");
                    return false;
                }

                netlen = getUint24(PACKET_LEN_OFFSET);
                netnum = getUint8(PACKET_SEQ_OFFSET);
                if (!fetch0(limit, netlen)) {
                    logger.warn(""Reached end of input stream: packet #"" + netnum + "", len = "" + netlen);
                    return false;
                }
            }

            // Preparing buffer variables to decoding.
            origin = NET_HEADER_SIZE + 1;
            position = origin;
            limit -= origin;
            return true;
        } catch (SocketTimeoutException e) {
            close(); /* Do cleanup */
            logger.error(""Socket timeout expired, closing connection"", e);
            throw e;
        } catch (InterruptedIOException e) {
            close(); /* Do cleanup */
            logger.warn(""I/O interrupted while reading from client socket"", e);
            throw e;
        } catch (IOException e) {
            close(); /* Do cleanup */
            logger.error(""I/O error while reading from client socket"", e);
            throw e;
        }
    }"
"public byte[] encrypt(String data, KeyType keyType) {
		return encrypt(StrUtil.bytes(data, CharsetUtil.CHARSET_UTF_8), keyType);
	}"
"@PublicEvolving
	public <R> SingleOutputStreamOperator<R> process(
			CoProcessFunction<IN1, IN2, R> coProcessFunction) {

		TypeInformation<R> outTypeInfo = TypeExtractor.getBinaryOperatorReturnType(
			coProcessFunction,
			CoProcessFunction.class,
			0,
			1,
			2,
			TypeExtractor.NO_INDEX,
			getType1(),
			getType2(),
			Utils.getCallLocationName(),
			true);

		return process(coProcessFunction, outTypeInfo);
	}"
"private CompletableFuture<LogicalSlot> allocateSharedSlot(
		SlotRequestId slotRequestId,
		ScheduledUnit scheduledUnit,
		SlotProfile slotProfile,
		boolean allowQueuedScheduling,
		Time allocationTimeout) {
		// allocate slot with slot sharing
		final SlotSharingManager multiTaskSlotManager = slotSharingManagers.computeIfAbsent(
			scheduledUnit.getSlotSharingGroupId(),
			id -> new SlotSharingManager(
				id,
				slotPool,
				this));

		final SlotSharingManager.MultiTaskSlotLocality multiTaskSlotLocality;
		try {
			if (scheduledUnit.getCoLocationConstraint() != null) {
				multiTaskSlotLocality = allocateCoLocatedMultiTaskSlot(
					scheduledUnit.getCoLocationConstraint(),
					multiTaskSlotManager,
					slotProfile,
					allowQueuedScheduling,
					allocationTimeout);
			} else {
				multiTaskSlotLocality = allocateMultiTaskSlot(
					scheduledUnit.getJobVertexId(),
					multiTaskSlotManager,
					slotProfile,
					allowQueuedScheduling,
					allocationTimeout);
			}
		} catch (NoResourceAvailableException noResourceException) {
			return FutureUtils.completedExceptionally(noResourceException);
		}

		// sanity check
		Preconditions.checkState(!multiTaskSlotLocality.getMultiTaskSlot().contains(scheduledUnit.getJobVertexId()));

		final SlotSharingManager.SingleTaskSlot leaf = multiTaskSlotLocality.getMultiTaskSlot().allocateSingleTaskSlot(
			slotRequestId,
			scheduledUnit.getJobVertexId(),
			multiTaskSlotLocality.getLocality());
		return leaf.getLogicalSlotFuture();
	}"
"@SneakyThrows
    protected void generate(final Resource file, final int bits) {
        if (!ResourceUtils.doesResourceExist(file)) {
            val rsaJsonWebKey = RsaJwkGenerator.generateJwk(bits);
            val jsonWebKeySet = new JsonWebKeySet(rsaJsonWebKey);
            val data = jsonWebKeySet.toJson(JsonWebKey.OutputControlLevel.INCLUDE_PRIVATE);
            val location = file instanceof FileSystemResource
                ? FileSystemResource.class.cast(file).getFile()
                : DEFAULT_JWKS_LOCATION;
            FileUtils.write(location, data, StandardCharsets.UTF_8);
            LOGGER.debug(""Generated JSON web keystore at [{}]"", location);
        } else {
            LOGGER.debug(""Located JSON web keystore at [{}]"", file);
        }
    }"
"public static <T> T release(final Resource<T> resource, final T instance) {
    return holder.releaseInternal(resource, instance);
  }"
"public List<SDVariable> diff(List<SDVariable> i_v1) {
        List<SDVariable> vals = doDiff(i_v1);
        if(vals == null){
            throw new IllegalStateException(""Error executing diff operation: doDiff returned null for op: "" + this.opName());
        }

        val outputVars = args();
        boolean copied = false;
        for(int i = 0; i < vals.size(); i++) {
            SDVariable var = outputVars[i];
            SDVariable grad = var.hasGradient() ? var.getGradient() : null;
            if(grad != null) {
                if(!copied){
                    //Don't mutate the original - this could mess with the original op's state!
                    vals = new ArrayList<>(vals);
                    copied = true;
                }

                SDVariable gradVar =  f().add(grad, vals.get(i));
                vals.set(i, gradVar);
                sameDiff.setGradientForVariableName(var.getVarName(), gradVar);
            } else {
                SDVariable gradVar = vals.get(i);
                sameDiff.updateVariableNameAndReference(gradVar,var.getVarName() + ""-grad"");
                sameDiff.setGradientForVariableName(var.getVarName(), gradVar);
                sameDiff.setForwardVariableForVarName(gradVar.getVarName(),var);

            }
        }

        return vals;
    }"
"private static boolean deleteRecursivelyIfExists(HdfsContext context, HdfsEnvironment hdfsEnvironment, Path path)
    {
        FileSystem fileSystem;
        try {
            fileSystem = hdfsEnvironment.getFileSystem(context, path);
        }
        catch (IOException ignored) {
            return false;
        }

        return deleteIfExists(fileSystem, path, true);
    }"
"public static int reflectionHashCode(final Object object, final boolean testTransients) {
        return reflectionHashCode(DEFAULT_INITIAL_VALUE, DEFAULT_MULTIPLIER_VALUE, object, 
                testTransients, null);
    }"
"public static String getFillerRuleDefinitionFileName(final String rootDir, final DatabaseType databaseType) {
        return Joiner.on('/').join(rootDir, databaseType.name().toLowerCase(), FILLER_DEFINITION_FILE_NAME);
    }"
"public ConfigurableApplicationContext run(String... args) {
		if (this.running.get()) {
			// If already created we just return the existing context
			return this.context;
		}
		configureAsChildIfNecessary(args);
		if (this.running.compareAndSet(false, true)) {
			synchronized (this.running) {
				// If not already running copy the sources over and then run.
				this.context = build().run(args);
			}
		}
		return this.context;
	}"
"private static void updateNetwork(WifiManager wifiManager, WifiConfiguration config) {
    Integer foundNetworkID = findNetworkInExistingConfig(wifiManager, config.SSID);
    if (foundNetworkID != null) {
      Log.i(TAG, ""Removing old configuration for network "" + config.SSID);
      wifiManager.removeNetwork(foundNetworkID);
      wifiManager.saveConfiguration();
    }
    int networkId = wifiManager.addNetwork(config);
    if (networkId >= 0) {
      // Try to disable the current network and start a new one.
      if (wifiManager.enableNetwork(networkId, true)) {
        Log.i(TAG, ""Associating to network "" + config.SSID);
        wifiManager.saveConfiguration();
      } else {
        Log.w(TAG, ""Failed to enable network "" + config.SSID);
      }
    } else {
      Log.w(TAG, ""Unable to add network "" + config.SSID);
    }
  }"
"public @Nullable String getRootUrl() throws IllegalStateException {
        final JenkinsLocationConfiguration config = JenkinsLocationConfiguration.get();
        if (config == null) {
            // Try to get standard message if possible
            final Jenkins j = Jenkins.getInstance();
            throw new IllegalStateException(""Jenkins instance "" + j + "" has been successfully initialized, but JenkinsLocationConfiguration is undefined."");
        }
        String url = config.getUrl();
        if(url!=null) {
            return Util.ensureEndsWith(url,""/"");
        }
        StaplerRequest req = Stapler.getCurrentRequest();
        if(req!=null)
            return getRootUrlFromRequest();
        return null;
    }"
"public Graph<K, VV, EV> filterOnEdges(FilterFunction<Edge<K, EV>> edgeFilter) {
		DataSet<Edge<K, EV>> filteredEdges = this.edges.filter(edgeFilter).name(""Filter on edges"");

		return new Graph<>(this.vertices, filteredEdges, this.context);
	}"
"private Result doDecode(BinaryBitmap image,
                          Map<DecodeHintType,?> hints) throws NotFoundException {
    int width = image.getWidth();
    int height = image.getHeight();
    BitArray row = new BitArray(width);

    boolean tryHarder = hints != null && hints.containsKey(DecodeHintType.TRY_HARDER);
    int rowStep = Math.max(1, height >> (tryHarder ? 8 : 5));
    int maxLines;
    if (tryHarder) {
      maxLines = height; // Look at the whole image, not just the center
    } else {
      maxLines = 15; // 15 rows spaced 1/32 apart is roughly the middle half of the image
    }

    int middle = height / 2;
    for (int x = 0; x < maxLines; x++) {

      // Scanning from the middle out. Determine which row we're looking at next:
      int rowStepsAboveOrBelow = (x + 1) / 2;
      boolean isAbove = (x & 0x01) == 0; // i.e. is x even?
      int rowNumber = middle + rowStep * (isAbove ? rowStepsAboveOrBelow : -rowStepsAboveOrBelow);
      if (rowNumber < 0 || rowNumber >= height) {
        // Oops, if we run off the top or bottom, stop
        break;
      }

      // Estimate black point for this row and load it:
      try {
        row = image.getBlackRow(rowNumber, row);
      } catch (NotFoundException ignored) {
        continue;
      }

      // While we have the image data in a BitArray, it's fairly cheap to reverse it in place to
      // handle decoding upside down barcodes.
      for (int attempt = 0; attempt < 2; attempt++) {
        if (attempt == 1) { // trying again?
          row.reverse(); // reverse the row and continue
          // This means we will only ever draw result points *once* in the life of this method
          // since we want to avoid drawing the wrong points after flipping the row, and,
          // don't want to clutter with noise from every single row scan -- just the scans
          // that start on the center line.
          if (hints != null && hints.containsKey(DecodeHintType.NEED_RESULT_POINT_CALLBACK)) {
            Map<DecodeHintType,Object> newHints = new EnumMap<>(DecodeHintType.class);
            newHints.putAll(hints);
            newHints.remove(DecodeHintType.NEED_RESULT_POINT_CALLBACK);
            hints = newHints;
          }
        }
        try {
          // Look for a barcode
          Result result = decodeRow(rowNumber, row, hints);
          // We found our barcode
          if (attempt == 1) {
            // But it was upside down, so note that
            result.putMetadata(ResultMetadataType.ORIENTATION, 180);
            // And remember to flip the result points horizontally.
            ResultPoint[] points = result.getResultPoints();
            if (points != null) {
              points[0] = new ResultPoint(width - points[0].getX() - 1, points[0].getY());
              points[1] = new ResultPoint(width - points[1].getX() - 1, points[1].getY());
            }
          }
          return result;
        } catch (ReaderException re) {
          // continue -- just couldn't decode this row
        }
      }
    }

    throw NotFoundException.getNotFoundInstance();
  }"
"public static UriTemplate append(UriTemplate uriTemplate, String fragment) {
    return new UriTemplate(uriTemplate.toString() + fragment, uriTemplate.encodeSlash(),
        uriTemplate.getCharset());
  }"
"public WebServiceTemplateBuilder customizers(
			Collection<? extends WebServiceTemplateCustomizer> customizers) {
		Assert.notNull(customizers, ""Customizers must not be null"");
		return new WebServiceTemplateBuilder(this.detectHttpMessageSender,
				this.interceptors, this.internalCustomizers,
				append(Collections.<WebServiceTemplateCustomizer>emptySet(), customizers),
				this.messageSenders, this.marshaller, this.unmarshaller,
				this.destinationProvider, this.transformerFactoryClass,
				this.messageFactory);
	}"
"public static void cut(InputStream srcStream, OutputStream destStream, Rectangle rectangle) {
		cut(read(srcStream), destStream, rectangle);
	}"
"@CheckForNull
    public Node getNode(String name) {
        return name == null ? null : nodes.get(name);
    }"
"public static RedissonReactiveClient createReactive() {
        Config config = new Config();
        config.useSingleServer().setAddress(""redis://127.0.0.1:6379"");
        return createReactive(config);
    }"
"public ApiResponse handleApiAction(String name, JSONObject params) throws ApiException {
		throw new ApiException(ApiException.Type.BAD_ACTION, name);
	}"
"@Override
    public byte[] toBytes(T instance)
            throws IllegalArgumentException
    {
        try {
            return mapper.writeValueAsBytes(instance);
        }
        catch (IOException e) {
            throw new IllegalArgumentException(format(""%s could not be converted to SMILE"", instance.getClass().getName()), e);
        }
    }"
"public static int[] stride(INDArray arr, INDArrayIndex[] indexes, int... shape) {
        List<Integer> strides = new ArrayList<>();
        int strideIndex = 0;
        //list of indexes to prepend to for new axes
        //if all is encountered
        List<Integer> prependNewAxes = new ArrayList<>();

        for (int i = 0; i < indexes.length; i++) {
            //just like the shape, drops the stride
            if (indexes[i] instanceof PointIndex) {
                strideIndex++;
                continue;
            } else if (indexes[i] instanceof NewAxis) {

            }
        }

        /**
         * For each dimension
         * where we want to prepend a dimension
         * we need to add it at the index such that
         * we account for the offset of the number of indexes
         * added up to that point.
         *
         * We do this by doing an offset
         * for each item added ""so far""
         *
         * Note that we also have an offset of - 1
         * because we want to prepend to the given index.
         *
         * When prepend new axes for in the middle is triggered
         * i is already > 0
         */
        for (int i = 0; i < prependNewAxes.size(); i++) {
            strides.add(prependNewAxes.get(i) - i, 1);
        }

        return Ints.toArray(strides);

    }"
"private RPC<V> handleLocal() {
    assert _dt.getCompleter()==null;
    _dt.setCompleter(new H2O.H2OCallback<DTask>() {
        @Override public void callback(DTask dt) {
          synchronized(RPC.this) {
            _done = true;
            RPC.this.notifyAll();
          }
          doAllCompletions();
        }
        @Override public boolean onExceptionalCompletion(Throwable ex, CountedCompleter dt) {
          synchronized(RPC.this) { // Might be called several times
            if( _done ) return true; // Filter down to 1st exceptional completion
            _dt.setException(ex);
            // must be the last set before notify call cause the waiting thread
            // can wake up at any moment independently on notify
            _done = true;
            RPC.this.notifyAll();
          }
          doAllCompletions();
          return true;
        }
      });
    H2O.submitTask(_dt);
    return this;
  }"
"private int findValueIndicesIndexForSubColumn()
  {
    final DimensionSelector keySelector = getKeySelector();
    final DimensionSelector valueSelector = getValueSelector();

    final IndexedInts keyIndices = keySelector.getRow();
    final IndexedInts valueIndices = valueSelector.getRow();

    final int limit = Math.min(keyIndices.size(), valueIndices.size());

    return IntStream
        .range(0, limit)
        .filter(i -> subColumnName.equals(keySelector.lookupName(keyIndices.get(i)))) // subColumnName is never null
        .findAny()
        .orElse(-1);
  }"
"public <T extends Serializer<?> & Serializable>void registerTypeWithKryoSerializer(Class<?> type, T serializer) {
		if (type == null || serializer == null) {
			throw new NullPointerException(""Cannot register null class or serializer."");
		}

		registeredTypesWithKryoSerializers.put(type, new SerializableSerializer<>(serializer));
	}"
"@Override
   void recycle(final PoolEntry poolEntry)
   {
      metricsTracker.recordConnectionUsage(poolEntry);

      connectionBag.requite(poolEntry);
   }"
"public List<DistinctQueryResult> divide() {
        return Lists.newArrayList(Iterators.transform(resultData, new Function<QueryRow, DistinctQueryResult>() {
            
            @Override
            public DistinctQueryResult apply(final QueryRow row) {
                Set<QueryRow> resultData = new LinkedHashSet<>();
                resultData.add(row);
                return new DistinctQueryResult(columnLabelAndIndexMap, resultData.iterator());
            }
        }));
    }"
"@Override
	public Map<String, SerializedValue<OptionalFailure<Object>>> getAccumulatorsSerialized() {
		return aggregateUserAccumulators()
			.entrySet()
			.stream()
			.collect(Collectors.toMap(
				Map.Entry::getKey,
				entry -> serializeAccumulator(entry.getKey(), entry.getValue())));
	}"
"public static String getValue(String xpath, Document document) throws XPathExpressionException {
        XPath xPathProcessor = XPathFactory.newInstance().newXPath();
        return xPathProcessor.compile(xpath).evaluate(document);
    }"
"public RetryTransformer<T> recover(@Nullable Function<Throwable, ? extends T> recoverer) {
        this.recoverer = recoverer;
        return this;
    }"
"public MultiNormalizerStandardize restore(@NonNull InputStream stream) throws IOException {
        DataInputStream dis = new DataInputStream(stream);
        boolean fitLabels = dis.readBoolean();
        int numInputs = dis.readInt();
        int numOutputs = dis.readInt();

        MultiNormalizerStandardize result = new MultiNormalizerStandardize();
        result.fitLabel(fitLabels);

        List<DistributionStats> featureStats = new ArrayList<>();
        for (int i = 0; i < numInputs; i++) {
            featureStats.add(new DistributionStats(Nd4j.read(dis), Nd4j.read(dis)));
        }
        result.setFeatureStats(featureStats);

        if (fitLabels) {
            List<DistributionStats> labelStats = new ArrayList<>();
            for (int i = 0; i < numOutputs; i++) {
                labelStats.add(new DistributionStats(Nd4j.read(dis), Nd4j.read(dis)));
            }
            result.setLabelStats(labelStats);
        }

        return result;
    }"
"static String generateErrorCorrection(CharSequence dataCodewords, int errorCorrectionLevel) {
    int k = getErrorCorrectionCodewordCount(errorCorrectionLevel);
    char[] e = new char[k];
    int sld = dataCodewords.length();
    for (int i = 0; i < sld; i++) {
      int t1 = (dataCodewords.charAt(i) + e[e.length - 1]) % 929;
      int t2;
      int t3;
      for (int j = k - 1; j >= 1; j--) {
        t2 = (t1 * EC_COEFFICIENTS[errorCorrectionLevel][j]) % 929;
        t3 = 929 - t2;
        e[j] = (char) ((e[j - 1] + t3) % 929);
      }
      t2 = (t1 * EC_COEFFICIENTS[errorCorrectionLevel][0]) % 929;
      t3 = 929 - t2;
      e[0] = (char) (t3 % 929);
    }
    StringBuilder sb = new StringBuilder(k);
    for (int j = k - 1; j >= 0; j--) {
      if (e[j] != 0) {
        e[j] = (char) (929 - e[j]);
      }
      sb.append(e[j]);
    }
    return sb.toString();
  }"
"public static List<Field> getAllFields(Class clazz) {
        List<Field> all = new ArrayList<Field>();
        for (Class<?> c = clazz; c != Object.class && c != null; c = c.getSuperclass()) {
            Field[] fields = c.getDeclaredFields(); // 所有方法，不包含父类
            for (Field field : fields) {
                int mod = field.getModifiers();
                // 过滤static 和 transient，支持final
                if (Modifier.isStatic(mod) || Modifier.isTransient(mod)) {
                    continue;
                }
                field.setAccessible(true); // 不管private还是protect都可以
                all.add(field);
            }
        }
        return all;
    }"
"private byte[] readLineBytesSlowly() {
    ByteArrayOutputStream bout = null;
    while (true) {
      ensureFill();

      byte b = buf[count++];
      if (b == '\r') {
        ensureFill(); // Must be one more byte

        byte c = buf[count++];
        if (c == '\n') {
          break;
        }

        if (bout == null) {
          bout = new ByteArrayOutputStream(16);
        }

        bout.write(b);
        bout.write(c);
      } else {
        if (bout == null) {
          bout = new ByteArrayOutputStream(16);
        }

        bout.write(b);
      }
    }

    return bout == null ? new byte[0] : bout.toByteArray();
  }"
"public HistoryReference getHistoryReference(int historyReferenceId) {
        DefaultHistoryReferencesTableEntry entry = getEntryWithHistoryId(historyReferenceId);
        if (entry != null) {
            return entry.getHistoryReference();
        }
        return null;
    }"
"public List<String> lsFiles(String path) {
		return ls(path, new Filter<LsEntry>() {
			@Override
			public boolean accept(LsEntry t) {
				return false == t.getAttrs().isDir();
			}
		});
	}"
"public void setRunningStatusIfNecessary() {
        if (ConnectionStatus.TRANSACTION != status.get() && ConnectionStatus.RUNNING != status.get()) {
            status.getAndSet(ConnectionStatus.RUNNING);
        }
    }"
"public static TumblingEventTimeWindows of(Time size, Time offset) {
		return new TumblingEventTimeWindows(size.toMilliseconds(), offset.toMilliseconds());
	}"
"@Override
    public double computeScore(double fullNetRegTerm, boolean training, LayerWorkspaceMgr workspaceMgr) {
        if (input == null)
            throw new IllegalStateException(""Cannot calculate score without input and labels "" + layerId());
        INDArray preOut = preOutput2d(training, workspaceMgr);

        ILossFunction lossFunction = layerConf().getLossFn();

        double score = lossFunction.computeScore(getLabels2d(workspaceMgr, ArrayType.FF_WORKING_MEM), preOut,
                layerConf().getActivationFn(), maskArray,false);
        if(conf().isMiniBatch())
            score /= getInputMiniBatchSize();

        score += fullNetRegTerm;
        this.score = score;
        return score;
    }"
"private static <T> List<TableFactory> filterByContext(
		Class<T> factoryClass,
		Map<String, String> properties,
		List<TableFactory> foundFactories,
		List<TableFactory> classFactories) {

		List<TableFactory> matchingFactories = classFactories.stream().filter(factory -> {
			Map<String, String> requestedContext = normalizeContext(factory);

			Map<String, String> plainContext = new HashMap<>(requestedContext);
			// we remove the version for now until we have the first backwards compatibility case
			// with the version we can provide mappings in case the format changes
			plainContext.remove(CONNECTOR_PROPERTY_VERSION);
			plainContext.remove(FORMAT_PROPERTY_VERSION);
			plainContext.remove(METADATA_PROPERTY_VERSION);
			plainContext.remove(STATISTICS_PROPERTY_VERSION);
			plainContext.remove(CATALOG_PROPERTY_VERSION);

			// check if required context is met
			return plainContext.keySet().stream().allMatch(e -> properties.containsKey(e) && properties.get(e).equals(plainContext.get(e)));
		}).collect(Collectors.toList());

		if (matchingFactories.isEmpty()) {
			throw new NoMatchingTableFactoryException(
				""No context matches."",
				factoryClass,
				foundFactories,
				properties);
		}

		return matchingFactories;
	}"
"public ByteBuffer[] nioBuffers(int maxCount, long maxBytes) {
        assert maxCount > 0;
        assert maxBytes > 0;
        long nioBufferSize = 0;
        int nioBufferCount = 0;
        final InternalThreadLocalMap threadLocalMap = InternalThreadLocalMap.get();
        ByteBuffer[] nioBuffers = NIO_BUFFERS.get(threadLocalMap);
        Entry entry = flushedEntry;
        while (isFlushedEntry(entry) && entry.msg instanceof ByteBuf) {
            if (!entry.cancelled) {
                ByteBuf buf = (ByteBuf) entry.msg;
                final int readerIndex = buf.readerIndex();
                final int readableBytes = buf.writerIndex() - readerIndex;

                if (readableBytes > 0) {
                    if (maxBytes - readableBytes < nioBufferSize && nioBufferCount != 0) {
                        // If the nioBufferSize + readableBytes will overflow maxBytes, and there is at least one entry
                        // we stop populate the ByteBuffer array. This is done for 2 reasons:
                        // 1. bsd/osx don't allow to write more bytes then Integer.MAX_VALUE with one writev(...) call
                        // and so will return 'EINVAL', which will raise an IOException. On Linux it may work depending
                        // on the architecture and kernel but to be safe we also enforce the limit here.
                        // 2. There is no sense in putting more data in the array than is likely to be accepted by the
                        // OS.
                        //
                        // See also:
                        // - https://www.freebsd.org/cgi/man.cgi?query=write&sektion=2
                        // - http://linux.die.net/man/2/writev
                        break;
                    }
                    nioBufferSize += readableBytes;
                    int count = entry.count;
                    if (count == -1) {
                        //noinspection ConstantValueVariableUse
                        entry.count = count = buf.nioBufferCount();
                    }
                    int neededSpace = min(maxCount, nioBufferCount + count);
                    if (neededSpace > nioBuffers.length) {
                        nioBuffers = expandNioBufferArray(nioBuffers, neededSpace, nioBufferCount);
                        NIO_BUFFERS.set(threadLocalMap, nioBuffers);
                    }
                    if (count == 1) {
                        ByteBuffer nioBuf = entry.buf;
                        if (nioBuf == null) {
                            // cache ByteBuffer as it may need to create a new ByteBuffer instance if its a
                            // derived buffer
                            entry.buf = nioBuf = buf.internalNioBuffer(readerIndex, readableBytes);
                        }
                        nioBuffers[nioBufferCount++] = nioBuf;
                    } else {
                        // The code exists in an extra method to ensure the method is not too big to inline as this
                        // branch is not very likely to get hit very frequently.
                        nioBufferCount = nioBuffers(entry, buf, nioBuffers, nioBufferCount, maxCount);
                    }
                    if (nioBufferCount == maxCount) {
                        break;
                    }
                }
            }
            entry = entry.next;
        }
        this.nioBufferCount = nioBufferCount;
        this.nioBufferSize = nioBufferSize;

        return nioBuffers;
    }"
"public SDVariable norm2(String name, boolean keepDims, int... dimensions){
        return sameDiff.norm2(name, this, keepDims, dimensions);
    }"
"@Override
	public void serialize(SavepointV2 checkpointMetadata, DataOutputStream dos) throws IOException {
		// first: checkpoint ID
		dos.writeLong(checkpointMetadata.getCheckpointId());

		// second: master state
		final Collection<MasterState> masterStates = checkpointMetadata.getMasterStates();
		dos.writeInt(masterStates.size());
		for (MasterState ms : masterStates) {
			serializeMasterState(ms, dos);
		}

		// third: operator states
		Collection<OperatorState> operatorStates = checkpointMetadata.getOperatorStates();
		dos.writeInt(operatorStates.size());

		for (OperatorState operatorState : operatorStates) {
			// Operator ID
			dos.writeLong(operatorState.getOperatorID().getLowerPart());
			dos.writeLong(operatorState.getOperatorID().getUpperPart());

			// Parallelism
			int parallelism = operatorState.getParallelism();
			dos.writeInt(parallelism);
			dos.writeInt(operatorState.getMaxParallelism());
			dos.writeInt(1);

			// Sub task states
			Map<Integer, OperatorSubtaskState> subtaskStateMap = operatorState.getSubtaskStates();
			dos.writeInt(subtaskStateMap.size());
			for (Map.Entry<Integer, OperatorSubtaskState> entry : subtaskStateMap.entrySet()) {
				dos.writeInt(entry.getKey());
				serializeSubtaskState(entry.getValue(), dos);
			}
		}
	}"
"public void connect(List<Tree> children) {
        this.children = children;
        for (Tree t : children)
            t.setParent(this);
    }"
"public static Integer getInteger(String name, Integer def) {
        return getInteger(name, def, Level.CONFIG);
    }"
"public static PublicKey generatePublicKey(String algorithm, byte[] key) {
		if (null == key) {
			return null;
		}
		return generatePublicKey(algorithm, new X509EncodedKeySpec(key));
	}"
"public AppenderatorDriverAddResult add(
      final InputRow row,
      final String sequenceName,
      final Supplier<Committer> committerSupplier,
      final boolean skipSegmentLineageCheck,
      final boolean allowIncrementalPersists
  ) throws IOException
  {
    return append(row, sequenceName, committerSupplier, skipSegmentLineageCheck, allowIncrementalPersists);
  }"
"public static java.sql.Timestamp toSqlTimestamp(java.util.Date date) {
		return new java.sql.Timestamp(date.getTime());
	}"
"public static Dependencies fromThrift(ByteBuffer bytes) {
    long startTs = 0L;
    long endTs = 0L;
    List<DependencyLink> links = Collections.emptyList();

    while (true) {
      ThriftField thriftField = ThriftField.read(bytes);
      if (thriftField.type == TYPE_STOP) break;

      if (thriftField.isEqualTo(START_TS)) {
        startTs = bytes.getLong();
      } else if (thriftField.isEqualTo(END_TS)) {
        endTs = bytes.getLong();
      } else if (thriftField.isEqualTo(LINKS)) {
        int length = ThriftCodec.readListLength(bytes);
        if (length == 0) continue;
        links = new ArrayList<>(length);
        for (int i = 0; i < length; i++) {
          links.add(DependencyLinkAdapter.read(bytes));
        }
      } else {
        skip(bytes, thriftField.type);
      }
    }

    return Dependencies.create(startTs, endTs, links);
  }"
"public static boolean isCasAuthenticationOldForMaxAgeAuthorizationRequest(final WebContext context,
                                                                              final UserProfile profile) {

        val authTime = profile.getAttribute(CasProtocolConstants.VALIDATION_CAS_MODEL_ATTRIBUTE_NAME_AUTHENTICATION_DATE);
        if (authTime == null) {
            return false;
        }
        val dt = ZonedDateTime.parse(authTime.toString());
        return isCasAuthenticationOldForMaxAgeAuthorizationRequest(context, dt);
    }"
"public DataSource<String> readTextFile(String filePath, String charsetName) {
		Preconditions.checkNotNull(filePath, ""The file path may not be null."");

		TextInputFormat format = new TextInputFormat(new Path(filePath));
		format.setCharsetName(charsetName);
		return new DataSource<>(this, format, BasicTypeInfo.STRING_TYPE_INFO, Utils.getCallLocationName());
	}"
"public TransportStats getStats() {
    long localFlowControlWindow =
        flowControlWindowReader == null ? -1 : flowControlWindowReader.read().localBytes;
    long remoteFlowControlWindow =
        flowControlWindowReader == null ? -1 : flowControlWindowReader.read().remoteBytes;
    return new TransportStats(
        streamsStarted,
        lastLocalStreamCreatedTimeNanos,
        lastRemoteStreamCreatedTimeNanos,
        streamsSucceeded,
        streamsFailed,
        messagesSent,
        messagesReceived.value(),
        keepAlivesSent,
        lastMessageSentTimeNanos,
        lastMessageReceivedTimeNanos,
        localFlowControlWindow,
        remoteFlowControlWindow);
  }"
"public static String sha256Hex(String data, String charset) {
		return new Digester(DigestAlgorithm.SHA256).digestHex(data, charset);
	}"
"public static void main(final String[] args) throws IOException {
        ShardingConfiguration shardingConfig = new ShardingConfigurationLoader().load();
        int port = getPort(args);
        if (null == shardingConfig.getServerConfiguration().getOrchestration()) {
            startWithoutRegistryCenter(shardingConfig.getRuleConfigurationMap(), shardingConfig.getServerConfiguration().getAuthentication(), shardingConfig.getServerConfiguration().getProps(), port);
        } else {
            startWithRegistryCenter(shardingConfig.getServerConfiguration(), shardingConfig.getRuleConfigurationMap().keySet(), shardingConfig.getRuleConfigurationMap(), port);
        }
    }"
"public static DataBuffer shapeOf(DataBuffer buffer) {
        int rank = (int) buffer.getLong(0);
        return Nd4j.createBuffer(buffer, 1, rank);
    }"
"public static KeyPair generateKeyPair(String algorithm, AlgorithmParameterSpec params) {
		return KeyUtil.generateKeyPair(algorithm, params);
	}"
"private X509TrustManager defaultTrustManager() throws GeneralSecurityException {
    TrustManagerFactory trustManagerFactory = TrustManagerFactory.getInstance(
        TrustManagerFactory.getDefaultAlgorithm());
    trustManagerFactory.init((KeyStore) null);
    TrustManager[] trustManagers = trustManagerFactory.getTrustManagers();
    if (trustManagers.length != 1 || !(trustManagers[0] instanceof X509TrustManager)) {
      throw new IllegalStateException(""Unexpected default trust managers:""
          + Arrays.toString(trustManagers));
    }
    return (X509TrustManager) trustManagers[0];
  }"
"private static Object typeCast(String str) {
        if (str == null || str.equals("""")) {
            return null;
        }
        // Try to cast to boolean true
        for (String trueString : trueArray) {
            if (trueString.equals(str)) {
                return true;
            }
        }
        // Try to cast to boolean false
        for (String falseString : falseArray) {
            if (falseString.equals(str)) {
                return false;
            }
        }
        // Strings that cannot cast to int or double are treated as string
        try {
            return Integer.parseInt(str);
        } catch (Exception e1) {
            try {
                return Double.parseDouble(str);
            } catch (Exception e2) {
                return str;
            }
        }
    }"
"public boolean handleMessageReceivedFromServer(Message aMessage, boolean onlyIfInScope) {
        if (! isBreakpoint(aMessage, false, onlyIfInScope)) {
            return true;
        }
        
        // Do this outside of the semaphore loop so that the 'continue' button can apply to all queued break points
        // but be reset when the next break point is hit
        breakMgmt.breakpointHit();
        BreakEventPublisher.getPublisher().publishHitEvent(aMessage);

        synchronized(SEMAPHORE) {
            if (breakMgmt.isHoldMessage(aMessage)) {
                BreakEventPublisher.getPublisher().publishActiveEvent(aMessage);
                setBreakDisplay(aMessage, false);
                waitUntilContinue(aMessage, false);
                BreakEventPublisher.getPublisher().publishInactiveEvent(aMessage);
            }
        }
        breakMgmt.clearAndDisableResponse();
        return ! breakMgmt.isToBeDropped();
    }"
"public static byte schemaToColumnType(Schema s) {
    Schema.Type typ =  s.getType();
    switch (typ) {
      case BOOLEAN:
      case INT:
      case LONG:
      case FLOAT:
      case DOUBLE:
        return Vec.T_NUM;
      case ENUM:
        return Vec.T_CAT;
      case STRING:
        return Vec.T_STR;
      case NULL:
        return Vec.T_BAD;
      case BYTES:
        return Vec.T_STR;
      case UNION: // Flattenize the union
        List<Schema> unionSchemas = s.getTypes();
        if (unionSchemas.size() == 1) {
          return schemaToColumnType(unionSchemas.get(0));
        } else if (unionSchemas.size() == 2) {
          Schema s1 = unionSchemas.get(0);
          Schema s2 = unionSchemas.get(1);
          if (s1.getType().equals(Schema.Type.NULL)) return schemaToColumnType(s2);
          else if (s2.getType().equals(Schema.Type.NULL)) return schemaToColumnType(s1);
        }
      default:
        throw new IllegalArgumentException(""Unsupported Avro schema type: "" + s);
    }
  }"
"public static String getOriginalNameFromInternal(String internalName) {
		Preconditions.checkNotNull(internalName);
		return internalName.split(STATE_NAME_DELIM)[0];
	}"
"public boolean shouldInvoke(C context) {
    cleanupExpiredSuppressions();

    if (cache.containsKey(context)) return false;

    Suppression<C> suppression = new Suppression<>(ticker, context, ticker.read() + ttlNanos);

    if (cache.putIfAbsent(context, suppression) != null) return false; // lost race

    suppressions.offer(suppression);

    // If we added an entry, it could make us go over the max size.
    if (suppressions.size() > cardinality) removeOneSuppression();

    return true;
  }"
"public static int[] getHeightAndWidth(int[] shape) {
        if (shape.length < 2)
            throw new IllegalArgumentException(""No width and height able to be found: array must be at least length 2"");
        return new int[]{shape[shape.length - 1], shape[shape.length - 2]};
    }"
"protected void configureLinkedInClient(final Collection<BaseClient> properties) {
        val ln = pac4jProperties.getLinkedIn();
        if (StringUtils.isNotBlank(ln.getId()) && StringUtils.isNotBlank(ln.getSecret())) {
            val client = new LinkedIn2Client(ln.getId(), ln.getSecret());
            configureClient(client, ln);

            if (StringUtils.isNotBlank(ln.getScope())) {
                client.setScope(ln.getScope());
            }

            if (StringUtils.isNotBlank(ln.getFields())) {
                client.setFields(ln.getFields());
            }
            LOGGER.debug(""Created client [{}] with identifier [{}]"", client.getName(), client.getKey());
            properties.add(client);
        }
    }"
"private static boolean isAbsolute(@Nonnull String rel) {
        return rel.startsWith(""/"") || DRIVE_PATTERN.matcher(rel).matches() || UNC_PATTERN.matcher(rel).matches();
    }"
"public static boolean isDelimiter(String str)
    {
        if (str != null && (""-"".equals(str) || ""－"".equals(str)))
            return true;
        else
            return false;
    }"
"public static boolean deleteDir(File dirFile) {
        if (!dirFile.exists()) {
            return false;
        }

        if (dirFile.isFile()) {
            return dirFile.delete();
        } else {
            File[] files = dirFile.listFiles();
            if (files == null || files.length == 0) {
                return dirFile.delete();
            }
            for (File file : files) {
                deleteDir(file);
            }
        }

        return dirFile.delete();
    }"
"@Bean
  public AlternateTypeRuleConvention pageableConvention(
      final TypeResolver resolver,
      final RepositoryRestConfiguration restConfiguration) {
    return new AlternateTypeRuleConvention() {

      @Override
      public int getOrder() {
        return Ordered.HIGHEST_PRECEDENCE;
      }

      @Override
      public List<AlternateTypeRule> rules() {
        return singletonList(
            newRule(resolver.resolve(Pageable.class), resolver.resolve(pageableMixin(restConfiguration)))
        );
      }
    };
  }"
"public void putMemorySize(String key, MemorySize size) {
		checkNotNull(key);
		checkNotNull(size);
		put(key, size.toString());
	}"
"@NonNull
  public static Caffeine<Object, Object> from(String spec) {
    return from(CaffeineSpec.parse(spec));
  }"
"public int getInt(String key) {
		addToDefaults(key, null);
		String value = getRequired(key);
		return Integer.parseInt(value);
	}"
"public static String extractMultiAndDelPre(String regex, Holder<CharSequence> contentHolder, String template) {
		if (null == contentHolder || null == regex || null == template) {
			return null;
		}

		// Pattern pattern = Pattern.compile(regex, Pattern.DOTALL);
		final Pattern pattern = PatternPool.get(regex, Pattern.DOTALL);
		return extractMultiAndDelPre(pattern, contentHolder, template);
	}"
"public double score(DataSet data, boolean training) {
        try{
            return scoreHelper(data, training);
        } catch (OutOfMemoryError e){
            CrashReportingUtil.writeMemoryCrashDump(this, e);
            throw e;
        }
    }"
"public static BigDecimal fen2yuan(String num) {
		if (StringUtils.isEmpty(num)) {
			return new BigDecimal(0);
		}
		return fen2yuan(new BigDecimal(num));
	}"
"public INDArray[] output(boolean train, INDArray... input) {
        return output(train, (MemoryWorkspace)null, input);
    }"
"static BinaryString readBinaryStringFieldFromSegments(
			MemorySegment[] segments, int baseOffset, int fieldOffset,
			long variablePartOffsetAndLen) {
		long mark = variablePartOffsetAndLen & HIGHEST_FIRST_BIT;
		if (mark == 0) {
			final int subOffset = (int) (variablePartOffsetAndLen >> 32);
			final int len = (int) variablePartOffsetAndLen;
			return new BinaryString(segments, baseOffset + subOffset, len);
		} else {
			int len = (int) ((variablePartOffsetAndLen & HIGHEST_SECOND_TO_EIGHTH_BIT) >>> 56);
			if (SegmentsUtil.LITTLE_ENDIAN) {
				return new BinaryString(segments, fieldOffset, len);
			} else {
				// fieldOffset + 1 to skip header.
				return new BinaryString(segments, fieldOffset + 1, len);
			}
		}
	}"
"public static SameDiff replaceSubgraphsMatching(@NonNull SameDiff sd, @NonNull SubGraphPredicate p, @NonNull SubGraphProcessor processor) {
        //Make a copy so that if the transform fails part way through, we don't leave user with broken graph
        sd = sd.dup();

        List<SubGraph> subgraphs = getSubgraphsMatching(sd, p);

        for (SubGraph sg : subgraphs) {
            List<SDVariable> newOutputs = processor.processSubgraph(sd, sg);
            List<SDVariable> oldOutputs = sg.outputs();
            Preconditions.checkState(oldOutputs.size() == newOutputs.size(), ""Error applying subgraph processor: "" +
                    ""different number of outputs for subgraph (%s) vs. returned by preprocessor (%s)"", oldOutputs.size(), newOutputs.size());

            //Step 1: replace the old outputs with new outputs
            //So for initial graph (x -> y -> z) and post application of processor we now have (x -> (y, A); y->z),
            // we want to end up with (x -> A -> z)
            List<DifferentialFunction> allSubGraphFns = sg.allFunctionsInSubgraph();
            for (int i = 0; i < oldOutputs.size(); i++) {
                String oldOutVarName = oldOutputs.get(i).getVarName();
                String newOutVarName = newOutputs.get(i).getVarName();
                Preconditions.checkState(!oldOutVarName.equals(newOutVarName), ""Reusing old variables not yet implemented"");

                //Update inputs for ops: if X->opA, and now Y->opA, then X.inputsForOps contains ""opA""; Y.inputsForOps should be updated
                List<String> oldInputsForOps = sd.getVariables().get(oldOutVarName).getInputsForOp();
                if (oldInputsForOps != null) {
                    List<String> newInputsForOps = new ArrayList<>();
                    for (String s : oldInputsForOps) {
                        DifferentialFunction df = sd.getFunctionById(s);
                        if (!allSubGraphFns.contains(df)) {
                            newInputsForOps.add(s);
                        }
                    }
                    sd.getVariables().get(newOutVarName).setInputsForOp(newInputsForOps);
                }


                //Basically: anywhere that oldName exists, newName should be substituted
                for (Variable v : sd.getVariables().values()) {
                    // if control dep v -> oldOutput exists, replace it
                    if (v.getControlDepsForVar() != null) {
                        List<String> cds = v.getControlDepsForVar();
                        int idx;
                        while ((idx = cds.indexOf(oldOutVarName)) > 0) {
                            cds.set(idx, newOutVarName);
                        }
                    }

                    if (v.getControlDeps() != null) {
                        List<String> cds = v.getControlDeps();
                        //Control dependency oldOutput -> v exists, replace it
                        int idx;
                        while ((idx = cds.indexOf(oldOutVarName)) > 0) {
                            cds.set(idx, newOutVarName);
                        }
                    }
                }

                for (SameDiffOp op : sd.getOps().values()) {
                    List<String> inputsToOp = op.getInputsToOp();
                    if (inputsToOp != null) {
                        int idx;
                        while ((idx = inputsToOp.indexOf(oldOutVarName)) >= 0) {
                            //Previous Op.inputs = {oldVarName, ...} - now {newVarName, ...}
                            inputsToOp.set(idx, newOutVarName);
                        }
                    }

                    //Don't need to modify outputsOfOp - old outputs are only on functions to be removed anyway
                    List<String> controlDeps = op.getControlDeps();
                    if (controlDeps != null) {
                        int idx;
                        while ((idx = controlDeps.indexOf(oldOutVarName)) >= 0) {
                            //Previous Op.inputs = {oldVarName, ...} - now {newVarName, ...}
                            controlDeps.set(idx, newOutVarName);
                        }
                    }
                }
            }

            //Step 2: Update input variables: if X -> (subgraph) exists, then X.inputsForOp needs to be updated
            List<SDVariable> inputs = sg.inputs();
            for (SDVariable v : inputs) {
                Variable var = sd.getVariables().get(v.getVarName());
                if (var.getInputsForOp() != null) {
                    List<String> newInputsForOp = new ArrayList<>(var.getInputsForOp());
                    for (String opName : var.getInputsForOp()) {
                        //Two possibilities here:
                        // (1) variable is (was) input to op that has been removed - just remove from list
                        // (2) variable is now connected directly as an output: (A->B->C) becomes (A->C)
                        // For the latter case, this
                        DifferentialFunction df = sd.getFunctionById(opName);
                        if (allSubGraphFns.contains(df)) {
                            newInputsForOp.remove(opName);
                        }
                    }
                    var.setInputsForOp(newInputsForOp);
                }
            }


            //Step 3: Remove the old variables and old functions
            Map<String, SameDiffOp> ops = sd.getOps();
            Map<String, Variable> vars = sd.getVariables();

            for (DifferentialFunction df : sg.allFunctionsInSubgraph()) {
                ops.remove(df.getOwnName());
                SDVariable[] outputs = df.outputVariables();
                if (outputs != null) {
                    for (SDVariable v : outputs) {
                        vars.remove(v.getVarName());
                    }
                }
            }
        }

        return sd;
    }"
"public AztecDetectorResult detect(boolean isMirror) throws NotFoundException {

    // 1. Get the center of the aztec matrix
    Point pCenter = getMatrixCenter();

    // 2. Get the center points of the four diagonal points just outside the bull's eye
    //  [topRight, bottomRight, bottomLeft, topLeft]
    ResultPoint[] bullsEyeCorners = getBullsEyeCorners(pCenter);

    if (isMirror) {
      ResultPoint temp = bullsEyeCorners[0];
      bullsEyeCorners[0] = bullsEyeCorners[2];
      bullsEyeCorners[2] = temp;
    }

    // 3. Get the size of the matrix and other parameters from the bull's eye
    extractParameters(bullsEyeCorners);

    // 4. Sample the grid
    BitMatrix bits = sampleGrid(image,
                                bullsEyeCorners[shift % 4],
                                bullsEyeCorners[(shift + 1) % 4],
                                bullsEyeCorners[(shift + 2) % 4],
                                bullsEyeCorners[(shift + 3) % 4]);

    // 5. Get the corners of the matrix.
    ResultPoint[] corners = getMatrixCornerPoints(bullsEyeCorners);

    return new AztecDetectorResult(bits, corners, compact, nbDataBlocks, nbLayers);
  }"
"public static double nextDouble(Random random, final double min, final double max) {
		Validate.isTrue(max >= min, ""Start value must be smaller or equal to end value."");
		MoreValidate.nonNegative(""min"", min);

		if (Double.compare(min, max) == 0) {
			return min;
		}

		return min + ((max - min) * random.nextDouble());
	}"
"public static List<Action> createAllFor(View v) {
		List<Action> result = new ArrayList<>();
		for (TransientViewActionFactory f: all()) {
			result.addAll(f.createFor(v));
		}
		return result;
	}"
"@PublicEvolving
	@Deprecated
	public <OUT> DataStreamSource<OUT> readFile(FileInputFormat<OUT> inputFormat,
												String filePath,
												FileProcessingMode watchType,
												long interval,
												FilePathFilter filter) {
		inputFormat.setFilesFilter(filter);

		TypeInformation<OUT> typeInformation;
		try {
			typeInformation = TypeExtractor.getInputFormatTypes(inputFormat);
		} catch (Exception e) {
			throw new InvalidProgramException(""The type returned by the input format could not be "" +
					""automatically determined. Please specify the TypeInformation of the produced type "" +
					""explicitly by using the 'createInput(InputFormat, TypeInformation)' method instead."");
		}
		return readFile(inputFormat, filePath, watchType, interval, typeInformation);
	}"
"public void contextInitialized(ServletContextEvent event) {
        JenkinsJVMAccess._setJenkinsJVM(true);
        final ServletContext context = event.getServletContext();
        File home=null;
        try {

            // use the current request to determine the language
            LocaleProvider.setProvider(new LocaleProvider() {
                public Locale get() {
                    return Functions.getCurrentLocale();
                }
            });

            // quick check to see if we (seem to) have enough permissions to run. (see #719)
            JVM jvm;
            try {
                jvm = new JVM();
                new URLClassLoader(new URL[0],getClass().getClassLoader());
            } catch(SecurityException e) {
                throw new InsufficientPermissionDetected(e);
            }

            try {// remove Sun PKCS11 provider if present. See http://wiki.jenkins-ci.org/display/JENKINS/Solaris+Issue+6276483
                Security.removeProvider(""SunPKCS11-Solaris"");
            } catch (SecurityException e) {
                // ignore this error.
            }

            installLogger();

            final FileAndDescription describedHomeDir = getHomeDir(event);
            home = describedHomeDir.file.getAbsoluteFile();
            home.mkdirs();
            System.out.println(""Jenkins home directory: ""+home+"" found at: ""+describedHomeDir.description);

            // check that home exists (as mkdirs could have failed silently), otherwise throw a meaningful error
            if (!home.exists())
                throw new NoHomeDir(home);

            recordBootAttempt(home);

            // make sure that we are using XStream in the ""enhanced"" (JVM-specific) mode
            if(jvm.bestReflectionProvider().getClass()==PureJavaReflectionProvider.class) {
                throw new IncompatibleVMDetected(); // nope
            }

//  JNA is no longer a hard requirement. It's just nice to have. See HUDSON-4820 for more context.
//            // make sure JNA works. this can fail if
//            //    - platform is unsupported
//            //    - JNA is already loaded in another classloader
//            // see http://wiki.jenkins-ci.org/display/JENKINS/JNA+is+already+loaded
//            // TODO: or shall we instead modify Hudson to work gracefully without JNA?
//            try {
//                /*
//                    java.lang.UnsatisfiedLinkError: Native Library /builds/apps/glassfish/domains/hudson-domain/generated/jsp/j2ee-modules/hudson-1.309/loader/com/sun/jna/sunos-sparc/libjnidispatch.so already loaded in another classloader
//                        at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1743)
//                        at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1674)
//                        at java.lang.Runtime.load0(Runtime.java:770)
//                        at java.lang.System.load(System.java:1005)
//                        at com.sun.jna.Native.loadNativeLibraryFromJar(Native.java:746)
//                        at com.sun.jna.Native.loadNativeLibrary(Native.java:680)
//                        at com.sun.jna.Native.<clinit>(Native.java:108)
//                        at hudson.util.jna.GNUCLibrary.<clinit>(GNUCLibrary.java:86)
//                        at hudson.Util.createSymlink(Util.java:970)
//                        at hudson.model.Run.run(Run.java:1174)
//                        at hudson.matrix.MatrixBuild.run(MatrixBuild.java:149)
//                        at hudson.model.ResourceController.execute(ResourceController.java:88)
//                        at hudson.model.Executor.run(Executor.java:123)
//                 */
//                String.valueOf(Native.POINTER_SIZE); // this meaningless operation forces the classloading and initialization
//            } catch (LinkageError e) {
//                if (e.getMessage().contains(""another classloader""))
//                    context.setAttribute(APP,new JNADoublyLoaded(e));
//                else
//                    context.setAttribute(APP,new HudsonFailedToLoad(e));
//            }

            // make sure this is servlet 2.4 container or above
            try {
                ServletResponse.class.getMethod(""setCharacterEncoding"",String.class);
            } catch (NoSuchMethodException e) {
                throw new IncompatibleServletVersionDetected(ServletResponse.class);
            }

            // make sure that we see Ant 1.7
            try {
                FileSet.class.getMethod(""getDirectoryScanner"");
            } catch (NoSuchMethodException e) {
                throw new IncompatibleAntVersionDetected(FileSet.class);
            }

            // make sure AWT is functioning, or else JFreeChart won't even load.
            if(ChartUtil.awtProblemCause!=null) {
                throw new AWTProblem(ChartUtil.awtProblemCause);
            }

            // some containers (in particular Tomcat) doesn't abort a launch
            // even if the temp directory doesn't exist.
            // check that and report an error
            try {
                File f = File.createTempFile(""test"", ""test"");
                f.delete();
            } catch (IOException e) {
                throw new NoTempDir(e);
            }

            // Tomcat breaks XSLT with JDK 5.0 and onward. Check if that's the case, and if so,
            // try to correct it
            try {
                TransformerFactory.newInstance();
                // if this works we are all happy
            } catch (TransformerFactoryConfigurationError x) {
                // no it didn't.
                LOGGER.log(WARNING, ""XSLT not configured correctly. Hudson will try to fix this. See http://issues.apache.org/bugzilla/show_bug.cgi?id=40895 for more details"",x);
                System.setProperty(TransformerFactory.class.getName(),""com.sun.org.apache.xalan.internal.xsltc.trax.TransformerFactoryImpl"");
                try {
                    TransformerFactory.newInstance();
                    LOGGER.info(""XSLT is set to the JAXP RI in JRE"");
                } catch(TransformerFactoryConfigurationError y) {
                    LOGGER.log(SEVERE, ""Failed to correct the problem."");
                }
            }

            installExpressionFactory(event);

            context.setAttribute(APP,new HudsonIsLoading());

            final File _home = home;
            initThread = new Thread(""Jenkins initialization thread"") {
                @Override
                public void run() {
                    boolean success = false;
                    try {
                        Jenkins instance = new Hudson(_home, context);

                        // one last check to make sure everything is in order before we go live
                        if (Thread.interrupted())
                            throw new InterruptedException();

                        context.setAttribute(APP, instance);

                        BootFailure.getBootFailureFile(_home).delete();

                        // at this point we are open for business and serving requests normally
                        LOGGER.info(""Jenkins is fully up and running"");
                        success = true;
                    } catch (Error e) {
                        new HudsonFailedToLoad(e).publish(context,_home);
                        throw e;
                    } catch (Exception e) {
                        new HudsonFailedToLoad(e).publish(context,_home);
                    } finally {
                        Jenkins instance = Jenkins.getInstanceOrNull();
                        if(!success && instance!=null)
                            instance.cleanUp();
                    }
                }
            };
            initThread.start();
        } catch (BootFailure e) {
            e.publish(context, home);
        } catch (Error | RuntimeException e) {
            LOGGER.log(SEVERE, ""Failed to initialize Jenkins"",e);
            throw e;
        }
    }"
"public Matrix predict(Matrix features) {
        return MLLibUtil.toMatrix(network.output(MLLibUtil.toMatrix(features)));
    }"
"public static boolean substringMatch(CharSequence str, int index, CharSequence substring) {
        for (int j = 0; j < substring.length(); j++) {
            int i = index + j;
            if (i >= str.length() || str.charAt(i) != substring.charAt(j)) {
                return false;
            }
        }
        return true;
    }"
"public void asFlatFile(@NonNull File file) throws IOException {
        val fb = asFlatBuffers();
        val offset = fb.position();

        val array = fb.array();

        try (val fos = new FileOutputStream(file); val bos = new BufferedOutputStream(fos); val dos = new DataOutputStream(bos)) {
            dos.write(array, offset, array.length - offset);
        }
    }"
"public static AltsChannelBuilder forAddress(String name, int port) {
    return forTarget(GrpcUtil.authorityFromHostAndPort(name, port));
  }"
"void build()
    {
        _ranks = new int[_units.size()];

        _numOnes = 0;
        for (int i = 0; i < _units.size(); ++i)
        {
            _ranks[i] = _numOnes;
            _numOnes += popCount(_units.get(i));
        }
    }"
"@Override
	public boolean revokeApprovals(Collection<Approval> approvals) {
		boolean success = true;
		for (Approval approval : approvals) {
			Collection<OAuth2AccessToken> tokens = store.findTokensByClientIdAndUserName(approval.getClientId(), approval.getUserId());
			for (OAuth2AccessToken token : tokens) {
				OAuth2Authentication authentication = store.readAuthentication(token);
				if (authentication != null
						&& approval.getClientId().equals(authentication.getOAuth2Request().getClientId())) {
					store.removeAccessToken(token);
				}
			}
		}
		return success;
	}"
"private HttpPrefixFetchFilter getUriPrefixFecthFilter(Object[] customConfigurations) {
		if (customConfigurations != null) {
			for (Object customConfiguration : customConfigurations) {
				if (customConfiguration instanceof HttpPrefixFetchFilter) {
					return (HttpPrefixFetchFilter) customConfiguration;
				}
			}
		}
		return null;
	}"
"public LinkedHashMap<String, String> getTierToBrokerMap()
  {
    return tierToBrokerMap == null ? new LinkedHashMap<>(
        ImmutableMap.of(
            DruidServer.DEFAULT_TIER, defaultBrokerServiceName
        )
    ) : tierToBrokerMap;
  }"
"public void addServerSocket(
      InternalInstrumented<ServerStats> server, InternalInstrumented<SocketStats> socket) {
    ServerSocketMap serverSockets = perServerSockets.get(id(server));
    assert serverSockets != null;
    add(serverSockets, socket);
  }"
"public TableOperation createLimitWithFetch(int fetch, TableOperation child) {
		SortTableOperation previousSort = validateAndGetChildSort(child);

		if (fetch < 0) {
			throw new ValidationException(""Fetch should be greater or equal 0"");
		}

		int offset = Math.max(previousSort.getOffset(), 0);

		return new SortTableOperation(previousSort.getOrder(), previousSort.getChild(), offset, fetch);
	}"
"private void useNextAddressAsNewContactSeedBroker() {
		if (++currentContactSeedBrokerIndex == seedBrokerAddresses.length) {
			currentContactSeedBrokerIndex = 0;
		}

		URL newContactUrl = NetUtils.getCorrectHostnamePort(seedBrokerAddresses[currentContactSeedBrokerIndex]);
		this.consumer = new SimpleConsumer(newContactUrl.getHost(), newContactUrl.getPort(), soTimeout, bufferSize, dummyClientId);
	}"
"public BinaryBitmap rotateCounterClockwise() {
    LuminanceSource newSource = binarizer.getLuminanceSource().rotateCounterClockwise();
    return new BinaryBitmap(binarizer.createBinarizer(newSource));
  }"
"public static void writeJpg(Image image, OutputStream out) throws IORuntimeException {
		write(image, IMAGE_TYPE_JPG, out);
	}"
"public static Field getField(final Class clazz, final String fieldName) {
		Validate.notNull(clazz, ""clazz can't be null"");
		Validate.notEmpty(fieldName, ""fieldName can't be blank"");
		for (Class<?> superClass = clazz; superClass != Object.class; superClass = superClass.getSuperclass()) {
			try {
				Field field = superClass.getDeclaredField(fieldName);
				makeAccessible(field);
				return field;
			} catch (NoSuchFieldException e) {// NOSONAR
				// Field不在当前类定义,继续向上转型
			}
		}
		return null;
	}"
"public static CommandExecutor newInstance(final PostgreSQLCommandPacketType commandPacketType, final PostgreSQLCommandPacket commandPacket, final BackendConnection backendConnection) {
        log.debug(""Execute packet type: {}, value: {}"", commandPacketType, commandPacket);
        switch (commandPacketType) {
            case QUERY:
                return new PostgreSQLComQueryExecutor((PostgreSQLComQueryPacket) commandPacket, backendConnection);
            case PARSE:
                return new PostgreSQLComParseExecutor((PostgreSQLComParsePacket) commandPacket, backendConnection);
            case BIND:
                return new PostgreSQLComBindExecutor((PostgreSQLComBindPacket) commandPacket, backendConnection);
            case DESCRIBE:
                return new PostgreSQLComDescribeExecutor();
            case EXECUTE:
                return new PostgreSQLComExecuteExecutor();
            case SYNC:
                return new PostgreSQLComSyncExecutor();
            case TERMINATE:
                return new PostgreSQLComTerminationExecutor();
            default:
                return new PostgreSQLUnsupportedCommandExecutor();
        }
    }"
"public FlatGraph asFlatGraph(long graphId, ExecutorConfiguration configuration) {
        return FlatGraph.getRootAsFlatGraph(asFlatBuffers(graphId, configuration));
    }"
"protected JComboBox<SessionManagementMethodType> getSessionManagementMethodsComboBox() {
		if (sessionManagementMethodsComboBox == null) {
			Vector<SessionManagementMethodType> methods = new Vector<>(
					extension.getSessionManagementMethodTypes());
			sessionManagementMethodsComboBox = new JComboBox<>(methods);
			sessionManagementMethodsComboBox.setSelectedItem(null);

			// Prepare the listener for the change of selection
			sessionManagementMethodsComboBox.addItemListener(new ItemListener() {

				@Override
				public void itemStateChanged(ItemEvent e) {
					if (e.getStateChange() == ItemEvent.SELECTED) {
						// Prepare the new session management method
						log.debug(""Selected new Session Management type: "" + e.getItem());
						SessionManagementMethodType type = ((SessionManagementMethodType) e.getItem());

						// If no session management method was previously selected or it's a
						// different class, create it now
						if (selectedMethod == null || !type.isTypeForMethod(selectedMethod)) {
							// Create the new session management method
							selectedMethod = type.createSessionManagementMethod(getContextIndex());
						}

						// Show the status panel and configuration button, if needed
						changeMethodConfigPanel(type);
						if (type.hasOptionsPanel())
							shownConfigPanel.bindMethod(selectedMethod);
					}
				}
			});
		}
		return sessionManagementMethodsComboBox;

	}"
"public static <K, V> HashMap<K, V> newHashMapWithCapacity(int expectedSize, float loadFactor) {
		int finalSize = (int) (expectedSize / loadFactor + 1.0F);
		return new HashMap<K, V>(finalSize, loadFactor);
	}"
"@Nullable
  private static Long getValidTargetCompactionSizeBytes(
      @Nullable Long targetCompactionSizeBytes,
      @Nullable Integer maxRowsPerSegment,
      @Nullable UserCompactTuningConfig tuningConfig
  )
  {
    if (targetCompactionSizeBytes != null) {
      Preconditions.checkArgument(
          !hasPartitionConfig(maxRowsPerSegment, tuningConfig),
          ""targetCompactionSizeBytes[%s] cannot be used with maxRowsPerSegment[%s] and maxTotalRows[%s]"",
          targetCompactionSizeBytes,
          maxRowsPerSegment,
          tuningConfig == null ? null : tuningConfig.getMaxTotalRows()
      );
      return targetCompactionSizeBytes;
    } else {
      return hasPartitionConfig(maxRowsPerSegment, tuningConfig) ? null : DEFAULT_TARGET_COMPACTION_SIZE_BYTES;
    }
  }"
"public static void init(String sensitiveWords, char separator, boolean isAsync){
		if(StrUtil.isNotBlank(sensitiveWords)){
			init(StrUtil.split(sensitiveWords, separator), isAsync);
		}
	}"
"@Nullable
  public static Granularity toQueryGranularity(final DruidExpression expression, final ExprMacroTable macroTable)
  {
    final TimestampFloorExprMacro.TimestampFloorExpr expr = asTimestampFloorExpr(expression, macroTable);

    if (expr == null) {
      return null;
    }

    final Expr arg = expr.getArg();
    final Granularity granularity = expr.getGranularity();

    if (ColumnHolder.TIME_COLUMN_NAME.equals(Parser.getIdentifierIfIdentifier(arg))) {
      return granularity;
    } else {
      return null;
    }
  }"
"public static String formatBetween(long betweenMs, BetweenFormater.Level level) {
		return new BetweenFormater(betweenMs, level).format();
	}"
"@SneakyThrows
    protected Http signHttpAuthRequest(final Http request, final String id) {
        request.addParam(""username"", id);
        request.addParam(""factor"", ""auto"");
        request.addParam(""device"", ""auto"");
        request.signRequest(
            duoProperties.getDuoIntegrationKey(),
            duoProperties.getDuoSecretKey());
        return request;
    }"
"public RMatGraph<T> setConstants(float a, float b, float c) {
		Preconditions.checkArgument(a >= 0.0f && b >= 0.0f && c >= 0.0f && a + b + c <= 1.0f,
			""RMat parameters A, B, and C must be non-negative and sum to less than or equal to one"");

		this.a = a;
		this.b = b;
		this.c = c;

		return this;
	}"
"public static String toJSONString(final Props props, final boolean localOnly) {
    final Map<String, String> map = toStringMap(props, localOnly);
    return JSONUtils.toJSON(map);
  }"
"@SuppressWarnings(""unchecked"")
    public <T> Http2StreamChannelBootstrap attr(AttributeKey<T> key, T value) {
        if (key == null) {
            throw new NullPointerException(""key"");
        }
        if (value == null) {
            synchronized (attrs) {
                attrs.remove(key);
            }
        } else {
            synchronized (attrs) {
                attrs.put(key, value);
            }
        }
        return this;
    }"
"public Object invoke(T target, Object... args) throws InvocationTargetException {
    Method m = getMethod(target.getClass());
    if (m == null) {
      throw new AssertionError(""Method "" + methodName + "" not supported for object "" + target);
    }
    try {
      return m.invoke(target, args);
    } catch (IllegalAccessException e) {
      // Method should be public: we checked.
      AssertionError error = new AssertionError(""Unexpectedly could not call: "" + m);
      error.initCause(e);
      throw error;
    }
  }"
"public INDArray reducedBasis(double variance) {
        INDArray vars = Transforms.pow(eigenvalues, -0.5, true);
        double res = vars.sumNumber().doubleValue();
        double total = 0.0;
        int ndims = 0;
        for (int i = 0; i < vars.columns(); i++) {
            ndims++;
            total += vars.getDouble(i);
            if (total / res > variance)
                break;
        }
        INDArray result = Nd4j.create(eigenvectors.rows(), ndims);
        for (int i = 0; i < ndims; i++)
            result.putColumn(i, eigenvectors.getColumn(i));
        return result;
    }"
"public static byte[] correctTypeConversions(ByteVec vec, byte[] requestedTypes) {
    byte[] metadataBytes = VecParquetReader.readFooterAsBytes(vec);
    ParquetMetadata metadata = VecParquetReader.readFooter(metadataBytes, ParquetMetadataConverter.NO_FILTER);
    byte[] roughTypes = roughGuessTypes(metadata.getFileMetaData().getSchema());
    return correctTypeConversions(roughTypes, requestedTypes);
  }"
"SharedSlot allocateSharedSlot(AbstractID groupId){
		if (isAlive()) {
			SharedSlot slot = new SharedSlot(
				getOwner(),
				getTaskManagerLocation(),
				subSlots.size(),
				getTaskManagerGateway(),
				assignmentGroup,
				this,
				groupId);
			subSlots.add(slot);
			return slot;
		}
		else {
			return null;
		}
	}"
"public SslContextBuilder trustManager(File trustCertCollectionFile) {
        try {
            return trustManager(SslContext.toX509Certificates(trustCertCollectionFile));
        } catch (Exception e) {
            throw new IllegalArgumentException(""File does not contain valid certificates: ""
                    + trustCertCollectionFile, e);
        }
    }"
"public LongParameter setMaximumValue(long maximumValue) {
		if (hasMinimumValue) {
			Util.checkParameter(maximumValue >= minimumValue,
				""Maximum value ("" + maximumValue + "") must be greater than or equal to minimum ("" + minimumValue + "")"");
		}

		this.hasMaximumValue = true;
		this.maximumValue = maximumValue;

		return this;
	}"
"public static Font getFont (Font font, int style, Size size) {
		return getFont(font, size).deriveFont(style);
	}"
"public synchronized void fit(MultiDataSetIterator multi) {
        if (flattenedGradients == null) {
            initGradientsView();
        }

        if(!multi.hasNext() && multi.resetSupported()){
            multi.reset();
        }

        for (TrainingListener tl : trainingListeners) {
            tl.onEpochStart(this);
        }

        boolean destructable = false;

        MultiDataSetIterator multiDataSetIterator;
        if (multi.asyncSupported()) {
            multiDataSetIterator = new AsyncMultiDataSetIterator(multi, Math.max(Nd4j.getAffinityManager().getNumberOfDevices() * 2, 2), true);
            destructable = true;
        } else
            multiDataSetIterator = multi;

        long time1 = System.currentTimeMillis();
        while(multiDataSetIterator.hasNext()){
            MultiDataSet mds = multiDataSetIterator.next();
            long time2 = System.currentTimeMillis();
            lastEtlTime.set((time2 - time1));

            fit(mds.getFeatures(),mds.getLabels(), mds.getFeaturesMaskArrays(), mds.getLabelsMaskArrays());
            time1 = System.currentTimeMillis();
        }

        if (destructable)
            ((AsyncMultiDataSetIterator) multiDataSetIterator).shutdown();

        for (TrainingListener tl : trainingListeners) {
            tl.onEpochEnd(this);
        }

        incrementEpochCount();
    }"
"public <T> void addValueCallback(KeyPath keyPath, T property, LottieValueCallback<T> callback) {
    lottieDrawable.addValueCallback(keyPath, property, callback);
  }"
"private static @CheckForNull ResourceBundle getBundle(@Nonnull String baseName, @Nonnull Locale locale, @Nonnull ClassLoader classLoader) {
        try {
            return ResourceBundle.getBundle(baseName, locale, classLoader);
        } catch (MissingResourceException e) {
            // fall through and return null.
            logger.finer(e.getMessage());
        }
        return null;
    }"
"public EpollSocketChannelConfig setTcpCork(boolean tcpCork) {
        try {
            ((EpollSocketChannel) channel).socket.setTcpCork(tcpCork);
            return this;
        } catch (IOException e) {
            throw new ChannelException(e);
        }
    }"
"@Override
    public WebSocketFrame readChunk(ByteBufAllocator allocator) throws Exception {
        ByteBuf buf = input.readChunk(allocator);
        if (buf == null) {
            return null;
        }
        return new ContinuationWebSocketFrame(input.isEndOfInput(), rsv, buf);
    }"
"@View(name = ""size"", map = ""function(doc) { if (doc.service) { emit(doc, doc._id) }}"", reduce = ""_count"")
    public int size() {
        val r = db.queryView(createQuery(""size""));
        LOGGER.trace(""r.isEmpty [{}]"", r.isEmpty());
        LOGGER.trace(""r.getRows [{}]"", r.getRows());
        if (r.isEmpty()) {
            return 0;
        }

        return r.getRows().get(0).getValueAsInt();
    }"
"public void preApply(Trainable layer, Gradient gradient, int iteration) {

        if (layer.getConfig() == null || layer.numParams() == 0) {
            //Layer does not have parameters -> no gradient
            return;
        }

        GradientNormalization normalization = layer.getConfig().getGradientNormalization();
        if (normalization == null || normalization == GradientNormalization.None)
            return; //no op

        final double threshold = layer.getConfig().getGradientNormalizationThreshold();
        INDArray layerGradientView = layer.getGradientsViewArray();

        switch (normalization) {
            case RenormalizeL2PerLayer:
                if (layerGradientView != null) {
                    double l2 = layerGradientView.norm2Number().doubleValue();
                    if (l2 == 0.0)
                        l2 = 1e-5;  //Avoid 0/0 -> NaN
                    layerGradientView.divi(l2);
                }
                break;
            case RenormalizeL2PerParamType:
                for (INDArray g : gradient.gradientForVariable().values()) {
                    double l2 = Nd4j.getExecutioner().execAndReturn(new Norm2(g)).getFinalResult().doubleValue();
                    if (l2 == 0.0)
                        l2 = 1e-5;  //Avoid 0/0 -> NaN
                    g.divi(l2);
                }
                break;
            case ClipElementWiseAbsoluteValue:
                if (layerGradientView != null) {
                    CustomOp op = DynamicCustomOp.builder(""clipbyvalue"")
                            .addInputs(layerGradientView)
                            .callInplace(true)
                            .addFloatingPointArguments(-threshold, threshold)
                            .build();
                    Nd4j.getExecutioner().exec(op);
                }
                break;
            case ClipL2PerLayer:
                if (layerGradientView != null) {
                    double layerL2 = layerGradientView.norm2Number().doubleValue();
                    if (layerL2 > threshold) {
                        double scalingFactor = threshold / layerL2; // g = g / l2 * threshold ->
                        layerGradientView.muli(scalingFactor);
                    }
                }
                break;
            case ClipL2PerParamType:
                for (INDArray g : gradient.gradientForVariable().values()) {
                    double l2 = g.norm2Number().doubleValue();
                    if (l2 > threshold) {
                        double scalingFactor = l2 / threshold;
                        g.divi(scalingFactor);
                    }
                }
                break;
            default:
                throw new RuntimeException(
                                ""Unknown (or not implemented) gradient normalization strategy: "" + normalization);
        }
    }"
"public void setIndexForItems(final Map<String, Integer> columnLabelIndexMap) {
        setIndexForAggregationItem(columnLabelIndexMap);
        setIndexForOrderItem(columnLabelIndexMap, orderByItems);
        setIndexForOrderItem(columnLabelIndexMap, groupByItems);
    }"
"public void unmaximiseComponent() {
        if (maximisedComponent == null) {
            return;
        }

        container.remove(maximisedComponent);
        container.add(containerChild);
        parentMaximisedComponent.add(maximisedComponent);
        container.validate();

        containerChild = null;
        parentMaximisedComponent = null;
        maximisedComponent = null;
    }"
"protected void createLogoutViewState(final Flow flow) {
        val logoutView = createEndState(flow, CasWebflowConstants.STATE_ID_LOGOUT_VIEW, ""casLogoutView"");
        logoutView.getEntryActionList().add(createEvaluateAction(CasWebflowConstants.ACTION_ID_LOGOUT_VIEW_SETUP));
    }"
"public static Vec categoricalDomainsToNumeric(final Vec src) {
    if( !src.isCategorical() ) throw new H2OIllegalArgumentException(""categoricalToNumeric() conversion only works on categorical columns"");
    // check if the 1st lvl of the domain can be parsed as int
    return new MRTask() {
        @Override public void map(Chunk c) {
          for (int i=0;i<c._len;++i)
            if( !c.isNA(i) )
              c.set(i, Integer.parseInt(src.domain()[(int)c.at8(i)]));
        }
      }.doAll(Vec.T_NUM, src).outputFrame().anyVec();
  }"
"public static String shaBase64(final String salt, final String data) {
        return shaBase64(salt, data, null);
    }"
"public void prepare(HiveConf sqlOperationConf) throws HiveSQLException {
    setState(OperationState.RUNNING);

    try {
      driver = new Driver(sqlOperationConf, getParentSession().getUserName());

      // set the operation handle information in Driver, so that thrift API users
      // can use the operation handle they receive, to lookup query information in
      // Yarn ATS
      String guid64 = Base64.encodeBase64URLSafeString(getHandle().getHandleIdentifier()
          .toTHandleIdentifier().getGuid()).trim();
      driver.setOperationId(guid64);

      // In Hive server mode, we are not able to retry in the FetchTask
      // case, when calling fetch queries since execute() has returned.
      // For now, we disable the test attempts.
      driver.setTryCount(Integer.MAX_VALUE);

      String subStatement = new VariableSubstitution().substitute(sqlOperationConf, statement);
      response = driver.compileAndRespond(subStatement);
      if (0 != response.getResponseCode()) {
        throw toSQLException(""Error while compiling statement"", response);
      }

      mResultSchema = driver.getSchema();

      // hasResultSet should be true only if the query has a FetchTask
      // ""explain"" is an exception for now
      if(driver.getPlan().getFetchTask() != null) {
        //Schema has to be set
        if (mResultSchema == null || !mResultSchema.isSetFieldSchemas()) {
          throw new HiveSQLException(""Error compiling query: Schema and FieldSchema "" +
              ""should be set when query plan has a FetchTask"");
        }
        resultSchema = new TableSchema(mResultSchema);
        setHasResultSet(true);
      } else {
        setHasResultSet(false);
      }
      // Set hasResultSet true if the plan has ExplainTask
      // TODO explain should use a FetchTask for reading
      for (Task<? extends Serializable> task: driver.getPlan().getRootTasks()) {
        if (task.getClass() == ExplainTask.class) {
          resultSchema = new TableSchema(mResultSchema);
          setHasResultSet(true);
          break;
        }
      }
    } catch (HiveSQLException e) {
      setState(OperationState.ERROR);
      throw e;
    } catch (Exception e) {
      setState(OperationState.ERROR);
      throw new HiveSQLException(""Error running query: "" + e.toString(), e);
    }
  }"
"public static void rotate(File imageFile, int degree, File outFile) throws IORuntimeException {
		rotate(read(imageFile), degree, outFile);
	}"
"public void set(T value) {
        try {
            lock.writeLock().lock();

            this.value = value;
        } finally {
            lock.writeLock().unlock();
        }
    }"
"private PipelineDO modelToDo(Pipeline pipeline) {
        PipelineDO pipelineDO = new PipelineDO();

        try {
            pipelineDO.setId(pipeline.getId());
            pipelineDO.setName(pipeline.getName());
            pipelineDO.setParameters(pipeline.getParameters());
            pipelineDO.setDescription(pipeline.getDescription());
            pipelineDO.setChannelId(pipeline.getChannelId());
            pipelineDO.setGmtCreate(pipeline.getGmtCreate());
            pipelineDO.setGmtModified(pipeline.getGmtModified());

        } catch (Exception e) {
            logger.error(""ERROR ## change the pipeline Model to Do has an exception"");
            throw new ManagerException(e);
        }

        return pipelineDO;
    }"
"public void doPng(StaplerRequest req, StaplerResponse rsp) throws IOException {
        if (req.checkIfModified(timestamp, rsp)) return;

        try {
            BufferedImage image = render(req,null);
            rsp.setContentType(""image/png"");
            ServletOutputStream os = rsp.getOutputStream();
            ImageIO.write(image, ""PNG"", os);
            os.close();
        } catch(Error e) {
            /* OpenJDK on ARM produces an error like this in case of headless error
                Caused by: java.lang.Error: Probable fatal error:No fonts found.
                        at sun.font.FontManager.getDefaultPhysicalFont(FontManager.java:1088)
                        at sun.font.FontManager.initialiseDeferredFont(FontManager.java:967)
                        at sun.font.CompositeFont.doDeferredInitialisation(CompositeFont.java:254)
                        at sun.font.CompositeFont.getSlotFont(CompositeFont.java:334)
                        at sun.font.CompositeStrike.getStrikeForSlot(CompositeStrike.java:77)
                        at sun.font.CompositeStrike.getFontMetrics(CompositeStrike.java:93)
                        at sun.font.Font2D.getFontMetrics(Font2D.java:387)
                        at java.awt.Font.defaultLineMetrics(Font.java:2082)
                        at java.awt.Font.getLineMetrics(Font.java:2152)
                        at org.jfree.chart.axis.NumberAxis.estimateMaximumTickLabelHeight(NumberAxis.java:974)
                        at org.jfree.chart.axis.NumberAxis.selectVerticalAutoTickUnit(NumberAxis.java:1104)
                        at org.jfree.chart.axis.NumberAxis.selectAutoTickUnit(NumberAxis.java:1048)
                        at org.jfree.chart.axis.NumberAxis.refreshTicksVertical(NumberAxis.java:1249)
                        at org.jfree.chart.axis.NumberAxis.refreshTicks(NumberAxis.java:1149)
                        at org.jfree.chart.axis.ValueAxis.reserveSpace(ValueAxis.java:788)
                        at org.jfree.chart.plot.CategoryPlot.calculateRangeAxisSpace(CategoryPlot.java:2650)
                        at org.jfree.chart.plot.CategoryPlot.calculateAxisSpace(CategoryPlot.java:2669)
                        at org.jfree.chart.plot.CategoryPlot.draw(CategoryPlot.java:2716)
                        at org.jfree.chart.JFreeChart.draw(JFreeChart.java:1222)
                        at org.jfree.chart.JFreeChart.createBufferedImage(JFreeChart.java:1396)
                        at org.jfree.chart.JFreeChart.createBufferedImage(JFreeChart.java:1376)
                        at org.jfree.chart.JFreeChart.createBufferedImage(JFreeChart.java:1361)
                        at hudson.util.ChartUtil.generateGraph(ChartUtil.java:116)
                        at hudson.util.ChartUtil.generateGraph(ChartUtil.java:99)
                        at hudson.tasks.test.AbstractTestResultAction.doPng(AbstractTestResultAction.java:196)
                        at hudson.tasks.test.TestResultProjectAction.doTrend(TestResultProjectAction.java:97)
                        ... 37 more
             */
            if(e.getMessage().contains(""Probable fatal error:No fonts found"")) {
                rsp.sendRedirect2(req.getContextPath()+""/images/headless.png"");
                return;
            }
            throw e; // otherwise let the caller deal with it
        } catch(HeadlessException e) {
            // not available. send out error message
            rsp.sendRedirect2(req.getContextPath()+""/images/headless.png"");
        }
    }"
"private void notifyConnectMessage(HttpMessage connectMessage) {
        for (ConnectRequestProxyListener listener : parentServer.getConnectRequestProxyListeners()) {
            try {
                listener.receivedConnectRequest(connectMessage);
            } catch (Exception e) {
                log.error(""An error occurred while notifying listener:"", e);
            }
        }
    }"
"public boolean add(final float k) {
		int intKey = Float.floatToIntBits(k);
		if (intKey == 0) {
			if (this.containsZero) {
				return false;
			}

			this.containsZero = true;
		} else {
			float[] key = this.key;
			int pos;
			int curr;
			if ((curr = Float.floatToIntBits(key[pos = MurmurHashUtil.fmix(intKey) & this.mask])) != 0) {
				if (curr == intKey) {
					return false;
				}

				while ((curr = Float.floatToIntBits(key[pos = pos + 1 & this.mask])) != 0) {
					if (curr == intKey) {
						return false;
					}
				}
			}

			key[pos] = k;
		}

		if (this.size++ >= this.maxFill) {
			this.rehash(OptimizableHashSet.arraySize(this.size + 1, this.f));
		}

		return true;
	}"
"private void permitSem() {
        if (channelStatus.isStart()) {
            channelMutex.set(true);
            logger.debug(""channel status is ok!"");
        } else {
            channelMutex.set(false);
            logger.debug(""channel status is fail!"");
        }

        boolean permit = isPermit(false);
        if (permit == false) {
            if (logger.isDebugEnabled()) {
                logger.debug(""Permit is fail!"");
            }
            // 如果未授权，则设置信号量为0
            permitMutex.set(false);
        } else {
            // 信号量+1
            if (logger.isDebugEnabled()) {
                logger.debug(""Permit is Ok!"");
            }
            permitMutex.set(true);
        }

        processChanged(permit);// 通知下变化
    }"
"public static Tuple<String, String> split(String strColumn, String pattern, int index, String valueName) {
        String name = ""split_"" + random();
        String script = """";
        if (valueName == null) {
            script = ""def "" + name + "" = doc['"" + strColumn + ""'].value.split('"" + pattern + ""')["" + index + ""]"";

        } else {
            script = ""; def "" + name + "" = "" + valueName + "".split('"" + pattern + ""')["" + index + ""]"";
        }
        return new Tuple<>(name, script);
    }"
"@Override
  public RangeSet<String> getDimensionRangeSet(String dimension)
  {
    if (field instanceof AndDimFilter) {
      List<DimFilter> fields = ((AndDimFilter) field).getFields();
      return new OrDimFilter(Lists.transform(fields, NotDimFilter::new)).getDimensionRangeSet(dimension);
    }
    if (field instanceof OrDimFilter) {
      List<DimFilter> fields = ((OrDimFilter) field).getFields();
      return new AndDimFilter(Lists.transform(fields, NotDimFilter::new)).getDimensionRangeSet(dimension);
    }
    if (field instanceof NotDimFilter) {
      return ((NotDimFilter) field).getField().getDimensionRangeSet(dimension);
    }
    RangeSet<String> rangeSet = field.getDimensionRangeSet(dimension);
    return rangeSet == null ? null : rangeSet.complement();
  }"
"public void addApiImplementor(ApiImplementor apiImplementor) {
        if (apiImplementor == null) {
            throw new IllegalArgumentException(""Parameter apiImplementor must not be null."");
        }

        if (apiImplementors == null) {
            apiImplementors = new ArrayList<>();
        }
        apiImplementors.add(apiImplementor);
    }"
"public void loadBigData(@Nullable PermanentBlobService blobService)
			throws IOException, ClassNotFoundException {

		// re-integrate offloaded job info from blob
		// here, if this fails, we need to throw the exception as there is no backup path anymore
		if (serializedJobInformation instanceof Offloaded) {
			PermanentBlobKey jobInfoKey = ((Offloaded<JobInformation>) serializedJobInformation).serializedValueKey;

			Preconditions.checkNotNull(blobService);

			final File dataFile = blobService.getFile(jobId, jobInfoKey);
			// NOTE: Do not delete the job info BLOB since it may be needed again during recovery.
			//       (it is deleted automatically on the BLOB server and cache when the job
			//       enters a terminal state)
			SerializedValue<JobInformation> serializedValue =
				SerializedValue.fromBytes(FileUtils.readAllBytes(dataFile.toPath()));
			serializedJobInformation = new NonOffloaded<>(serializedValue);
		}

		// re-integrate offloaded task info from blob
		if (serializedTaskInformation instanceof Offloaded) {
			PermanentBlobKey taskInfoKey = ((Offloaded<TaskInformation>) serializedTaskInformation).serializedValueKey;

			Preconditions.checkNotNull(blobService);

			final File dataFile = blobService.getFile(jobId, taskInfoKey);
			// NOTE: Do not delete the task info BLOB since it may be needed again during recovery.
			//       (it is deleted automatically on the BLOB server and cache when the job
			//       enters a terminal state)
			SerializedValue<TaskInformation> serializedValue =
				SerializedValue.fromBytes(FileUtils.readAllBytes(dataFile.toPath()));
			serializedTaskInformation = new NonOffloaded<>(serializedValue);
		}

		// make sure that the serialized job and task information fields are filled
		Preconditions.checkNotNull(serializedJobInformation);
		Preconditions.checkNotNull(serializedTaskInformation);
	}"
"protected void setTabScrollable(String tabLabel, boolean scrollable) {
		JPanel tabPanel = this.tabNameMap.get(tabLabel);
		if (tabPanel == null) {
			return;
		}

		if (scrollable) {
			if (isTabScrollable(tabPanel)) {
				return;
			}

			String title = Constant.messages.getString(tabLabel);
			int tabIndex = tabbedPane.indexOfTab(title);
			boolean selected = tabbedPane.getSelectedIndex() == tabIndex;

			JScrollPane scrollPane = createTabScrollable(tabLabel, tabPanel);
			if (scrollPane == null) {
				return;
			}
			panelToScrollPaneMap.put(tabPanel, scrollPane);

			if (tabIndex == -1) {
				return;
			}

			tabbedPane.insertTab(title, null, scrollPane, null, tabIndex);
			if (selected) {
				tabbedPane.setSelectedIndex(tabIndex);
			}
			return;
		}

		if (!isTabScrollable(tabPanel)) {
			return;
		}

		String title = Constant.messages.getString(tabLabel);
		int tabIndex = tabbedPane.indexOfTab(title);
		tabbedPane.insertTab(title, null, tabPanel, null, tabIndex);
		tabbedPane.removeTabAt(tabIndex + 1);
		panelToScrollPaneMap.remove(tabPanel);
	}"
"public static OpPredicate opNameEquals(final String opName){
        return new OpPredicate() {
            @Override
            public boolean matches(SameDiff sameDiff, DifferentialFunction function) {
                return function.opName().equals(opName);
            }
        };
    }"
"public Comparable<?> generateKey(final String logicTableName) {
        Optional<TableRule> tableRule = findTableRule(logicTableName);
        if (!tableRule.isPresent()) {
            throw new ShardingConfigurationException(""Cannot find strategy for generate keys."");
        }
        ShardingKeyGenerator shardingKeyGenerator = null == tableRule.get().getShardingKeyGenerator() ? defaultShardingKeyGenerator : tableRule.get().getShardingKeyGenerator();
        return shardingKeyGenerator.generateKey();
    }"
"@Override
	public void close() {

		synchronized (lock) {

			closed = true;

			while (leaseCount > 0) {

				try {
					lock.wait();
				} catch (InterruptedException ignore) {
					// Even on interruption, we cannot terminate the loop until all open leases are closed.
				}
			}
		}
	}"
"public static <T extends CharSequence> T validateGeneralWithChinese(T value, String errorMsg) throws ValidateException {
		if (false == isGeneralWithChinese(value)) {
			throw new ValidateException(errorMsg);
		}
		return value;
	}"
"public static void assertOpenActiveAndCurrent(@NonNull String ws, @NonNull String errorMsg) throws ND4JWorkspaceException {
        if (!Nd4j.getWorkspaceManager().checkIfWorkspaceExistsAndActive(ws)) {
            throw new ND4JWorkspaceException(errorMsg + "" - workspace is not open and active"");
        }
        MemoryWorkspace currWs = Nd4j.getMemoryManager().getCurrentWorkspace();
        if (currWs == null || !ws.equals(currWs.getId())) {
            throw new ND4JWorkspaceException(errorMsg + "" - not the current workspace (current workspace: ""
                    + (currWs == null ? null : currWs.getId()));
        }
    }"
"private static void getContainedGenericTypes(CompositeType<?> typeInfo, List<GenericTypeInfo<?>> target) {
		for (int i = 0; i < typeInfo.getArity(); i++) {
			TypeInformation<?> type = typeInfo.getTypeAt(i);
			if (type instanceof CompositeType) {
				getContainedGenericTypes((CompositeType<?>) type, target);
			} else if (type instanceof GenericTypeInfo) {
				if (!target.contains(type)) {
					target.add((GenericTypeInfo<?>) type);
				}
			}
		}
	}"
"@Override protected double score1(Chunk[] chks, double weight, double offset, double[/*nclass*/] fs, int row) {
    return score1static(chks, idx_tree(0), offset, fs, row, new Distribution(_parms), _nclass);
  }"
"public SQLExpression parse(final SQLStatement sqlStatement) {
        int beginPosition = lexerEngine.getCurrentToken().getEndPosition();
        SQLExpression result = parseExpression(sqlStatement);
        if (result instanceof SQLPropertyExpression) {
            setTableToken(sqlStatement, beginPosition, (SQLPropertyExpression) result);
        }
        return result;
    }"
"public SDVariable convertToVariable(@NonNull SDVariable constant) {
        Preconditions.checkState(constant.dataType().isFPType(), ""Only floating point SDVariables can be converted to variables,"" +
                "" datatype of %s is %s"", constant.getVarName(), constant.dataType());
        convertToVariables(Collections.singletonList(constant));
        return constant;
    }"
"@Override
    public INDArray toDense() {
        // TODO support view conversion
        INDArray result = Nd4j.zeros(shape());

        switch (data().dataType()) {
            case DOUBLE:
                for (int i = 0; i < length; i++) {
                    int[] idx = getUnderlyingIndicesOf(i).asInt();
                    double value = values.getDouble(i);
                    result.putScalar(idx, value);
                }
                break;
            case FLOAT:
                for (int i = 0; i < length; i++) {
                    int[] idx = getUnderlyingIndicesOf(i).asInt();
                    float value = values.getFloat(i);
                    result.putScalar(idx, value);
                }
                break;
            default:
                throw new UnsupportedOperationException();
        }
        return result;
    }"
"@SneakyThrows
    protected Ticket encodeTicket(final Ticket ticket) {
        if (!isCipherExecutorEnabled()) {
            LOGGER.trace(MESSAGE);
            return ticket;
        }
        if (ticket == null) {
            LOGGER.debug(""Ticket passed is null and cannot be encoded"");
            return null;
        }
        LOGGER.debug(""Encoding ticket [{}]"", ticket);
        val encodedTicketObject = SerializationUtils.serializeAndEncodeObject(this.cipherExecutor, ticket);
        val encodedTicketId = encodeTicketId(ticket.getId());
        val encodedTicket = new EncodedTicket(encodedTicketId, ByteSource.wrap(encodedTicketObject).read());
        LOGGER.debug(""Created encoded ticket [{}]"", encodedTicket);
        return encodedTicket;
    }"
"public static void writeToPath(BitMatrix matrix, String format, Path file, MatrixToImageConfig config)
      throws IOException {
    BufferedImage image = toBufferedImage(matrix, config);
    if (!ImageIO.write(image, format, file.toFile())) {
      throw new IOException(""Could not write an image of format "" + format + "" to "" + file);
    }
  }"
"@SneakyThrows
    public static String decryptJwtValue(final Key secretKeyEncryptionKey, final String value) {
        val jwe = new JsonWebEncryption();
        jwe.setKey(secretKeyEncryptionKey);
        jwe.setCompactSerialization(value);
        LOGGER.trace(""Decrypting value..."");
        try {
            return jwe.getPayload();
        } catch (final JoseException e) {
            if (LOGGER.isTraceEnabled()) {
                throw new DecryptionException(e);
            }
            throw new DecryptionException();
        }
    }"
"protected Collection<Pattern> createPatternForMappedAttribute(final String attributeName) {
        val matchingPattern = patterns.get(attributeName).toString();
        val pattern = RegexUtils.createPattern(matchingPattern, this.caseInsensitive ? Pattern.CASE_INSENSITIVE : 0);
        LOGGER.debug(""Created pattern for mapped attribute filter [{}]"", pattern.pattern());
        return CollectionUtils.wrap(pattern);
    }"
"public Alert newInstance() {
		Alert item = new Alert(this.pluginId);
		item.setRiskConfidence(this.risk, this.confidence);
		item.setName(this.name);
		item.setDetail(this.description, this.uri, this.param, this.attack, this.otherInfo, this.solution, this.reference, this.historyRef);
		item.setSource(this.source);
		return item;
	}"
"public static Type getTypeHierarchy(List<Type> typeHierarchy, Type t, Class<?> stopAtClass) {
		while (!(isClassType(t) && typeToClass(t).equals(stopAtClass))) {
			typeHierarchy.add(t);
			t = typeToClass(t).getGenericSuperclass();

			if (t == null) {
				break;
			}
		}
		return t;
	}"
"public static LogFactory set(Class<? extends LogFactory> logFactoryClass) {
		try {
			return set(logFactoryClass.newInstance());
		} catch (Exception e) {
			throw new IllegalArgumentException(""Can not instance LogFactory class!"", e);
		}
	}"
"public List<ProcessDefinition> executeList(CommandContext commandContext, Map<String, Object> parameterMap, int firstResult, int maxResults) {
    return commandContext.getProcessDefinitionEntityManager().findProcessDefinitionsByNativeQuery(parameterMap, firstResult, maxResults);
  }"
"public static Map<String, Object> beanToMap(Object bean, boolean isToUnderlineCase, boolean ignoreNullValue) {
		return beanToMap(bean, new LinkedHashMap<String, Object>(), isToUnderlineCase, ignoreNullValue);
	}"
"@Nonnull
    @Restricted(NoExternalUse.class)
    @SuppressWarnings(""unused"") // invoked from stapler view
    public List<View> sort(@Nonnull List<? extends View> views) {
        List<View> result = new ArrayList<>(views);
        result.sort(new Comparator<View>() {
            @Override
            public int compare(View o1, View o2) {
                return o1.getDisplayName().compareTo(o2.getDisplayName());
            }
        });
        return result;
    }"
"public DefaultTicketFactory addTicketFactory(final @NonNull Class<? extends Ticket> ticketClass, final @NonNull TicketFactory factory) {
        this.factoryMap.put(ticketClass.getCanonicalName(), factory);
        return this;
    }"
"private void flushNewPartitions() {
		LOG.info(""Flushing new partitions"");
		TransactionalRequestResult result = enqueueNewPartitions();
		Object sender = getValue(kafkaProducer, ""sender"");
		invoke(sender, ""wakeup"");
		result.await();
	}"
"@Override
	public boolean upload(String path, File file) {
		Assert.notNull(file, ""file to upload is null !"");
		return upload(path, file.getName(), file);
	}"
"private static Pair<List<DimensionSpec>, List<DimensionSpec>> partitionDimensionList(
      StorageAdapter adapter,
      List<DimensionSpec> dimensions
  )
  {
    final List<DimensionSpec> bitmapDims = new ArrayList<>();
    final List<DimensionSpec> nonBitmapDims = new ArrayList<>();
    final List<DimensionSpec> dimsToSearch = getDimsToSearch(
        adapter.getAvailableDimensions(),
        dimensions
    );

    for (DimensionSpec spec : dimsToSearch) {
      ColumnCapabilities capabilities = adapter.getColumnCapabilities(spec.getDimension());
      if (capabilities == null) {
        continue;
      }

      if (capabilities.hasBitmapIndexes()) {
        bitmapDims.add(spec);
      } else {
        nonBitmapDims.add(spec);
      }
    }

    return new Pair<>(bitmapDims, nonBitmapDims);
  }"
"private static void setConf(String varname, String key, String varvalue, boolean register)
          throws IllegalArgumentException {
    HiveConf conf = SessionState.get().getConf();
    String value = new VariableSubstitution().substitute(conf, varvalue);
    if (conf.getBoolVar(HiveConf.ConfVars.HIVECONFVALIDATION)) {
      HiveConf.ConfVars confVars = HiveConf.getConfVars(key);
      if (confVars != null) {
        if (!confVars.isType(value)) {
          StringBuilder message = new StringBuilder();
          message.append(""'SET "").append(varname).append('=').append(varvalue);
          message.append(""' FAILED because "").append(key).append("" expects "");
          message.append(confVars.typeString()).append("" type value."");
          throw new IllegalArgumentException(message.toString());
        }
        String fail = confVars.validate(value);
        if (fail != null) {
          StringBuilder message = new StringBuilder();
          message.append(""'SET "").append(varname).append('=').append(varvalue);
          message.append(""' FAILED in validation : "").append(fail).append('.');
          throw new IllegalArgumentException(message.toString());
        }
      } else if (key.startsWith(""hive."")) {
        throw new IllegalArgumentException(""hive configuration "" + key + "" does not exists."");
      }
    }
    conf.verifyAndSet(key, value);
    if (register) {
      SessionState.get().getOverriddenConfigurations().put(key, value);
    }
  }"
"@SuppressWarnings(""deprecation"")
    public final void doBuild(StaplerRequest req, StaplerResponse rsp, @QueryParameter TimeDuration delay) throws IOException, ServletException {
        if (delay == null) {
            delay=new TimeDuration(TimeUnit.MILLISECONDS.convert(asJob().getQuietPeriod(), TimeUnit.SECONDS));
        }

        if (!asJob().isBuildable()) {
            throw HttpResponses.error(SC_CONFLICT, new IOException(asJob().getFullName() + "" is not buildable""));
        }

        // if a build is parameterized, let that take over
        ParametersDefinitionProperty pp = asJob().getProperty(ParametersDefinitionProperty.class);
        if (pp != null && !req.getMethod().equals(""POST"")) {
            // show the parameter entry form.
            req.getView(pp, ""index.jelly"").forward(req, rsp);
            return;
        }

        hudson.model.BuildAuthorizationToken.checkPermission(asJob(), asJob().getAuthToken(), req, rsp);

        if (pp != null) {
            pp._doBuild(req, rsp, delay);
            return;
        }


        Queue.Item item = Jenkins.getInstance().getQueue().schedule2(asJob(), delay.getTimeInSeconds(), getBuildCause(asJob(), req)).getItem();
        if (item != null) {
            rsp.sendRedirect(SC_CREATED, req.getContextPath() + '/' + item.getUrl());
        } else {
            rsp.sendRedirect(""."");
        }
    }"
"public static Method getMethod(Class clazz, String methodName, Class... argsType) {
        try {
            return clazz.getMethod(methodName, argsType);
        } catch (NoSuchMethodException e) {
            throw new SofaRpcRuntimeException(e.getMessage(), e);
        }
    }"
"public static Channel openChannel(Session session, ChannelType channelType) {
		final Channel channel = createChannel(session, channelType);
		try {
			channel.connect();
		} catch (JSchException e) {
			throw new JschRuntimeException(e);
		}
		return channel;
	}"
"public void addOutgoingConnection(DagConnection connection) {
		if (this.outgoingConnections == null) {
			this.outgoingConnections = new ArrayList<DagConnection>();
		} else {
			if (this.outgoingConnections.size() == 64) {
				throw new CompilerException(""Cannot currently handle nodes with more than 64 outputs."");
			}
		}

		this.outgoingConnections.add(connection);
	}"
"protected Map<String, List<Object>> getReleasedByDefaultAttributes(final Principal p, final Map<String, List<Object>> attributes) {
        val ctx = ApplicationContextProvider.getApplicationContext();
        if (ctx != null) {
            LOGGER.trace(""Located application context. Retrieving default attributes for release, if any"");
            val props = ctx.getAutowireCapableBeanFactory().getBean(CasConfigurationProperties.class);
            val defaultAttrs = props.getAuthn().getAttributeRepository().getDefaultAttributesToRelease();
            LOGGER.debug(""Default attributes for release are: [{}]"", defaultAttrs);
            val defaultAttributesToRelease = new TreeMap<String, List<Object>>(String.CASE_INSENSITIVE_ORDER);
            defaultAttrs.forEach(key -> {
                if (attributes.containsKey(key)) {
                    LOGGER.debug(""Found and added default attribute for release: [{}]"", key);
                    defaultAttributesToRelease.put(key, attributes.get(key));
                }
            });
            return defaultAttributesToRelease;
        }
        return new TreeMap<>();
    }"
"@SuppressWarnings(""unchecked"")
	public static <T> Class<T> loadClass(String className, boolean isInitialized) {
		return (Class<T>) ClassLoaderUtil.loadClass(className, isInitialized);
	}"
"public EtlEventData await(Long pipelineId) throws InterruptedException {
        Assert.notNull(pipelineId);
        PermitMonitor permitMonitor = ArbitrateFactory.getInstance(pipelineId, PermitMonitor.class);
        permitMonitor.waitForPermit();// 阻塞等待授权

        ExtractStageListener extractStageListener = ArbitrateFactory.getInstance(pipelineId, ExtractStageListener.class);
        Long processId = extractStageListener.waitForProcess(); // 符合条件的processId

        ChannelStatus status = permitMonitor.getChannelPermit();
        if (status.isStart()) {// 即时查询一下当前的状态，状态随时可能会变
            // 根据pipelineId+processId构造对应的path
            String path = StagePathUtils.getSelectStage(pipelineId, processId);

            try {
                byte[] data = zookeeper.readData(path);
                EtlEventData eventData = JsonUtils.unmarshalFromByte(data, EtlEventData.class);

                Node node = LoadBalanceFactory.getNextTransformNode(pipelineId);// 获取下一个处理节点信息
                if (node == null) {// 没有后端节点
                    // TerminEventData termin = new TerminEventData();
                    // termin.setPipelineId(pipelineId);
                    // termin.setType(TerminType.ROLLBACK);
                    // termin.setCode(""no_node"");
                    // termin.setDesc(MessageFormat.format(""pipeline[{}] extract stage has no node!"", pipelineId));
                    // terminEvent.single(termin);
                    throw new ArbitrateException(""Extract_single"", ""no next node"");
                } else {
                    eventData.setNextNid(node.getId());
                    return eventData;// 只有这一条路返回
                }
            } catch (ZkNoNodeException e) {
                logger.error(""pipeline[{}] processId[{}] is invalid , retry again"", pipelineId, processId);
                return await(pipelineId);// /出现节点不存在，说明出现了error情况,递归调用重新获取一次
            } catch (ZkException e) {
                throw new ArbitrateException(""Extract_await"", e.getMessage(), e);
            }
        } else {
            logger.warn(""pipelineId[{}] extract ignore processId[{}] by status[{}]"", new Object[] { pipelineId,
                    processId, status });
                    
            // 释放下processId，因为load是等待processId最小值完成Tranform才继续，如果这里不释放，会一直卡死等待
            String path = StagePathUtils.getProcess(pipelineId, processId);
            zookeeper.delete(path);
            return await(pipelineId);// 递归调用
        }

    }"
"protected Set<String> getAccessTokenDependencies(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) {
    Set<String> deps = new TreeSet<String>();

    if (getObjectDefinitionSource() != null) {
      FilterInvocation invocation = new FilterInvocation(request, response, filterChain);
      Collection<ConfigAttribute> attributes = getObjectDefinitionSource().getAttributes(invocation);
      if (attributes != null) {
        for (ConfigAttribute attribute : attributes) {
          deps.add(attribute.getAttribute());
        }
      }
    }
    return deps;
  }"
"public Collection<String> getSubKeys() {
        WINBASE.FILETIME lpftLastWriteTime;
        TreeSet<String> subKeys = new TreeSet<>();
        char[] lpName = new char[256];
        IntByReference lpcName = new IntByReference(256);
        lpftLastWriteTime = new WINBASE.FILETIME();
        int dwIndex = 0;

        while (Advapi32.INSTANCE.RegEnumKeyEx(handle, dwIndex, lpName, lpcName, null,
                null, null, lpftLastWriteTime) == WINERROR.ERROR_SUCCESS) {
            subKeys.add(new String(lpName, 0, lpcName.getValue()));
            lpcName.setValue(256);
            dwIndex++;
        }

        return subKeys;
    }"
"public static String extName(File file) {
		if (null == file) {
			return null;
		}
		if (file.isDirectory()) {
			return null;
		}
		return extName(file.getName());
	}"
"@Override
	protected String[] getRow(String[] resultRow) {
		return Arrays.copyOfRange(resultRow, 1, resultRow.length);
	}"
"@Override
  @ExperimentalApi(""https://github.com/grpc/grpc-java/issues/2222"")
  public List<ServerServiceDefinition> getServices() {
    return Collections.unmodifiableList(new ArrayList<>(services.values()));
  }"
"protected final <V> V get(Function<T, V> getter, Supplier<V> fallback) {
		V value = getter.apply(this.properties);
		return (value != null) ? value : fallback.get();
	}"
"public boolean isSet(_Fields field) {
    if (field == null) {
      throw new IllegalArgumentException();
    }

    switch (field) {
    case STATUS_CODE:
      return isSetStatusCode();
    case INFO_MESSAGES:
      return isSetInfoMessages();
    case SQL_STATE:
      return isSetSqlState();
    case ERROR_CODE:
      return isSetErrorCode();
    case ERROR_MESSAGE:
      return isSetErrorMessage();
    }
    throw new IllegalStateException();
  }"
"public CassandraSink<IN> slotSharingGroup(String slotSharingGroup) {
		if (useDataStreamSink) {
			getSinkTransformation().setSlotSharingGroup(slotSharingGroup);
		} else {
			getStreamTransformation().setSlotSharingGroup(slotSharingGroup);
		}
		return this;
	}"
"public TimingStatistics add(TimingStatistics timingStatistics) {
        return TimingStatistics.builder()
                .ndarrayCreationTimeNanos(ndarrayCreationTimeNanos + timingStatistics.ndarrayCreationTimeNanos)
                .bandwidthNanosHostToDevice(bandwidthNanosHostToDevice + timingStatistics.bandwidthNanosHostToDevice)
                .diskReadingTimeNanos(diskReadingTimeNanos + timingStatistics.diskReadingTimeNanos)
                .bandwidthDeviceToHost(bandwidthDeviceToHost + timingStatistics.bandwidthDeviceToHost)
                .build();
    }"
"public void append(byte[] contents, int length) {
		if (contents == null || length <= 0) {
			return;
		}
		
		int len = Math.min(contents.length, length);
		if (pos + len > body.length) {
			byte[] newBody = new byte[pos + len];
			System.arraycopy(body, 0, newBody, 0, pos);
			body = newBody;
		}
		System.arraycopy(contents, 0, body, pos, len);
		pos += len;
		
        cachedString = null;
	}"
"public SDVariable mul(SDVariable x) {
        return mul(sameDiff.generateNewVarName(MulOp.OP_NAME,0),x);
    }"
"static void buildMatrix(BitArray dataBits,
                          ErrorCorrectionLevel ecLevel,
                          Version version,
                          int maskPattern,
                          ByteMatrix matrix) throws WriterException {
    clearMatrix(matrix);
    embedBasicPatterns(version, matrix);
    // Type information appear with any version.
    embedTypeInfo(ecLevel, maskPattern, matrix);
    // Version info appear if version >= 7.
    maybeEmbedVersionInfo(version, matrix);
    // Data should be embedded at end.
    embedDataBits(dataBits, maskPattern, matrix);
  }"
"public static ExpectedCondition<Boolean> urlToBe(final String url) {
    return new ExpectedCondition<Boolean>() {
      private String currentUrl = """";

      @Override
      public Boolean apply(WebDriver driver) {
        currentUrl = driver.getCurrentUrl();
        return currentUrl != null && currentUrl.equals(url);
      }

      @Override
      public String toString() {
        return String.format(""url to be \""%s\"". Current url: \""%s\"""", url, currentUrl);
      }
    };
  }"
"public double getStorageSize(String name, String defaultValue,
	                             StorageUnit targetUnit) {
		Preconditions.checkState(isNotBlank(name), ""Key cannot be blank."");
		String vString = get(name);
		if (isBlank(vString)) {
			vString = defaultValue;
		}

		// Please note: There is a bit of subtlety here. If the user specifies
		// the default unit as ""1GB"", but the requested unit is MB, we will return
		// the format in MB even thought the default string is specified in GB.

		// Converts a string like ""1GB"" to to unit specified in targetUnit.

		StorageSize measure = StorageSize.parse(vString);
		return convertStorageUnit(measure.getValue(), measure.getUnit(),
				targetUnit);
	}"
"@Override
    public void step(INDArray parameters, INDArray searchDirection, double step) {
        Nd4j.getBlasWrapper().level1().axpy(searchDirection.length(), step, searchDirection, parameters);
    }"
"@SuppressWarnings({ ""unchecked"", ""rawtypes"" })
	public <NV> Graph<K, NV, EV> mapVertices(final MapFunction<Vertex<K, VV>, NV> mapper) {

		TypeInformation<K> keyType = ((TupleTypeInfo<?>) vertices.getType()).getTypeAt(0);

		TypeInformation<NV> valueType;

		if (mapper instanceof ResultTypeQueryable) {
			valueType = ((ResultTypeQueryable) mapper).getProducedType();
		} else {
			valueType = TypeExtractor.createTypeInfo(MapFunction.class, mapper.getClass(), 1, vertices.getType(), null);
		}

		TypeInformation<Vertex<K, NV>> returnType = (TypeInformation<Vertex<K, NV>>) new TupleTypeInfo(
				Vertex.class, keyType, valueType);

		return mapVertices(mapper, returnType);
	}"
"public boolean containsValue(CharSequence name, CharSequence value, boolean ignoreCase) {
        Iterator<? extends CharSequence> itr = valueCharSequenceIterator(name);
        while (itr.hasNext()) {
            if (containsCommaSeparatedTrimmed(itr.next(), value, ignoreCase)) {
                return true;
            }
        }
        return false;
    }"
"private static boolean isValidStartEndForLength(int start, int end, int length) {
        if (start > length || end > length) {
            return false;
        }
        return true;
    }"
"public MultiLayerNetwork getMultiLayerNetwork(boolean importWeights)
            throws InvalidKerasConfigurationException, UnsupportedKerasConfigurationException {
        MultiLayerNetwork model = new MultiLayerNetwork(getMultiLayerConfiguration());
        model.init();
        if (importWeights)
            model = (MultiLayerNetwork) KerasModelUtils.copyWeightsToModel(model, this.layers);
        return model;
    }"
"@Override
  protected OpenedObject<T> generateOpenObject(T object) throws IOException
  {
    return new OpenedObject<>(
        object,
        new RetryingInputStream<>(object, openObjectFunction, retryCondition, getMaxFetchRetry()),
        getNoopCloser()
    );
  }"
"public void abortCheckpointOnBarrier(long checkpointId, Throwable cause) throws Exception {
		throw new UnsupportedOperationException(String.format(""abortCheckpointOnBarrier not supported by %s"", this.getClass().getName()));
	}"
"public static ByteBuf serializeRequestFailure(
			final ByteBufAllocator alloc,
			final long requestId,
			final Throwable cause) throws IOException {

		final ByteBuf buf = alloc.ioBuffer();

		// Frame length is set at the end
		buf.writeInt(0);
		writeHeader(buf, MessageType.REQUEST_FAILURE);
		buf.writeLong(requestId);

		try (ByteBufOutputStream bbos = new ByteBufOutputStream(buf);
				ObjectOutput out = new ObjectOutputStream(bbos)) {
			out.writeObject(cause);
		}

		// Set frame length
		int frameLength = buf.readableBytes() - Integer.BYTES;
		buf.setInt(0, frameLength);
		return buf;
	}"
"public static String getHadoopUser() {
		try {
			Class<?> ugiClass = Class.forName(
				""org.apache.hadoop.security.UserGroupInformation"",
				false,
				EnvironmentInformation.class.getClassLoader());

			Method currentUserMethod = ugiClass.getMethod(""getCurrentUser"");
			Method shortUserNameMethod = ugiClass.getMethod(""getShortUserName"");
			Object ugi = currentUserMethod.invoke(null);
			return (String) shortUserNameMethod.invoke(ugi);
		}
		catch (ClassNotFoundException e) {
			return ""<no hadoop dependency found>"";
		}
		catch (LinkageError e) {
			// hadoop classes are not in the classpath
			LOG.debug(""Cannot determine user/group information using Hadoop utils. "" +
					""Hadoop classes not loaded or compatible"", e);
		}
		catch (Throwable t) {
			// some other error occurred that we should log and make known
			LOG.warn(""Error while accessing user/group information via Hadoop utils."", t);
		}
		
		return UNKNOWN;
	}"
"public Map<String, String> parseParameters(HttpServletRequest request) {
    Map<String, String> parameters = parseHeaderParameters(request);

    if (parameters == null) {
      //if there is no header authorization parameters, then the oauth parameters are the supported OAuth request parameters.
      parameters = new HashMap<String, String>();
      for (String supportedOAuthParameter : getSupportedOAuthParameters()) {
        String param = request.getParameter(supportedOAuthParameter);
        if (param != null) {
          parameters.put(supportedOAuthParameter, param);
        }
      }
    }

    return parameters;
  }"
"public List<String> getLogicalDrives() {
		int flags = getLogicalDrives0();
		
		List<String> letters = new ArrayList<String>();
		for (int i = 0; i < 26; i++) {
			if ((flags & (1 << i)) != 0) letters.add(Character.toString((char)('A' + i)));
		}
		
		return letters;
	}"
"public static Protos.Resource ports(String role, Protos.Value.Range... ranges) {
		return ranges(""ports"", role, ranges);
	}"
"@VisibleForTesting
  static List<Interval> filterSkipIntervals(Interval totalInterval, List<Interval> skipIntervals)
  {
    final List<Interval> filteredIntervals = new ArrayList<>(skipIntervals.size() + 1);

    DateTime remainingStart = totalInterval.getStart();
    DateTime remainingEnd = totalInterval.getEnd();
    for (Interval skipInterval : skipIntervals) {
      if (skipInterval.getStart().isBefore(remainingStart) && skipInterval.getEnd().isAfter(remainingStart)) {
        remainingStart = skipInterval.getEnd();
      } else if (skipInterval.getStart().isBefore(remainingEnd) && skipInterval.getEnd().isAfter(remainingEnd)) {
        remainingEnd = skipInterval.getStart();
      } else if (!remainingStart.isAfter(skipInterval.getStart()) && !remainingEnd.isBefore(skipInterval.getEnd())) {
        filteredIntervals.add(new Interval(remainingStart, skipInterval.getStart()));
        remainingStart = skipInterval.getEnd();
      } else {
        // Ignore this skipInterval
        log.warn(
            ""skipInterval[%s] is not contained in remainingInterval[%s]"",
            skipInterval,
            new Interval(remainingStart, remainingEnd)
        );
      }
    }

    if (!remainingStart.equals(remainingEnd)) {
      filteredIntervals.add(new Interval(remainingStart, remainingEnd));
    }

    return filteredIntervals;
  }"
"private void rehash(int newCapacity) {
		long[] oldKeys = keys;
		V[] oldVals = values;

		keys = new long[newCapacity];
		@SuppressWarnings({ ""unchecked"", ""SuspiciousArrayCast"" })
		V[] temp = (V[]) new Object[newCapacity];
		values = temp;

		maxSize = calcMaxSize(newCapacity);
		mask = newCapacity - 1;

		// Insert to the new arrays.
		for (int i = 0; i < oldVals.length; ++i) {
			V oldVal = oldVals[i];
			if (oldVal != null) {
				// Inlined put(), but much simpler: we don't need to worry about
				// duplicated keys, growing/rehashing, or failing to insert.
				long oldKey = oldKeys[i];
				int index = hashIndex(oldKey);

				for (;;) {
					if (values[index] == null) {
						keys[index] = oldKey;
						values[index] = oldVal;
						break;
					}

					// Conflict, keep probing. Can wrap around, but never reaches startIndex again.
					index = probeNext(index);
				}
			}
		}
	}"
"private boolean transitionState(ExecutionState currentState, ExecutionState newState, Throwable cause) {
		if (STATE_UPDATER.compareAndSet(this, currentState, newState)) {
			if (cause == null) {
				LOG.info(""{} ({}) switched from {} to {}."", taskNameWithSubtask, executionId, currentState, newState);
			} else {
				LOG.info(""{} ({}) switched from {} to {}."", taskNameWithSubtask, executionId, currentState, newState, cause);
			}

			return true;
		} else {
			return false;
		}
	}"
"public static <T extends CharSequence> T validateIpv4(T value, String errorMsg) throws ValidateException {
		if (false == isIpv4(value)) {
			throw new ValidateException(errorMsg);
		}
		return value;
	}"
"public static ExpectedCondition<List<WebElement>> presenceOfAllElementsLocatedBy(
    final By locator) {
    return new ExpectedCondition<List<WebElement>>() {
      @Override
      public List<WebElement> apply(WebDriver driver) {
        List<WebElement> elements = driver.findElements(locator);
        return elements.size() > 0 ? elements : null;
      }

      @Override
      public String toString() {
        return ""presence of any elements located by "" + locator;
      }
    };
  }"
"@Override
    public Sequence<T> next() {
        Sequence<T> sequence = new Sequence<>();

        int startPosition = position.getAndIncrement();
        int lastId = -1;
        int currentPoint = order[startPosition];
        int startPoint = currentPoint;
        for (int i = 0; i < walkLength; i++) {

            if (alpha > 0 && lastId != startPoint && lastId != -1 && alpha > rng.nextDouble()) {
                startPosition = startPoint;
                continue;
            }


            Vertex<T> vertex = sourceGraph.getVertex(currentPoint);
            sequence.addElement(vertex.getValue());

            List<? extends Edge<? extends Number>> edges = sourceGraph.getEdgesOut(currentPoint);

            if (edges == null || edges.isEmpty()) {
                switch (noEdgeHandling) {
                    case CUTOFF_ON_DISCONNECTED:
                        // we just break this sequence
                        i = walkLength;
                        break;
                    case EXCEPTION_ON_DISCONNECTED:
                        throw new NoEdgesException(""No available edges left"");
                    case PADDING_ON_DISCONNECTED:
                        // TODO: implement padding
                        throw new UnsupportedOperationException(""Padding isn't implemented yet"");
                    case RESTART_ON_DISCONNECTED:
                        currentPoint = order[startPosition];
                        break;
                    case SELF_LOOP_ON_DISCONNECTED:
                        // we pad walk with this vertex, to do that - we just don't do anything, and currentPoint will be the same till the end of walk
                        break;
                }
            } else {
                double totalWeight = 0.0;
                for (Edge<? extends Number> edge : edges) {
                    totalWeight += edge.getValue().doubleValue();
                }

                double d = rng.nextDouble();
                double threshold = d * totalWeight;
                double sumWeight = 0.0;
                for (Edge<? extends Number> edge : edges) {
                    sumWeight += edge.getValue().doubleValue();
                    if (sumWeight >= threshold) {
                        if (edge.isDirected()) {
                            currentPoint = edge.getTo();
                        } else {
                            if (edge.getFrom() == currentPoint) {
                                currentPoint = edge.getTo();
                            } else {
                                currentPoint = edge.getFrom(); //Undirected edge: might be next--currVertexIdx instead of currVertexIdx--next
                            }
                        }
                        lastId = currentPoint;
                        break;
                    }
                }
            }
        }

        return sequence;
    }"
"public static void scale(Image srcImage, ImageOutputStream destImageStream, int width, int height, Color fixedColor) throws IORuntimeException {
		writeJpg(scale(srcImage, width, height, fixedColor), destImageStream);
	}"
"@Delete
    public Maybe<Boolean> invalidateCaches() {
        return Flowable.fromIterable(cacheManager.getCacheNames())
                .map(cacheManager::getCache)
                .flatMap(c ->
                        Publishers.fromCompletableFuture(() -> c.async().invalidateAll())
                ).reduce((aBoolean, aBoolean2) -> aBoolean && aBoolean2);
    }"
"protected void getBundledPluginsFromProperty(final List<File> r) {
        String hplProperty = SystemProperties.getString(""hudson.bundled.plugins"");
        if (hplProperty != null) {
            for (String hplLocation : hplProperty.split("","")) {
                File hpl = new File(hplLocation.trim());
                if (hpl.exists()) {
                    r.add(hpl);
                } else if (hpl.getName().contains(""*"")) {
                    try {
                        new DirScanner.Glob(hpl.getName(), null).scan(hpl.getParentFile(), new FileVisitor() {
                            @Override public void visit(File f, String relativePath) throws IOException {
                                r.add(f);
                            }
                        });
                    } catch (IOException x) {
                        LOGGER.log(Level.WARNING, ""could not expand "" + hplLocation, x);
                    }
                } else {
                    LOGGER.warning(""bundled plugin "" + hplLocation + "" does not exist"");
                }
            }
        }
    }"
"public void setup(ExecutorType clientExecutor,
                    ExecutorType serverExecutor,
                    MessageSize requestSize,
                    MessageSize responseSize,
                    FlowWindowSize windowSize,
                    ChannelType channelType,
                    int maxConcurrentStreams,
                    int channelCount) throws Exception {
    NettyServerBuilder serverBuilder;
    NettyChannelBuilder channelBuilder;
    if (channelType == ChannelType.LOCAL) {
      LocalAddress address = new LocalAddress(""netty-e2e-benchmark"");
      serverBuilder = NettyServerBuilder.forAddress(address);
      serverBuilder.channelType(LocalServerChannel.class);
      channelBuilder = NettyChannelBuilder.forAddress(address);
      channelBuilder.channelType(LocalChannel.class);
    } else {
      ServerSocket sock = new ServerSocket();
      // Pick a port using an ephemeral socket.
      sock.bind(new InetSocketAddress(BENCHMARK_ADDR, 0));
      SocketAddress address = sock.getLocalSocketAddress();
      sock.close();
      serverBuilder = NettyServerBuilder.forAddress(address);
      channelBuilder = NettyChannelBuilder.forAddress(address);
    }

    if (serverExecutor == ExecutorType.DIRECT) {
      serverBuilder.directExecutor();
    }
    if (clientExecutor == ExecutorType.DIRECT) {
      channelBuilder.directExecutor();
    }

    // Always use a different worker group from the client.
    ThreadFactory serverThreadFactory = new DefaultThreadFactory(""STF pool"", true /* daemon */);
    serverBuilder.workerEventLoopGroup(new NioEventLoopGroup(0, serverThreadFactory));

    // Always set connection and stream window size to same value
    serverBuilder.flowControlWindow(windowSize.bytes());
    channelBuilder.flowControlWindow(windowSize.bytes());

    channelBuilder.negotiationType(NegotiationType.PLAINTEXT);
    serverBuilder.maxConcurrentCallsPerConnection(maxConcurrentStreams);

    // Create buffers of the desired size for requests and responses.
    PooledByteBufAllocator alloc = PooledByteBufAllocator.DEFAULT;
    // Use a heap buffer for now, since MessageFramer doesn't know how to directly convert this
    // into a WritableBuffer
    // TODO(carl-mastrangelo): convert this into a regular buffer() call.  See
    // https://github.com/grpc/grpc-java/issues/2062#issuecomment-234646216
    request = alloc.heapBuffer(requestSize.bytes());
    request.writerIndex(request.capacity() - 1);
    response = alloc.heapBuffer(responseSize.bytes());
    response.writerIndex(response.capacity() - 1);

    // Simple method that sends and receives NettyByteBuf
    unaryMethod = MethodDescriptor.<ByteBuf, ByteBuf>newBuilder()
        .setType(MethodType.UNARY)
        .setFullMethodName(""benchmark/unary"")
        .setRequestMarshaller(new ByteBufOutputMarshaller())
        .setResponseMarshaller(new ByteBufOutputMarshaller())
        .build();

    pingPongMethod = unaryMethod.toBuilder()
        .setType(MethodType.BIDI_STREAMING)
        .setFullMethodName(""benchmark/pingPong"")
        .build();
    flowControlledStreaming = pingPongMethod.toBuilder()
        .setFullMethodName(""benchmark/flowControlledStreaming"")
        .build();

    // Server implementation of unary & streaming methods
    serverBuilder.addService(
        ServerServiceDefinition.builder(
            new ServiceDescriptor(""benchmark"",
                unaryMethod,
                pingPongMethod,
                flowControlledStreaming))
            .addMethod(unaryMethod, new ServerCallHandler<ByteBuf, ByteBuf>() {
                  @Override
                  public ServerCall.Listener<ByteBuf> startCall(
                      final ServerCall<ByteBuf, ByteBuf> call,
                      Metadata headers) {
                    call.sendHeaders(new Metadata());
                    call.request(1);
                    return new ServerCall.Listener<ByteBuf>() {
                      @Override
                      public void onMessage(ByteBuf message) {
                        // no-op
                        message.release();
                        call.sendMessage(response.slice());
                      }

                      @Override
                      public void onHalfClose() {
                        call.close(Status.OK, new Metadata());
                      }

                      @Override
                      public void onCancel() {

                      }

                      @Override
                      public void onComplete() {
                      }
                    };
                  }
                })
            .addMethod(pingPongMethod, new ServerCallHandler<ByteBuf, ByteBuf>() {
                  @Override
                  public ServerCall.Listener<ByteBuf> startCall(
                      final ServerCall<ByteBuf, ByteBuf> call,
                      Metadata headers) {
                    call.sendHeaders(new Metadata());
                    call.request(1);
                    return new ServerCall.Listener<ByteBuf>() {
                      @Override
                      public void onMessage(ByteBuf message) {
                        message.release();
                        call.sendMessage(response.slice());
                        // Request next message
                        call.request(1);
                      }

                      @Override
                      public void onHalfClose() {
                        call.close(Status.OK, new Metadata());
                      }

                      @Override
                      public void onCancel() {

                      }

                      @Override
                      public void onComplete() {

                      }
                    };
                  }
                })
            .addMethod(flowControlledStreaming, new ServerCallHandler<ByteBuf, ByteBuf>() {
                  @Override
                  public ServerCall.Listener<ByteBuf> startCall(
                      final ServerCall<ByteBuf, ByteBuf> call,
                      Metadata headers) {
                    call.sendHeaders(new Metadata());
                    call.request(1);
                    return new ServerCall.Listener<ByteBuf>() {
                      @Override
                      public void onMessage(ByteBuf message) {
                        message.release();
                        while (call.isReady()) {
                          call.sendMessage(response.slice());
                        }
                        // Request next message
                        call.request(1);
                      }

                      @Override
                      public void onHalfClose() {
                        call.close(Status.OK, new Metadata());
                      }

                      @Override
                      public void onCancel() {

                      }

                      @Override
                      public void onComplete() {

                      }

                      @Override
                      public void onReady() {
                        while (call.isReady()) {
                          call.sendMessage(response.slice());
                        }
                      }
                    };
                  }
                })
            .build());

    // Build and start the clients and servers
    server = serverBuilder.build();
    server.start();
    channels = new ManagedChannel[channelCount];
    ThreadFactory clientThreadFactory = new DefaultThreadFactory(""CTF pool"", true /* daemon */);
    for (int i = 0; i < channelCount; i++) {
      // Use a dedicated event-loop for each channel
      channels[i] = channelBuilder
          .eventLoopGroup(new NioEventLoopGroup(1, clientThreadFactory))
          .build();
    }
  }"
"@Override
  public void recordTaskAssignment(TaskEntity task) {
    ExecutionEntity executionEntity = task.getExecution();
    if (isHistoryLevelAtLeast(HistoryLevel.ACTIVITY)) {
      if (executionEntity != null) {
        HistoricActivityInstanceEntity historicActivityInstance = findActivityInstance(executionEntity, false, true);
        if (historicActivityInstance != null) {
          historicActivityInstance.setAssignee(task.getAssignee());
        }
      }
    }
  }"
"public synchronized void start(List<Long> weights) throws InterruptedException {
        for (int i = 0; i < weights.size(); i++) {
            this.weights.add(weights.get(i));
        }

        int number = latch.decrementAndGet();
        if (number == 0) {
            Long initWeight = this.weights.peek();
            if (initWeight != null) {
                barrier.single(initWeight);
            }
        }
    }"
"@SuppressWarnings(""FutureReturnValueIgnored"")
  void refreshIfNeeded(Node<K, V> node, long now) {
    if (!refreshAfterWrite()) {
      return;
    }
    K key;
    V oldValue;
    long oldWriteTime = node.getWriteTime();
    long refreshWriteTime = (now + ASYNC_EXPIRY);
    if (((now - oldWriteTime) > refreshAfterWriteNanos())
        && ((key = node.getKey()) != null) && ((oldValue = node.getValue()) != null)
        && node.casWriteTime(oldWriteTime, refreshWriteTime)) {
      try {
        CompletableFuture<V> refreshFuture;
        long startTime = statsTicker().read();
        if (isAsync) {
          @SuppressWarnings(""unchecked"")
          CompletableFuture<V> future = (CompletableFuture<V>) oldValue;
          if (Async.isReady(future)) {
            @SuppressWarnings(""NullAway"")
            CompletableFuture<V> refresh = future.thenCompose(value ->
              cacheLoader.asyncReload(key, value, executor));
            refreshFuture = refresh;
          } else {
            // no-op if load is pending
            node.casWriteTime(refreshWriteTime, oldWriteTime);
            return;
          }
        } else {
          @SuppressWarnings(""NullAway"")
          CompletableFuture<V> refresh = cacheLoader.asyncReload(key, oldValue, executor);
          refreshFuture = refresh;
        }
        refreshFuture.whenComplete((newValue, error) -> {
          long loadTime = statsTicker().read() - startTime;
          if (error != null) {
            logger.log(Level.WARNING, ""Exception thrown during refresh"", error);
            node.casWriteTime(refreshWriteTime, oldWriteTime);
            statsCounter().recordLoadFailure(loadTime);
            return;
          }

          @SuppressWarnings(""unchecked"")
          V value = (isAsync && (newValue != null)) ? (V) refreshFuture : newValue;

          boolean[] discard = new boolean[1];
          compute(key, (k, currentValue) -> {
            if (currentValue == null) {
              return value;
            } else if ((currentValue == oldValue) && (node.getWriteTime() == refreshWriteTime)) {
              return value;
            }
            discard[0] = true;
            return currentValue;
          }, /* recordMiss */ false, /* recordLoad */ false, /* recordLoadFailure */ true);

          if (discard[0] && hasRemovalListener()) {
            notifyRemoval(key, value, RemovalCause.REPLACED);
          }
          if (newValue == null) {
            statsCounter().recordLoadFailure(loadTime);
          } else {
            statsCounter().recordLoadSuccess(loadTime);
          }
        });
      } catch (Throwable t) {
        node.casWriteTime(refreshWriteTime, oldWriteTime);
        logger.log(Level.SEVERE, ""Exception thrown when submitting refresh task"", t);
      }
    }
  }"
"private void handleGetMetricHistory(final HttpServletRequest req,
      final Map<String, Object> ret) throws ServletException {
    if (MetricReportManager.isAvailable()) {
      final MetricReportManager metricManager = MetricReportManager.getInstance();
      final InMemoryMetricEmitter memoryEmitter =
          extractInMemoryMetricEmitter(metricManager);

      // if we have a memory emitter
      if (memoryEmitter != null) {
        try {
          final List<InMemoryHistoryNode> result =
              memoryEmitter.getMetrics(
                  getParam(req, STATS_MAP_METRICNAMEPARAM),
                  parseDate(getParam(req, STATS_MAP_STARTDATE)),
                  parseDate(getParam(req, STATS_MAP_ENDDATE)),
                  getBooleanParam(req, STATS_MAP_METRICRETRIEVALMODE));

          if (result != null && result.size() > 0) {
            ret.put(""data"", result);
          } else {
            ret.put(RESPONSE_ERROR, ""No metric stats available"");
          }

        } catch (final ParseException ex) {
          ret.put(RESPONSE_ERROR, ""Invalid Date filter"");
        }
      } else {
        ret.put(RESPONSE_ERROR, ""InMemoryMetricEmitter not instantiated"");
      }
    } else {
      ret.put(RESPONSE_ERROR, ""MetricReportManager is not available"");
    }
  }"
"public void add(String word)
    {
        word = reverse(word);
        trie.put(word, word.length());
    }"
"public static TypeVariableConstraint withVariadicBound(String name, String variadicBound)
    {
        return new TypeVariableConstraint(name, false, false, variadicBound);
    }"
"@Override
    public void destroy() {
        try {
            LOGGER.debug(""Closing Cassandra session"");
            session.close();
        } catch (final Exception e) {
            LOGGER.warn(e.getMessage(), e);
        }
        try {
            LOGGER.debug(""Closing Cassandra cluster"");
            cluster.close();
        } catch (final Exception e) {
            LOGGER.warn(e.getMessage(), e);
        }
    }"
"public ComputationGraph fit(JavaRDD<DataSet> rdd) {
        if (Nd4j.getExecutioner() instanceof GridExecutioner)
            ((GridExecutioner) Nd4j.getExecutioner()).flushQueue();

        trainingMaster.executeTraining(this, rdd);
        network.incrementEpochCount();
        return network;
    }"
"@CheckReturnValue
    @Override
    public long writeLogTo(long start, OutputStream out) throws IOException {
        return super.writeLogTo(start, new PlainTextConsoleOutputStream(out));
    }"
"public Mat asMat(INDArray array, int dataType) {
        if (array.rank() > 4 || (array.rank() > 3 && array.size(0) != 1)) {
            throw new UnsupportedOperationException(""Only rank 3 (or rank 4 with size(0) == 1) arrays supported"");
        }
        int rank = array.rank();
        long[] stride = array.stride();
        long offset = array.data().offset();
        Pointer pointer = array.data().pointer().position(offset);

        long rows = array.size(rank == 3 ? 1 : 2);
        long cols = array.size(rank == 3 ? 2 : 3);
        long channels = array.size(rank == 3 ? 0 : 1);
        boolean done = false;

        if (dataType < 0) {
            dataType = pointer instanceof DoublePointer ? CV_64F : CV_32F;
        }
        Mat mat = new Mat((int)Math.min(rows, Integer.MAX_VALUE), (int)Math.min(cols, Integer.MAX_VALUE),
                CV_MAKETYPE(dataType, (int)Math.min(channels, Integer.MAX_VALUE)));
        Indexer matidx = mat.createIndexer(direct);

        Nd4j.getAffinityManager().ensureLocation(array, AffinityManager.Location.HOST);

        if (pointer instanceof FloatPointer && dataType == CV_32F) {
            FloatIndexer ptridx = FloatIndexer.create((FloatPointer)pointer, new long[] {channels, rows, cols},
                    new long[] {stride[rank == 3 ? 0 : 1], stride[rank == 3 ? 1 : 2], stride[rank == 3 ? 2 : 3]}, direct);
            FloatIndexer idx = (FloatIndexer)matidx;
            for (long k = 0; k < channels; k++) {
                for (long i = 0; i < rows; i++) {
                    for (long j = 0; j < cols; j++) {
                        idx.put(i, j, k, ptridx.get(k, i, j));
                    }
                }
            }
            done = true;
            ptridx.release();
        } else if (pointer instanceof DoublePointer && dataType == CV_64F) {
            DoubleIndexer ptridx = DoubleIndexer.create((DoublePointer)pointer, new long[] {channels, rows, cols},
                    new long[] {stride[rank == 3 ? 0 : 1], stride[rank == 3 ? 1 : 2], stride[rank == 3 ? 2 : 3]}, direct);
            DoubleIndexer idx = (DoubleIndexer)matidx;
            for (long k = 0; k < channels; k++) {
                for (long i = 0; i < rows; i++) {
                    for (long j = 0; j < cols; j++) {
                        idx.put(i, j, k, ptridx.get(k, i, j));
                    }
                }
            }
            done = true;
            ptridx.release();
        }

        if (!done) {
            for (long k = 0; k < channels; k++) {
                for (long i = 0; i < rows; i++) {
                    for (long j = 0; j < cols; j++) {
                        if (rank == 3) {
                            matidx.putDouble(new long[] {i, j, k}, array.getDouble(k, i, j));
                        } else {
                            matidx.putDouble(new long[] {i, j, k}, array.getDouble(0, k, i, j));
                        }
                    }
                }
            }
        }

        matidx.release();
        return mat;
    }"
"public static Class getWrapperType(Class primitiveType) {
        if (primitiveType.isPrimitive()) {
            return PRIMITIVES_TO_WRAPPERS.get(primitiveType);
        }
        return primitiveType;
    }"
"public static Throwable unwrap(@Nullable Throwable t) {
		if (t instanceof UncheckedException || t instanceof java.util.concurrent.ExecutionException
				|| t instanceof java.lang.reflect.InvocationTargetException
				|| t instanceof UndeclaredThrowableException) {
			return t.getCause();
		}

		return t;
	}"
"private Class<?> attemptFromContextLoader(final String driverClassName) {
      final ClassLoader threadContextClassLoader = Thread.currentThread().getContextClassLoader();
      if (threadContextClassLoader != null) {
         try {
            final Class<?> driverClass = threadContextClassLoader.loadClass(driverClassName);
            LOGGER.debug(""Driver class {} found in Thread context class loader {}"", driverClassName, threadContextClassLoader);
            return driverClass;
         } catch (ClassNotFoundException e) {
            LOGGER.debug(""Driver class {} not found in Thread context class loader {}, trying classloader {}"",
               driverClassName, threadContextClassLoader, this.getClass().getClassLoader());
         }
      }

      return null;
   }"
"public final long getLong(int index) {
		final long pos = address + index;
		if (index >= 0 && pos <= addressLimit - 8) {
			return UNSAFE.getLong(heapMemory, pos);
		}
		else if (address > addressLimit) {
			throw new IllegalStateException(""segment has been freed"");
		}
		else {
			// index is in fact invalid
			throw new IndexOutOfBoundsException();
		}
	}"
"public void execute(@Param(""pipelineId"") Long pipelineId, Context context, Navigator nav) throws Exception {
        Channel channel = channelService.findByPipelineId(pipelineId);
        if (channel.getStatus().isStart()) {
            nav.redirectTo(WebConstant.ERROR_FORBIDDEN_Link);
            return;
        }

        Pipeline pipeline = pipelineService.findById(pipelineId);
        context.put(""pipeline"", pipeline);
        context.put(""nodes"", nodeService.listAll());
    }"
"public int getMaximumParallelism() {
		int maxParallelism = -1;
		for (JobVertex vertex : taskVertices.values()) {
			maxParallelism = Math.max(vertex.getParallelism(), maxParallelism);
		}
		return maxParallelism;
	}"
"public static Throwable unwrapCause(Throwable e) {
        if (e instanceof CommandActionExecutionException) {
            return e.getCause();
        }
        if (e instanceof HystrixBadRequestException) {
            return e.getCause();
        }
        return e;
    }"
"public static DataQualityAnalysis analyzeQuality(final Schema schema, final JavaRDD<List<Writable>> data) {
        int nColumns = schema.numColumns();
        List<QualityAnalysisState> states = data.aggregate(null,
                new BiFunctionAdapter<>(new QualityAnalysisAddFunction(schema)),
                new BiFunctionAdapter<>(new QualityAnalysisCombineFunction()));

        List<ColumnQuality> list = new ArrayList<>(nColumns);

        for (QualityAnalysisState qualityState : states) {
            list.add(qualityState.getColumnQuality());
        }
        return new DataQualityAnalysis(schema, list);
    }"
"protected boolean isRecoverableSdkClientException(SdkClientException ex) {
		if (ex instanceof AmazonServiceException) {
			return KinesisProxy.isRecoverableException((AmazonServiceException) ex);
		}
		// customizations may decide to retry other errors, such as read timeouts
		return false;
	}"
"public synchronized void pause() {
        // use compareAndSet to make sure it stops only once and when running
        if (running.compareAndSet(true, false)) {
            logger.debug(""Stopping the HystrixMetricsPoller"");
            scheduledTask.cancel(true);
        } else {
            logger.debug(""Attempted to pause a stopped poller"");
        }
    }"
"public OtpErlangRef read_ref() throws OtpErlangDecodeException {
        String node;
        int id;
        int creation;
        int tag;

        tag = read1skip_version();

        switch (tag) {
        case OtpExternal.refTag:
            node = read_atom();
            id = read4BE() & 0x3ffff; // 18 bits
            creation = read1() & 0x03; // 2 bits
            return new OtpErlangRef(node, id, creation);

        case OtpExternal.newRefTag:
        case OtpExternal.newerRefTag:
            final int arity = read2BE();
            if (arity > 3) {
		throw new OtpErlangDecodeException(
		    ""Ref arity "" + arity + "" too large "");
	    }
            node = read_atom();
	    if (tag == OtpExternal.newRefTag)
		creation = read1();
	    else
		creation = read4BE();

            final int[] ids = new int[arity];
            for (int i = 0; i < arity; i++) {
                ids[i] = read4BE();
            }
            return new OtpErlangRef(tag, node, ids, creation);

        default:
            throw new OtpErlangDecodeException(
                    ""Wrong tag encountered, expected ref, got "" + tag);
        }
    }"
"public CompositeByteBuf addComponents(boolean increaseWriterIndex, Iterable<ByteBuf> buffers) {
        return addComponents(increaseWriterIndex, componentCount, buffers);
    }"
"@Override
    public long skip(long n) throws IOException {
        byte[] buf = new byte[(int)Math.min(n,64*1024)];
        return read(buf,0,buf.length);
    }"
"private ResourceBundleHolder loadMessageBundle(Method m) throws ClassNotFoundException {
        Class c = m.getDeclaringClass();
        Class<?> msg = c.getClassLoader().loadClass(c.getName().substring(0, c.getName().lastIndexOf(""."")) + "".Messages"");
        return ResourceBundleHolder.get(msg);
    }"
"public INDArray getProbabilityMatrix(INDArray networkOutput, int example, int classNumber){
        //Input format: [minibatch, 5B+C, H, W], with order [x,y,w,h,c]
        //Therefore: probabilities for class I is at depths 5B + classNumber

        val bbs = layerConf().getBoundingBoxes().size(0);
        INDArray conf = networkOutput.get(point(example), point(5*bbs + classNumber), all(), all());
        return conf;
    }"
"public long getResponseContentLength() {
        Header[] headers = getResponseHeaderGroup().getHeaders(""Content-Length"");
        if (headers.length == 0) {
            return -1;
        }
        if (headers.length > 1) {
            LOG.warn(""Multiple content-length headers detected"");
        }
        for (int i = headers.length - 1; i >= 0; i--) {
            Header header = headers[i];
            try {
                return Long.parseLong(header.getValue());
            } catch (NumberFormatException e) {
                if (LOG.isWarnEnabled()) {
                    LOG.warn(""Invalid content-length value: "" + e.getMessage());
                }
            }
            // See if we can have better luck with another header, if present
        }
        return -1;
    }"
"@Override
    public Set<Long> getDeviceTrackingPoints(Integer deviceId) {
        return deviceAllocations.get(deviceId).keySet();
    }"
"private void checkDuplicate() {
		KeyboardShortcut ks = this.getDuplicate();
		if (ks != null) {
			this.setFieldValue(FIELD_INFO, Constant.messages.getString(""keyboard.dialog.warning.dup"", ks.getName()));
		} else {
			this.setFieldValue(FIELD_INFO, """");
		}
	}"
"public List<AdministrativeMonitor> getActiveAdministrativeMonitors() {
        return administrativeMonitors.stream().filter(m -> m.isEnabled() && m.isActivated()).collect(Collectors.toList());
    }"
"public static void safeRelease(Object msg, int decrement) {
        try {
            release(msg, decrement);
        } catch (Throwable t) {
            if (logger.isWarnEnabled()) {
                logger.warn(""Failed to release a message: {} (decrement: {})"", msg, decrement, t);
            }
        }
    }"
"@Override
	public void reset() {
		this.cursor = fixedSize;
		for (int i = 0; i < nullBitsSizeInBytes; i += 8) {
			segment.putLong(i, 0L);
		}
		this.segment.putInt(0, numElements);
	}"
"public static <T extends Collection<String>> T readUtf8Lines(String path, T collection) throws IORuntimeException {
		return readLines(path, CharsetUtil.CHARSET_UTF_8, collection);
	}"
"public List<String> similarWordsInVocabTo(String word, double accuracy) {
        return this.modelUtils.similarWordsInVocabTo(word, accuracy);
    }"
"static void removeOldKeys(Map<String, String> map, String... keys) {
        if (CommonUtils.isEmpty(map)) {
            return;
        }
        for (String key : keys) {
            map.remove(key);
        }
    }"
"public float getFloat(String key, float defaultValue) {
		Object o = getRawValue(key);
		if (o == null) {
			return defaultValue;
		}

		return convertToFloat(o, defaultValue);
	}"
"public static boolean shouldProxy(Properties props) {
    String shouldProxy = props.getProperty(HadoopSecurityManager.ENABLE_PROXYING);
    return shouldProxy != null && shouldProxy.equals(""true"");
  }"
"public static JavacNode injectType(JavacNode typeNode, final JCClassDecl type) {
		JCClassDecl typeDecl = (JCClassDecl) typeNode.get();
		addSuppressWarningsAll(type.mods, typeNode, type.pos, getGeneratedBy(type), typeNode.getContext());
		addGenerated(type.mods, typeNode, type.pos, getGeneratedBy(type), typeNode.getContext());
		typeDecl.defs = typeDecl.defs.append(type);
		return typeNode.add(type, Kind.TYPE);
	}"
"@Override
    public InputType getOutputType(InputType... inputType) throws InvalidKerasConfigurationException {
        if (inputType.length > 1)
            throw new InvalidKerasConfigurationException(
                    ""Keras SimpleRnn layer accepts only one input (received "" + inputType.length + "")"");
        InputPreProcessor preProcessor = getInputPreprocessor(inputType);
        if (preProcessor != null)
            return preProcessor.getOutputType(inputType[0]);
        else
            return this.getSimpleRnnLayer().getOutputType(-1, inputType[0]);
    }"
"public <T> List<T> readAll(Class<T> beanType) {
		return read(0, 1, Integer.MAX_VALUE, beanType);
	}"
"public DescribableList<ViewProperty,ViewPropertyDescriptor> getProperties() {
        // readResolve was the best place to do this, but for compatibility reasons,
        // this class can no longer have readResolve() (the mechanism itself isn't suitable for class hierarchy)
        // see JENKINS-9431
        //
        // until we have that, putting this logic here.
        synchronized (PropertyList.class) {
            if (properties == null) {
                properties = new PropertyList(this);
            } else {
                properties.setOwner(this);
            }
            return properties;
        }
    }"
"public T orElseCreate(Class<? extends T> type) {
		Assert.notNull(type, ""Type must not be null"");
		return (this.value != null) ? this.value : BeanUtils.instantiateClass(type);
	}"
"@Nullable
  public static com.google.rpc.Status fromThrowable(Throwable t) {
    Throwable cause = checkNotNull(t, ""t"");
    while (cause != null) {
      if (cause instanceof StatusException) {
        StatusException e = (StatusException) cause;
        return fromStatusAndTrailers(e.getStatus(), e.getTrailers());
      } else if (cause instanceof StatusRuntimeException) {
        StatusRuntimeException e = (StatusRuntimeException) cause;
        return fromStatusAndTrailers(e.getStatus(), e.getTrailers());
      }
      cause = cause.getCause();
    }
    return null;
  }"
"protected BindingResult<T> doConvert(Object value, ArgumentConversionContext<T> context) {
        Optional<T> result = conversionService.convert(value, context);
        if (result.isPresent() && context.getArgument().getType() == Optional.class) {
            return () -> (Optional<T>) result.get();
        }
        return () -> result;
    }"
"public INDArray output(INDArray input, boolean train, INDArray featuresMask, INDArray labelsMask) {
        return output(input, train, featuresMask, labelsMask, null);
    }"
"public SentinelServersConfig addSentinelAddress(String... addresses) {
        for (String address : addresses) {
            sentinelAddresses.add(URIBuilder.create(address));
        }
        return this;
    }"
"public static ByteBuf copyDouble(double... values) {
        if (values == null || values.length == 0) {
            return EMPTY_BUFFER;
        }
        ByteBuf buffer = buffer(values.length * 8);
        for (double v: values) {
            buffer.writeDouble(v);
        }
        return buffer;
    }"
"public EnvVars overrideAll(Map<String,String> all) {
        for (Map.Entry<String, String> e : all.entrySet()) {
            override(e.getKey(),e.getValue());
        }
        return this;
    }"
"public static int hash(String str, int k) {
		switch (k) {
			case 0:
				return HashUtil.rsHash(str);
			case 1:
				return HashUtil.jsHash(str);
			case 2:
				return HashUtil.elfHash(str);
			case 3:
				return HashUtil.bkdrHash(str);
			case 4:
				return HashUtil.apHash(str);
			case 5:
				return HashUtil.djbHash(str);
			case 6:
				return HashUtil.sdbmHash(str);
			case 7:
				return HashUtil.pjwHash(str);
			default:
				return 0;
		}
	}"
"public V get(K key) {
    if (root == null) {
      return null;
    }
    return root.get(key, key.hashCode(), 0);
  }"
"public void kill() throws InterruptedException {
            // after sending SIGTERM, wait for the process to cease to exist
            long deadline = System.nanoTime() + TimeUnit.SECONDS.toNanos(softKillWaitSeconds);
            kill(deadline);
        }"
"public static String getString(String key, @CheckForNull String def, Level logLevel) {
        String value = System.getProperty(key); // keep passing on any exceptions
        if (value != null) {
            if (LOGGER.isLoggable(logLevel)) {
                LOGGER.log(logLevel, ""Property (system): {0} => {1}"", new Object[] {key, value});
            }
            return value;
        } 
        
        value = handler.getString(key);
        if (value != null) {
            if (LOGGER.isLoggable(logLevel)) {
                LOGGER.log(logLevel, ""Property (context): {0} => {1}"", new Object[]{key, value});
            }
            return value;
        }
        
        value = def;
        if (LOGGER.isLoggable(logLevel)) {
            LOGGER.log(logLevel, ""Property (default): {0} => {1}"", new Object[] {key, value});
        }
        return value;
    }"
"public static ReadablePeriod parsePeriodString(final String periodStr) {
    final ReadablePeriod period;
    final char periodUnit = periodStr.charAt(periodStr.length() - 1);
    if (periodStr.equals(""null"") || periodUnit == 'n') {
      return null;
    }

    final int periodInt =
        Integer.parseInt(periodStr.substring(0, periodStr.length() - 1));
    switch (periodUnit) {
      case 'y':
        period = Years.years(periodInt);
        break;
      case 'M':
        period = Months.months(periodInt);
        break;
      case 'w':
        period = Weeks.weeks(periodInt);
        break;
      case 'd':
        period = Days.days(periodInt);
        break;
      case 'h':
        period = Hours.hours(periodInt);
        break;
      case 'm':
        period = Minutes.minutes(periodInt);
        break;
      case 's':
        period = Seconds.seconds(periodInt);
        break;
      default:
        throw new IllegalArgumentException(""Invalid schedule period unit '""
            + periodUnit);
    }

    return period;
  }"
"@PublicEvolving
	public DataStreamSink<T> writeToSocket(String hostName, int port, SerializationSchema<T> schema) {
		DataStreamSink<T> returnStream = addSink(new SocketClientSink<>(hostName, port, schema, 0));
		returnStream.setParallelism(1); // It would not work if multiple instances would connect to the same port
		return returnStream;
	}"
"public static void main (String[] args) {
    try {
      h2omapper m = new h2omapper();
      m.run(null);
    }
    catch (Exception e) {
      e.printStackTrace();
    }
  }"
"@Override public final int compareTo( Delayed t ) {
    RPC<?> dt = (RPC<?>)t;
    long nextTime = _started+_retry, dtNextTime = dt._started+dt._retry;
    return nextTime == dtNextTime ? 0 : (nextTime > dtNextTime ? 1 : -1);
  }"
"@Deprecated
	public FSDataOutputStream create(
			Path f,
			boolean overwrite,
			int bufferSize,
			short replication,
			long blockSize) throws IOException {

		return create(f, overwrite ? WriteMode.OVERWRITE : WriteMode.NO_OVERWRITE);
	}"
"void get_possible_actions(State source,
                              List<Action> actions)
    {
        if (0 == L || -1 == R)
        {
            System.err.println(""decoder: not initialized, please check if the root dependency relation is correct set by --root."");
            return;
        }
        actions.clear();

        if (!source.buffer_empty())
        {
            actions.add(ActionFactory.make_shift());
        }

        if (source.stack_size() == 2)
        {
            if (source.buffer_empty())
            {
                actions.add(ActionFactory.make_right_arc(R));
            }
        }
        else if (source.stack_size() > 2)
        {
            for (int l = 0; l < L; ++l)
            {
                if (l == R)
                {
                    continue;
                }
                actions.add(ActionFactory.make_left_arc(l));
                actions.add(ActionFactory.make_right_arc(l));
            }
        }
    }"
"@VisibleForTesting
  static String generateTraceSpanName(boolean isServer, String fullMethodName) {
    String prefix = isServer ? ""Recv"" : ""Sent"";
    return prefix + ""."" + fullMethodName.replace('/', '.');
  }"
"@Override
    public void shutdown() {
        try {
            DefaultMonitorRegistry.getInstance().unregister(Monitors.newObjectMonitor(this));
        } catch (Throwable t) {
            logger.error(""Cannot shutdown monitor registry"", t);
        }
        try {
            peerEurekaNodes.shutdown();
        } catch (Throwable t) {
            logger.error(""Cannot shutdown ReplicaAwareInstanceRegistry"", t);
        }
        numberOfReplicationsLastMin.stop();

        super.shutdown();
    }"
"Collection<Method> getMethodAndInterfaceDeclarations(Method method, Collection<Class> interfaces) {
        final List<Method> methods = new ArrayList<>();
        methods.add(method);

        // we search for matching method by iteration and comparison vs getMethod to avoid repeated NoSuchMethodException
        // being thrown, while interface typically only define a few set of methods to check.
        interfaces.stream()
                .map(Class::getMethods)
                .flatMap(Arrays::stream)
                .filter(m -> m.getName().equals(method.getName()) && Arrays.equals(m.getParameterTypes(), method.getParameterTypes()))
                .findFirst()
                .ifPresent(methods::add);

        return methods;
    }"
"public double averageFalseAlarmRate() {
        double ret = 0.0;
        for (int i = 0; i < numLabels(); i++) {
            ret += falseAlarmRate(i);
        }

        ret /= (double) numLabels();
        return ret;
    }"
"public void setURI(URI uri) throws URIException {

        if (uri.getScheme() == null || uri.getScheme().equals("""")) {
            mUri = new URI(HTTP + ""://"" + getHeader(HOST) + ""/"" + mUri.toString(), true);
            
        } else {
            mUri = uri;
        }

        if (uri.getScheme().equalsIgnoreCase(HTTPS)) {
            mIsSecure = true;
            
        } else {
            mIsSecure = false;
        }

        setHostPort(mUri.getPort());
    }"
"@Bean(initMethod = ""start"")
  KafkaCollector kafka(
      ZipkinKafkaCollectorProperties properties,
      CollectorSampler sampler,
      CollectorMetrics metrics,
      StorageComponent storage) {
    return properties.toBuilder().sampler(sampler).metrics(metrics).storage(storage).build();
  }"
"@SuppressWarnings(""WeakerAccess"")
    @Internal
    protected final Stream getStreamOfTypeForField(BeanResolutionContext resolutionContext, BeanContext context, FieldInjectionPoint injectionPoint) {
        return resolveBeanWithGenericsForField(resolutionContext, injectionPoint, (beanType, qualifier) ->
                ((DefaultBeanContext) context).streamOfType(resolutionContext, beanType, qualifier)
        );
    }"
"public static java.util.List<String> toAllGetterNames(JavacNode field) {
		return HandlerUtil.toAllGetterNames(field.getAst(), getAccessorsForField(field), field.getName(), isBoolean(field));
	}"
"public static String getSystemProperty(String key, @Nullable String defaultValue) {
    String value;
    try {
      value = System.getProperty(key);
    } catch (AccessControlException ex) {
      return defaultValue;
    }
    return value != null ? value : defaultValue;
  }"
"public byte[] generateSecretKey() throws AESException {
        try {
            // Get the KeyGenerator
            KeyGenerator kgen = KeyGenerator.getInstance(ENCRYPTION_ALGORITHM);
            kgen.init(KEY_SIZE); // 192 and 256 bits may not be available
            // Generate the secret key specs.
            SecretKey skey = kgen.generateKey();
            secretKey = skey.getEncoded();
            return secretKey;
        } catch (NoSuchAlgorithmException e) {
            throw new AESException(e);
        }
    }"
"protected List<String> resolveEventFromHttpRequest(final HttpServletRequest request) {
        val mfaRequestHeader = casProperties.getAuthn().getMfa().getRequestHeader();
        val headers = request.getHeaders(mfaRequestHeader);
        if (headers != null && headers.hasMoreElements()) {
            LOGGER.debug(""Received request header [{}] as [{}]"", mfaRequestHeader, headers);
            return Collections.list(headers);
        }

        val mfaRequestParameter = casProperties.getAuthn().getMfa().getRequestParameter();
        val params = request.getParameterValues(mfaRequestParameter);
        if (params != null && params.length > 0) {
            LOGGER.debug(""Received request parameter [{}] as [{}]"", mfaRequestParameter, params);
            return Arrays.stream(params).collect(Collectors.toList());
        }

        val attributeName = casProperties.getAuthn().getMfa().getSessionAttribute();
        val session = request.getSession(false);
        var attributeValue = session != null ? session.getAttribute(attributeName) : null;
        if (attributeValue == null) {
            LOGGER.trace(""No value could be found for session attribute [{}]. Checking request attributes..."", attributeName);
            attributeValue = request.getAttribute(attributeName);
        }

        if (attributeValue == null) {
            LOGGER.trace(""No value could be found for [{}]"", attributeName);
            return null;
        }

        val values = CollectionUtils.toCollection(attributeValue);
        LOGGER.debug(""Found values [{}] mapped to attribute name [{}]"", values, attributeName);
        return values.stream().map(Object::toString).collect(Collectors.toList());
    }"
"public void applicationRemoved(String appId, boolean cleanupLocalDirs) {
    logger.info(""Application {} removed, cleanupLocalDirs = {}"", appId, cleanupLocalDirs);
    Iterator<Map.Entry<AppExecId, ExecutorShuffleInfo>> it = executors.entrySet().iterator();
    while (it.hasNext()) {
      Map.Entry<AppExecId, ExecutorShuffleInfo> entry = it.next();
      AppExecId fullId = entry.getKey();
      final ExecutorShuffleInfo executor = entry.getValue();

      // Only touch executors associated with the appId that was removed.
      if (appId.equals(fullId.appId)) {
        it.remove();
        if (db != null) {
          try {
            db.delete(dbAppExecKey(fullId));
          } catch (IOException e) {
            logger.error(""Error deleting {} from executor state db"", appId, e);
          }
        }

        if (cleanupLocalDirs) {
          logger.info(""Cleaning up executor {}'s {} local dirs"", fullId, executor.localDirs.length);

          // Execute the actual deletion in a different thread, as it may take some time.
          directoryCleaner.execute(() -> deleteExecutorDirs(executor.localDirs));
        }
      }
    }
  }"
"public static Class<?> loadClass(String name, ClassLoader classLoader, boolean isInitialized) throws UtilException {
		Assert.notNull(name, ""Name must not be null"");

		// 加载原始类型和缓存中的类
		Class<?> clazz = loadPrimitiveClass(name);
		if (clazz == null) {
			clazz = classCache.get(name);
		}
		if (clazz != null) {
			return clazz;
		}

		if (name.endsWith(ARRAY_SUFFIX)) {
			// 对象数组""java.lang.String[]""风格
			final String elementClassName = name.substring(0, name.length() - ARRAY_SUFFIX.length());
			final Class<?> elementClass = loadClass(elementClassName, classLoader, isInitialized);
			clazz = Array.newInstance(elementClass, 0).getClass();
		} else if (name.startsWith(NON_PRIMITIVE_ARRAY_PREFIX) && name.endsWith("";"")) {
			// ""[Ljava.lang.String;"" 风格
			final String elementName = name.substring(NON_PRIMITIVE_ARRAY_PREFIX.length(), name.length() - 1);
			final Class<?> elementClass = loadClass(elementName, classLoader, isInitialized);
			clazz = Array.newInstance(elementClass, 0).getClass();
		} else if (name.startsWith(INTERNAL_ARRAY_PREFIX)) {
			// ""[[I"" 或 ""[[Ljava.lang.String;"" 风格
			final String elementName = name.substring(INTERNAL_ARRAY_PREFIX.length());
			final Class<?> elementClass = loadClass(elementName, classLoader, isInitialized);
			clazz = Array.newInstance(elementClass, 0).getClass();
		} else {
			// 加载普通类
			if (null == classLoader) {
				classLoader = getClassLoader();
			}
			try {
				clazz = Class.forName(name, isInitialized, classLoader);
			} catch (ClassNotFoundException ex) {
				// 尝试获取内部类，例如java.lang.Thread.State =》java.lang.Thread$State
				clazz = tryLoadInnerClass(name, classLoader, isInitialized);
				if (null == clazz) {
					throw new UtilException(ex);
				}
			}
		}

		// 加入缓存并返回
		return classCache.put(name, clazz);
	}"
"public SDVariable cosineDistance(String name, @NonNull SDVariable label, @NonNull SDVariable predictions,
                                     SDVariable weights, @NonNull LossReduce lossReduce, int dimension) {
        validateFloatingPoint(""cosine distance loss"", ""predictions"", predictions);
        validateNumerical(""cosine distance loss"", ""labels"", label);
        if (weights == null)
            weights = sd.scalar(null, predictions.dataType(), 1.0);
        SDVariable result = f().lossCosineDistance(label, predictions, weights, lossReduce, dimension);
        result = updateVariableNameAndReference(result, name);
        result.markAsLoss();
        return result;
    }"
"public static Map<String, ValueType> rowSignatureFor(final GroupByQuery query)
  {
    final ImmutableMap.Builder<String, ValueType> types = ImmutableMap.builder();

    for (DimensionSpec dimensionSpec : query.getDimensions()) {
      types.put(dimensionSpec.getOutputName(), dimensionSpec.getOutputType());
    }

    for (AggregatorFactory aggregatorFactory : query.getAggregatorSpecs()) {
      final String typeName = aggregatorFactory.getTypeName();
      final ValueType valueType;
      if (typeName != null) {
        valueType = GuavaUtils.getEnumIfPresent(ValueType.class, StringUtils.toUpperCase(typeName));
      } else {
        valueType = null;
      }
      if (valueType != null) {
        types.put(aggregatorFactory.getName(), valueType);
      }
    }

    // Don't include post-aggregators since we don't know what types they are.
    return types.build();
  }"
"static void configureArtifactServer(MesosArtifactServer server, ContainerSpecification container) throws IOException {
		// serve the artifacts associated with the container environment
		for (ContainerSpecification.Artifact artifact : container.getArtifacts()) {
			server.addPath(artifact.source, artifact.dest);
		}
	}"
"public static List<String> zipListFiles(File zipFile) throws IOException {
        List<String> out = new ArrayList<>();
        try (ZipFile zf = new ZipFile(zipFile)) {
            Enumeration entries = zf.entries();
            while (entries.hasMoreElements()) {
                ZipEntry ze = (ZipEntry) entries.nextElement();
                out.add(ze.getName());
            }
        }
        return out;
    }"
"public boolean setDefaultTokenEnabled(String name, boolean enabled) {
		Optional<HttpSessionToken> maybeToken = getDefaultToken(getNormalisedSessionTokenName(name));
		if (maybeToken.isPresent()) {
			HttpSessionToken token = maybeToken.get();
			if (token.isEnabled() == enabled) {
				return true;
			}
			if (token.isEnabled()) {
				defaultTokensEnabled.remove(token.getName());
			} else {
				defaultTokensEnabled.add(token.getName());
			}
			token.setEnabled(enabled);
			saveDefaultTokens();
			return true;
		}
		return false;
	}"
"public OtpErlangObject read_any() throws OtpErlangDecodeException {
        // calls one of the above functions, depending on o
        final int tag = peek1skip_version();

        switch (tag) {
        case OtpExternal.smallIntTag:
        case OtpExternal.intTag:
        case OtpExternal.smallBigTag:
        case OtpExternal.largeBigTag:
            return new OtpErlangLong(this);

        case OtpExternal.atomTag:
        case OtpExternal.smallAtomUtf8Tag:
        case OtpExternal.atomUtf8Tag:
            return new OtpErlangAtom(this);

        case OtpExternal.floatTag:
        case OtpExternal.newFloatTag:
            return new OtpErlangDouble(this);

        case OtpExternal.refTag:
        case OtpExternal.newRefTag:
        case OtpExternal.newerRefTag:
            return new OtpErlangRef(this);

        case OtpExternal.mapTag:
            return new OtpErlangMap(this);

        case OtpExternal.portTag:
        case OtpExternal.newPortTag:
            return new OtpErlangPort(this);

        case OtpExternal.pidTag:
        case OtpExternal.newPidTag:
            return new OtpErlangPid(this);

        case OtpExternal.stringTag:
            return new OtpErlangString(this);

        case OtpExternal.listTag:
        case OtpExternal.nilTag:
            if ((flags & DECODE_INT_LISTS_AS_STRINGS) != 0) {
                final int savePos = getPos();
                try {
                    return new OtpErlangString(this);
                } catch (final OtpErlangDecodeException e) {
                }
                setPos(savePos);
            }
            return new OtpErlangList(this);

        case OtpExternal.smallTupleTag:
        case OtpExternal.largeTupleTag:
            return new OtpErlangTuple(this);

        case OtpExternal.binTag:
            return new OtpErlangBinary(this);

        case OtpExternal.bitBinTag:
            return new OtpErlangBitstr(this);

        case OtpExternal.compressedTag:
            return read_compressed();

        case OtpExternal.newFunTag:
        case OtpExternal.funTag:
            return new OtpErlangFun(this);

	case OtpExternal.externalFunTag:
	    return new OtpErlangExternalFun(this);

        default:
            throw new OtpErlangDecodeException(""Uknown data type: "" + tag);
        }
    }"
"public static String toWitherName(AST<?, ?, ?> ast, AnnotationValues<Accessors> accessors, CharSequence fieldName, boolean isBoolean) {
		return toAccessorName(ast, accessors, fieldName, isBoolean, ""with"", ""with"", false);
	}"
"public <V> V run(Callable<V,IOException> callable) throws IOException {
        return callable.call();
    }"
"protected <T extends TokenBase> List<T> createTokenList(String text) {

        if (!split) {
            return createTokenList(0, text);
        }

        List<Integer> splitPositions = getSplitPositions(text);

        if (splitPositions.isEmpty()) {
            return createTokenList(0, text);
        }

        ArrayList<T> result = new ArrayList<>();

        int offset = 0;

        for (int position : splitPositions) {
            result.addAll(this.<T>createTokenList(offset, text.substring(offset, position + 1)));
            offset = position + 1;
        }

        if (offset < text.length()) {
            result.addAll(this.<T>createTokenList(offset, text.substring(offset)));
        }

        return result;
    }"
"public static String signParams(DigestAlgorithm digestAlgorithm, Map<?, ?> params) {
		return signParams(digestAlgorithm, params, StrUtil.EMPTY, StrUtil.EMPTY, true);
	}"
"@SneakyThrows
    public static ClientConfiguration buildClientConfiguration(final BaseAmazonWebServicesProperties props) {
        val cfg = new ClientConfiguration();
        cfg.setConnectionTimeout(props.getConnectionTimeout());
        cfg.setMaxConnections(props.getMaxConnections());
        cfg.setRequestTimeout(props.getRequestTimeout());
        cfg.setSocketTimeout(props.getSocketTimeout());
        cfg.setUseGzip(props.isUseGzip());
        cfg.setUseReaper(props.isUseReaper());
        cfg.setUseThrottleRetries(props.isUseThrottleRetries());
        cfg.setUseTcpKeepAlive(props.isUseTcpKeepAlive());
        cfg.setProtocol(Protocol.valueOf(props.getProtocol().toUpperCase()));
        cfg.setClientExecutionTimeout(props.getClientExecutionTimeout());
        if (props.getMaxErrorRetry() > 0) {
            cfg.setMaxErrorRetry(props.getMaxErrorRetry());
        }
        cfg.setProxyHost(props.getProxyHost());
        cfg.setProxyPassword(props.getProxyPassword());
        if (props.getProxyPort() > 0) {
            cfg.setProxyPort(props.getProxyPort());
        }
        cfg.setProxyUsername(props.getProxyUsername());
        cfg.setCacheResponseMetadata(props.isCacheResponseMetadata());

        if (StringUtils.isNotBlank(props.getLocalAddress())) {
            LOGGER.trace(""Creating DynamoDb client local address [{}]"", props.getLocalAddress());
            cfg.setLocalAddress(InetAddress.getByName(props.getLocalAddress()));
        }

        return cfg;
    }"
"public void modify(Pipeline pipeline) {
        Assert.assertNotNull(pipeline);
        try {

            PipelineDO pipelineDo = modelToDo(pipeline);

            if (!pipelineDao.checkUnique(pipelineDo)) {
                String exceptionCause = ""exist the same name pipeline under the channel("" + pipelineDo.getChannelId()
                                        + "") in the database."";
                logger.warn(""WARN ## "" + exceptionCause);
                throw new RepeatConfigureException(exceptionCause);
            }

            pipelineNodeRelationDao.deleteByPipelineId(pipelineDo.getId());

            pipelineDao.update(pipelineDo);

            List<PipelineNodeRelationDO> pipelineNodeRelationDos = new ArrayList<PipelineNodeRelationDO>();

            for (Node node : pipeline.getSelectNodes()) {
                PipelineNodeRelationDO pipelineNodeRelationDo = new PipelineNodeRelationDO();
                pipelineNodeRelationDo.setPipelineId(pipelineDo.getId());
                pipelineNodeRelationDo.setNodeId(node.getId());
                pipelineNodeRelationDo.setLocation(Location.SELECT);
                pipelineNodeRelationDos.add(pipelineNodeRelationDo);
            }

            for (Node node : pipeline.getExtractNodes()) {
                PipelineNodeRelationDO pipelineNodeRelationDo = new PipelineNodeRelationDO();
                pipelineNodeRelationDo.setPipelineId(pipelineDo.getId());
                pipelineNodeRelationDo.setNodeId(node.getId());
                pipelineNodeRelationDo.setLocation(Location.EXTRACT);
                pipelineNodeRelationDos.add(pipelineNodeRelationDo);
            }

            for (Node node : pipeline.getLoadNodes()) {
                PipelineNodeRelationDO pipelineNodeRelationDo = new PipelineNodeRelationDO();
                pipelineNodeRelationDo.setPipelineId(pipelineDo.getId());
                pipelineNodeRelationDo.setNodeId(node.getId());
                pipelineNodeRelationDo.setLocation(Location.LOAD);
                pipelineNodeRelationDos.add(pipelineNodeRelationDo);
            }

            pipelineNodeRelationDao.insertBatch(pipelineNodeRelationDos);
        } catch (Exception e) {
            logger.error(""ERROR ## modify the pipeline("" + pipeline.getId() + "") has an exception!"");
            throw new ManagerException(e);
        }
    }"
"protected SelectItem addRowNumber(PlainSelect plainSelect, List<SelectItem> autoItems) {
        //增加ROW_NUMBER()
        StringBuilder orderByBuilder = new StringBuilder();
        orderByBuilder.append(""ROW_NUMBER() OVER ("");
        if (isNotEmptyList(plainSelect.getOrderByElements())) {
            orderByBuilder.append(PlainSelect.orderByToString(
                    getOrderByElements(plainSelect, autoItems)).substring(1));
            //清空排序列表
            plainSelect.setOrderByElements(null);
        } else {
            orderByBuilder.append(""ORDER BY RAND()"");
        }
        orderByBuilder.append("") "");
        orderByBuilder.append(PAGE_ROW_NUMBER);
        return new SelectExpressionItem(new Column(orderByBuilder.toString()));
    }"
"public static PasswordEncoder newPasswordEncoder(final PasswordEncoderProperties properties) {
        val type = properties.getType();
        if (StringUtils.isBlank(type)) {
            LOGGER.trace(""No password encoder type is defined, and so none shall be created"");
            return NoOpPasswordEncoder.getInstance();
        }

        if (type.endsWith("".groovy"")) {
            LOGGER.debug(""Creating Groovy-based password encoder at [{}]"", type);
            val resource = ApplicationContextProvider.getResourceLoader().getResource(type);
            return new GroovyPasswordEncoder(resource);
        }

        if (type.contains(""."")) {
            try {
                LOGGER.debug(""Configuration indicates use of a custom password encoder [{}]"", type);
                val clazz = (Class<PasswordEncoder>) Class.forName(type);
                return clazz.getDeclaredConstructor().newInstance();
            } catch (final Exception e) {
                LOGGER.error(""Falling back to a no-op password encoder as CAS has failed to create ""
                    + ""an instance of the custom password encoder class "" + type, e);
                return NoOpPasswordEncoder.getInstance();
            }
        }

        val encoderType = PasswordEncoderProperties.PasswordEncoderTypes.valueOf(type);
        switch (encoderType) {
            case DEFAULT:
                LOGGER.debug(""Creating default password encoder with encoding alg [{}] and character encoding [{}]"",
                    properties.getEncodingAlgorithm(), properties.getCharacterEncoding());
                return new DefaultPasswordEncoder(properties.getEncodingAlgorithm(), properties.getCharacterEncoding());
            case STANDARD:
                LOGGER.debug(""Creating standard password encoder with the secret defined in the configuration"");
                return new StandardPasswordEncoder(properties.getSecret());
            case BCRYPT:
                LOGGER.debug(""Creating BCRYPT password encoder given the strength [{}] and secret in the configuration"",
                    properties.getStrength());
                if (StringUtils.isBlank(properties.getSecret())) {
                    LOGGER.debug(""Creating BCRYPT encoder without secret"");
                    return new BCryptPasswordEncoder(properties.getStrength());
                }
                LOGGER.debug(""Creating BCRYPT encoder with secret"");
                return new BCryptPasswordEncoder(properties.getStrength(), RandomUtils.getNativeInstance());
            case SCRYPT:
                LOGGER.debug(""Creating SCRYPT encoder"");
                return new SCryptPasswordEncoder();
            case PBKDF2:
                if (StringUtils.isBlank(properties.getSecret())) {
                    LOGGER.trace(""Creating PBKDF2 encoder without secret"");
                    return new Pbkdf2PasswordEncoder();
                }
                return new Pbkdf2PasswordEncoder(properties.getSecret(), properties.getStrength(), HASH_WIDTH);
            case GLIBC_CRYPT:
                val hasSecret = StringUtils.isNotBlank(properties.getSecret());
                LOGGER.debug(""Creating glibc CRYPT encoder with encoding alg [{}], strength [{}] and {}secret"",
                        properties.getEncodingAlgorithm(), properties.getStrength(),
                        BooleanUtils.toString(hasSecret, StringUtils.EMPTY, ""without ""));
                return new GlibcCryptPasswordEncoder(properties.getEncodingAlgorithm(), properties.getStrength(), properties.getSecret());
            case NONE:
            default:
                LOGGER.trace(""No password encoder shall be created given the requested encoder type [{}]"", type);
                return NoOpPasswordEncoder.getInstance();
        }
    }"
"public JobExecutionResult execute(String job_name) throws Exception {
		distributeFiles();
		JobExecutionResult result = this.env.execute(job_name);
		return result;
	}"
"public static ParameterAveragingTrainingMaster fromJson(String jsonStr) {
        ObjectMapper om = getJsonMapper();
        try {
            return om.readValue(jsonStr, ParameterAveragingTrainingMaster.class);
        } catch (IOException e) {
            throw new RuntimeException(""Could not parse JSON"", e);
        }
    }"
"private DruidRel<?> getLeftRelWithFilter()
  {
    final DruidRel<?> druidRight = (DruidRel) this.right;

    // Build list of acceptable values from right side.
    final Set<List<String>> valuess = new HashSet<>();
    final List<RexNode> conditions = druidRight.runQuery().accumulate(
        new ArrayList<>(),
        new Accumulator<List<RexNode>, Object[]>()
        {
          int numRows;

          @Override
          public List<RexNode> accumulate(final List<RexNode> theConditions, final Object[] row)
          {
            final List<String> values = new ArrayList<>(rightKeys.size());

            for (int i : rightKeys) {
              final Object value = row[i];
              if (value == null) {
                // NULLs are not supposed to match NULLs in a join. So ignore them.
                continue;
              }
              final String stringValue = DimensionHandlerUtils.convertObjectToString(value);
              values.add(stringValue);
            }

            if (valuess.add(values)) {
              if (++numRows > maxSemiJoinRowsInMemory) {
                throw new ResourceLimitExceededException(
                    StringUtils.format(""maxSemiJoinRowsInMemory[%,d] exceeded"", maxSemiJoinRowsInMemory)
                );
              }
              final List<RexNode> subConditions = new ArrayList<>();

              for (int i = 0; i < values.size(); i++) {
                final String value = values.get(i);
                // NULLs are not supposed to match NULLs in a join. So ignore them.
                if (value != null) {
                  subConditions.add(
                      getCluster().getRexBuilder().makeCall(
                          SqlStdOperatorTable.EQUALS,
                          leftExpressions.get(i),
                          getCluster().getRexBuilder().makeLiteral(value)
                      )
                  );
                }
                theConditions.add(makeAnd(subConditions));
              }
            }
            return theConditions;
          }
        }
    );

    valuess.clear();

    if (!conditions.isEmpty()) {
      // Add a filter to the left side.
      final PartialDruidQuery leftPartialQuery = left.getPartialDruidQuery();
      final Filter whereFilter = leftPartialQuery.getWhereFilter();
      final Filter newWhereFilter;

      if (whereFilter != null) {
        newWhereFilter = whereFilter.copy(
            whereFilter.getTraitSet(),
            whereFilter.getInput(),
            RexUtil.flatten(
                getCluster().getRexBuilder(),
                makeAnd(ImmutableList.of(whereFilter.getCondition(), makeOr(conditions)))
            )
        );
      } else {
        newWhereFilter = LogicalFilter.create(
            leftPartialQuery.getScan(),
            makeOr(conditions) // already in flattened form
        );
      }

      PartialDruidQuery newPartialQuery = PartialDruidQuery.create(leftPartialQuery.getScan())
                                                           .withWhereFilter(newWhereFilter)
                                                           .withSelectProject(leftPartialQuery.getSelectProject())
                                                           .withSelectSort(leftPartialQuery.getSelectSort());

      if (leftPartialQuery.getAggregate() != null) {
        newPartialQuery = newPartialQuery.withAggregate(leftPartialQuery.getAggregate());
      }

      if (leftPartialQuery.getHavingFilter() != null) {
        newPartialQuery = newPartialQuery.withHavingFilter(leftPartialQuery.getHavingFilter());
      }

      if (leftPartialQuery.getAggregateProject() != null) {
        newPartialQuery = newPartialQuery.withAggregateProject(leftPartialQuery.getAggregateProject());
      }

      if (leftPartialQuery.getSort() != null) {
        newPartialQuery = newPartialQuery.withSort(leftPartialQuery.getSort());
      }

      if (leftPartialQuery.getSortProject() != null) {
        newPartialQuery = newPartialQuery.withSortProject(leftPartialQuery.getSortProject());
      }

      return left.withPartialQuery(newPartialQuery);
    } else {
      return null;
    }
  }"
"public SharedTreeSubgraph makeSubgraph(String name) {
    SharedTreeSubgraph sg = new SharedTreeSubgraph(subgraphArray.size(), name);
    subgraphArray.add(sg);
    return sg;
  }"
"protected Map<String, List<Object>> retrievePersonAttributesFromAttributeRepository(final String id) {
        synchronized (lock) {
            val repository = getAttributeRepository();
            if (repository == null) {
                LOGGER.warn(""No attribute repositories could be fetched from application context"");
                return new HashMap<>(0);
            }
            return CoreAuthenticationUtils.retrieveAttributesFromAttributeRepository(repository, id, this.attributeRepositoryIds);
        }
    }"
"public static ThreadGroup currentThreadGroup() {
		final SecurityManager s = System.getSecurityManager();
		return (null != s) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup();
	}"
"@Deprecated
    public int numThreadLocalCaches() {
        PoolArena<?>[] arenas = heapArenas != null ? heapArenas : directArenas;
        if (arenas == null) {
            return 0;
        }

        int total = 0;
        for (PoolArena<?> arena : arenas) {
            total += arena.numThreadCaches.get();
        }

        return total;
    }"
"private DataSourceWrapper createDataSource(String group) {
		if (group == null) {
			group = StrUtil.EMPTY;
		}

		final Setting config = setting.getSetting(group);
		if (CollectionUtil.isEmpty(config)) {
			throw new DbRuntimeException(""No config for group: [{}]"", group);
		}

		// 基本信息
		final String url = config.getAndRemoveStr(KEY_ALIAS_URL);
		if (StrUtil.isBlank(url)) {
			throw new DbRuntimeException(""No JDBC URL for group: [{}]"", group);
		}
		// 自动识别Driver
		String driver = config.getAndRemoveStr(KEY_ALIAS_DRIVER);
		if (StrUtil.isBlank(driver)) {
			driver = DriverUtil.identifyDriver(url);
		}
		final String user = config.getAndRemoveStr(KEY_ALIAS_USER);
		final String pass = config.getAndRemoveStr(KEY_ALIAS_PASSWORD);

		return DataSourceWrapper.wrap(createDataSource(url, driver, user, pass, config), driver);
	}"
"public static int combine(String... path)
    {
        TFDictionary dictionaryMain = new TFDictionary();
        dictionaryMain.load(path[0]);
        int preSize = dictionaryMain.trie.size();
        for (int i = 1; i < path.length; ++i)
        {
            TFDictionary dictionary = new TFDictionary();
            dictionary.load(path[i]);
            dictionaryMain.combine(dictionary, 1, true);
        }
        try
        {
            BufferedWriter bw = new BufferedWriter(new OutputStreamWriter(IOUtil.newOutputStream(path[0]), ""UTF-8""));
            for (Map.Entry<String, TermFrequency> entry : dictionaryMain.trie.entrySet())
            {
                bw.write(entry.getKey());
                bw.write(' ');
                bw.write(String.valueOf(entry.getValue().getValue()));
                bw.newLine();
            }
            bw.close();
        }
        catch (Exception e)
        {
            e.printStackTrace();
            return -1;
        }

        return dictionaryMain.trie.size() - preSize;
    }"
"@Override
    public Object map(Object input) {
        Number n = (Number) input;
        return doOp(n.longValue());
    }"
"public long getPrefix() {
    // Since JVMs are either 4-byte aligned or 8-byte aligned, we check the size of the string.
    // If size is 0, just return 0.
    // If size is between 0 and 4 (inclusive), assume data is 4-byte aligned under the hood and
    // use a getInt to fetch the prefix.
    // If size is greater than 4, assume we have at least 8 bytes of data to fetch.
    // After getting the data, we use a mask to mask out data that is not part of the string.
    long p;
    long mask = 0;
    if (IS_LITTLE_ENDIAN) {
      if (numBytes >= 8) {
        p = Platform.getLong(base, offset);
      } else if (numBytes > 4) {
        p = Platform.getLong(base, offset);
        mask = (1L << (8 - numBytes) * 8) - 1;
      } else if (numBytes > 0) {
        p = (long) Platform.getInt(base, offset);
        mask = (1L << (8 - numBytes) * 8) - 1;
      } else {
        p = 0;
      }
      p = java.lang.Long.reverseBytes(p);
    } else {
      // byteOrder == ByteOrder.BIG_ENDIAN
      if (numBytes >= 8) {
        p = Platform.getLong(base, offset);
      } else if (numBytes > 4) {
        p = Platform.getLong(base, offset);
        mask = (1L << (8 - numBytes) * 8) - 1;
      } else if (numBytes > 0) {
        p = ((long) Platform.getInt(base, offset)) << 32;
        mask = (1L << (8 - numBytes) * 8) - 1;
      } else {
        p = 0;
      }
    }
    p &= ~mask;
    return p;
  }"
"@Override
	protected Object customKey(Object key) {
		if (null != key && key instanceof CharSequence) {
			key = StrUtil.toCamelCase(key.toString());
		}
		return key;
	}"
"public static long betweenMonth(Date beginDate, Date endDate, boolean isReset) {
		return new DateBetween(beginDate, endDate).betweenMonth(isReset);
	}"
"public void insert(float[] coords, int entry)
  {
    Preconditions.checkArgument(coords.length == numDims);
    insertInner(new Point(coords, entry, bitmapFactory));
  }"
"public void close() {
        done = true;
        connected = false;
        synchronized (this) {
            try {
                if (socket != null) {
                    if (traceLevel >= ctrlThreshold) {
                        System.out.println(""-> CLOSE"");
                    }
                    socket.close();
                }
            } catch (final IOException e) { /* ignore socket close errors */
            } finally {
                socket = null;
            }
        }
    }"
"public SDVariable fill(String name, SDVariable shape, org.nd4j.linalg.api.buffer.DataType dataType, double value) {
        SDVariable result = f().fill(shape, dataType, value);
        return updateVariableNameAndReference(result, name);
    }"
"public static <T extends Describable<T>>
    List<T> newInstancesFromHeteroList(StaplerRequest req, JSONObject formData, String key,
                Collection<? extends Descriptor<T>> descriptors) throws FormException {

        return newInstancesFromHeteroList(req,formData.get(key),descriptors);
    }"
"private static synchronized void checkAndCreateUploadDir(final Path uploadDir, final Logger log) throws IOException {
		if (Files.exists(uploadDir) && Files.isWritable(uploadDir)) {
			log.info(""Using directory {} for file uploads."", uploadDir);
		} else if (Files.isWritable(Files.createDirectories(uploadDir))) {
			log.info(""Created directory {} for file uploads."", uploadDir);
		} else {
			log.warn(""Upload directory {} cannot be created or is not writable."", uploadDir);
			throw new IOException(
				String.format(""Upload directory %s cannot be created or is not writable."",
					uploadDir));
		}
	}"
"protected synchronized void populateStatistics(final boolean noCache) {
    //check again before starting the work.
    if (noCache || System.currentTimeMillis() - lastRefreshedTime > cacheTimeInMilliseconds) {
      final ExecutorInfo stats = new ExecutorInfo();

      fillRemainingMemoryPercent(stats);
      fillRemainingFlowCapacityAndLastDispatchedTime(stats);
      fillCpuUsage(stats);

      cachedstats = stats;
      lastRefreshedTime = System.currentTimeMillis();
    }
  }"
"private void validateQuietZone(BitArray row, int startPattern) throws NotFoundException {

    int quietCount = this.narrowLineWidth * 10;  // expect to find this many pixels of quiet zone

    // if there are not so many pixel at all let's try as many as possible
    quietCount = quietCount < startPattern ? quietCount : startPattern;

    for (int i = startPattern - 1; quietCount > 0 && i >= 0; i--) {
      if (row.get(i)) {
        break;
      }
      quietCount--;
    }
    if (quietCount != 0) {
      // Unable to find the necessary number of quiet zone pixels.
      throw NotFoundException.getNotFoundInstance();
    }
  }"
"public static boolean isPrimitiveWrapper(Class<?> clazz) {
		if (null == clazz) {
			return false;
		}
		return BasicType.wrapperPrimitiveMap.containsKey(clazz);
	}"
"@RequirePOST
    @Restricted(NoExternalUse.class)
    public HttpResponse doCreateAdminUser(StaplerRequest req, StaplerResponse rsp) throws IOException {
        Jenkins j = Jenkins.getInstance();

        j.checkPermission(Jenkins.ADMINISTER);

        // This will be set up by default. if not, something changed, ok to fail
        HudsonPrivateSecurityRealm securityRealm = (HudsonPrivateSecurityRealm) j.getSecurityRealm();

        User admin = securityRealm.getUser(SetupWizard.initialSetupAdminUserName);
        try {
            if (admin != null) {
                admin.delete(); // assume the new user may well be 'admin'
            }

            User newUser = securityRealm.createAccountFromSetupWizard(req);
            if (admin != null) {
                admin = null;
            }

            // Success! Delete the temporary password file:
            try {
                getInitialAdminPasswordFile().delete();
            } catch (InterruptedException e) {
                throw new IOException(e);
            }

            InstallUtil.proceedToNextStateFrom(InstallState.CREATE_ADMIN_USER);

            // ... and then login
            Authentication auth = new UsernamePasswordAuthenticationToken(newUser.getId(), req.getParameter(""password1""));
            auth = securityRealm.getSecurityComponents().manager.authenticate(auth);
            SecurityContextHolder.getContext().setAuthentication(auth);
            
            HttpSession session = req.getSession(false);
            if (session != null) {
                // avoid session fixation
                session.invalidate();
            }
            HttpSession newSession = req.getSession(true);

            UserSeedProperty userSeed = newUser.getProperty(UserSeedProperty.class);
            String sessionSeed = userSeed.getSeed();
            // include the new seed
            newSession.setAttribute(UserSeedProperty.USER_SESSION_SEED, sessionSeed);
            
            CrumbIssuer crumbIssuer = Jenkins.getInstance().getCrumbIssuer();
            JSONObject data = new JSONObject();
            if (crumbIssuer != null) {
                data.accumulate(""crumbRequestField"", crumbIssuer.getCrumbRequestField()).accumulate(""crumb"", crumbIssuer.getCrumb(req));
            }
            return HttpResponses.okJSON(data);
        } catch (AccountCreationFailedException e) {
            /*
            Return Unprocessable Entity from WebDAV. While this is not technically in the HTTP/1.1 standard, browsers
            seem to accept this. 400 Bad Request is technically inappropriate because that implies invalid *syntax*,
            not incorrect data. The client only cares about it being >200 anyways.
             */
            rsp.setStatus(422);
            return HttpResponses.forwardToView(securityRealm, ""/jenkins/install/SetupWizard/setupWizardFirstUser.jelly"");
        } finally {
            if (admin != null) {
                admin.save(); // recreate this initial user if something failed
            }
        }
    }"
"public final long getLong48(final int pos) {
        final int position = origin + pos;

        if (pos + 5 >= limit || pos < 0) throw new IllegalArgumentException(""limit excceed: ""
                                                                            + (pos < 0 ? pos : (pos + 5)));

        byte[] buf = buffer;
        return ((long) (0xff & buf[position])) | ((long) (0xff & buf[position + 1]) << 8)
               | ((long) (0xff & buf[position + 2]) << 16) | ((long) (0xff & buf[position + 3]) << 24)
               | ((long) (0xff & buf[position + 4]) << 32) | ((long) (buf[position + 5]) << 40);
    }"
"public static List<OrderByElement> extraOrderBy(SelectBody selectBody) {
        if (selectBody instanceof PlainSelect) {
            List<OrderByElement> orderByElements = ((PlainSelect) selectBody).getOrderByElements();
            ((PlainSelect) selectBody).setOrderByElements(null);
            return orderByElements;
        } else if (selectBody instanceof WithItem) {
            WithItem withItem = (WithItem) selectBody;
            if (withItem.getSelectBody() != null) {
                return extraOrderBy(withItem.getSelectBody());
            }
        } else {
            SetOperationList operationList = (SetOperationList) selectBody;
            if (operationList.getSelects() != null && operationList.getSelects().size() > 0) {
                List<SelectBody> plainSelects = operationList.getSelects();
                return extraOrderBy(plainSelects.get(plainSelects.size() - 1));
            }
        }
        return null;
    }"
"public static DescriptorExtensionList<RetentionStrategy<?>,Descriptor<RetentionStrategy<?>>> all() {
        return (DescriptorExtensionList) Jenkins.get().getDescriptorList(RetentionStrategy.class);
    }"
"protected void processSystemArg(DefaultCommandLine cl, String arg) {
        int i = arg.indexOf(""="");
        String name = arg.substring(2, i);
        String value = arg.substring(i + 1, arg.length());
        cl.addSystemProperty(name, value);
    }"
"public Collection<Ticket> getAll() {
        val tickets = new ArrayList<Ticket>();
        val metadata = this.ticketCatalog.findAll();
        metadata.forEach(r -> {
            val scan = new ScanRequest(r.getProperties().getStorageName());
            LOGGER.debug(""Scanning table with request [{}]"", scan);
            val result = this.amazonDynamoDBClient.scan(scan);
            LOGGER.debug(""Scanned table with result [{}]"", scan);
            tickets.addAll(result.getItems().stream().map(DynamoDbTicketRegistryFacilitator::deserializeTicket).collect(Collectors.toList()));
        });
        return tickets;
    }"
"private static int estimateQuotient(int u2, int u1, int u0, int v1, int v0)
    {
        // estimate qhat based on the first 2 digits of divisor divided by the first digit of a dividend
        long u21 = combineInts(u2, u1);
        long qhat;
        if (u2 == v1) {
            qhat = INT_BASE - 1;
        }
        else if (u21 >= 0) {
            qhat = u21 / (v1 & LONG_MASK);
        }
        else {
            qhat = divideUnsignedLong(u21, v1);
        }

        if (qhat == 0) {
            return 0;
        }

        // Check if qhat is greater than expected considering only first 3 digits of a dividend
        // This step help to eliminate all the cases when the estimation is greater than q by 2
        // and eliminates most of the cases when qhat is greater than q by 1
        //
        // u2 * b * b + u1 * b + u0 >= (v1 * b + v0) * qhat
        // u2 * b * b + u1 * b + u0 >= v1 * b * qhat + v0 * qhat
        // u2 * b * b + u1 * b - v1 * b * qhat >=  v0 * qhat - u0
        // (u21 - v1 * qhat) * b >=  v0 * qhat - u0
        // (u21 - v1 * qhat) * b + u0 >=  v0 * qhat
        // When ((u21 - v1 * qhat) * b + u0) is less than (v0 * qhat) decrease qhat by one

        int iterations = 0;
        long rhat = u21 - (v1 & LONG_MASK) * qhat;
        while (Long.compareUnsigned(rhat, INT_BASE) < 0 && Long.compareUnsigned((v0 & LONG_MASK) * qhat, combineInts(lowInt(rhat), u0)) > 0) {
            iterations++;
            qhat--;
            rhat += (v1 & LONG_MASK);
        }

        if (iterations > 2) {
            throw new IllegalStateException(""qhat is greater than q by more than 2: "" + iterations);
        }

        return (int) qhat;
    }"
"public static File mkdir(String dirPath) {
		if (dirPath == null) {
			return null;
		}
		final File dir = file(dirPath);
		return mkdir(dir);
	}"
"private void append2slowd() {
    assert _ms==null;
    if(_ds != null && _ds.length > 0){
      if(_id == null) { // check for sparseness
        int nzs = 0; // assume one non-zero for the element currently being stored
        int nonnas = 0;
        for(double d:_ds) {
          if(d != 0)++nzs;
          if(!Double.isNaN(d))++nonnas;
        }
        if((nzs+1)*_sparseRatio < _len) {
          set_sparse(nzs,Compress.ZERO);
          assert _sparseLen == 0 || _sparseLen <= _ds.length:""_sparseLen = "" + _sparseLen + "", _ds.length = "" + _ds.length + "", nzs = "" + nzs +  "", len = "" + _len;
          assert _id.length == _ds.length;
          assert _sparseLen <= _len;
          return;
        }
        else if((nonnas+1)*_sparseRatio < _len) {
          set_sparse(nonnas,Compress.NA);
          assert _sparseLen == 0 || _sparseLen <= _ds.length:""_sparseLen = "" + _sparseLen + "", _ds.length = "" + _ds.length + "", nonnas = "" + nonnas +  "", len = "" + _len;
          assert _id.length == _ds.length;
          assert _sparseLen <= _len;
          return;
        }
      }
      else {
        // verify we're still sufficiently sparse
        if((_sparseRatio*(_sparseLen) >> 2) > _len)  cancel_sparse();
        else _id = MemoryManager.arrayCopyOf(_id, _sparseLen << 1);
      }
      _ds = MemoryManager.arrayCopyOf(_ds, _sparseLen << 1);
    } else {
      alloc_doubles(4);
      if (_id != null) alloc_indices(4);
    }
    assert _sparseLen == 0 || _ds.length > _sparseLen :""_ds.length = "" + _ds.length + "", _sparseLen = "" + _sparseLen;
    assert _id == null || _id.length == _ds.length;
    assert _sparseLen <= _len;
  }"
"public static List<String> getServiceUrlsFromDNS(
            EmbeddedServer embeddedServer,
            ApplicationConfiguration.InstanceConfiguration instanceConfiguration,
            DiscoveryClientConfiguration discoveryClientConfiguration) {

        return getServiceUrlsFromDNS(
                instanceConfiguration,
                discoveryClientConfiguration,
                instanceConfiguration.getZone().orElse(DEFAULT_ZONE),
                true,
                new InstanceInfoBasedUrlRandomizer(embeddedServer)
        );
    }"
"public String updateSetColumnsForce(Class<?> entityClass, String entityName, boolean notNull, boolean notEmpty) {
        StringBuilder sql = new StringBuilder();
        sql.append(""<set>"");
        //获取全部列
        Set<EntityColumn> columnSet = EntityHelper.getColumns(entityClass);
        //对乐观锁的支持
        EntityColumn versionColumn = null;
        //当某个列有主键策略时，不需要考虑他的属性是否为空，因为如果为空，一定会根据主键策略给他生成一个值
        for (EntityColumn column : columnSet) {
            if (column.getEntityField().isAnnotationPresent(Version.class)) {
                if (versionColumn != null) {
                    throw new VersionException(entityClass.getCanonicalName() + "" 中包含多个带有 @Version 注解的字段，一个类中只能存在一个带有 @Version 注解的字段!"");
                }
                versionColumn = column;
            }
            if (!column.isId() && column.isUpdatable()) {
                if (column == versionColumn) {
                    Version version = versionColumn.getEntityField().getAnnotation(Version.class);
                    String versionClass = version.nextVersion().getCanonicalName();
                    //version = ${@tk.mybatis.mapper.version@nextVersionClass(""versionClass"", version)}
                    sql.append(column.getColumn())
                        .append("" = ${@tk.mybatis.mapper.version.VersionUtil@nextVersion("")
                        .append(""@"").append(versionClass).append(""@class, "")
                        .append(column.getProperty()).append("")},"");
                } else if (notNull) {
                    sql.append(this.getIfNotNull(entityName, column, column.getColumnEqualsHolder(entityName) + "","", notEmpty));
                } else {
                    sql.append(column.getColumnEqualsHolder(entityName) + "","");
                }
            }
        }
        sql.append(""</set>"");
        return sql.toString();
    }"
"@Override
    public boolean containsValue(Object value) {
        for (V v : values()) {
            if (v.equals(value)) {
                return true;
            }
        }
        return false;
    }"
"private static S3Object getObjectForKey(Key k, long offset, long length) throws IOException {
    String[] bk = decodeKey(k);
    GetObjectRequest r = new GetObjectRequest(bk[0], bk[1]);
    r.setRange(offset, offset + length - 1); // Range is *inclusive* according to docs???
    return getClient().getObject(r);
  }"
"public static <T extends Item> List<T> getAllItems(final ItemGroup root, Class<T> type) {
        List<T> r = new ArrayList<>();
        getAllItems(root, type, r);
        return r;
    }"
"public synchronized int startServer(String ip, int port, boolean isDynamicPort) {

        if (isProxyRunning) {
            stopServer();
        }

        isProxyRunning = false;

        // ZAP: Set the name of the thread.
        thread = new Thread(this, threadName);
        thread.setDaemon(true);
        // the priority below should be higher than normal to allow fast accept on the server socket
        thread.setPriority(Thread.NORM_PRIORITY + 1);

        proxySocket = null;
        for (int i = 0; i < 20 && proxySocket == null; i++) {
            try {
                proxySocket = createServerSocket(ip, port);
                proxySocket.setSoTimeout(PORT_TIME_OUT);
                isProxyRunning = true;

            } catch (UnknownHostException e) {
                // ZAP: Warn the user if the host is unknown
                if (View.isInitialised()) {
                    View.getSingleton().showWarningDialog(Constant.messages.getString(""proxy.error.host.unknow"") + "" "" + ip);
                
                } else {
                    System.out.println(Constant.messages.getString(""proxy.error.host.unknow"") + "" "" + ip);
                }
                
                return -1;
            } catch (BindException e) {
                String message = e.getMessage();
                if (message == null || message.isEmpty()) {
                    handleUnknownException(e);
                    return -1;
                }

                if (message.startsWith(""Cannot assign requested address"")) {
                    showErrorMessage(Constant.messages.getString(""proxy.error.address"") + "" "" + ip);
                    return -1;
                } else if (message.startsWith(""Permission denied"") || message.startsWith(""Address already in use"")) {
                    if (!isDynamicPort) {
                        showErrorMessage(Constant.messages.getString(""proxy.error.port"", ip, Integer.toString(port)));
                        return -1;
                    } else if (port < 65535) {
                        port++;
                    }
                } else {
                    handleUnknownException(e);
                    return -1;
                }
            } catch (IOException e) {
                handleUnknownException(e);
                return -1;
            }

        }

        if (proxySocket == null) {
            return -1;
        }

        thread.start();

        return proxySocket.getLocalPort();

    }"
"@Override
  public void loadValidators(final Props props, final Logger log) {
    this.validators = new LinkedHashMap<>();
    if (!props.containsKey(ValidatorConfigs.XML_FILE_PARAM)) {
      logger.warn(
          ""Azkaban properties file does not contain the key "" + ValidatorConfigs.XML_FILE_PARAM);
      return;
    }
    final String xmlPath = props.get(ValidatorConfigs.XML_FILE_PARAM);
    final File file = new File(xmlPath);
    if (!file.exists()) {
      logger.error(""Azkaban validator configuration file "" + xmlPath + "" does not exist."");
      return;
    }

    // Creating the document builder to parse xml.
    final DocumentBuilderFactory docBuilderFactory =
        DocumentBuilderFactory.newInstance();
    DocumentBuilder builder = null;
    try {
      builder = docBuilderFactory.newDocumentBuilder();
    } catch (final ParserConfigurationException e) {
      throw new ValidatorManagerException(
          ""Exception while parsing validator xml. Document builder not created."", e);
    }

    Document doc = null;
    try {
      doc = builder.parse(file);
    } catch (final SAXException e) {
      throw new ValidatorManagerException(""Exception while parsing "" + xmlPath
          + "". Invalid XML."", e);
    } catch (final IOException e) {
      throw new ValidatorManagerException(""Exception while parsing "" + xmlPath
          + "". Error reading file."", e);
    }

    final NodeList tagList = doc.getChildNodes();
    final Node azkabanValidators = tagList.item(0);

    final NodeList azkabanValidatorsList = azkabanValidators.getChildNodes();
    for (int i = 0; i < azkabanValidatorsList.getLength(); ++i) {
      final Node node = azkabanValidatorsList.item(i);
      if (node.getNodeType() == Node.ELEMENT_NODE) {
        if (node.getNodeName().equals(VALIDATOR_TAG)) {
          parseValidatorTag(node, props, log);
        }
      }
    }
  }"
"private String[] handleDeprecation(DeprecationContext deprecations,
	                                   String name) {
		if (null != name) {
			name = name.trim();
		}
		// Initialize the return value with requested name
		String[] names = new String[]{name};
		// Deprecated keys are logged once and an updated names are returned
		DeprecatedKeyInfo keyInfo = deprecations.getDeprecatedKeyMap().get(name);
		if (keyInfo != null) {
			if (!keyInfo.getAndSetAccessed()) {
				logDeprecation(keyInfo.getWarningMessage(name));
			}
			// Override return value for deprecated keys
			names = keyInfo.newKeys;
		}
		// If there are no overlay values we can return early
		Properties overlayProperties = getOverlay();
		if (overlayProperties.isEmpty()) {
			return names;
		}
		// Update properties and overlays with reverse lookup values
		for (String n : names) {
			String deprecatedKey = deprecations.getReverseDeprecatedKeyMap().get(n);
			if (deprecatedKey != null && !overlayProperties.containsKey(n)) {
				String deprecatedValue = overlayProperties.getProperty(deprecatedKey);
				if (deprecatedValue != null) {
					getProps().setProperty(n, deprecatedValue);
					overlayProperties.setProperty(n, deprecatedValue);
				}
			}
		}
		return names;
	}"
"public static List<String> split(String str, char separator, int limit, boolean isTrim, boolean ignoreEmpty){
		return split(str, separator, limit, isTrim, ignoreEmpty, false);
	}"
"private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {
		hasher.putString(node.getTransformationUID(), Charset.forName(""UTF-8""));

		return hasher.hash().asBytes();
	}"
"public List<String> getCandidateIps() throws MalformedURLException {
        InstanceInfo myInfo = applicationInfoManager.getInfo();
        String myZone = ((AmazonInfo) myInfo.getDataCenterInfo()).get(AmazonInfo.MetaDataKey.availabilityZone);

        Collection<String> candidates = clientConfig.shouldUseDnsForFetchingServiceUrls()
                ? getIPsForZoneFromDNS(myZone)
                : getIPsForZoneFromConfig(myZone);

        if (candidates == null || candidates.size() == 0) {
            throw new RuntimeException(""Could not get any ips from the pool for zone :"" + myZone);
        }
        List<String> ips = Lists.newArrayList();

        for(String candidate : candidates) {
            String host = new URL(candidate).getHost();
            if (InetAddresses.isInetAddress(host)) {
                ips.add(host);
            } else {
                // ip-172-31-55-172.ec2.internal -> ip-172-31-55-172
                String firstPartOfHost = Splitter.on(""."").splitToList(host).get(0);
                // ip-172-31-55-172 -> [172,31,55,172]
                List<String> noIpPrefix = Splitter.on(""-"").splitToList(firstPartOfHost).subList(1, 5);
                // [172,31,55,172] -> 172.31.55.172
                String ip = Joiner.on(""."").join(noIpPrefix);
                if (InetAddresses.isInetAddress(ip)) {
                    ips.add(ip);
                } else {
                    throw new IllegalArgumentException(""Illegal internal hostname "" + host + "" translated to '"" + ip + ""'"");
                }
            }
        }
        return ips;
    }"
"public static <T extends Comparable<T>> T leq(T value) {
        reportMatcher(new LessOrEqual<T>(value));
        return null;
    }"
"public static TextProtocolBackendHandler newInstance(final String sql, final BackendConnection backendConnection) {
        if (sql.toUpperCase().startsWith(ShardingCTLBackendHandlerFactory.SCTL)) {
            return ShardingCTLBackendHandlerFactory.newInstance(sql, backendConnection);
        }
        // TODO use sql parser engine instead of string compare
        Optional<TransactionOperationType> transactionOperationType = TransactionOperationType.getOperationType(sql.toUpperCase());
        if (transactionOperationType.isPresent()) {
            return new TransactionBackendHandler(transactionOperationType.get(), backendConnection);
        }
        if (sql.toUpperCase().contains(SET_AUTOCOMMIT_1)) {
            return backendConnection.getStateHandler().isInTransaction() ? new TransactionBackendHandler(TransactionOperationType.COMMIT, backendConnection) : new SkipBackendHandler();
        }
        SQLStatement sqlStatement = new SQLJudgeEngine(sql).judge();
        return SQLType.DAL == sqlStatement.getType() ? createDALBackendHandler(sqlStatement, sql, backendConnection) : new QueryBackendHandler(sql, backendConnection);
    }"
"public static Integer[] wrap(int... values) {
		if (null == values) {
			return null;
		}
		final int length = values.length;
		if (0 == length) {
			return new Integer[0];
		}

		final Integer[] array = new Integer[length];
		for (int i = 0; i < length; i++) {
			array[i] = Integer.valueOf(values[i]);
		}
		return array;
	}"
"@CheckForNull
    @Restricted(NoExternalUse.class)
    public String getMetadataUrlForDownloadable(String downloadable) {
        String siteUrl = getUrl();
        String updateSiteMetadataUrl = null;
        int baseUrlEnd = siteUrl.indexOf(""update-center.json"");
        if (baseUrlEnd != -1) {
            String siteBaseUrl = siteUrl.substring(0, baseUrlEnd);
            updateSiteMetadataUrl = siteBaseUrl + ""updates/"" + downloadable;
        } else {
            LOGGER.log(Level.WARNING, ""Url {0} does not look like an update center:"", siteUrl);
        }
        return updateSiteMetadataUrl;
    }"
"public double iterateSample(T w1, T w2, double score) {
        INDArray w1Vector = syn0.slice(w1.getIndex());
        INDArray w2Vector = syn0.slice(w2.getIndex());
        //prediction: input + bias
        if (w1.getIndex() < 0 || w1.getIndex() >= syn0.rows())
            throw new IllegalArgumentException(""Illegal index for word "" + w1.getLabel());
        if (w2.getIndex() < 0 || w2.getIndex() >= syn0.rows())
            throw new IllegalArgumentException(""Illegal index for word "" + w2.getLabel());


        //w1 * w2 + bias
        double prediction = Nd4j.getBlasWrapper().dot(w1Vector, w2Vector);
        prediction += bias.getDouble(w1.getIndex()) + bias.getDouble(w2.getIndex());

        double weight = Math.pow(Math.min(1.0, (score / maxCount)), xMax);

        double fDiff = score > xMax ? prediction : weight * (prediction - Math.log(score));
        if (Double.isNaN(fDiff))
            fDiff = Nd4j.EPS_THRESHOLD;
        //amount of change
        double gradient = fDiff;

        //note the update step here: the gradient is
        //the gradient of the OPPOSITE word
        //for adagrad we will use the index of the word passed in
        //for the gradient calculation we will use the context vector
        update(w1, w1Vector, w2Vector, gradient);
        update(w2, w2Vector, w1Vector, gradient);
        return fDiff;



    }"
"public void addEmit(String keyword)
    {
        if (this.emits == null)
        {
            this.emits = new TreeSet<String>();
        }
        this.emits.add(keyword);
    }"
"public void closeConnection(RpcClient rpcClient, ClientTransportConfig transportConfig, Url url) {
        if (rpcClient == null || transportConfig == null || url == null) {
            return;
        }
        //TODO do not close
    }"
"public void clear() {
        for (Layer layer : layers)
            layer.clear();

        input = null;
        labels = null;
        solver = null;
    }"
"public void setSlotSharingGroup(SlotSharingGroup grp) {
		if (this.slotSharingGroup != null) {
			this.slotSharingGroup.removeVertexFromGroup(id);
		}

		this.slotSharingGroup = grp;
		if (grp != null) {
			grp.addVertexToGroup(id);
		}
	}"
"@Internal
    public static AnnotationMetadata mutateMember(
            AnnotationMetadata annotationMetadata,
            String annotationName,
            Map<CharSequence, Object> members) {
        if (StringUtils.isEmpty(annotationName)) {
            throw new IllegalArgumentException(""Argument [annotationName] cannot be blank"");
        }
        if (!members.isEmpty()) {
            for (Map.Entry<CharSequence, Object> entry: members.entrySet()) {
                if (StringUtils.isEmpty(entry.getKey())) {
                    throw new IllegalArgumentException(""Argument [members] cannot have a blank key"");
                }
                if (entry.getValue() == null) {
                    throw new IllegalArgumentException(""Argument [members] cannot have a null value. Key ["" + entry.getKey() + ""]"");
                }
            }
        }
        if (!(annotationMetadata instanceof DefaultAnnotationMetadata)) {
            return new DefaultAnnotationMetadata() {{
                addDeclaredAnnotation(annotationName, members);
            }};
        } else {
            DefaultAnnotationMetadata defaultMetadata = (DefaultAnnotationMetadata) annotationMetadata;

            defaultMetadata = (DefaultAnnotationMetadata) defaultMetadata.clone();

            defaultMetadata
                    .addDeclaredAnnotation(annotationName, members);

            return defaultMetadata;
        }
    }"
"static <T extends RemoteRunnable> T runOnH2ONode(H2ONode node, T runnable) {
    if (node == H2O.SELF) {
      // run directly
      runnable.run();
      return runnable;
    } else {
      RunnableWrapperTask<T> task = new RunnableWrapperTask<>(runnable);
      try {
        return new RPC<>(node, task).call().get()._runnable;
      } catch (DistributedException e) {
        Log.trace(""Exception in calling runnable on a remote node"",  e);
        Throwable cause = e.getCause();
        throw cause instanceof RuntimeException ? (RuntimeException) cause : e;
      }
    }
  }"
"@Override
    public Response build(final WebApplicationService webApplicationService, final String ticketId, final Authentication authentication) {

        val service = (OpenIdService) webApplicationService;
        val parameterList = new ParameterList(HttpRequestUtils.getHttpServletRequestFromRequestAttributes().getParameterMap());

        val parameters = new HashMap<String, String>();

        if (StringUtils.isBlank(ticketId)) {
            parameters.put(OpenIdProtocolConstants.OPENID_MODE, OpenIdProtocolConstants.CANCEL);
            return buildRedirect(service, parameters);
        }

        val association = getAssociation(serverManager, parameterList);
        val associated = association != null;
        val associationValid = isAssociationValid(association);
        var successFullAuthentication = true;

        var assertion = (Assertion) null;
        try {
            if (associated && associationValid) {
                assertion = centralAuthenticationService.validateServiceTicket(ticketId, service);
                LOGGER.debug(""Validated openid ticket [{}] for [{}]"", ticketId, service);
            } else if (!associated) {
                LOGGER.debug(""Responding to non-associated mode. Service ticket [{}] must be validated by the RP"", ticketId);
            } else {
                LOGGER.warn(""Association does not exist or is not valid"");
                successFullAuthentication = false;
            }
        } catch (final AbstractTicketException e) {
            LOGGER.error(""Could not validate ticket : [{}]"", e.getMessage(), e);
            successFullAuthentication = false;
        }
        val id = determineIdentity(service, assertion);
        return buildAuthenticationResponse(service, parameters, successFullAuthentication, id, parameterList);
    }"
"public static Op.Type getTypeFromByte(byte type) {
        switch (type) {
            case OpType.SCALAR:
                return Op.Type.SCALAR;
            case OpType.SCALAR_BOOL:
                return Op.Type.SCALAR_BOOL;
            case OpType.BROADCAST:
                return Op.Type.BROADCAST;
            case OpType.BROADCAST_BOOL:
                return Op.Type.BROADCAST_BOOL;
            case OpType.TRANSFORM_BOOL:
                return Op.Type.TRANSFORM_BOOL;
            case OpType.TRANSFORM_FLOAT:
                return Op.Type.TRANSFORM_FLOAT;
            case OpType.TRANSFORM_SAME:
                return Op.Type.TRANSFORM_SAME;
            case OpType.TRANSFORM_ANY:
                return Op.Type.TRANSFORM_ANY;
            case OpType.TRANSFORM_STRICT:
                return Op.Type.TRANSFORM_STRICT;
            case OpType.REDUCE_BOOL:
                return Op.Type.REDUCE_BOOL;
            case OpType.REDUCE_LONG:
                return Op.Type.REDUCE_LONG;
            case OpType.REDUCE_FLOAT:
                return Op.Type.REDUCE_FLOAT;
            case OpType.REDUCE_SAME:
                return Op.Type.REDUCE_SAME;
            case OpType.REDUCE_3:
                return Op.Type.REDUCE3;
            case OpType.INDEX_REDUCE:
                return Op.Type.INDEXREDUCE;
            case OpType.RANDOM:
                return Op.Type.RANDOM;
            case OpType.LOGIC:
                return Op.Type.META;
            case OpType.CUSTOM:
                return Op.Type.CUSTOM;
            case OpType.PAIRWISE:
                return Op.Type.PAIRWISE;
            case OpType.PAIRWISE_BOOL:
                return Op.Type.PAIRWISE_BOOL;
            case OpType.SUMMARYSTATS:
                return Op.Type.SUMMARYSTATS;
            default:
                throw new UnsupportedOperationException(""Unknown op type passed in: "" + type);
        }
    }"
"public boolean finalizeNativeLibs(final ClassLoader cl) throws ValidatorManagerException {
    boolean res = false;
    final Class classClassLoader = ClassLoader.class;
    java.lang.reflect.Field nativeLibraries = null;
    try {
      nativeLibraries = classClassLoader.getDeclaredField(""nativeLibraries"");
    } catch (final NoSuchFieldException e) {
      throw new ValidatorManagerException(e);
    }
    if (nativeLibraries == null) {
      return res;
    }
    nativeLibraries.setAccessible(true);
    Object obj = null;
    try {
      obj = nativeLibraries.get(cl);
    } catch (final IllegalAccessException e) {
      throw new ValidatorManagerException(e);
    }
    if (!(obj instanceof Vector)) {
      return res;
    }
    res = true;
    final Vector java_lang_ClassLoader_NativeLibrary = (Vector) obj;
    for (final Object lib : java_lang_ClassLoader_NativeLibrary) {
      java.lang.reflect.Method finalize = null;
      try {
        finalize = lib.getClass().getDeclaredMethod(""finalize"", new Class[0]);
      } catch (final NoSuchMethodException e) {
        throw new ValidatorManagerException(e);
      }
      if (finalize != null) {
        finalize.setAccessible(true);
        try {
          finalize.invoke(lib, new Object[0]);
        } catch (final IllegalAccessException e) {
          throw new ValidatorManagerException(e);
        } catch (final InvocationTargetException e) {
          throw new ValidatorManagerException(e);
        }
      }
    }
    return res;
  }"
"protected String findValidHeaderValue(Set<CharSequence> paramValues) {
    String selectedValue = null;
    if (paramValues != null && !paramValues.isEmpty()) {
      CharSequence value = paramValues.iterator().next();
      if (!(value instanceof QueryParameterValue)) {
        selectedValue = value.toString();
      }
    }
    return selectedValue;
  }"
"public static List<Integer> reverseSequence(int start, int end, int step) {
        return sequence(end-1,start-1,-step);
    }"
"public static CoreDictionary.Attribute get(String key)
    {
        if (HanLP.Config.Normalization) key = CharTable.convert(key);
        CoreDictionary.Attribute attribute = dat.get(key);
        if (attribute != null) return attribute;
        if (trie == null) return null;
        return trie.get(key);
    }"
"public void execute(final Collection<T> targets, final ForceExecuteCallback<T> callback) throws SQLException {
        Collection<SQLException> exceptions = new LinkedList<>();
        for (T each : targets) {
            try {
                callback.execute(each);
            } catch (final SQLException ex) {
                exceptions.add(ex);
            }
        }
        throwSQLExceptionIfNecessary(exceptions);
    }"
"public static String formatDate(Date date) {
		if (null == date) {
			return null;
		}
		return DatePattern.NORM_DATE_FORMAT.format(date);
	}"
"public static HttpRequestHeader changeMethod(String method, String header, String body) throws URIException, HttpMalformedHeaderException {
		HttpRequestHeader hrh = new HttpRequestHeader(header);
		URI uri = hrh.getURI();
		String prevMethod = hrh.getMethod();
		if (prevMethod.equalsIgnoreCase(method)) {
			return hrh;
		}
		if (prevMethod.equals(HttpRequestHeader.POST)) {
			// Was POST, move all params onto the URL
			if (body != null && body.length() > 0) {
				StringBuilder sb = new StringBuilder();
				if (uri.getQuery() != null) {
					sb.append(uri.getQuery());
				}

				String [] params = body.split(""&"");
				for (String param : params) {
					if (sb.length() > 0) {
						sb.append('&');
					}
					String[] nv = param.split(""="");
					if (nv.length == 1) {
						// This effectively strips out the equals if theres no value 
						sb.append(nv[0]);
					} else {
						sb.append(param);
					}
				}
				uri.setQuery(sb.toString());

			}
			hrh.setURI(uri);
			// Clear the body
			body = """";

		} else if (method.equals(HttpRequestHeader.POST)) {
			// To be a port, move all URL query params into the body
			String query = uri.getQuery();
			if (query != null) {
				StringBuilder sb = new StringBuilder();
				String [] params = query.split(""&"");
				for (String param : params) {
					if (sb.length() > 0) {
						sb.append('&');
					}
					sb.append(param);
					String[] nv = param.split(""="");
					if (nv.length == 1) {
						// Cope with URL params with no values e.g. http://www.example.com/test?key
						sb.append('=');
					}
				}
				// fixed: dead store to variable body by commenting the following line
				// body = sb.toString();
				uri.setQuery(null);
				hrh.setURI(uri);
			}
		}
		hrh.setMethod(method);
		
		return hrh;
	}"
"public static List<Long> getDelayMillsList(String schedulePlans) {
		List<Long> result = new ArrayList<>();
		String[] plans = StringUtils.split(schedulePlans, ',');
		for (String plan : plans) {
			result.add(getDelayMillis(plan));
		}
		return result;
	}"
"public Label getLabel(String expr) {
        if(expr==null)  return null;
        expr = hudson.util.QuotedStringTokenizer.unquote(expr);
        while(true) {
            Label l = labels.get(expr);
            if(l!=null)
                return l;

            // non-existent
            try {
                labels.putIfAbsent(expr,Label.parseExpression(expr));
            } catch (ANTLRException e) {
                // laxly accept it as a single label atom for backward compatibility
                return getLabelAtom(expr);
            }
        }
    }"
"public static boolean contentEquals(File file1, File file2) throws IORuntimeException {
		boolean file1Exists = file1.exists();
		if (file1Exists != file2.exists()) {
			return false;
		}

		if (false == file1Exists) {
			// 两个文件都不存在，返回true
			return true;
		}

		if (file1.isDirectory() || file2.isDirectory()) {
			// 不比较目录
			throw new IORuntimeException(""Can't compare directories, only files"");
		}

		if (file1.length() != file2.length()) {
			// 文件长度不同
			return false;
		}

		if (equals(file1, file2)) {
			// 同一个文件
			return true;
		}

		InputStream input1 = null;
		InputStream input2 = null;
		try {
			input1 = getInputStream(file1);
			input2 = getInputStream(file2);
			return IoUtil.contentEquals(input1, input2);

		} finally {
			IoUtil.close(input1);
			IoUtil.close(input2);
		}
	}"
"public void setResponseBody(HttpResponseBody resBody) {
		if (resBody == null) {
			throw new IllegalArgumentException(""The parameter resBody must not be null."");
		}
		mResBody = resBody;
	    getResponseBody().setCharset(getResponseHeader().getCharset());

	}"
"public void handleAnnotation(JCCompilationUnit unit, JavacNode node, JCAnnotation annotation, long priority) {
		TypeResolver resolver = new TypeResolver(node.getImportList());
		String rawType = annotation.annotationType.toString();
		String fqn = resolver.typeRefToFullyQualifiedName(node, typeLibrary, rawType);
		if (fqn == null) return;
		List<AnnotationHandlerContainer<?>> containers = annotationHandlers.get(fqn);
		if (containers == null) return;
		
		for (AnnotationHandlerContainer<?> container : containers) {
			try {
				if (container.getPriority() == priority) {
					if (checkAndSetHandled(annotation)) {
						container.handle(node);
					} else {
						if (container.isEvenIfAlreadyHandled()) container.handle(node);
					}
				}
			} catch (AnnotationValueDecodeFail fail) {
				fail.owner.setError(fail.getMessage(), fail.idx);
			} catch (Throwable t) {
				String sourceName = ""(unknown).java"";
				if (unit != null && unit.sourcefile != null) sourceName = unit.sourcefile.getName();
				javacError(String.format(""Lombok annotation handler %s failed on "" + sourceName, container.handler.getClass()), t);
			}
		}
	}"
"public static PlanNodeStatsEstimate computeSemiJoin(PlanNodeStatsEstimate sourceStats, PlanNodeStatsEstimate filteringSourceStats, Symbol sourceJoinSymbol, Symbol filteringSourceJoinSymbol)
    {
        return compute(sourceStats, filteringSourceStats, sourceJoinSymbol, filteringSourceJoinSymbol,
                (sourceJoinSymbolStats, filteringSourceJoinSymbolStats) ->
                        min(filteringSourceJoinSymbolStats.getDistinctValuesCount(), sourceJoinSymbolStats.getDistinctValuesCount()));
    }"
"public static int openAndBindPortToLocal(Connector sshConn, String remoteHost, int remotePort) throws JschRuntimeException {
		final Session session = openSession(sshConn.getHost(), sshConn.getPort(), sshConn.getUser(), sshConn.getPassword());
		if (session == null) {
			throw new JschRuntimeException(""Error to create SSH Session！"");
		}
		final int localPort = generateLocalPort();
		bindPort(session, remoteHost, remotePort, localPort);
		return localPort;
	}"
"public static Object getCellValue(Cell cell, CellType cellType, final boolean isTrimCellValue) {
		return getCellValue(cell, cellType, isTrimCellValue ? new TrimEditor() : null);
	}"
"public Class<?> type() {
        Type type = Types.getBaseClass(getClass(), ConsoleAnnotatorFactory.class);
        if (type instanceof ParameterizedType)
            return Types.erasure(Types.getTypeArgument(type,0));
        else
            return Object.class;
    }"
"public static int size(IntBuffer buffer, int dimension) {
        int rank = rank(buffer);
        if (dimension >= rank)
            throw new IllegalArgumentException(""Invalid dimension "" + dimension + "" for rank "" + rank + "" array"");
        return buffer.get(1 + dimension);
    }"
"private static InetAddress getLocalHostBySocket(InetSocketAddress remoteAddress) {
        InetAddress host = null;
        try {
            // 去连一下远程地址
            Socket socket = new Socket();
            try {
                socket.connect(remoteAddress, 1000);
                // 得到本地地址
                host = socket.getLocalAddress();
            } finally {
                IOUtils.closeQuietly(socket);
            }
        } catch (Exception e) {
            LOGGER.warn(""Can not connect to host {}, cause by :{}"",
                remoteAddress.toString(), e.getMessage());
        }
        return host;
    }"
"public static long count(int n, int m) {
		if(n == m) {
			return NumberUtil.factorial(n);
		}
		return (n > m) ? NumberUtil.factorial(n, n - m) : 0;
	}"
"void delay(long alreadyElapsed) {
    recorder.recordValue(alreadyElapsed);
    if (distribution != null) {
      long nextPermitted = Math.round(distribution.sample() * 1000000000.0);
      if (nextPermitted > alreadyElapsed) {
        LockSupport.parkNanos(nextPermitted - alreadyElapsed);
      }
    }
  }"
"private void computePathIfNeeded() {
    if (path == null) {
      // This will make sure path array has one extra element in the end, where we will store the version string.
      // Pass -1 because otherwise split() removes any trailing empty strings.
      path = (url + ""/"").split(""/"", -1);

      assert path[0].isEmpty() && path.length >= 3;

      String ver = path[1].toUpperCase();
      if (ver.equals(""EXPERIMENTAL"")) ver = ((Integer) SchemaServer.getExperimentalVersion()).toString();
      if (ver.equals(""LATEST"")) ver = ((Integer) SchemaServer.getLatestOrHighestSupportedVersion()).toString();

      // Old clients (h2o-2) tend to append .json suffix to the endpoint's name -- fixing that
      if (path[2].endsWith("".json""))
        path[2] = path[2].substring(0, path[2].length() - 5);

      path[1] = method;
      path[path.length - 1] = ver;
    }
  }"
"public void processWithItemsList(List<WithItem> withItemsList) {
        if (withItemsList != null && withItemsList.size() > 0) {
            for (WithItem item : withItemsList) {
                processSelectBody(item.getSelectBody());
            }
        }
    }"
"public static Response getRedirectResponse(final String url, final Map<String, String> parameters) {
        val builder = new StringBuilder(parameters.size() * RESPONSE_INITIAL_CAPACITY);
        val sanitizedUrl = sanitizeUrl(url);
        LOGGER.debug(""Sanitized URL for redirect response is [{}]"", sanitizedUrl);
        val fragmentSplit = Splitter.on(""#"").splitToList(sanitizedUrl);
        builder.append(fragmentSplit.get(0));
        val params = parameters.entrySet()
            .stream()
            .filter(entry -> entry.getValue() != null)
            .map(entry -> {
                try {
                    return String.join(""="", entry.getKey(), EncodingUtils.urlEncode(entry.getValue()));
                } catch (final Exception e) {
                    return String.join(""="", entry.getKey(), entry.getValue());
                }
            })
            .collect(Collectors.joining(""&""));
        if (!(params == null || params.isEmpty())) {
            builder.append(url.contains(""?"") ? ""&"" : ""?"");
            builder.append(params);
        }
        if (fragmentSplit.size() > 1) {
            builder.append('#');
            builder.append(fragmentSplit.get(1));
        }
        val urlRedirect = builder.toString();
        LOGGER.debug(""Final redirect response is [{}]"", urlRedirect);
        return new DefaultResponse(ResponseType.REDIRECT, urlRedirect, parameters);
    }"
"public static CellStyle setAlign(CellStyle cellStyle, HorizontalAlignment halign, VerticalAlignment valign) {
		cellStyle.setAlignment(halign);
		cellStyle.setVerticalAlignment(valign);
		return cellStyle;
	}"
"@Override
	void sendTaskEvent(TaskEvent event) throws IOException {
		checkError();
		checkState(subpartitionView != null, ""Tried to send task event to producer before requesting the subpartition."");

		if (!taskEventPublisher.publish(partitionId, event)) {
			throw new IOException(""Error while publishing event "" + event + "" to producer. The producer could not be found."");
		}
	}"
"private void saveHandleInState(final long checkpointId, final long timestamp) throws Exception {

		//only add handle if a new OperatorState was created since the last snapshot
		if (out != null) {
			int subtaskIdx = getRuntimeContext().getIndexOfThisSubtask();
			StreamStateHandle handle = out.closeAndGetHandle();

			PendingCheckpoint pendingCheckpoint = new PendingCheckpoint(
				checkpointId, subtaskIdx, timestamp, handle);

			if (pendingCheckpoints.contains(pendingCheckpoint)) {
				//we already have a checkpoint stored for that ID that may have been partially written,
				//so we discard this ""alternate version"" and use the stored checkpoint
				handle.discardState();
			} else {
				pendingCheckpoints.add(pendingCheckpoint);
			}
			out = null;
		}
	}"
"private void deleteNonShuffleFiles(String[] dirs) {
    FilenameFilter filter = new FilenameFilter() {
      @Override
      public boolean accept(File dir, String name) {
        // Don't delete shuffle data or shuffle index files.
        return !name.endsWith("".index"") && !name.endsWith("".data"");
      }
    };

    for (String localDir : dirs) {
      try {
        JavaUtils.deleteRecursively(new File(localDir), filter);
        logger.debug(""Successfully cleaned up non-shuffle files in directory: {}"", localDir);
      } catch (Exception e) {
        logger.error(""Failed to delete non-shuffle files in directory: "" + localDir, e);
      }
    }
  }"
"@CheckForNull
    public View getView(@CheckForNull String name) {
        if (name == null) {
            return null;
        }
        //Top level views returned first if match
        List<View> views = views();
        for (View v : views) {
            if (v.getViewName().equals(name)) {
                return v;
            }
        }
        for (View v : views) {
            //getAllViews() cannot be used as it filters jobs by permission which is bad e.g. when trying to add a new job
            if (v instanceof ViewGroup) {
                View nestedView = ((ViewGroup) v).getView(name);
                if (nestedView != null) {
                    return nestedView;
                }
            }
        }
        if (!name.equals(primaryView())) {
            // Fallback to subview of primary view if it is a ViewGroup
            View pv = getPrimaryView();
            if (pv instanceof ViewGroup)
                return ((ViewGroup)pv).getView(name);
            if (pv instanceof AllView && AllView.DEFAULT_VIEW_NAME.equals(pv.name)) {
                // JENKINS-38606: primary view is the default AllView, is somebody using an old link to localized form?
                for (Locale l : Locale.getAvailableLocales()) {
                    if (name.equals(Messages._Hudson_ViewName().toString(l))) {
                        // why yes they are, let's keep that link working
                        return pv;
                    }
                }
            }
        }
        return null;
    }"
"public static int additiveHash(String key, int prime) {
		int hash, i;
		for (hash = key.length(), i = 0; i < key.length(); i++) {
			hash += key.charAt(i);
		}
		return hash % prime;
	}"
"@Deprecated
    public static SslContext newServerContext(
            File certChainFile, File keyFile, String keyPassword,
            Iterable<String> ciphers, Iterable<String> nextProtocols,
            long sessionCacheSize, long sessionTimeout) throws SSLException {

        return newServerContext(
                null, certChainFile, keyFile, keyPassword,
                ciphers, nextProtocols, sessionCacheSize, sessionTimeout);
    }"
"public O returns(Class<OUT> typeClass) {
		requireNonNull(typeClass, ""type class must not be null"");

		try {
			return returns(TypeInformation.of(typeClass));
		}
		catch (InvalidTypesException e) {
			throw new InvalidTypesException(""Cannot infer the type information from the class alone."" +
					""This is most likely because the class represents a generic type. In that case,"" +
					""please use the 'returns(TypeHint)' method instead."", e);
		}
	}"
"private Response cacheWritingResponse(final CacheRequest cacheRequest, Response response)
      throws IOException {
    // Some apps return a null body; for compatibility we treat that like a null cache request.
    if (cacheRequest == null) return response;
    Sink cacheBodyUnbuffered = cacheRequest.body();
    if (cacheBodyUnbuffered == null) return response;

    final BufferedSource source = response.body().source();
    final BufferedSink cacheBody = Okio.buffer(cacheBodyUnbuffered);

    Source cacheWritingSource = new Source() {
      boolean cacheRequestClosed;

      @Override public long read(Buffer sink, long byteCount) throws IOException {
        long bytesRead;
        try {
          bytesRead = source.read(sink, byteCount);
        } catch (IOException e) {
          if (!cacheRequestClosed) {
            cacheRequestClosed = true;
            cacheRequest.abort(); // Failed to write a complete cache response.
          }
          throw e;
        }

        if (bytesRead == -1) {
          if (!cacheRequestClosed) {
            cacheRequestClosed = true;
            cacheBody.close(); // The cache response is complete!
          }
          return -1;
        }

        sink.copyTo(cacheBody.buffer(), sink.size() - bytesRead, bytesRead);
        cacheBody.emitCompleteSegments();
        return bytesRead;
      }

      @Override public Timeout timeout() {
        return source.timeout();
      }

      @Override public void close() throws IOException {
        if (!cacheRequestClosed
            && !discard(this, ExchangeCodec.DISCARD_STREAM_TIMEOUT_MILLIS, MILLISECONDS)) {
          cacheRequestClosed = true;
          cacheRequest.abort();
        }
        source.close();
      }
    };

    String contentType = response.header(""Content-Type"");
    long contentLength = response.body().contentLength();
    return response.newBuilder()
        .body(new RealResponseBody(contentType, contentLength, Okio.buffer(cacheWritingSource)))
        .build();
  }"
"@PublicEvolving
	public boolean contains(ConfigOption<?> configOption) {
		synchronized (this.confData){
			// first try the current key
			if (this.confData.containsKey(configOption.key())) {
				return true;
			}
			else if (configOption.hasFallbackKeys()) {
				// try the fallback keys
				for (FallbackKey fallbackKey : configOption.fallbackKeys()) {
					if (this.confData.containsKey(fallbackKey.getKey())) {
						loggingFallback(fallbackKey, configOption);
						return true;
					}
				}
			}

			return false;
		}
	}"
"public static <I extends AbstractItem & TopLevelItem> I move(I item, DirectlyModifiableTopLevelItemGroup destination) throws IOException, IllegalArgumentException {
        DirectlyModifiableTopLevelItemGroup oldParent = (DirectlyModifiableTopLevelItemGroup) item.getParent();
        if (oldParent == destination) {
            throw new IllegalArgumentException();
        }
        // TODO verify that destination is to not equal to, or inside, item
        if (!destination.canAdd(item)) {
            throw new IllegalArgumentException();
        }
        String name = item.getName();
        verifyItemDoesNotAlreadyExist(destination, name, null);
        String oldFullName = item.getFullName();
        // TODO AbstractItem.renameTo has a more baroque implementation; factor it out into a utility method perhaps?
        File destDir = destination.getRootDirFor(item);
        FileUtils.forceMkdir(destDir.getParentFile());
        FileUtils.moveDirectory(item.getRootDir(), destDir);
        oldParent.remove(item);
        I newItem = destination.add(item, name);
        item.movedTo(destination, newItem, destDir);
        ItemListener.fireLocationChange(newItem, oldFullName);
        return newItem;
    }"
"private boolean containsHpiJpi(Collection<String> bundledPlugins, String name) {
        return bundledPlugins.contains(name.replaceAll(""\\.hpi"","".jpi""))
                || bundledPlugins.contains(name.replaceAll(""\\.jpi"","".hpi""));
    }"
"public String getPerformanceStats() {
        int total = totalQuery.get();
        int hit = cacheHit.get();
        int weakRef = weakRefLost.get();
        int failure = loadFailure.get();
        int miss = total-hit-weakRef;

        return MessageFormat.format(""total={0} hit={1}% lostRef={2}% failure={3}% miss={4}%"",
                total,hit,weakRef,failure,miss);
    }"
"public String getGrantType() {
		if (getRequestParameters().containsKey(OAuth2Utils.GRANT_TYPE)) {
			return getRequestParameters().get(OAuth2Utils.GRANT_TYPE);
		}
		if (getRequestParameters().containsKey(OAuth2Utils.RESPONSE_TYPE)) {
			String response = getRequestParameters().get(OAuth2Utils.RESPONSE_TYPE);
			if (response.contains(""token"")) {
				return ""implicit"";
			}
		}
		return null;
	}"
"public void destory(Long channelId) {
        String path = ManagePathUtils.getChannelByChannelId(channelId);
        try {
            zookeeper.delete(path); // 删除节点，不关心版本
        } catch (ZkNoNodeException e) {
            // 如果节点已经不存在，则不抛异常
            // ignore
        } catch (ZkException e) {
            throw new ArbitrateException(""Channel_destory"", channelId.toString(), e);
        }
    }"
"public T get(Computer c) {
        if(record==null || !record.data.containsKey(c)) {
            // if we don't have the data, schedule the check now
            triggerUpdate();
            return null;
        }
        return record.data.get(c);
    }"
"public static boolean isIdOrFullnameAllowed(@CheckForNull String id) {
        if (StringUtils.isBlank(id)) {
            return false;
        }
        final String trimmedId = id.trim();
        for (String invalidId : ILLEGAL_PERSISTED_USERNAMES) {
            if (trimmedId.equalsIgnoreCase(invalidId))
                return false;
        }
        return true;
    }"
"@Override
    public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) {
        String command = (String) msg;
        if (command.startsWith(""get "")) {
            String keyString = command.substring(""get "".length());
            ByteBuf key = Unpooled.wrappedBuffer(keyString.getBytes(CharsetUtil.UTF_8));

            BinaryMemcacheRequest req = new DefaultBinaryMemcacheRequest(key);
            req.setOpcode(BinaryMemcacheOpcodes.GET);

            ctx.write(req, promise);
        } else if (command.startsWith(""set "")) {
            String[] parts = command.split("" "", 3);
            if (parts.length < 3) {
                throw new IllegalArgumentException(""Malformed Command: "" + command);
            }
            String keyString = parts[1];
            String value = parts[2];

            ByteBuf key = Unpooled.wrappedBuffer(keyString.getBytes(CharsetUtil.UTF_8));
            ByteBuf content = Unpooled.wrappedBuffer(value.getBytes(CharsetUtil.UTF_8));
            ByteBuf extras = ctx.alloc().buffer(8);
            extras.writeZero(8);

            BinaryMemcacheRequest req = new DefaultFullBinaryMemcacheRequest(key, extras, content);
            req.setOpcode(BinaryMemcacheOpcodes.SET);

            ctx.write(req, promise);
        } else {
            throw new IllegalStateException(""Unknown Message: "" + msg);
        }
    }"
"@Override
	public Map<String, String> toProperties() {
		DescriptorProperties properties = new DescriptorProperties();

		// this performs only basic validation
		// more validation can only happen within a factory
		if (connectorDescriptor.isFormatNeeded() && !formatDescriptor.isPresent()) {
			throw new ValidationException(String.format(""The connector %s requires a format description."", connectorDescriptor.toString()));
		} else if (!connectorDescriptor.isFormatNeeded() && formatDescriptor.isPresent()) {
			throw new ValidationException(
				String.format(""The connector %s does not require a format description "" +
				""but %s found."", connectorDescriptor.toString(), formatDescriptor.get().toString()));
		}

		properties.putProperties(connectorDescriptor.toProperties());

		formatDescriptor.ifPresent(s -> properties.putProperties(s.toProperties()));
		schemaDescriptor.ifPresent(s -> properties.putProperties(s.toProperties()));

		return properties.asMap();
	}"
"byte type() {
    if( _naCnt == -1 ) {        // No rollups yet?
      int nas=0, es=0, nzs=0, ss=0;
      if( _ds != null && _ms != null ) { // UUID?
        for(int i = 0; i< _sparseLen; i++ )
          if( _xs != null && _xs.get(i)==Integer.MIN_VALUE )  nas++;
          else if( _ds[i] !=0 || _ms.get(i) != 0 ) nzs++;
        _uuidCnt = _len -nas;
      } else if( _ds != null ) { // Doubles?
        assert _xs==null;
        for(int i = 0; i < _sparseLen; ++i) {
          if( Double.isNaN(_ds[i]) ) nas++;
          else if( _ds[i]!=0 ) nzs++;
        }
      } else {
        if( _ms != null && _sparseLen > 0) // Longs and categoricals?
          for(int i = 0; i< _sparseLen; i++ )
            if( isNA2(i) ) nas++;
            else {
              if( isCategorical2(i)   ) es++;
              if( _ms.get(i) != 0 ) nzs++;
            }
        if( _is != null )  // Strings
          for(int i = 0; i< _sparseLen; i++ )
            if( isNA2(i) ) nas++;
            else ss++;
      }
      if (_sparseNA) nas += (_len - _sparseLen);
      _nzCnt=nzs;  _catCnt =es;  _naCnt=nas; _strCnt = ss;
    }
    // Now run heuristic for type
    if(_naCnt == _len)          // All NAs ==> NA Chunk
      return Vec.T_BAD;
    if(_strCnt > 0)
      return Vec.T_STR;
    if(_catCnt > 0 && _catCnt + _naCnt + (isSparseZero()? _len-_sparseLen : 0) == _len)
      return Vec.T_CAT; // All are Strings+NAs ==> Categorical Chunk
    // UUIDs?
    if( _uuidCnt > 0 ) return Vec.T_UUID;
    // Larger of time & numbers
    int nums = _len -_naCnt-_timCnt;
    return _timCnt >= nums ? Vec.T_TIME : Vec.T_NUM;
  }"
"public final UnresolvedReferenceExpression[] mergeOperands() {
		UnresolvedReferenceExpression[] aggBuffers = aggBufferAttributes();
		UnresolvedReferenceExpression[] ret = new UnresolvedReferenceExpression[aggBuffers.length];
		for (int i = 0; i < aggBuffers.length; i++) {
			String name = String.valueOf(i);
			validateOperandName(name);
			ret[i] = new UnresolvedReferenceExpression(name);
		}
		return ret;
	}"
"public final Result solve(GradientSolver gslvr, double [] coefs){
    return solve(gslvr, coefs, gslvr.getGradient(coefs), new ProgressMonitor(){
      @Override
      public boolean progress(double[] beta, GradientInfo ginfo) {
        return true;
      }
    });
  }"
"public void addPluginClass(final String jobTypeName,
      final Class<? extends Job> jobTypeClass) {
    this.jobToClass.put(jobTypeName, jobTypeClass);
  }"
"public Schema schema(TableSchema schema) {
		tableSchema.clear();
		lastField = null;
		for (int i = 0; i < schema.getFieldCount(); i++) {
			field(schema.getFieldName(i).get(), schema.getFieldType(i).get());
		}
		return this;
	}"
"public Long peek() throws InterruptedException {
        lock.lockInterruptibly();
        try {
            while (queue.size() == 0) {
                notEmpty.await();
            }

            return queue.peek();
        } finally {
            lock.unlock();
        }
    }"
"private static DataSet<Centroid> getCentroidDataSet(ParameterTool params, ExecutionEnvironment env) {
		DataSet<Centroid> centroids;
		if (params.has(""centroids"")) {
			centroids = env.readCsvFile(params.get(""centroids""))
				.fieldDelimiter("" "")
				.pojoType(Centroid.class, ""id"", ""x"", ""y"");
		} else {
			System.out.println(""Executing K-Means example with default centroid data set."");
			System.out.println(""Use --centroids to specify file input."");
			centroids = KMeansData.getDefaultCentroidDataSet(env);
		}
		return centroids;
	}"
"@VisibleForTesting
	List<Container> getContainersFromPreviousAttemptsUnsafe(final Object response) {
		if (method != null && response != null) {
			try {
				@SuppressWarnings(""unchecked"")
				final List<Container> containers = (List<Container>) method.invoke(response);
				if (containers != null && !containers.isEmpty()) {
					return containers;
				}
			} catch (Exception t) {
				logger.error(""Error invoking 'getContainersFromPreviousAttempts()'"", t);
			}
		}

		return Collections.emptyList();
	}"
"private void parseArray(String fieldName) {
        int chr;
        int idx = 0;
        while (true) {
            sr.skipWhitespaceRead();
            sr.unreadLastCharacter();
            parseValue(fieldName + ""["" + (idx++) + ""]"");
            
            chr = sr.skipWhitespaceRead();
            if (chr == END_ARRAY) {
                break;
            }
            
            if (chr != VALUE_SEPARATOR) {
                throw new IllegalArgumentException(""Expected ',' or ']' inside array at position "" + sr.getPosition());
            }
        }
    }"
"public static File writeString(String content, File file, String charset) throws IORuntimeException {
		return FileWriter.create(file, CharsetUtil.charset(charset)).write(content);
	}"
"public void doScript(StaplerRequest req, StaplerResponse rsp) throws IOException, ServletException {
        _doScript(req, rsp, ""_script.jelly"");
    }"
"HttpRequestConfig getRedirectRequestConfig() {
        if (redirectRequestConfig == null) {
            redirectRequestConfig = HttpRequestConfig.builder().setRedirectionValidator(getRedirectionValidator()).build();
        }
        return redirectRequestConfig;
    }"
"private String[] parseLine(String nextLine, boolean multi) throws IOException {

        if (!multi && pending != null) {
            pending = null;
        }

        if (nextLine == null) {
            if (pending != null) {
                String s = pending;
                pending = null;
                return new String[]{s};
            } else {
                return null;
            }
        }

        List<String> tokensOnThisLine = new ArrayList<String>();
        StringBuilder sb = new StringBuilder(INITIAL_READ_SIZE);
        boolean inQuotes = false;
        if (pending != null) {
            sb.append(pending);
            pending = null;
            inQuotes = true;
        }
        for (int i = 0; i < nextLine.length(); i++) {

            char c = nextLine.charAt(i);
            if (c == this.escape) {
                if (isNextCharacterEscapable(nextLine, inQuotes || inField, i)) {
                    sb.append(nextLine.charAt(i + 1));
                    i++;
                }
            } else if (c == quotechar) {
                if (isNextCharacterEscapedQuote(nextLine, inQuotes || inField, i)) {
                    sb.append(nextLine.charAt(i + 1));
                    i++;
                } else {
                    //inQuotes = !inQuotes;

                    // the tricky case of an embedded quote in the middle: a,bc""d""ef,g
                    if (!strictQuotes) {
                        if (i > 2 //not on the beginning of the line
                                && nextLine.charAt(i - 1) != this.separator //not at the beginning of an escape sequence
                                && nextLine.length() > (i + 1) &&
                                nextLine.charAt(i + 1) != this.separator //not at the	end of an escape sequence
                                ) {

                            if (ignoreLeadingWhiteSpace && sb.length() > 0 && isAllWhiteSpace(sb)) {
                                sb.setLength(0);  //discard white space leading up to quote
                            } else {
                                sb.append(c);
                                //continue;
                            }

                        }
                    }

                    inQuotes = !inQuotes;
                }
                inField = !inField;
            } else if (c == separator && !inQuotes) {
                tokensOnThisLine.add(sb.toString());
                sb.setLength(0); // start work on next token
                inField = false;
            } else {
                if (!strictQuotes || inQuotes) {
                    sb.append(c);
                    inField = true;
                }
            }
        }
        // line is done - check status
        if (inQuotes) {
            if (multi) {
                // continuing a quoted section, re-append newline
                sb.append(""\n"");
                pending = sb.toString();
                sb = null; // this partial content is not to be added to field list yet
            } else {
                throw new IOException(""Un-terminated quoted field at end of CSV line"");
            }
        }
        if (sb != null) {
            tokensOnThisLine.add(sb.toString());
        }
        return tokensOnThisLine.toArray(new String[tokensOnThisLine.size()]);

    }"
"public static void checkParameter(boolean condition, @Nullable Object errorMessage) {
		if (!condition) {
			throw new ProgramParametrizationException(String.valueOf(errorMessage));
		}
	}"
"public void deleteNamespace(String namespaceId) {

        DeleteNamespaceRequest deleteNamespaceRequest = new DeleteNamespaceRequest().withId(namespaceId);
        getDiscoveryClient().deleteNamespace(deleteNamespaceRequest);

    }"
"@Exported
    public int getTotalExecutors() {
        int r=0;
        for (Node n : getNodes()) {
            Computer c = n.toComputer();
            if(c!=null && c.isOnline())
                r += c.countExecutors();
        }
        return r;
    }"
"static int randomNumber(int minimum, int maximum) {
        assert minimum < maximum;
        double fraction = PlatformDependent.threadLocalRandom().nextDouble();

        // the idea here is that nextDouble gives us a random value
        //
        //              0 <= fraction <= 1
        //
        // the distance from min to max declared as
        //
        //              dist = max - min
        //
        // satisfies the following
        //
        //              min + dist = max
        //
        // taking into account
        //
        //         0 <= fraction * dist <= dist
        //
        // we've got
        //
        //       min <= min + fraction * dist <= max
        return (int) (minimum + fraction * (maximum - minimum));
    }"
"@CheckReturnValue
    public static <T> T mock(Class<T> classToMock, String name) {
        return mock(classToMock, withSettings()
                .name(name)
                .defaultAnswer(RETURNS_DEFAULTS));
    }"
"void merge(Settings other) {
    for (int i = 0; i < COUNT; i++) {
      if (!other.isSet(i)) continue;
      set(i, other.flags(i), other.get(i));
    }
  }"
"public void persistConfiguration(final String shardingSchemaName, final Map<String, DataSourceConfiguration> dataSourceConfigs, final RuleConfiguration ruleConfig,
                                     final Authentication authentication, final Properties props, final boolean isOverwrite) {
        persistDataSourceConfiguration(shardingSchemaName, dataSourceConfigs, isOverwrite);
        persistRuleConfiguration(shardingSchemaName, ruleConfig, isOverwrite);
        persistAuthentication(authentication, isOverwrite);
        persistProperties(props, isOverwrite);
    }"
"protected void processGeneratedValue(EntityTable entityTable, EntityColumn entityColumn, GeneratedValue generatedValue) {
        if (""JDBC"".equals(generatedValue.generator())) {
            entityColumn.setIdentity(true);
            entityColumn.setGenerator(""JDBC"");
            entityTable.setKeyProperties(entityColumn.getProperty());
            entityTable.setKeyColumns(entityColumn.getColumn());
        } else {
            //允许通过generator来设置获取id的sql,例如mysql=CALL IDENTITY(),hsqldb=SELECT SCOPE_IDENTITY()
            //允许通过拦截器参数设置公共的generator
            if (generatedValue.strategy() == GenerationType.IDENTITY) {
                //mysql的自动增长
                entityColumn.setIdentity(true);
                if (!"""".equals(generatedValue.generator())) {
                    String generator = null;
                    IdentityDialect identityDialect = IdentityDialect.getDatabaseDialect(generatedValue.generator());
                    if (identityDialect != null) {
                        generator = identityDialect.getIdentityRetrievalStatement();
                    } else {
                        generator = generatedValue.generator();
                    }
                    entityColumn.setGenerator(generator);
                }
            } else {
                throw new MapperException(entityColumn.getProperty()
                        + "" - 该字段@GeneratedValue配置只允许以下几种形式:"" +
                        ""\n1.useGeneratedKeys的@GeneratedValue(generator=\\\""JDBC\\\"")  "" +
                        ""\n2.类似mysql数据库的@GeneratedValue(strategy=GenerationType.IDENTITY[,generator=\""Mysql\""])"");
            }
        }
    }"
"@Override
    protected void daxpyi(long N, double alpha, INDArray X, DataBuffer pointers, INDArray Y){
        cblas_daxpyi((int) N, alpha, (DoublePointer) X.data().addressPointer(), (IntPointer) pointers.addressPointer(),
                (DoublePointer) Y.data().addressPointer());
    }"
"void setListBytes(byte[] publicSuffixListBytes, byte[] publicSuffixExceptionListBytes) {
    this.publicSuffixListBytes = publicSuffixListBytes;
    this.publicSuffixExceptionListBytes = publicSuffixExceptionListBytes;
    listRead.set(true);
    readCompleteLatch.countDown();
  }"
"public static int writeAscii(ByteBuf buf, CharSequence seq) {
        // ASCII uses 1 byte per char
        final int len = seq.length();
        if (seq instanceof AsciiString) {
            AsciiString asciiString = (AsciiString) seq;
            buf.writeBytes(asciiString.array(), asciiString.arrayOffset(), len);
        } else {
            for (;;) {
                if (buf instanceof WrappedCompositeByteBuf) {
                    // WrappedCompositeByteBuf is a sub-class of AbstractByteBuf so it needs special handling.
                    buf = buf.unwrap();
                } else if (buf instanceof AbstractByteBuf) {
                    AbstractByteBuf byteBuf = (AbstractByteBuf) buf;
                    byteBuf.ensureWritable0(len);
                    int written = writeAscii(byteBuf, byteBuf.writerIndex, seq, len);
                    byteBuf.writerIndex += written;
                    return written;
                } else if (buf instanceof WrappedByteBuf) {
                    // Unwrap as the wrapped buffer may be an AbstractByteBuf and so we can use fast-path.
                    buf = buf.unwrap();
                } else {
                    byte[] bytes = seq.toString().getBytes(CharsetUtil.US_ASCII);
                    buf.writeBytes(bytes);
                    return bytes.length;
                }
            }
        }
        return len;
    }"
"public double density(double x) {
        if (means != null)
            throw new IllegalStateException(""Unable to sample from more than one mean"");
        final double x0 = x - mean;
        final double x1 = x0 / standardDeviation;
        return FastMath.exp(-0.5 * x1 * x1) / (standardDeviation * SQRT2PI);
    }"
"public static void deregister(@Nonnull Item item) {
        ItemDeletion instance = instance();
        if (instance != null) {
            instance.lock.writeLock().lock();
            try {
                instance.registrations.remove(item);
            } finally {
                instance.lock.writeLock().unlock();
            }
        }
    }"
"public static <T> T invokeConstructor(final Class<T> cls, Object... args) {
		try {
			return ConstructorUtils.invokeConstructor(cls, args);
		} catch (Exception e) {
			throw ExceptionUtil.unwrapAndUnchecked(e);
		}
	}"
"public int decrementAndGet(Object key)
    {
        long hashCode = getHashCode(key);
        int previousCount = addTo(hashCode, -1);
        if (previousCount == 1) {
            remove(hashCode);
        }
        return previousCount - 1;
    }"
"public SQLStatement parse(final boolean useCache) {
        Optional<SQLStatement> cachedSQLStatement = getSQLStatementFromCache(useCache);
        if (cachedSQLStatement.isPresent()) {
            return cachedSQLStatement.get();
        }
        LexerEngine lexerEngine = LexerEngineFactory.newInstance(dbType, sql);
        SQLStatement result = SQLParserFactory.newInstance(dbType, shardingRule, lexerEngine, shardingTableMetaData, sql).parse();
        if (useCache) {
            parsingResultCache.put(sql, result);
        }
        return result;
    }"
"public DnsNameResolverBuilder searchDomains(Iterable<String> searchDomains) {
        checkNotNull(searchDomains, ""searchDomains"");

        final List<String> list = new ArrayList<String>(4);

        for (String f : searchDomains) {
            if (f == null) {
                break;
            }

            // Avoid duplicate entries.
            if (list.contains(f)) {
                continue;
            }

            list.add(f);
        }

        this.searchDomains = list.toArray(new String[0]);
        return this;
    }"
"public void resetCompleters() {
        final ConsoleReader reader = getReader();
        if (reader != null) {
            Collection<Completer> completers = reader.getCompleters();
            for (Completer completer : completers) {
                reader.removeCompleter(completer);
            }

            // for some unknown reason / bug in JLine you have to iterate over twice to clear the completers (WTF)
            completers = reader.getCompleters();
            for (Completer completer : completers) {
                reader.removeCompleter(completer);
            }
        }
    }"
"static void handleClientDisconnect(H2ONode client) {
    if(client != H2O.SELF) {
      if (H2O.isFlatfileEnabled()) {
        H2O.removeNodeFromFlatfile(client);
      }
      H2O.removeClient(client);
    }
  }"
"public SortedMap<Integer, RangeSet> getRelationship(AbstractProject that) {
        TreeMap<Integer,RangeSet> r = new TreeMap<Integer,RangeSet>(REVERSE_INTEGER_COMPARATOR);

        checkAndRecord(that, r, this.getBuilds());
        // checkAndRecord(that, r, that.getBuilds());

        return r;
    }"
"private SingleOutputStreamOperator<T> setResources(ResourceSpec resources) {
		Preconditions.checkNotNull(resources, ""The resources must be not null."");
		Preconditions.checkArgument(resources.isValid(), ""The values in resources must be not less than 0."");

		transformation.setResources(resources, resources);

		return this;
	}"
"public static <T> T validateNull(T value, String errorMsgTemplate, Object... params) throws ValidateException {
		if (isNotNull(value)) {
			throw new ValidateException(errorMsgTemplate, params);
		}
		return value;
	}"
"void adjustCompleteIndicatorColumnRowNumbers(BarcodeMetadata barcodeMetadata) {
    Codeword[] codewords = getCodewords();
    setRowNumbers();
    removeIncorrectCodewords(codewords, barcodeMetadata);
    BoundingBox boundingBox = getBoundingBox();
    ResultPoint top = isLeft ? boundingBox.getTopLeft() : boundingBox.getTopRight();
    ResultPoint bottom = isLeft ? boundingBox.getBottomLeft() : boundingBox.getBottomRight();
    int firstRow = imageRowToCodewordIndex((int) top.getY());
    int lastRow = imageRowToCodewordIndex((int) bottom.getY());
    // We need to be careful using the average row height. Barcode could be skewed so that we have smaller and
    // taller rows
    //float averageRowHeight = (lastRow - firstRow) / (float) barcodeMetadata.getRowCount();
    int barcodeRow = -1;
    int maxRowHeight = 1;
    int currentRowHeight = 0;
    for (int codewordsRow = firstRow; codewordsRow < lastRow; codewordsRow++) {
      if (codewords[codewordsRow] == null) {
        continue;
      }
      Codeword codeword = codewords[codewordsRow];

      //      float expectedRowNumber = (codewordsRow - firstRow) / averageRowHeight;
      //      if (Math.abs(codeword.getRowNumber() - expectedRowNumber) > 2) {
      //        SimpleLog.log(LEVEL.WARNING,
      //            ""Removing codeword, rowNumberSkew too high, codeword["" + codewordsRow + ""]: Expected Row: "" +
      //                expectedRowNumber + "", RealRow: "" + codeword.getRowNumber() + "", value: "" + codeword.getValue());
      //        codewords[codewordsRow] = null;
      //      }

      int rowDifference = codeword.getRowNumber() - barcodeRow;

      // TODO improve handling with case where first row indicator doesn't start with 0

      if (rowDifference == 0) {
        currentRowHeight++;
      } else if (rowDifference == 1) {
        maxRowHeight = Math.max(maxRowHeight, currentRowHeight);
        currentRowHeight = 1;
        barcodeRow = codeword.getRowNumber();
      } else if (rowDifference < 0 ||
                 codeword.getRowNumber() >= barcodeMetadata.getRowCount() ||
                 rowDifference > codewordsRow) {
        codewords[codewordsRow] = null;
      } else {
        int checkedRows;
        if (maxRowHeight > 2) {
          checkedRows = (maxRowHeight - 2) * rowDifference;
        } else {
          checkedRows = rowDifference;
        }
        boolean closePreviousCodewordFound = checkedRows >= codewordsRow;
        for (int i = 1; i <= checkedRows && !closePreviousCodewordFound; i++) {
          // there must be (height * rowDifference) number of codewords missing. For now we assume height = 1.
          // This should hopefully get rid of most problems already.
          closePreviousCodewordFound = codewords[codewordsRow - i] != null;
        }
        if (closePreviousCodewordFound) {
          codewords[codewordsRow] = null;
        } else {
          barcodeRow = codeword.getRowNumber();
          currentRowHeight = 1;
        }
      }
    }
    //return (int) (averageRowHeight + 0.5);
  }"
"public JSONArray getJSONArray(int index) throws JSONException {
    Object o = get(index);
    if (o instanceof JSONArray) {
      return (JSONArray) o;
    }
    throw new JSONException(""JSONArray["" + index + ""] is not a JSONArray."");
  }"
"protected void processField(EntityTable entityTable, EntityField field, Config config, Style style) {
        //排除字段
        if (field.isAnnotationPresent(Transient.class)) {
            return;
        }
        //Id
        EntityColumn entityColumn = new EntityColumn(entityTable);
        //是否使用 {xx, javaType=xxx}
        entityColumn.setUseJavaType(config.isUseJavaType());
        //记录 field 信息，方便后续扩展使用
        entityColumn.setEntityField(field);
        if (field.isAnnotationPresent(Id.class)) {
            entityColumn.setId(true);
        }
        //Column
        String columnName = null;
        if (field.isAnnotationPresent(Column.class)) {
            Column column = field.getAnnotation(Column.class);
            columnName = column.name();
            entityColumn.setUpdatable(column.updatable());
            entityColumn.setInsertable(column.insertable());
        }
        //ColumnType
        if (field.isAnnotationPresent(ColumnType.class)) {
            ColumnType columnType = field.getAnnotation(ColumnType.class);
            //是否为 blob 字段
            entityColumn.setBlob(columnType.isBlob());
            //column可以起到别名的作用
            if (StringUtil.isEmpty(columnName) && StringUtil.isNotEmpty(columnType.column())) {
                columnName = columnType.column();
            }
            if (columnType.jdbcType() != JdbcType.UNDEFINED) {
                entityColumn.setJdbcType(columnType.jdbcType());
            }
            if (columnType.typeHandler() != UnknownTypeHandler.class) {
                entityColumn.setTypeHandler(columnType.typeHandler());
            }
        }
        //列名
        if (StringUtil.isEmpty(columnName)) {
            columnName = StringUtil.convertByStyle(field.getName(), style);
        }
        //自动处理关键字
        if (StringUtil.isNotEmpty(config.getWrapKeyword()) && SqlReservedWords.containsWord(columnName)) {
            columnName = MessageFormat.format(config.getWrapKeyword(), columnName);
        }
        entityColumn.setProperty(field.getName());
        entityColumn.setColumn(columnName);
        entityColumn.setJavaType(field.getJavaType());
        if (field.getJavaType().isPrimitive()) {
            log.warn(""通用 Mapper 警告信息: <["" + entityColumn + ""]> 使用了基本类型，基本类型在动态 SQL 中由于存在默认值，因此任何时候都不等于 null，建议修改基本类型为对应的包装类型!"");
        }
        //OrderBy
        processOrderBy(entityTable, field, entityColumn);
        //处理主键策略
        processKeyGenerator(entityTable, field, entityColumn);
        entityTable.getEntityClassColumns().add(entityColumn);
        if (entityColumn.isId()) {
            entityTable.getEntityClassPKColumns().add(entityColumn);
        }
    }"
"public static PrivateKey generatePrivateKey(String algorithm, byte[] key) {
		if (null == key) {
			return null;
		}
		return generatePrivateKey(algorithm, new PKCS8EncodedKeySpec(key));
	}"
"public boolean nextBoolean() throws IOException {
    int p = peeked;
    if (p == PEEKED_NONE) {
      p = doPeek();
    }
    if (p == PEEKED_TRUE) {
      peeked = PEEKED_NONE;
      pathIndices[stackSize - 1]++;
      return true;
    } else if (p == PEEKED_FALSE) {
      peeked = PEEKED_NONE;
      pathIndices[stackSize - 1]++;
      return false;
    }
    throw new IllegalStateException(""Expected a boolean but was "" + peek() + locationString());
  }"
"private Request createTunnel(int readTimeout, int writeTimeout, Request tunnelRequest,
      HttpUrl url) throws IOException {
    // Make an SSL Tunnel on the first message pair of each SSL + proxy connection.
    String requestLine = ""CONNECT "" + Util.hostHeader(url, true) + "" HTTP/1.1"";
    while (true) {
      Http1ExchangeCodec tunnelCodec = new Http1ExchangeCodec(null, null, source, sink);
      source.timeout().timeout(readTimeout, MILLISECONDS);
      sink.timeout().timeout(writeTimeout, MILLISECONDS);
      tunnelCodec.writeRequest(tunnelRequest.headers(), requestLine);
      tunnelCodec.finishRequest();
      Response response = tunnelCodec.readResponseHeaders(false)
          .request(tunnelRequest)
          .build();
      tunnelCodec.skipConnectBody(response);

      switch (response.code()) {
        case HTTP_OK:
          // Assume the server won't send a TLS ServerHello until we send a TLS ClientHello. If
          // that happens, then we will have buffered bytes that are needed by the SSLSocket!
          // This check is imperfect: it doesn't tell us whether a handshake will succeed, just
          // that it will almost certainly fail because the proxy has sent unexpected data.
          if (!source.getBuffer().exhausted() || !sink.buffer().exhausted()) {
            throw new IOException(""TLS tunnel buffered too many bytes!"");
          }
          return null;

        case HTTP_PROXY_AUTH:
          tunnelRequest = route.address().proxyAuthenticator().authenticate(route, response);
          if (tunnelRequest == null) throw new IOException(""Failed to authenticate with proxy"");

          if (""close"".equalsIgnoreCase(response.header(""Connection""))) {
            return tunnelRequest;
          }
          break;

        default:
          throw new IOException(
              ""Unexpected response code for CONNECT: "" + response.code());
      }
    }
  }"
"public static boolean isFileURL(URL url) {
        String protocol = url.getProtocol();
        return (URL_PROTOCOL_FILE.equals(protocol) || protocol.startsWith(URL_PROTOCOL_VFS));
    }"
"private static Optional<Class> resolveSingleTypeArgument(Type genericType) {
        if (genericType instanceof ParameterizedType) {
            ParameterizedType pt = (ParameterizedType) genericType;
            Type[] actualTypeArguments = pt.getActualTypeArguments();
            if (actualTypeArguments.length == 1) {
                Type actualTypeArgument = actualTypeArguments[0];
                return resolveParameterizedTypeArgument(actualTypeArgument);
            }
        }
        return Optional.empty();
    }"
"public static String encode(String url, String charset) throws UtilException {
		if (StrUtil.isEmpty(url)) {
			return url;
		}
		return encode(url, StrUtil.isBlank(charset) ? CharsetUtil.defaultCharset() : CharsetUtil.charset(charset));
	}"
"public boolean getBoolean(String key, boolean defaultValue) {
		addToDefaults(key, Boolean.toString(defaultValue));
		String value = get(key);
		if (value == null) {
			return defaultValue;
		} else {
			return Boolean.valueOf(value);
		}
	}"
"public void show(Node node, PopupVPosition vAlign, PopupHPosition hAlign, double initOffsetX, double initOffsetY) {
        if (!isShowing()) {
            if (node.getScene() == null || node.getScene().getWindow() == null) {
                throw new IllegalStateException(""Can not show popup. The node must be attached to a scene/window."");
            }
            Window parent = node.getScene().getWindow();
            final Point2D origin = node.localToScene(0, 0);
            final double anchorX = parent.getX() + origin.getX()
                + node.getScene().getX() + (hAlign == PopupHPosition.RIGHT ? ((Region) node).getWidth() : 0);
            final double anchorY = parent.getY() + origin.getY()
                + node.getScene()
                      .getY() + (vAlign == PopupVPosition.BOTTOM ? ((Region) node).getHeight() : 0);
            this.show(parent, anchorX, anchorY);
            ((JFXPopupSkin) getSkin()).reset(vAlign, hAlign, initOffsetX, initOffsetY);
            Platform.runLater(() -> ((JFXPopupSkin) getSkin()).animate());
        }
    }"
"@Deprecated
    public static void setDateHeader(HttpMessage message, String name, Iterable<Date> values) {
        message.headers().set(name, values);
    }"
"@SuppressWarnings(""unchecked"")
	public static <T extends Savepoint> SavepointSerializer<T> getSerializer(T savepoint) {
		Preconditions.checkNotNull(savepoint, ""Savepoint"");
		SavepointSerializer<T> serializer = (SavepointSerializer<T>) SERIALIZERS.get(savepoint.getVersion());
		if (serializer != null) {
			return serializer;
		} else {
			throw new IllegalArgumentException(""Unknown savepoint version "" + savepoint.getVersion() + ""."");
		}
	}"
"public void close(C1NChunk c, int cidx, Futures fs) {
    assert _len==-1;            // Not closed
    c._vec = this;              // Attach chunk to this vec.
    DKV.put(chunkKey(cidx),c,fs); // Write updated chunk back into K/V
    long l = _nchunks-1L;
    _len = l*_chunkSize +c._len;
  }"
"public void importVocabulary(@NonNull VocabCache<T> vocabCache) {
        AtomicBoolean added = new AtomicBoolean(false);
        for (T element : vocabCache.vocabWords()) {
            if (this.addToken(element))
                added.set(true);
        }
        //logger.info(""Current state: {}; Adding value: {}"", this.documentsCounter.get(), vocabCache.totalNumberOfDocs());
        if (added.get())
            this.documentsCounter.addAndGet(vocabCache.totalNumberOfDocs());
    }"
"public void write_ref(final String node, final int id, final int creation) {
	/* Always encode as an extended reference; all
	   participating parties are now expected to be
	   able to decode extended references. */
	int ids[] = new int[1];
	ids[0] = id;
	write_ref(node, ids, creation);
    }"
"private void addStringStatistics(long valueCount, StringStatistics value)
    {
        requireNonNull(value, ""value is null"");
        checkArgument(valueCount > 0, ""valueCount is 0"");
        checkArgument(value.getMin() != null || value.getMax() != null, ""min and max cannot both be null"");

        if (nonNullValueCount == 0) {
            checkState(minimum == null && maximum == null);
            minimum = value.getMin();
            maximum = value.getMax();
        }
        else {
            if (minimum != null && (value.getMin() == null || minimum.compareTo(value.getMin()) > 0)) {
                minimum = value.getMin();
            }
            if (maximum != null && (value.getMax() == null || maximum.compareTo(value.getMax()) < 0)) {
                maximum = value.getMax();
            }
        }

        nonNullValueCount += valueCount;
        sum = addExact(sum, value.getSum());
    }"
"private void computeScore(Sentence sentence, SmartForest<Double> forest) {
        SmartGetWord<Double> sgw = new SmartGetWord<>(forest, sentence.value);
        String name = null;
        while ((name = sgw.getFrontWords()) != null) {
            sentence.updateScore(name, sgw.getParam());
        }
        if (sentence.score == 0) {
            sentence.score = sentence.value.length() * -0.005;
        } else {
            sentence.score /= Math.log(sentence.value.length() + 3);
        }
    }"
"public static int getNumFrames(byte[] fingerprint) {

        if (fingerprint.length < 8) {
            return 0;
        }

        // get the last x-coordinate (length-8&length-7)bytes from fingerprint
        return ((fingerprint[fingerprint.length - 8] & 0xff) << 8 | (fingerprint[fingerprint.length - 7] & 0xff)) + 1;
    }"
"public AllWindowedStream<T, GlobalWindow> countWindowAll(long size, long slide) {
		return windowAll(GlobalWindows.create())
				.evictor(CountEvictor.of(size))
				.trigger(CountTrigger.of(slide));
	}"
"public void setLocked(boolean locked) {
		if (ap == null) {
			return;
		}
		ap.setLocked(locked);
		btnPin.setVisible(! locked);
		if (!ap.isPinned()) {
			// Wont be visible if its pinned
			btnClose.setVisible(! locked);
		}
	}"
"@Deprecated
    public DomainNameMapping<V> add(String hostname, V output) {
        map.put(normalizeHostname(checkNotNull(hostname, ""hostname"")), checkNotNull(output, ""output""));
        return this;
    }"
"private boolean applySnapshotToDB(EntryPosition position, boolean init) {
        // 获取一份快照
        Map<String, String> schemaDdls = null;
        lock.readLock().lock();
        try {
            if (!init && !hasNewDdl) {
                // 如果是持续构建,则识别一下是否有DDL变更过,如果没有就忽略了
                return false;
            }
            this.hasNewDdl = false;
            schemaDdls = memoryTableMeta.snapshot();
        } finally {
            lock.readLock().unlock();
        }

        MemoryTableMeta tmpMemoryTableMeta = new MemoryTableMeta();
        for (Map.Entry<String, String> entry : schemaDdls.entrySet()) {
            tmpMemoryTableMeta.apply(position, entry.getKey(), entry.getValue(), null);
        }

        // 基于临时内存对象进行对比
        boolean compareAll = true;
        for (Schema schema : tmpMemoryTableMeta.getRepository().getSchemas()) {
            for (String table : schema.showTables()) {
                String fullName = schema + ""."" + table;
                if (blackFilter == null || !blackFilter.filter(fullName)) {
                    if (filter == null || filter.filter(fullName)) {
                        // issue : https://github.com/alibaba/canal/issues/1168
                        // 在生成snapshot时重新过滤一遍
                        if (!compareTableMetaDbAndMemory(connection, tmpMemoryTableMeta, schema.getName(), table)) {
                            compareAll = false;
                        }
                    }
                }
            }
        }

        if (compareAll) {
            Map<String, String> content = new HashMap<String, String>();
            content.put(""destination"", destination);
            content.put(""binlogFile"", position.getJournalName());
            content.put(""binlogOffest"", String.valueOf(position.getPosition()));
            content.put(""binlogMasterId"", String.valueOf(position.getServerId()));
            content.put(""binlogTimestamp"", String.valueOf(position.getTimestamp()));
            content.put(""data"", JSON.toJSONString(schemaDdls));
            if (content.isEmpty()) {
                throw new RuntimeException(""apply failed caused by content is empty in applySnapshotToDB"");
            }

            MetaSnapshotDO snapshotDO = new MetaSnapshotDO();
            try {
                BeanUtils.populate(snapshotDO, content);
                metaSnapshotDAO.insert(snapshotDO);
            } catch (Throwable e) {
                if (isUkDuplicateException(e)) {
                    // 忽略掉重复的位点
                    logger.info(""dup apply snapshot use position : "" + position + "" , just ignore"");
                } else {
                    throw new CanalParseException(""apply failed caused by : "" + e.getMessage(), e);
                }
            }
            return true;
        } else {
            logger.error(""compare failed , check log"");
        }
        return false;
    }"
"public static MesosConfiguration createMesosSchedulerConfiguration(Configuration flinkConfig, String hostname) {

		Protos.FrameworkInfo.Builder frameworkInfo = Protos.FrameworkInfo.newBuilder()
			.setHostname(hostname);
		Protos.Credential.Builder credential = null;

		if (!flinkConfig.contains(MesosOptions.MASTER_URL)) {
			throw new IllegalConfigurationException(MesosOptions.MASTER_URL.key() + "" must be configured."");
		}
		String masterUrl = flinkConfig.getString(MesosOptions.MASTER_URL);

		Duration failoverTimeout = FiniteDuration.apply(
			flinkConfig.getInteger(
				MesosOptions.FAILOVER_TIMEOUT_SECONDS),
				TimeUnit.SECONDS);
		frameworkInfo.setFailoverTimeout(failoverTimeout.toSeconds());

		frameworkInfo.setName(flinkConfig.getString(
			MesosOptions.RESOURCEMANAGER_FRAMEWORK_NAME));

		frameworkInfo.setRole(flinkConfig.getString(
			MesosOptions.RESOURCEMANAGER_FRAMEWORK_ROLE));

		frameworkInfo.setUser(flinkConfig.getString(
			MesosOptions.RESOURCEMANAGER_FRAMEWORK_USER));

		if (flinkConfig.contains(MesosOptions.RESOURCEMANAGER_FRAMEWORK_PRINCIPAL)) {
			frameworkInfo.setPrincipal(flinkConfig.getString(
				MesosOptions.RESOURCEMANAGER_FRAMEWORK_PRINCIPAL));

			credential = Protos.Credential.newBuilder();
			credential.setPrincipal(frameworkInfo.getPrincipal());

			// some environments use a side-channel to communicate the secret to Mesos,
			// and thus don't set the 'secret' configuration setting
			if (flinkConfig.contains(MesosOptions.RESOURCEMANAGER_FRAMEWORK_SECRET)) {
				credential.setSecret(flinkConfig.getString(
					MesosOptions.RESOURCEMANAGER_FRAMEWORK_SECRET));
			}
		}

		MesosConfiguration mesos =
			new MesosConfiguration(masterUrl, frameworkInfo, scala.Option.apply(credential));

		return mesos;
	}"
"public StyleSet setAlign(HorizontalAlignment halign, VerticalAlignment valign) {
		StyleUtil.setAlign(this.headCellStyle, halign, valign);
		StyleUtil.setAlign(this.cellStyle, halign, valign);
		StyleUtil.setAlign(this.cellStyleForNumber, halign, valign);
		StyleUtil.setAlign(this.cellStyleForDate, halign, valign);
		return this;
	}"
"@Override
	@SuppressWarnings(""unchecked"")
	public void initialize() throws Exception {
		
		final TypeComparator<IT2> solutionSetComparator;
		
		// grab a handle to the hash table from the iteration broker
		if (taskContext instanceof AbstractIterativeTask) {
			AbstractIterativeTask<?, ?> iterativeTaskContext = (AbstractIterativeTask<?, ?>) taskContext;
			String identifier = iterativeTaskContext.brokerKey();
			Object table = SolutionSetBroker.instance().get(identifier);
			
			if (table instanceof CompactingHashTable) {
				this.hashTable = (CompactingHashTable<IT2>) table;
				solutionSetSerializer = this.hashTable.getBuildSideSerializer();
				solutionSetComparator = this.hashTable.getBuildSideComparator().duplicate();
			}
			else if (table instanceof JoinHashMap) {
				this.objectMap = (JoinHashMap<IT2>) table;
				solutionSetSerializer = this.objectMap.getBuildSerializer();
				solutionSetComparator = this.objectMap.getBuildComparator().duplicate();
			}
			else {
				throw new RuntimeException(""Unrecognized solution set index: "" + table);
			}
		}
		else {
			throw new Exception(""The task context of this driver is no iterative task context."");
		}
		
		TaskConfig config = taskContext.getTaskConfig();
		ClassLoader classLoader = taskContext.getUserCodeClassLoader();
		
		TypeComparatorFactory<IT1> probeSideComparatorFactory = config.getDriverComparator(0, classLoader); 
		
		this.probeSideSerializer = taskContext.<IT1>getInputSerializer(0).getSerializer();
		this.probeSideComparator = probeSideComparatorFactory.createComparator();

		ExecutionConfig executionConfig = taskContext.getExecutionConfig();
		objectReuseEnabled = executionConfig.isObjectReuseEnabled();

		if (objectReuseEnabled) {
			solutionSideRecord = solutionSetSerializer.createInstance();
		};
		
		TypePairComparatorFactory<IT1, IT2> factory = taskContext.getTaskConfig().getPairComparatorFactory(taskContext.getUserCodeClassLoader());
		pairComparator = factory.createComparator12(this.probeSideComparator, solutionSetComparator);
	}"
"void saveScript() throws IOException {
		// We'll always try to read it in with the default next time its loaded
		this.charset = ExtensionScript.DEFAULT_CHARSET;
		try ( BufferedWriter bw = Files.newBufferedWriter(file.toPath(), charset)) {
			bw.append(getContents());
		}
		this.lastModified = file.lastModified();
	}"
"public static double perfectAUC( Vec vprob, Vec vacts ) {
    if( vacts.min() < 0 || vacts.max() > 1 || !vacts.isInt() )
      throw new IllegalArgumentException(""Actuals are either 0 or 1"");
    if( vprob.min() < 0 || vprob.max() > 1 )
      throw new IllegalArgumentException(""Probabilities are between 0 and 1"");
    // Horrible data replication into array of structs, to sort.  
    Pair[] ps = new Pair[(int)vprob.length()];
    Vec.Reader rprob = vprob.new Reader();
    Vec.Reader racts = vacts.new Reader();
    for( int i=0; i<ps.length; i++ )
      ps[i] = new Pair(rprob.at(i),(byte)racts.at8(i));
    return perfectAUC(ps);
  }"
"public @CheckForNull Plugin getPlugin() {
        PluginInstanceStore pis = Jenkins.lookup(PluginInstanceStore.class);
        return pis != null ? pis.store.get(this) : null;
    }"
"private void ensureNodeVisible(TreePath nodePath) {
        Rectangle bounds = getTreeParam().getPathBounds(nodePath);
        if (!getTreeParam().getVisibleRect().contains(bounds)) {
            // Just do vertical scrolling.
            bounds.x = 0;
            getTreeParam().scrollRectToVisible(bounds);
        }
    }"
"public static InetAddress findConnectingAddress(InetSocketAddress targetAddress,
							long maxWaitMillis, long startLoggingAfter) throws IOException {
		if (targetAddress == null) {
			throw new NullPointerException(""targetAddress must not be null"");
		}
		if (maxWaitMillis <= 0) {
			throw new IllegalArgumentException(""Max wait time must be positive"");
		}

		final long startTimeNanos = System.nanoTime();

		long currentSleepTime = MIN_SLEEP_TIME;
		long elapsedTimeMillis = 0;

		final List<AddressDetectionState> strategies = Collections.unmodifiableList(
			Arrays.asList(
				AddressDetectionState.LOCAL_HOST,
				AddressDetectionState.ADDRESS,
				AddressDetectionState.FAST_CONNECT,
				AddressDetectionState.SLOW_CONNECT));

		// loop while there is time left
		while (elapsedTimeMillis < maxWaitMillis) {
			boolean logging = elapsedTimeMillis >= startLoggingAfter;
			if (logging) {
				LOG.info(""Trying to connect to "" + targetAddress);
			}

			// Try each strategy in order
			for (AddressDetectionState strategy : strategies) {
				InetAddress address = findAddressUsingStrategy(strategy, targetAddress, logging);
				if (address != null) {
					return address;
				}
			}

			// we have made a pass with all strategies over all interfaces
			// sleep for a while before we make the next pass
			elapsedTimeMillis = (System.nanoTime() - startTimeNanos) / 1_000_000;

			long toWait = Math.min(maxWaitMillis - elapsedTimeMillis, currentSleepTime);
			if (toWait > 0) {
				if (logging) {
					LOG.info(""Could not connect. Waiting for {} msecs before next attempt"", toWait);
				} else {
					LOG.debug(""Could not connect. Waiting for {} msecs before next attempt"", toWait);
				}

				try {
					Thread.sleep(toWait);
				}
				catch (InterruptedException e) {
					throw new IOException(""Connection attempts have been interrupted."");
				}
			}

			// increase the exponential backoff timer
			currentSleepTime = Math.min(2 * currentSleepTime, MAX_SLEEP_TIME);
		}

		// our attempts timed out. use the heuristic fallback
		LOG.warn(""Could not connect to {}. Selecting a local address using heuristics."", targetAddress);
		InetAddress heuristic = findAddressUsingStrategy(AddressDetectionState.HEURISTIC, targetAddress, true);
		if (heuristic != null) {
			return heuristic;
		}
		else {
			LOG.warn(""Could not find any IPv4 address that is not loopback or link-local. Using localhost address."");
			return InetAddress.getLocalHost();
		}
	}"
"public static CharsetEncoder encoder(Charset charset, CodingErrorAction codingErrorAction) {
        return encoder(charset, codingErrorAction, codingErrorAction);
    }"
"public static CheckpointStatistics generateCheckpointStatistics(AbstractCheckpointStats checkpointStats, boolean includeTaskCheckpointStatistics) {
		Preconditions.checkNotNull(checkpointStats);

		Map<JobVertexID, TaskCheckpointStatistics> checkpointStatisticsPerTask;

		if (includeTaskCheckpointStatistics) {
			Collection<TaskStateStats> taskStateStats = checkpointStats.getAllTaskStateStats();

			checkpointStatisticsPerTask = new HashMap<>(taskStateStats.size());

			for (TaskStateStats taskStateStat : taskStateStats) {
				checkpointStatisticsPerTask.put(
					taskStateStat.getJobVertexId(),
					new TaskCheckpointStatistics(
							checkpointStats.getCheckpointId(),
							checkpointStats.getStatus(),
						taskStateStat.getLatestAckTimestamp(),
						taskStateStat.getStateSize(),
						taskStateStat.getEndToEndDuration(checkpointStats.getTriggerTimestamp()),
						taskStateStat.getAlignmentBuffered(),
						taskStateStat.getNumberOfSubtasks(),
						taskStateStat.getNumberOfAcknowledgedSubtasks()));
			}
		} else {
			checkpointStatisticsPerTask = Collections.emptyMap();
		}

		if (checkpointStats instanceof CompletedCheckpointStats) {
			final CompletedCheckpointStats completedCheckpointStats = ((CompletedCheckpointStats) checkpointStats);

			return new CheckpointStatistics.CompletedCheckpointStatistics(
				completedCheckpointStats.getCheckpointId(),
				completedCheckpointStats.getStatus(),
				completedCheckpointStats.getProperties().isSavepoint(),
				completedCheckpointStats.getTriggerTimestamp(),
				completedCheckpointStats.getLatestAckTimestamp(),
				completedCheckpointStats.getStateSize(),
				completedCheckpointStats.getEndToEndDuration(),
				completedCheckpointStats.getAlignmentBuffered(),
				completedCheckpointStats.getNumberOfSubtasks(),
				completedCheckpointStats.getNumberOfAcknowledgedSubtasks(),
				checkpointStatisticsPerTask,
				completedCheckpointStats.getExternalPath(),
				completedCheckpointStats.isDiscarded());
		} else if (checkpointStats instanceof FailedCheckpointStats) {
			final FailedCheckpointStats failedCheckpointStats = ((FailedCheckpointStats) checkpointStats);

			return new CheckpointStatistics.FailedCheckpointStatistics(
				failedCheckpointStats.getCheckpointId(),
				failedCheckpointStats.getStatus(),
				failedCheckpointStats.getProperties().isSavepoint(),
				failedCheckpointStats.getTriggerTimestamp(),
				failedCheckpointStats.getLatestAckTimestamp(),
				failedCheckpointStats.getStateSize(),
				failedCheckpointStats.getEndToEndDuration(),
				failedCheckpointStats.getAlignmentBuffered(),
				failedCheckpointStats.getNumberOfSubtasks(),
				failedCheckpointStats.getNumberOfAcknowledgedSubtasks(),
				checkpointStatisticsPerTask,
				failedCheckpointStats.getFailureTimestamp(),
				failedCheckpointStats.getFailureMessage());
		} else if (checkpointStats instanceof PendingCheckpointStats) {
			final PendingCheckpointStats pendingCheckpointStats = ((PendingCheckpointStats) checkpointStats);

			return new CheckpointStatistics.PendingCheckpointStatistics(
				pendingCheckpointStats.getCheckpointId(),
				pendingCheckpointStats.getStatus(),
				pendingCheckpointStats.getProperties().isSavepoint(),
				pendingCheckpointStats.getTriggerTimestamp(),
				pendingCheckpointStats.getLatestAckTimestamp(),
				pendingCheckpointStats.getStateSize(),
				pendingCheckpointStats.getEndToEndDuration(),
				pendingCheckpointStats.getAlignmentBuffered(),
				pendingCheckpointStats.getNumberOfSubtasks(),
				pendingCheckpointStats.getNumberOfAcknowledgedSubtasks(),
				checkpointStatisticsPerTask
			);
		} else {
			throw new IllegalArgumentException(""Given checkpoint stats object of type ""
				+ checkpointStats.getClass().getName() + "" cannot be converted."");
		}
	}"
"public double optDouble(String name, double fallback) {
		Object object = opt(name);
		Double result = JSON.toDouble(object);
		return result != null ? result : fallback;
	}"
"public <T> Graph<K, VV, EV> joinWithEdges(DataSet<Tuple3<K, K, T>> inputDataSet,
			final EdgeJoinFunction<EV, T> edgeJoinFunction) {

		DataSet<Edge<K, EV>> resultedEdges = this.getEdges()
				.coGroup(inputDataSet).where(0, 1).equalTo(0, 1)
				.with(new ApplyCoGroupToEdgeValues<>(edgeJoinFunction))
					.name(""Join with edges"");
		return new Graph<>(this.vertices, resultedEdges, this.context);
	}"
"void resize(int size, byte value)
    {
        if (size > _capacity)
        {
            resizeBuf(size);
        }
        while (_size < size)
        {
            _buf[_size++] = value;
        }
    }"
"public static Long positive(@Nullable String role, Long x) {
		if (x.longValue() <= 0) {
			throw new IllegalArgumentException(role + "" ("" + x + "") must be > 0"");
		}
		return x;
	}"
"public SDVariable neq(String name, SDVariable x, double y) {
        validateNumerical(""not equals (neq)"", x);
        SDVariable result = f().neq(x, y);
        return updateVariableNameAndReference(result, name);
    }"
"public T addPyFile(String file) {
    checkNotNull(file, ""file"");
    builder.pyFiles.add(file);
    return self();
  }"
"public static boolean isEncrypted(ByteBuf buffer) {
        if (buffer.readableBytes() < SslUtils.SSL_RECORD_HEADER_LENGTH) {
            throw new IllegalArgumentException(
                    ""buffer must have at least "" + SslUtils.SSL_RECORD_HEADER_LENGTH + "" readable bytes"");
        }
        return getEncryptedPacketLength(buffer, buffer.readerIndex()) != SslUtils.NOT_ENCRYPTED;
    }"
"private void removeHandlerIfActive(ChannelHandlerContext ctx, String name) {
        if (ctx.channel().isActive()) {
            ChannelPipeline pipeline = ctx.pipeline();
            ChannelHandler handler = pipeline.get(name);
            if (handler != null) {
                pipeline.remove(name);
            }
        }
    }"
"public CassandraSink<IN> disableChaining() {
		if (useDataStreamSink) {
			getSinkTransformation().setChainingStrategy(ChainingStrategy.NEVER);
		} else {
			getStreamTransformation().setChainingStrategy(ChainingStrategy.NEVER);
		}
		return this;
	}"
"@Override
    public void flushQueueBlocking() {
        flushQueue();

        val context =((CudaContext) AtomicAllocator.getInstance().getDeviceContext().getContext());

        context.syncSpecialStream();
        context.syncOldStream();
    }"
"public static <T> List<T> popPart(Stack<T> surplusAlaDatas, int partSize) {
		if (isEmpty(surplusAlaDatas)) {
			return null;
		}

		final List<T> currentAlaDatas = new ArrayList<>();
		int size = surplusAlaDatas.size();
		// 切割
		if (size > partSize) {
			for (int i = 0; i < partSize; i++) {
				currentAlaDatas.add(surplusAlaDatas.pop());
			}
		} else {
			for (int i = 0; i < size; i++) {
				currentAlaDatas.add(surplusAlaDatas.pop());
			}
		}
		return currentAlaDatas;
	}"
"@Override
	public void channelActive(final ChannelHandlerContext ctx) throws Exception {
		if (this.ctx == null) {
			this.ctx = ctx;
		}

		super.channelActive(ctx);
	}"
"public static List<String> getServiceUrlsFromConfig(EurekaClientConfig clientConfig, String instanceZone, boolean preferSameZone) {
        List<String> orderedUrls = new ArrayList<String>();
        String region = getRegion(clientConfig);
        String[] availZones = clientConfig.getAvailabilityZones(clientConfig.getRegion());
        if (availZones == null || availZones.length == 0) {
            availZones = new String[1];
            availZones[0] = DEFAULT_ZONE;
        }
        logger.debug(""The availability zone for the given region {} are {}"", region, availZones);
        int myZoneOffset = getZoneOffset(instanceZone, preferSameZone, availZones);

        List<String> serviceUrls = clientConfig.getEurekaServerServiceUrls(availZones[myZoneOffset]);
        if (serviceUrls != null) {
            orderedUrls.addAll(serviceUrls);
        }
        int currentOffset = myZoneOffset == (availZones.length - 1) ? 0 : (myZoneOffset + 1);
        while (currentOffset != myZoneOffset) {
            serviceUrls = clientConfig.getEurekaServerServiceUrls(availZones[currentOffset]);
            if (serviceUrls != null) {
                orderedUrls.addAll(serviceUrls);
            }
            if (currentOffset == (availZones.length - 1)) {
                currentOffset = 0;
            } else {
                currentOffset++;
            }
        }

        if (orderedUrls.size() < 1) {
            throw new IllegalArgumentException(""DiscoveryClient: invalid serviceUrl specified!"");
        }
        return orderedUrls;
    }"
"private static byte[] lmv2Response(final byte[] hash, final byte[] challenge, final byte[] clientData)
            throws AuthenticationException {
        final HMACMD5 hmacMD5 = new HMACMD5(hash);
        hmacMD5.update(challenge);
        hmacMD5.update(clientData);
        final byte[] mac = hmacMD5.getOutput();
        final byte[] lmv2Response = new byte[mac.length + clientData.length];
        System.arraycopy(mac, 0, lmv2Response, 0, mac.length);
        System.arraycopy(clientData, 0, lmv2Response, mac.length, clientData.length);
        return lmv2Response;
    }"
"@ExperimentalApi(""https://github.com/grpc/grpc-java/issues/2563"")
  public CallOptions withMaxInboundMessageSize(int maxSize) {
    checkArgument(maxSize >= 0, ""invalid maxsize %s"", maxSize);
    CallOptions newOptions = new CallOptions(this);
    newOptions.maxInboundMessageSize = maxSize;
    return newOptions;
  }"
"@Deprecated
    protected boolean resolveReplacement(StringBuilder builder, String str, String expr) {
        if (environment.containsProperty(expr)) {
            builder.append(environment.getProperty(expr, String.class).orElseThrow(() -> new ConfigurationException(""Could not resolve placeholder ${"" + expr + ""} in value: "" + str)));
            return true;
        }
        return false;
    }"
"private static Schema schema(int version, String type) {
    Class<? extends Schema> clz = schemaClass(version, type);
    if (clz == null) clz = schemaClass(EXPERIMENTAL_VERSION, type);

    if (clz == null)
      throw new H2ONotFoundArgumentException(""Failed to find schema for version: "" + version + "" and type: "" + type,
          ""Failed to find schema for version: "" + version + "" and type: "" + type + ""\n"" +
          ""Did you forget to add an entry into META-INF/services/water.api.Schema?"");
    return Schema.newInstance(clz);
  }"
"public static Object takeAnd(Object arg1, Object arg2) throws NoSuchMethodException {
        if ((arg1 instanceof Boolean) || (arg2 instanceof Boolean)) {
            if ((arg1 instanceof Boolean) && (arg2 instanceof Boolean))
                return boxToBoolean(((java.lang.Boolean) arg1).booleanValue() & ((java.lang.Boolean) arg2).booleanValue());
            else
                throw new NoSuchMethodException();
        }
        int code1 = typeCode(arg1);
        int code2 = typeCode(arg2);
        int maxcode = (code1 < code2) ? code2 : code1;

        if (maxcode <= INT)
            return boxToInteger(unboxCharOrInt(arg1, code1) & unboxCharOrInt(arg2, code2));
        if (maxcode <= LONG)
            return boxToLong(unboxCharOrLong(arg1, code1) & unboxCharOrLong(arg2, code2));

        throw new NoSuchMethodException();
    }"
"public Object getResponseProp(String key) {
        return responseProps == null ? null : responseProps.get(key);
    }"
"public static void register() {
        if (Main.isUnitTest && JENKINS_LOC == null) {
            mockOff();
            return;
        }
        ClassFilter.setDefault(new ClassFilterImpl());
        if (SUPPRESS_ALL) {
            LOGGER.warning(""All class filtering suppressed. Your Jenkins installation is at risk from known attacks. See https://jenkins.io/redirect/class-filter/"");
        } else if (SUPPRESS_WHITELIST) {
            LOGGER.warning(""JEP-200 class filtering by whitelist suppressed. Your Jenkins installation may be at risk. See https://jenkins.io/redirect/class-filter/"");
        }
    }"
"public static @CheckForNull <T extends Trigger<?>> T getTrigger(Job<?,?> job, Class<T> clazz) {
        if (!(job instanceof ParameterizedJob)) {
            return null;
        }
        for (Trigger<?> t : ((ParameterizedJob<?, ?>) job).getTriggers().values()) {
            if (clazz.isInstance(t)) {
                return clazz.cast(t);
            }
        }
        return null;
    }"
"public static int countLines(InputStream is) throws IOException {
        try {
            byte[] c = new byte[1024];
            int count = 0;
            int readChars = 0;
            boolean empty = true;
            while ((readChars = is.read(c)) != -1) {
                empty = false;
                for (int i = 0; i < readChars; ++i) {
                    if (c[i] == '\n') {
                        ++count;
                    }
                }
            }
            return (count == 0 && !empty) ? 1 : count;
        } finally {
            is.close();
        }


    }"
"private ByteBuf decodeLine(ChannelHandlerContext ctx, ByteBuf buffer) throws Exception {
        final int eol = findEndOfLine(buffer);
        if (!discarding) {
            if (eol >= 0) {
                final int length = eol - buffer.readerIndex();
                if (length > V1_MAX_LENGTH) {
                    buffer.readerIndex(eol + DELIMITER_LENGTH);
                    failOverLimit(ctx, length);
                    return null;
                }
                ByteBuf frame = buffer.readSlice(length);
                buffer.skipBytes(DELIMITER_LENGTH);
                return frame;
            } else {
                final int length = buffer.readableBytes();
                if (length > V1_MAX_LENGTH) {
                    discardedBytes = length;
                    buffer.skipBytes(length);
                    discarding = true;
                    failOverLimit(ctx, ""over "" + discardedBytes);
                }
                return null;
            }
        } else {
            if (eol >= 0) {
                final int delimLength = buffer.getByte(eol) == '\r' ? 2 : 1;
                buffer.readerIndex(eol + delimLength);
                discardedBytes = 0;
                discarding = false;
            } else {
                discardedBytes = buffer.readableBytes();
                buffer.skipBytes(discardedBytes);
            }
            return null;
        }
    }"
"protected void setResultType(MappedStatement ms, Class<?> entityClass) {
        EntityTable entityTable = EntityHelper.getEntityTable(entityClass);
        List<ResultMap> resultMaps = new ArrayList<ResultMap>();
        resultMaps.add(entityTable.getResultMap(ms.getConfiguration()));
        MetaObject metaObject = MetaObjectUtil.forObject(ms);
        metaObject.setValue(""resultMaps"", Collections.unmodifiableList(resultMaps));
    }"
"public static BasicFileAttributes getAttributes(Path path, boolean isFollowLinks) throws IORuntimeException {
		if (null == path) {
			return null;
		}

		final LinkOption[] options = isFollowLinks ? new LinkOption[0] : new LinkOption[] { LinkOption.NOFOLLOW_LINKS };
		try {
			return Files.readAttributes(path, BasicFileAttributes.class, options);
		} catch (IOException e) {
			throw new IORuntimeException(e);
		}
	}"
"public int combine(TFDictionary dictionary, int limit, boolean add)
    {
        int preSize = trie.size();
        for (Map.Entry<String, TermFrequency> entry : dictionary.trie.entrySet())
        {
            TermFrequency termFrequency = trie.get(entry.getKey());
            if (termFrequency == null)
            {
                trie.put(entry.getKey(), new TermFrequency(entry.getKey(), Math.min(limit, entry.getValue().getValue())));
            }
            else
            {
                if (add)
                {
                    termFrequency.setValue(termFrequency.getValue() + Math.min(limit, entry.getValue().getValue()));
                }
            }
        }
        return trie.size() - preSize;
    }"
"public static Model copyWeightsToModel(Model model, Map<String, KerasLayer> kerasLayers)
            throws InvalidKerasConfigurationException {
        /* Get list if layers from model. */
        Layer[] layersFromModel;
        if (model instanceof MultiLayerNetwork)
            layersFromModel = ((MultiLayerNetwork) model).getLayers();
        else
            layersFromModel = ((ComputationGraph) model).getLayers();

        /* Iterate over layers in model, setting weights when relevant. */
        Set<String> layerNames = new HashSet<>(kerasLayers.keySet());
        for (org.deeplearning4j.nn.api.Layer layer : layersFromModel) {
            String layerName = layer.conf().getLayer().getLayerName();
            if (!kerasLayers.containsKey(layerName))
                throw new InvalidKerasConfigurationException(
                        ""No weights found for layer in model (named "" + layerName + "")"");
            kerasLayers.get(layerName).copyWeightsToLayer(layer);
            layerNames.remove(layerName);
        }

        for (String layerName : layerNames) {
            if (kerasLayers.get(layerName).getNumParams() > 0)
                throw new InvalidKerasConfigurationException(
                        ""Attemping to copy weights for layer not in model (named "" + layerName + "")"");
        }
        return model;
    }"
"@SuppressWarnings(""rawtypes"")
	public static HashMap<Object, Object> of(Object[] array) {
		if (array == null) {
			return null;
		}
		final HashMap<Object, Object> map = new HashMap<>((int) (array.length * 1.5));
		for (int i = 0; i < array.length; i++) {
			Object object = array[i];
			if (object instanceof Map.Entry) {
				Map.Entry entry = (Map.Entry) object;
				map.put(entry.getKey(), entry.getValue());
			} else if (object instanceof Object[]) {
				final Object[] entry = (Object[]) object;
				if (entry.length > 1) {
					map.put(entry[0], entry[1]);
				}
			} else if (object instanceof Iterable) {
				Iterator iter = ((Iterable) object).iterator();
				if (iter.hasNext()) {
					final Object key = iter.next();
					if (iter.hasNext()) {
						final Object value = iter.next();
						map.put(key, value);
					}
				}
			} else if (object instanceof Iterator) {
				Iterator iter = ((Iterator) object);
				if (iter.hasNext()) {
					final Object key = iter.next();
					if (iter.hasNext()) {
						final Object value = iter.next();
						map.put(key, value);
					}
				}
			} else {
				throw new IllegalArgumentException(StrUtil.format(""Array element {}, '{}', is not type of Map.Entry or Array or Iterable or Iterator"", i, object));
			}
		}
		return map;
	}"
"public void close() {
		// make sure that we close only once
		if (!this.closed.compareAndSet(false, true)) {
			return;
		}
		
		// clear the iterators, so the next call to next() will notice
		this.bucketIterator = null;
		this.probeIterator = null;
		
		// release the table structure
		releaseTable();
		
		// clear the memory in the partitions
		clearPartitions();
		
		// clear the current probe side channel, if there is one
		if (this.currentSpilledProbeSide != null) {
			try {
				this.currentSpilledProbeSide.closeAndDelete();
			}
			catch (Throwable t) {
				LOG.warn(""Could not close and delete the temp file for the current spilled partition probe side."", t);
			}
		}
		
		// clear the partitions that are still to be done (that have files on disk)
		for (int i = 0; i < this.partitionsPending.size(); i++) {
			final HashPartition<BT, PT> p = this.partitionsPending.get(i);
			p.clearAllMemory(this.availableMemory);
		}
		
		// return the write-behind buffers
		for (int i = 0; i < this.numWriteBehindBuffers + this.writeBehindBuffersAvailable; i++) {
			try {
				this.availableMemory.add(this.writeBehindBuffers.take());
			}
			catch (InterruptedException iex) {
				throw new RuntimeException(""Hashtable closing was interrupted"");
			}
		}
		this.writeBehindBuffersAvailable = 0;
	}"
"public void setEngineValves(Collection<? extends Valve> engineValves) {
		Assert.notNull(engineValves, ""Valves must not be null"");
		this.engineValves = new ArrayList<>(engineValves);
	}"
"@CanIgnoreReturnValue
  ChannelFuture enqueue(QueuedCommand command, boolean flush) {
    // Detect erroneous code that tries to reuse command objects.
    Preconditions.checkArgument(command.promise() == null, ""promise must not be set on command"");

    ChannelPromise promise = channel.newPromise();
    command.promise(promise);
    queue.add(command);
    if (flush) {
      scheduleFlush();
    }
    return promise;
  }"
"public static INDArray cnn1dMaskReduction(INDArray in, int kernel, int stride, int padding, int dilation, ConvolutionMode cm){
        Preconditions.checkState(in.rank()==2, ""Rank must be 2 for cnn1d mask array - shape "", in.shape());
        if(cm == ConvolutionMode.Same && stride == 1 ){
            return in;
        }

        if(!Shape.hasDefaultStridesForShape(in)){
            in = in.dup();
        }

        INDArray reshaped4d = in.reshape(in.size(0), 1, in.size(1), 1);

        int[] outSize;
        int[] pad;
        int[] k = new int[]{kernel,1};
        int[] s = new int[]{stride, 1};
        int[] d = new int[]{dilation, 1};
        if (cm == ConvolutionMode.Same) {
            outSize = ConvolutionUtils.getOutputSize(reshaped4d, k, s, null, cm, d); //Also performs validation
        } else {
            pad = new int[]{padding, 0};
            outSize = ConvolutionUtils.getOutputSize(reshaped4d, k, s, pad, cm, d); //Also performs validation
        }
        int outH = outSize[0];

        INDArray output = Nd4j.createUninitialized(new int[]{(int)in.size(0), 1, outH, 1}, 'c');

        Op op = new LegacyPooling2D(reshaped4d, kernel, 1, stride, 1, padding, 0, dilation, 1,
                cm == ConvolutionMode.Same, LegacyPooling2D.Pooling2DType.MAX, 0.0, output);
        Nd4j.getExecutioner().exec(op);
        return output.reshape('c', in.size(0), outH);
    }"
"public boolean markActive() {
		if (TaskSlotState.ALLOCATED == state || TaskSlotState.ACTIVE == state) {
			state = TaskSlotState.ACTIVE;

			return true;
		} else {
			return false;
		}
	}"
"@SneakyThrows
    public Event terminate(final RequestContext context) {
        val request = WebUtils.getHttpServletRequestFromExternalWebflowContext(context);
        val response = WebUtils.getHttpServletResponseFromExternalWebflowContext(context);

        val tgtId = getTicketGrantingTicket(context);
        if (StringUtils.isNotBlank(tgtId)) {
            LOGGER.trace(""Destroying SSO session linked to ticket-granting ticket [{}]"", tgtId);
            val logoutRequests = this.centralAuthenticationService.destroyTicketGrantingTicket(tgtId);
            WebUtils.putLogoutRequests(context, logoutRequests);
        }
        LOGGER.trace(""Removing CAS cookies"");
        this.ticketGrantingTicketCookieGenerator.removeCookie(response);
        this.warnCookieGenerator.removeCookie(response);

        destroyApplicationSession(request, response);
        LOGGER.debug(""Terminated all CAS sessions successfully."");

        if (StringUtils.isNotBlank(logoutProperties.getRedirectUrl())) {
            WebUtils.putLogoutRedirectUrl(context, logoutProperties.getRedirectUrl());
            return this.eventFactorySupport.event(this, CasWebflowConstants.STATE_ID_REDIRECT);
        }

        return this.eventFactorySupport.success(this);
    }"
"@Nonnull
  public StringComparator naturalStringComparator(final SimpleExtraction simpleExtraction)
  {
    Preconditions.checkNotNull(simpleExtraction, ""simpleExtraction"");
    if (simpleExtraction.getExtractionFn() != null
        || getColumnType(simpleExtraction.getColumn()) == ValueType.STRING) {
      return StringComparators.LEXICOGRAPHIC;
    } else {
      return StringComparators.NUMERIC;
    }
  }"
"public void notifyStateChangeToUnavailable() {
        final List<ConsumerStateListener> onAvailable = consumerConfig.getOnAvailable();
        if (onAvailable != null) {
            AsyncRuntime.getAsyncThreadPool().execute(new Runnable() {
                @Override
                public void run() {
                    // 状态变化通知监听器
                    for (ConsumerStateListener listener : onAvailable) {
                        try {
                            listener.onUnavailable(consumerConfig.getConsumerBootstrap().getProxyIns());
                        } catch (Exception e) {
                            LOGGER.errorWithApp(consumerConfig.getAppName(),
                                ""Failed to notify consumer state listener when state change to unavailable"");
                        }
                    }
                }
            });
        }
    }"
"public static EntityScanPackages get(BeanFactory beanFactory) {
		// Currently we only store a single base package, but we return a list to
		// allow this to change in the future if needed
		try {
			return beanFactory.getBean(BEAN, EntityScanPackages.class);
		}
		catch (NoSuchBeanDefinitionException ex) {
			return NONE;
		}
	}"
"public void setNumExecutors(@Nonnegative int n) throws IOException, IllegalArgumentException {
        if (n < 0) {
            throw new IllegalArgumentException(""Incorrect field \""# of executors\"": "" + n +"". It should be a non-negative number."");
        }
        if (this.numExecutors != n) {
            this.numExecutors = n;
            updateComputerList();
            save();
        }
    }"
"public void loadDimensionIterable(
      Iterable<String> oldDimensionOrder,
      Map<String, ColumnCapabilitiesImpl> oldColumnCapabilities
  )
  {
    synchronized (dimensionDescs) {
      if (!dimensionDescs.isEmpty()) {
        throw new ISE(""Cannot load dimension order when existing order[%s] is not empty."", dimensionDescs.keySet());
      }
      for (String dim : oldDimensionOrder) {
        if (dimensionDescs.get(dim) == null) {
          ColumnCapabilitiesImpl capabilities = oldColumnCapabilities.get(dim);
          columnCapabilities.put(dim, capabilities);
          DimensionHandler handler = DimensionHandlerUtils.getHandlerFromCapabilities(dim, capabilities, null);
          addNewDimension(dim, capabilities, handler);
        }
      }
    }
  }"
"public static <T> int count(Iterable<T> iterable, Matcher<T> matcher) {
		int count = 0;
		if (null != iterable) {
			for (T t : iterable) {
				if (null == matcher || matcher.match(t)) {
					count++;
				}
			}
		}
		return count;
	}"
"public List<MemorySegment> close() throws IOException
	{
		// send off set last segment
		writeSegment(getCurrentSegment(), getCurrentPositionInSegment(), true);
		clear();
		
		// close the writer and gather all segments
		final LinkedBlockingQueue<MemorySegment> queue = this.writer.getReturnQueue();
		this.writer.close();
		
		// re-collect all memory segments
		ArrayList<MemorySegment> list = new ArrayList<MemorySegment>(this.numSegments);	
		for (int i = 0; i < this.numSegments; i++) {
			final MemorySegment m = queue.poll();
			if (m == null) {
				// we get null if the queue is empty. that should not be the case if the reader was properly closed.
				throw new RuntimeException(""ChannelWriterOutputView: MemorySegments have been taken from return queue by different actor."");
			}
			list.add(m);
		}
		
		return list;
	}"
"public Object getVariable(String variableName, boolean fetchAllVariables) {
    Object value = null;
    VariableInstance variable = getVariableInstance(variableName, fetchAllVariables);
    if (variable != null) {
      value = variable.getValue();
    }
    return value;
  }"
"protected static boolean defaultIgnoreNullValue(Object obj) {
		if(obj instanceof CharSequence || obj instanceof JSONTokener || obj instanceof Map) {
			return false;
		}
		return true;
	}"
"@Override
    public void memcpySpecial(DataBuffer dstBuffer, Pointer srcPointer, long length, long dstOffset) {
        CudaContext context = getCudaContext();
        AllocationPoint point = ((BaseCudaDataBuffer) dstBuffer).getAllocationPoint();

        Pointer dP = new CudaPointer((point.getPointers().getHostPointer().address()) + dstOffset);

        val profH = PerformanceTracker.getInstance().helperStartTransaction();

        if (nativeOps.memcpyAsync(dP, srcPointer, length, CudaConstants.cudaMemcpyHostToHost, context.getOldStream()) == 0)
            throw new ND4JIllegalStateException(""memcpyAsync failed"");

        PerformanceTracker.getInstance().helperRegisterTransaction(point.getDeviceId(), profH, point.getNumberOfBytes(),MemcpyDirection.HOST_TO_HOST);

        if (point.getAllocationStatus() == AllocationStatus.DEVICE) {
            Pointer rDP = new CudaPointer(point.getPointers().getDevicePointer().address() + dstOffset);

            val profD = PerformanceTracker.getInstance().helperStartTransaction();

            if (nativeOps.memcpyAsync(rDP, dP, length, CudaConstants.cudaMemcpyHostToDevice, context.getOldStream()) == 0)
                throw new ND4JIllegalStateException(""memcpyAsync failed"");

            context.syncOldStream();

            PerformanceTracker.getInstance().helperRegisterTransaction(point.getDeviceId(), profD, point.getNumberOfBytes(),MemcpyDirection.HOST_TO_DEVICE);
        }

        context.syncOldStream();


        point.tickDeviceWrite();
    }"
"@SuppressWarnings(""unchecked"")
  synchronized <T> T getInternal(Resource<T> resource) {
    Instance instance = instances.get(resource);
    if (instance == null) {
      instance = new Instance(resource.create());
      instances.put(resource, instance);
    }
    if (instance.destroyTask != null) {
      instance.destroyTask.cancel(false);
      instance.destroyTask = null;
    }
    instance.refcount++;
    return (T) instance.payload;
  }"
"public <T> T page(Collection<String> fields, Entity where, int page, int numPerPage, RsHandler<T> rsh) throws SQLException {
		Connection conn = null;
		try {
			conn = this.getConnection();
			return runner.page(conn, fields, where, page, numPerPage, rsh);
		} catch (SQLException e) {
			throw e;
		} finally {
			this.closeConnection(conn);
		}
	}"
"public static void generateIPC(double[] std_deviation, double totVar, double[] vars, double[] prop_var,
                                   double[] cum_var) {
        int arrayLen = std_deviation.length;

        if (totVar > 0) {
            for (int i = 0; i < arrayLen; i++) {
                vars[i] = std_deviation[i] * std_deviation[i];
                prop_var[i] = vars[i] / totVar;
                cum_var[i] = i == 0 ? prop_var[0] : cum_var[i-1] + prop_var[i];
            }
        }
        double lastCum = cum_var[arrayLen-1];
        if (lastCum > 1) {  // GLRM sometimes screw up the matrix estimation pretty bad
            double multF = 1/lastCum;
            ArrayUtils.mult(prop_var, multF);
            ArrayUtils.mult(cum_var, multF);
            ArrayUtils.mult(vars, multF);
            ArrayUtils.mult(std_deviation, sqrt(multF));
        }
    }"
"public boolean getBoolean(String name, boolean defaultValue) {
		String valueString = getTrimmed(name);
		if (null == valueString || valueString.isEmpty()) {
			return defaultValue;
		}

		if (StringUtils.equalsIgnoreCase(""true"", valueString))
			return true;
		else if (StringUtils.equalsIgnoreCase(""false"", valueString))
			return false;
		else return defaultValue;
	}"
"private void increaseWriteIndex()
  {
    final long startAtNs = System.nanoTime();
    final long queryTimeoutAtNs = getQueryTimeoutAtNs(startAtNs);
    final long spinTimeoutAtNs = startAtNs + SPIN_FOR_TIMEOUT_THRESHOLD_NS;
    long timeoutNs = queryTimeoutAtNs - startAtNs;
    long spinTimeoutNs = SPIN_FOR_TIMEOUT_THRESHOLD_NS;

    // In the below, we check that the array is full and wait for at least one slot to become available.
    //
    // nextReadIndex is a volatile variable and the changes on it are continuously checked until they are seen in
    // the while loop. See the following links.
    // * http://docs.oracle.com/javase/specs/jls/se7/html/jls-8.html#jls-8.3.1.4
    // * http://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.4.5
    // * https://stackoverflow.com/questions/11761552/detailed-semantics-of-volatile-regarding-timeliness-of-visibility

    if (curWriteIndex == maxNumSlots - 1) {
      // We additionally check that nextReadIndex is -1 here because the writing thread should wait for the reading
      // thread to start reading only when the writing thread tries to overwrite the first slot for the first time.

      // The below condition is checked in a while loop instead of using a lock to avoid frequent thread park.
      while ((nextReadIndex == -1 || nextReadIndex == 0) && !Thread.currentThread().isInterrupted()) {
        if (timeoutNs <= 0L) {
          throw new RuntimeException(new TimeoutException());
        }
        // Thread.yield() should not be called from the very beginning
        if (spinTimeoutNs <= 0L) {
          Thread.yield();
        }
        long now = System.nanoTime();
        timeoutNs = queryTimeoutAtNs - now;
        spinTimeoutNs = spinTimeoutAtNs - now;
      }

      // Changes on nextReadIndex happens-before changing curWriteIndex.
      curWriteIndex = 0;
    } else {
      final int nextWriteIndex = curWriteIndex + 1;

      // The below condition is checked in a while loop instead of using a lock to avoid frequent thread park.
      while ((nextWriteIndex == nextReadIndex) && !Thread.currentThread().isInterrupted()) {
        if (timeoutNs <= 0L) {
          throw new RuntimeException(new TimeoutException());
        }
        // Thread.yield() should not be called from the very beginning
        if (spinTimeoutNs <= 0L) {
          Thread.yield();
        }
        long now = System.nanoTime();
        timeoutNs = queryTimeoutAtNs - now;
        spinTimeoutNs = spinTimeoutAtNs - now;
      }

      // Changes on nextReadIndex happens-before changing curWriteIndex.
      curWriteIndex = nextWriteIndex;
    }
  }"
"private static String coerceToEpoch(String s) {
		Long epoch = parseEpochSecond(s);
		if (epoch != null) {
			return String.valueOf(epoch);
		}
		SimpleDateFormat format = new SimpleDateFormat(""yyyy-MM-dd'T'HH:mm:ssZ"");
		try {
			return String.valueOf(format.parse(s).getTime());
		}
		catch (ParseException ex) {
			return s;
		}
	}"
"@Override
    protected void putDumpInfoTo(Map<String, Object> result) {
        if(StringUtils.isNotBlank(this.statusCodeResult)) {
            result.put(DumpConstants.STATUS_CODE, this.statusCodeResult);
        }
    }"
"protected DataSourceMetadataUpdateResult updateDataSourceMetadataWithHandle(
      final Handle handle,
      final String dataSource,
      final DataSourceMetadata startMetadata,
      final DataSourceMetadata endMetadata
  ) throws IOException
  {
    Preconditions.checkNotNull(dataSource, ""dataSource"");
    Preconditions.checkNotNull(startMetadata, ""startMetadata"");
    Preconditions.checkNotNull(endMetadata, ""endMetadata"");

    final byte[] oldCommitMetadataBytesFromDb = getDataSourceMetadataWithHandleAsBytes(handle, dataSource);
    final String oldCommitMetadataSha1FromDb;
    final DataSourceMetadata oldCommitMetadataFromDb;

    if (oldCommitMetadataBytesFromDb == null) {
      oldCommitMetadataSha1FromDb = null;
      oldCommitMetadataFromDb = null;
    } else {
      oldCommitMetadataSha1FromDb = BaseEncoding.base16().encode(
          Hashing.sha1().hashBytes(oldCommitMetadataBytesFromDb).asBytes()
      );
      oldCommitMetadataFromDb = jsonMapper.readValue(oldCommitMetadataBytesFromDb, DataSourceMetadata.class);
    }

    final boolean startMetadataMatchesExisting;

    if (oldCommitMetadataFromDb == null) {
      startMetadataMatchesExisting = startMetadata.isValidStart();
    } else {
      // Checking against the last committed metadata.
      // Converting the last one into start metadata for checking since only the same type of metadata can be matched.
      // Even though kafka/kinesis indexing services use different sequenceNumber types for representing
      // start and end sequenceNumbers, the below conversion is fine because the new start sequenceNumbers are supposed
      // to be same with end sequenceNumbers of the last commit.
      startMetadataMatchesExisting = startMetadata.asStartMetadata().matches(oldCommitMetadataFromDb.asStartMetadata());
    }

    if (!startMetadataMatchesExisting) {
      // Not in the desired start state.
      log.error(
          ""Not updating metadata, existing state[%s] in metadata store doesn't match to the new start state[%s]."",
          oldCommitMetadataFromDb,
          startMetadata
      );
      return DataSourceMetadataUpdateResult.FAILURE;
    }

    // Only endOffsets should be stored in metadata store
    final DataSourceMetadata newCommitMetadata = oldCommitMetadataFromDb == null
                                                 ? endMetadata
                                                 : oldCommitMetadataFromDb.plus(endMetadata);
    final byte[] newCommitMetadataBytes = jsonMapper.writeValueAsBytes(newCommitMetadata);
    final String newCommitMetadataSha1 = BaseEncoding.base16().encode(
        Hashing.sha1().hashBytes(newCommitMetadataBytes).asBytes()
    );

    final DataSourceMetadataUpdateResult retVal;
    if (oldCommitMetadataBytesFromDb == null) {
      // SELECT -> INSERT can fail due to races; callers must be prepared to retry.
      final int numRows = handle.createStatement(
          StringUtils.format(
              ""INSERT INTO %s (dataSource, created_date, commit_metadata_payload, commit_metadata_sha1) ""
              + ""VALUES (:dataSource, :created_date, :commit_metadata_payload, :commit_metadata_sha1)"",
              dbTables.getDataSourceTable()
          )
      )
                                .bind(""dataSource"", dataSource)
                                .bind(""created_date"", DateTimes.nowUtc().toString())
                                .bind(""commit_metadata_payload"", newCommitMetadataBytes)
                                .bind(""commit_metadata_sha1"", newCommitMetadataSha1)
                                .execute();

      retVal = numRows == 1 ? DataSourceMetadataUpdateResult.SUCCESS : DataSourceMetadataUpdateResult.TRY_AGAIN;
    } else {
      // Expecting a particular old metadata; use the SHA1 in a compare-and-swap UPDATE
      final int numRows = handle.createStatement(
          StringUtils.format(
              ""UPDATE %s SET ""
              + ""commit_metadata_payload = :new_commit_metadata_payload, ""
              + ""commit_metadata_sha1 = :new_commit_metadata_sha1 ""
              + ""WHERE dataSource = :dataSource AND commit_metadata_sha1 = :old_commit_metadata_sha1"",
              dbTables.getDataSourceTable()
          )
      )
                                .bind(""dataSource"", dataSource)
                                .bind(""old_commit_metadata_sha1"", oldCommitMetadataSha1FromDb)
                                .bind(""new_commit_metadata_payload"", newCommitMetadataBytes)
                                .bind(""new_commit_metadata_sha1"", newCommitMetadataSha1)
                                .execute();

      retVal = numRows == 1 ? DataSourceMetadataUpdateResult.SUCCESS : DataSourceMetadataUpdateResult.TRY_AGAIN;
    }

    if (retVal == DataSourceMetadataUpdateResult.SUCCESS) {
      log.info(""Updated metadata from[%s] to[%s]."", oldCommitMetadataFromDb, newCommitMetadata);
    } else {
      log.info(""Not updating metadata, compare-and-swap failure."");
    }

    return retVal;
  }"
"public long getTimeDurationHelper(String name, String vStr, TimeUnit unit) {
		vStr = vStr.trim();
		vStr = StringUtils.toLowerCase(vStr);
		ParsedTimeDuration vUnit = ParsedTimeDuration.unitFor(vStr);
		if (null == vUnit) {
			logDeprecation(""No unit for "" + name + ""("" + vStr + "") assuming "" + unit);
			vUnit = ParsedTimeDuration.unitFor(unit);
		} else {
			vStr = vStr.substring(0, vStr.lastIndexOf(vUnit.suffix()));
		}

		long raw = Long.parseLong(vStr);
		long converted = unit.convert(raw, vUnit.unit());
		if (vUnit.unit().convert(converted, unit) < raw) {
			logDeprecation(""Possible loss of precision converting "" + vStr
					+ vUnit.suffix() + "" to "" + unit + "" for "" + name);
		}
		return converted;
	}"
"public boolean tryReserve(QueryId queryId, String allocationTag, long bytes)
    {
        checkArgument(bytes >= 0, ""bytes is negative"");
        synchronized (this) {
            if (getFreeBytes() - bytes < 0) {
                return false;
            }
            reservedBytes += bytes;
            if (bytes != 0) {
                queryMemoryReservations.merge(queryId, bytes, Long::sum);
                updateTaggedMemoryAllocations(queryId, allocationTag, bytes);
            }
        }

        onMemoryReserved();
        return true;
    }"
"@Override
    public boolean condition(Object input) {
        Number n = (Number) input;
        switch (op) {
            case LessThan:
                return n.intValue() < value;
            case LessOrEqual:
                return n.intValue() <= value;
            case GreaterThan:
                return n.intValue() > value;
            case GreaterOrEqual:
                return n.intValue() >= value;
            case Equal:
                return n.intValue() == value;
            case NotEqual:
                return n.intValue() != value;
            case InSet:
                return set.contains(n.intValue());
            case NotInSet:
                return !set.contains(n.intValue());
            default:
                throw new RuntimeException(""Unknown or not implemented op: "" + op);
        }
    }"
"public static <W extends Window> ContinuousEventTimeTrigger<W> of(Time interval) {
		return new ContinuousEventTimeTrigger<>(interval.toMilliseconds());
	}"
"public static Tag outcome(ClientResponse response) {
		try {
			if (response != null) {
				HttpStatus status = response.statusCode();
				if (status.is1xxInformational()) {
					return OUTCOME_INFORMATIONAL;
				}
				if (status.is2xxSuccessful()) {
					return OUTCOME_SUCCESS;
				}
				if (status.is3xxRedirection()) {
					return OUTCOME_REDIRECTION;
				}
				if (status.is4xxClientError()) {
					return OUTCOME_CLIENT_ERROR;
				}
				if (status.is5xxServerError()) {
					return OUTCOME_SERVER_ERROR;
				}
			}
			return OUTCOME_UNKNOWN;
		}
		catch (IllegalArgumentException exc) {
			return OUTCOME_UNKNOWN;
		}
	}"
"public static <T extends Collection<String>> T readLines(InputStream in, String charsetName, T collection) throws IORuntimeException {
		return readLines(in, CharsetUtil.charset(charsetName), collection);
	}"
"private void updateComputer(Node n, Map<String,Computer> byNameMap, Set<Computer> used, boolean automaticSlaveLaunch) {
        Map<Node,Computer> computers = getComputerMap();
        Computer c;
        c = byNameMap.get(n.getNodeName());
        if (c!=null) {
            try {
                c.setNode(n); // reuse
                used.add(c);
            } catch (RuntimeException e) {
                LOGGER.log(Level.WARNING, ""Error updating node "" + n.getNodeName() + "", continuing"", e);
            }
        } else {
            // we always need Computer for the master as a fallback in case there's no other Computer.
            if(n.getNumExecutors()>0 || n==Jenkins.getInstance()) {
                try {
                    c = n.createComputer();
                } catch(RuntimeException ex) { // Just in case there is a bogus extension
                    LOGGER.log(Level.WARNING, ""Error retrieving computer for node "" + n.getNodeName() + "", continuing"", ex);
                }
                if (c == null) {
                    LOGGER.log(Level.WARNING, ""Cannot create computer for node {0}, the {1}#createComputer() method returned null. Skipping this node"", 
                            new Object[]{n.getNodeName(), n.getClass().getName()});
                    return;
                }
                
                computers.put(n, c);
                if (!n.isHoldOffLaunchUntilSave() && automaticSlaveLaunch) {
                    RetentionStrategy retentionStrategy = c.getRetentionStrategy();
                    if (retentionStrategy != null) {
                        // if there is a retention strategy, it is responsible for deciding to start the computer
                        retentionStrategy.start(c);
                    } else {
                        // we should never get here, but just in case, we'll fall back to the legacy behaviour
                        c.connect(true);
                    }
                }
                used.add(c);
            } else {
                // TODO: Maybe it should be allowed, but we would just get NPE in the original logic before JENKINS-43496
                LOGGER.log(Level.WARNING, ""Node {0} has no executors. Cannot update the Computer instance of it"", n.getNodeName());
            }
        }
    }"
"public boolean forEachMatcherAndArgument(ArgumentMatcherAction action) {
        if (matchingType == ERROR_UNSUPPORTED_NUMBER_OF_MATCHERS)
            return false;

        Object[] arguments = invocation.getArguments();
        for (int i = 0; i < arguments.length; i++) {
            ArgumentMatcher<?> matcher = matchers.get(i);
            Object argument = arguments[i];

            if (!action.apply(matcher, argument)) {
                return false;
            }
        }
        return true;
    }"
"public static String format(String message, Object... formatArgs)
  {
    return String.format(Locale.ENGLISH, message, formatArgs);
  }"
"public NewChunk asciiLength(NewChunk nc) {
    //pre-allocate since size is known
    nc.alloc_mantissa(_len);
    nc.alloc_exponent(_len); // sadly, a waste
    // fill in lengths
    for(int i=0; i < _len; i++) {
      int off = UnsafeUtils.get4(_mem,idx(i));
      int len = 0;
      if (off != NA) {
        while (_mem[_valstart + off + len] != 0) len++;
        nc.addNum(len, 0);
      } else nc.addNA();
    }
    return nc;
  }"
"public void setFieldPopupMenu(String fieldLabel, JPopupMenu popup) {
		Component c = this.fieldMap.get(fieldLabel);
		if (c != null) {
			if (c instanceof JComponent) {
				((JComponent) c).setComponentPopupMenu(popup);
			} else {
				handleUnexpectedFieldClass(fieldLabel, c);
			}
		}
	}"
"public <T extends Evaluation> T evaluate(MultiDataSetIterator iterator, List<String> labelsList) {
        return evaluate(iterator, labelsList, 1);
    }"
"public void incrementCount(F first, S second, double inc) {
        Counter<S> counter = maps.get(first);
        if (counter == null) {
            counter = new Counter<S>();
            maps.put(first, counter);
        }

        counter.incrementCount(second, inc);
    }"
"public Img pressText(String pressText, Color color, Font font, int x, int y, float alpha) {
		final BufferedImage targetImage = getValidSrcImg();
		final Graphics2D g = targetImage.createGraphics();
		
		if(null == font) {
			// 默认字体
			font = new Font(""Courier"", Font.PLAIN, (int)(targetImage.getHeight() * 0.75));
		}

		// 抗锯齿
		g.setRenderingHint(RenderingHints.KEY_ANTIALIASING, RenderingHints.VALUE_ANTIALIAS_ON);
		g.setColor(color);
		g.setFont(font);
		// 透明度
		g.setComposite(AlphaComposite.getInstance(AlphaComposite.SRC_ATOP, alpha));
		// 在指定坐标绘制水印文字
		final FontMetrics metrics = g.getFontMetrics(font);
		final int textLength = metrics.stringWidth(pressText);
		final int textHeight = metrics.getAscent() - metrics.getLeading() - metrics.getDescent();
		g.drawString(pressText, Math.abs(targetImage.getWidth() - textLength) / 2 + x, Math.abs(targetImage.getHeight() + textHeight) / 2 + y);
		g.dispose();
		this.targetImage = targetImage;

		return this;
	}"
"public long readIntLenenc() {
        int firstByte = readInt1();
        if (firstByte < 0xfb) {
            return firstByte;
        }
        if (0xfb == firstByte) {
            return 0;
        }
        if (0xfc == firstByte) {
            return byteBuf.readShortLE();
        }
        if (0xfd == firstByte) {
            return byteBuf.readMediumLE();
        }
        return byteBuf.readLongLE();
    }"
"@Override
    public int[] toIdList(int codePoint)
    {
        int count;
        if (codePoint < 0x80)
            count = 1;
        else if (codePoint < 0x800)
            count = 2;
        else if (codePoint < 0x10000)
            count = 3;
        else if (codePoint < 0x200000)
            count = 4;
        else if (codePoint < 0x4000000)
            count = 5;
        else if (codePoint <= 0x7fffffff)
            count = 6;
        else
            return EMPTYLIST;
        int[] r = new int[count];
        switch (count)
        { /* note: code falls through cases! */
            case 6:
                r[5] = (char) (0x80 | (codePoint & 0x3f));
                codePoint = codePoint >> 6;
                codePoint |= 0x4000000;
            case 5:
                r[4] = (char) (0x80 | (codePoint & 0x3f));
                codePoint = codePoint >> 6;
                codePoint |= 0x200000;
            case 4:
                r[3] = (char) (0x80 | (codePoint & 0x3f));
                codePoint = codePoint >> 6;
                codePoint |= 0x10000;
            case 3:
                r[2] = (char) (0x80 | (codePoint & 0x3f));
                codePoint = codePoint >> 6;
                codePoint |= 0x800;
            case 2:
                r[1] = (char) (0x80 | (codePoint & 0x3f));
                codePoint = codePoint >> 6;
                codePoint |= 0xc0;
            case 1:
                r[0] = (char) codePoint;
        }
        return r;
    }"
"private void readNextBlock()
            throws IOException
    {
        lastReadInputCheckpoint = input.getCheckpoint();

        int control = input.read();
        if (control == -1) {
            throw new OrcCorruptionException(input.getOrcDataSourceId(), ""Read past end of buffer RLE byte"");
        }

        offset = 0;

        // if byte high bit is not set, this is a repetition; otherwise it is a literal sequence
        if ((control & 0x80) == 0) {
            length = control + MIN_REPEAT_SIZE;

            // read the repeated value
            int value = input.read();
            if (value == -1) {
                throw new OrcCorruptionException(input.getOrcDataSourceId(), ""Reading RLE byte got EOF"");
            }

            // fill buffer with the value
            Arrays.fill(buffer, 0, length, (byte) value);
        }
        else {
            // length is 2's complement of byte
            length = 0x100 - control;

            // read the literals into the buffer
            input.readFully(buffer, 0, length);
        }
    }"
"public void addListener(MetricRegistryListener listener) {
        listeners.add(listener);

        for (Map.Entry<MetricName, Metric> entry : metrics.entrySet()) {
            notifyListenerOfAddedMetric(listener, entry.getValue(), entry.getKey());
        }
    }"
"private long calculateSize(DbBatch data) {
        long size = 0;
        for (EventData eventData : data.getRowBatch().getDatas()) {
            size += eventData.getSize();
        }

        return size;

        // 走序列化的方式快速计算一下大小
        // SerializeWriter out = new SerializeWriter();
        // try {
        // JSONSerializer serializer = new JSONSerializer(out);
        // serializer.config(SerializerFeature.SortField, false);// 关掉排序
        // serializer.write(data);
        // byte[] bytes = out.toBytes(""UTF-8"");
        // return bytes.length;
        // } finally {
        // out.close();
        // }
    }"
"@Override
	public FsStateBackend configure(Configuration config, ClassLoader classLoader) {
		return new FsStateBackend(this, config, classLoader);
	}"
"private void handleChangeManagerStatusRequest(final HttpServletRequest req,
      final Map<String, Object> ret, final boolean enableMetricManager) {
    try {
      logger.info(""Updating metric manager status"");
      if ((enableMetricManager && MetricReportManager.isInstantiated())
          || MetricReportManager.isAvailable()) {
        final MetricReportManager metricManager = MetricReportManager.getInstance();
        if (enableMetricManager) {
          metricManager.enableManager();
        } else {
          metricManager.disableManager();
        }
        ret.put(STATUS_PARAM, RESPONSE_SUCCESS);
      } else {
        ret.put(RESPONSE_ERROR, ""MetricManager is not available"");
      }
    } catch (final Exception e) {
      logger.error(e);
      ret.put(RESPONSE_ERROR, e.getMessage());
    }
  }"
"@Override
    public V pollFromAny(long timeout, TimeUnit unit, String... queueNames) throws InterruptedException {
        return get(pollFromAnyAsync(timeout, unit, queueNames));
    }"
"public static OutputStream asOututStream(File file) throws IOException {
		Validate.notNull(file, ""file is null"");
		return asOututStream(file.toPath());
	}"
"@SuppressWarnings(""unchecked"")
	public <T> Converter<T> getDefaultConverter(Type type) {
		return (null == defaultConverterMap) ? null : (Converter<T>) defaultConverterMap.get(type);
	}"
"public void shutdown() {
		synchronized (lock) {
			if (isShutdown) {
				return;
			}

			LOG.info(""Shutting down the network environment and its components."");

			// terminate all network connections
			try {
				LOG.debug(""Shutting down network connection manager"");
				connectionManager.shutdown();
			}
			catch (Throwable t) {
				LOG.warn(""Cannot shut down the network connection manager."", t);
			}

			// shutdown all intermediate results
			try {
				LOG.debug(""Shutting down intermediate result partition manager"");
				resultPartitionManager.shutdown();
			}
			catch (Throwable t) {
				LOG.warn(""Cannot shut down the result partition manager."", t);
			}

			// make sure that the global buffer pool re-acquires all buffers
			networkBufferPool.destroyAllBufferPools();

			// destroy the buffer pool
			try {
				networkBufferPool.destroy();
			}
			catch (Throwable t) {
				LOG.warn(""Network buffer pool did not shut down properly."", t);
			}

			isShutdown = true;
		}
	}"
"public static WatchMonitor create(URL url, int maxDepth, WatchEvent.Kind<?>... events){
		return create(URLUtil.toURI(url), maxDepth, events);
	}"
"public static Type[] getTypeArguments(Type type) {
		if (null == type) {
			return null;
		}

		final ParameterizedType parameterizedType = toParameterizedType(type);
		return (null == parameterizedType) ? null : parameterizedType.getActualTypeArguments();
	}"
"public String toStandoff(boolean withComment)
    {
        StringBuilder sb = new StringBuilder(size() * 4);
        String delimiter = "" "";
        String text = text(delimiter);
        sb.append(text).append('\n');
        int i = 1;
        int offset = 0;
        for (IWord word : wordList)
        {
            assert text.charAt(offset) == word.getValue().charAt(0);
            printWord(word, sb, i, offset, withComment);
            ++i;
            if (word instanceof CompoundWord)
            {
                int offsetChild = offset;
                for (Word child : ((CompoundWord) word).innerList)
                {
                    printWord(child, sb, i, offsetChild, withComment);
                    offsetChild += child.length();
                    offsetChild += delimiter.length();
                    ++i;
                }
                offset += delimiter.length() * ((CompoundWord) word).innerList.size();
            }
            else
            {
                offset += delimiter.length();
            }
            offset += word.length();
        }
        return sb.toString();
    }"
"public final String getFixString(final int len, String charsetName) {
        if (position + len > origin + limit) throw new IllegalArgumentException(""limit excceed: ""
                                                                                + (position + len - origin));

        final int from = position;
        final int end = from + len;
        byte[] buf = buffer;
        int found = from;
        for (; (found < end) && buf[found] != '\0'; found++)
            /* empty loop */;

        try {
            String string = new String(buf, from, found - from, charsetName);
            position += len;
            return string;
        } catch (UnsupportedEncodingException e) {
            throw new IllegalArgumentException(""Unsupported encoding: "" + charsetName, e);
        }
    }"
"@SuppressWarnings(""unchecked"")
    public static <T> AttributeKey<T> valueOf(String name) {
        return (AttributeKey<T>) pool.valueOf(name);
    }"
"protected boolean calculateFailureThresholdRateAndCompare(final List<Date> failures) {
        if (failures.size() < 2) {
            return false;
        }
        val lastTime = failures.get(0).getTime();
        val secondToLastTime = failures.get(1).getTime();
        val difference = lastTime - secondToLastTime;
        val rate = NUMBER_OF_MILLISECONDS_IN_SECOND / difference;
        LOGGER.debug(""Last attempt was at [{}] and the one before that was at [{}]. Difference is [{}] calculated as rate of [{}]"",
            lastTime, secondToLastTime, difference, rate);
        if (rate > getThresholdRate()) {
            LOGGER.warn(""Authentication throttling rate [{}] exceeds the defined threshold [{}]"", rate, getThresholdRate());
            return true;
        }
        return false;
    }"
"public static <T extends Throwable> Optional<T> findThrowable(Throwable throwable, Class<T> searchType) {
		if (throwable == null || searchType == null) {
			return Optional.empty();
		}

		Throwable t = throwable;
		while (t != null) {
			if (searchType.isAssignableFrom(t.getClass())) {
				return Optional.of(searchType.cast(t));
			} else {
				t = t.getCause();
			}
		}

		return Optional.empty();
	}"
"public static Http2Exception connectionError(Http2Error error, String fmt, Object... args) {
        return new Http2Exception(error, String.format(fmt, args));
    }"
"public void unionFields(Record other) {
		final int minFields = Math.min(this.numFields, other.numFields);
		final int maxFields = Math.max(this.numFields, other.numFields);
		
		final int[] offsets = this.offsets.length >= maxFields ? this.offsets : new int[maxFields];
		final int[] lengths = this.lengths.length >= maxFields ? this.lengths : new int[maxFields];
		
		if (!(this.isModified() || other.isModified())) {
			// handle the special (but common) case where both records have a valid binary representation differently
			// allocate space for the switchBuffer first
			final int estimatedLength = this.binaryLen + other.binaryLen;
			this.serializer.memory = (this.switchBuffer != null && this.switchBuffer.length >= estimatedLength) ? 
										this.switchBuffer : new byte[estimatedLength];
			this.serializer.position = 0;
			
			try {
				// common loop for both records
				for (int i = 0; i < minFields; i++) {
					final int thisOff = this.offsets[i];
					if (thisOff == NULL_INDICATOR_OFFSET) {
						final int otherOff = other.offsets[i];
						if (otherOff == NULL_INDICATOR_OFFSET) {
							offsets[i] = NULL_INDICATOR_OFFSET;
						} else {
							// take field from other record
							offsets[i] = this.serializer.position;
							this.serializer.write(other.binaryData, otherOff, other.lengths[i]);
							lengths[i] = other.lengths[i];
						}
					} else {
						// copy field from this one
						offsets[i] = this.serializer.position;
						this.serializer.write(this.binaryData, thisOff, this.lengths[i]);
						lengths[i] = this.lengths[i];
					}
				}
				
				// add the trailing fields from one record
				if (minFields != maxFields) {
					final Record sourceForRemainder = this.numFields > minFields ? this : other;
					int begin = -1;
					int end = -1;
					int offsetDelta = 0;
					
					// go through the offsets, find the non-null fields to account for the remaining data
					for (int k = minFields; k < maxFields; k++) {
						final int off = sourceForRemainder.offsets[k];
						if (off == NULL_INDICATOR_OFFSET) {
							offsets[k] = NULL_INDICATOR_OFFSET;
						} else {
							end = sourceForRemainder.offsets[k]+sourceForRemainder.lengths[k];
							if (begin == -1) {
								// first non null column in the remainder
								begin = sourceForRemainder.offsets[k];
								offsetDelta = this.serializer.position - begin;
							}
							offsets[k] = sourceForRemainder.offsets[k] + offsetDelta;
						}
					}
					
					// copy the remaining fields directly as binary
					if (begin != -1) {
						this.serializer.write(sourceForRemainder.binaryData, begin, 
								end - begin);
					}
					
					// the lengths can be copied directly
					if (lengths != sourceForRemainder.lengths) {
						System.arraycopy(sourceForRemainder.lengths, minFields, lengths, minFields, maxFields - minFields);
					}
				}
			} catch (Exception ioex) {
				throw new RuntimeException(""Error creating field union of record data"" + 
							ioex.getMessage() == null ? ""."" : "": "" + ioex.getMessage(), ioex);
			}
		}
		else {
			// the general case, where at least one of the two records has a binary representation that is not in sync.
			final int estimatedLength = (this.binaryLen > 0 ? this.binaryLen : this.numFields * DEFAULT_FIELD_LEN_ESTIMATE) + 
										(other.binaryLen > 0 ? other.binaryLen : other.numFields * DEFAULT_FIELD_LEN_ESTIMATE);
			this.serializer.memory = (this.switchBuffer != null && this.switchBuffer.length >= estimatedLength) ? 
										this.switchBuffer : new byte[estimatedLength];
			this.serializer.position = 0;
			
			try {
				// common loop for both records
				for (int i = 0; i < minFields; i++) {
					final int thisOff = this.offsets[i];
					if (thisOff == NULL_INDICATOR_OFFSET) {
						final int otherOff = other.offsets[i];
						if (otherOff == NULL_INDICATOR_OFFSET) {
							offsets[i] = NULL_INDICATOR_OFFSET;
						} else if (otherOff == MODIFIED_INDICATOR_OFFSET) {
							// serialize modified field from other record
							offsets[i] = this.serializer.position;
							other.writeFields[i].write(this.serializer);
							lengths[i] = this.serializer.position - offsets[i];
						} else {
							// take field from other record binary
							offsets[i] = this.serializer.position;
							this.serializer.write(other.binaryData, otherOff, other.lengths[i]);
							lengths[i] = other.lengths[i];
						}
					} else if (thisOff == MODIFIED_INDICATOR_OFFSET) {
						// serialize modified field from this record
						offsets[i] = this.serializer.position;
						this.writeFields[i].write(this.serializer);
						lengths[i] = this.serializer.position - offsets[i];
					} else {
						// copy field from this one
						offsets[i] = this.serializer.position;
						this.serializer.write(this.binaryData, thisOff, this.lengths[i]);
						lengths[i] = this.lengths[i];
					}
				}
				
				// add the trailing fields from one record
				if (minFields != maxFields) {
					final Record sourceForRemainder = this.numFields > minFields ? this : other;
					
					// go through the offsets, find the non-null fields
					for (int k = minFields; k < maxFields; k++) {
						final int off = sourceForRemainder.offsets[k];
						if (off == NULL_INDICATOR_OFFSET) {
							offsets[k] = NULL_INDICATOR_OFFSET;
						} else if (off == MODIFIED_INDICATOR_OFFSET) {
							// serialize modified field from the source record
							offsets[k] = this.serializer.position;
							sourceForRemainder.writeFields[k].write(this.serializer);
							lengths[k] = this.serializer.position - offsets[k];
						} else {
							// copy field from the source record binary
							offsets[k] = this.serializer.position;
							final int len = sourceForRemainder.lengths[k];
							this.serializer.write(sourceForRemainder.binaryData, off, len);
							lengths[k] = len;
						}
					}
				}
			} catch (Exception ioex) {
				throw new RuntimeException(""Error creating field union of record data"" + 
							ioex.getMessage() == null ? ""."" : "": "" + ioex.getMessage(), ioex);
			}
		}
		
		serializeHeader(this.serializer, offsets, maxFields);
		
		// set the fields
		this.switchBuffer = this.binaryData;
		this.binaryData = serializer.memory;
		this.binaryLen = serializer.position;
		
		this.numFields = maxFields;
		this.offsets = offsets;
		this.lengths = lengths;
		
		this.firstModifiedPos = Integer.MAX_VALUE;
		
		// make sure that the object arrays reflect the size as well
		if (this.readFields == null || this.readFields.length < maxFields) {
			final Value[] na = new Value[maxFields];
			System.arraycopy(this.readFields, 0, na, 0, this.readFields.length);
			this.readFields = na;
		}
		this.writeFields = (this.writeFields == null || this.writeFields.length < maxFields) ? 
																new Value[maxFields] : this.writeFields;
	}"
"public static int[] getBodyToViewPosition(JTextArea view, String header, int start, int end) {
        validateView(view);
        validateHeader(header);
        validateStartEnd(start, end);

        if (!isValidStartEndForLength(start, end, view.getDocument().getLength())) {
            return INVALID_POSITION;
        }

        int excessChars = 0;

        int pos = 0;
        while ((pos = header.indexOf(HttpHeader.CRLF, pos)) != -1) {
            pos += 2;
            ++excessChars;
        }

        int len = view.getDocument().getLength();
        int bodyLen = len - header.length() + excessChars;
        if (bodyLen < 0 || start > bodyLen || end > bodyLen) {
            return INVALID_POSITION;
        }

        int finalStartPos = start + header.length() - excessChars;
        int finalEndPos = end + header.length() - excessChars;
        return new int[] { finalStartPos, finalEndPos };
    }"
"public void addMessage(Object msg, int size, ChannelPromise promise) {
        Entry entry = Entry.newInstance(msg, size, total(msg), promise);
        if (tailEntry == null) {
            flushedEntry = null;
        } else {
            Entry tail = tailEntry;
            tail.next = entry;
        }
        tailEntry = entry;
        if (unflushedEntry == null) {
            unflushedEntry = entry;
        }

        // increment pending bytes after adding message to the unflushed arrays.
        // See https://github.com/netty/netty/issues/1619
        incrementPendingOutboundBytes(entry.pendingSize, false);
    }"
"protected History prepareHistory() throws IOException {
        File file = new File(System.getProperty(""user.home""), HISTORYFILE);
        if (!file.exists()) {
            try {
                file.createNewFile();
            } catch (IOException ignored) {
                // can't create the file, so no history for you
            }
        }
        return file.canWrite() ? new FileHistory(file) : null;
    }"
"public static Config build(final BaseHazelcastProperties hz, final MapConfig mapConfig) {
        val cfg = new HashMap<String, MapConfig>();
        cfg.put(mapConfig.getName(), mapConfig);
        return build(hz, cfg);
    }"
"public void setPanelsVisible(boolean visible) {
		if (layout == Layout.FULL) {
			getTabbedFull().setPanelsVisible(visible);
		} else {
			getTabbedSelect().setPanelsVisible(visible);
			getTabbedWork().setPanelsVisible(visible);
			getTabbedStatus().setPanelsVisible(visible);
		}
	}"
"@SuppressWarnings(""unchecked"")
  @VisibleForTesting
  public static List<Map<String, ?>> getLoadBalancingConfigsFromServiceConfig(
      Map<String, ?> serviceConfig) {
    /* schema as follows
    {
      ""loadBalancingConfig"": [
        {""xds"" :
          {
            ""balancerName"": ""balancer1"",
            ""childPolicy"": [...],
            ""fallbackPolicy"": [...],
          }
        },
        {""round_robin"": {}}
      ],
      ""loadBalancingPolicy"": ""ROUND_ROBIN""  // The deprecated policy key
    }
    */
    List<Map<String, ?>> lbConfigs = new ArrayList<>();
    if (serviceConfig.containsKey(SERVICE_CONFIG_LOAD_BALANCING_CONFIG_KEY)) {
      List<?> configs = getList(serviceConfig, SERVICE_CONFIG_LOAD_BALANCING_CONFIG_KEY);
      for (Map<String, ?> config : checkObjectList(configs)) {
        lbConfigs.add(config);
      }
    }
    if (lbConfigs.isEmpty()) {
      // No LoadBalancingConfig found.  Fall back to the deprecated LoadBalancingPolicy
      if (serviceConfig.containsKey(SERVICE_CONFIG_LOAD_BALANCING_POLICY_KEY)) {
        // TODO(zhangkun83): check if this is null.
        String policy = getString(serviceConfig, SERVICE_CONFIG_LOAD_BALANCING_POLICY_KEY);
        // Convert the policy to a config, so that the caller can handle them in the same way.
        policy = policy.toLowerCase(Locale.ROOT);
        Map<String, ?> fakeConfig = Collections.singletonMap(policy, Collections.emptyMap());
        lbConfigs.add(fakeConfig);
      }
    }
    return Collections.unmodifiableList(lbConfigs);
  }"
"private JLabel getFoundCountNameLabel() {
		if (foundCountNameLabel == null) {
			foundCountNameLabel = new JLabel();
			foundCountNameLabel.setText(Constant.messages.getString(""spider.toolbar.found.label""));
		}
		return foundCountNameLabel;
	}"
"@SuppressWarnings(""deprecation"")
	public final void setValidatedNodeType(SqlNode node, RelDataType type) {
		Objects.requireNonNull(type);
		Objects.requireNonNull(node);
		if (type.equals(unknownType)) {
			// don't set anything until we know what it is, and don't overwrite
			// a known type with the unknown type
			return;
		}
		nodeToTypeMap.put(node, type);
	}"
"public List<WordInfo> discover(String doc, int size)
    {
        try
        {
            return discover(new BufferedReader(new StringReader(doc)), size);
        }
        catch (IOException e)
        {
            throw new RuntimeException(e);
        }
    }"
"public static String orderByDefault(Class<?> entityClass) {
        StringBuilder sql = new StringBuilder();
        String orderByClause = EntityHelper.getOrderByClause(entityClass);
        if (orderByClause.length() > 0) {
            sql.append("" ORDER BY "");
            sql.append(orderByClause);
        }
        return sql.toString();
    }"
"@Override
    public void processEvent(ListenerEvent event, SequenceVectors<T> sequenceVectors, long argument) {
        try {
            locker.acquire();

            SimpleDateFormat sdf = new SimpleDateFormat(""yyyy-MM-dd HH:mm:ss.SSS"");

            StringBuilder builder = new StringBuilder(targetFolder.getAbsolutePath());
            builder.append(""/"").append(modelPrefix).append(""_"").append(sdf.format(new Date())).append("".seqvec"");
            File targetFile = new File(builder.toString());

            if (useBinarySerialization) {
                SerializationUtils.saveObject(sequenceVectors, targetFile);
            } else {
                throw new UnsupportedOperationException(""Not implemented yet"");
            }

        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            locker.release();
        }
    }"
"public INDArray outputSingle(boolean train, boolean clearInputs, INDArray... input){
        if (numOutputArrays != 1) {
            throw new IllegalStateException(
                    ""Cannot use outputSingle with ComputationGraph that does not have exactly 1 output. nOutputs: ""
                            + numOutputArrays);
        }
        return output(train, clearInputs, input)[0];
    }"
"public static List<String> getPasswordResetQuestions(final RequestContext requestContext) {
        val flowScope = requestContext.getFlowScope();
        return flowScope.get(""questions"", List.class);
    }"
"private boolean isLatticeBrokenBefore(int nodeIndex, ViterbiLattice lattice) {
        ViterbiNode[][] nodeEndIndices = lattice.getEndIndexArr();

        return nodeEndIndices[nodeIndex] == null;
    }"
"public AggregationBuilder makeGroupAgg(Field field) throws SqlParseException {

        //zhongshu-comment script类型的MethodField
        if (field instanceof MethodField && field.getName().equals(""script"")) {
            MethodField methodField = (MethodField) field;
                /*
                TermsAggregationBuilder termsBuilder的样例：
                来自这条sql的group by子句的gg字段解析结果：
                select a,case when c='1' then 'haha' when c='2' then 'book' else 'hbhb' end as gg from tbl_a group by a,gg
                {
                    ""gg"":{ //aggs的名字就叫gg
                        ""terms"":{
                            ""script"":{
                                ""source"":""if((doc['c'].value=='1')){'haha'} else if((doc['c'].value=='2')){'book'} else {'hbhb'}"",
                                ""lang"":""painless""
                            },
                            ""size"":10,
                            ""min_doc_count"":1,
                            ""shard_min_doc_count"":0,
                            ""show_term_doc_count_error"":false,
                            ""order"":[
                                {
                                    ""_count"":""desc""
                                },
                                {
                                    ""_key"":""asc""
                                }
                            ]
                        }
                    }
                }
             */
            TermsAggregationBuilder termsBuilder = AggregationBuilders.terms(methodField.getAlias()).script(new Script(methodField.getParams().get(1).value.toString()));

            //question 这里为什么要将这些信息加到groupMap中？
            groupMap.put(methodField.getAlias(), new KVValue(""KEY"", termsBuilder));

            return termsBuilder;
        }

        //zhongshu-comment filter类型的MethodField
        if (field instanceof MethodField) {

            MethodField methodField = (MethodField) field;
            if (methodField.getName().equals(""filter"")) {
                Map<String, Object> paramsAsMap = methodField.getParamsAsMap();
                Where where = (Where) paramsAsMap.get(""where"");
                return AggregationBuilders.filter(paramsAsMap.get(""alias"").toString(),
                        QueryMaker.explan(where));
            }
            return makeRangeGroup(methodField);
        } else {
            TermsAggregationBuilder termsBuilder = AggregationBuilders.terms(field.getName()).field(field.getName());
            groupMap.put(field.getName(), new KVValue(""KEY"", termsBuilder));
            return termsBuilder;
        }
    }"
"protected void addCookieRequestHeader(HttpState state, HttpConnection conn)
        throws IOException, HttpException {

        LOG.trace(""enter HttpMethodBase.addCookieRequestHeader(HttpState, ""
                  + ""HttpConnection)"");

        Header[] cookieheaders = getRequestHeaderGroup().getHeaders(""Cookie"");
        for (int i = 0; i < cookieheaders.length; i++) {
            Header cookieheader = cookieheaders[i];
            if (cookieheader.isAutogenerated()) {
                getRequestHeaderGroup().removeHeader(cookieheader);
            }
        }

        CookieSpec matcher = getCookieSpec(state);
        String host = this.params.getVirtualHost();
        if (host == null) {
            host = conn.getHost();
        }
        Cookie[] cookies = matcher.match(host, conn.getPort(),
            getPath(), conn.isSecure(), state.getCookies());
        if ((cookies != null) && (cookies.length > 0)) {
            if (getParams().isParameterTrue(HttpMethodParams.SINGLE_COOKIE_HEADER)) {
                // In strict mode put all cookies on the same header
                putAllCookiesInASingleHeader(host, matcher, cookies);
            } else {
                // In non-strict mode put each cookie on a separate header
                for (int i = 0; i < cookies.length; i++) {
                    String s = matcher.formatCookie(cookies[i]);
                    getRequestHeaderGroup().addHeader(new Header(HttpHeader.COOKIE, s, true));
                }
            }
            if (matcher instanceof CookieVersionSupport) {
                CookieVersionSupport versupport = (CookieVersionSupport) matcher;
                int ver = versupport.getVersion();
                boolean needVersionHeader = false;
                for (int i = 0; i < cookies.length; i++) {
                    if (ver != cookies[i].getVersion()) {
                        needVersionHeader = true;
                    }
                }
                if (needVersionHeader) {
                    // Advertise cookie version support
                    getRequestHeaderGroup().addHeader(versupport.getVersionHeader());
                }
            }
        }
    }"
"@Override
    public void setWeights(Map<String, INDArray> weights) throws InvalidKerasConfigurationException {
        this.weights = new HashMap<>();

        INDArray dW;
        if (weights.containsKey(conf.getLAYER_PARAM_NAME_DEPTH_WISE_KERNEL()))
            dW = weights.get(conf.getLAYER_PARAM_NAME_DEPTH_WISE_KERNEL());
        else
            throw new InvalidKerasConfigurationException(
                    ""Keras DepthwiseConvolution2D layer does not contain parameter ""
                            + conf.getLAYER_PARAM_NAME_DEPTH_WISE_KERNEL());

        this.weights.put(SeparableConvolutionParamInitializer.DEPTH_WISE_WEIGHT_KEY, dW);
        if (hasBias) {
            INDArray bias;
            if (kerasMajorVersion == 2 && weights.containsKey(""bias""))
                bias = weights.get(""bias"");
            else if (kerasMajorVersion == 1 && weights.containsKey(""b""))
                bias = weights.get(""b"");
            else
                throw new InvalidKerasConfigurationException(
                        ""Keras DepthwiseConvolution2D layer does not contain bias parameter"");
            this.weights.put(SeparableConvolutionParamInitializer.BIAS_KEY, bias);

        }

    }"
"public SDVariable var(@NonNull String name, @NonNull VariableType variableType, WeightInitScheme weightInitScheme,
                             org.nd4j.linalg.api.buffer.DataType dataType, long... shape) {
        if (variables.containsKey(name) && variables.get(name).getVariable().getArr() != null)
            throw new IllegalArgumentException(""Another variable with the name "" + name + "" already exists."");

        if (name == null || name.length() < 1)
            name = getNewVarName();


        SDVariable ret = new SDVariable(name, variableType, this, shape, dataType, weightInitScheme);
        addVariable(ret);

        if(variableType == VariableType.PLACEHOLDER){
            setOriginalPlaceHolderShape(name, shape);
            putShapeForVarName(name, shape);
        }
        return ret;
    }"
"public boolean isSet(_Fields field) {
    if (field == null) {
      throw new IllegalArgumentException();
    }

    switch (field) {
    case COLUMN_NAME:
      return isSetColumnName();
    case TYPE_DESC:
      return isSetTypeDesc();
    case POSITION:
      return isSetPosition();
    case COMMENT:
      return isSetComment();
    }
    throw new IllegalStateException();
  }"
"public static Row project(Row row, int[] fields) {
		final Row newRow = new Row(fields.length);
		for (int i = 0; i < fields.length; i++) {
			newRow.fields[i] = row.fields[fields[i]];
		}
		return newRow;
	}"
"public void fitSequences(JavaRDD<Sequence<T>> corpus) {
        /**
         * Basically all we want for base implementation here is 3 things:
         * a) build vocabulary
         * b) build huffman tree
         * c) do training
         *
         * in this case all classes extending SeqVec, like deepwalk or word2vec will be just building their RDD<Sequence<T>>,
         * and calling this method for training, instead implementing own routines
         */

        validateConfiguration();

        if (ela == null) {
            try {
                ela = (SparkElementsLearningAlgorithm) Class.forName(configuration.getElementsLearningAlgorithm())
                                .newInstance();
            } catch (Exception e) {
                throw new RuntimeException(e);
            }
        }


        if (workers > 1) {
            log.info(""Repartitioning corpus to {} parts..."", workers);
            corpus.repartition(workers);
        }

        if (storageLevel != null)
            corpus.persist(storageLevel);

        final JavaSparkContext sc = new JavaSparkContext(corpus.context());

        // this will have any effect only if wasn't called before, in extension classes
        broadcastEnvironment(sc);

        Counter<Long> finalCounter;
        long numberOfSequences = 0;

        /**
         * Here we s
         */
        if (paramServerConfiguration == null) {
            paramServerConfiguration = VoidConfiguration.builder()
                    .numberOfShards(2).unicastPort(40123).multicastPort(40124).build();
            paramServerConfiguration.setFaultToleranceStrategy(FaultToleranceStrategy.NONE);
        }

        isAutoDiscoveryMode = paramServerConfiguration.getShardAddresses() != null
                        && !paramServerConfiguration.getShardAddresses().isEmpty() ? false : true;

        Broadcast<VoidConfiguration> paramServerConfigurationBroadcast = null;

        if (isAutoDiscoveryMode) {
            log.info(""Trying auto discovery mode..."");

            elementsFreqAccumExtra = corpus.context().accumulator(new ExtraCounter<Long>(),
                            new ExtraElementsFrequenciesAccumulator());

            ExtraCountFunction<T> elementsCounter =
                            new ExtraCountFunction<>(elementsFreqAccumExtra, configuration.isTrainSequenceVectors());

            JavaRDD<Pair<Sequence<T>, Long>> countedCorpus = corpus.map(elementsCounter);

            // just to trigger map function, since we need huffman tree before proceeding
            numberOfSequences = countedCorpus.count();

            finalCounter = elementsFreqAccumExtra.value();

            ExtraCounter<Long> spareReference = (ExtraCounter<Long>) finalCounter;

            // getting list of available hosts
            Set<NetworkInformation> availableHosts = spareReference.getNetworkInformation();

            log.info(""availableHosts: {}"", availableHosts);
            if (availableHosts.size() > 1) {
                // now we have to pick N shards and optionally N backup nodes, and pass them within configuration bean
                NetworkOrganizer organizer =
                                new NetworkOrganizer(availableHosts, paramServerConfiguration.getNetworkMask());

                paramServerConfiguration
                                .setShardAddresses(organizer.getSubset(paramServerConfiguration.getNumberOfShards()));

                // backup shards are optional
                if (paramServerConfiguration.getFaultToleranceStrategy() != FaultToleranceStrategy.NONE) {
                    paramServerConfiguration.setBackupAddresses(
                                    organizer.getSubset(paramServerConfiguration.getNumberOfShards(),
                                                    paramServerConfiguration.getShardAddresses()));
                }
            } else {
                // for single host (aka driver-only, aka spark-local) just run on loopback interface
                paramServerConfiguration.setShardAddresses(
                                Arrays.asList(""127.0.0.1:"" + paramServerConfiguration.getPortSupplier().getPort()));
                paramServerConfiguration.setFaultToleranceStrategy(FaultToleranceStrategy.NONE);
            }



            log.info(""Got Shards so far: {}"", paramServerConfiguration.getShardAddresses());

            // update ps configuration with real values where required
            paramServerConfiguration.setNumberOfShards(paramServerConfiguration.getShardAddresses().size());
            paramServerConfiguration.setUseHS(configuration.isUseHierarchicSoftmax());
            paramServerConfiguration.setUseNS(configuration.getNegative() > 0);

            paramServerConfigurationBroadcast = sc.broadcast(paramServerConfiguration);

        } else {

            // update ps configuration with real values where required
            paramServerConfiguration.setNumberOfShards(paramServerConfiguration.getShardAddresses().size());
            paramServerConfiguration.setUseHS(configuration.isUseHierarchicSoftmax());
            paramServerConfiguration.setUseNS(configuration.getNegative() > 0);

            paramServerConfigurationBroadcast = sc.broadcast(paramServerConfiguration);


            // set up freqs accumulator
            elementsFreqAccum = corpus.context().accumulator(new Counter<Long>(), new ElementsFrequenciesAccumulator());
            CountFunction<T> elementsCounter =
                            new CountFunction<>(configurationBroadcast, paramServerConfigurationBroadcast,
                                            elementsFreqAccum, configuration.isTrainSequenceVectors());

            // count all sequence elements and their sum
            JavaRDD<Pair<Sequence<T>, Long>> countedCorpus = corpus.map(elementsCounter);

            // just to trigger map function, since we need huffman tree before proceeding
            numberOfSequences = countedCorpus.count();

            // now we grab counter, which contains frequencies for all SequenceElements in corpus
            finalCounter = elementsFreqAccum.value();
        }

        long numberOfElements = (long) finalCounter.totalCount();

        long numberOfUniqueElements = finalCounter.size();

        log.info(""Total number of sequences: {}; Total number of elements entries: {}; Total number of unique elements: {}"",
                        numberOfSequences, numberOfElements, numberOfUniqueElements);

        /*
         build RDD of reduced SequenceElements, just get rid of labels temporary, stick to some numerical values,
         like index or hashcode. So we could reduce driver memory footprint
         */


        // build huffman tree, and update original RDD with huffman encoding info
        shallowVocabCache = buildShallowVocabCache(finalCounter);
        shallowVocabCacheBroadcast = sc.broadcast(shallowVocabCache);

        // FIXME: probably we need to reconsider this approach
        JavaRDD<T> vocabRDD = corpus
                        .flatMap(new VocabRddFunctionFlat<T>(configurationBroadcast, paramServerConfigurationBroadcast))
                        .distinct();
        vocabRDD.count();

        /**
         * now we initialize Shards with values. That call should be started from driver which is either Client or Shard in standalone mode.
         */
        VoidParameterServer.getInstance().init(paramServerConfiguration, new RoutedTransport(),
                        ela.getTrainingDriver());
        VoidParameterServer.getInstance().initializeSeqVec(configuration.getLayersSize(), (int) numberOfUniqueElements,
                        119, configuration.getLayersSize() / paramServerConfiguration.getNumberOfShards(),
                        paramServerConfiguration.isUseHS(), paramServerConfiguration.isUseNS());

        // proceed to training
        // also, training function is the place where we invoke ParameterServer
        TrainingFunction<T> trainer = new TrainingFunction<>(shallowVocabCacheBroadcast, configurationBroadcast,
                        paramServerConfigurationBroadcast);
        PartitionTrainingFunction<T> partitionTrainer = new PartitionTrainingFunction<>(shallowVocabCacheBroadcast,
                        configurationBroadcast, paramServerConfigurationBroadcast);

        if (configuration != null)
            for (int e = 0; e < configuration.getEpochs(); e++)
                corpus.foreachPartition(partitionTrainer);
        //corpus.foreach(trainer);


        // we're transferring vectors to ExportContainer
        JavaRDD<ExportContainer<T>> exportRdd =
                        vocabRDD.map(new DistributedFunction<T>(paramServerConfigurationBroadcast,
                                        configurationBroadcast, shallowVocabCacheBroadcast));

        // at this particular moment training should be pretty much done, and we're good to go for export
        if (exporter != null)
            exporter.export(exportRdd);

        // unpersist, if we've persisten corpus after all
        if (storageLevel != null)
            corpus.unpersist();

        log.info(""Training finish, starting cleanup..."");
        VoidParameterServer.getInstance().shutdown();
    }"
"public Set<String> getUnconditionalClasses() {
		Set<String> filtered = new HashSet<>(this.unconditionalClasses);
		filtered.removeAll(this.exclusions);
		return Collections.unmodifiableSet(filtered);
	}"
"public static ByteBuf copyFloat(float... values) {
        if (values == null || values.length == 0) {
            return EMPTY_BUFFER;
        }
        ByteBuf buffer = buffer(values.length * 4);
        for (float v: values) {
            buffer.writeFloat(v);
        }
        return buffer;
    }"
"public static String numberToString(Number number) throws JSONException {
		if (number == null) {
			throw new JSONException(""Number must be non-null"");
		}

		double doubleValue = number.doubleValue();
		JSON.checkDouble(doubleValue);

		// the original returns ""-0"" instead of ""-0.0"" for negative zero
		if (number.equals(NEGATIVE_ZERO)) {
			return ""-0"";
		}

		long longValue = number.longValue();
		if (doubleValue == longValue) {
			return Long.toString(longValue);
		}

		return number.toString();
	}"
"public void registerMapper(Class<?> mapperClass) {
        if (!registerMapper.containsKey(mapperClass)) {
            registerClass.add(mapperClass);
            registerMapper.put(mapperClass, fromMapperClass(mapperClass));
        }
        //自动注册继承的接口
        Class<?>[] interfaces = mapperClass.getInterfaces();
        if (interfaces != null && interfaces.length > 0) {
            for (Class<?> anInterface : interfaces) {
                registerMapper(anInterface);
            }
        }
    }"
"public Calendar floor(long t) {
        Calendar cal = new GregorianCalendar(Locale.US);
        cal.setTimeInMillis(t);
        return floor(cal);
    }"
"protected AddressResolver<InetSocketAddress> newAddressResolver(EventLoop eventLoop,
                                                                    NameResolver<InetAddress> resolver)
            throws Exception {
        return new InetSocketAddressResolver(eventLoop, resolver);
    }"
"public void removeToken(String name) {
        if (name == null || name.isEmpty()) {
            return;
        }

        for (Iterator<AntiCsrfParamToken> it = tokens.iterator(); it.hasNext();) {
            AntiCsrfParamToken token = it.next();
            if (name.equals(token.getName())) {
                it.remove();
                if (token.isEnabled()) {
                    this.enabledTokensNames.remove(name);
                }
                break;
            }
        }
    }"
"@SuppressWarnings(""deprecation"")
    public static ByteBuf setShortBE(ByteBuf buf, int index, int shortValue) {
        return buf.order() == ByteOrder.BIG_ENDIAN? buf.setShort(index, shortValue) : buf.setShortLE(index, shortValue);
    }"
"private void flush() {
    try {
      QueuedCommand cmd;
      int i = 0;
      boolean flushedOnce = false;
      while ((cmd = queue.poll()) != null) {
        cmd.run(channel);
        if (++i == DEQUE_CHUNK_SIZE) {
          i = 0;
          // Flush each chunk so we are releasing buffers periodically. In theory this loop
          // might never end as new events are continuously added to the queue, if we never
          // flushed in that case we would be guaranteed to OOM.
          channel.flush();
          flushedOnce = true;
        }
      }
      // Must flush at least once, even if there were no writes.
      if (i != 0 || !flushedOnce) {
        channel.flush();
      }
    } finally {
      // Mark the write as done, if the queue is non-empty after marking trigger a new write.
      scheduled.set(false);
      if (!queue.isEmpty()) {
        scheduleFlush();
      }
    }
  }"
"public static SocketAddress getRemoteAddress(AsynchronousSocketChannel channel) {
		try {
			return (null == channel) ? null : channel.getRemoteAddress();
		} catch (ClosedChannelException e) {
			// Channel未打开或已关闭，返回null表示未连接
			return null;
		} catch (IOException e) {
			throw new IORuntimeException(e);
		}
	}"
"public static String signParams(SymmetricCrypto crypto, Map<?, ?> params) {
		return signParams(crypto, params, StrUtil.EMPTY, StrUtil.EMPTY, true);
	}"
"public Collection<TrafficCounter> channelTrafficCounters() {
        return new AbstractCollection<TrafficCounter>() {
            @Override
            public Iterator<TrafficCounter> iterator() {
                return new Iterator<TrafficCounter>() {
                    final Iterator<PerChannel> iter = channelQueues.values().iterator();
                    @Override
                    public boolean hasNext() {
                        return iter.hasNext();
                    }
                    @Override
                    public TrafficCounter next() {
                        return iter.next().channelTrafficCounter;
                    }
                    @Override
                    public void remove() {
                        throw new UnsupportedOperationException();
                    }
                };
            }
            @Override
            public int size() {
                return channelQueues.size();
            }
        };
    }"
"public void addParamPanel(String[] parentParams, AbstractParamPanel panel, boolean sort) {
        addParamPanel(parentParams, panel.getName(), panel, sort);
    }"
"@WorkerThread
  public static LottieResult<LottieComposition> fromJsonStringSync(String json, @Nullable String cacheKey) {
    return fromJsonReaderSync(new JsonReader(new StringReader(json)), cacheKey);
  }"
"public String expand(Map<String, ?> variables) {
    if (variables == null) {
      throw new IllegalArgumentException(""variable map is required."");
    }

    /* resolve all expressions within the template */
    StringBuilder resolved = new StringBuilder();
    for (TemplateChunk chunk : this.templateChunks) {
      if (chunk instanceof Expression) {
        String resolvedExpression = this.resolveExpression((Expression) chunk, variables);
        if (resolvedExpression != null) {
          resolved.append(resolvedExpression);
        }
      } else {
        /* chunk is a literal value */
        resolved.append(chunk.getValue());
      }
    }
    return resolved.toString();
  }"
"public void releaseExecutionMemory(long size, MemoryConsumer consumer) {
    logger.debug(""Task {} release {} from {}"", taskAttemptId, Utils.bytesToString(size), consumer);
    memoryManager.releaseExecutionMemory(size, taskAttemptId, consumer.getMode());
  }"
"private String encode(String value) {
    return this.encode.isEncodingRequired() ? UriUtils.encode(value, this.charset) : value;
  }"
"public static List<String[]> convertSentenceToNER(Sentence sentence, NERTagSet tagSet)
    {
        List<String[]> collector = new LinkedList<String[]>();
        Set<String> nerLabels = tagSet.nerLabels;
        for (IWord word : sentence.wordList)
        {
            if (word instanceof CompoundWord)
            {
                List<Word> wordList = ((CompoundWord) word).innerList;
                Word[] words = wordList.toArray(new Word[0]);

                if (nerLabels.contains(word.getLabel()))
                {
                    collector.add(new String[]{words[0].value, words[0].label, tagSet.B_TAG_PREFIX + word.getLabel()});
                    for (int i = 1; i < words.length - 1; i++)
                    {
                        collector.add(new String[]{words[i].value, words[i].label, tagSet.M_TAG_PREFIX + word.getLabel()});
                    }
                    collector.add(new String[]{words[words.length - 1].value, words[words.length - 1].label,
                        tagSet.E_TAG_PREFIX + word.getLabel()});
                }
                else
                {
                    for (Word w : words)
                    {
                        collector.add(new String[]{w.value, w.label, tagSet.O_TAG});
                    }
                }
            }
            else
            {
                if (nerLabels.contains(word.getLabel()))
                {
                    // 单个实体
                    collector.add(new String[]{word.getValue(), word.getLabel(), tagSet.S_TAG});
                }
                else
                {
                    collector.add(new String[]{word.getValue(), word.getLabel(), tagSet.O_TAG});
                }
            }
        }
        return collector;
    }"
"public ProcStarter launch(Launcher launcher) {
        return launcher.launch().cmds(toFullArguments()).pwd(pwd);
    }"
"public static Field[] getDeclaredFields(Class<?> clazz) throws SecurityException {
		if (null == clazz) {
			return null;
		}
		return clazz.getDeclaredFields();
	}"
"public static CombinationAnnotationElement toCombination(AnnotatedElement annotationEle) {
		if(annotationEle instanceof CombinationAnnotationElement) {
			return (CombinationAnnotationElement)annotationEle;
		}
		return new CombinationAnnotationElement(annotationEle);
	}"
"public static Strictness determineStrictness(Stubbing stubbing, MockCreationSettings mockSettings, Strictness testLevelStrictness) {
        if (stubbing != null && stubbing.getStrictness() != null) {
            return stubbing.getStrictness();
        }

        if (mockSettings.isLenient()) {
            return Strictness.LENIENT;
        }

        return testLevelStrictness;
    }"
"public static int splice(int fd, long offIn, int fdOut, long offOut, long len) throws IOException {
        int res = splice0(fd, offIn, fdOut, offOut, len);
        if (res >= 0) {
            return res;
        }
        return ioResult(""splice"", res, SPLICE_CONNECTION_RESET_EXCEPTION, SPLICE_CLOSED_CHANNEL_EXCEPTION);
    }"
"@Override
	public T deserialize(byte[] message) {
		if (dis != null) {
			dis.setBuffer(message);
		} else {
			dis = new DataInputDeserializer(message);
		}

		try {
			return serializer.deserialize(dis);
		}
		catch (IOException e) {
			throw new RuntimeException(""Unable to deserialize message"", e);
		}
	}"
"protected void processSelectBody(SelectBody selectBody, int level) {
        if (selectBody instanceof PlainSelect) {
            processPlainSelect((PlainSelect) selectBody, level + 1);
        } else if (selectBody instanceof WithItem) {
            WithItem withItem = (WithItem) selectBody;
            if (withItem.getSelectBody() != null) {
                processSelectBody(withItem.getSelectBody(), level + 1);
            }
        } else {
            SetOperationList operationList = (SetOperationList) selectBody;
            if (operationList.getSelects() != null && operationList.getSelects().size() > 0) {
                List<SelectBody> plainSelects = operationList.getSelects();
                for (SelectBody plainSelect : plainSelects) {
                    processSelectBody(plainSelect, level + 1);
                }
            }
        }
    }"
"Closure createClosure(String rootMethodName, final Object closureObj) throws Exception {
        if (!isClosureCommand(closureObj)) {
            throw new RuntimeException(format(ERROR_TYPE_MESSAGE, rootMethodName,
                    getClosureCommandType().getName()).getMessage());
        }
        Method closureMethod = closureObj.getClass().getMethod(INVOKE_METHOD);
        return new Closure(closureMethod, closureObj);
    }"
"public boolean init(Resource resource, Charset charset, boolean isUseVariable) {
		if (resource == null) {
			throw new NullPointerException(""Null setting url define!"");
		}
		this.settingUrl = resource.getUrl();
		this.charset = charset;
		this.isUseVariable = isUseVariable;

		return load();
	}"
"protected void initializeVariable(HistoricVariableInstanceEntity e) {
    if (Context.getCommandContext() != null && e != null && e.getVariableType() != null) {
      e.getValue();

      // make sure JPA entities are cached for later retrieval
      if (JPAEntityVariableType.TYPE_NAME.equals(e.getVariableType().getTypeName()) || JPAEntityListVariableType.TYPE_NAME.equals(e.getVariableType().getTypeName())) {
        ((CacheableVariable) e.getVariableType()).setForceCacheable(true);
      }
    }
  }"
"public synchronized INDArray output(INDArray input, boolean train, INDArray featuresMask, INDArray labelsMask, MemoryWorkspace outputWorkspace) {
        try {
            return outputOfLayerDetached(train, FwdPassType.STANDARD, layers.length - 1, input, featuresMask, labelsMask, outputWorkspace);
        } catch (OutOfMemoryError e) {
            CrashReportingUtil.writeMemoryCrashDump(this, e);
            throw e;
        }
    }"
"private long getSize() {
		long numSegments = 0;
		numSegments += this.availableMemory.size();
		numSegments += this.buckets.length;
		for(InMemoryPartition<T> p : this.partitions) {
			numSegments += p.getBlockCount();
			numSegments += p.numOverflowSegments;
		}
		numSegments += this.compactionMemory.getBlockCount();
		return numSegments*this.segmentSize;
	}"
"@Override
	public Ftp reconnectIfTimeout() {
		String pwd = null;
		try {
			pwd = pwd();
		} catch (FtpException fex) {
			//ignore
		}
		
		if (pwd == null) {
			return this.init();
		}
		return this;
	}"
"private int allocateNode(int d) {
        int id = 1;
        int initial = - (1 << d); // has last d bits = 0 and rest all = 1
        byte val = value(id);
        if (val > d) { // unusable
            return -1;
        }
        while (val < d || (id & initial) == 0) { // id & initial == 1 << d for all ids at depth d, for < d it is 0
            id <<= 1;
            val = value(id);
            if (val > d) {
                id ^= 1;
                val = value(id);
            }
        }
        byte value = value(id);
        assert value == d && (id & initial) == 1 << d : String.format(""val = %d, id & initial = %d, d = %d"",
                value, id & initial, d);
        setValue(id, unusable); // mark as unusable
        updateParentsAlloc(id);
        return id;
    }"
"JSONStringer open(Scope empty, String openBracket) throws JSONException {
		if (this.stack.isEmpty() && this.out.length() > 0) {
			throw new JSONException(""Nesting problem: multiple top-level roots"");
		}
		beforeValue();
		this.stack.add(empty);
		this.out.append(openBracket);
		return this;
	}"
"String[] parseArgs(String[] args) {
    int i = 0;
    boolean driverArgs = true;
    while (driverArgs) {
      if (i >= args.length) {
        break;
      }

      String s = args[i];
      if (s.equals(""-h"") ||
              s.equals(""help"") ||
              s.equals(""-help"") ||
              s.equals(""--help"")) {
        usage();
      }
      else if (s.equals(""-n"") ||
              s.equals(""-nodes"")) {
        i++; if (i >= args.length) { usage(); }
        numNodes = Integer.parseInt(args[i]);
      }
      else if (s.equals(""-o"") ||
              s.equals(""-output"")) {
        i++; if (i >= args.length) { usage(); }
        outputPath = args[i];
      }
      else if (s.equals(""-jobname"")) {
        i++; if (i >= args.length) { usage(); }
        jobtrackerName = args[i];
      }
      else if (s.equals(""-mapperXmx"")) {
        i++; if (i >= args.length) { usage(); }
        mapperXmx = args[i];
      }
      else if (s.equals(""-extramempercent"")) {
        i++; if (i >= args.length) { usage(); }
        extraMemPercent = Integer.parseInt(args[i]);
      }
      else if (s.equals(""-mapperPermSize"")) {
        i++; if (i >= args.length) { usage(); }
        mapperPermSize = args[i];
      }
      else if (s.equals(""-driverif"")) {
        i++; if (i >= args.length) { usage(); }
        driverCallbackIp = args[i];
      }
      else if (s.equals(""-driverport"")) {
        i++; if (i >= args.length) { usage(); }
        driverCallbackPort = Integer.parseInt(args[i]);
      }
      else if (s.equals(""-driverportrange"")) {
        i++; if (i >= args.length) { usage(); }
        driverCallbackPortRange = PortRange.parse(args[i]);
      }
      else if (s.equals(""-network"")) {
        i++; if (i >= args.length) { usage(); }
        network = args[i];
      }
      else if (s.equals(""-timeout"")) {
        i++; if (i >= args.length) { usage(); }
        cloudFormationTimeoutSeconds = Integer.parseInt(args[i]);
      }
      else if (s.equals(""-disown"")) {
        disown = true;
      }
      else if (s.equals(""-notify"")) {
        i++; if (i >= args.length) { usage(); }
        clusterReadyFileName = args[i];
      }
      else if (s.equals(""-nthreads"")) {
        i++; if (i >= args.length) { usage(); }
        nthreads = Integer.parseInt(args[i]);
      }
      else if (s.equals(""-context_path"")) {
        i++; if (i >= args.length) { usage(); }
        contextPath = args[i];
      }
      else if (s.equals(""-baseport"")) {
        i++; if (i >= args.length) { usage(); }
        basePort = Integer.parseInt(args[i]);
        if ((basePort < 0) || (basePort > 65535)) {
            error(""Base port must be between 1 and 65535"");
        }
      }
      else if (s.equals(""-port_offset"")) {
        i++; if (i >= args.length) { usage(); }
        portOffset = Integer.parseInt(args[i]);
        if ((portOffset <= 0) || (portOffset > 65534)) {
          error(""Port offset must be between 1 and 65534"");
        }
      }
      else if (s.equals(""-beta"")) {
        beta = true;
      }
      else if (s.equals(""-random_udp_drop"")) {
        enableRandomUdpDrop = true;
      }
      else if (s.equals(""-ea"")) {
        enableExceptions = true;
      }
      else if (s.equals(""-verbose:gc"") && !JAVA_VERSION.useUnifiedLogging()) {
        if (!JAVA_VERSION.useUnifiedLogging()) {
          enableVerboseGC = true;
        } else {
          error(""Parameter -verbose:gc is unusable, running on JVM with deprecated GC debugging flags."");
        }
      } else if (s.equals(""-Xlog:gc=info"")) {
        if (JAVA_VERSION.useUnifiedLogging()) {
          enableVerboseGC = true;
        } else {
          error(""Parameter -verbose:gc is unusable, running on JVM without unified JVM logging."");
        }
      }
      else if (s.equals(""-verbose:class"")) {
        enableVerboseClass = true;
      }
      else if (s.equals(""-XX:+PrintCompilation"")) {
        enablePrintCompilation = true;
      }
      else if (s.equals(""-exclude"")) {
        enableExcludeMethods = true;
      }
      else if (s.equals(""-Dlog4j.defaultInitOverride=true"")) {
        enableLog4jDefaultInitOverride = true;
      }
      else if (s.equals(""-debug"")) {
        enableDebug = true;
      }
      else if (s.equals(""-suspend"")) {
        enableSuspend = true;
      }
      else if (s.equals(""-debugport"")) {
        i++; if (i >= args.length) { usage(); }
        debugPort = Integer.parseInt(args[i]);
        if ((debugPort < 0) || (debugPort > 65535)) {
          error(""Debug port must be between 1 and 65535"");
        }
      } else if (s.equals(""-XX:+PrintGCDetails"")) {
        if (!JAVA_VERSION.useUnifiedLogging()) {
          enablePrintGCDetails = true;
        } else {
          error(""Parameter -XX:+PrintGCDetails is unusable, running on JVM with deprecated GC debugging flags."");
        }
      }
      else if (s.equals(""-XX:+PrintGCTimeStamps"")) {
        if (!JAVA_VERSION.useUnifiedLogging()) {
          enablePrintGCDetails = true;
        } else {
          error(""Parameter -XX:+PrintGCTimeStamps is unusable, running on JVM with deprecated GC debugging flags."");
        }
      }
      else if (s.equals(""-gc"")) {
        enableVerboseGC = true;
        enablePrintGCDetails = true;
        enablePrintGCTimeStamps = true;
      }
      else if (s.equals(""-nogc"")) {
        enableVerboseGC = false;
        enablePrintGCDetails = false;
        enablePrintGCTimeStamps = false;
      }
      else if (s.equals(""-flow_dir"")) {
        i++; if (i >= args.length) { usage(); }
        flowDir = args[i];
      }
      else if (s.equals(""-J"")) {
        i++; if (i >= args.length) { usage(); }
        extraArguments.add(args[i]);
      }
      else if (s.equals(""-JJ"")) {
        i++; if (i >= args.length) { usage(); }
        extraJvmArguments.add(args[i]);
      }
      else if (s.equals(""-jks"")) {
        i++; if (i >= args.length) { usage(); }
        jksFileName = args[i];
      }
      else if (s.equals(""-jks_pass"")) {
        i++; if (i >= args.length) { usage(); }
        jksPass = args[i];
      }
      else if (s.equals(""-internal_secure_connections"")) {
        internal_secure_connections = true;
      }
      else if (s.equals(""-internal_security_conf"") || s.equals(""-internal_security"")) {
        if(s.equals(""-internal_security"")){
          System.out.println(""The '-internal_security' configuration is deprecated. "" +
                  ""Please use '-internal_security_conf' instead."");
        }
        i++; if (i >= args.length) { usage(); }
        securityConf = args[i];
      }
      else if (s.equals(""-hash_login"")) {
        hashLogin = true;
      }
      else if (s.equals(""-ldap_login"")) {
        ldapLogin = true;
      }
      else if (s.equals(""-kerberos_login"")) {
        kerberosLogin = true;
      }
      else if (s.equals(""-pam_login"")) {
        pamLogin = true;
      }
      else if (s.equals(""-login_conf"")) {
        i++; if (i >= args.length) { usage(); }
        loginConfFileName = args[i];
      }
      else if (s.equals(""-form_auth"")) {
        formAuth = true;
      }
      else if (s.equals(""-session_timeout"")) {
        i++; if (i >= args.length) { usage(); }
        sessionTimeout = args[i];
      }
      else if (s.equals(""-user_name"")) {
        i++; if (i >= args.length) { usage(); }
        userName = args[i];
      }
      else if (s.equals(""-client"")) {
        client = true;
        driverArgs = false;
      }
      else if (s.equals(""-proxy"")) {
        proxy = true;
        driverArgs = false;
      } else if (s.equals(""-run_as_user"")) {
        i++; if (i >= args.length) { usage(); }
        runAsUser = args[i];
      } else if (s.equals(""-principal"")) {
        i++; if (i >= args.length) { usage(); }
        principal = args[i];
      } else if (s.equals(""-keytab"")) {
        i++; if (i >= args.length) { usage (); }
        keytabPath = args[i];
      } else if (s.equals(""-report_hostname"")) {
        reportHostname = true;
      } else if (s.equals(""-driver_debug"")) {
        driverDebug = true;
      } else if (s.equals(""-hiveHost"")) {
        i++; if (i >= args.length) { usage (); }
        hiveHost = args[i];
      } else if (s.equals(""-hivePrincipal"")) {
        i++; if (i >= args.length) { usage (); }
        hivePrincipal = args[i];
      } else if (s.equals(""-refreshTokens"")) {
        refreshTokens = true;
      } else {
        error(""Unrecognized option "" + s);
      }

      i++;
    }
    String[] otherArgs = new String[Math.max(args.length - i, 0)];
    for (int j = 0; j < otherArgs.length; j++)
      otherArgs[j] = args[i++];
    return otherArgs;
  }"
"private List<Tuple2<String, String>> getHelpOptions() {
		final List<Tuple2<String, String>> options = new ArrayList<>();

		options.add(Tuple2.of(""Q"", CliStrings.RESULT_QUIT));
		options.add(Tuple2.of(""R"", CliStrings.RESULT_REFRESH));

		options.add(Tuple2.of(""+"", CliStrings.RESULT_INC_REFRESH));
		options.add(Tuple2.of(""-"", CliStrings.RESULT_DEC_REFRESH));

		options.add(Tuple2.of(""O"", CliStrings.RESULT_OPEN));

		return options;
	}"
"public void fit(DataSet dataSet) {
        if (numInputArrays != 1 || numOutputArrays != 1)
            throw new UnsupportedOperationException(""Cannot train ComputationGraph network with ""
                    + "" multiple inputs or outputs using a DataSet"");

        boolean hasMaskArrays = dataSet.hasMaskArrays();
        if (hasMaskArrays) {
            INDArray[] fMask = (dataSet.getFeaturesMaskArray() != null ? new INDArray[]{dataSet.getFeaturesMaskArray()}
                    : null);
            INDArray[] lMask = (dataSet.getLabelsMaskArray() != null ? new INDArray[]{dataSet.getLabelsMaskArray()}
                    : null);
            fit(new INDArray[]{dataSet.getFeatures()}, new INDArray[]{dataSet.getLabels()}, fMask, lMask);
        } else {
            fit(new INDArray[]{dataSet.getFeatures()}, new INDArray[]{dataSet.getLabels()});
        }

        if (hasMaskArrays)
            clearLayerMaskArrays();

        clearLayersStates();
    }"
"public static String getLocalhostStr() {
		InetAddress localhost = getLocalhost();
		if (null != localhost) {
			return localhost.getHostAddress();
		}
		return null;
	}"
"public static Class<?> unwrapCglib(Object instance) {
		Validate.notNull(instance, ""Instance must not be null"");
		Class<?> clazz = instance.getClass();
		if ((clazz != null) && clazz.getName().contains(CGLIB_CLASS_SEPARATOR)) {
			Class<?> superClass = clazz.getSuperclass();
			if ((superClass != null) && !Object.class.equals(superClass)) {
				return superClass;
			}
		}
		return clazz;
	}"
"public static Class findMethodParameterClass(Method method, int parm) {
    Class[] clzes = method.getParameterTypes();

    if (clzes.length <= parm)
      throw H2O.fail(""Asked for the class of parameter number: "" + parm + "" of method: "" + method + "", which only has: "" + clzes.length + "" parameters."");

    return clzes[parm];
  }"
"@SuppressWarnings({ ""unchecked"", ""rawtypes"" })
	public void set(String fieldName, Object value) throws BeanException{
		if(Map.class.isAssignableFrom(beanClass)){
			((Map)bean).put(fieldName, value);
			return;
		}else{
			try {
				final Method setter = BeanUtil.getBeanDesc(beanClass).getSetter(fieldName);
				if(null == setter){
					throw new BeanException(""No set method for {}"", fieldName);
				}
				setter.invoke(this.bean, value);
			} catch (Exception e) {
				throw new BeanException(e);
			}
		}
	}"
"public long deserialize(Row row, String name) {
    return 1000L * TypeCodec.bigint().deserialize(row.getBytesUnsafe(name), protocolVersion);
  }"
"public static  List<FieldVector> toArrowColumnsString(final BufferAllocator bufferAllocator, final Schema schema, List<List<String>> dataVecRecord) {
        int numRows = dataVecRecord.size();

        List<FieldVector> ret = createFieldVectors(bufferAllocator,schema,numRows);
        /**
         * Need to change iteration scheme
         */

        for(int j = 0; j < schema.numColumns(); j++) {
            FieldVector fieldVector = ret.get(j);
            for(int row = 0; row < numRows; row++) {
                String writable = dataVecRecord.get(row).get(j);
                setValue(schema.getType(j),fieldVector,writable,row);
            }

        }

        return ret;
    }"
"private void readAll(final boolean readModelDescriptor) throws IOException {
    String[] columns = (String[]) _lkv.get(""[columns]"");
    String[][] domains = parseModelDomains(columns.length);
    boolean isSupervised = readkv(""supervised"");
    _model = makeModel(columns, domains, isSupervised ? columns[columns.length - 1] : null);
    _model._uuid = readkv(""uuid"");
    _model._h2oVersion = readkv(""h2o_version"", ""unknown"");
    _model._category = hex.ModelCategory.valueOf((String) readkv(""category""));
    _model._supervised = isSupervised;
    _model._nfeatures = readkv(""n_features"");
    _model._nclasses = readkv(""n_classes"");
    _model._balanceClasses = readkv(""balance_classes"");
    _model._defaultThreshold = readkv(""default_threshold"");
    _model._priorClassDistrib = readkv(""prior_class_distrib"");
    _model._modelClassDistrib = readkv(""model_class_distrib"");
    _model._offsetColumn = readkv(""offset_column"");
    _model._mojo_version = ((Number) readkv(""mojo_version"")).doubleValue();
    checkMaxSupportedMojoVersion();
    readModelData();
    if (readModelDescriptor) {
      _model._modelDescriptor = readModelDescriptor();
    }
  }"
"@SuppressWarnings(""unchecked"")
  protected <T> T readkv(String key, T defVal) {
    Object val = _lkv.get(key);
    if (! (val instanceof RawValue))
      return val != null ? (T) val : defVal;
    return ((RawValue) val).parse(defVal);
  }"
"public Map<String, Object> getMBeanResult(final String mbeanName) {
    final Map<String, Object> ret = new HashMap<>();
    try {
      final ObjectName name = new ObjectName(mbeanName);
      final MBeanInfo info = getMBeanInfo(name);

      final MBeanAttributeInfo[] mbeanAttrs = info.getAttributes();
      final Map<String, Object> attributes = new TreeMap<>();

      for (final MBeanAttributeInfo attrInfo : mbeanAttrs) {
        final Object obj = getMBeanAttribute(name, attrInfo.getName());
        attributes.put(attrInfo.getName(), obj);
      }

      ret.put(""attributes"", attributes);
    } catch (final Exception e) {
      logger.error(""Invalid MBean Name. name = "" + mbeanName, e);
      ret.put(""error"", ""'"" + mbeanName + ""' is not a valid mBean name"");
    }

    return ret;
  }"
"@Override
   public Connection getConnection() throws SQLException
   {
      Connection conn = null;
      if (this.hds != null) {
         conn = this.hds.getConnection();
      }

      return conn;
   }"
"public double gMeasure(EvaluationAveraging averaging) {
        int nClasses = confusion().getClasses().size();
        if (averaging == EvaluationAveraging.Macro) {
            double macroGMeasure = 0.0;
            for (int i = 0; i < nClasses; i++) {
                macroGMeasure += gMeasure(i);
            }
            macroGMeasure /= nClasses;
            return macroGMeasure;
        } else if (averaging == EvaluationAveraging.Micro) {
            long tpCount = 0;
            long fpCount = 0;
            long fnCount = 0;
            for (int i = 0; i < nClasses; i++) {
                tpCount += truePositives.getCount(i);
                fpCount += falsePositives.getCount(i);
                fnCount += falseNegatives.getCount(i);
            }
            double precision = EvaluationUtils.precision(tpCount, fpCount, DEFAULT_EDGE_VALUE);
            double recall = EvaluationUtils.recall(tpCount, fnCount, DEFAULT_EDGE_VALUE);
            return EvaluationUtils.gMeasure(precision, recall);
        } else {
            throw new UnsupportedOperationException(""Unknown averaging approach: "" + averaging);
        }
    }"
"public static Map<String, String[]> getParams(ServletRequest request) {
		final Map<String, String[]> map = request.getParameterMap();
		return Collections.unmodifiableMap(map);
	}"
"private <IN1, IN2> TypeInformation<?>[] createSubTypesInfo(Type originalType, ParameterizedType definingType,
			ArrayList<Type> typeHierarchy, TypeInformation<IN1> in1Type, TypeInformation<IN2> in2Type, boolean lenient) {
		Type[] subtypes = new Type[definingType.getActualTypeArguments().length];

		// materialize possible type variables
		for (int i = 0; i < subtypes.length; i++) {
			final Type actualTypeArg = definingType.getActualTypeArguments()[i];
			// materialize immediate TypeVariables
			if (actualTypeArg instanceof TypeVariable<?>) {
				subtypes[i] = materializeTypeVariable(typeHierarchy, (TypeVariable<?>) actualTypeArg);
			}
			// class or parameterized type
			else {
				subtypes[i] = actualTypeArg;
			}
		}

		TypeInformation<?>[] subTypesInfo = new TypeInformation<?>[subtypes.length];
		for (int i = 0; i < subtypes.length; i++) {
			final ArrayList<Type> subTypeHierarchy = new ArrayList<>(typeHierarchy);
			subTypeHierarchy.add(subtypes[i]);
			// sub type could not be determined with materializing
			// try to derive the type info of the TypeVariable from the immediate base child input as a last attempt
			if (subtypes[i] instanceof TypeVariable<?>) {
				subTypesInfo[i] = createTypeInfoFromInputs((TypeVariable<?>) subtypes[i], subTypeHierarchy, in1Type, in2Type);

				// variable could not be determined
				if (subTypesInfo[i] == null && !lenient) {
					throw new InvalidTypesException(""Type of TypeVariable '"" + ((TypeVariable<?>) subtypes[i]).getName() + ""' in '""
						+ ((TypeVariable<?>) subtypes[i]).getGenericDeclaration()
						+ ""' could not be determined. This is most likely a type erasure problem. ""
						+ ""The type extraction currently supports types with generic variables only in cases where ""
						+ ""all variables in the return type can be deduced from the input type(s). ""
						+ ""Otherwise the type has to be specified explicitly using type information."");
				}
			} else {
				// create the type information of the subtype or null/exception
				try {
					subTypesInfo[i] = createTypeInfoWithTypeHierarchy(subTypeHierarchy, subtypes[i], in1Type, in2Type);
				} catch (InvalidTypesException e) {
					if (lenient) {
						subTypesInfo[i] = null;
					} else {
						throw e;
					}
				}
			}
		}

		// check that number of fields matches the number of subtypes
		if (!lenient) {
			Class<?> originalTypeAsClass = null;
			if (isClassType(originalType)) {
				originalTypeAsClass = typeToClass(originalType);
			}
			checkNotNull(originalTypeAsClass, ""originalType has an unexpected type"");
			// check if the class we assumed to conform to the defining type so far is actually a pojo because the
			// original type contains additional fields.
			// check for additional fields.
			int fieldCount = countFieldsInClass(originalTypeAsClass);
			if(fieldCount > subTypesInfo.length) {
				return null;
			}
		}

		return subTypesInfo;
	}"
"@Override
    public InputType getOutputType(InputType... inputType) throws InvalidKerasConfigurationException {
        if (inputType.length > 1)
            throw new InvalidKerasConfigurationException(
                    ""Keras Convolution layer accepts only one input (received "" + inputType.length + "")"");
        return this.getDeconvolution2DLayer().getOutputType(-1, inputType[0]);
    }"
"public ApiDescriptionBuilder operations(List<Operation> operations) {
    if (operations != null) {
      this.operations = operations.stream().sorted(operationOrdering).collect(toList());
    }
    return this;
  }"
"public Map<String, Double> accuracy(List<String> questions) {
        return modelUtils.accuracy(questions);
    }"
"public Postcard withBundle(@Nullable String key, @Nullable Bundle value) {
        mBundle.putBundle(key, value);
        return this;
    }"
"protected void initInputReaders() throws Exception {
		final int numInputs = getNumTaskInputs();
		final MutableReader<?>[] inputReaders = new MutableReader<?>[numInputs];

		int currentReaderOffset = 0;

		for (int i = 0; i < numInputs; i++) {
			//  ---------------- create the input readers ---------------------
			// in case where a logical input unions multiple physical inputs, create a union reader
			final int groupSize = this.config.getGroupSize(i);

			if (groupSize == 1) {
				// non-union case
				inputReaders[i] = new MutableRecordReader<IOReadableWritable>(
						getEnvironment().getInputGate(currentReaderOffset),
						getEnvironment().getTaskManagerInfo().getTmpDirectories());
			} else if (groupSize > 1){
				// union case
				InputGate[] readers = new InputGate[groupSize];
				for (int j = 0; j < groupSize; ++j) {
					readers[j] = getEnvironment().getInputGate(currentReaderOffset + j);
				}
				inputReaders[i] = new MutableRecordReader<IOReadableWritable>(
						new UnionInputGate(readers),
						getEnvironment().getTaskManagerInfo().getTmpDirectories());
			} else {
				throw new Exception(""Illegal input group size in task configuration: "" + groupSize);
			}

			currentReaderOffset += groupSize;
		}
		this.inputReaders = inputReaders;

		// final sanity check
		if (currentReaderOffset != this.config.getNumInputs()) {
			throw new Exception(""Illegal configuration: Number of input gates and group sizes are not consistent."");
		}
	}"
"public int compareTo(final Rational val) {
        /* Since we have always kept the denominators positive,
         * simple cross-multiplying works without changing the sign.
         */
        final BigInteger left = a.multiply(val.b);
        final BigInteger right = val.a.multiply(b);
        return left.compareTo(right);
    }"
"public void start() throws Throwable {
		Preconditions.checkState(serverAddress == null && serverShutdownFuture.get() == null,
				serverName + "" is already running @ "" + serverAddress + "". "");

		Iterator<Integer> portIterator = bindPortRange.iterator();
		while (portIterator.hasNext() && !attemptToBind(portIterator.next())) {}

		if (serverAddress != null) {
			log.info(""Started {} @ {}."", serverName, serverAddress);
		} else {
			log.info(""Unable to start {}. All ports in provided range ({}) are occupied."", serverName, bindPortRange);
			throw new FlinkRuntimeException(""Unable to start "" + serverName + "". All ports in provided range are occupied."");
		}
	}"
"@Override
	protected List<Instance> getInstancesForApp(String serviceId) throws Exception {
		List<Instance> instances = new ArrayList<>();
		log.info(""Fetching instances for app: "" + serviceId);
		Application app = eurekaClient.getApplication(serviceId);
		if (app == null) {
			log.warn(""Eureka returned null for app: "" + serviceId);
			return instances;
		}
		try {
			List<InstanceInfo> instancesForApp = app.getInstances();
			if (instancesForApp != null) {
				log.info(""Received instance list for app: "" + serviceId + "", size=""
						+ instancesForApp.size());
				for (InstanceInfo iInfo : instancesForApp) {
					Instance instance = marshall(iInfo);
					if (instance != null) {
						instances.add(instance);
					}
				}
			}
		}
		catch (Exception e) {
			log.warn(""Failed to retrieve instances from Eureka"", e);
		}
		return instances;
	}"
"@SuppressWarnings({ ""serial"", ""unchecked"" })
	public <K, VV> Graph<K, VV, NullValue> vertexTypes(Class<K> vertexKey, Class<VV> vertexValue) {

		if (edgeReader == null) {
			throw new RuntimeException(""The edge input file cannot be null!"");
		}

		DataSet<Edge<K, NullValue>> edges = edgeReader
			.types(vertexKey, vertexKey)
				.name(GraphCsvReader.class.getName())
			.map(new Tuple2ToEdgeMap<>())
				.name(""To Edge"");

		// the vertex value can be provided by an input file or a user-defined mapper
		if (vertexReader != null) {
			DataSet<Vertex<K, VV>> vertices = vertexReader
				.types(vertexKey, vertexValue)
					.name(GraphCsvReader.class.getName())
				.map(new Tuple2ToVertexMap<>())
					.name(""Type conversion"");

			return Graph.fromDataSet(vertices, edges, executionContext);
		}
		else if (mapper != null) {
			return Graph.fromDataSet(edges, (MapFunction<K, VV>) mapper, executionContext);
		}
		else {
			throw new RuntimeException(""Vertex values have to be specified through a vertices input file""
					+ ""or a user-defined map function."");
		}
	}"
"protected void handleResponse(HttpRequest<?> request, MutableHttpResponse<?> response) {
        HttpHeaders headers = request.getHeaders();
        Optional<String> originHeader = headers.getOrigin();
        originHeader.ifPresent(requestOrigin -> {

            Optional<CorsOriginConfiguration> optionalConfig = getConfiguration(requestOrigin);

            if (optionalConfig.isPresent()) {
                CorsOriginConfiguration config = optionalConfig.get();

                if (CorsUtil.isPreflightRequest(request)) {
                    Optional<HttpMethod> result = headers.getFirst(ACCESS_CONTROL_REQUEST_METHOD, HttpMethod.class);
                    setAllowMethods(result.get(), response);
                    Argument<List> type = Argument.of(List.class, String.class);
                    Optional<List> allowedHeaders = headers.get(ACCESS_CONTROL_REQUEST_HEADERS, type);
                    allowedHeaders.ifPresent(val ->
                        setAllowHeaders(val, response)
                    );

                    setMaxAge(config.getMaxAge(), response);
                }

                setOrigin(requestOrigin, response);
                setVary(response);
                setExposeHeaders(config.getExposedHeaders(), response);
                setAllowCredentials(config, response);
            }
        });
    }"
"@Deprecated
    public static void initializeClass(Class theClass) {
        // ***HACK*** We ask the VM to create an instance
        // by voluntarily providing illegal arguments to force
        // the VM to run the class' static initializer, while
        // at the same time not running a valid constructor.

        final Constructor[] cons = theClass.getDeclaredConstructors();
        //At least one constructor is guaranteed to be there, but check anyway.
        if (cons != null) {
            if (cons.length > 0 && cons[0] != null) {
                final String[] strs = new String[NUMBER_OF_STRINGS];
                try {
                    cons[0].newInstance((Object[]) strs);
                    // Expecting an exception to be thrown by this call:
                    // IllegalArgumentException: wrong number of Arguments
                } catch (Exception e) {
                    // Ignore - we are interested only in the side
                    // effect - that of getting the static initializers
                    // invoked.  As we do not want to call a valid
                    // constructor to get this side effect, an
                    // attempt is made to call a hopefully
                    // invalid constructor - come on, nobody
                    // would have a constructor that takes in
                    // 256 String arguments ;-)
                    // (In fact, they can't - according to JVM spec
                    // section 4.10, the number of method parameters is limited
                    // to 255 by the definition of a method descriptor.
                    // Constructors count as methods here.)
                }
            }
        }
    }"
"protected void setupToolbarElements(JToolBar toolbar) {
		int x = 0;
		Insets insets = new Insets(0, 4, 0, 2);

		x = this.addToolBarElements(toolbar, TOOLBAR_LOCATION_START, x);

		toolbar.add(new JLabel(Constant.messages.getString(panelPrefix + "".toolbar.context.label"")),
				LayoutHelper.getGBC(x++, 0, 1, 0, insets));
		toolbar.add(getContextSelectComboBox(), LayoutHelper.getGBC(x++, 0, 1, 0, insets));

		x = this.addToolBarElements(toolbar, TOOLBAR_LOCATION_AFTER_CONTEXTS_SELECT, x);

		toolbar.add(new JLabel(), LayoutHelper.getGBC(x++, 0, 1, 1.0)); // Spacer
		if (hasOptions()) {
			toolbar.add(getOptionsButton(), LayoutHelper.getGBC(x++, 0, 1, 0, insets));
		}

		this.addToolBarElements(toolbar, TOOLBAR_LOCATION_END, x);
	}"
"public static <E extends Enum<E>> long generateBits(final Class<E> enumClass, final Iterable<? extends E> values) {
		return EnumUtils.generateBitVector(enumClass, values);
	}"
"@Override
	public void update() {
		synchronized (this) {
			long currentTime = System.currentTimeMillis();
			if (currentTime - lastUpdateTime > updateInterval) {
				lastUpdateTime = currentTime;
				fetchMetrics();
			}
		}
	}"
"public static @CheckForNull Permission fromId(@Nonnull String id) {
        int idx = id.lastIndexOf('.');
        if(idx<0)   return null;

        try {
            // force the initialization so that it will put all its permissions into the list.
            Class cl = Class.forName(id.substring(0,idx),true, Jenkins.getInstance().getPluginManager().uberClassLoader);
            PermissionGroup g = PermissionGroup.get(cl);
            if(g ==null)  return null;
            return g.find(id.substring(idx+1));
        } catch (ClassNotFoundException e) {
            return null;
        }
    }"
"public Executor fixedContextExecutor(final Executor e) {
    final class FixedContextExecutor implements Executor {
      @Override
      public void execute(Runnable r) {
        e.execute(wrap(r));
      }
    }

    return new FixedContextExecutor();
  }"
"public static File getFile(URI resourceUri, String description) throws FileNotFoundException {
        if (!URL_PROTOCOL_FILE.equals(resourceUri.getScheme())) {
            throw new FileNotFoundException(
                description + "" cannot be resolved to absolute file path "" +
                    ""because it does not reside in the file system: "" + resourceUri);
        }
        return new File(resourceUri.getSchemeSpecificPart());
    }"
"public static ContentMatcher getInstance(InputStream xmlInputStream) {
        ContentMatcher cm = new ContentMatcher();

        // Load the pattern definitions from an XML file
        try {
            cm.loadXMLPatternDefinitions(xmlInputStream);
            
        } catch (JDOMException | IOException ex) {
            throw new IllegalArgumentException(""Failed to initialize the ContentMatcher object using that stream"", ex);
        }
        
        return cm;
    }"
"public void notifyNewMessage(Plugin plugin) {
        if (plugin == null) {
            throw new IllegalArgumentException(""Parameter plugin must not be null."");
        }

        PluginStats pluginStats = mapPluginStats.get(plugin.getId());
        if (pluginStats != null) {
            pluginStats.incMessageCount();
        }
    }"
"public SqlBuilder insert(Entity entity, DialectName dialectName) {
		// 验证
		validateEntity(entity);

		if (null != wrapper) {
			// 包装表名
			// entity = wrapper.wrap(entity);
			entity.setTableName(wrapper.wrap(entity.getTableName()));
		}

		final boolean isOracle = ObjectUtil.equal(dialectName, DialectName.ORACLE);// 对Oracle的特殊处理
		final StringBuilder fieldsPart = new StringBuilder();
		final StringBuilder placeHolder = new StringBuilder();

		boolean isFirst = true;
		String field;
		Object value;
		for (Entry<String, Object> entry : entity.entrySet()) {
			field = entry.getKey();
			value = entry.getValue();
			if (StrUtil.isNotBlank(field) /* && null != value */) {
				if (isFirst) {
					isFirst = false;
				} else {
					// 非第一个参数，追加逗号
					fieldsPart.append("", "");
					placeHolder.append("", "");
				}

				this.fields.add(field);
				fieldsPart.append((null != wrapper) ? wrapper.wrap(field) : field);
				if (isOracle && value instanceof String && StrUtil.endWithIgnoreCase((String) value, "".nextval"")) {
					// Oracle的特殊自增键，通过字段名.nextval获得下一个值
					placeHolder.append(value);
				} else {
					placeHolder.append(""?"");
					this.paramValues.add(value);
				}
			}
		}
		sql.append(""INSERT INTO "")//
				.append(entity.getTableName()).append("" ("").append(fieldsPart).append("") VALUES ("")//
				.append(placeHolder.toString()).append("")"");

		return this;
	}"
"public List<Object> syncAndReturnAll() {
    if (getPipelinedResponseLength() > 0) {
      List<Object> unformatted = client.getMany(getPipelinedResponseLength());
      List<Object> formatted = new ArrayList<Object>();
      for (Object o : unformatted) {
        try {
          formatted.add(generateResponse(o).get());
        } catch (JedisDataException e) {
          formatted.add(e);
        }
      }
      return formatted;
    } else {
      return java.util.Collections.<Object> emptyList();
    }
  }"
"public TechSet getTechSet() {
        TechSet techSet = new TechSet();
        Iterator<Entry<Tech, DefaultMutableTreeNode>> iter = techToNodeMap.entrySet().iterator();
        while (iter.hasNext()) {
            Entry<Tech, DefaultMutableTreeNode> node = iter.next();
            TreePath tp = this.getPath(node.getValue());
            Tech tech = node.getKey();
            if (techTree.isSelectedFully(tp)) {
                techSet.include(tech);
            } else {
                techSet.exclude(tech);
            }
        }
        return techSet;
    }"
"public static Vec categoricalToInt(final Vec src) {
    if( src.isInt() && (src.domain()==null || src.domain().length == 0)) return copyOver(src, Vec.T_NUM, null);
    if( !src.isCategorical() ) throw new IllegalArgumentException(""categoricalToInt conversion only works on categorical columns."");
    // check if the 1st lvl of the domain can be parsed as int
    boolean useDomain=false;
    Vec newVec = copyOver(src, Vec.T_NUM, null);
    try {
      Integer.parseInt(src.domain()[0]);
      useDomain=true;
    } catch (NumberFormatException e) {
      // makeCopy and return...
    }
    if( useDomain ) {
      new MRTask() {
        @Override public void map(Chunk c) {
          for (int i=0;i<c._len;++i)
            if( !c.isNA(i) )
              c.set(i, Integer.parseInt(src.domain()[(int)c.at8(i)]));
        }
      }.doAll(newVec);
    }
    return newVec;
  }"
"public DataSink<T> setParallelism(int parallelism) {
		Preconditions.checkArgument(parallelism > 0 || parallelism == ExecutionConfig.PARALLELISM_DEFAULT,
			""The parallelism of an operator must be at least 1."");

		this.parallelism = parallelism;

		return this;
	}"
"@PutMapping(""/syncSwitch/{destination}/{status}"")
    public Result etl(@PathVariable String destination, @PathVariable String status) {
        if (status.equals(""on"")) {
            syncSwitch.on(destination);
            logger.info(""#Destination: {} sync on"", destination);
            return Result.createSuccess(""实例: "" + destination + "" 开启同步成功"");
        } else if (status.equals(""off"")) {
            syncSwitch.off(destination);
            logger.info(""#Destination: {} sync off"", destination);
            return Result.createSuccess(""实例: "" + destination + "" 关闭同步成功"");
        } else {
            Result result = new Result();
            result.setCode(50000);
            result.setMessage(""实例: "" + destination + "" 操作失败"");
            return result;
        }
    }"
"protected boolean isTabScrollable(String tabLabel) {
		JPanel tabPanel = this.tabNameMap.get(tabLabel);
		if (tabPanel == null) {
			return false;
		}
		return isTabScrollable(tabPanel);
	}"
"public int getValueAtPercentile(double percentile) {
        int permyriad = (int) (percentile * 100);
        switch (permyriad) {
            case 0: return p0;
            case 500: return p5;
            case 1000: return p10;
            case 1500: return p15;
            case 2000: return p20;
            case 2500: return p25;
            case 3000: return p30;
            case 3500: return p35;
            case 4000: return p40;
            case 4500: return p45;
            case 5000: return p50;
            case 5500: return p55;
            case 6000: return p60;
            case 6500: return p65;
            case 7000: return p70;
            case 7500: return p75;
            case 8000: return p80;
            case 8500: return p85;
            case 9000: return p90;
            case 9500: return p95;
            case 9900: return p99;
            case 9950: return p99_5;
            case 9990: return p99_9;
            case 9995: return p99_95;
            case 9999: return p99_99;
            case 10000: return p100;
            default: throw new IllegalArgumentException(""Percentile ("" + percentile + "") is not currently cached"");
        }
    }"
"@Deprecated
  public static <RequestT, ResponseT> MethodDescriptor<RequestT, ResponseT> create(
      MethodType type, String fullMethodName,
      Marshaller<RequestT> requestMarshaller,
      Marshaller<ResponseT> responseMarshaller) {
    return new MethodDescriptor<>(
        type, fullMethodName, requestMarshaller, responseMarshaller, null, false, false, false);
  }"
"public String getPublicKey() {
        RSAPublicKey key = InstanceIdentityProvider.RSA.getPublicKey();
        if (key == null) {
            return null;
        }
        byte[] encoded = Base64.encodeBase64(key.getEncoded());
        int index = 0;
        StringBuilder buf = new StringBuilder(encoded.length + 20);
        while (index < encoded.length) {
            int len = Math.min(64, encoded.length - index);
            if (index > 0) {
                buf.append(""\n"");
            }
            buf.append(new String(encoded, index, len, Charsets.UTF_8));
            index += len;
        }
        return String.format(""-----BEGIN PUBLIC KEY-----%n%s%n-----END PUBLIC KEY-----%n"", buf.toString());
    }"
"public static UserGroupInformation loginFromSpnegoKeytabAndReturnUGI(HiveConf hiveConf)
    throws IOException {
    String principal = hiveConf.getVar(ConfVars.HIVE_SERVER2_SPNEGO_PRINCIPAL);
    String keyTabFile = hiveConf.getVar(ConfVars.HIVE_SERVER2_SPNEGO_KEYTAB);
    if (principal.isEmpty() || keyTabFile.isEmpty()) {
      throw new IOException(""HiveServer2 SPNEGO principal or keytab is not correctly configured"");
    } else {
      return UserGroupInformation.loginUserFromKeytabAndReturnUGI(SecurityUtil.getServerPrincipal(principal, ""0.0.0.0""), keyTabFile);
    }
  }"
"public static FrameNodes findFrameNodes(Frame fr) {
    // Count on how many nodes the data resides
    boolean[] nodesHoldingFrame = new boolean[H2O.CLOUD.size()];
    Vec vec = fr.anyVec();
    for(int chunkNr = 0; chunkNr < vec.nChunks(); chunkNr++) {
      int home = vec.chunkKey(chunkNr).home_node().index();
      if (! nodesHoldingFrame[home])
        nodesHoldingFrame[home] = true;
    }
    return new FrameNodes(fr, nodesHoldingFrame);
  }"
"State addBinaryShiftChar(int index) {
    Token token = this.token;
    int mode = this.mode;
    int bitCount = this.bitCount;
    if (this.mode == HighLevelEncoder.MODE_PUNCT || this.mode == HighLevelEncoder.MODE_DIGIT) {
      //assert binaryShiftByteCount == 0;
      int latch = HighLevelEncoder.LATCH_TABLE[mode][HighLevelEncoder.MODE_UPPER];
      token = token.add(latch & 0xFFFF, latch >> 16);
      bitCount += latch >> 16;
      mode = HighLevelEncoder.MODE_UPPER;
    }
    int deltaBitCount =
      (binaryShiftByteCount == 0 || binaryShiftByteCount == 31) ? 18 :
      (binaryShiftByteCount == 62) ? 9 : 8;
    State result = new State(token, mode, binaryShiftByteCount + 1, bitCount + deltaBitCount);
    if (result.binaryShiftByteCount == 2047 + 31) {
      // The string is as long as it's allowed to be.  We should end it.
      result = result.endBinaryShift(index + 1);
    }
    return result;
  }"
"protected String normalizePath(BeanWrapper wrapper, String path) {
        return initializePath(wrapper, new RelaxedDataBinder.BeanPath(path), 0);
    }"
"public static Integer nonNegative(@Nullable String role, Integer x) {
		if (x.intValue() < 0) {
			throw new IllegalArgumentException(role + "" ("" + x + "") must be >= 0"");
		}
		return x;
	}"
"public void onLoad(ItemGroup<? extends Item> parent, String name) throws IOException {
        this.parent = parent;
        doSetName(name);
    }"
"public static RelaxedNames forCamelCase(String name) {
        StringBuilder result = new StringBuilder();
        for (char c : name.toCharArray()) {
            result.append(Character.isUpperCase(c) && result.length() > 0
                          && result.charAt(result.length() - 1) != '-' ? ""-"" + Character.toLowerCase(c) : c);
        }
        return new RelaxedNames(result.toString());
    }"
"private final BigDecimal getDecimal0(final int begin, final int intg, final int frac, final int intg0,
                                         final int frac0, final int intg0x, final int frac0x) {
        final int mask = ((buffer[begin] & 0x80) == 0x80) ? 0 : -1;
        int from = begin;

        /* max string length */
        final int len = ((mask != 0) ? 1 : 0) + ((intg != 0) ? intg : 1) // NL
                        + ((frac != 0) ? 1 : 0) + frac;
        char[] buf = new char[len];
        int pos = 0;

        if (mask != 0) /* decimal sign */
        buf[pos++] = ('-');

        final byte[] d_copy = buffer;
        d_copy[begin] ^= 0x80; /* clear sign */
        int mark = pos;

        if (intg0x != 0) {
            final int i = dig2bytes[intg0x];
            int x = 0;
            switch (i) {
                case 1:
                    x = d_copy[from] /* one byte */;
                    break;
                case 2:
                    x = getInt16BE(d_copy, from);
                    break;
                case 3:
                    x = getInt24BE(d_copy, from);
                    break;
                case 4:
                    x = getInt32BE(d_copy, from);
                    break;
            }
            from += i;
            x ^= mask;
            if (x < 0 || x >= powers10[intg0x + 1]) {
                throw new IllegalArgumentException(""bad format, x exceed: "" + x + "", "" + powers10[intg0x + 1]);
            }
            if (x != 0 /* !digit || x != 0 */) {
                for (int j = intg0x; j > 0; j--) {
                    final int divisor = powers10[j - 1];
                    final int y = x / divisor;
                    if (mark < pos || y != 0) {
                        buf[pos++] = ((char) ('0' + y));
                    }
                    x -= y * divisor;
                }
            }
        }

        for (final int stop = from + intg0 * SIZE_OF_INT32; from < stop; from += SIZE_OF_INT32) {
            int x = getInt32BE(d_copy, from);
            x ^= mask;
            if (x < 0 || x > DIG_MAX) {
                throw new IllegalArgumentException(""bad format, x exceed: "" + x + "", "" + DIG_MAX);
            }
            if (x != 0) {
                if (mark < pos) {
                    for (int i = DIG_PER_DEC1; i > 0; i--) {
                        final int divisor = powers10[i - 1];
                        final int y = x / divisor;
                        buf[pos++] = ((char) ('0' + y));
                        x -= y * divisor;
                    }
                } else {
                    for (int i = DIG_PER_DEC1; i > 0; i--) {
                        final int divisor = powers10[i - 1];
                        final int y = x / divisor;
                        if (mark < pos || y != 0) {
                            buf[pos++] = ((char) ('0' + y));
                        }
                        x -= y * divisor;
                    }
                }
            } else if (mark < pos) {
                for (int i = DIG_PER_DEC1; i > 0; i--)
                    buf[pos++] = ('0');
            }
        }

        if (mark == pos)
        /* fix 0.0 problem, only '.' may cause BigDecimal parsing exception. */
        buf[pos++] = ('0');

        if (frac > 0) {
            buf[pos++] = ('.');
            mark = pos;

            for (final int stop = from + frac0 * SIZE_OF_INT32; from < stop; from += SIZE_OF_INT32) {
                int x = getInt32BE(d_copy, from);
                x ^= mask;
                if (x < 0 || x > DIG_MAX) {
                    throw new IllegalArgumentException(""bad format, x exceed: "" + x + "", "" + DIG_MAX);
                }
                if (x != 0) {
                    for (int i = DIG_PER_DEC1; i > 0; i--) {
                        final int divisor = powers10[i - 1];
                        final int y = x / divisor;
                        buf[pos++] = ((char) ('0' + y));
                        x -= y * divisor;
                    }
                } else {
                    for (int i = DIG_PER_DEC1; i > 0; i--)
                        buf[pos++] = ('0');
                }
            }

            if (frac0x != 0) {
                final int i = dig2bytes[frac0x];
                int x = 0;
                switch (i) {
                    case 1:
                        x = d_copy[from] /* one byte */;
                        break;
                    case 2:
                        x = getInt16BE(d_copy, from);
                        break;
                    case 3:
                        x = getInt24BE(d_copy, from);
                        break;
                    case 4:
                        x = getInt32BE(d_copy, from);
                        break;
                }
                x ^= mask;
                if (x != 0) {
                    final int dig = DIG_PER_DEC1 - frac0x;
                    x *= powers10[dig];
                    if (x < 0 || x > DIG_MAX) {
                        throw new IllegalArgumentException(""bad format, x exceed: "" + x + "", "" + DIG_MAX);
                    }
                    for (int j = DIG_PER_DEC1; j > dig; j--) {
                        final int divisor = powers10[j - 1];
                        final int y = x / divisor;
                        buf[pos++] = ((char) ('0' + y));
                        x -= y * divisor;
                    }
                }
            }

            if (mark == pos)
            /* make number more friendly */
            buf[pos++] = ('0');
        }

        d_copy[begin] ^= 0x80; /* restore sign */
        String decimal = String.valueOf(buf, 0, pos);
        return new BigDecimal(decimal);
    }

    /**
     * Fill MY_BITMAP structure from buffer.
     * 
     * @param len The length of MY_BITMAP in bits.
     */
    public final void fillBitmap(BitSet bitmap, final int pos, final int len) {
        if (pos + ((len + 7) / 8) > limit || pos < 0) throw new IllegalArgumentException(""limit excceed: ""
                                                                                         + (pos + (len + 7) / 8));

        fillBitmap0(bitmap, origin + pos, len);
    }

    /**
     * Fill next MY_BITMAP structure from buffer.
     * 
     * @param len The length of MY_BITMAP in bits.
     */
    public final void fillBitmap(BitSet bitmap, final int len) {
        if (position + ((len + 7) / 8) > origin + limit) throw new IllegalArgumentException(""limit excceed: ""
                                                                                            + (position
                                                                                               + ((len + 7) / 8) - origin));

        position = fillBitmap0(bitmap, position, len);
    }

    /**
     * Fill MY_BITMAP structure from buffer.
     * 
     * @param len The length of MY_BITMAP in bits.
     */
    private final int fillBitmap0(BitSet bitmap, int pos, final int len) {
        final byte[] buf = buffer;

        for (int bit = 0; bit < len; bit += 8) {
            int flag = ((int) buf[pos++]) & 0xff;
            if (flag == 0) {
                continue;
            }
            if ((flag & 0x01) != 0) bitmap.set(bit);
            if ((flag & 0x02) != 0) bitmap.set(bit + 1);
            if ((flag & 0x04) != 0) bitmap.set(bit + 2);
            if ((flag & 0x08) != 0) bitmap.set(bit + 3);
            if ((flag & 0x10) != 0) bitmap.set(bit + 4);
            if ((flag & 0x20) != 0) bitmap.set(bit + 5);
            if ((flag & 0x40) != 0) bitmap.set(bit + 6);
            if ((flag & 0x80) != 0) bitmap.set(bit + 7);
        }
        return pos;
    }

    /**
     * Return MY_BITMAP structure from buffer.
     * 
     * @param len The length of MY_BITMAP in bits.
     */
    public final BitSet getBitmap(final int pos, final int len) {
        BitSet bitmap = new BitSet(len);
        fillBitmap(bitmap, pos, len);
        return bitmap;
    }

    /**
     * Return next MY_BITMAP structure from buffer.
     * 
     * @param len The length of MY_BITMAP in bits.
     */
    public final BitSet getBitmap(final int len) {
        BitSet bitmap = new BitSet(len);
        fillBitmap(bitmap, len);
        return bitmap;
    }

    /**
     * Fill n bytes into output stream.
     */
    public final void fillOutput(OutputStream out, final int pos, final int len) throws IOException {
        if (pos + len > limit || pos < 0) throw new IllegalArgumentException(""limit excceed: "" + (pos + len));

        out.write(buffer, origin + pos, len);
    }

    /**
     * Fill next n bytes into output stream.
     */
    public final void fillOutput(OutputStream out, final int len) throws IOException {
        if (position + len > origin + limit) throw new IllegalArgumentException(""limit excceed: ""
                                                                                + (position + len - origin));

        out.write(buffer, position, len);
        position += len;
    }

    /**
     * Fill n bytes in this buffer.
     */
    public final void fillBytes(final int pos, byte[] dest, final int destPos, final int len) {
        if (pos + len > limit || pos < 0) throw new IllegalArgumentException(""limit excceed: "" + (pos + len));

        System.arraycopy(buffer, origin + pos, dest, destPos, len);
    }

    /**
     * Fill next n bytes in this buffer.
     */
    public final void fillBytes(byte[] dest, final int destPos, final int len) {
        if (position + len > origin + limit) throw new IllegalArgumentException(""limit excceed: ""
                                                                                + (position + len - origin));

        System.arraycopy(buffer, position, dest, destPos, len);
        position += len;
    }

    /**
     * Return n-byte data from buffer.
     */
    public final byte[] getData(final int pos, final int len) {
        byte[] buf = new byte[len];
        fillBytes(pos, buf, 0, len);
        return buf;
    }

    /**
     * Return next n-byte data from buffer.
     */
    public final byte[] getData(final int len) {
        byte[] buf = new byte[len];
        fillBytes(buf, 0, len);
        return buf;
    }

    /**
     * Return all remaining data from buffer.
     */
    public final byte[] getData() {
        return getData(0, limit);
    }

    /**
     * Return full hexdump from position.
     */
    public final String hexdump(final int pos) {
        if ((limit - pos) > 0) {
            final int begin = origin + pos;
            final int end = origin + limit;

            byte[] buf = buffer;
            StringBuilder dump = new StringBuilder();
            dump.append(Integer.toHexString(buf[begin] >> 4));
            dump.append(Integer.toHexString(buf[begin] & 0xf));
            for (int i = begin + 1; i < end; i++) {
                dump.append(""_"");
                dump.append(Integer.toHexString(buf[i] >> 4));
                dump.append(Integer.toHexString(buf[i] & 0xf));
            }

            return dump.toString();
        }
        return """";
    }

    /**
     * Return hexdump from position, for len bytes.
     */
    public final String hexdump(final int pos, final int len) {
        if ((limit - pos) > 0) {
            final int begin = origin + pos;
            final int end = Math.min(begin + len, origin + limit);

            byte[] buf = buffer;
            StringBuilder dump = new StringBuilder();
            dump.append(Integer.toHexString(buf[begin] >> 4));
            dump.append(Integer.toHexString(buf[begin] & 0xf));
            for (int i = begin + 1; i < end; i++) {
                dump.append(""_"");
                dump.append(Integer.toHexString(buf[i] >> 4));
                dump.append(Integer.toHexString(buf[i] & 0xf));
            }

            return dump.toString();
        }
        return """";
    }
}"
"public static <E> RingBuffer<E> createSingleProducer(EventFactory<E> factory, int bufferSize)
    {
        return createSingleProducer(factory, bufferSize, new BlockingWaitStrategy());
    }"
"public Status augmentDescription(String additionalDetail) {
    if (additionalDetail == null) {
      return this;
    } else if (this.description == null) {
      return new Status(this.code, additionalDetail, this.cause);
    } else {
      return new Status(this.code, this.description + ""\n"" + additionalDetail, this.cause);
    }
  }"
"public CsvReader includeFields(String mask) {
		boolean[] includedMask = new boolean[mask.length()];

		for (int i = 0; i < mask.length(); i++) {
			char c = mask.charAt(i);
			if (c == '1' || c == 'T' || c == 't') {
				includedMask[i] = true;
			} else if (c != '0' && c != 'F' && c != 'f') {
				throw new IllegalArgumentException(""Mask string may contain only '0' and '1'."");
			}
		}

		return includeFields(includedMask);
	}"
"private SofaRpcException clientTimeoutWhenReceiveRequest(String appName, String serviceName, String remoteAddress) {
        String errorMsg = LogCodes.getLog(
            LogCodes.ERROR_DISCARD_TIMEOUT_REQUEST, serviceName, remoteAddress);
        if (LOGGER.isWarnEnabled(appName)) {
            LOGGER.warnWithApp(appName, errorMsg);
        }
        return new SofaRpcException(RpcErrorType.SERVER_UNDECLARED_ERROR, errorMsg);
    }"
"public void updateAndRestart(ClassLoaderFiles files) {
		Set<URL> urls = new LinkedHashSet<>();
		Set<URL> classLoaderUrls = getClassLoaderUrls();
		for (SourceFolder folder : files.getSourceFolders()) {
			for (Entry<String, ClassLoaderFile> entry : folder.getFilesEntrySet()) {
				for (URL url : classLoaderUrls) {
					if (updateFileSystem(url, entry.getKey(), entry.getValue())) {
						urls.add(url);
					}
				}
			}
			urls.addAll(getMatchingUrls(classLoaderUrls, folder.getName()));
		}
		updateTimeStamp(urls);
		restart(urls, files);
	}"
"public String findInContent(String content) {
        
        // First check for a simple exact occurrence
        for (BoyerMooreMatcher matcher : strings) {
            if (matcher.findInContent(content) >= 0)
                return matcher.getPattern();
        }
        
        // Then check for a regex occurrence
        Matcher matcher;
        for (Pattern pattern : patterns) {
            matcher = pattern.matcher(content);
            if (matcher.find()) {
                return matcher.group();
            }
        }
        
        // No match found return null
        return null;
    }"
"private String callForJsonString(final String host, final int port, final String path,
      List<Pair<String, String>> paramList) throws IOException {
    if (paramList == null) {
      paramList = new ArrayList<>();
    }

    @SuppressWarnings(""unchecked"") final URI uri =
        ExecutorApiClient.buildUri(host, port, path, true);

    return this.apiClient.httpPost(uri, paramList);
  }"
"public static <A extends Annotation> A getAnnotation(AnnotatedElement annotationEle, Class<A> annotationType) {
		return (null == annotationEle) ? null : toCombination(annotationEle).getAnnotation(annotationType);
	}"
"public static Response<SearchResult> executeSearchOperation(final ConnectionFactory connectionFactory,
                                                                final String baseDn,
                                                                final SearchFilter filter) throws LdapException {
        return executeSearchOperation(connectionFactory, baseDn, filter, ReturnAttributes.ALL_USER.value(), ReturnAttributes.ALL_USER.value());
    }"
"private static char readStringChar(DataInputView source) throws IOException {
		int c = source.readByte() & 0xFF;

		if (c >= HIGH_BIT) {
			int shift = 7;
			int curr;
			c = c & 0x7F;
			while ((curr = source.readByte() & 0xFF) >= HIGH_BIT) {
				c |= (curr & 0x7F) << shift;
				shift += 7;
			}
			c |= curr << shift;
		}

		return (char) c;
	}"
"public static <T> Page<T> getPageFromObject(Object params, boolean required) {
        if (params == null) {
            throw new PageException(""无法获取分页查询参数!"");
        }
        if(params instanceof IPage){
            IPage pageParams = (IPage) params;
            Page page = null;
            if(pageParams.getPageNum() != null && pageParams.getPageSize() != null){
                page = new Page(pageParams.getPageNum(), pageParams.getPageSize());
            }
            if (StringUtil.isNotEmpty(pageParams.getOrderBy())) {
                if(page != null){
                    page.setOrderBy(pageParams.getOrderBy());
                } else {
                    page = new Page();
                    page.setOrderBy(pageParams.getOrderBy());
                    page.setOrderByOnly(true);
                }
            }
            return page;
        }
        int pageNum;
        int pageSize;
        MetaObject paramsObject = null;
        if (hasRequest && requestClass.isAssignableFrom(params.getClass())) {
            try {
                paramsObject = MetaObjectUtil.forObject(getParameterMap.invoke(params, new Object[]{}));
            } catch (Exception e) {
                //忽略
            }
        } else {
            paramsObject = MetaObjectUtil.forObject(params);
        }
        if (paramsObject == null) {
            throw new PageException(""分页查询参数处理失败!"");
        }
        Object orderBy = getParamValue(paramsObject, ""orderBy"", false);
        boolean hasOrderBy = false;
        if (orderBy != null && orderBy.toString().length() > 0) {
            hasOrderBy = true;
        }
        try {
            Object _pageNum = getParamValue(paramsObject, ""pageNum"", required);
            Object _pageSize = getParamValue(paramsObject, ""pageSize"", required);
            if (_pageNum == null || _pageSize == null) {
                if(hasOrderBy){
                    Page page = new Page();
                    page.setOrderBy(orderBy.toString());
                    page.setOrderByOnly(true);
                    return page;
                }
                return null;
            }
            pageNum = Integer.parseInt(String.valueOf(_pageNum));
            pageSize = Integer.parseInt(String.valueOf(_pageSize));
        } catch (NumberFormatException e) {
            throw new PageException(""分页参数不是合法的数字类型!"", e);
        }
        Page page = new Page(pageNum, pageSize);
        //count查询
        Object _count = getParamValue(paramsObject, ""count"", false);
        if (_count != null) {
            page.setCount(Boolean.valueOf(String.valueOf(_count)));
        }
        //排序
        if (hasOrderBy) {
            page.setOrderBy(orderBy.toString());
        }
        //分页合理化
        Object reasonable = getParamValue(paramsObject, ""reasonable"", false);
        if (reasonable != null) {
            page.setReasonable(Boolean.valueOf(String.valueOf(reasonable)));
        }
        //查询全部
        Object pageSizeZero = getParamValue(paramsObject, ""pageSizeZero"", false);
        if (pageSizeZero != null) {
            page.setPageSizeZero(Boolean.valueOf(String.valueOf(pageSizeZero)));
        }
        return page;
    }"
"public void addParam(String name, String value, int type) {
        // Current size usually is equal to the position
        params.add(new NameValuePair(type, name, value, params.size()));
    }"
"@Override
    public HttpMessage get(int index) {
        try {
            return historyReferences.get(index).getHttpMessage();
        } catch (HttpMalformedHeaderException | DatabaseException e) {
            if (LOGGER.isDebugEnabled()) {
                LOGGER.debug(""Failed to get the message from DB: "" + e.getMessage(), e);
            }
        }
        return null;
    }"
"public static StringDictionary combine(StringDictionary... args)
    {
        StringDictionary[] dictionaries = args.clone();
        StringDictionary mainDictionary = dictionaries[0];
        for (int i = 1; i < dictionaries.length; ++i)
        {
            mainDictionary.combine(dictionaries[i]);
        }

        return mainDictionary;
    }"
"@Nonnull
    @Deprecated
    public static String loadFile(@Nonnull File logfile) throws IOException {
        return loadFile(logfile, Charset.defaultCharset());
    }"
"public static <T> DataSet<LongValue> count(DataSet<T> input) {
		return input
			.map(new MapTo<>(new LongValue(1)))
				.returns(LONG_VALUE_TYPE_INFO)
				.name(""Emit 1"")
			.reduce(new AddLongValue())
				.name(""Sum"");
	}"
"private int countOfMode(boolean data) {
        int count = 0;
        for (Node p = head; p != null; ) {
            if (!p.isMatched()) {
                if (p.isData != data)
                    return 0;
                if (++count == Integer.MAX_VALUE) // saturated
                    break;
            }
            Node n = p.next;
            if (n != p)
                p = n;
            else {
                count = 0;
                p = head;
            }
        }
        return count;
    }"
"public void parse(final SelectStatement selectStatement) {
        if (!lexerEngine.skipIfEqual(MySQLKeyword.LIMIT)) {
            return;
        }
        int valueIndex = -1;
        int valueBeginPosition = lexerEngine.getCurrentToken().getEndPosition();
        int value;
        boolean isParameterForValue = false;
        if (lexerEngine.equalAny(Literals.INT)) {
            value = Integer.parseInt(lexerEngine.getCurrentToken().getLiterals());
            valueBeginPosition = valueBeginPosition - (value + """").length();
        } else if (lexerEngine.equalAny(Symbol.QUESTION)) {
            valueIndex = selectStatement.getParametersIndex();
            value = -1;
            valueBeginPosition--;
            isParameterForValue = true;
        } else {
            throw new SQLParsingException(lexerEngine);
        }
        lexerEngine.nextToken();
        if (lexerEngine.skipIfEqual(Symbol.COMMA)) {
            selectStatement.setLimit(getLimitWithComma(valueIndex, valueBeginPosition, value, isParameterForValue, selectStatement));
            return;
        }
        if (lexerEngine.skipIfEqual(MySQLKeyword.OFFSET)) {
            selectStatement.setLimit(getLimitWithOffset(valueIndex, valueBeginPosition, value, isParameterForValue, selectStatement));
            return;
        }
        if (isParameterForValue) {
            selectStatement.setParametersIndex(selectStatement.getParametersIndex() + 1);
        } else {
            selectStatement.addSQLToken(new RowCountToken(valueBeginPosition, value));
        }
        Limit limit = new Limit();
        limit.setRowCount(new LimitValue(value, valueIndex, false));
        selectStatement.setLimit(limit);
    }"
"public static Properties toCryptoConf(String prefix, Iterable<Map.Entry<String, String>> conf) {
    Properties props = new Properties();
    for (Map.Entry<String, String> e : conf) {
      String key = e.getKey();
      if (key.startsWith(prefix)) {
        props.setProperty(COMMONS_CRYPTO_CONFIG_PREFIX + key.substring(prefix.length()),
          e.getValue());
      }
    }
    return props;
  }"
"public boolean insert(int newIndex) {
        // Ignore objects which do not belong in this quad tree
        INDArray point = data.slice(newIndex);
        if (!boundary.containsPoint(point))
            return false;

        cumSize++;
        double mult1 = (double) (cumSize - 1) / (double) cumSize;
        double mult2 = 1.0 / (double) cumSize;

        centerOfMass.muli(mult1);
        centerOfMass.addi(point.mul(mult2));

        // If there is space in this quad tree and it is a leaf, add the object here
        if (isLeaf() && size < QT_NODE_CAPACITY) {
            index[size] = newIndex;
            size++;
            return true;
        }

        //duplicate point
        if (size > 0) {
            for (int i = 0; i < size; i++) {
                INDArray compPoint = data.slice(index[i]);
                if (point.getDouble(0) == compPoint.getDouble(0) && point.getDouble(1) == compPoint.getDouble(1))
                    return true;
            }
        }



        // If this Node has already been subdivided just add the elements to the
        // appropriate cell
        if (!isLeaf()) {
            QuadTree index = findIndex(point);
            index.insert(newIndex);
            return true;
        }

        if (isLeaf())
            subDivide();

        boolean ret = insertIntoOneOf(newIndex);



        return ret;
    }"
"private void writeModelDetails() throws IOException {
    ModelSchemaV3 modelSchema = (ModelSchemaV3) SchemaServer.schema(3, model).fillFromImpl(model);
    startWritingTextFile(""experimental/modelDetails.json"");
    writeln(modelSchema.toJsonString());
    finishWritingTextFile();
  }"
"private void initChannelStatus() {
        String path = null;
        try {
            path = StagePathUtils.getChannel(getPipelineId());
            byte[] bytes = zookeeper.readData(path);
            initChannelStatus(bytes);
        } catch (ZkNoNodeException e) {
            channelStatus = ChannelStatus.STOP;
            permitSem();
        } catch (ZkException e) {
            logger.error(path, e);
        }
    }"
"public void setFields(String[] requiredFields, String[] optionalFields) {
		if (requiredFields == null) {
			throw new IllegalArgumentException(""Parameter requiredFields must not be null."");
		}

		if (optionalFields == null) {
			throw new IllegalArgumentException(""Parameter optionalFields must not be null."");
		}

		this.requiredFields = requiredFields;
		this.optionalFields = optionalFields;

		this.textFields = new HashMap<>(requiredFields.length + optionalFields.length);

		removeAll();

		int fieldIndex = 0;
		for (String fieldName : requiredFields) {
			addRequiredField(fieldName, fieldIndex);
			fieldIndex++;
		}

		for (String fieldName : optionalFields) {
			addField(fieldName, fieldIndex);
			fieldIndex++;
		}
		add(Box.createVerticalGlue(), LayoutHelper.getGBC(0, fieldIndex, 2, 0.0d, 1.0d));

		validate();
	}"
"@Override
	public void grantLeadership(final UUID newLeaderSessionID) {
		final CompletableFuture<Boolean> acceptLeadershipFuture = clearStateFuture
			.thenComposeAsync((ignored) -> tryAcceptLeadership(newLeaderSessionID), getUnfencedMainThreadExecutor());

		final CompletableFuture<Void> confirmationFuture = acceptLeadershipFuture.thenAcceptAsync(
			(acceptLeadership) -> {
				if (acceptLeadership) {
					// confirming the leader session ID might be blocking,
					leaderElectionService.confirmLeaderSessionID(newLeaderSessionID);
				}"
"@SuppressWarnings(""NumericOverflow"")
    private static long nextLong(long n) {
        long bits, val;
        do {
            bits = ThreadLocalRandom.current().nextLong() & (~(1L << BITS_PER_LONG));
            val = bits % n;
        } while (bits - val + (n - 1) < 0L);
        return val;
    }"
"public boolean write(ImageOutputStream targetImageStream) throws IORuntimeException {
		Assert.notBlank(this.targetImageType, ""Target image type is blank !"");
		Assert.notNull(targetImageStream, ""Target output stream is null !"");

		final BufferedImage targetImage = (null == this.targetImage) ? this.srcImage : this.targetImage;
		Assert.notNull(targetImage, ""Target image is null !"");
		
		return ImgUtil.write(targetImage, this.targetImageType, targetImageStream, this.quality);
	}"
"private InterfaceHttpData decodeMultipart(MultiPartStatus state) {
        switch (state) {
        case NOTSTARTED:
            throw new ErrorDataDecoderException(""Should not be called with the current getStatus"");
        case PREAMBLE:
            // Content-type: multipart/form-data, boundary=AaB03x
            throw new ErrorDataDecoderException(""Should not be called with the current getStatus"");
        case HEADERDELIMITER: {
            // --AaB03x or --AaB03x--
            return findMultipartDelimiter(multipartDataBoundary, MultiPartStatus.DISPOSITION,
                    MultiPartStatus.PREEPILOGUE);
        }
        case DISPOSITION: {
            // content-disposition: form-data; name=""field1""
            // content-disposition: form-data; name=""pics""; filename=""file1.txt""
            // and other immediate values like
            // Content-type: image/gif
            // Content-Type: text/plain
            // Content-Type: text/plain; charset=ISO-8859-1
            // Content-Transfer-Encoding: binary
            // The following line implies a change of mode (mixed mode)
            // Content-type: multipart/mixed, boundary=BbC04y
            return findMultipartDisposition();
        }
        case FIELD: {
            // Now get value according to Content-Type and Charset
            Charset localCharset = null;
            Attribute charsetAttribute = currentFieldAttributes.get(HttpHeaderValues.CHARSET);
            if (charsetAttribute != null) {
                try {
                    localCharset = Charset.forName(charsetAttribute.getValue());
                } catch (IOException e) {
                    throw new ErrorDataDecoderException(e);
                } catch (UnsupportedCharsetException e) {
                    throw new ErrorDataDecoderException(e);
                }
            }
            Attribute nameAttribute = currentFieldAttributes.get(HttpHeaderValues.NAME);
            if (currentAttribute == null) {
                Attribute lengthAttribute = currentFieldAttributes
                        .get(HttpHeaderNames.CONTENT_LENGTH);
                long size;
                try {
                    size = lengthAttribute != null? Long.parseLong(lengthAttribute
                            .getValue()) : 0L;
                } catch (IOException e) {
                    throw new ErrorDataDecoderException(e);
                } catch (NumberFormatException ignored) {
                    size = 0;
                }
                try {
                    if (size > 0) {
                        currentAttribute = factory.createAttribute(request,
                                cleanString(nameAttribute.getValue()), size);
                    } else {
                        currentAttribute = factory.createAttribute(request,
                                cleanString(nameAttribute.getValue()));
                    }
                } catch (NullPointerException e) {
                    throw new ErrorDataDecoderException(e);
                } catch (IllegalArgumentException e) {
                    throw new ErrorDataDecoderException(e);
                } catch (IOException e) {
                    throw new ErrorDataDecoderException(e);
                }
                if (localCharset != null) {
                    currentAttribute.setCharset(localCharset);
                }
            }
            // load data
            if (!loadDataMultipart(undecodedChunk, multipartDataBoundary, currentAttribute)) {
                // Delimiter is not found. Need more chunks.
                return null;
            }
            Attribute finalAttribute = currentAttribute;
            currentAttribute = null;
            currentFieldAttributes = null;
            // ready to load the next one
            currentStatus = MultiPartStatus.HEADERDELIMITER;
            return finalAttribute;
        }
        case FILEUPLOAD: {
            // eventually restart from existing FileUpload
            return getFileUpload(multipartDataBoundary);
        }
        case MIXEDDELIMITER: {
            // --AaB03x or --AaB03x--
            // Note that currentFieldAttributes exists
            return findMultipartDelimiter(multipartMixedBoundary, MultiPartStatus.MIXEDDISPOSITION,
                    MultiPartStatus.HEADERDELIMITER);
        }
        case MIXEDDISPOSITION: {
            return findMultipartDisposition();
        }
        case MIXEDFILEUPLOAD: {
            // eventually restart from existing FileUpload
            return getFileUpload(multipartMixedBoundary);
        }
        case PREEPILOGUE:
            return null;
        case EPILOGUE:
            return null;
        default:
            throw new ErrorDataDecoderException(""Shouldn't reach here."");
        }
    }"
"public List<PlanFragment> getAllFragments()
    {
        ImmutableList.Builder<PlanFragment> fragments = ImmutableList.builder();

        fragments.add(getFragment());
        for (SubPlan child : getChildren()) {
            fragments.addAll(child.getAllFragments());
        }

        return fragments.build();
    }"
"public static Integer positive(@Nullable String role, Integer x) {
		if (x.intValue() <= 0) {
			throw new IllegalArgumentException(role + "" ("" + x + "") must be > 0"");
		}
		return x;
	}"
"public boolean isAdjacent(Marker other)
    {
        checkTypeCompatibility(other);
        if (isUpperUnbounded() || isLowerUnbounded() || other.isUpperUnbounded() || other.isLowerUnbounded()) {
            return false;
        }
        if (type.compareTo(valueBlock.get(), 0, other.valueBlock.get(), 0) != 0) {
            return false;
        }
        return (bound == Bound.EXACTLY && other.bound != Bound.EXACTLY) ||
                (bound != Bound.EXACTLY && other.bound == Bound.EXACTLY);
    }"
"public <T> BindResult<T> bind(String name, Bindable<T> target) {
		return bind(ConfigurationPropertyName.of(name), target, null);
	}"
"protected static Path getCheckpointDirectoryForJob(Path baseCheckpointPath, JobID jobId) {
		return new Path(baseCheckpointPath, jobId.toString());
	}"
"public void addWarning(String message, DiagnosticPosition pos) {
		ast.printMessage(Diagnostic.Kind.WARNING, message, null, pos, false);
	}"
"private void removeFromInternalState(Component panel) {
		this.fullTabList.remove(panel);
		if (this.hiddenTabs.remove(panel)) {
			handleHiddenTabListTab();
		}
	}"
"public static List<String> getResultLines(Process process, Charset charset) {
		InputStream in = null;
		try {
			in = process.getInputStream();
			return IoUtil.readLines(in, charset, new ArrayList<String>());
		} finally {
			IoUtil.close(in);
			destroy(process);
		}
	}"
"@Deprecated
	public <R> SingleOutputStreamOperator<R> apply(R initialValue, FoldFunction<T, R> foldFunction, WindowFunction<R, R, K, W> function) {

		TypeInformation<R> resultType = TypeExtractor.getFoldReturnTypes(foldFunction, input.getType(),
			Utils.getCallLocationName(), true);

		return apply(initialValue, foldFunction, function, resultType);
	}"
"@RequirePOST
    public void doCancelRestart(StaplerResponse response) throws IOException, ServletException {
        synchronized (jobs) {
            for (UpdateCenterJob job : jobs) {
                if (job instanceof RestartJenkinsJob) {
                    if (((RestartJenkinsJob) job).cancel()) {
                        LOGGER.info(""Scheduled Jenkins reboot unscheduled"");
                    }
                }
            }
        }
        response.sendRedirect2(""."");
    }"
"@Restricted(NoExternalUse.class)
    public Iterator<VersionNumber> getVersionList() {
        TreeSet<VersionNumber> set = new TreeSet<VersionNumber>();
        for (VersionRange vr : data.values()) {
            if (vr.max != null) {
                set.add(vr.max);
            }
        }
        return set.iterator();
    }"
"public static byte[] decode(byte[] in) {
		if (ArrayUtil.isEmpty(in)) {
			return in;
		}
		return decode(in, 0, in.length);
	}"
"public static List<List<IWord>> convert2CompatibleList(List<List<Word>> simpleSentenceList)
    {
        List<List<IWord>> compatibleList = new LinkedList<List<IWord>>();
        for (List<Word> wordList : simpleSentenceList)
        {
            compatibleList.add(new LinkedList<IWord>(wordList));
        }
        return compatibleList;
    }"
"@CheckForNull
    public UpdateSite getById(String id) {
        for (UpdateSite s : sites) {
            if (s.getId().equals(id)) {
                return s;
            }
        }
        return null;
    }"
"public static WatchMonitor create(File file, WatchEvent.Kind<?>... events){
		return create(file, 0, events);
	}"
"public void deleteChannel(FileIOChannel.ID channel) throws IOException {
		if (channel != null) {
			if (channel.getPathFile().exists() && !channel.getPathFile().delete()) {
				LOG.warn(""IOManager failed to delete temporary file {}"", channel.getPath());
			}
		}
	}"
"private void validate(final X509Certificate cert) throws GeneralSecurityException {
        cert.checkValidity();
        this.revocationChecker.check(cert);

        val pathLength = cert.getBasicConstraints();
        if (pathLength < 0) {
            if (!isCertificateAllowed(cert)) {
                throw new FailedLoginException(""Certificate subject does not match pattern "" + this.regExSubjectDnPattern.pattern());
            }
            if (this.checkKeyUsage && !isValidKeyUsage(cert)) {
                throw new FailedLoginException(""Certificate keyUsage constraint forbids SSL client authentication."");
            }
        } else {
            if (pathLength == Integer.MAX_VALUE && !this.maxPathLengthAllowUnspecified) {
                throw new FailedLoginException(""Unlimited certificate path length not allowed by configuration."");
            }
            if (pathLength > this.maxPathLength && pathLength < Integer.MAX_VALUE) {
                throw new FailedLoginException(String.format(
                    ""Certificate path length %s exceeds maximum value %s."", pathLength, this.maxPathLength));
            }
        }
    }"
"public String obtainLoopbackIp4Address() {
    final NetworkInterface networkInterface = getLoopBackAndIp4Only();
    if (networkInterface != null) {
      return networkInterface.getIp4LoopbackOnly().getHostName();
    }

    final String ipOfIp4LoopBack = getIpOfLoopBackIp4();
    if (ipOfIp4LoopBack != null) {
      return ipOfIp4LoopBack;
    }

    if (Platform.getCurrent().is(Platform.UNIX)) {
      NetworkInterface linuxLoopback = networkInterfaceProvider.getLoInterface();
      if (linuxLoopback != null) {
        final InetAddress netAddress = linuxLoopback.getIp4LoopbackOnly();
        if (netAddress != null) {
          return netAddress.getHostAddress();
        }
      }
    }

    throw new WebDriverException(
        ""Unable to resolve local loopback address, please file an issue with the full message of this error:\n""
            +
            getNetWorkDiags() + ""\n==== End of error message"");
  }"
"public AnnotationValueBuilder<T> member(String name, int... ints) {
        if (ints != null) {
            values.put(name, ints);
        }
        return this;
    }"
"@Override
    @JsonIgnore
    public String getId() {
        if (instanceId != null && !instanceId.isEmpty()) {
            return instanceId;
        } else if (dataCenterInfo instanceof AmazonInfo) {
            String uniqueId = ((AmazonInfo) dataCenterInfo).getId();
            if (uniqueId != null && !uniqueId.isEmpty()) {
                return uniqueId;
            }
        }
        return hostName;
    }"
"public static void remove(String key, String word) {

        SmartForest<List<String>> synonyms = get(key);

        SmartForest<List<String>> branch = synonyms.getBranch(word);

        if (branch == null || branch.getStatus() < 2) {
            return;
        }

        List<String> params = branch.getParam();

        synonyms.remove(word);
        branch.setParam(null);
        params.remove(word);

        if (params.size() == 1) { //如果是1 个也删除
            synonyms.remove(params.get(0));
            params.remove(0);
        } else {
            params.remove(word);
        }
    }"
"protected FullResponseHolder submitSmileRequest(
      String taskId,
      HttpMethod method,
      String encodedPathSuffix,
      @Nullable String encodedQueryString,
      byte[] content,
      boolean retry
  ) throws IOException, ChannelException, NoTaskLocationException
  {
    return submitRequest(
        taskId,
        SmileMediaTypes.APPLICATION_JACKSON_SMILE,
        method,
        encodedPathSuffix,
        encodedQueryString,
        content,
        retry
    );
  }"
"public String[] namedEntityRecognize(String[] wordArray, String[] posArray)
    {
        if (neRecognizer == null)
        {
            throw new IllegalStateException(""未提供命名实体识别模型"");
        }
        return recognize(wordArray, posArray);
    }"
"public Object getAndRemove(String... keys) {
		Object value = null;
		for (String key : keys) {
			value = remove(key);
			if (null != value) {
				break;
			}
		}
		return value;
	}"
"public static <T extends CharSequence> T validateUUID(T value, String errorMsg) throws ValidateException {
		if (false == isUUID(value)) {
			throw new ValidateException(errorMsg);
		}
		return value;
	}"
"public void add(@Nonnull Iterable<T> runItems, @Nonnull List<Queue.Item> queueItems) {
        sort(queueItems);
        addInternal(Iterables.concat(queueItems, runItems));
    }"
"public static List<MasterState> triggerMasterHooks(
			Collection<MasterTriggerRestoreHook<?>> hooks,
			long checkpointId,
			long timestamp,
			Executor executor,
			Time timeout) throws FlinkException {

		final ArrayList<MasterState> states = new ArrayList<>(hooks.size());

		for (MasterTriggerRestoreHook<?> hook : hooks) {
			MasterState state = triggerHook(hook, checkpointId, timestamp, executor, timeout);
			if (state != null) {
				states.add(state);
			}
		}

		states.trimToSize();
		return states;
	}"
"private int getMaxStringSize() {
    Iced<?> maxSize = DKV.getGet(Key.make(WriterDelegate.class.getCanonicalName() + ""_maxStringSize""));
    return (maxSize instanceof IcedInt) ? ((IcedInt) maxSize)._val : MAX_STR_LEN;
  }"
"@Override
  public void close()
  {
    super.close();
    closeAggregators();
    aggregators.clear();
    facts.clear();
    if (selectors != null) {
      selectors.clear();
    }
  }"
"public static DataSource createDataSource(final File yamlFile) throws SQLException, IOException {
        YamlOrchestrationMasterSlaveRuleConfiguration config = unmarshal(yamlFile);
        return createDataSource(config.getDataSources(), config.getMasterSlaveRule(), config.getProps(), config.getOrchestration());
    }"
"public @Nonnull final <T> T getRequiredValue(Class<T> type) {
        return getRequiredValue(AnnotationMetadata.VALUE_MEMBER, type);
    }"
"@SuppressWarnings(""unchecked"")
	@Override
	public double getDelta(DATA oldDataPoint, DATA newDataPoint) {
		if (converter == null) {
			// In case no conversion/extraction is required, we can cast DATA to
			// TO
			// => Therefore, ""unchecked"" warning is suppressed for this method.
			return getNestedDelta((TO) oldDataPoint, (TO) newDataPoint);
		} else {
			return getNestedDelta(converter.extract(oldDataPoint), converter.extract(newDataPoint));
		}

	}"
"public String url() {

    /* build the fully qualified url with all query parameters */
    StringBuilder url = new StringBuilder(this.path());
    if (!this.queries.isEmpty()) {
      url.append(this.queryLine());
    }
    if (fragment != null) {
      url.append(fragment);
    }

    return url.toString();
  }"
"@Nonnull
    public static SecretKey toAes128Key(@Nonnull String s) {
        try {
            // turn secretKey into 256 bit hash
            MessageDigest digest = MessageDigest.getInstance(""SHA-256"");
            digest.reset();
            digest.update(s.getBytes(StandardCharsets.UTF_8));

            // Due to the stupid US export restriction JDK only ships 128bit version.
            return new SecretKeySpec(digest.digest(),0,128/8, ""AES"");
        } catch (NoSuchAlgorithmException e) {
            throw new Error(e);
        }
    }"
"public static BigDecimal toBigDecimal(Object value, BigDecimal defaultValue) {
		return convert(BigDecimal.class, value, defaultValue);
	}"
"public static float[] unWrap(Float... values) {
		if (null == values) {
			return null;
		}
		final int length = values.length;
		if (0 == length) {
			return new float[0];
		}

		final float[] array = new float[length];
		for (int i = 0; i < length; i++) {
			array[i] = values[i].floatValue();
		}
		return array;
	}"
"private char skipWS() {
    char c = ' ';
    while (_x < _str.length() && isWS(c = peek(0))) _x++;
    return c;
  }"
"public void keepTopNElements(int N){
        PriorityQueue<Pair<T, Double>> queue = asPriorityQueue();
        clear();
        for (int e = 0; e < N; e++) {
            Pair<T, Double> pair = queue.poll();
            if (pair != null)
                incrementCount(pair.getFirst(), pair.getSecond());
        }
    }"
"private Result getSummaryStatus(){
        StatsStorage ss = knownSessionIDs.get(currentSessionID);
        if(ss == null){
            log.debug(""getOptimizationConfig(): Session ID is unknown: {}"", currentSessionID);
            return ok();
        }

        Persistable p = ss.getStaticInfo(currentSessionID, ARBITER_UI_TYPE_ID, GlobalConfigPersistable.GLOBAL_WORKER_ID);

        if(p == null){
            log.info(""No static info"");
            return ok();
        }

        GlobalConfigPersistable gcp = (GlobalConfigPersistable)p;
        OptimizationConfiguration oc = gcp.getOptimizationConfiguration();
        long execStartTime = oc.getExecutionStartTime();



        //Charts:
        //Best model score vs. time
        //All candidate scores (scatter plot vs. time)

        //How to get this? query all model infos...

        List<Persistable> allModelInfoTemp = new ArrayList<>(ss.getLatestUpdateAllWorkers(currentSessionID, ARBITER_UI_TYPE_ID));
        List<ModelInfoPersistable> allModelInfo = new ArrayList<>();
        for(Persistable per : allModelInfoTemp){
            ModelInfoPersistable mip = (ModelInfoPersistable)per;
            if(mip.getStatus() == CandidateStatus.Complete && mip.getScore() != null && Double.isFinite(mip.getScore())){
                allModelInfo.add(mip);
            }
        }

        allModelInfo.sort(Comparator.comparingLong(Persistable::getTimeStamp));

        Pair<List<Component>, ModelInfoPersistable> chartsAndBest = getSummaryChartsAndBest(allModelInfo, oc.getScoreFunction().minimize(), execStartTime );

        //First: table - number completed, queued, running, failed, total
        //Best model index, score, and time
        //Total runtime
        //Termination conditions
        List<Component> components = new ArrayList<>();



        List<TerminationCondition> tcs = oc.getTerminationConditions();

        //TODO: I18N

        //TODO don't use currentTimeMillis due to stored data??
        long bestTime;
        Double bestScore = null;
        String bestModelString = null;
        if(chartsAndBest.getSecond() != null){
            bestTime = chartsAndBest.getSecond().getTimeStamp();
            bestScore = chartsAndBest.getSecond().getScore();
            String sinceBest = UIUtils.formatDuration(System.currentTimeMillis() - bestTime);

            bestModelString = ""Model "" + chartsAndBest.getSecond().getModelIdx() + "", Found at "" +
            TIME_FORMATTER.print(bestTime) + "" ("" + sinceBest + "" ago)"";
        }

        String execStartTimeStr = """";
        String execTotalRuntimeStr = """";
        if(execStartTime > 0){
            execStartTimeStr = TIME_FORMATTER.print(execStartTime);
            execTotalRuntimeStr = UIUtils.formatDuration(System.currentTimeMillis() - execStartTime);
        }


        String[][] table = new String[][]{
                {""Models Completed"", String.valueOf(gcp.getCandidatesCompleted())},
                {""Models Queued/Running"", String.valueOf(gcp.getCandidatesQueued())},
                {""Models Failed"", String.valueOf(gcp.getCandidatesFailed())},
                {""Models Total"", String.valueOf(gcp.getCandidatesTotal())},
                {""Best Score"", (bestScore != null ? String.valueOf(bestScore) : """")},
                {""Best Scoring Model"", bestModelString != null ? bestModelString : """"},
                {""Optimization Runner"", gcp.getOptimizationRunner()},
                {""Execution Start Time"", execStartTimeStr},
                {""Total Runtime"", execTotalRuntimeStr}
        };



        ComponentTable ct = new ComponentTable.Builder(STYLE_TABLE)
                .content(table)
                .header(""Status"", """")
                .build();

        components.add(ct);

        String[][] tcTable = new String[tcs.size()][2];
        for( int i=0; i<tcs.size(); i++ ){
            tcTable[i][0] = ""Termination Condition "" + i;
            tcTable[i][1] = tcs.get(i).toString();
        }

        components.add(DIV_SPACER_20PX);

        ComponentTable ct2 = new ComponentTable.Builder(STYLE_TABLE)
                .content(tcTable)
                .header(""Termination Condition"", """")
                .build();

        components.add(ct2);

        components.addAll(chartsAndBest.getFirst());


        ComponentDiv cd = new ComponentDiv(STYLE_DIV_WIDTH_100_PC, components);

        return ok(asJson(cd)).as(JSON);
    }"
"public static String getReconcileHashCode(Map<String, AtomicInteger> instanceCountMap) {
        StringBuilder reconcileHashCode = new StringBuilder(75);
        for (Map.Entry<String, AtomicInteger> mapEntry : instanceCountMap.entrySet()) {
            reconcileHashCode.append(mapEntry.getKey()).append(STATUS_DELIMITER).append(mapEntry.getValue().get())
                    .append(STATUS_DELIMITER);
        }
        return reconcileHashCode.toString();
    }"
"protected void registerFactorComparator(final FactorComparator<T> comparator) {
    if (null == comparator ||
        Integer.MAX_VALUE - this.getTotalWeight() < comparator.getWeight()) {
      throw new IllegalArgumentException(""unable to register comparator."" +
          "" The passed comparator is null or has an invalid weight value."");
    }

    // add or replace the Comparator.
    this.factorComparatorList.put(comparator.getFactorName(), comparator);
    logger.debug(String.format(""Factor comparator added for '%s'. Weight = '%s'"",
        comparator.getFactorName(), comparator.getWeight()));
  }"
"@Deprecated
	public static <T> FlinkKafkaProducer010Configuration<T> writeToKafkaWithTimestamps(DataStream<T> inStream,
																					String topicId,
																					KeyedSerializationSchema<T> serializationSchema,
																					Properties producerConfig,
																					FlinkKafkaPartitioner<T> customPartitioner) {
		FlinkKafkaProducer010<T> kafkaProducer = new FlinkKafkaProducer010<>(topicId, serializationSchema, producerConfig, customPartitioner);
		DataStreamSink<T> streamSink = inStream.addSink(kafkaProducer);
		return new FlinkKafkaProducer010Configuration<>(streamSink, inStream, kafkaProducer);
	}"
"public void updateByXml(Source source) throws IOException {
        checkPermission(CONFIGURE);
        StringWriter out = new StringWriter();
        try {
            // this allows us to use UTF-8 for storing data,
            // plus it checks any well-formedness issue in the submitted
            // data
            XMLUtils.safeTransform(source, new StreamResult(out));
            out.close();
        } catch (TransformerException|SAXException e) {
            throw new IOException(""Failed to persist configuration.xml"", e);
        }

        // try to reflect the changes by reloading
        try (InputStream in = new BufferedInputStream(new ByteArrayInputStream(out.toString().getBytes(StandardCharsets.UTF_8)))){
            // Do not allow overwriting view name as it might collide with another
            // view in same ViewGroup and might not satisfy Jenkins.checkGoodName.
            String oldname = name;
            ViewGroup oldOwner = owner; // oddly, this field is not transient
            Object o = Jenkins.XSTREAM2.unmarshal(XStream2.getDefaultDriver().createReader(in), this, null, true);
            if (!o.getClass().equals(getClass())) {
                // ensure that we've got the same view type. extending this code to support updating
                // to different view type requires destroying & creating a new view type
                throw new IOException(""Expecting view type: ""+this.getClass()+"" but got: ""+o.getClass()+"" instead."" +
                    ""\nShould you needed to change to a new view type, you must first delete and then re-create "" +
                    ""the view with the new view type."");
            }
            name = oldname;
            owner = oldOwner;
        } catch (StreamException | ConversionException | Error e) {// mostly reflection errors
            throw new IOException(""Unable to read"",e);
        }
        save();
    }"
"@EventListener
    public void logTicketGrantingTicketCreatedEvent(final CasTicketGrantingTicketCreatedEvent e) {
        val tgtId = sanitize(e.getTgtId());
        LOGGER.debug(GRANTED_TGT_MSG,
                e.getTgtCreationTime(),
                tgtId,
                e.getTimeToLive(),
                e.getTimeToIdle(),
                e.getPrincipalId());
    }"
"public static Unmarshaller createUnmarshaller(Class clazz) {
		try {
			JAXBContext jaxbContext = getJaxbContext(clazz);
			return jaxbContext.createUnmarshaller();
		} catch (JAXBException e) {
			throw ExceptionUtil.unchecked(e);
		}
	}"
"public boolean close() {
		lock.lock();
		try {
			if (open) {
				if (elements.isEmpty()) {
					open = false;
					nonEmpty.signalAll();
					return true;
				} else {
					return false;
				}
			}
			else {
				// already closed
				return true;
			}
		} finally {
			lock.unlock();
		}
	}"
"public ColumnValueSelector<?> makeColumnValueSelector(String columnName, ColumnSelectorFactory factory)
  {
    final VirtualColumn virtualColumn = getVirtualColumn(columnName);
    if (virtualColumn == null) {
      throw new IAE(""No such virtual column[%s]"", columnName);
    } else {
      final ColumnValueSelector<?> selector = virtualColumn.makeColumnValueSelector(columnName, factory);
      Preconditions.checkNotNull(selector, ""selector"");
      return selector;
    }
  }"
"@SneakyThrows
    public static IPersonAttributeDao newStubAttributeRepository(final PrincipalAttributesProperties p) {
        val dao = new NamedStubPersonAttributeDao();
        val pdirMap = new LinkedHashMap<String, List<Object>>();
        val stub = p.getStub();
        stub.getAttributes().forEach((key, value) -> {
            val vals = StringUtils.commaDelimitedListToStringArray(value);
            pdirMap.put(key, Arrays.stream(vals).collect(Collectors.toList()));
        });
        dao.setBackingMap(pdirMap);
        if (StringUtils.hasText(stub.getId())) {
            dao.setId(stub.getId());
        }
        return dao;
    }"
"public Actions release() {
    if (isBuildingActions()) {
      action.addAction(new ButtonReleaseAction(jsonMouse, null));
    }

    return tick(defaultMouse.createPointerUp(Button.LEFT.asArg()));
  }"
"public static void main(String[] args) throws Exception {
    if (args.length < 2) {
      logger.severe(""Usage: please pass 2 arguments:\n"" +
                    ""arg0 = location of the JSON file for the service account you created in the GCP console\n"" +
                    ""arg1 = project name in the form \""projects/xyz\"" where \""xyz\"" is the project ID of the project you created.\n"");
      System.exit(1);
    }
    GoogleCredentials credentials = GoogleCredentials.fromStream(new FileInputStream(args[0]));

    // We need to create appropriate scope as per https://cloud.google.com/storage/docs/authentication#oauth-scopes
    credentials = credentials.createScoped(Arrays.asList(""https://www.googleapis.com/auth/cloud-platform""));

    // credentials must be refreshed before the access token is available
    credentials.refreshAccessToken();
    GoogleAuthClient client =
            new GoogleAuthClient(""pubsub.googleapis.com"", 443, MoreCallCredentials.from(credentials));

    try {
      client.getTopics(args[1]);
    } finally {
      client.shutdown();
    }
  }"
"Optional<ExecutableElement> overridingOrHidingMethod(ExecutableElement overridden, TypeElement classElement) {
        List<ExecutableElement> methods = ElementFilter.methodsIn(elementUtils.getAllMembers(classElement));
        for (ExecutableElement method : methods) {
            if (!method.equals(overridden) && method.getSimpleName().equals(overridden.getSimpleName())) {
                return Optional.of(method);
            }
        }
        // might be looking for a package private & packages differ method in a superclass
        // that is not visible to the most concrete subclass, really!
        // e.g. see injectPackagePrivateMethod4() for SpareTire -> Tire -> RoundThing in Inject tck
        // check the superclass until we reach Object, then bail out with empty if necessary.
        TypeElement superClass = superClassFor(classElement);
        if (superClass != null && !isObjectClass(superClass)) {
            return overridingOrHidingMethod(overridden, superClass);
        }
        return Optional.empty();
    }"
"public Map<String, Float> getTermAndRank(String content, int size)
    {
        Map<String, Float> map = getTermAndRank(content);
        Map<String, Float> result = top(size, map);

        return result;
    }"
"private void throwPoolInitializationException(Throwable t)
   {
      logger.error(""{} - Exception during pool initialization."", poolName, t);
      destroyHouseKeepingExecutorService();
      throw new PoolInitializationException(t);
   }"
"@SneakyThrows
    public void start(final int port) {
        try {
            ServerBootstrap bootstrap = new ServerBootstrap();
            bossGroup = createEventLoopGroup();
            if (bossGroup instanceof EpollEventLoopGroup) {
                groupsEpoll(bootstrap);
            } else {
                groupsNio(bootstrap);
            }
            ChannelFuture future = bootstrap.bind(port).sync();
            future.channel().closeFuture().sync();
        } finally {
            workerGroup.shutdownGracefully();
            bossGroup.shutdownGracefully();
            BackendExecutorContext.getInstance().getExecuteEngine().close();
        }
    }"
"protected Proxy selectProxy(URL requestTokenURL) {
    try {
      List<Proxy> selectedProxies = getProxySelector().select(requestTokenURL.toURI());
      return selectedProxies.isEmpty() ? Proxy.NO_PROXY : selectedProxies.get(0);
    }
    catch (URISyntaxException e) {
      throw new IllegalArgumentException(e);
    }
  }"
"public RemoteInputChannel toRemoteInputChannel(ConnectionID producerAddress) {
		return new RemoteInputChannel(inputGate, channelIndex, partitionId, checkNotNull(producerAddress), connectionManager, initialBackoff, maxBackoff, metrics);
	}"
"@Override
	public Appendable append(CharSequence csq, int start, int end) {
		final int otherLen = end - start;
		grow(this.len + otherLen);
		for (int pos = start; pos < end; pos++) {
			this.value[this.len + pos] = csq.charAt(pos);
		}
		this.len += otherLen;
		return this;
	}"
"protected void handleOversizedMessage(ChannelHandlerContext ctx, S oversized) throws Exception {
        ctx.fireExceptionCaught(
                new TooLongFrameException(""content length exceeded "" + maxContentLength() + "" bytes.""));
    }"
"@Nonnull
	static StateMetaInfoReader getReader(int readVersion) {
		switch (readVersion) {
			case CURRENT_STATE_META_INFO_SNAPSHOT_VERSION:
				return CurrentReaderImpl.INSTANCE;
			case 5:
				return V5ReaderImpl.INSTANCE;
			default:
					throw new IllegalArgumentException(""Unsupported read version for state meta info: "" + readVersion);
		}
	}"
"final boolean tryCompensate(ForkJoinTask<?> task, ManagedBlocker blocker) {
        int pc = parallelism, e;
        long c = ctl;
        WorkQueue[] ws = workQueues;
        if ((e = (int)c) >= 0 && ws != null) {
            int u, a, ac, hc;
            int tc = (short)((u = (int)(c >>> 32)) >>> UTC_SHIFT) + pc;
            boolean replace = false;
            if ((a = u >> UAC_SHIFT) <= 0) {
                if ((ac = a + pc) <= 1)
                    replace = true;
                else if ((e > 0 || (task != null &&
                                    ac <= (hc = pc >>> 1) && tc < pc + hc))) {
                    WorkQueue w;
                    for (int j = 0; j < ws.length; ++j) {
                        if ((w = ws[j]) != null && !w.isEmpty()) {
                            replace = true;
                            break;   // in compensation range and tasks available
                        }
                    }
                }
            }
            if ((task == null || task.status >= 0) && // recheck need to block
                (blocker == null || !blocker.isReleasable()) && ctl == c) {
                if (!replace) {          // no compensation
                    long nc = ((c - AC_UNIT) & AC_MASK) | (c & ~AC_MASK);
                    if (U.compareAndSwapLong(this, CTL, c, nc))
                        return true;
                }
                else if (e != 0) {       // release an idle worker
                    WorkQueue w; Thread p; int i;
                    if ((i = e & SMASK) < ws.length && (w = ws[i]) != null) {
                        long nc = ((long)(w.nextWait & E_MASK) |
                                   (c & (AC_MASK|TC_MASK)));
                        if (w.eventCount == (e | INT_SIGN) &&
                            U.compareAndSwapLong(this, CTL, c, nc)) {
                            w.eventCount = (e + E_SEQ) & E_MASK;
                            if ((p = w.parker) != null)
                                U.unpark(p);
                            return true;
                        }
                    }
                }
                else if (tc < MAX_CAP) { // create replacement
                    long nc = ((c + TC_UNIT) & TC_MASK) | (c & ~TC_MASK);
                    if (U.compareAndSwapLong(this, CTL, c, nc)) {
                        addWorker();
                        return true;
                    }
                }
            }
        }
        return false;
    }"
"@PublicEvolving
	public String getValue(ConfigOption<?> configOption) {
		Object o = getValueOrDefaultFromOption(configOption);
		return o == null ? null : o.toString();
	}"
"private Map<String, Object> convertParametersToMap(ParametersWithBasePath parametersWithBasePath) {

        Map<String, Object> output = new HashMap<>();
        for (Parameter param : parametersWithBasePath.parameters) {
            switch (param.getType()) {
                case ""StringList"":
                    // command delimited list back into a set/list and exvalues value to be key=value,key=value
                    String[] items = param.getValue().split("","");
                    for (String item : items) {
                        // now split to key value
                        String[] keyValue = item.split(""="");
                        if (keyValue.length > 1) {
                            output.put(keyValue[0], keyValue[1]);
                        } else {
                            addKeyFromPath(output, parametersWithBasePath, param, keyValue[0]);
                        }
                    }
                    break;

                case ""SecureString"":
                    // if decrypt is set to true on request KMS is supposed to decrypt these for us otherwise we get
                    // back an encoded encrypted string of gobbly gook. It uses the default account key unless
                    // one is specified in the config
                    String[] keyValue = param.getValue().split(""="");
                    if (keyValue.length > 1) {
                        output.put(keyValue[0], keyValue[1]);
                    } else {
                        addKeyFromPath(output, parametersWithBasePath, param, keyValue[0]);
                    }

                    break;

                default:
                case ""String"":
                    String[] keyVal = param.getValue().split(""="");
                    if (keyVal.length > 1) {
                        output.put(keyVal[0], keyVal[1]);
                    } else {
                        addKeyFromPath(output, parametersWithBasePath, param, keyVal[0]);
                    }
                    break;
            }
        }
        return output;

    }"
"public EpollSocketChannelConfig setIpTransparent(boolean transparent) {
        try {
            ((EpollSocketChannel) channel).socket.setIpTransparent(transparent);
            return this;
        } catch (IOException e) {
            throw new ChannelException(e);
        }
    }"
"public static void main(String[] args)
  {
    BitmapIterationBenchmark state = new BitmapIterationBenchmark();
    state.bitmapAlgo = ""concise"";
    state.prob = 0.001;
    state.size = 1000000;
    state.setup();

    BitmapsForIntersection state2 = new BitmapsForIntersection();
    state2.setup(state);
    state.intersectionAndIter(state2);
  }"
"public static long[] shape(DataBuffer buffer) {
        val ret = new long[rank(buffer)];
        for (int i = 0; i < ret.length; i++)
            ret[i] = buffer.getInt(1 + i);
        return ret;
    }"
"public static VarBinaryVector vectorFor(BufferAllocator bufferAllocator,String name,INDArray[] data) {
        VarBinaryVector ret = new VarBinaryVector(name,bufferAllocator);
        ret.allocateNew();
        for(int i = 0; i < data.length; i++) {
            //slice the databuffer to use only the needed portion of the buffer
            //for proper offset
            ByteBuffer byteBuffer = BinarySerde.toByteBuffer(data[i]);
            ret.set(i,byteBuffer,0,byteBuffer.capacity());
        }

        return ret;
    }"
"@SafeVarargs
	public final <X> DataSource<X> fromElements(X... data) {
		if (data == null) {
			throw new IllegalArgumentException(""The data must not be null."");
		}
		if (data.length == 0) {
			throw new IllegalArgumentException(""The number of elements must not be zero."");
		}

		TypeInformation<X> typeInfo;
		try {
			typeInfo = TypeExtractor.getForObject(data[0]);
		}
		catch (Exception e) {
			throw new RuntimeException(""Could not create TypeInformation for type "" + data[0].getClass().getName()
					+ ""; please specify the TypeInformation manually via ""
					+ ""ExecutionEnvironment#fromElements(Collection, TypeInformation)"", e);
		}

		return fromCollection(Arrays.asList(data), typeInfo, Utils.getCallLocationName());
	}"
"public NioServer init(InetSocketAddress address) {
		try {
			// 打开服务器套接字通道
			this.serverSocketChannel = ServerSocketChannel.open();
			// 设置为非阻塞状态
			serverSocketChannel.configureBlocking(false);
			// 获取通道相关联的套接字
			final ServerSocket serverSocket = serverSocketChannel.socket();
			// 绑定端口号
			serverSocket.bind(address);

			// 打开一个选择器
			selector = Selector.open();
			// 服务器套接字注册到Selector中 并指定Selector监控连接事件
			serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);
		} catch (IOException e) {
			throw new IORuntimeException(e);
		}

		return this;
	}"
"public DistinctOperator<T> distinct(int... fields) {
		return new DistinctOperator<>(this, new Keys.ExpressionKeys<>(fields, getType()), Utils.getCallLocationName());
	}"
"public @Nonnull Result combine(@Nonnull Result that) {
        if(this.ordinal < that.ordinal)
            return that;
        else
            return this;
    }"
"protected S state(S newState) {
        S oldState = state;
        state = newState;
        return oldState;
    }"
"public static String mapToXmlStr(Map<?, ?> data, String rootName) {
		return toStr(mapToXml(data, rootName));
	}"
"public static List<Method> getPublicMethods(Class<?> clazz, Method... excludeMethods) {
		final HashSet<Method> excludeMethodSet = CollectionUtil.newHashSet(excludeMethods);
		return getPublicMethods(clazz, new Filter<Method>() {
			@Override
			public boolean accept(Method method) {
				return false == excludeMethodSet.contains(method);
			}
		});
	}"
"public static void start(String[] args, String relativeResourcePath, boolean finalizeRestRegistration) {
    long time0 = System.currentTimeMillis();
    // Fire up the H2O Cluster
    H2O.main(args);

    H2O.registerResourceRoot(new File(relativeResourcePath + File.separator + ""h2o-web/src/main/resources/www""));
    H2O.registerResourceRoot(new File(relativeResourcePath + File.separator + ""h2o-core/src/main/resources/www""));
    ExtensionManager.getInstance().registerRestApiExtensions();
    if (!H2O.ARGS.disable_web) {
      if (finalizeRestRegistration) {
        H2O.startServingRestApi();
      }
    }

    long timeF = System.currentTimeMillis();
    Log.info(""H2O started in "" + (timeF - time0) + ""ms"");
    if (!H2O.ARGS.disable_web) {
      Log.info("""");
      Log.info(""Open H2O Flow in your web browser: "" + H2O.getURL(NetworkInit.h2oHttpView.getScheme()));
      Log.info("""");
    }
  }"
"public boolean hasAnyScope(String... scopes) {
		boolean result = OAuth2ExpressionUtils.hasAnyScope(authentication, scopes);
		if (!result) {
			missingScopes.addAll(Arrays.asList(scopes));
		}
		return result;
	}"
"@Override
    public void run()
    {
        if (running.compareAndSet(IDLE, RUNNING))
        {
            sequenceBarrier.clearAlert();

            notifyStart();
            try
            {
                if (running.get() == RUNNING)
                {
                    processEvents();
                }
            }
            finally
            {
                notifyShutdown();
                running.set(IDLE);
            }
        }
        else
        {
            // This is a little bit of guess work.  The running state could of changed to HALTED by
            // this point.  However, Java does not have compareAndExchange which is the only way
            // to get it exactly correct.
            if (running.get() == RUNNING)
            {
                throw new IllegalStateException(""Thread is already running"");
            }
            else
            {
                earlyExit();
            }
        }
    }"
"public void onAsyncResponse(ConsumerConfig config, SofaRequest request, SofaResponse response, Throwable throwable)
        throws SofaRpcException {
        try {
            for (Filter loadedFilter : loadedFilters) {
                loadedFilter.onAsyncResponse(config, request, response, throwable);
            }
        } catch (SofaRpcException e) {
            LOGGER
                .errorWithApp(config.getAppName(), ""Catch exception when do filtering after asynchronous respond."", e);
        }
    }"
"@Override
	public void serializeRecord(T record) throws IOException {
		if (CHECKED) {
			if (dataBuffer.hasRemaining()) {
				throw new IllegalStateException(""Pending serialization of previous record."");
			}
		}

		serializationBuffer.clear();
		lengthBuffer.clear();

		// write data and length
		record.write(serializationBuffer);

		int len = serializationBuffer.length();
		lengthBuffer.putInt(0, len);

		dataBuffer = serializationBuffer.wrapAsByteBuffer();
	}"
"public float[] percentilesFloat(double[] pcts)
  {
    readWriteLock.readLock().lock();

    try {
      float[] results = new float[pcts.length];
      long total = count;

      int pctIdx = 0;

      long prev = 0;
      double prevP = 0.0;
      double prevB = lowerLimit;
      for (int i = 0; i < numBuckets; ++i) {
        long next = prev + histogram[i];
        double nextP = 100.0 * next / total;
        double nextB = (i + 1) * bucketSize + lowerLimit;
        while (pctIdx < pcts.length && nextP >= pcts[pctIdx]) {
          double f = (pcts[pctIdx] - prevP) / (nextP - prevP);
          results[pctIdx] = (float) (f * (nextB - prevB) + prevB);
          ++pctIdx;
        }
        if (pctIdx >= pcts.length) {
          break;
        }
        prev = next;
        prevP = nextP;
        prevB = nextB;
      }

      return results;
    }
    finally {
      readWriteLock.readLock().unlock();
    }
  }"
"public static EventLoopGroup getServerIoEventLoopGroup(ServerTransportConfig config) {
        String type = config.getProtocolType();
        EventLoopGroup ioGroup = serverIoGroups.get(type);
        if (ioGroup == null) {
            synchronized (NettyHelper.class) {
                ioGroup = serverIoGroups.get(config.getProtocolType());
                if (ioGroup == null) {
                    int ioThreads = config.getIoThreads();
                    ioThreads = ioThreads <= 0 ? Math.max(8, SystemInfo.getCpuCores() + 1) : ioThreads;
                    NamedThreadFactory threadName =
                            new NamedThreadFactory(""SEV-IO-"" + config.getPort(), config.isDaemon());
                    ioGroup = config.isUseEpoll() ?
                        new EpollEventLoopGroup(ioThreads, threadName) :
                        new NioEventLoopGroup(ioThreads, threadName);
                    serverIoGroups.put(type, ioGroup);
                    refCounter.putIfAbsent(ioGroup, new AtomicInteger(0));
                }
            }
        }
        refCounter.get(ioGroup).incrementAndGet();
        return ioGroup;
    }"
"private String getUniqueTemplateName(String name, String ext) {
		if (this.getTreeModel().getTemplate(name) == null) {
			// Its unique
			return name;
		}
		// Its not unique, add a suitable index...
		String stub = name.substring(0, name.length() - ext.length() - 1);
		int index = 1;
		do {
			index++;
			name = stub + ""("" + index + "")."" + ext;
		}
		while (this.getTreeModel().getTemplate(name) != null);
		
		return name;
	}"
"protected void cancel(String[] args) throws Exception {
		LOG.info(""Running 'cancel' command."");

		final Options commandOptions = CliFrontendParser.getCancelCommandOptions();

		final Options commandLineOptions = CliFrontendParser.mergeOptions(commandOptions, customCommandLineOptions);

		final CommandLine commandLine = CliFrontendParser.parse(commandLineOptions, args, false);

		CancelOptions cancelOptions = new CancelOptions(commandLine);

		// evaluate help flag
		if (cancelOptions.isPrintHelp()) {
			CliFrontendParser.printHelpForCancel(customCommandLines);
			return;
		}

		final CustomCommandLine<?> activeCommandLine = getActiveCustomCommandLine(commandLine);

		final String[] cleanedArgs = cancelOptions.getArgs();

		if (cancelOptions.isWithSavepoint()) {
			final JobID jobId;
			final String targetDirectory;

			if (cleanedArgs.length > 0) {
				jobId = parseJobId(cleanedArgs[0]);
				targetDirectory = cancelOptions.getSavepointTargetDirectory();
			} else {
				jobId = parseJobId(cancelOptions.getSavepointTargetDirectory());
				targetDirectory = null;
			}

			if (targetDirectory == null) {
				logAndSysout(""Cancelling job "" + jobId + "" with savepoint to default savepoint directory."");
			} else {
				logAndSysout(""Cancelling job "" + jobId + "" with savepoint to "" + targetDirectory + '.');
			}

			runClusterAction(
				activeCommandLine,
				commandLine,
				clusterClient -> {
					final String savepointPath;
					try {
						savepointPath = clusterClient.cancelWithSavepoint(jobId, targetDirectory);
					} catch (Exception e) {
						throw new FlinkException(""Could not cancel job "" + jobId + '.', e);
					}
					logAndSysout(""Cancelled job "" + jobId + "". Savepoint stored in "" + savepointPath + '.');
				});
		} else {
			final JobID jobId;

			if (cleanedArgs.length > 0) {
				jobId = parseJobId(cleanedArgs[0]);
			} else {
				throw new CliArgsException(""Missing JobID. Specify a JobID to cancel a job."");
			}

			logAndSysout(""Cancelling job "" + jobId + '.');

			runClusterAction(
				activeCommandLine,
				commandLine,
				clusterClient -> {
					try {
						clusterClient.cancel(jobId);
					} catch (Exception e) {
						throw new FlinkException(""Could not cancel job "" + jobId + '.', e);
					}
				});

			logAndSysout(""Cancelled job "" + jobId + '.');
		}
	}"
"@GuardedBy(""evictionLock"")
  int evictFromWindow() {
    int candidates = 0;
    Node<K, V> node = accessOrderWindowDeque().peek();
    while (windowWeightedSize() > windowMaximum()) {
      // The pending operations will adjust the size to reflect the correct weight
      if (node == null) {
        break;
      }

      Node<K, V> next = node.getNextInAccessOrder();
      if (node.getWeight() != 0) {
        node.makeMainProbation();
        accessOrderWindowDeque().remove(node);
        accessOrderProbationDeque().add(node);
        candidates++;

        setWindowWeightedSize(windowWeightedSize() - node.getPolicyWeight());
      }
      node = next;
    }

    return candidates;
  }"
"public static Map<String, List<String>> getServiceUrlsMapFromConfig(EurekaClientConfig clientConfig, String instanceZone, boolean preferSameZone) {
        Map<String, List<String>> orderedUrls = new LinkedHashMap<>();
        String region = getRegion(clientConfig);
        String[] availZones = clientConfig.getAvailabilityZones(clientConfig.getRegion());
        if (availZones == null || availZones.length == 0) {
            availZones = new String[1];
            availZones[0] = DEFAULT_ZONE;
        }
        logger.debug(""The availability zone for the given region {} are {}"", region, availZones);
        int myZoneOffset = getZoneOffset(instanceZone, preferSameZone, availZones);

        String zone = availZones[myZoneOffset];
        List<String> serviceUrls = clientConfig.getEurekaServerServiceUrls(zone);
        if (serviceUrls != null) {
            orderedUrls.put(zone, serviceUrls);
        }
        int currentOffset = myZoneOffset == (availZones.length - 1) ? 0 : (myZoneOffset + 1);
        while (currentOffset != myZoneOffset) {
            zone = availZones[currentOffset];
            serviceUrls = clientConfig.getEurekaServerServiceUrls(zone);
            if (serviceUrls != null) {
                orderedUrls.put(zone, serviceUrls);
            }
            if (currentOffset == (availZones.length - 1)) {
                currentOffset = 0;
            } else {
                currentOffset++;
            }
        }

        if (orderedUrls.size() < 1) {
            throw new IllegalArgumentException(""DiscoveryClient: invalid serviceUrl specified!"");
        }
        return orderedUrls;
    }"
"public static File zip(File zipFile, String path, String data) throws UtilException {
		return zip(zipFile, path, data, DEFAULT_CHARSET);
	}"
"public static <T> List<T> page(int pageNo, int pageSize, List<T> list) {
		if (isEmpty(list)) {
			return new ArrayList<>(0);
		}

		int resultSize = list.size();
		// 每页条目数大于总数直接返回所有
		if (resultSize <= pageSize) {
			if (pageNo <= 1) {
				return Collections.unmodifiableList(list);
			} else {
				// 越界直接返回空
				return new ArrayList<>(0);
			}
		}
		final int[] startEnd = PageUtil.transToStartEnd(pageNo, pageSize);
		if (startEnd[1] > resultSize) {
			startEnd[1] = resultSize;
		}
		return list.subList(startEnd[0], startEnd[1]);
	}"
"protected void list(String[] args) throws Exception {
		LOG.info(""Running 'list' command."");

		final Options commandOptions = CliFrontendParser.getListCommandOptions();

		final Options commandLineOptions = CliFrontendParser.mergeOptions(commandOptions, customCommandLineOptions);

		final CommandLine commandLine = CliFrontendParser.parse(commandLineOptions, args, false);

		ListOptions listOptions = new ListOptions(commandLine);

		// evaluate help flag
		if (listOptions.isPrintHelp()) {
			CliFrontendParser.printHelpForList(customCommandLines);
			return;
		}

		final boolean showRunning;
		final boolean showScheduled;
		final boolean showAll;

		// print running and scheduled jobs if not option supplied
		if (!listOptions.showRunning() && !listOptions.showScheduled() && !listOptions.showAll()) {
			showRunning = true;
			showScheduled = true;
			showAll = false;
		} else {
			showRunning = listOptions.showRunning();
			showScheduled = listOptions.showScheduled();
			showAll = listOptions.showAll();
		}

		final CustomCommandLine<?> activeCommandLine = getActiveCustomCommandLine(commandLine);

		runClusterAction(
			activeCommandLine,
			commandLine,
			clusterClient -> listJobs(clusterClient, showRunning, showScheduled, showAll));

	}"
"protected void updateDescendentsForExec(int execStep, VarId executedVar) {
        String varName = executedVar.getVariable();
        Variable var = sameDiff.getVariables().get(executedVar.getVariable());
        //Find any ops (or variables with control dependencies) that this is required for execution of and check if now available for exec
        List<String> l = sameDiff.getVariables().get(executedVar.getVariable()).getInputsForOp();
        String[] inputForOps = l == null ? null : l.toArray(new String[l.size()]);  //Just executed variable is input to these ops
        List<String> controlDepForVars = var.getControlDepsForVar();                //Just executed variable is a control dependency for these variables
        List<String> controlDepForOps = var.getControlDepsForOp();                  //Just executed variable is a control dependency for these ops


        SDVariable v = var.getVariable();
        boolean isConstOrPhInput = v.isPlaceHolder() || v.isConstant();

        //After a variable becomes available, we should look at the ops this is an input to, and check if we can execute this op now...
        if (inputForOps != null) {
            for (String opName : inputForOps) {

                DifferentialFunction fn = sameDiff.getFunctionById(opName);
                if (fn instanceof Merge) {
                    //Merge op: available for execution when *any* of its inputs are available. But only mark it for exec once...
                    List<String> opOutputs = sameDiff.getOps().get(opName).getOutputsOfOp();
                    Preconditions.checkState(opOutputs.size() == 1, ""Expected only 1 output variable for merge op, got %s"", opOutputs);
                    VarId outVarId = newVarId(opOutputs.get(0), executedVar.getFrame(), executedVar.getIteration(), executedVar.getParentFrame());
                    if (!nodeOutputs.containsKey(outVarId) && subgraph.contains(outVarId.getVariable()) && !availableForExecSet.contains(outVarId)) {
                        availableForExec.add(outVarId);
                        availableForExecSet.add(outVarId);
                        log.trace(""Marked merge op ({}) variable {} as available for execution: input {} is now available"", opName, outVarId, executedVar);
                    }

                    //Mark that we need the specified input to calculate this output
                    addToExecInputs(isConstOrPhInput, executedVar, outVarId);
                    continue;
                } else if (fn instanceof Enter) {
                    //Enter node: available for exec when any of its inputs are available for exec
                    // Note input feeds from one frame to another
                    List<String> opOutputs = sameDiff.getOps().get(opName).getOutputsOfOp();
                    Preconditions.checkState(opOutputs.size() == 1, ""Expected only 1 output variable for enter op, got %s"", opOutputs);
                    Enter e = (Enter) fn;
                    boolean isConstant = e.isConstant();
                    VarId outVarId = newVarId(opOutputs.get(0), e.getFrameName(), 0, executedVar.toFrameIter());     //Note: parent frame of output op is enter var's *current* frame

                    if(isConstant && executedVar.getParentFrame() != null){
                        //For enter nodes that are constants, we want iteration 0 in all frames in the heirarchy
                        //For example, const -> Enter(a) -> Enter(b) -> op; in this case, the input to Op (at any frame/iteration) should should
                        // be the constant value - which is recorded as (frame=""a"",iter=0,parent=(frame=""b"",iter=0))
                        outVarId.setParentFrame(outVarId.getParentFrame().clone());
                        FrameIter fi = outVarId.getParentFrame();
                        while(fi != null){
                            fi.setIteration(0);
                            fi = fi.getParentFrame();
                        }
                    }

                    if (!nodeOutputs.containsKey(outVarId) && subgraph.contains(outVarId.getVariable()) && !availableForExecSet.contains(outVarId)) {
                        availableForExec.add(outVarId);
                        availableForExecSet.add(outVarId);
                        log.trace(""Marked enter op ({}) variable {} as available for execution: input {} is now available"", opName, outVarId, executedVar);
                    }

                    //Also record the parent frame: we'll need this when we get to the corresponding exit ops
                    frameParents.put(e.getFrameName(), executedVar.toFrameIter());

                    //Mark that we need the specified input to calculate this output
                    addToExecInputs(isConstOrPhInput, executedVar, outVarId);
                    continue;
                } else if (fn instanceof Exit) {
                    //Exit node forwards input to parent frame
                    List<String> opOutputs = sameDiff.getOps().get(opName).getOutputsOfOp();
                    FrameIter parentFrame = frameParents.get(executedVar.getFrame());
                    Preconditions.checkNotNull(parentFrame, ""Parent frame must not be null for exit op: variable to exec is %s"", executedVar);

                    VarId outVarId = new VarId(opOutputs.get(0), parentFrame.getFrame(), parentFrame.getIteration(), executedVar.getParentFrame().getParentFrame());    //Parent frame of output is parent of current parent
                    if (!nodeOutputs.containsKey(outVarId) && subgraph.contains(outVarId.getVariable()) && !availableForExecSet.contains(outVarId)) {
                        availableForExec.add(outVarId);
                        availableForExecSet.add(outVarId);
                        log.trace(""Marked Exit op ({}) variable {} as available for execution: input {} is now available"", opName, outVarId, executedVar);
                    }

                    addToExecInputs(isConstOrPhInput, executedVar, outVarId);
                    continue;
                } else if (fn instanceof NextIteration) {
                    //NextIteration is available for execution when its single input is available
                    //NextIteration op: forwards its single input to the output of the current frame, but increments the iteration number
                    List<String> opOutputs = sameDiff.getOps().get(opName).getOutputsOfOp();
                    Preconditions.checkState(opOutputs.size() == 1, ""Expected exactly 1 output for NextIteration op: got %s"", opOutputs);
                    VarId outVarId = newVarId(opOutputs.get(0), executedVar.getFrame(), executedVar.getIteration() + 1, executedVar.getParentFrame());

                    if (!nodeOutputs.containsKey(outVarId) && subgraph.contains(outVarId.getVariable()) && !availableForExecSet.contains(outVarId)) {
                        availableForExec.add(outVarId);
                        availableForExecSet.add(outVarId);
                        log.trace(""Marked NextIteration op ({}) variable {} as available for execution: input {} is now available"", opName, outVarId, executedVar);
                    }

                    //Mark that we need the specified input to calculate this output
                    addToExecInputs(isConstOrPhInput, executedVar, outVarId);
                    continue;
                }
                //Note for LoopCond: just forwards input to output - so basically handle it the same as other ops here


                //Can execute this op - and hence get it's output variables - if all inputs (and control deps) are available
                String[] inputsThisOp = fn.argNames();
                boolean allInputsAvailable = true;
                if (inputsThisOp != null) {
                    allInputsAvailable = allInputsAvailable(execStep, inputsThisOp, executedVar);
                }

                //Check Op control dependencies
                List<String> opControlDeps = sameDiff.getOps().get(opName).getControlDeps();
                if (opControlDeps != null && allInputsAvailable) {
                    for (String cd : opControlDeps) {
                        VarId vcd = newVarId(cd, executedVar.getFrame(), executedVar.getIteration(), executedVar.getParentFrame());
                        if (!nodeOutputs.containsKey(vcd)) {
                            allInputsAvailable = false;
                            break;
                        }
                    }
                }

                List<String> opOutputs = sameDiff.getOps().get(opName).getOutputsOfOp();
                if (opOutputs != null) {

                    for (String s : opOutputs) {
                        //The input (for normal ops - not Enter/Exit/NextIteration) have the same frame and iteration number as the just executed var
                        //Exception 1 to this: constants. If variable is a constant, then it's always iteration 0 of the main frame  (unless variable control dep exists)
                        //Exception 2 to this: placeholders. As above
                        SDVariable sdv = sameDiff.getVariable(s);
                        Variable variable = sameDiff.getVariables().get(s);
                        VarId outVarId;
                        if (sdv.isConstant() || sdv.isPlaceHolder()) {
                            //Constant
                            if(variable.getControlDeps() == null || var.getControlDeps().isEmpty()){
                                //Standard case - do a lookup of placeholder/constant
                                outVarId = newVarId(s, OUTER_FRAME, 0, null);
                            } else {
                                //Edge case: control dependency x -> constant exists
                                //We should look up based on x's frame/iteration
                                outVarId = newVarId(s, executedVar.getFrame(), executedVar.getIteration(), executedVar.getParentFrame());
                            }
                        } else {
                            //Normal (non-constant)
                            outVarId = newVarId(s, executedVar.getFrame(), executedVar.getIteration(), executedVar.getParentFrame());
                        }

                        //Mark that we need the specified input to calculate this output
                        addToExecInputs(isConstOrPhInput, executedVar, outVarId);

                        //Check variable control dependencies, for each of the op outputs
                        if(allInputsAvailable && variable.getControlDeps() != null && !variable.getControlDeps().isEmpty()){
                            //If one of the op outputs has a control dependency input, make sure this is available
                            // before executing the op
                            //For example, if z=add(x,y) and control dependency A->z exists, then don't execute op until A is available
                            for(String cd : variable.getControlDeps()){
                                Variable cdVar = sameDiff.getVariables().get(cd);
                                VarId cdVarId = null;
                                if (cdVar.getVariable().isConstant() || cdVar.getVariable().isPlaceHolder()) {
                                    //Constant
                                    if(variable.getControlDeps() == null || var.getControlDeps().isEmpty()){
                                        //Standard case - do a lookup of placeholder/constant
                                        cdVarId = newVarId(cd, OUTER_FRAME, 0, null);
                                    } else {
                                        //Edge case: control dependency x -> constant -> thisOutput exists
                                        //We should look up based on x's frame/iteration
                                        cdVarId = newVarId(cd, executedVar.getFrame(), executedVar.getIteration(), executedVar.getParentFrame());
                                    }
                                } else {
                                    //Normal (non-constant)
                                    cdVarId = newVarId(cd, executedVar.getFrame(), executedVar.getIteration(), executedVar.getParentFrame());
                                }
                                allInputsAvailable &= nodeOutputs.containsKey(cdVarId);
                                if(!allInputsAvailable)
                                    break;
                            }
                        }
                    }

                    if (allInputsAvailable) {
                        //Op can be executed -> variables as output are available for exec

                        for (String s : opOutputs) {
                            if (!subgraph.contains(s))
                                continue;       //Don't need this variable to calculate requested outputs - so don't mark as available for execution
                            VarId vid = newVarId(s, executedVar.getFrame(), executedVar.getIteration(), executedVar.getParentFrame());
                            if(!availableForExecSet.contains(vid)) {
                                availableForExec.add(vid);
                                availableForExecSet.add(vid);
                                log.trace(""Marked variable as available for execution: {} - output of op {} ({}) with op inputs {}"", vid, opName,
                                        fn.getClass().getSimpleName(), (inputsThisOp == null ? ""<none>"" : Arrays.toString(inputsThisOp)));
                            }
                        }
                    }
                }

            }
        }

        //Also check variable control dependencies... if control dependency varX->varY exists and varY is a constant/placeholder/variable,
        // then it's not going to be triggered by the op-based check above
        if(controlDepForVars != null){
            for(String s : controlDepForVars){
                if (!subgraph.contains(s))
                    continue;       //Don't need this variable to calculate requested outputs - so don't mark as available for execution

                SDVariable depFor = sameDiff.getVariable(s);
                if(depFor.getVariableType() != VariableType.ARRAY){
                    //Control dependency executedVar -> s exists, where ""s"" is not the output of an op
                    //Even thought this is a constant, we'll inherit the frame and iteration from the control dependency
                    // otherwise, we lose this frame/iteration information for any downstream variables using the constant within a frame
                    VarId outVarId = newVarId(s, executedVar.getFrame(), executedVar.getIteration(), executedVar.getParentFrame());
                    if(!availableForExecSet.contains(outVarId)) {
                        availableForExec.add(outVarId);
                        availableForExecSet.add(outVarId);
                        log.trace(""Marked variable as available for execution: {} - control dependency {} -> {} exists"", outVarId, executedVar.getVariable(), s);
                    }
                } else {
                    //Another edge case: OpX has output varY (with no inputs), and control dependency executedVar -> varY exists
                    //We should check if OpX is now available for execution...
                    //Similarly, if we have OpX with inputs, but we're only waiting on a varible control dependency Z -> X
                    // then we might not get triggered as available for exec above either
                    String opName = sameDiff.getVariables().get(s).getOutputOfOp();
                    if(opName != null){
                        SameDiffOp op = sameDiff.getOps().get(opName);
                        boolean allInputsAvailable = true;
                        if(op.getInputsToOp() != null && !op.getInputsToOp().isEmpty()){
                            List<String> inputList = op.getInputsToOp();
                            allInputsAvailable = allInputsAvailable(execStep, inputList.toArray(new String[inputList.size()]), executedVar);
                        }

                        if(allInputsAvailable && op.getControlDeps() != null){
                            for(String cd : op.getControlDeps()){
                                VarId vid = newVarId(cd, executedVar.getFrame(), executedVar.getIteration(), executedVar.getParentFrame());     //Note: is array type, therefore has same frame/iter as parent
                                allInputsAvailable &= nodeOutputs.containsKey(vid);
                                if(!allInputsAvailable)
                                    break;
                            }
                        }
                        if(allInputsAvailable){
                            for(String opOutput : op.getOutputsOfOp()){
                                Variable v2 = sameDiff.getVariables().get(opOutput);
                                if(v2.getControlDeps() != null){
                                    for(String s2 : v2.getControlDeps()){
                                        VarId vid = newVarId(s2, executedVar.getFrame(), executedVar.getIteration(), executedVar.getParentFrame());     //Note: is array type, therefore has same frame/iter as parent
                                        allInputsAvailable &= nodeOutputs.containsKey(vid);
                                        if(!allInputsAvailable)
                                            break;
                                    }
                                }
                            }
                        }

                        if(allInputsAvailable){
                            VarId outVarId = newVarId(s, executedVar.getFrame(), executedVar.getIteration(), executedVar.getParentFrame());
                            if(!availableForExecSet.contains(outVarId)) {
                                availableForExec.add(outVarId);
                                log.trace(""Marked variable as available for execution: {} - is output of op {} with no inputs (but has control dependencies)"", outVarId, op.getName());
                            }
                        }
                    }
                }
            }
        }

        //Edge case: if control dependency varX->opY exists, and opY doesn't have any inputs, it also can't be triggeered
        // (made available for execution) by any of the previous checks. For any ops that DO have inputs, they will
        // be triggered already
        if(controlDepForOps != null){
            for(String opName : controlDepForOps){
                SameDiffOp op = sameDiff.getOps().get(opName);
                if(op.getInputsToOp() == null || op.getInputsToOp().isEmpty()){
                    for(String out : op.getOutputsOfOp()){
                        if (!subgraph.contains(out))
                            continue;       //Don't need this variable to calculate requested outputs - so don't mark as available for execution

                        //TODO is it possible to have both variable and op control dependencies??
                        VarId outVarId = newVarId(out, OUTER_FRAME, 0, null);
                        if(!availableForExecSet.contains(outVarId)) {
                            availableForExec.add(outVarId);
                            availableForExecSet.add(outVarId);
                            log.trace(""Marked variable as available for execution: {} - op control dependency variable {} -> op {} exists"", outVarId, executedVar.getVariable(), opName);
                        }
                    }
                }
            }
        }
    }"
"private static String factorizeFullness(long bitmapCardinality, long numRows)
  {
    if (bitmapCardinality == 0) {
      return ""0"";
    } else if (bitmapCardinality == numRows) {
      return ""1"";
    } else {
      double fullness = bitmapCardinality / (double) numRows;
      int index = Arrays.binarySearch(BITMAP_FULLNESS_FACTORIZATION_STOPS, fullness);
      if (index < 0) {
        index = ~index;
      }
      return FACTORIZED_FULLNESS[index];
    }
  }"
"private String getConnectionFactoryName(String beanName) {
		if (beanName.length() > CONNECTION_FACTORY_SUFFIX.length()
				&& StringUtils.endsWithIgnoreCase(beanName, CONNECTION_FACTORY_SUFFIX)) {
			return beanName.substring(0,
					beanName.length() - CONNECTION_FACTORY_SUFFIX.length());
		}
		return beanName;
	}"
"private void writeObject(ObjectOutputStream out) throws IOException {
		super.write(out);
		out.writeUTF(this.mapreduceInputFormat.getClass().getName());
		out.writeUTF(this.keyClass.getName());
		out.writeUTF(this.valueClass.getName());
		this.configuration.write(out);
	}"
"public static void execute(final Connection connection, final String sql) throws SQLException {
        try (PreparedStatement preparedStatement = connection.prepareStatement(sql)){
            preparedStatement.execute();
        }
    }"
"@Override
  public String decodeUtf8(ByteBuffer buffer, int offset, int length)
      throws IllegalArgumentException {
    if (buffer.hasArray()) {
      return decodeUtf8Array(buffer.array(), buffer.arrayOffset() + offset, length);
    } else {
      return decodeUtf8Buffer(buffer, offset, length);
    }
  }"
"public static Object[] notEmpty(Object[] array, String errorMsgTemplate, Object... params) throws IllegalArgumentException {
		if (ArrayUtil.isEmpty(array)) {
			throw new IllegalArgumentException(StrUtil.format(errorMsgTemplate, params));
		}
		return array;
	}"
"private void createMDAGNode(SimpleMDAGNode current, int fromIndex, MDAGNode[] toNodeArray, MDAGNode[] fromNodeArray)
    {
        MDAGNode from = (fromIndex == -1 ? sourceNode : toNodeArray[fromIndex]);
        int transitionSetBegin = current.getTransitionSetBeginIndex();
        int onePastTransitionSetEnd = transitionSetBegin + current.getOutgoingTransitionSetSize();

        for (int i = transitionSetBegin; i < onePastTransitionSetEnd; i++)
        {
            SimpleMDAGNode targetNode = mdagDataArray[i];
            if (toNodeArray[i] != null)
            {
                fromNodeArray[fromIndex].addOutgoingTransition(current.getLetter(), fromNodeArray[i]);
                toNodeArray[fromIndex] = fromNodeArray[i];
                continue;
            }
            toNodeArray[i] = from.addOutgoingTransition(targetNode.getLetter(), targetNode.isAcceptNode());
            fromNodeArray[i] = from;
            createMDAGNode(targetNode, i, toNodeArray, fromNodeArray);
        }
    }"
"public ExecutionResult addEvent(HystrixEventType eventType) {
        return new ExecutionResult(eventCounts.plus(eventType), startTimestamp, executionLatency,
                userThreadLatency, failedExecutionException, executionException,
                executionOccurred, isExecutedInThread, collapserKey);
    }"
"@Override
    public void setMessage(HttpMessage msg) {
	try {
            if (script != null) {
                script.parseParameters(this, msg);
            }
            
        } catch (Exception e) {
            // Catch Exception instead of ScriptException because script engine implementations might
            // throw other exceptions on script errors (e.g. jdk.nashorn.internal.runtime.ECMAException)
            extension.handleScriptException(wrapper, e);
        }
    }"
"public SDVariable erf(String name, SDVariable x) {
        validateNumerical(""erf (error function)"", x);
        SDVariable ret = f().erf(x);
        return updateVariableNameAndReference(ret, name);
    }"
"public static void checkNotNull(Object o, String msg, int arg1) {
        if (o == null) {
            throwNullPointerEx(msg, arg1);
        }
    }"
"private String getServerTlsFingerPrint() {
        String fingerPrint = null;
        Map<String, Object> serverConfig = Config.getInstance().getJsonMapConfigNoCache(""server"");
        Map<String, Object> secretConfig = Config.getInstance().getJsonMapConfigNoCache(""secret"");
        // load keystore here based on server config and secret config
        String keystoreName = (String)serverConfig.get(""keystoreName"");
        String serverKeystorePass = (String)secretConfig.get(""serverKeystorePass"");
        if(keystoreName != null) {
            try (InputStream stream = Config.getInstance().getInputStreamFromFile(keystoreName)) {
                KeyStore loadedKeystore = KeyStore.getInstance(""JKS"");
                loadedKeystore.load(stream, serverKeystorePass.toCharArray());
                X509Certificate cert = (X509Certificate)loadedKeystore.getCertificate(""server"");
                if(cert != null) {
                    fingerPrint = FingerPrintUtil.getCertFingerPrint(cert);
                } else {
                    logger.error(""Unable to find the certificate with alias name as server in the keystore"");
                }
            } catch (Exception e) {
                logger.error(""Unable to load server keystore "", e);
            }
        }
        return fingerPrint;
    }"
"private BatchObject initBatchObject(Identity identity, Class clazz) {
        if (EventData.class.equals(clazz)) {
            RowBatch rowbatch = new RowBatch();
            rowbatch.setIdentity(identity);
            return rowbatch;
        } else if (FileData.class.equals(clazz)) {
            FileBatch fileBatch = new FileBatch();
            fileBatch.setIdentity(identity);
            return fileBatch;
        } else {
            throw new TransformException(""no support Data["" + clazz.getName() + ""]"");
        }
    }"
"public final void putShortLittleEndian(int index, short value) {
		if (LITTLE_ENDIAN) {
			putShort(index, value);
		} else {
			putShort(index, Short.reverseBytes(value));
		}
	}"
"public static String arrayAwareToString(Object o) {
		if (o == null) {
			return ""null"";
		}
		if (o.getClass().isArray()) {
			return arrayToString(o);
		}

		return o.toString();
	}"
"public static void gray(Image srcImage, ImageOutputStream destImageStream) throws IORuntimeException {
		writeJpg(gray(srcImage), destImageStream);
	}"
"@Override
    public Node visitUse(SqlBaseParser.UseContext context)
    {
        return new Use(
                getLocation(context),
                visitIfPresent(context.catalog, Identifier.class),
                (Identifier) visit(context.schema));
    }"
"public void stop() {
        Plugin plugin = getPlugin();
        if (plugin != null) {
            try {
                LOGGER.log(Level.FINE, ""Stopping {0}"", shortName);
                plugin.stop();
            } catch (Throwable t) {
                LOGGER.log(WARNING, ""Failed to shut down "" + shortName, t);
            }
        } else {
            LOGGER.log(Level.FINE, ""Could not find Plugin instance to stop for {0}"", shortName);
        }
        // Work around a bug in commons-logging.
        // See http://www.szegedi.org/articles/memleak.html
        LogFactory.release(classLoader);
    }"
"public double[] getColumnPackedCopy()
    {
        double[] vals = new double[m * n];
        for (int i = 0; i < m; i++)
        {
            for (int j = 0; j < n; j++)
            {
                vals[i + j * m] = A[i][j];
            }
        }
        return vals;
    }"
"@SuppressWarnings(""unused"")
  @Deprecated
  public RequestTemplate insert(int pos, CharSequence value) {
    return target(value.toString());
  }"
"public static String toStringWithRootCause(@Nullable Throwable t) {
		if (t == null) {
			return StringUtils.EMPTY;
		}

		final String clsName = ClassUtils.getShortClassName(t, null);
		final String message = StringUtils.defaultString(t.getMessage());
		Throwable cause = getRootCause(t);

		StringBuilder sb = new StringBuilder(128).append(clsName).append("": "").append(message);
		if (cause != t) {
			sb.append(""; <---"").append(toStringWithShortName(cause));
		}

		return sb.toString();
	}"
"public LogicalWindow resolveGroupWindow(GroupWindow window) {
		Expression alias = window.getAlias();

		if (!(alias instanceof UnresolvedReferenceExpression)) {
			throw new ValidationException(""Alias of group window should be an UnresolvedFieldReference"");
		}

		final String windowName = ((UnresolvedReferenceExpression) alias).getName();
		List<Expression> resolvedTimeFieldExpression =
			prepareExpressions(Collections.singletonList(window.getTimeField()));
		if (resolvedTimeFieldExpression.size() != 1) {
			throw new ValidationException(""Group Window only supports a single time field column."");
		}
		PlannerExpression timeField = resolvedTimeFieldExpression.get(0).accept(bridgeConverter);

		//TODO replace with LocalReferenceExpression
		WindowReference resolvedAlias = new WindowReference(windowName, new Some<>(timeField.resultType()));

		if (window instanceof TumbleWithSizeOnTimeWithAlias) {
			TumbleWithSizeOnTimeWithAlias tw = (TumbleWithSizeOnTimeWithAlias) window;
			return new TumblingGroupWindow(
				resolvedAlias,
				timeField,
				resolveFieldsInSingleExpression(tw.getSize()).accept(bridgeConverter));
		} else if (window instanceof SlideWithSizeAndSlideOnTimeWithAlias) {
			SlideWithSizeAndSlideOnTimeWithAlias sw = (SlideWithSizeAndSlideOnTimeWithAlias) window;
			return new SlidingGroupWindow(
				resolvedAlias,
				timeField,
				resolveFieldsInSingleExpression(sw.getSize()).accept(bridgeConverter),
				resolveFieldsInSingleExpression(sw.getSlide()).accept(bridgeConverter));
		} else if (window instanceof SessionWithGapOnTimeWithAlias) {
			SessionWithGapOnTimeWithAlias sw = (SessionWithGapOnTimeWithAlias) window;
			return new SessionGroupWindow(
				resolvedAlias,
				timeField,
				resolveFieldsInSingleExpression(sw.getGap()).accept(bridgeConverter));
		} else {
			throw new TableException(""Unknown window type"");
		}
	}"
"public final void __tryComplete(CountedCompleter caller) {
    CountedCompleter a = this, s = caller;
    for (int c;;) {
      if((c = a.pending) == 0) {
        a.onCompletion(s);
        if ((a = (s = a).completer) == null) {
          s.quietlyComplete();
          return;
        }
      }
      else if (U.compareAndSwapInt(a, PENDING, c, c - 1))
        return;
    }
  }"
"public static String downloadString(String url, String customCharsetName) {
		return downloadString(url, CharsetUtil.charset(customCharsetName), null);
	}"
"@Override
    public Object map(Object input) {
        if (input instanceof Number) {
            Number number = (Number) input;
            return doOp(number.doubleValue());
        }
        throw new IllegalArgumentException(""Input must be a number"");
    }"
"static void verifyJenkinsConnection(URLConnection c) throws IOException {
        if (c.getHeaderField(""X-Hudson"")==null && c.getHeaderField(""X-Jenkins"")==null)
            throw new NotTalkingToJenkinsException(c);
    }"
"@Deprecated
    public static long parseTimestampLiteral(TimeZoneKey timeZoneKey, String value)
    {
        try {
            DateTime dateTime = TIMESTAMP_WITH_TIME_ZONE_FORMATTER.parseDateTime(value);
            return packDateTimeWithZone(dateTime);
        }
        catch (RuntimeException e) {
            return LEGACY_TIMESTAMP_WITHOUT_TIME_ZONE_FORMATTER.withChronology(getChronology(timeZoneKey)).parseMillis(value);
        }
    }"
"public void mergeContinuousNsIntoOne()
    {
        for (int row = 0; row < vertexes.length - 1; ++row)
        {
            List<Vertex> vertexListFrom = vertexes[row];
            ListIterator<Vertex> listIteratorFrom = vertexListFrom.listIterator();
            while (listIteratorFrom.hasNext())
            {
                Vertex from = listIteratorFrom.next();
                if (from.getNature() == Nature.ns)
                {
                    int toIndex = row + from.realWord.length();
                    ListIterator<Vertex> listIteratorTo = vertexes[toIndex].listIterator();
                    while (listIteratorTo.hasNext())
                    {
                        Vertex to = listIteratorTo.next();
                        if (to.getNature() == Nature.ns)
                        {
                            // 我们不能直接改，因为很多条线路在公用指针
//                            from.realWord += to.realWord;
                            logger.info(""合并【"" + from.realWord + ""】和【"" + to.realWord + ""】"");
                            listIteratorFrom.set(Vertex.newAddressInstance(from.realWord + to.realWord));
//                            listIteratorTo.remove();
                            break;
                        }
                    }
                }
            }
        }
    }"
"@Override
   public void addBagItem(final int waiting)
   {
      final boolean shouldAdd = waiting - addConnectionQueue.size() >= 0; // Yes, >= is intentional.
      if (shouldAdd) {
         addConnectionExecutor.submit(poolEntryCreator);
      }
   }"
"@VisibleForTesting
	@Override
	public void requestSubpartition(int subpartitionIndex) throws IOException, InterruptedException {
		if (partitionRequestClient == null) {
			// Create a client and request the partition
			partitionRequestClient = connectionManager
				.createPartitionRequestClient(connectionId);

			partitionRequestClient.requestSubpartition(partitionId, subpartitionIndex, this, 0);
		}
	}"
"@Override
	public void addBuilderCustomizers(UndertowBuilderCustomizer... customizers) {
		Assert.notNull(customizers, ""Customizers must not be null"");
		this.builderCustomizers.addAll(Arrays.asList(customizers));
	}"
"public void parse(final InsertStatement insertStatement) {
        if (!lexerEngine.skipIfEqual(getCustomizedInsertKeywords())) {
            return;
        }
        lexerEngine.accept(DefaultKeyword.DUPLICATE);
        lexerEngine.accept(DefaultKeyword.KEY);
        lexerEngine.accept(DefaultKeyword.UPDATE);
        do {
            Column column = new Column(SQLUtil.getExactlyValue(lexerEngine.getCurrentToken().getLiterals()), insertStatement.getTables().getSingleTableName());
            if (shardingRule.isShardingColumn(column.getName(), column.getTableName())) {
                throw new SQLParsingException(""INSERT INTO .... ON DUPLICATE KEY UPDATE can not support on sharding column, token is '%s', literals is '%s'."",
                        lexerEngine.getCurrentToken().getType(), lexerEngine.getCurrentToken().getLiterals());
            }
            basicExpressionParser.parse(insertStatement);
            lexerEngine.accept(Symbol.EQ);
            if (lexerEngine.skipIfEqual(DefaultKeyword.VALUES)) {
                lexerEngine.accept(Symbol.LEFT_PAREN);
                basicExpressionParser.parse(insertStatement);
                lexerEngine.accept(Symbol.RIGHT_PAREN);
            } else {
                lexerEngine.nextToken();
            }
        } while (lexerEngine.skipIfEqual(Symbol.COMMA));
    }"
"@Override
    public int iamin(INDArray arr) {
        switch (arr.data().dataType()) {
            case DOUBLE:
                DefaultOpExecutioner.validateDataType(DataType.DOUBLE, arr);
                return idamin(arr.length(), arr, 1);
            case FLOAT:
                DefaultOpExecutioner.validateDataType(DataType.FLOAT, arr);
                return isamin(arr.length(), arr, 1);
            case HALF:
                DefaultOpExecutioner.validateDataType(DataType.HALF, arr);
                return ihamin(arr.length(), arr, 1);
            default:
        }
        throw new UnsupportedOperationException();
    }"
"public Http2Stream newStream(List<Header> requestHeaders, boolean out) throws IOException {
    return newStream(0, requestHeaders, out);
  }"
"private String validateCookie(HttpServletRequest request) throws UnsupportedEncodingException {
    // Find all the valid cookies associated with the request.
    Cookie[] cookies = request.getCookies();

    if (cookies == null) {
      if (LOG.isDebugEnabled()) {
        LOG.debug(""No valid cookies associated with the request "" + request);
      }
      return null;
    }
    if (LOG.isDebugEnabled()) {
      LOG.debug(""Received cookies: "" + toCookieStr(cookies));
    }
    return getClientNameFromCookie(cookies);
  }"
"@Override
    public void deliver(final OtpMsg msg) {
        final boolean delivered = self.deliver(msg);

        switch (msg.type()) {
        case OtpMsg.linkTag:
            if (delivered) {
                links.addLink(msg.getRecipientPid(), msg.getSenderPid());
            } else {
                try {
                    // no such pid - send exit to sender
                    super.sendExit(msg.getRecipientPid(), msg.getSenderPid(),
                            new OtpErlangAtom(""noproc""));
                } catch (final IOException e) {
                }
            }
            break;

        case OtpMsg.unlinkTag:
        case OtpMsg.exitTag:
            links.removeLink(msg.getRecipientPid(), msg.getSenderPid());
            break;

        case OtpMsg.exit2Tag:
            break;
        }

        return;
    }"
"public void collectRouteStats(String route, int statusCode) {

        // increments 200, 301, 401, 503, etc. status counters
        final String preciseStatusString = String.format(""status_%d"", statusCode);
        NamedCountingMonitor preciseStatus = namedStatusMap.get(preciseStatusString);
        if (preciseStatus == null) {
            preciseStatus = new NamedCountingMonitor(preciseStatusString);
            NamedCountingMonitor found = namedStatusMap.putIfAbsent(preciseStatusString, preciseStatus);
            if (found != null) preciseStatus = found;
            else MonitorRegistry.getInstance().registerObject(preciseStatus);
        }
        preciseStatus.increment();

        // increments 2xx, 3xx, 4xx, 5xx status counters
        final String summaryStatusString = String.format(""status_%dxx"", statusCode / 100);
        NamedCountingMonitor summaryStatus = namedStatusMap.get(summaryStatusString);
        if (summaryStatus == null) {
            summaryStatus = new NamedCountingMonitor(summaryStatusString);
            NamedCountingMonitor found = namedStatusMap.putIfAbsent(summaryStatusString, summaryStatus);
            if (found != null) summaryStatus = found;
            else MonitorRegistry.getInstance().registerObject(summaryStatus);
        }
        summaryStatus.increment();

        // increments route and status counter
        if (route == null) route = ""ROUTE_NOT_FOUND"";
        route = route.replace(""/"", ""_"");
        ConcurrentHashMap<Integer, RouteStatusCodeMonitor> statsMap = routeStatusMap.get(route);
        if (statsMap == null) {
            statsMap = new ConcurrentHashMap<Integer, RouteStatusCodeMonitor>();
            routeStatusMap.putIfAbsent(route, statsMap);
        }
        RouteStatusCodeMonitor sd = statsMap.get(statusCode);
        if (sd == null) {
            //don't register only 404 status codes (these are garbage endpoints)
            if (statusCode == 404) {
                if (statsMap.size() == 0) {
                    return;
                }
            }

            sd = new RouteStatusCodeMonitor(route, statusCode);
            RouteStatusCodeMonitor sd1 = statsMap.putIfAbsent(statusCode, sd);
            if (sd1 != null) {
                sd = sd1;
            } else {
                MonitorRegistry.getInstance().registerObject(sd);
            }
        }
        sd.update();
    }"
"public static Integer hexToIntObject(@Nullable String str, Integer defaultValue) {
		if (StringUtils.isEmpty(str)) {
			return defaultValue;
		}
		try {
			return Integer.decode(str);
		} catch (final NumberFormatException nfe) {
			return defaultValue;
		}
	}"
"public Collection<ProviderInfo> currentProviderList() {
        List<ProviderInfo> providerInfos = new ArrayList<ProviderInfo>();
        List<ProviderGroup> providerGroups = addressHolder.getProviderGroups();
        if (CommonUtils.isNotEmpty(providerGroups)) {
            for (ProviderGroup entry : providerGroups) {
                providerInfos.addAll(entry.getProviderInfos());
            }
        }
        return providerInfos;
    }"
"protected char[] resolvePath(char[] basePath, char[] relPath)
        throws URIException {

        // REMINDME: paths are never null
        String base = (basePath == null) ? """" : new String(basePath);

        // _path could be empty
        if (relPath == null || relPath.length == 0) {
            return normalize(basePath);
        } else if (relPath[0] == '/') {
            return normalize(relPath);
        } else {
            int at = base.lastIndexOf('/');
            if (at != -1) {
                basePath = base.substring(0, at + 1).toCharArray();
            }
            StringBuffer buff = new StringBuffer(base.length() 
                + relPath.length);
            buff.append((at != -1) ? base.substring(0, at + 1) : ""/"");
            buff.append(relPath);
            return normalize(buff.toString().toCharArray());
        }
    }"
"@SuppressWarnings(""unchecked"")
	public long addRecord(T record) throws IOException {

		if (recordsOutFile == null) {
			
			if (closed) {
				throw new IllegalStateException(""The large record handler has been closed."");
			}
			if (recordsReader != null) {
				throw new IllegalStateException(""The handler has already switched to sorting."");
			}
			
			LOG.debug(""Initializing the large record spilling..."");
			
			// initialize the utilities
			{
				final TypeComparator<?>[] keyComps = comparator.getFlatComparators();
				numKeyFields = keyComps.length;
				Object[] keyHolder = new Object[numKeyFields];
				
				comparator.extractKeys(record, keyHolder, 0);
				
				TypeSerializer<?>[] keySers = new TypeSerializer<?>[numKeyFields];
				TypeSerializer<?>[] tupleSers = new TypeSerializer<?>[numKeyFields + 1];
				
				int[] keyPos = new int[numKeyFields];
				
				for (int i = 0; i < numKeyFields; i++) {
					keyPos[i] = i;
					keySers[i] = createSerializer(keyHolder[i], i);
					tupleSers[i] = keySers[i];
				}
				// add the long serializer for the offset
				tupleSers[numKeyFields] = LongSerializer.INSTANCE;
				
				keySerializer = new TupleSerializer<Tuple>((Class<Tuple>) Tuple.getTupleClass(numKeyFields+1), tupleSers);
				keyComparator = new TupleComparator<Tuple>(keyPos, keyComps, keySers);
				
				keySerializerFactory = new RuntimeSerializerFactory<Tuple>(keySerializer, keySerializer.getTupleClass());

				keyTuple = keySerializer.createInstance();
			}
			
			// initialize the spilling
			final int totalNumSegments = memory.size();
			final int segmentsForKeys = (totalNumSegments >= 2*MAX_SEGMENTS_FOR_KEY_SPILLING) ? MAX_SEGMENTS_FOR_KEY_SPILLING : 
				Math.max(MIN_SEGMENTS_FOR_KEY_SPILLING, totalNumSegments - MAX_SEGMENTS_FOR_KEY_SPILLING);
				
			List<MemorySegment> recordsMemory = new ArrayList<MemorySegment>();
			List<MemorySegment> keysMemory = new ArrayList<MemorySegment>();
			
			for (int i = 0; i < segmentsForKeys; i++) {
				keysMemory.add(memory.get(i));
			}
			for (int i = segmentsForKeys; i < totalNumSegments; i++) {
				recordsMemory.add(memory.get(i));
			}
			
			recordsChannel = ioManager.createChannel();
			keysChannel = ioManager.createChannel();
			
			recordsOutFile = new FileChannelOutputView(
					ioManager.createBlockChannelWriter(recordsChannel), memManager,
					recordsMemory, memManager.getPageSize());
			
			keysOutFile = new FileChannelOutputView(
					ioManager.createBlockChannelWriter(keysChannel), memManager,
					keysMemory, memManager.getPageSize());
		}
		
		final long offset = recordsOutFile.getWriteOffset();
		if (offset < 0) {
			throw new RuntimeException(""wrong offset"");
		}
		
		Object[] keyHolder = new Object[numKeyFields];
		
		comparator.extractKeys(record, keyHolder, 0);
		for (int i = 0; i < numKeyFields; i++) {
			keyTuple.setField(keyHolder[i], i);
		}
		keyTuple.setField(offset, numKeyFields);
		
		keySerializer.serialize(keyTuple, keysOutFile);
		serializer.serialize(record, recordsOutFile);
		
		recordCounter++;
		
		return offset;
	}"
"public void setCustomEndpointInitializer(EndpointInitializer initializer) {
		Objects.requireNonNull(initializer, ""Initializer has to be set"");
		ClosureCleaner.ensureSerializable(initializer);
		this.initializer = initializer;
	}"
"public boolean hasCache() {
        if (isCache()) {
            return true;
        }
        if (CommonUtils.isNotEmpty(methods)) {
            for (MethodConfig methodConfig : methods.values()) {
                if (CommonUtils.isTrue(methodConfig.getCache())) {
                    return true;
                }
            }
        }
        return false;
    }"
"private JCheckBox getChkProcessForm() {
		if (chkProcessForm == null) {
			chkProcessForm = new JCheckBox();
			chkProcessForm.setText(Constant.messages.getString(""spider.options.label.processform""));

			// Code for controlling the status of the chkPostForm
			chkProcessForm.addChangeListener(new ChangeListener() {
				@Override
				public void stateChanged(ChangeEvent ev) {
					if (chkProcessForm.isSelected()) {
						chkPostForm.setEnabled(true);
					} else {
						chkPostForm.setEnabled(false);
					}
				}
			});
		}
		return chkProcessForm;
	}"
"public File createTempDir(String prefix, String suffix) {
    try {
      // Create a tempfile, and delete it.
      File file = File.createTempFile(prefix, suffix, baseDir);
      file.delete();

      // Create it as a directory.
      File dir = new File(file.getAbsolutePath());
      if (!dir.mkdirs()) {
        throw new WebDriverException(""Cannot create profile directory at "" + dir.getAbsolutePath());
      }

      // Create the directory and mark it writable.
      FileHandler.createDir(dir);

      temporaryFiles.add(dir);
      return dir;
    } catch (IOException e) {
      throw new WebDriverException(
          ""Unable to create temporary file at "" + baseDir.getAbsolutePath());
    }
  }"
"public static InternalLogId allocate(Class<?> type, @Nullable String details) {
    return allocate(getClassName(type), details);
  }"
"@Exported
    @QuickSilver
    public RunT getLastCompletedBuild() {
        RunT r = getLastBuild();
        while (r != null && r.isBuilding())
            r = r.getPreviousBuild();
        return r;
    }"
"public Map<Symbol, Symbol> sourceSymbolMap(int sourceIndex)
    {
        ImmutableMap.Builder<Symbol, Symbol> builder = ImmutableMap.builder();
        for (Map.Entry<Symbol, Collection<Symbol>> entry : outputToInputs.asMap().entrySet()) {
            builder.put(entry.getKey(), Iterables.get(entry.getValue(), sourceIndex));
        }

        return builder.build();
    }"
"public int exactMatchSearch(char[] keyChars, int pos, int len, int nodePos)
    {
        int result = -1;

        int b = base[nodePos];
        int p;

        for (int i = pos; i < len; i++)
        {
            p = b + (int) (keyChars[i]) + 1;
            if (b == check[p])
                b = base[p];
            else
                return result;
        }

        p = b;
        int n = base[p];
        if (b == check[p] && n < 0)
        {
            result = -n - 1;
        }
        return result;
    }"
"@Override
   public ResultSet getResultSet() throws SQLException {
      final ResultSet resultSet = delegate.getResultSet();
      if (resultSet != null) {
         if (proxyResultSet == null || ((ProxyResultSet) proxyResultSet).delegate != resultSet) {
            proxyResultSet = ProxyFactory.getProxyResultSet(connection, this, resultSet);
         }
      }
      else {
         proxyResultSet = null;
      }
      return proxyResultSet;
   }"
"@Override
	public void writeEntry(String entryName, InputStream inputStream) throws IOException {
		JarArchiveEntry entry = new JarArchiveEntry(entryName);
		writeEntry(entry, new InputStreamEntryWriter(inputStream, true));
	}"
"public int read_int() throws OtpErlangDecodeException {
        final long l = this.read_long(false);
        final int i = (int) l;

        if (l != i) {
            throw new OtpErlangDecodeException(""Value does not fit in int: ""
                    + l);
        }

        return i;
    }"
"public static <T extends Item> AutoCompletionCandidates ofJobNames(final Class<T> type, final String value, @CheckForNull Item self, ItemGroup container) {
        if (self==container)
            container = self.getParent();
        return ofJobNames(type, value, container);
    }"
"private void internalCopyDirContent(File src, File dest) throws IORuntimeException {
		if (null != copyFilter && false == copyFilter.accept(src)) {
			//被过滤的目录跳过
			return;
		}
		
		if (false == dest.exists()) {
			//目标为不存在路径，创建为目录
			dest.mkdirs();
		} else if (false == dest.isDirectory()) {
			throw new IORuntimeException(StrUtil.format(""Src [{}] is a directory but dest [{}] is a file!"", src.getPath(), dest.getPath()));
		}
		
		final String files[] = src.list();
		File srcFile;
		File destFile;
		for (String file : files) {
			srcFile = new File(src, file);
			destFile = this.isOnlyCopyFile ? dest : new File(dest, file);
			// 递归复制
			if (srcFile.isDirectory()) {
				internalCopyDirContent(srcFile, destFile);
			} else {
				internalCopyFile(srcFile, destFile);
			}
		}
	}"
"public RelationType joinWith(RelationType other)
    {
        List<Field> fields = ImmutableList.<Field>builder()
                .addAll(this.allFields)
                .addAll(other.allFields)
                .build();

        return new RelationType(fields);
    }"
"@SneakyThrows
    public TableMetaData load(final String logicTableName, final ShardingRule shardingRule) {
        return tableMetaDataLoader.load(logicTableName, shardingRule);
    }"
"public final boolean unregisterCloseable(C closeable) {

		if (null == closeable) {
			return false;
		}

		synchronized (getSynchronizationLock()) {
			return doUnRegister(closeable, closeableToRef);
		}
	}"
"protected void configureSigningKeyFromPrivateKeyResource(final String signingSecretKey) {
        val object = extractPrivateKeyFromResource(signingSecretKey);
        LOGGER.trace(""Located signing key resource [{}]"", signingSecretKey);
        setSigningKey(object);
    }"
"private void unlinkLast(Node<E> last, Node<E> prev) {
        // assert last != null;
        // assert prev != null;
        // assert last.item == null;
        for (Node<E> o = null, p = prev, q;;) {
            if (p.item != null || (q = p.prev) == null) {
                if (o != null && p.next != p && last.casPrev(prev, p)) {
                    skipDeletedSuccessors(p);
                    if (last.next == null &&
                        (p.prev == null || p.item != null) &&
                        p.next == last) {

                        updateHead(); // Ensure o is not reachable from head
                        updateTail(); // Ensure o is not reachable from tail

                        // Finally, actually gc-unlink
                        o.lazySetPrev(o);
                        o.lazySetNext(nextTerminator());
                    }
                }
                return;
            }
            else if (p == q)
                return;
            else {
                o = p;
                p = q;
            }
        }
    }"
"public static String decodeHexStr(String hexStr, Charset charset) {
		if (StrUtil.isEmpty(hexStr)) {
			return hexStr;
		}
		return decodeHexStr(hexStr.toCharArray(), charset);
	}"
"public static HystrixThreadPoolProperties.Setter initializeThreadPoolProperties(List<HystrixProperty> properties) throws IllegalArgumentException {
        return initializeProperties(HystrixThreadPoolProperties.Setter(), properties, TP_PROP_MAP, ""thread pool"");
    }"
"private void emitRecordWithTimestampAndPunctuatedWatermark(
			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {
		@SuppressWarnings(""unchecked"")
		final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =
				(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) partitionState;

		// only one thread ever works on accessing timestamps and watermarks
		// from the punctuated extractor
		final long timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp);
		final Watermark newWatermark = withWatermarksState.checkAndGetNewWatermark(record, timestamp);

		// emit the record with timestamp, using the usual checkpoint lock to guarantee
		// atomicity of record emission and offset state update
		synchronized (checkpointLock) {
			sourceContext.collectWithTimestamp(record, timestamp);
			partitionState.setOffset(offset);
		}

		// if we also have a new per-partition watermark, check if that is also a
		// new cross-partition watermark
		if (newWatermark != null) {
			updateMinPunctuatedWatermark(newWatermark);
		}
	}"
"public OAuthSession exchangeCode(String code, HttpUrl redirectUrl) throws IOException {
    HttpUrl url = baseUrl.newBuilder(""oauth.access"")
        .addQueryParameter(""client_id"", clientId)
        .addQueryParameter(""client_secret"", clientSecret)
        .addQueryParameter(""code"", code)
        .addQueryParameter(""redirect_uri"", redirectUrl.toString())
        .build();
    Request request = new Request.Builder()
        .url(url)
        .build();
    Call call = httpClient.newCall(request);
    try (Response response = call.execute()) {
      JsonAdapter<OAuthSession> jsonAdapter = moshi.adapter(OAuthSession.class);
      return jsonAdapter.fromJson(response.body().source());
    }
  }"
"Instance marshall(ServiceInstance serviceInstance) {
		String hostname = serviceInstance.getHost();
		String managementPort = serviceInstance.getMetadata().get(""management.port"");
		String port = managementPort == null ? String.valueOf(serviceInstance.getPort())
				: managementPort;
		String cluster = getClusterName(serviceInstance);
		Boolean status = Boolean.TRUE; // TODO: where to get?
		if (hostname != null && cluster != null && status != null) {
			Instance instance = getInstance(hostname, port, cluster, status);

			Map<String, String> metadata = serviceInstance.getMetadata();
			boolean securePortEnabled = serviceInstance.isSecure();

			addMetadata(instance, hostname, port, securePortEnabled, port, metadata);

			return instance;
		}
		else {
			return null;
		}
	}"
"public static RateLimiterExports ofIterable(String prefix, Iterable<RateLimiter> rateLimiters) {
        return new RateLimiterExports(prefix, rateLimiters);
    }"
"public static HystrixMetricsPublisherCommand createOrRetrievePublisherForCommand(HystrixCommandKey commandKey, HystrixCommandGroupKey commandOwner, HystrixCommandMetrics metrics, HystrixCircuitBreaker circuitBreaker, HystrixCommandProperties properties) {
        return SINGLETON.getPublisherForCommand(commandKey, commandOwner, metrics, circuitBreaker, properties);
    }"
"protected Url convertProviderToUrl(ClientTransportConfig transportConfig, ProviderInfo providerInfo) {
        // Url的第一个参数，如果不用事件的话，其实无所谓
        Url boltUrl = new Url(providerInfo.toString(), providerInfo.getHost(), providerInfo.getPort());

        boltUrl.setConnectTimeout(transportConfig.getConnectTimeout());
        // 默认初始化connNum个长连接,为了slb和vip的情况
        final int connectionNum = transportConfig.getConnectionNum();
        if (connectionNum > 0) {
            boltUrl.setConnNum(connectionNum);
        } else {
            boltUrl.setConnNum(1);
        }
        boltUrl.setConnWarmup(false); // true的话
        if (RpcConstants.PROTOCOL_TYPE_BOLT.equals(providerInfo.getProtocolType())) {
            boltUrl.setProtocol(RemotingConstants.PROTOCOL_BOLT);
        } else {
            boltUrl.setProtocol(RemotingConstants.PROTOCOL_TR);
        }
        return boltUrl;
    }"
"protected Throwable decomposeException(Exception e) {
        if (e instanceof IllegalStateException) {
            return (IllegalStateException) e;
        }
        if (e instanceof HystrixBadRequestException) {
            if (shouldNotBeWrapped(e.getCause())) {
                return e.getCause();
            }
            return (HystrixBadRequestException) e;
        }
        if (e.getCause() instanceof HystrixBadRequestException) {
            if(shouldNotBeWrapped(e.getCause().getCause())) {
                return e.getCause().getCause();
            }
            return (HystrixBadRequestException) e.getCause();
        }
        if (e instanceof HystrixRuntimeException) {
            return (HystrixRuntimeException) e;
        }
        // if we have an exception we know about we'll throw it directly without the wrapper exception
        if (e.getCause() instanceof HystrixRuntimeException) {
            return (HystrixRuntimeException) e.getCause();
        }
        if (shouldNotBeWrapped(e)) {
            return e;
        }
        if (shouldNotBeWrapped(e.getCause())) {
            return e.getCause();
        }
        // we don't know what kind of exception this is so create a generic message and throw a new HystrixRuntimeException
        String message = getLogMessagePrefix() + "" failed while executing."";
        logger.debug(message, e); // debug only since we're throwing the exception and someone higher will do something with it
        return new HystrixRuntimeException(FailureType.COMMAND_EXCEPTION, this.getClass(), message, e, null);

    }"
"protected Map<K, Expirable<V>> getAndFilterExpiredEntries(
      Set<? extends K> keys, boolean updateAccessTime) {
    Map<K, Expirable<V>> result = new HashMap<>(cache.getAllPresent(keys));

    int[] expired = { 0 };
    long[] millis = { 0L };
    result.entrySet().removeIf(entry -> {
      if (!entry.getValue().isEternal() && (millis[0] == 0L)) {
        millis[0] = currentTimeMillis();
      }
      if (entry.getValue().hasExpired(millis[0])) {
        cache.asMap().computeIfPresent(entry.getKey(), (k, expirable) -> {
          if (expirable == entry.getValue()) {
            dispatcher.publishExpired(this, entry.getKey(), entry.getValue().get());
            expired[0]++;
            return null;
          }
          return expirable;
        });
        return true;
      }
      if (updateAccessTime) {
        setAccessExpirationTime(entry.getValue(), millis[0]);
      }
      return false;
    });

    statistics.recordHits(result.size());
    statistics.recordMisses(keys.size() - result.size());
    statistics.recordEvictions(expired[0]);
    return result;
  }"
"private void executeReactor(final InitStrategy is, TaskBuilder... builders) throws IOException, InterruptedException, ReactorException {
        Reactor reactor = new Reactor(builders) {
            /**
             * Sets the thread name to the task for better diagnostics.
             */
            @Override
            protected void runTask(Task task) throws Exception {
                if (is!=null && is.skipInitTask(task))  return;

                ACL.impersonate(ACL.SYSTEM); // full access in the initialization thread
                String taskName = InitReactorRunner.getDisplayName(task);

                Thread t = Thread.currentThread();
                String name = t.getName();
                if (taskName !=null)
                    t.setName(taskName);
                try {
                    long start = System.currentTimeMillis();
                    super.runTask(task);
                    if(LOG_STARTUP_PERFORMANCE)
                        LOGGER.info(String.format(""Took %dms for %s by %s"",
                                System.currentTimeMillis()-start, taskName, name));
                } catch (Exception | Error x) {
                    if (containsLinkageError(x)) {
                        LOGGER.log(Level.WARNING, taskName + "" failed perhaps due to plugin dependency issues"", x);
                    } else {
                        throw x;
                    }
                } finally {
                    t.setName(name);
                    SecurityContextHolder.clearContext();
                }
            }
            private boolean containsLinkageError(Throwable x) {
                if (x instanceof LinkageError) {
                    return true;
                }
                Throwable x2 = x.getCause();
                return x2 != null && containsLinkageError(x2);
            }
        };

        new InitReactorRunner() {
            @Override
            protected void onInitMilestoneAttained(InitMilestone milestone) {
                initLevel = milestone;
                if (milestone==PLUGINS_PREPARED) {
                    // set up Guice to enable injection as early as possible
                    // before this milestone, ExtensionList.ensureLoaded() won't actually try to locate instances
                    ExtensionList.lookup(ExtensionFinder.class).getComponents();
                }
            }
        }.run(reactor);
    }"
"public static ProtocolNegotiator serverPlaintext() {
    return new ProtocolNegotiator() {
      @Override
      public ChannelHandler newHandler(final GrpcHttp2ConnectionHandler handler) {
        class PlaintextHandler extends ChannelHandlerAdapter {
          @Override
          public void handlerAdded(ChannelHandlerContext ctx) throws Exception {
            // Set sttributes before replace to be sure we pass it before accepting any requests.
            handler.handleProtocolNegotiationCompleted(Attributes.newBuilder()
                .set(Grpc.TRANSPORT_ATTR_REMOTE_ADDR, ctx.channel().remoteAddress())
                .set(Grpc.TRANSPORT_ATTR_LOCAL_ADDR, ctx.channel().localAddress())
                .build(),
                /*securityInfo=*/ null);
            // Just replace this handler with the gRPC handler.
            ctx.pipeline().replace(this, null, handler);
          }
        }

        return new PlaintextHandler();
      }

      @Override
      public void close() {}

      @Override
      public AsciiString scheme() {
        return Utils.HTTP;
      }
    };
  }"
"@Override
    public void fit(@NonNull MultiDataSetIterator iterator) {
        Map<Integer, NormalizerStats.Builder> inputStatsBuilders = new HashMap<>();
        Map<Integer, NormalizerStats.Builder> outputStatsBuilders = new HashMap<>();

        iterator.reset();
        while (iterator.hasNext()) {
            fitPartial(iterator.next(), inputStatsBuilders, outputStatsBuilders);
        }

        inputStats = buildAllStats(inputStatsBuilders);
        outputStats = buildAllStats(outputStatsBuilders);
    }"
"private List<SiteNode> getChildren(SiteNode siteNode) {
		int childCount = siteNode.getChildCount();
		if (childCount == 0) {
			return Collections.emptyList();
		}

		List<SiteNode> children = new ArrayList<>(childCount);
		for (int i = 0; i < childCount; i++) {
			children.add((SiteNode) siteNode.getChildAt(i));
		}
		return children;
	}"
"public static void slowLog(Logger logger, String key, long duration, long threshold, String context) {
		if (duration > threshold) {
			logger.warn(""[Performance Warning] task {} use {}ms, slow than {}ms, contxt={}"", key, duration, threshold,
					context);
		}
	}"
"public boolean isValidInet4Address(String inet4Address) {
        // verify that address conforms to generic IPv4 format
        String[] groups = ipv4Validator.match(inet4Address);

        if (groups == null) {
            return false;
        }

        // verify that address subgroups are legal
        for (String ipSegment : groups) {
            if (ipSegment == null || ipSegment.length() == 0) {
                return false;
            }

            int iIpSegment = 0;

            try {
                iIpSegment = Integer.parseInt(ipSegment);
            } catch(NumberFormatException e) {
                return false;
            }

            if (iIpSegment > IPV4_MAX_OCTET_VALUE) {
                return false;
            }

            if (ipSegment.length() > 1 && ipSegment.startsWith(""0"")) {
                return false;
            }

        }

        return true;
    }"
"@Inject
    public void setHub(IOHubProvider hub) {
        this.hub = hub;
        handler = new JnlpProtocol4Handler(JnlpAgentReceiver.DATABASE, Computer.threadPoolForRemoting, hub.getHub(),
                sslContext, false, true);
    }"
"public Collection<String> nearestLabels(@NonNull String rawText, int topN) {
        List<String> tokens = tokenizerFactory.create(rawText).getTokens();
        List<VocabWord> document = new ArrayList<>();
        for (String token : tokens) {
            if (vocab.containsWord(token)) {
                document.add(vocab.wordFor(token));
            }
        }

        // we're returning empty collection for empty document
        if (document.isEmpty()) {
            log.info(""Document passed to nearestLabels() has no matches in model vocabulary"");
            return new ArrayList<>();
        }

        return nearestLabels(document, topN);
    }"
"public String setStr(String key, String value) {
		try (Jedis jedis = getJedis()) {
			return jedis.set(key, value);
		}
	}"
"public ClasspathBuilder addAll(FilePath base, String glob) throws IOException, InterruptedException {
        for(FilePath item : base.list(glob))
            add(item);
        return this;
    }

    /**
     * Returns the string representation of the classpath.
     */
    @Override
    public String toString() {
        return Util.join(args,File.pathSeparator);
    }
}"
"public void copyStateTo(HikariConfig other)
   {
      for (Field field : HikariConfig.class.getDeclaredFields()) {
         if (!Modifier.isFinal(field.getModifiers())) {
            field.setAccessible(true);
            try {
               field.set(other, field.get(this));
            }
            catch (Exception e) {
               throw new RuntimeException(""Failed to copy HikariConfig state: "" + e.getMessage(), e);
            }
         }
      }

      other.sealed = false;
   }"
"private void addConstructorByKey() {
    context.constructorByKey = MethodSpec.constructorBuilder().addParameter(keySpec);
    context.constructorByKey.addParameter(keyRefQueueSpec);
    addCommonParameters(context.constructorByKey);
    if (isBaseClass()) {
      callSiblingConstructor();
    } else {
      callParentByKey();
    }
  }"
"public void setPaths(@Nonnull List<Path> paths) {
        ArgumentUtils.requireNonNull(""paths"", paths);
        this.paths = paths;
    }"
"private JScrollPane getJScrollPane() {
		if (jScrollPane == null) {
			jScrollPane = new JScrollPane();
			jScrollPane.setViewportView(getTxtOutput());
			jScrollPane.setName(""jScrollPane"");
			jScrollPane.setHorizontalScrollBarPolicy(javax.swing.JScrollPane.HORIZONTAL_SCROLLBAR_NEVER);
		}
		return jScrollPane;
	}"
"@Override
    public INDArray compress(float[] data, int[] shape, char order) {
        FloatPointer pointer = new FloatPointer(data);

        DataBuffer shapeInfo = Nd4j.getShapeInfoProvider().createShapeInformation(ArrayUtil.toLongArray(shape), order, DataType.FLOAT).getFirst();
        DataBuffer buffer = compressPointer(DataTypeEx.FLOAT, pointer, data.length, 4);

        return Nd4j.createArrayFromShapeBuffer(buffer, shapeInfo);
    }"
"static Key getKey(boolean isLeft, int col, H2ONode node) {
    return Key.make(""__radix_order__MSBNodeCounts_col"" + col + ""_node"" + node.index() + (isLeft ? ""_LEFT"" : ""_RIGHT""));
    // Each node's contents is different so the node number needs to be in the key
    // TODO: need the biggestBit in here too, that the MSB is offset from
  }"
"@Override
  public boolean hasNext() {
    for (int i = 0; i < _events.length; ++i)
      if (_events[i] != null && (!_events[i].isEmpty() || _events[i].next())) {
        assert (_events[i] == null)
          || ((_events[i]._eventIdx < TimeLine.MAX_EVENTS) && !_events[i].isEmpty());
        return true;
      } else {
        assert (_events[i] == null)
          || ((_events[i]._eventIdx < TimeLine.MAX_EVENTS) && !_events[i].isEmpty());
        _events[i] = null;
      }
    return false;
  }"
"public static CircleCaptcha createCircleCaptcha(int width, int height, int codeCount, int circleCount) {
		return new CircleCaptcha(width, height, codeCount, circleCount);
	}"
"public boolean optBoolean(int index, boolean fallback) {
		Object object = opt(index);
		Boolean result = JSON.toBoolean(object);
		return result != null ? result : fallback;
	}"
"public Actions clickAndHold(WebElement target) {
    if (isBuildingActions()) {
      action.addAction(new ClickAndHoldAction(jsonMouse, (Locatable) target));
    }
    return moveInTicks(target, 0, 0)
        .tick(defaultMouse.createPointerDown(LEFT.asArg()));
  }"
"@Override
    protected void parse() {
        maximumInstances = getInt(PARAM_MAXIMUM_INSTANCES, DEFAULT_MAXIMUM_INSTANCES);
        mergeRelatedIssues = getBoolean(PARAM_MERGE_RELATED_ISSUES, true);
        overridesFilename = getString(PARAM_OVERRIDES_FILENAME, """");
    }"
"private static String getCharacter(Table table, int code) {
    switch (table) {
      case UPPER:
        return UPPER_TABLE[code];
      case LOWER:
        return LOWER_TABLE[code];
      case MIXED:
        return MIXED_TABLE[code];
      case PUNCT:
        return PUNCT_TABLE[code];
      case DIGIT:
        return DIGIT_TABLE[code];
      default:
        // Should not reach here.
        throw new IllegalStateException(""Bad table"");
    }
  }"
"public static Bitmap renderPath(Path path) {
    RectF bounds = new RectF();
    path.computeBounds(bounds, false);
    Bitmap bitmap = Bitmap.createBitmap((int) bounds.right, (int) bounds.bottom, Bitmap.Config.ARGB_8888);
    Canvas canvas = new Canvas(bitmap);
    Paint paint = new LPaint();
    paint.setAntiAlias(true);
    paint.setColor(Color.BLUE);
    canvas.drawPath(path, paint);
    return bitmap;
  }"
"public BytecodeNode generateCall(
            String name,
            ScalarFunctionImplementation function,
            List<BytecodeNode> arguments,
            Optional<OutputBlockVariableAndType> outputBlockVariableAndType)
    {
        Optional<BytecodeNode> instance = Optional.empty();
        if (function.getInstanceFactory().isPresent()) {
            FieldDefinition field = cachedInstanceBinder.getCachedInstance(function.getInstanceFactory().get());
            instance = Optional.of(scope.getThis().getField(field));
        }
        return generateInvocation(scope, name, function, instance, arguments, callSiteBinder, outputBlockVariableAndType);
    }"
"public AggregateOperator<T> min (int field) {
		return this.aggregate (Aggregations.MIN, field, Utils.getCallLocationName());
	}"
"public void scan(HttpMessage msg, NameValuePair originalParam) {
        scan(msg, originalParam.getName(), originalParam.getValue());
    }"
"@Override
  public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise)
      throws Exception {
    if (msg instanceof SendGrpcFrameCommand) {
      sendGrpcFrame(ctx, (SendGrpcFrameCommand) msg, promise);
    } else if (msg instanceof SendResponseHeadersCommand) {
      sendResponseHeaders(ctx, (SendResponseHeadersCommand) msg, promise);
    } else if (msg instanceof CancelServerStreamCommand) {
      cancelStream(ctx, (CancelServerStreamCommand) msg, promise);
    } else if (msg instanceof ForcefulCloseCommand) {
      forcefulClose(ctx, (ForcefulCloseCommand) msg, promise);
    } else {
      AssertionError e =
          new AssertionError(""Write called for unexpected type: "" + msg.getClass().getName());
      ReferenceCountUtil.release(msg);
      promise.setFailure(e);
      throw e;
    }
  }"
"public void setCosts(Costs nodeCosts) {
		// set the node costs
		this.nodeCosts = nodeCosts;
		
		// the cumulative costs are the node costs plus the costs of all inputs
		this.cumulativeCosts = nodeCosts.clone();
		
		// add all the normal inputs
		for (PlanNode pred : getPredecessors()) {
			
			Costs parentCosts = pred.getCumulativeCostsShare();
			if (parentCosts != null) {
				this.cumulativeCosts.addCosts(parentCosts);
			} else {
				throw new CompilerException(""Trying to set the costs of an operator before the predecessor costs are computed."");
			}
		}
		
		// add all broadcast variable inputs
		if (this.broadcastInputs != null) {
			for (NamedChannel nc : this.broadcastInputs) {
				Costs bcInputCost = nc.getSource().getCumulativeCostsShare();
				if (bcInputCost != null) {
					this.cumulativeCosts.addCosts(bcInputCost);
				} else {
					throw new CompilerException(""Trying to set the costs of an operator before the broadcast input costs are computed."");
				}
			}
		}
	}"
"public void setParseSitemapXml(boolean parseSitemapXml) {
		this.parseSitemapXml = parseSitemapXml;
		getConfig().setProperty(SPIDER_PARSE_SITEMAP_XML, Boolean.toString(parseSitemapXml));
	}"
"public <U> BindResult<U> map(Function<? super T, ? extends U> mapper) {
		Assert.notNull(mapper, ""Mapper must not be null"");
		return of((this.value != null) ? mapper.apply(this.value) : null);
	}"
"public static void writePng(Image image, OutputStream out) throws IORuntimeException {
		write(image, IMAGE_TYPE_PNG, out);
	}"
"void resolvePluginDependencies() throws IOException {
        if (ENABLE_PLUGIN_DEPENDENCIES_VERSION_CHECK) {
            String requiredCoreVersion = getRequiredCoreVersion();
            if (requiredCoreVersion == null) {
                LOGGER.warning(shortName + "" doesn't declare required core version."");
            } else {
                VersionNumber actualVersion = Jenkins.getVersion();
                if (actualVersion.isOlderThan(new VersionNumber(requiredCoreVersion))) {
                    versionDependencyError(Messages.PluginWrapper_obsoleteCore(Jenkins.getVersion().toString(), requiredCoreVersion), Jenkins.getVersion().toString(), requiredCoreVersion);
                }
            }

            String minimumJavaVersion = getMinimumJavaVersion();
            if (minimumJavaVersion != null) {
                JavaSpecificationVersion actualVersion = JavaUtils.getCurrentJavaRuntimeVersionNumber();
                if (actualVersion.isOlderThan(new JavaSpecificationVersion(minimumJavaVersion))) {
                    versionDependencyError(Messages.PluginWrapper_obsoleteJava(actualVersion.toString(), minimumJavaVersion), actualVersion.toString(), minimumJavaVersion);
                }
            }
        }
        // make sure dependencies exist
        for (Dependency d : dependencies) {
            PluginWrapper dependency = parent.getPlugin(d.shortName);
            if (dependency == null) {
                PluginWrapper failedDependency = NOTICE.getPlugin(d.shortName);
                if (failedDependency != null) {
                    dependencyErrors.put(Messages.PluginWrapper_failed_to_load_dependency(failedDependency.getLongName(), failedDependency.getVersion()), true);
                    break;
                } else {
                    dependencyErrors.put(Messages.PluginWrapper_missing(d.shortName, d.version), false);
                }
            } else {
                if (dependency.isActive()) {
                    if (isDependencyObsolete(d, dependency)) {
                        versionDependencyError(Messages.PluginWrapper_obsolete(dependency.getLongName(), dependency.getVersion(), d.version), dependency.getVersion(), d.version);
                    }
                } else {
                    if (isDependencyObsolete(d, dependency)) {
                        versionDependencyError(Messages.PluginWrapper_disabledAndObsolete(dependency.getLongName(), dependency.getVersion(), d.version), dependency.getVersion(), d.version);
                    } else {
                        dependencyErrors.put(Messages.PluginWrapper_disabled(dependency.getLongName()), false);
                    }
                }

            }
        }
        // add the optional dependencies that exists
        for (Dependency d : optionalDependencies) {
            PluginWrapper dependency = parent.getPlugin(d.shortName);
            if (dependency != null && dependency.isActive()) {
                if (isDependencyObsolete(d, dependency)) {
                    versionDependencyError(Messages.PluginWrapper_obsolete(dependency.getLongName(), dependency.getVersion(), d.version), dependency.getVersion(), d.version);
                } else {
                    dependencies.add(d);
                }
            }
        }
        if (!dependencyErrors.isEmpty()) {
            NOTICE.addPlugin(this);
            StringBuilder messageBuilder = new StringBuilder();
            messageBuilder.append(Messages.PluginWrapper_failed_to_load_plugin(getLongName(), getVersion())).append(System.lineSeparator());
            for (Iterator<String> iterator = dependencyErrors.keySet().iterator(); iterator.hasNext(); ) {
                String dependencyError = iterator.next();
                messageBuilder.append("" - "").append(dependencyError);
                if (iterator.hasNext()) {
                    messageBuilder.append(System.lineSeparator());
                }
            }
            throw new IOException(messageBuilder.toString());
        }
    }"
"@Restricted(NoExternalUse.class) // TODO pending ApI
    public Cipher decrypt(byte[] iv) {
        try {
            Cipher cipher = Secret.getCipher(ALGORITHM);
            cipher.init(Cipher.DECRYPT_MODE, getKey(), new IvParameterSpec(iv));
            return cipher;
        } catch (GeneralSecurityException e) {
            throw new AssertionError(e);
        }
    }"
"public byte getByte(String key) {
		addToDefaults(key, null);
		String value = getRequired(key);
		return Byte.valueOf(value);
	}"
"@SneakyThrows
    public static <R> Supplier<R> doIf(final boolean condition, final Supplier<R> trueFunction,
                                       final Supplier<R> falseFunction) {
        return () -> {
            try {
                if (condition) {
                    return trueFunction.get();
                }
                return falseFunction.get();
            } catch (final Throwable e) {
                LOGGER.warn(e.getMessage(), e);
                return falseFunction.get();
            }
        };
    }"
"public static String getPackage(Class<?> clazz) {
		if (clazz == null) {
			return StrUtil.EMPTY;
		}
		final String className = clazz.getName();
		int packageEndIndex = className.lastIndexOf(StrUtil.DOT);
		if (packageEndIndex == -1) {
			return StrUtil.EMPTY;
		}
		return className.substring(0, packageEndIndex);
	}"
"private HiveConf getConfigForOperation() throws HiveSQLException {
    HiveConf sqlOperationConf = getParentSession().getHiveConf();
    if (!getConfOverlay().isEmpty() || shouldRunAsync()) {
      // clone the parent session config for this query
      sqlOperationConf = new HiveConf(sqlOperationConf);

      // apply overlay query specific settings, if any
      for (Map.Entry<String, String> confEntry : getConfOverlay().entrySet()) {
        try {
          sqlOperationConf.verifyAndSet(confEntry.getKey(), confEntry.getValue());
        } catch (IllegalArgumentException e) {
          throw new HiveSQLException(""Error applying statement specific settings"", e);
        }
      }
    }
    return sqlOperationConf;
  }"
"public static int getDimension(INDArray arr, boolean defaultRows) {
        // FIXME: int cast

        //ignore ordering for vectors
        if (arr.isVector()) {
            return defaultRows ? (int) arr.rows() : (int) arr.columns();
        }
        if (arr.ordering() == NDArrayFactory.C)
            return defaultRows ? (int) arr.columns() : (int) arr.rows();
        return defaultRows ? (int) arr.rows() : (int) arr.columns();
    }"
"public <T extends IEvaluation> Map<Integer, T[]> evaluate(DataSetIterator iterator, Map<Integer,T[]> evaluations){
        return evaluate(new MultiDataSetIteratorAdapter(iterator), evaluations);
    }"
"@SuppressWarnings(""unchecked"")
	public Iterable<Edge<K, EV>> getEdges() {
		if (edgesUsed) {
			throw new IllegalStateException(""Can use either 'getEdges()' or 'sendMessageToAllNeighbors()' exactly once."");
		}
		edgesUsed = true;
		this.edgeIterator.set((Iterator<Edge<K, EV>>) edges);
		return this.edgeIterator;
	}"
"public CompletableFuture<Collection<JobStatusMessage>> listJobs() {
		return runDispatcherCommand(dispatcherGateway ->
			dispatcherGateway
				.requestMultipleJobDetails(rpcTimeout)
				.thenApply(jobs ->
					jobs.getJobs().stream()
						.map(details -> new JobStatusMessage(details.getJobId(), details.getJobName(), details.getStatus(), details.getStartTime()))
						.collect(Collectors.toList())));
	}"
"private Optional<PlanNode> recurseToPartial(PlanNode node, Lookup lookup, PlanNodeIdAllocator idAllocator)
    {
        if (node instanceof AggregationNode && ((AggregationNode) node).getStep() == PARTIAL) {
            return Optional.of(addGatheringIntermediate((AggregationNode) node, idAllocator));
        }

        if (!(node instanceof ExchangeNode) && !(node instanceof ProjectNode)) {
            return Optional.empty();
        }

        ImmutableList.Builder<PlanNode> builder = ImmutableList.builder();
        for (PlanNode source : node.getSources()) {
            Optional<PlanNode> planNode = recurseToPartial(lookup.resolve(source), lookup, idAllocator);
            if (!planNode.isPresent()) {
                return Optional.empty();
            }
            builder.add(planNode.get());
        }
        return Optional.of(node.replaceChildren(builder.build()));
    }"
"public final void parse() {
        Collection<Keyword> unsupportedRestKeywords = new LinkedList<>();
        unsupportedRestKeywords.addAll(Arrays.asList(DefaultKeyword.UNION, DefaultKeyword.INTERSECT, DefaultKeyword.EXCEPT, DefaultKeyword.MINUS));
        unsupportedRestKeywords.addAll(Arrays.asList(getUnsupportedKeywordsRest()));
        lexerEngine.unsupportedIfEqual(unsupportedRestKeywords.toArray(new Keyword[unsupportedRestKeywords.size()]));
    }"
"public NodeId put(
		final String stateName,
		final EventId eventId,
		@Nullable final NodeId previousNodeId,
		final DeweyNumber version) {

		if (previousNodeId != null) {
			lockNode(previousNodeId);
		}

		NodeId currentNodeId = new NodeId(eventId, getOriginalNameFromInternal(stateName));
		Lockable<SharedBufferNode> currentNode = sharedBuffer.getEntry(currentNodeId);
		if (currentNode == null) {
			currentNode = new Lockable<>(new SharedBufferNode(), 0);
			lockEvent(eventId);
		}

		currentNode.getElement().addEdge(new SharedBufferEdge(
			previousNodeId,
			version));
		sharedBuffer.upsertEntry(currentNodeId, currentNode);

		return currentNodeId;
	}"
"private boolean expandSelectItem(
		final SqlNode selectItem,
		SqlSelect select,
		RelDataType targetType,
		List<SqlNode> selectItems,
		Set<String> aliases,
		List<Map.Entry<String, RelDataType>> fields,
		final boolean includeSystemVars) {
		final SelectScope scope = (SelectScope) getWhereScope(select);
		if (expandStar(selectItems, aliases, fields, includeSystemVars, scope,
			selectItem)) {
			return true;
		}

		// Expand the select item: fully-qualify columns, and convert
		// parentheses-free functions such as LOCALTIME into explicit function
		// calls.
		SqlNode expanded = expand(selectItem, scope);
		final String alias =
			deriveAlias(
				selectItem,
				aliases.size());

		// If expansion has altered the natural alias, supply an explicit 'AS'.
		final SqlValidatorScope selectScope = getSelectScope(select);
		if (expanded != selectItem) {
			String newAlias =
				deriveAlias(
					expanded,
					aliases.size());
			if (!newAlias.equals(alias)) {
				expanded =
					SqlStdOperatorTable.AS.createCall(
						selectItem.getParserPosition(),
						expanded,
						new SqlIdentifier(alias, SqlParserPos.ZERO));
				deriveTypeImpl(selectScope, expanded);
			}
		}

		selectItems.add(expanded);
		aliases.add(alias);

		if (expanded != null) {
			inferUnknownTypes(targetType, scope, expanded);
		}
		final RelDataType type = deriveType(selectScope, expanded);
		setValidatedNodeType(expanded, type);
		fields.add(Pair.of(alias, type));
		return false;
	}"
"public static Optional<MultifactorAuthenticationProvider> resolveProvider(final Map<String, MultifactorAuthenticationProvider> providers,
                                                                              final String requestMfaMethod) {
        return resolveProvider(providers, Stream.of(requestMfaMethod).collect(Collectors.toList()));
    }"
"static boolean loadDat(String path)
    {
        try
        {
            ByteArray byteArray = ByteArray.createByteArray(path + Predefine.BIN_EXT);
            if (byteArray == null) return false;
            int size = byteArray.nextInt();
            CoreDictionary.Attribute[] attributes = new CoreDictionary.Attribute[size];
            final Nature[] natureIndexArray = Nature.values();
            for (int i = 0; i < size; ++i)
            {
                // 第一个是全部频次，第二个是词性个数
                int currentTotalFrequency = byteArray.nextInt();
                int length = byteArray.nextInt();
                attributes[i] = new CoreDictionary.Attribute(length);
                attributes[i].totalFrequency = currentTotalFrequency;
                for (int j = 0; j < length; ++j)
                {
                    attributes[i].nature[j] = natureIndexArray[byteArray.nextInt()];
                    attributes[i].frequency[j] = byteArray.nextInt();
                }
            }
            if (!trie.load(byteArray, attributes) || byteArray.hasMore()) return false;
        }
        catch (Exception e)
        {
            logger.warning(""读取失败，问题发生在"" + e);
            return false;
        }
        return true;
    }"
"public RestTemplateBuilder setReadTimeout(Duration readTimeout) {
		return new RestTemplateBuilder(this.detectRequestFactory, this.rootUri,
				this.messageConverters, this.requestFactorySupplier,
				this.uriTemplateHandler, this.errorHandler, this.basicAuthentication,
				this.restTemplateCustomizers,
				this.requestFactoryCustomizer.readTimeout(readTimeout),
				this.interceptors);
	}"
"@Override
    public boolean containsKey(Object key) {
        if (key == null) {
            throw new NullPointerException();
        }
        
        CachedValue<K, V> entry = map.get(key);
        if (entry == null) {
            return false;
        }
        if (isValueExpired(entry)) {
            if (map.remove(key, entry)) {
                onValueRemove(entry);
                return false;
            }
            return containsKey(key);
        }
        return true;
    }"
"public OutputStream decorateLogger(AbstractBuild build, OutputStream logger) throws IOException, InterruptedException, RunnerAbortedException {
        return logger;
    }"
"public static boolean isReachable(String processDefinitionId, String sourceElementId, String targetElementId) {

    // Fetch source and target elements
    Process process = ProcessDefinitionUtil.getProcess(processDefinitionId);

    FlowElement sourceFlowElement = process.getFlowElement(sourceElementId, true);
    FlowNode sourceElement = null;
    if (sourceFlowElement instanceof FlowNode) {
      sourceElement = (FlowNode) sourceFlowElement;
    } else if (sourceFlowElement instanceof SequenceFlow) {
      sourceElement = (FlowNode) ((SequenceFlow) sourceFlowElement).getTargetFlowElement();
    }

    FlowElement targetFlowElement = process.getFlowElement(targetElementId, true);
    FlowNode targetElement = null;
    if (targetFlowElement instanceof FlowNode) {
      targetElement = (FlowNode) targetFlowElement;
    } else if (targetFlowElement instanceof SequenceFlow) {
      targetElement = (FlowNode) ((SequenceFlow) targetFlowElement).getTargetFlowElement();
    }

    if (sourceElement == null) {
      throw new ActivitiException(""Invalid sourceElementId '"" + sourceElementId + ""': no element found for this id n process definition '"" + processDefinitionId + ""'"");
    }
    if (targetElement == null) {
      throw new ActivitiException(""Invalid targetElementId '"" + targetElementId + ""': no element found for this id n process definition '"" + processDefinitionId + ""'"");
    }

    Set<String> visitedElements = new HashSet<String>();
    return isReachable(process, sourceElement, targetElement, visitedElements);
  }"
"public static long copy(ReadableByteChannel in, WritableByteChannel out) throws IORuntimeException {
		return copy(in, out, DEFAULT_BUFFER_SIZE);
	}"
"@Deprecated
    public String readLine() throws IOException, IllegalStateException {
        LOG.trace(""enter HttpConnection.readLine()"");

        assertOpen();
        return HttpParser.readLine(inputStream);
    }"
"public boolean conflictsWith(OptionalBoolean other) {
		return state == State.CONFLICTING
			|| other.state == State.CONFLICTING
			|| (state == State.TRUE && other.state == State.FALSE)
			|| (state == State.FALSE && other.state == State.TRUE);
	}"
"public static TaskExecutor startTaskManager(
			Configuration configuration,
			ResourceID resourceID,
			RpcService rpcService,
			HighAvailabilityServices highAvailabilityServices,
			HeartbeatServices heartbeatServices,
			MetricRegistry metricRegistry,
			BlobCacheService blobCacheService,
			boolean localCommunicationOnly,
			FatalErrorHandler fatalErrorHandler) throws Exception {

		checkNotNull(configuration);
		checkNotNull(resourceID);
		checkNotNull(rpcService);
		checkNotNull(highAvailabilityServices);

		LOG.info(""Starting TaskManager with ResourceID: {}"", resourceID);

		InetAddress remoteAddress = InetAddress.getByName(rpcService.getAddress());

		TaskManagerServicesConfiguration taskManagerServicesConfiguration =
			TaskManagerServicesConfiguration.fromConfiguration(
				configuration,
				EnvironmentInformation.getMaxJvmHeapMemory(),
				remoteAddress,
				localCommunicationOnly);

		TaskManagerMetricGroup taskManagerMetricGroup = MetricUtils.instantiateTaskManagerMetricGroup(
			metricRegistry,
			TaskManagerLocation.getHostName(remoteAddress),
			resourceID,
			taskManagerServicesConfiguration.getSystemResourceMetricsProbingInterval());

		TaskManagerServices taskManagerServices = TaskManagerServices.fromConfiguration(
			taskManagerServicesConfiguration,
			taskManagerMetricGroup,
			resourceID,
			rpcService.getExecutor(), // TODO replace this later with some dedicated executor for io.
			EnvironmentInformation.getSizeOfFreeHeapMemoryWithDefrag(),
			EnvironmentInformation.getMaxJvmHeapMemory());

		TaskManagerConfiguration taskManagerConfiguration = TaskManagerConfiguration.fromConfiguration(configuration);

		String metricQueryServiceAddress = metricRegistry.getMetricQueryServiceGatewayRpcAddress();

		return new TaskExecutor(
			rpcService,
			taskManagerConfiguration,
			highAvailabilityServices,
			taskManagerServices,
			heartbeatServices,
			taskManagerMetricGroup,
			metricQueryServiceAddress,
			blobCacheService,
			fatalErrorHandler);
	}"
"@SuppressWarnings(""unused"") // called through reflection by RequestServer
  public MetadataV3 listSchemas(int version, MetadataV3 docs) {
    Map<String, Class<? extends Schema>> ss = SchemaServer.schemas();
    docs.schemas = new SchemaMetadataV3[ss.size()];

    // NOTE: this will throw an exception if the classname isn't found:
    int i = 0;
    for (Class<? extends Schema> schema_class : ss.values()) {
      // No hardwired version! YAY!  FINALLY!

      Schema schema = Schema.newInstance(schema_class);
      // get defaults
      try {
        Iced impl = (Iced) schema.getImplClass().newInstance();
        schema.fillFromImpl(impl);
      }
      catch (Exception e) {
        // ignore if create fails; this can happen for abstract classes
      }

      docs.schemas[i++] = new SchemaMetadataV3(new SchemaMetadata(schema));
    }
    return docs;
  }"
"private void restoreKVStateMetaData() throws IOException, StateMigrationException {
		KeyedBackendSerializationProxy<K> serializationProxy = readMetaData(currentStateHandleInView);

		this.keygroupStreamCompressionDecorator = serializationProxy.isUsingKeyGroupCompression() ?
			SnappyStreamCompressionDecorator.INSTANCE : UncompressedStreamCompressionDecorator.INSTANCE;

		List<StateMetaInfoSnapshot> restoredMetaInfos =
			serializationProxy.getStateMetaInfoSnapshots();
		currentStateHandleKVStateColumnFamilies = new ArrayList<>(restoredMetaInfos.size());

		for (StateMetaInfoSnapshot restoredMetaInfo : restoredMetaInfos) {
			RocksDbKvStateInfo registeredStateCFHandle =
				getOrRegisterStateColumnFamilyHandle(null, restoredMetaInfo);
			currentStateHandleKVStateColumnFamilies.add(registeredStateCFHandle.columnFamilyHandle);
		}
	}"
"public TabbedPanel2 getTabbedWork() {
		if (tabbedWork == null) {
			tabbedWork = new TabbedPanel2();
			tabbedWork.setPreferredSize(new Dimension(600, 400));
			tabbedWork.setName(""tabbedWork"");
			tabbedWork.setBorder(BorderFactory.createEmptyBorder(0, 0, 0, 0));
		}
		return tabbedWork;
	}"
"void stopAfter(int remainingScans) {
		Thread thread;
		synchronized (this.monitor) {
			thread = this.watchThread;
			if (thread != null) {
				this.remainingScans.set(remainingScans);
				if (remainingScans <= 0) {
					thread.interrupt();
				}
			}
			this.watchThread = null;
		}
		if (thread != null && Thread.currentThread() != thread) {
			try {
				thread.join();
			}
			catch (InterruptedException ex) {
				Thread.currentThread().interrupt();
			}
		}
	}"
"public Schema handle(int version, Route route, Properties parms, String post_body) throws Exception {
    Class<? extends Schema> handler_schema_class = getHandlerMethodInputSchema(route._handler_method);
    Schema schema = Schema.newInstance(handler_schema_class);

    // If the schema has a real backing class fill from it to get the default field values:
    Class<? extends Iced> iced_class = schema.getImplClass();
    if (iced_class != Iced.class) {
      Iced defaults = schema.createImpl();
      schema.fillFromImpl(defaults);
    }

    boolean has_body = (null != post_body);

    // Fill from http request params:
    schema = schema.fillFromParms(parms, !has_body);
    if (schema == null)
      throw H2O.fail(""fillFromParms returned a null schema for version: "" + version + "" in: "" + this.getClass() + "" with params: "" + parms);

    //Fill from JSON body, if there is one.  NOTE: there should *either* be a JSON body *or* parms,
    //with the exception of control-type query parameters.
    if (has_body) {
      schema = schema.fillFromBody(post_body);
    }

    // NOTE! The handler method is free to modify the input schema and hand it back.
    Schema result = null;
    try {
      route._handler_method.setAccessible(true);
      result = (Schema)route._handler_method.invoke(this, version, schema);
    }
    // Exception thrown out of the invoked method turn into InvocationTargetException
    // rather uselessly.  Peel out the original exception & throw it.
    catch( InvocationTargetException ite ) {
      Throwable t = ite.getCause();
      if( t instanceof RuntimeException ) throw (RuntimeException)t;
      if( t instanceof Error ) throw (Error)t;
      throw new RuntimeException(t);
    }

    // Version-specific unwind from the Iced back into the Schema
    return result;
  }"
"public void initBatch(
      TypeDescription orcSchema,
      StructField[] requiredFields,
      int[] requestedDataColIds,
      int[] requestedPartitionColIds,
      InternalRow partitionValues) {
    wrap = new VectorizedRowBatchWrap(orcSchema.createRowBatch(capacity));
    assert(!wrap.batch().selectedInUse); // `selectedInUse` should be initialized with `false`.
    assert(requiredFields.length == requestedDataColIds.length);
    assert(requiredFields.length == requestedPartitionColIds.length);
    // If a required column is also partition column, use partition value and don't read from file.
    for (int i = 0; i < requiredFields.length; i++) {
      if (requestedPartitionColIds[i] != -1) {
        requestedDataColIds[i] = -1;
      }
    }
    this.requiredFields = requiredFields;
    this.requestedDataColIds = requestedDataColIds;

    StructType resultSchema = new StructType(requiredFields);

    // Just wrap the ORC column vector instead of copying it to Spark column vector.
    orcVectorWrappers = new org.apache.spark.sql.vectorized.ColumnVector[resultSchema.length()];

    for (int i = 0; i < requiredFields.length; i++) {
      DataType dt = requiredFields[i].dataType();
      if (requestedPartitionColIds[i] != -1) {
        OnHeapColumnVector partitionCol = new OnHeapColumnVector(capacity, dt);
        ColumnVectorUtils.populate(partitionCol, partitionValues, requestedPartitionColIds[i]);
        partitionCol.setIsConstant();
        orcVectorWrappers[i] = partitionCol;
      } else {
        int colId = requestedDataColIds[i];
        // Initialize the missing columns once.
        if (colId == -1) {
          OnHeapColumnVector missingCol = new OnHeapColumnVector(capacity, dt);
          missingCol.putNulls(0, capacity);
          missingCol.setIsConstant();
          orcVectorWrappers[i] = missingCol;
        } else {
          orcVectorWrappers[i] = new OrcColumnVector(dt, wrap.batch().cols[colId]);
        }
      }
    }

    columnarBatch = new ColumnarBatch(orcVectorWrappers);
  }"
"public static SearchExecutor newLdaptiveSearchExecutor(final String baseDn, final String filterQuery) {
        return newLdaptiveSearchExecutor(baseDn, filterQuery, new ArrayList<>(0));
    }"
"public void resetColumnLabel(final String schema) {
        Map<String, Integer> labelAndIndexMap = new HashMap<>(1, 1);
        labelAndIndexMap.put(schema, 1);
        resetLabelAndIndexMap(labelAndIndexMap);
    }"
"private static void visitOnCondition(SQLExpr expr, TableItem tableItem) {
        if (!(expr instanceof SQLBinaryOpExpr)) {
            throw new UnsupportedOperationException();
        }
        SQLBinaryOpExpr sqlBinaryOpExpr = (SQLBinaryOpExpr) expr;
        if (sqlBinaryOpExpr.getOperator() == BooleanAnd) {
            visitOnCondition(sqlBinaryOpExpr.getLeft(), tableItem);
            visitOnCondition(sqlBinaryOpExpr.getRight(), tableItem);
        } else if (sqlBinaryOpExpr.getOperator() == Equality) {
            FieldItem leftFieldItem = new FieldItem();
            visitColumn(sqlBinaryOpExpr.getLeft(), leftFieldItem);
            if (leftFieldItem.getColumnItems().size() != 1 || leftFieldItem.isMethod() || leftFieldItem.isBinaryOp()) {
                throw new UnsupportedOperationException(""Unsupported for complex of on-condition"");
            }
            FieldItem rightFieldItem = new FieldItem();
            visitColumn(sqlBinaryOpExpr.getRight(), rightFieldItem);
            if (rightFieldItem.getColumnItems().size() != 1 || rightFieldItem.isMethod()
                || rightFieldItem.isBinaryOp()) {
                throw new UnsupportedOperationException(""Unsupported for complex of on-condition"");
            }
            tableItem.getRelationFields().add(new RelationFieldsPair(leftFieldItem, rightFieldItem));
        } else {
            throw new UnsupportedOperationException(""Unsupported for complex of on-condition"");
        }
    }"
"@Override
    public HttpMessage handleShortcut(HttpMessage msg) throws ApiException {
        // We've to look at the name and verify if the challenge has
        // been registered by one of the executed plugins 
        // ----------------
        // http://<zap_IP>/json/xxe/other/NGFrteu568sgToo100
        // ----------------
        try {
            String path = msg.getRequestHeader().getURI().getPath();            
            String challenge = path.substring(path.indexOf(getPrefix()) + getPrefix().length() + 1);
            if (challenge.charAt(challenge.length() - 1) == '/') {
                challenge = challenge.substring(0, challenge.length() - 1);
            }
            
            RegisteredCallback rcback = regCallbacks.get(challenge);
            String response;
            
            if (rcback != null) {
                rcback.getPlugin().notifyCallback(challenge, rcback.getAttackMessage());
                response = API_RESPONSE_OK;
                
                // OK we consumed it so it's time to clean
                regCallbacks.remove(challenge);
                
            } else {
                response = API_RESPONSE_KO;
                
                // Maybe we've a lot of dirty entries
                cleanExpiredCallbacks();
            }
            
            // Build the response
            msg.setResponseHeader(API.getDefaultResponseHeader(""text/html"", response.length()));
            msg.getResponseHeader().setHeader(""Access-Control-Allow-Origin"", ""*"");
            
            msg.setResponseBody(response);
            
        } catch (URIException | HttpMalformedHeaderException e) {
            logger.warn(e.getMessage(), e);
        }
        
        return msg;
    }"
"@Override
	public void configure(Configuration parameters) {
		table = createTable();
		if (table != null) {
			scan = getScanner();
		}
	}"
"public static SearchRequest newLdaptiveSearchRequest(final String baseDn,
                                                         final SearchFilter filter) {
        return newLdaptiveSearchRequest(baseDn, filter, ReturnAttributes.ALL_USER.value(), ReturnAttributes.ALL_USER.value());
    }"
"@Override
	public void receiveHeartbeat(ResourceID heartbeatOrigin, I heartbeatPayload) {
		if (!stopped) {
			log.debug(""Received heartbeat from {}."", heartbeatOrigin);
			reportHeartbeat(heartbeatOrigin);

			if (heartbeatPayload != null) {
				heartbeatListener.reportPayload(heartbeatOrigin, heartbeatPayload);
			}
		}
	}"
"@Nullable
  byte[][] serialize() {
    if (len() == cap()) {
      return namesAndValues;
    }
    byte[][] serialized = new byte[len()][];
    System.arraycopy(namesAndValues, 0, serialized, 0, len());
    return serialized;
  }"
"public double matthewsCorrelation(EvaluationAveraging averaging) {
        int nClasses = confusion().getClasses().size();
        if (averaging == EvaluationAveraging.Macro) {
            double macroMatthewsCorrelation = 0.0;
            for (int i = 0; i < nClasses; i++) {
                macroMatthewsCorrelation += matthewsCorrelation(i);
            }
            macroMatthewsCorrelation /= nClasses;
            return macroMatthewsCorrelation;
        } else if (averaging == EvaluationAveraging.Micro) {
            long tpCount = 0;
            long fpCount = 0;
            long fnCount = 0;
            long tnCount = 0;
            for (int i = 0; i < nClasses; i++) {
                tpCount += truePositives.getCount(i);
                fpCount += falsePositives.getCount(i);
                fnCount += falseNegatives.getCount(i);
                tnCount += trueNegatives.getCount(i);
            }
            return EvaluationUtils.matthewsCorrelation(tpCount, fpCount, fnCount, tnCount);
        } else {
            throw new UnsupportedOperationException(""Unknown averaging approach: "" + averaging);
        }
    }"
"@Override
	public void shutdown() {
		// mark shut down and exit if it already was shut down
		if (!isShutdown.compareAndSet(false, true)) {
			return;
		}

		// Remove shutdown hook to prevent resource leaks
		ShutdownHookUtil.removeShutdownHook(shutdownHook, getClass().getSimpleName(), LOG);

		try {
			if (LOG.isDebugEnabled()) {
				LOG.debug(""Shutting down I/O manager."");
			}

			// close writing and reading threads with best effort and log problems
			// first notify all to close, then wait until all are closed

			for (WriterThread wt : writers) {
				try {
					wt.shutdown();
				}
				catch (Throwable t) {
					LOG.error(""Error while shutting down IO Manager writer thread."", t);
				}
			}
			for (ReaderThread rt : readers) {
				try {
					rt.shutdown();
				}
				catch (Throwable t) {
					LOG.error(""Error while shutting down IO Manager reader thread."", t);
				}
			}
			try {
				for (WriterThread wt : writers) {
					wt.join();
				}
				for (ReaderThread rt : readers) {
					rt.join();
				}
			}
			catch (InterruptedException iex) {
				// ignore this on shutdown
			}
		}
		finally {
			// make sure we call the super implementation in any case and at the last point,
			// because this will clean up the I/O directories
			super.shutdown();
		}
	}"
"private void fakeResponse(final HttpMethod method)
        throws IOException, HttpException {
        // What is to follow is an ugly hack.
        // I REALLY hate having to resort to such
        // an appalling trick
        // The only feasible solution is to split monolithic
        // HttpMethod into HttpRequest/HttpResponse pair.
        // That would allow to execute CONNECT method 
        // behind the scene and return CONNECT HttpResponse 
        // object in response to the original request that 
        // contains the correct status line, headers & 
        // response body.
        LOG.debug(""CONNECT failed, fake the response for the original method"");
        // Pass the status, headers and response stream to the wrapped
        // method.
        // To ensure that the connection is not released more than once
        // this method is still responsible for releasing the connection. 
        // This will happen when the response body is consumed, or when
        // the wrapped method closes the response connection in 
        // releaseConnection().
        if (method instanceof HttpMethodBase) {
            ((HttpMethodBase) method).fakeResponse(
                this.connectMethod.getStatusLine(),
                this.connectMethod.getResponseHeaderGroup(),
                conn,
                this.connectMethod.getResponseBodyAsStream()
            );
            method.getProxyAuthState().setAuthScheme(
                this.connectMethod.getProxyAuthState().getAuthScheme());
            this.connectMethod = null;
        } else {
            releaseConnection = true;
            LOG.warn(
                ""Unable to fake response on method as it is not derived from HttpMethodBase."");
        }
    }"
"public void setRawQuery(char[] escapedQuery) throws URIException {
        if (escapedQuery == null || escapedQuery.length == 0) {
            _query = escapedQuery;
            setURI();
            return;
        }
        // remove the fragment identifier
        escapedQuery = removeFragmentIdentifier(escapedQuery);
        if (!validate(escapedQuery, query)) {
            throw new URIException(URIException.ESCAPING,
                    ""escaped query not valid"");
        }
        _query = escapedQuery;
        setURI();
    }"
"private void updateIndex(
			long key,
			int hashCode,
			long address,
			int size,
			MemorySegment dataSegment,
			int currentPositionInSegment) throws IOException {
		assert (numKeys <= numBuckets / 2);
		int bucketId = hashCode & numBucketsMask;

		// each bucket occupied 16 bytes (long key + long pointer to data address)
		int bucketOffset = bucketId * SPARSE_BUCKET_ELEMENT_SIZE_IN_BYTES;
		MemorySegment segment = buckets[bucketOffset >>> segmentSizeBits];
		int segOffset = bucketOffset & segmentSizeMask;
		long currAddress;

		while (true) {
			currAddress = segment.getLong(segOffset + 8);
			if (segment.getLong(segOffset) != key && currAddress != INVALID_ADDRESS) {
				// hash conflicts, the bucket is occupied by another key

				// TODO test Conflict resolution:
				// now:    +1 +1 +1... cache friendly but more conflict, so we set factor to 0.5
				// other1: +1 +2 +3... less conflict, factor can be 0.75
				// other2: Secondary hashCode... less and less conflict, but need compute hash again
				bucketId = (bucketId + 1) & numBucketsMask;
				if (segOffset + SPARSE_BUCKET_ELEMENT_SIZE_IN_BYTES < segmentSize) {
					// if the new bucket still in current segment, we only need to update offset
					// within this segment
					segOffset += SPARSE_BUCKET_ELEMENT_SIZE_IN_BYTES;
				} else {
					// otherwise, we should re-calculate segment and offset
					bucketOffset = bucketId * 16;
					segment = buckets[bucketOffset >>> segmentSizeBits];
					segOffset = bucketOffset & segmentSizeMask;
				}
			} else {
				break;
			}
		}
		if (currAddress == INVALID_ADDRESS) {
			// this is the first value for this key, put the address in array.
			segment.putLong(segOffset, key);
			segment.putLong(segOffset + 8, address);
			numKeys += 1;
			// dataSegment may be null if we only have to rehash bucket area
			if (dataSegment != null) {
				dataSegment.putLong(currentPositionInSegment, toAddrAndLen(INVALID_ADDRESS, size));
			}
			if (numKeys * 2 > numBuckets) {
				resize();
			}
		} else {
			// there are some values for this key, put the address in the front of them.
			dataSegment.putLong(currentPositionInSegment, toAddrAndLen(currAddress, size));
			segment.putLong(segOffset + 8, address);
		}
	}"
"public static RocksDBKeyedStateBackend.RocksDbKvStateInfo createStateInfo(
		RegisteredStateMetaInfoBase metaInfoBase,
		RocksDB db,
		Function<String, ColumnFamilyOptions> columnFamilyOptionsFactory,
		@Nullable RocksDbTtlCompactFiltersManager ttlCompactFiltersManager) {

		ColumnFamilyDescriptor columnFamilyDescriptor = createColumnFamilyDescriptor(
			metaInfoBase, columnFamilyOptionsFactory, ttlCompactFiltersManager);
		return new RocksDBKeyedStateBackend.RocksDbKvStateInfo(createColumnFamily(columnFamilyDescriptor, db), metaInfoBase);
	}"
"public static HttpServletRequest getHttpServletRequestFromExternalWebflowContext(final RequestContext context) {
        Assert.isInstanceOf(ServletExternalContext.class, context.getExternalContext(),
            ""Cannot obtain HttpServletRequest from event of type: ""
                + context.getExternalContext().getClass().getName());

        return (HttpServletRequest) context.getExternalContext().getNativeRequest();
    }"
"public static <K, V> MapBuilder<K, V> builder(K k, V v) {
		return (builder(new HashMap<K, V>())).put(k, v);
	}"
"public static Map<String, Object> map(Object... objects) {

    if (objects.length % 2 != 0) {
      throw new ActivitiIllegalArgumentException(""The input should always be even since we expect a list of key-value pairs!"");
    }

    Map<String, Object> map = new HashMap<String, Object>();
    for (int i = 0; i < objects.length; i += 2) {
      map.put((String) objects[i], objects[i + 1]);
    }

    return map;
  }"
"@Override
    public List<R> subList(int fromIndex, int toIndex) {
        List<R> r = new ArrayList<>();
        Iterator<R> itr = iterator();
        hudson.util.Iterators.skip(itr, fromIndex);
        for (int i=toIndex-fromIndex; i>0; i--) {
            r.add(itr.next());
        }
        return r;
    }"
"public static <T> T instantiate(Class<T> type) {
        try {
            return BeanIntrospector.SHARED.findIntrospection(type).map(BeanIntrospection::instantiate).orElseGet(() -> {
                try {
                    Logger log = ClassUtils.REFLECTION_LOGGER;
                    if (log.isDebugEnabled()) {
                        log.debug(""Reflectively instantiating type: "" + type);
                    }
                    return type.newInstance();
                } catch (Throwable e) {
                    throw new InstantiationException(""Could not instantiate type ["" + type.getName() + ""]: "" + e.getMessage(), e);
                }
            });
        } catch (Throwable e) {
            throw new InstantiationException(""Could not instantiate type ["" + type.getName() + ""]: "" + e.getMessage(), e);
        }
    }"
"public static X509Certificate readCertificate(final Resource resource) {
        try (val in = resource.getInputStream()) {
            return CertUtil.readCertificate(in);
        } catch (final Exception e) {
            throw new IllegalArgumentException(""Error reading certificate "" + resource, e);
        }
    }"
"protected void initControlListeners() {
        // if the control got resized the overlay rect must be rest
        control.layoutBoundsProperty().addListener(observable -> resetRippler());
        if(getChildren().contains(control))
            control.boundsInParentProperty().addListener(observable -> resetRippler());
        control.addEventHandler(MouseEvent.MOUSE_PRESSED,
            (event) -> createRipple(event.getX(), event.getY()));
        // create fade out transition for the ripple
        control.addEventHandler(MouseEvent.MOUSE_RELEASED, e -> releaseRipple());
    }"
"private static boolean migrate(TaskListener listener, String target) throws IOException, InterruptedException {
        PrintStream out = listener.getLogger();

        File home = Jenkins.getInstance().getRootDir();
        // do the migration
        LibZFS zfs = new LibZFS();
        ZFSFileSystem existing = zfs.getFileSystemByMountPoint(home);
        if(existing!=null) {
            out.println(home+"" is already on ZFS. Doing nothing"");
            return true;
        }

        File tmpDir = Util.createTempDir();

        // mount a new file system to a temporary location
        out.println(""Opening ""+target);
        ZFSFileSystem hudson = zfs.open(target, ZFSFileSystem.class);
        hudson.setMountPoint(tmpDir);
        hudson.setProperty(""hudson:managed-by"",""hudson""); // mark this file system as ""managed by Hudson""
        hudson.mount();

        // copy all the files
        out.println(""Copying all existing data files"");
        if(system(home,listener, ""/usr/bin/cp"",""-pR"",""."", tmpDir.getAbsolutePath())!=0) {
            out.println(""Failed to copy ""+home+"" to ""+tmpDir);
            return false;
        }

        // unmount
        out.println(""Unmounting ""+target);
        hudson.unmount(MountFlags.MS_FORCE);

        // move the original directory to the side
        File backup = new File(home.getPath()+"".backup"");
        out.println(""Moving ""+home+"" to ""+backup);
        if(backup.exists())
            Util.deleteRecursive(backup);
        if(!home.renameTo(backup)) {
            out.println(""Failed to move your current data ""+home+"" out of the way"");
        }

        // update the mount point
        out.println(""Creating a new mount point at ""+home);
        if(!home.mkdir())
            throw new IOException(""Failed to create mount point ""+home);

        out.println(""Mounting ""+target);
        hudson.setMountPoint(home);
        hudson.mount();

        out.println(""Sharing ""+target);
        try {
            hudson.setProperty(""sharesmb"",""on"");
            hudson.setProperty(""sharenfs"",""on"");
            hudson.share();
        } catch (ZFSException e) {
            listener.error(""Failed to share the file systems: ""+e.getCode());
        }

        // delete back up
        out.println(""Deleting ""+backup);
        if(system(new File(""/""),listener,""/usr/bin/rm"",""-rf"",backup.getAbsolutePath())!=0) {
            out.println(""Failed to delete ""+backup.getAbsolutePath());
            return false;
        }

        out.println(""Migration completed"");
        return true;
    }"
"public static <T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11> Tuple12<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11> of(T0 value0, T1 value1, T2 value2, T3 value3, T4 value4, T5 value5, T6 value6, T7 value7, T8 value8, T9 value9, T10 value10, T11 value11) {
		return new Tuple12<>(value0,
			value1,
			value2,
			value3,
			value4,
			value5,
			value6,
			value7,
			value8,
			value9,
			value10,
			value11);
	}"
"public List<int[]> getNPaths(int n)
    {
        List<int[]> result = new ArrayList<int[]>();

        n = Math.min(Predefine.MAX_SEGMENT_NUM, n);
        for (int i = 0; i < N && result.size() < n; ++i)
        {
            List<int[]> pathList = getPaths(i);
            for (int[] path : pathList)
            {
                if (result.size() == n) break;
                result.add(path);
            }
        }

        return result;
    }"
"public static SequenceBatchCSVRecord fromWritables(List<List<List<Writable>>> input) {
        SequenceBatchCSVRecord ret = new SequenceBatchCSVRecord();
        for(int i = 0; i < input.size(); i++) {
            ret.add(Arrays.asList(BatchCSVRecord.fromWritables(input.get(i))));
        }

        return ret;
    }"
"public static int writeUtf8(ByteBuf buf, CharSequence seq) {
        return reserveAndWriteUtf8(buf, seq, utf8MaxBytes(seq));
    }"
"public LinkedList<Entry<String, V>> commonPrefixSearchWithValue(String key)
    {
        return commonPrefixSearchWithValue(key.toCharArray(), 0);
    }"
"public static String getSDbl( double Value, int DecPrec ) {
		//
		String Result = """";
		//
		if ( Double.isNaN( Value ) ) return ""NaN"";
		//
		if ( DecPrec < 0 ) DecPrec = 0;
		//
		String DFS = ""###,###,##0"";
		//
		if ( DecPrec > 0 ) {
			int idx = 0;
			DFS += ""."";
			while ( idx < DecPrec ) {
				DFS = DFS + ""0"";
				idx ++;
				if ( idx > 100 ) break;
			}
		}
		//
//		Locale locale  = new Locale(""en"", ""UK"");
		//
		DecimalFormatSymbols DcmFrmSmb = new DecimalFormatSymbols( Locale.getDefault());
		DcmFrmSmb.setDecimalSeparator('.');
		DcmFrmSmb.setGroupingSeparator(' ');
		//
		DecimalFormat DcmFrm;
		//
		DcmFrm = new DecimalFormat( DFS, DcmFrmSmb );
		//
	//	DcmFrm.setGroupingSize( 3 );
		//
		Result = DcmFrm.format( Value );
		//
		return Result;
	}"
"public void doDynamic(StaplerRequest req, StaplerResponse rsp) throws IOException, ServletException {
        String path = req.getRestOfPath();

        String pathUC = path.toUpperCase(Locale.ENGLISH);
        if (path.isEmpty() || path.contains("".."") || path.startsWith(""."") || path.contains(""%"")
                || pathUC.contains(""META-INF"") || pathUC.contains(""WEB-INF"")
                // ClassicPluginStrategy#explode produce that file to know if a new explosion is required or not
                || pathUC.equals(""/.TIMESTAMP2"")
        ) {
            LOGGER.warning(""rejecting possibly malicious "" + req.getRequestURIWithQueryString());
            rsp.sendError(HttpServletResponse.SC_BAD_REQUEST);
            return;
        }

        // Stapler routes requests like the ""/static/.../foo/bar/zot"" to be treated like ""/foo/bar/zot""
        // and this is used to serve long expiration header, by using Jenkins.VERSION_HASH as ""...""
        // to create unique URLs. Recognize that and set a long expiration header.
        String requestPath = req.getRequestURI().substring(req.getContextPath().length());
        boolean staticLink = requestPath.startsWith(""/static/"");

        long expires = staticLink ? TimeUnit.DAYS.toMillis(365) : -1;

        // use serveLocalizedFile to support automatic locale selection
        rsp.serveLocalizedFile(req, new URL(wrapper.baseResourceURL, '.' + path), expires);
    }"
"private JPanel getJPanel() {
		if (jPanel == null) {
			GridBagConstraints gridBagConstraints15 = new GridBagConstraints();
			java.awt.GridBagConstraints gridBagConstraints13 = new GridBagConstraints();

			javax.swing.JLabel jLabel2 = new JLabel();

			java.awt.GridBagConstraints gridBagConstraints3 = new GridBagConstraints();

			java.awt.GridBagConstraints gridBagConstraints2 = new GridBagConstraints();

			jPanel = new JPanel();
			jPanel.setLayout(new GridBagLayout());
			jPanel.setPreferredSize(new java.awt.Dimension(400,400));
			jPanel.setMinimumSize(new java.awt.Dimension(400,400));
			gridBagConstraints2.gridx = 1;
			gridBagConstraints2.gridy = 5;
			gridBagConstraints2.insets = new java.awt.Insets(2,2,2,2);
			gridBagConstraints2.anchor = java.awt.GridBagConstraints.EAST;
			gridBagConstraints3.gridx = 2;
			gridBagConstraints3.gridy = 5;
			gridBagConstraints3.insets = new java.awt.Insets(2,2,2,10);
			gridBagConstraints3.anchor = java.awt.GridBagConstraints.EAST;

			gridBagConstraints13.gridx = 0;
			gridBagConstraints13.gridy = 5;
			gridBagConstraints13.fill = java.awt.GridBagConstraints.HORIZONTAL;
			gridBagConstraints13.weightx = 1.0D;
			gridBagConstraints13.insets = new java.awt.Insets(2,10,2,5);

			gridBagConstraints15.weightx = 1.0D;
			gridBagConstraints15.weighty = 1.0D;
			gridBagConstraints15.fill = java.awt.GridBagConstraints.BOTH;
			gridBagConstraints15.insets = new java.awt.Insets(2,2,2,2);
			gridBagConstraints15.gridwidth = 3;
			gridBagConstraints15.gridx = 0;
			gridBagConstraints15.gridy = 2;
			gridBagConstraints15.anchor = java.awt.GridBagConstraints.NORTHWEST;
			gridBagConstraints15.ipadx = 0;
			gridBagConstraints15.ipady = 10;

			jPanel.add(getJScrollPane(), gridBagConstraints15);
			jPanel.add(jLabel2, gridBagConstraints13);
			jPanel.add(getBtnCancel(), gridBagConstraints2);
			jPanel.add(getBtnOk(), gridBagConstraints3);
		}
		return jPanel;
	}"
"public List<Deployment> executeList(CommandContext commandContext, Map<String, Object> parameterMap, int firstResult, int maxResults) {
    return commandContext.getDeploymentEntityManager().findDeploymentsByNativeQuery(parameterMap, firstResult, maxResults);
  }"
"@SafeVarargs
	public final Set<Class<?>> scan(Class<? extends Annotation>... annotationTypes)
			throws ClassNotFoundException {
		List<String> packages = getPackages();
		if (packages.isEmpty()) {
			return Collections.emptySet();
		}
		ClassPathScanningCandidateComponentProvider scanner = new ClassPathScanningCandidateComponentProvider(
				false);
		scanner.setEnvironment(this.context.getEnvironment());
		scanner.setResourceLoader(this.context);
		for (Class<? extends Annotation> annotationType : annotationTypes) {
			scanner.addIncludeFilter(new AnnotationTypeFilter(annotationType));
		}
		Set<Class<?>> entitySet = new HashSet<>();
		for (String basePackage : packages) {
			if (StringUtils.hasText(basePackage)) {
				for (BeanDefinition candidate : scanner
						.findCandidateComponents(basePackage)) {
					entitySet.add(ClassUtils.forName(candidate.getBeanClassName(),
							this.context.getClassLoader()));
				}
			}
		}
		return entitySet;
	}"
"@RequirePOST
    public void doAct(StaplerRequest req, StaplerResponse rsp) throws IOException {
        if(req.hasParameter(""no"")) {
            disable(true);
            rsp.sendRedirect(req.getContextPath()+""/manage"");
        } else {
            rsp.sendRedirect(req.getContextPath()+""/configureSecurity"");
        }
    }"
"public boolean isApplicable(Class<? extends T> targetType) {
        Class<? extends T> applicable = Functions.getTypeParameter(clazz,getP(),0);
        return applicable.isAssignableFrom(targetType);
    }"
"private static int getPowerSum(char[] iArr) {
		int iSum = 0;
		if (power.length == iArr.length) {
			for (int i = 0; i < iArr.length; i++) {
				iSum += Integer.valueOf(String.valueOf(iArr[i])) * power[i];
			}
		}
		return iSum;
	}"
"static void shiftLeftDestructive(Slice decimal, int leftShifts)
    {
        if (leftShifts == 0) {
            return;
        }

        int wordShifts = leftShifts / 64;
        int bitShiftsInWord = leftShifts % 64;
        int shiftRestore = 64 - bitShiftsInWord;

        // check overflow
        if (bitShiftsInWord != 0) {
            if ((getLong(decimal, 1 - wordShifts) & (-1L << shiftRestore)) != 0) {
                throwOverflowException();
            }
        }
        if (wordShifts == 1) {
            if (getLong(decimal, 1) != 0) {
                throwOverflowException();
            }
        }

        // Store negative before settings values to result.
        boolean negative = isNegative(decimal);

        long low;
        long high;

        switch (wordShifts) {
            case 0:
                low = getLong(decimal, 0);
                high = getLong(decimal, 1);
                break;
            case 1:
                low = 0;
                high = getLong(decimal, 0);
                break;
            default:
                throw new IllegalArgumentException();
        }

        if (bitShiftsInWord > 0) {
            high = (high << bitShiftsInWord) | (low >>> shiftRestore);
            low = (low << bitShiftsInWord);
        }

        pack(decimal, low, high, negative);
    }"
"@ReadOperation
    public Map<String, Object> handle() {
        val model = new LinkedHashMap<String, Object>();
        if (healthEndpoint == null) {
            model.put(""status"", HttpStatus.OK.value());
            model.put(""description"", HttpStatus.OK.name());
            LOGGER.info(""Health endpoint is undefined/disabled. No health indicators may be consulted to query for health data ""
                + ""and the status results are always going to be [{}]"", model);
        } else {

            val health = this.healthEndpoint.health();
            val status = health.getStatus();

            if (status.equals(Status.DOWN) || status.equals(Status.OUT_OF_SERVICE)) {
                model.put(""status"", HttpStatus.SERVICE_UNAVAILABLE.value());
                model.put(""description"", HttpStatus.SERVICE_UNAVAILABLE.name());
            } else {
                model.put(""status"", HttpStatus.OK.value());
                model.put(""description"", HttpStatus.OK.name());
            }
            model.put(""health"", status.getCode());
        }
        val hostname = casProperties.getHost().getName();
        model.put(""host"", StringUtils.isBlank(hostname)
            ? InetAddressUtils.getCasServerHostName()
            : hostname);
        model.put(""server"", casProperties.getServer().getName());
        model.put(""version"", CasVersion.asString());
        return model;
    }"
"public void copy() throws Exception {
        if(callInitRecordReader) {
            if(recordReader != null) {
                recordReader.initialize(configuration, inputUrl);
            }
            else {
                if(readersToConcat == null || splitPerReader == null)  {
                    throw new IllegalArgumentException(""No readers or input  splits found."");
                }

                if(readersToConcat.length != splitPerReader.length) {
                    throw new IllegalArgumentException(""One input split must be specified per record reader"");
                }

                for(int i = 0; i < readersToConcat.length; i++) {
                    if(readersToConcat[i] == null) {
                        throw new IllegalStateException(""Reader at record "" + i + "" was null!"");
                    }
                    if(splitPerReader[i] == null) {
                        throw new IllegalStateException(""Split at "" + i + "" is null!"");
                    }
                    //allow for, but do not enforce configurations per reader.
                    if(configurationsPerReader != null) {
                        readersToConcat[i].initialize(configurationsPerReader[i], splitPerReader[i]);
                    }
                    else {
                        readersToConcat[i].initialize(configuration,splitPerReader[i]);
                    }
                }
            }
        }

        if(callInitPartitioner) {
            partitioner.init(configuration, outputUrl);
        }

        if(callInitRecordWriter) {
            recordWriter.initialize(configuration, outputUrl, partitioner);
        }

        if(recordReader != null) {
            write(recordReader,true);
        }
        else if(readersToConcat != null) {
            for(RecordReader recordReader : readersToConcat) {
                write(recordReader,false);
            }

            //close since we can't do it within the method
            recordWriter.close();
        }

    }"
"private void removeFromTable(Node[] table, Node node) {
    int last = table.length - 1;
    table[node.index] = table[last];
    table[node.index].index = node.index;
    table[last] = null;
  }"
"public static String getDriverClassName(final String url) {
        for (Entry<String, String> entry : URL_PREFIX_AND_DRIVER_CLASS_NAME_MAPPER.entrySet()) {
            if (url.startsWith(entry.getKey())) {
                return entry.getValue();
            }
        }
        throw new ShardingException(""Cannot resolve JDBC url `%s`. Please implements `%s` and add to SPI."", url, JDBCDriverURLRecognizer.class.getName());
    }"
"public static ImageOutputStream getImageOutputStream(OutputStream out) throws IORuntimeException {
		try {
			return ImageIO.createImageOutputStream(out);
		} catch (IOException e) {
			throw new IORuntimeException(e);
		}
	}"
"public void setPanelsVisible(boolean visible) {
        for (Component component : fullTabList) {
            if (component instanceof AbstractPanel) {
                AbstractPanel ap = (AbstractPanel) component;
                boolean canChangeVisibility = true;
                if (!visible) {
                    canChangeVisibility = canHidePanel(ap);
                }

                if (canChangeVisibility) {
                    setVisible(component, visible);
                }
            }
        }
    }"
"public void stop() {
        for (PluginWrapper p : activePlugins) {
            p.stop();
            p.releaseClassLoader();
        }
        activePlugins.clear();
        // Work around a bug in commons-logging.
        // See http://www.szegedi.org/articles/memleak.html
        LogFactory.release(uberClassLoader);
    }"
"private List<List<Writable>> filterRequiredColumns(String readerName, List<List<Writable>> list){

        //Options: (a) entire reader
        //(b) one or more subsets

        boolean entireReader = false;
        List<SubsetDetails> subsetList = null;
        int max = -1;
        int min = Integer.MAX_VALUE;
        for(List<SubsetDetails> sdList : Arrays.asList(inputs, outputs)) {
            for (SubsetDetails sd : sdList) {
                if (readerName.equals(sd.readerName)) {
                    if (sd.entireReader) {
                        entireReader = true;
                        break;
                    } else {
                        if (subsetList == null) {
                            subsetList = new ArrayList<>();
                        }
                        subsetList.add(sd);
                        max = Math.max(max, sd.subsetEndInclusive);
                        min = Math.min(min, sd.subsetStart);
                    }
                }
            }
        }

        if(entireReader){
            //No filtering required
            return list;
        } else if(subsetList == null){
            throw new IllegalStateException(""Found no usages of reader: "" + readerName);
        } else {
            //we need some - but not all - columns
            boolean[] req = new boolean[max+1];
            for(SubsetDetails sd : subsetList){
                for( int i=sd.subsetStart; i<= sd.subsetEndInclusive; i++ ){
                    req[i] = true;
                }
            }

            List<List<Writable>> out = new ArrayList<>();
            IntWritable zero = new IntWritable(0);
            for(List<Writable> l : list){
                List<Writable> lNew = new ArrayList<>(l.size());
                for(int i=0; i<l.size(); i++ ){
                    if(i >= req.length || !req[i]){
                        lNew.add(zero);
                    } else {
                        lNew.add(l.get(i));
                    }
                }
                out.add(lNew);
            }
            return out;
        }
    }"
"@SuppressWarnings(""unchecked"")
  public static Object parse(String raw) throws IOException {
    JsonReader jr = new JsonReader(new StringReader(raw));
    try {
      return parseRecursive(jr);
    } finally {
      try {
        jr.close();
      } catch (IOException e) {
        logger.log(Level.WARNING, ""Failed to close"", e);
      }
    }
  }"
"public void fitOnSequences(Integer[][] sequences) {
        documentCount += 1;
        for (Integer[] sequence: sequences) {
            Set<Integer> sequenceSet = new HashSet<>(Arrays.asList(sequence));
            for (Integer index: sequenceSet)
                indexDocs.put(index, indexDocs.get(index) + 1);
        }
    }"
"public static byte decodeHexByte(CharSequence s, int pos) {
        int hi = decodeHexNibble(s.charAt(pos));
        int lo = decodeHexNibble(s.charAt(pos + 1));
        if (hi == -1 || lo == -1) {
            throw new IllegalArgumentException(String.format(
                    ""invalid hex byte '%s' at index %d of '%s'"", s.subSequence(pos, pos + 2), pos, s));
        }
        return (byte) ((hi << 4) + lo);
    }"
"public static java.lang.Long toLong(Object arg) throws NoSuchMethodException {
        if (arg instanceof java.lang.Integer) return boxToLong((long)unboxToInt(arg));
        if (arg instanceof java.lang.Double) return boxToLong((long)unboxToDouble(arg));
        if (arg instanceof java.lang.Float) return boxToLong((long)unboxToFloat(arg));
        if (arg instanceof java.lang.Long) return (java.lang.Long)arg;
        if (arg instanceof java.lang.Character) return boxToLong((long)unboxToChar(arg));
        if (arg instanceof java.lang.Byte) return boxToLong((long)unboxToByte(arg));
        if (arg instanceof java.lang.Short) return boxToLong((long)unboxToShort(arg));
        throw new NoSuchMethodException();
    }"
"@Nonnull
    public static Properties loadProperties(@Nonnull String properties) throws IOException {
        Properties p = new Properties();
        p.load(new StringReader(properties));
        return p;
    }"
"@Override
	public int compareTo(ValueArray<LongValue> o) {
		LongValueArray other = (LongValueArray) o;

		int min = Math.min(position, other.position);
		for (int i = 0; i < min; i++) {
			int cmp = Long.compare(data[i], other.data[i]);

			if (cmp != 0) {
				return cmp;
			}
		}

		return Integer.compare(position, other.position);
	}"
"public void write_port(OtpErlangPort port) {
	write1(port.tag());
	write_atom(port.node());
	write4BE(port.id());
	switch (port.tag()) {
	case OtpExternal.portTag:	    
	    write1(port.creation());
	    break;
	case OtpExternal.newPortTag:
	    write4BE(port.creation());
	    break;
	default:
	    throw new AssertionError(""Invalid port tag "" + port.tag());
	}
    }"
"public Img cut(Rectangle rectangle) {
		final BufferedImage srcImage = getValidSrcImg();
		rectangle = fixRectangle(rectangle, srcImage.getWidth(), srcImage.getHeight());

		final ImageFilter cropFilter = new CropImageFilter(rectangle.x, rectangle.y, rectangle.width, rectangle.height);
		final Image image = Toolkit.getDefaultToolkit().createImage(new FilteredImageSource(srcImage.getSource(), cropFilter));
		this.targetImage = ImgUtil.toBufferedImage(image);
		return this;
	}"
"public T setPropertiesFile(String path) {
    checkNotNull(path, ""path"");
    builder.setPropertiesFile(path);
    return self();
  }"
"private Object handleJoinPointCompletableFuture(ProceedingJoinPoint proceedingJoinPoint, io.github.resilience4j.circuitbreaker.CircuitBreaker circuitBreaker) {
		return circuitBreaker.executeCompletionStage(() -> {
			try {
				return (CompletionStage<?>) proceedingJoinPoint.proceed();
			} catch (Throwable throwable) {
				throw new CompletionException(throwable);
			}
		});
	}"
"public void onHttpServerUpgrade(Http2Settings settings) throws Http2Exception {
        if (!connection().isServer()) {
            throw connectionError(PROTOCOL_ERROR, ""Server-side HTTP upgrade requested for a client"");
        }
        if (!prefaceSent()) {
            // If the preface was not sent yet it most likely means the handler was not added to the pipeline before
            // calling this method.
            throw connectionError(INTERNAL_ERROR, ""HTTP upgrade must occur after preface was sent"");
        }
        if (decoder.prefaceReceived()) {
            throw connectionError(PROTOCOL_ERROR, ""HTTP upgrade must occur before HTTP/2 preface is received"");
        }

        // Apply the settings but no ACK is necessary.
        encoder.remoteSettings(settings);

        // Create a stream in the half-closed state.
        connection().remote().createStream(HTTP_UPGRADE_STREAM_ID, true);
    }"
"public static <ReqT, RespT> RespT blockingUnaryCall(
      Channel channel, MethodDescriptor<ReqT, RespT> method, CallOptions callOptions, ReqT req) {
    ThreadlessExecutor executor = new ThreadlessExecutor();
    ClientCall<ReqT, RespT> call = channel.newCall(method, callOptions.withExecutor(executor));
    try {
      ListenableFuture<RespT> responseFuture = futureUnaryCall(call, req);
      while (!responseFuture.isDone()) {
        try {
          executor.waitAndDrain();
        } catch (InterruptedException e) {
          Thread.currentThread().interrupt();
          throw Status.CANCELLED
              .withDescription(""Call was interrupted"")
              .withCause(e)
              .asRuntimeException();
        }
      }
      return getUnchecked(responseFuture);
    } catch (RuntimeException e) {
      throw cancelThrow(call, e);
    } catch (Error e) {
      throw cancelThrow(call, e);
    }
  }"
"private static int maxLiteralLengthModulus(int n)
  {
    int m = (n & 0xC1F07C1F) + ((n >>> 5) & 0xC1F07C1F);
    m = (m >>> 15) + (m & 0x00007FFF);
    if (m <= 31) {
      return m == 31 ? 0 : m;
    }
    m = (m >>> 5) + (m & 0x0000001F);
    if (m <= 31) {
      return m == 31 ? 0 : m;
    }
    m = (m >>> 5) + (m & 0x0000001F);
    if (m <= 31) {
      return m == 31 ? 0 : m;
    }
    m = (m >>> 5) + (m & 0x0000001F);
    if (m <= 31) {
      return m == 31 ? 0 : m;
    }
    m = (m >>> 5) + (m & 0x0000001F);
    if (m <= 31) {
      return m == 31 ? 0 : m;
    }
    m = (m >>> 5) + (m & 0x0000001F);
    return m == 31 ? 0 : m;
  }"
"public static boolean isVector(IntBuffer shapeInfo) {
        int rank = Shape.rank(shapeInfo);
        if (rank > 2 || rank < 1)
            return false;
        else {
            int len = Shape.length(shapeInfo);
            IntBuffer shape = Shape.shapeOf(shapeInfo);
            return shape.get(0) == len || shape.get(1) == len;
        }
    }"
"@Override
  public void recordVariableCreate(VariableInstanceEntity variable) {
    // Historic variables
    if (isHistoryLevelAtLeast(HistoryLevel.ACTIVITY)) {
     getHistoricVariableInstanceEntityManager().copyAndInsert(variable);
    }
  }"
"@Override
	@SuppressWarnings(""unchecked"")
	public Tuple5<T0, T1, T2, T3, T4> copy() {
		return new Tuple5<>(this.f0,
			this.f1,
			this.f2,
			this.f3,
			this.f4);
	}"
"public static byte[] unWrap(Byte... values) {
		if (null == values) {
			return null;
		}
		final int length = values.length;
		if (0 == length) {
			return new byte[0];
		}

		final byte[] array = new byte[length];
		for (int i = 0; i < length; i++) {
			array[i] = values[i].byteValue();
		}
		return array;
	}"
"public ChannelFuture removeAndWriteAll() {
        assert ctx.executor().inEventLoop();

        if (isEmpty()) {
            return null;
        }

        ChannelPromise p = ctx.newPromise();
        PromiseCombiner combiner = new PromiseCombiner(ctx.executor());
        try {
            // It is possible for some of the written promises to trigger more writes. The new writes
            // will ""revive"" the queue, so we need to write them up until the queue is empty.
            for (PendingWrite write = head; write != null; write = head) {
                head = tail = null;
                size = 0;
                bytes = 0;

                while (write != null) {
                    PendingWrite next = write.next;
                    Object msg = write.msg;
                    ChannelPromise promise = write.promise;
                    recycle(write, false);
                    if (!(promise instanceof VoidChannelPromise)) {
                        combiner.add(promise);
                    }
                    ctx.write(msg, promise);
                    write = next;
                }
            }
            combiner.finish(p);
        } catch (Throwable cause) {
            p.setFailure(cause);
        }
        assertEmpty();
        return p;
    }"
"public UTF8String toLowerCase() {
    if (numBytes == 0) {
      return EMPTY_UTF8;
    }

    byte[] bytes = new byte[numBytes];
    bytes[0] = (byte) Character.toTitleCase(getByte(0));
    for (int i = 0; i < numBytes; i++) {
      byte b = getByte(i);
      if (numBytesForFirstByte(b) != 1) {
        // fallback
        return toLowerCaseSlow();
      }
      int lower = Character.toLowerCase((int) b);
      if (lower > 127) {
        // fallback
        return toLowerCaseSlow();
      }
      bytes[i] = (byte) lower;
    }
    return fromBytes(bytes);
  }"
"final void registerWorker(WorkQueue w) {
        Mutex lock = this.lock;
        lock.lock();
        try {
            WorkQueue[] ws = workQueues;
            if (w != null && ws != null) {          // skip on shutdown/failure
                int rs, n =  ws.length, m = n - 1;
                int s = nextSeed += SEED_INCREMENT; // rarely-colliding sequence
                w.seed = (s == 0) ? 1 : s;          // ensure non-zero seed
                int r = (s << 1) | 1;               // use odd-numbered indices
                if (ws[r &= m] != null) {           // collision
                    int probes = 0;                 // step by approx half size
                    int step = (n <= 4) ? 2 : ((n >>> 1) & SQMASK) + 2;
                    while (ws[r = (r + step) & m] != null) {
                        if (++probes >= n) {
                            workQueues = ws = Arrays.copyOf(ws, n <<= 1);
                            m = n - 1;
                            probes = 0;
                        }
                    }
                }
                w.eventCount = w.poolIndex = r;     // establish before recording
                ws[r] = w;                          // also update seq
                runState = ((rs = runState) & SHUTDOWN) | ((rs + 2) & ~SHUTDOWN);
            }
        } finally {
            lock.unlock();
        }
    }"
"@Override
  public Object invoke(Object[] argv) throws Throwable {
    if (handle == null) {
      throw new IllegalStateException(
          ""Default method handler invoked before proxy has been bound."");
    }
    return handle.invokeWithArguments(argv);
  }"
"public INDArray project(INDArray data, INDArray result){
        long[] tShape = targetShape(data.shape(), eps, components, autoMode);
        return data.mmuli(getProjectionMatrix(tShape, this.rng), result);
    }"
"static void adjustAutoCommitConfig(Properties properties, OffsetCommitMode offsetCommitMode) {
		if (offsetCommitMode == OffsetCommitMode.ON_CHECKPOINTS || offsetCommitMode == OffsetCommitMode.DISABLED) {
			properties.setProperty(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, ""false"");
		}
	}"
"public static <K, V> HadoopInputFormat<K, V> createHadoopInput(org.apache.hadoop.mapred.InputFormat<K, V> mapredInputFormat, Class<K> key, Class<V> value, JobConf job) {
		return new HadoopInputFormat<>(mapredInputFormat, key, value, job);
	}"
"public <T> Source<T> from(Supplier<T> supplier) {
		Assert.notNull(supplier, ""Supplier must not be null"");
		Source<T> source = getSource(supplier);
		if (this.sourceOperator != null) {
			source = this.sourceOperator.apply(source);
		}
		return source;
	}"
"public SDVariable softmaxCrossEntropy(String name, @NonNull SDVariable oneHotLabels, @NonNull SDVariable logitPredictions,
                                          SDVariable weights, @NonNull LossReduce lossReduce, double labelSmoothing) {
        validateFloatingPoint(""softmax cross entropy loss"", ""predictions"", logitPredictions);
        validateNumerical(""softmax cross entropy loss"", ""oneHotLabels"", oneHotLabels);
        if (weights == null)
            weights = sd.scalar(null, logitPredictions.dataType(), 1.0);
        SDVariable result = f().lossSoftmaxCrossEntropy(oneHotLabels, logitPredictions, weights, lossReduce, labelSmoothing);
        result = updateVariableNameAndReference(result, name);
        result.markAsLoss();
        return result;
    }"
"Object unwrapListPrimitive(Object o)
  {
    assert isWrappedListPrimitive(o);
    Group g = (Group) o;
    return convertPrimitiveField(g, 0, binaryAsString);
  }"
"public void invalidate(Key... keys) {
        for (Key key : keys) {
            logger.debug(""Invalidating the response cache key : {} {} {} {}, {}"",
                    key.getEntityType(), key.getName(), key.getVersion(), key.getType(), key.getEurekaAccept());

            readWriteCacheMap.invalidate(key);
            Collection<Key> keysWithRegions = regionSpecificKeys.get(key);
            if (null != keysWithRegions && !keysWithRegions.isEmpty()) {
                for (Key keysWithRegion : keysWithRegions) {
                    logger.debug(""Invalidating the response cache key : {} {} {} {} {}"",
                            key.getEntityType(), key.getName(), key.getVersion(), key.getType(), key.getEurekaAccept());
                    readWriteCacheMap.invalidate(keysWithRegion);
                }
            }
        }
    }"
"protected void setProcessDefinitionVersionsAndIds(ParsedDeployment parsedDeployment,
                                                      Map<ProcessDefinitionEntity, ProcessDefinitionEntity> mapNewToOldProcessDefinitions) {
        CommandContext commandContext = Context.getCommandContext();

        for (ProcessDefinitionEntity processDefinition : parsedDeployment.getAllProcessDefinitions()) {
            int version = 1;

            ProcessDefinitionEntity latest = mapNewToOldProcessDefinitions.get(processDefinition);
            if (latest != null) {
                version = latest.getVersion() + 1;
            }

            processDefinition.setVersion(version);
            processDefinition.setId(getIdForNewProcessDefinition(processDefinition));

            if (commandContext.getProcessEngineConfiguration().getEventDispatcher().isEnabled()) {
                commandContext.getProcessEngineConfiguration().getEventDispatcher().dispatchEvent(ActivitiEventBuilder.createEntityEvent(ActivitiEventType.ENTITY_CREATED,
                                                                                                                                         processDefinition));
            }
        }
    }"
"public Postcard withChar(@Nullable String key, char value) {
        mBundle.putChar(key, value);
        return this;
    }"
"public Double getDouble(String key, String group, Double defaultValue) {
		return Convert.toDouble(getByGroup(key, group), defaultValue);
	}"
"public void encode(ByteBuf out, CharSequence data) {
        ObjectUtil.checkNotNull(out, ""out"");
        if (data instanceof AsciiString) {
            AsciiString string = (AsciiString) data;
            try {
                encodeProcessor.out = out;
                string.forEachByte(encodeProcessor);
            } catch (Exception e) {
                PlatformDependent.throwException(e);
            } finally {
                encodeProcessor.end();
            }
        } else {
            encodeSlowPath(out, data);
        }
    }"
"public void add(ConfigurationMetadataProperty property,
			ConfigurationMetadataSource source) {
		if (source != null) {
			putIfAbsent(source.getProperties(), property.getId(), property);
		}
		putIfAbsent(getGroup(source).getProperties(), property.getId(), property);
	}"
"public void putString(String key, String str) {
		checkNotNull(key);
		checkNotNull(str);
		put(key, str);
	}"
"public final ChannelFuture spliceTo(final FileDescriptor ch, final int offset, final int len,
                                        final ChannelPromise promise) {
        checkPositiveOrZero(len, ""len"");
        checkPositiveOrZero(offset, ""offser"");
        if (config().getEpollMode() != EpollMode.LEVEL_TRIGGERED) {
            throw new IllegalStateException(""spliceTo() supported only when using "" + EpollMode.LEVEL_TRIGGERED);
        }
        checkNotNull(promise, ""promise"");
        if (!isOpen()) {
            promise.tryFailure(SPLICE_TO_CLOSED_CHANNEL_EXCEPTION);
        } else {
            addToSpliceQueue(new SpliceFdTask(ch, offset, len, promise));
            failSpliceIfClosed(promise);
        }
        return promise;
    }"
"public final Future<List<DnsRecord>> resolveAll(DnsQuestion question, Iterable<DnsRecord> additionals) {
        return resolveAll(question, additionals, executor().<List<DnsRecord>>newPromise());
    }"
"protected void closeWatchService() {
        try {
            getWatchService().close();
        } catch (IOException e) {
            if (LOG.isErrorEnabled()) {
                LOG.error(""Error stopping file watch service: "" + e.getMessage(), e);
            }
        }
    }"
"private ChannelFuture goAway(ChannelHandlerContext ctx, Http2Exception cause, ChannelPromise promise) {
        long errorCode = cause != null ? cause.error().code() : NO_ERROR.code();
        int lastKnownStream = connection().remote().lastStreamCreated();
        return goAway(ctx, lastKnownStream, errorCode, Http2CodecUtil.toByteBuf(ctx, cause), promise);
    }"
"protected static int[] adaptForTensorDescr(int[] shapeOrStrides){
        if(shapeOrStrides.length >= 4)
            return shapeOrStrides;
        int[] out = new int[4];
        int i=0;
        for(; i<shapeOrStrides.length; i++ ){
            out[i] = shapeOrStrides[i];
        }
        for(; i<4; i++ ){
            out[i] = 1;
        }
        return out;
    }"
"private void closeSessionAndCreateAndOpenUntitledDb() throws Exception {
        getExtensionLoader().sessionAboutToChangeAllPlugin(null);
        model.closeSession();
        log.info(""Create and Open Untitled Db"");
        model.createAndOpenUntitledDb();
    }"
"public GroupedMap putAll(String group, Map<? extends String, ? extends String> m) {
		for (Entry<? extends String, ? extends String> entry : m.entrySet()) {
			this.put(group, entry.getKey(), entry.getValue());
		}
		return this;
	}"
"public static Context current() {
    Context current = storage().current();
    if (current == null) {
      return ROOT;
    }
    return current;
  }"
"@VisibleForTesting
	public boolean onlyKeyExists(String name) {
		String[] names = handleDeprecation(deprecationContext.get(), name);
		for(String n : names) {
			if ( getProps().getProperty(n,DEFAULT_STRING_CHECK)
					.equals(DEFAULT_STRING_CHECK) ) {
				return true;
			}
		}
		return false;
	}"
"public static void main(final String[] args) {
		EnvironmentInformation.logEnvironmentInfo(LOG, ""Command Line Client"", args);

		// 1. find the configuration directory
		final String configurationDirectory = getConfigurationDirectoryFromEnv();

		// 2. load the global configuration
		final Configuration configuration = GlobalConfiguration.loadConfiguration(configurationDirectory);

		// 3. load the custom command lines
		final List<CustomCommandLine<?>> customCommandLines = loadCustomCommandLines(
			configuration,
			configurationDirectory);

		try {
			final CliFrontend cli = new CliFrontend(
				configuration,
				customCommandLines);

			SecurityUtils.install(new SecurityConfiguration(cli.configuration));
			int retCode = SecurityUtils.getInstalledContext()
					.runSecured(() -> cli.parseParameters(args));
			System.exit(retCode);
		}
		catch (Throwable t) {
			final Throwable strippedThrowable = ExceptionUtils.stripException(t, UndeclaredThrowableException.class);
			LOG.error(""Fatal error while running command line interface."", strippedThrowable);
			strippedThrowable.printStackTrace();
			System.exit(31);
		}
	}"
"protected static List<Pinyin> segLongest(char[] charArray, AhoCorasickDoubleArrayTrie<Pinyin[]> trie)
    {
        return segLongest(charArray, trie, true);
    }"
"public static INDArrayIndex[] allFor(INDArray arr) {
        INDArrayIndex[] ret = new INDArrayIndex[arr.rank()];
        for (int i = 0; i < ret.length; i++)
            ret[i] = NDArrayIndex.all();

        return ret;
    }"
"@Restricted(NoExternalUse.class)
    public static String loadJSON(URL src) throws IOException {
        URLConnection con = ProxyConfiguration.open(src);
        if (con instanceof HttpURLConnection) {
            // prevent problems from misbehaving plugins disabling redirects by default
            ((HttpURLConnection) con).setInstanceFollowRedirects(true);
        }
        try (InputStream is = con.getInputStream()) {
            String jsonp = IOUtils.toString(is, ""UTF-8"");
            int start = jsonp.indexOf('{');
            int end = jsonp.lastIndexOf('}');
            if (start >= 0 && end > start) {
                return jsonp.substring(start, end + 1);
            } else {
                throw new IOException(""Could not find JSON in "" + src);
            }
        }
    }"
"public static String createNonce() {
        val fmtDate = ZonedDateTime.now(ZoneOffset.UTC).toString();
        val rand = RandomUtils.getNativeInstance();
        val randomInt = rand.nextInt();
        return DigestUtils.md5Hex(fmtDate + randomInt);
    }"
"@ShellMethod(key = ""generate-key"", value = ""Generate signing/encryption crypto keys for CAS settings"")
    public void generateKey(@ShellOption(value = {""key-size""},
        defaultValue = ""256"", help = ""Key size"") final int keySize) {
        LOGGER.info(EncodingUtils.generateJsonWebKey(keySize));
    }"
"public static void showWarningMessageAddOnsNotRunnable(
            String message,
            AddOnCollection availableAddOns,
            Collection<AddOn> addOnsNotRunnable) {

        Object[] msgs = {
                message,
                createScrollableTreeAddOnsNotRunnable(
                        availableAddOns,
                        addOnsNotRunnable.toArray(new AddOn[addOnsNotRunnable.size()])) };

        JOptionPane.showMessageDialog(
                View.getSingleton().getMainFrame(),
                msgs,
                Constant.PROGRAM_NAME,
                JOptionPane.WARNING_MESSAGE);
    }"
"protected Authentication extractCredentials(HttpServletRequest request) {
		String grantType = request.getParameter(""grant_type"");
		if (grantType != null && grantType.equals(""password"")) {
			UsernamePasswordAuthenticationToken result = new UsernamePasswordAuthenticationToken(
					request.getParameter(""username""), request.getParameter(""password""));
			result.setDetails(authenticationDetailsSource.buildDetails(request));
			return result;
		}
		return null;
	}"
"public ComputerLauncher getDelegatedLauncher() {
        ComputerLauncher l = launcher;
        while (true) {
            if (l instanceof DelegatingComputerLauncher) {
                l = ((DelegatingComputerLauncher) l).getLauncher();
            } else if (l instanceof ComputerLauncherFilter) {
                l = ((ComputerLauncherFilter) l).getCore();
            } else {
                break;
            }
        }
        return l;
    }"
"private static InjectionPattern getInjectionPattern(String contents) {
        if (contents == null || contents.trim().equals("""")) {
            return null;
        }
        InjectionPattern injectionPattern = new InjectionPattern();
        contents = contents.trim();
        // Retrieve key, default value and error text
        String[] array = contents.split("":"", 2);
        array[0] = array[0].trim();
        if ("""".equals(array[0])) {
            return null;
        }
        // Set key of the injectionPattern
        injectionPattern.setKey(array[0]);
        if (array.length == 2) {
            // Adding space after colon is enabled, so trim is needed
            array[1] = array[1].trim();
            // Set error text
            if (array[1].startsWith(""?"")) {
                injectionPattern.setErrorText(array[1].substring(1));
            } else if (array[1].startsWith(""$"")) {
                // Skip this injection when ""$"" is only character found after the "":""
                if (array[1].length() == 1) {
                    injectionPattern.setDefaultValue(""\\$\\{"" + array[0] + ""\\}"");
                    // Otherwise, treat as a default value
                    // Add ""\\"" since $ is a special character
                } else {
                    injectionPattern.setDefaultValue(""\\"" + array[1]);
                }
                // Set default value
            } else {
                injectionPattern.setDefaultValue(array[1]);
            }
        }
        return injectionPattern;
    }"
"public Spider addUrl(String... urls) {
        for (String url : urls) {
            addRequest(new Request(url));
        }
        signalNewUrl();
        return this;
    }"
"@Deprecated
	public FSDataOutputStream create(Path f, boolean overwrite) throws IOException {
		return create(f, overwrite ? WriteMode.OVERWRITE : WriteMode.NO_OVERWRITE);
	}"
"public static String[] isValidCard10(String idCard) {
		if(StrUtil.isBlank(idCard)) {
			return null;
		}
		String[] info = new String[3];
		String card = idCard.replaceAll(""[\\(|\\)]"", """");
		if (card.length() != 8 && card.length() != 9 && idCard.length() != 10) {
			return null;
		}
		if (idCard.matches(""^[a-zA-Z][0-9]{9}$"")) { // 台湾
			info[0] = ""台湾"";
			String char2 = idCard.substring(1, 2);
			if (char2.equals(""1"")) {
				info[1] = ""M"";
			} else if (char2.equals(""2"")) {
				info[1] = ""F"";
			} else {
				info[1] = ""N"";
				info[2] = ""false"";
				return info;
			}
			info[2] = isValidTWCard(idCard) ? ""true"" : ""false"";
		} else if (idCard.matches(""^[1|5|7][0-9]{6}\\(?[0-9A-Z]\\)?$"")) { // 澳门
			info[0] = ""澳门"";
			info[1] = ""N"";
		} else if (idCard.matches(""^[A-Z]{1,2}[0-9]{6}\\(?[0-9A]\\)?$"")) { // 香港
			info[0] = ""香港"";
			info[1] = ""N"";
			info[2] = isValidHKCard(idCard) ? ""true"" : ""false"";
		} else {
			return null;
		}
		return info;
	}"
"@View(name = ""by_createdDate"", map = ""function(doc) { if(doc.record && doc.createdDate && doc.username) { emit(doc.createdDate, doc) } }"")
    public List<CouchDbU2FDeviceRegistration> findByDateBefore(final LocalDate expirationDate) {
        return db.queryView(createQuery(""by_createdDate"").endKey(expirationDate), CouchDbU2FDeviceRegistration.class);
    }"
"public boolean hasNext() {
    synchronized (lock) {
      try {
        return parser.peek() != JsonToken.END_DOCUMENT;
      } catch (MalformedJsonException e) {
        throw new JsonSyntaxException(e);
      } catch (IOException e) {
        throw new JsonIOException(e);
      }
    }
  }"
"@PublicEvolving
	public double getDouble(ConfigOption<Double> configOption, double overrideDefault) {
		Object o = getRawValueFromOption(configOption);
		if (o == null) {
			return overrideDefault;
		}
		return convertToDouble(o, configOption.defaultValue());
	}"
"public static String emptyToNull(String string) {
    return string == null || string.isEmpty() ? null : string;
  }"
"public static WatchMonitor createModify(File file, int maxDepth, Watcher watcher) {
		return createModify(file.toPath(), 0, watcher);
	}"
"@SuppressWarnings(""unchecked"")
  public void setExpiryFactory(Optional<Factory<? extends Expiry<K, V>>> factory) {
    expiryFactory = (Factory<Expiry<K, V>>) factory.orElse(null);
  }"
"public static MappedByteBufferHandler map(File file) throws IOException
  {
    MappedByteBuffer mappedByteBuffer = Files.map(file);
    return new MappedByteBufferHandler(mappedByteBuffer);
  }"
"public Postcard withLong(@Nullable String key, long value) {
        mBundle.putLong(key, value);
        return this;
    }"
"static TreeProperties convertSharedTreeSubgraph(final SharedTreeSubgraph sharedTreeSubgraph) {
        Objects.requireNonNull(sharedTreeSubgraph);

        final TreeProperties treeprops = new TreeProperties();

        treeprops._leftChildren = MemoryManager.malloc4(sharedTreeSubgraph.nodesArray.size());
        treeprops._rightChildren = MemoryManager.malloc4(sharedTreeSubgraph.nodesArray.size());
        treeprops._descriptions = new String[sharedTreeSubgraph.nodesArray.size()];
        treeprops._thresholds = MemoryManager.malloc4f(sharedTreeSubgraph.nodesArray.size());
        treeprops._features = new String[sharedTreeSubgraph.nodesArray.size()];
        treeprops._nas = new String[sharedTreeSubgraph.nodesArray.size()];
        treeprops._predictions = MemoryManager.malloc4f(sharedTreeSubgraph.nodesArray.size());

        // Set root node's children, there is no guarantee the root node will be number 0
        treeprops._rightChildren[0] = sharedTreeSubgraph.rootNode.getRightChild() != null ? sharedTreeSubgraph.rootNode.getRightChild().getNodeNumber() : -1;
        treeprops._leftChildren[0] = sharedTreeSubgraph.rootNode.getLeftChild() != null ? sharedTreeSubgraph.rootNode.getLeftChild().getNodeNumber() : -1;
        treeprops._thresholds[0] = sharedTreeSubgraph.rootNode.getSplitValue();
        treeprops._features[0] = sharedTreeSubgraph.rootNode.getColName();
        treeprops._nas[0] = getNaDirection(sharedTreeSubgraph.rootNode);
        treeprops.levels = new int[sharedTreeSubgraph.nodesArray.size()][];

        List<SharedTreeNode> nodesToTraverse = new ArrayList<>();
        nodesToTraverse.add(sharedTreeSubgraph.rootNode);
        append(treeprops._rightChildren, treeprops._leftChildren,
                treeprops._descriptions, treeprops._thresholds, treeprops._features, treeprops._nas,
                treeprops.levels, treeprops._predictions, nodesToTraverse, -1, false);

        return treeprops;
    }"
"@Override
    public void rnnSetPreviousState(Map<String, INDArray> stateMap) {
        this.stateMap.clear();
        this.stateMap.putAll(stateMap);
    }"
"public static Optional<Set<Symbol>> pruneInputs(Collection<Symbol> availableInputs, Collection<Expression> expressions)
    {
        Set<Symbol> availableInputsSet = ImmutableSet.copyOf(availableInputs);
        Set<Symbol> prunedInputs = Sets.filter(availableInputsSet, SymbolsExtractor.extractUnique(expressions)::contains);

        if (prunedInputs.size() == availableInputsSet.size()) {
            return Optional.empty();
        }

        return Optional.of(prunedInputs);
    }"
"@SuppressWarnings(""deprecation"")
    public final void doBuildWithParameters(StaplerRequest req, StaplerResponse rsp, @QueryParameter TimeDuration delay) throws IOException, ServletException {
        hudson.model.BuildAuthorizationToken.checkPermission(asJob(), asJob().getAuthToken(), req, rsp);

        ParametersDefinitionProperty pp = asJob().getProperty(ParametersDefinitionProperty.class);
        if (!asJob().isBuildable()) {
            throw HttpResponses.error(SC_CONFLICT, new IOException(asJob().getFullName() + "" is not buildable!""));
        }
        if (pp != null) {
            pp.buildWithParameters(req, rsp, delay);
        } else {
            throw new IllegalStateException(""This build is not parameterized!"");
        }
    }"
"public static ReadOnlyHttp2Headers clientHeaders(boolean validateHeaders,
                                                     AsciiString method, AsciiString path,
                                                     AsciiString scheme, AsciiString authority,
                                                     AsciiString... otherHeaders) {
        return new ReadOnlyHttp2Headers(validateHeaders,
                new AsciiString[] {
                  PseudoHeaderName.METHOD.value(), method, PseudoHeaderName.PATH.value(), path,
                  PseudoHeaderName.SCHEME.value(), scheme, PseudoHeaderName.AUTHORITY.value(), authority
                },
                otherHeaders);
    }"
"public File writeToStream(OutputStream out) throws IORuntimeException {
		FileInputStream in = null;
		try {
			in = new FileInputStream(file);
			IoUtil.copy(in, out);
		}catch (IOException e) {
			throw new IORuntimeException(e);
		} finally {
			IoUtil.close(in);
		}
		return this.file;
	}"
"public static String[] getTypeStrs(Class[] types, boolean javaStyle) {
        if (CommonUtils.isEmpty(types)) {
            return StringUtils.EMPTY_STRING_ARRAY;
        } else {
            String[] strings = new String[types.length];
            for (int i = 0; i < types.length; i++) {
                strings[i] = javaStyle ? types[i].getName() : getTypeStr(types[i]);
            }
            return strings;
        }
    }"
"public boolean saveNGramToTxt(String path)
    {
        try
        {
            BufferedWriter bw = new BufferedWriter(new OutputStreamWriter(IOUtil.newOutputStream(path)));
            for (Map.Entry<String, Integer> entry : trie.entrySet())
            {
                bw.write(entry.getKey() + "" "" + entry.getValue());
                bw.newLine();
            }
            bw.close();
        }
        catch (Exception e)
        {
            logger.warning(""在保存NGram词典到"" + path + ""时发生异常"" + e);
            return false;
        }

        return true;
    }"
"public static boolean cleanDirectory(File dir) {
        if (dir.isDirectory()) {
            String[] children = dir.list();
            if (children != null) {
                for (String aChildren : children) {
                    boolean success = cleanDirectory(new File(dir, aChildren));
                    if (!success) {
                        return false;
                    }
                }
            }
        }
        return dir.delete();
    }"
"public <X> DataSource<X> fromParallelCollection(SplittableIterator<X> iterator, Class<X> type) {
		return fromParallelCollection(iterator, TypeExtractor.getForClass(type));
	}"
"@Override
    protected void register(ServiceInstance instance) {
        // step 1 get domain from config
        // set service from config
        // check if service exists
        // register service if not
        // register instance to service

        Map<String, String> instanceAttributes = new HashMap<>();

        // you can't just put anything in there like a custom config. Only certain things are allowed or you get weird errors
        // see https://docs.aws.amazon.com/Route53/latest/APIReference/API_autonaming_RegisterInstance.html
        //if the service uses A records use these
        if (instance.getPort() > 0) {
            instanceAttributes.put(""AWS_INSTANCE_PORT"", Integer.toString(instance.getPort()));
        }
        if (amazonComputeInstanceMetadataResolver != null) {
            Optional<ComputeInstanceMetadata> instanceMetadata = amazonComputeInstanceMetadataResolver.resolve(environment);
            if (instanceMetadata.isPresent()) {
                ComputeInstanceMetadata computeInstanceMetadata = instanceMetadata.get();
                if (computeInstanceMetadata.getPublicIpV4() != null) {
                    instanceAttributes.put(AWS_INSTANCE_IPV4, computeInstanceMetadata.getPublicIpV4());
                } else {
                    if (computeInstanceMetadata.getPrivateIpV4() != null) {
                        instanceAttributes.put(AWS_INSTANCE_IPV4, computeInstanceMetadata.getPrivateIpV4());
                    }
                }

                if (!instanceAttributes.containsKey(AWS_INSTANCE_IPV4)) {
                    // try ip v6
                    if (computeInstanceMetadata.getPublicIpV4() != null) {
                        instanceAttributes.put(AWS_INSTANCE_IPV6, computeInstanceMetadata.getPublicIpV6());
                    } else {
                        if (computeInstanceMetadata.getPrivateIpV6() != null) {
                            instanceAttributes.put(AWS_INSTANCE_IPV6, computeInstanceMetadata.getPrivateIpV6());
                        }
                    }
                }
            }
        }


        ConvertibleValues<String> metadata = instance.getMetadata();

        String instanceId = null;
        if (instance.getInstanceId().isPresent()) {
            instanceId = instance.getInstanceId().get();
        } else {
            // try the metadata
            if (metadata.contains(""instanceId"")) {
                instanceId = metadata.asMap().get(""instanceId"");
            } else {
                if (LOG.isErrorEnabled()) {
                    LOG.error(""Cannot determine the instance ID. Are you sure you are running on AWS EC2?"");
                }
            }
        }
        RegisterInstanceRequest instanceRequest = new RegisterInstanceRequest().withServiceId(route53AutoRegistrationConfiguration.getAwsServiceId())
                .withInstanceId(instanceId).withCreatorRequestId(Long.toString(System.nanoTime())).withAttributes(instanceAttributes);

        Future<RegisterInstanceResult> instanceResult = getDiscoveryClient().registerInstanceAsync(instanceRequest);
        Flowable<RegisterInstanceResult> flowableResult = Flowable.fromFuture(instanceResult);


        //noinspection SubscriberImplementation
        flowableResult.subscribe(new Subscriber<RegisterInstanceResult>() {

            @Override
            public void onNext(RegisterInstanceResult registerInstanceResult) {
                if (LOG.isInfoEnabled()) {
                    LOG.info(""Called AWS to register service [{}] with {}"", instance.getId(), route53AutoRegistrationConfiguration.getAwsServiceId());
                }
                if (registerInstanceResult.getOperationId() != null) {
                    ServiceRegistrationStatusTask serviceRegistrationStatusTask = new ServiceRegistrationStatusTask(getDiscoveryClient(),
                            route53AutoRegistrationConfiguration,
                            instance,
                            registerInstanceResult.getOperationId());
                    executorService.execute(serviceRegistrationStatusTask);
                }

            }

            @Override
            public void onSubscribe(Subscription s) {
                s.request(1);
            }

            @Override
            public void onError(Throwable t) {
                if (LOG.isErrorEnabled()) {
                    LOG.error(""Error registering instance with AWS:"" + t.getMessage(), t);
                }
                if (route53AutoRegistrationConfiguration.isFailFast() && instance instanceof EmbeddedServerInstance) {
                    LOG.error(""Error registering instance with AWS and Failfast is set: stopping instance"");
                    ((EmbeddedServerInstance) instance).getEmbeddedServer().stop();
                }
            }

            @Override
            public void onComplete() {
                if (LOG.isInfoEnabled()) {
                    LOG.info(""Success calling register service request [{}] with {} is complete."", instance.getId(),
                            route53AutoRegistrationConfiguration.getAwsServiceId());
                }
            }
        });

    }"
"@Override
	public <PT> HashTableProber<PT> getProber(TypeComparator<PT> probeSideComparator, TypePairComparator<PT, T> pairComparator) {
		return new HashTableProber<PT>(probeSideComparator, pairComparator);
	}"
"public static String encrypt(CharSequence data, CharSequence cipherKey) {
		final int dataLen = data.length();
		final int cipherKeyLen = cipherKey.length();

		final char[] cipherArray = new char[dataLen];
		for (int i = 0; i < dataLen / cipherKeyLen + 1; i++) {
			for (int t = 0; t < cipherKeyLen; t++) {
				if (t + i * cipherKeyLen < dataLen) {
					final char dataChar = data.charAt(t + i * cipherKeyLen);
					final char cipherKeyChar = cipherKey.charAt(t);
					cipherArray[t + i * cipherKeyLen] = (char) ((dataChar + cipherKeyChar - 64) % 95 + 32);
				}
			}
		}

		return String.valueOf(cipherArray);
	}"
"private static DataSet<Tuple2<String, String>> getDocumentsDataSet(ExecutionEnvironment env, ParameterTool params) {
		// Create DataSet for documents relation (URL, Doc-Text)
		if (params.has(""documents"")) {
			return env.readCsvFile(params.get(""documents""))
						.fieldDelimiter(""|"")
						.types(String.class, String.class);
		} else {
			System.out.println(""Executing WebLogAnalysis example with default documents data set."");
			System.out.println(""Use --documents to specify file input."");
			return WebLogData.getDocumentDataSet(env);
		}
	}"
"public Class compile(String sCode, String sName) {
        GroovyClassLoader loader = getGroovyClassLoader();
        LOG.warn(""Compiling filter: "" + sName);
        Class groovyClass = loader.parseClass(sCode, sName);
        return groovyClass;
    }"
"@Override
  public SessionHandle openSession(String username, String password,
      Map<String, String> configuration) throws HiveSQLException {
    return cliService.openSession(username, password, configuration);
  }"
"@WithBridgeMethods(Future.class)
    public QueueTaskFuture<R> scheduleBuild2(int quietPeriod, Cause c) {
        return scheduleBuild2(quietPeriod, c, new Action[0]);
    }"
"protected int getIntMethodParam(String methodName, String paramKey, int defaultValue) {
        if (CommonUtils.isEmpty(configContext)) {
            return defaultValue;
        }
        Integer o = (Integer) configContext.get(buildMethodKey(methodName, paramKey));
        if (o == null) {
            o = (Integer) configContext.get(paramKey);
            return o == null ? defaultValue : o;
        } else {
            return o;
        }
    }"
"public void materializeVariable(MutableReader<?> reader, TypeSerializerFactory<?> serializerFactory, BatchTask<?, ?> referenceHolder)
			throws MaterializationExpiredException, IOException {
		Preconditions.checkNotNull(reader);
		Preconditions.checkNotNull(serializerFactory);
		Preconditions.checkNotNull(referenceHolder);

		final boolean materializer;

		// hold the reference lock only while we track references and decide who should be the materializer
		// that way, other tasks can de-register (in case of failure) while materialization is happening
		synchronized (references) {
			if (disposed) {
				throw new MaterializationExpiredException();
			}

			// sanity check
			if (!references.add(referenceHolder)) {
				throw new IllegalStateException(
						String.format(""The task %s already holds a reference to the broadcast variable %s."",
								referenceHolder.getEnvironment().getTaskInfo().getTaskNameWithSubtasks(),
								key.toString()));
			}

			materializer = references.size() == 1;
		}

		try {
			@SuppressWarnings(""unchecked"")
			final MutableReader<DeserializationDelegate<T>> typedReader = (MutableReader<DeserializationDelegate<T>>) reader;

			@SuppressWarnings(""unchecked"")
			final TypeSerializer<T> serializer = ((TypeSerializerFactory<T>) serializerFactory).getSerializer();

			final ReaderIterator<T> readerIterator = new ReaderIterator<T>(typedReader, serializer);

			if (materializer) {
				// first one, so we need to materialize;
				if (LOG.isDebugEnabled()) {
					LOG.debug(""Getting Broadcast Variable ("" + key + "") - First access, materializing."");
				}

				ArrayList<T> data = new ArrayList<T>();

				T element;
				while ((element = readerIterator.next()) != null) {
					data.add(element);
				}

				synchronized (materializationMonitor) {
					this.data = data;
					this.materialized = true;
					materializationMonitor.notifyAll();
				}

				if (LOG.isDebugEnabled()) {
					LOG.debug(""Materialization of Broadcast Variable ("" + key + "") finished."");
				}
			}
			else {
				// successor: discard all data and refer to the shared variable

				if (LOG.isDebugEnabled()) {
					LOG.debug(""Getting Broadcast Variable ("" + key + "") - shared access."");
				}

				T element = serializer.createInstance();
				while ((element = readerIterator.next(element)) != null) {
				}

				synchronized (materializationMonitor) {
					while (!this.materialized && !disposed) {
						materializationMonitor.wait();
					}
				}

			}
		}
		catch (Throwable t) {
			// in case of an exception, we need to clean up big time
			decrementReferenceIfHeld(referenceHolder);

			if (t instanceof IOException) {
				throw (IOException) t;
			} else {
				throw new IOException(""Materialization of the broadcast variable failed."", t);
			}
		}
	}"
"protected String getAuthorizationCodeString(byte[] verifierBytes) {
		char[] chars = new char[verifierBytes.length];
		for (int i = 0; i < verifierBytes.length; i++) {
			chars[i] = DEFAULT_CODEC[((verifierBytes[i] & 0xFF) % DEFAULT_CODEC.length)];
		}
		return new String(chars);
	}"
"private void followRedirections(HttpMessage message, HttpRequestConfig requestConfig) throws IOException {
        HttpRedirectionValidator validator = requestConfig.getRedirectionValidator();
        validator.notifyMessageReceived(message);

        User requestingUser = getUser(message);
        HttpMessage redirectMessage = message;
        int maxRedirections = client.getParams().getIntParameter(HttpClientParams.MAX_REDIRECTS, 100);
        for (int i = 0; i < maxRedirections && isRedirectionNeeded(redirectMessage.getResponseHeader().getStatusCode()); i++) {
            URI newLocation = extractRedirectLocation(redirectMessage);
            if (newLocation == null || !validator.isValid(newLocation)) {
                return;
            }

            redirectMessage = redirectMessage.cloneAll();
            redirectMessage.setRequestingUser(requestingUser);
            redirectMessage.getRequestHeader().setURI(newLocation);

            if (isRequestRewriteNeeded(redirectMessage)) {
                redirectMessage.getRequestHeader().setMethod(HttpRequestHeader.GET);
                redirectMessage.getRequestHeader().setHeader(HttpHeader.CONTENT_TYPE, null);
                redirectMessage.getRequestHeader().setHeader(HttpHeader.CONTENT_LENGTH, null);
                redirectMessage.setRequestBody("""");
            }

            sendAndReceiveImpl(redirectMessage, requestConfig);
            validator.notifyMessageReceived(redirectMessage);

            // Update the response of the (original) message
            message.setResponseHeader(redirectMessage.getResponseHeader());
            message.setResponseBody(redirectMessage.getResponseBody());
        }
    }"
"public void remove(final Task task)
  {
    giant.lock();
    try {
      try {
        log.info(""Removing task[%s] from activeTasks"", task.getId());
        for (final TaskLockPosse taskLockPosse : findLockPossesForTask(task)) {
          unlock(task, taskLockPosse.getTaskLock().getInterval());
        }
      }
      finally {
        activeTasks.remove(task.getId());
      }
    }
    finally {
      giant.unlock();
    }
  }"
"public void runPendingTasks() {
        try {
            loop.runTasks();
        } catch (Exception e) {
            recordException(e);
        }

        try {
            loop.runScheduledTasks();
        } catch (Exception e) {
            recordException(e);
        }
    }"
"public void create(final DataMatrix matrix) {
        Assert.assertNotNull(matrix);
        transactionTemplate.execute(new TransactionCallbackWithoutResult() {

            protected void doInTransactionWithoutResult(TransactionStatus status) {

                try {
                    DataMatrixDO matrixlDO = modelToDo(matrix);
                    matrixlDO.setId(0L);
                    if (!dataMatrixDao.checkUnique(matrixlDO)) {
                        String exceptionCause = ""exist the same repeat canal in the database."";
                        logger.warn(""WARN ## "" + exceptionCause);
                        throw new RepeatConfigureException(exceptionCause);
                    }
                    dataMatrixDao.insert(matrixlDO);
                } catch (RepeatConfigureException rce) {
                    throw rce;
                } catch (Exception e) {
                    logger.error(""ERROR ## create canal has an exception!"");
                    throw new ManagerException(e);
                }
            }
        });
    }"
"ServerResponse respond(ClientChallenge clientChallenge)
    throws GeneralSecurityException {

    SecretKeySpec authKey = generateKey(clientChallenge.kdf, clientChallenge.iterations,
      clientChallenge.nonce, clientChallenge.keyLength);
    initializeForAuth(clientChallenge.cipher, clientChallenge.nonce, authKey);

    byte[] challenge = validateChallenge(clientChallenge.nonce, clientChallenge.challenge);
    byte[] response = challenge(appId, clientChallenge.nonce, rawResponse(challenge));
    byte[] sessionNonce = randomBytes(conf.encryptionKeyLength() / Byte.SIZE);
    byte[] inputIv = randomBytes(conf.ivLength());
    byte[] outputIv = randomBytes(conf.ivLength());

    SecretKeySpec sessionKey = generateKey(clientChallenge.kdf, clientChallenge.iterations,
      sessionNonce, clientChallenge.keyLength);
    this.sessionCipher = new TransportCipher(cryptoConf, clientChallenge.cipher, sessionKey,
      inputIv, outputIv);

    // Note the IVs are swapped in the response.
    return new ServerResponse(response, encrypt(sessionNonce), encrypt(outputIv), encrypt(inputIv));
  }"
"public static long zip(File directory, OutputStream out) throws IOException
  {
    if (!directory.isDirectory()) {
      throw new IOE(""directory[%s] is not a directory"", directory);
    }

    final ZipOutputStream zipOut = new ZipOutputStream(out);

    long totalSize = 0;
    for (File file : directory.listFiles()) {
      log.info(""Adding file[%s] with size[%,d].  Total size so far[%,d]"", file, file.length(), totalSize);
      if (file.length() > Integer.MAX_VALUE) {
        zipOut.finish();
        throw new IOE(""file[%s] too large [%,d]"", file, file.length());
      }
      zipOut.putNextEntry(new ZipEntry(file.getName()));
      totalSize += Files.asByteSource(file).copyTo(zipOut);
    }
    zipOut.closeEntry();
    // Workaround for http://hg.openjdk.java.net/jdk8/jdk8/jdk/rev/759aa847dcaf
    zipOut.flush();
    zipOut.finish();

    return totalSize;
  }"
"@Override
    public MeasureModel buildMeasureModel(InvocationStat invocationStat) {
        InvocationStatDimension statDimension = invocationStat.getDimension();
        String key = statDimension.getDimensionKey();
        MeasureModel measureModel = appServiceMeasureModels.get(key);
        if (measureModel == null) {
            measureModel = new MeasureModel(statDimension.getAppName(), statDimension.getService());
            MeasureModel oldMeasureModel = appServiceMeasureModels.putIfAbsent(key, measureModel);
            if (oldMeasureModel == null) {
                measureModel.addInvocationStat(invocationStat);
                return measureModel;
            } else {
                oldMeasureModel.addInvocationStat(invocationStat);
                return null;
            }
        } else {
            measureModel.addInvocationStat(invocationStat);
            return null;
        }
    }"
"@Deprecated
    public FormValidation doViewExistsCheck(@QueryParameter String value) {
        checkPermission(View.CREATE);

        String view = fixEmpty(value);
        if(view==null) return FormValidation.ok();

        if(getView(view)==null)
            return FormValidation.ok();
        else
            return FormValidation.error(Messages.Hudson_ViewAlreadyExists(view));
    }"
"@Override protected double[] score0(double[] data, double[] preds, double offset, int ntrees) {
    super.score0(data, preds, offset, ntrees);
    if (ntrees >= 1) preds[1] = preds[0] / ntrees;
    preds[0] = normalizePathLength(preds[0]);
    return preds;
  }"
"public static List<String> execForLines(Charset charset, String... cmds) throws IORuntimeException {
		return getResultLines(exec(cmds), charset);
	}"
"@SuppressWarnings(""InnerAssignment"")
    private void quickSort(PagesIndex pagesIndex, int from, int to)
    {
        int len = to - from;
        // Insertion sort on smallest arrays
        if (len < SMALL) {
            for (int i = from; i < to; i++) {
                for (int j = i; j > from && (comparator.compareTo(pagesIndex, j - 1, j) > 0); j--) {
                    pagesIndex.swap(j, j - 1);
                }
            }
            return;
        }

        // Choose a partition element, v
        int m = from + len / 2; // Small arrays, middle element
        if (len > SMALL) {
            int l = from;
            int n = to - 1;
            if (len > MEDIUM) { // Big arrays, pseudomedian of 9
                int s = len / 8;
                l = median3(pagesIndex, l, l + s, l + 2 * s);
                m = median3(pagesIndex, m - s, m, m + s);
                n = median3(pagesIndex, n - 2 * s, n - s, n);
            }
            m = median3(pagesIndex, l, m, n); // Mid-size, med of 3
        }
        // int v = x[m];

        int a = from;
        int b = a;
        int c = to - 1;
        // Establish Invariant: v* (<v)* (>v)* v*
        int d = c;
        while (true) {
            int comparison;
            while (b <= c && ((comparison = comparator.compareTo(pagesIndex, b, m)) <= 0)) {
                if (comparison == 0) {
                    if (a == m) {
                        m = b; // moving target; DELTA to JDK !!!
                    }
                    else if (b == m) {
                        m = a; // moving target; DELTA to JDK !!!
                    }
                    pagesIndex.swap(a++, b);
                }
                b++;
            }
            while (c >= b && ((comparison = comparator.compareTo(pagesIndex, c, m)) >= 0)) {
                if (comparison == 0) {
                    if (c == m) {
                        m = d; // moving target; DELTA to JDK !!!
                    }
                    else if (d == m) {
                        m = c; // moving target; DELTA to JDK !!!
                    }
                    pagesIndex.swap(c, d--);
                }
                c--;
            }
            if (b > c) {
                break;
            }
            if (b == m) {
                m = d; // moving target; DELTA to JDK !!!
            }
            else if (c == m) {
                m = c; // moving target; DELTA to JDK !!!
            }
            pagesIndex.swap(b++, c--);
        }

        // Swap partition elements back to middle
        int s;
        int n = to;
        s = Math.min(a - from, b - a);
        vectorSwap(pagesIndex, from, b - s, s);
        s = Math.min(d - c, n - d - 1);
        vectorSwap(pagesIndex, b, n - s, s);

        // Recursively sort non-partition-elements
        if ((s = b - a) > 1) {
            quickSort(pagesIndex, from, from + s);
        }
        if ((s = d - c) > 1) {
            quickSort(pagesIndex, n - s, n);
        }
    }"
"@Override
	public void configure(Configuration parameters) {

		if (getFilePaths().length == 0) {
			// file path was not specified yet. Try to set it from the parameters.
			String filePath = parameters.getString(FILE_PARAMETER_KEY, null);
			if (filePath == null) {
				throw new IllegalArgumentException(""File path was not specified in input format or configuration."");
			} else {
				setFilePath(filePath);
			}
		}

		if (!this.enumerateNestedFiles) {
			this.enumerateNestedFiles = parameters.getBoolean(ENUMERATE_NESTED_FILES_FLAG, false);
		}
	}"
"public KeyedStream<T, Tuple> keyBy(int... fields) {
		if (getType() instanceof BasicArrayTypeInfo || getType() instanceof PrimitiveArrayTypeInfo) {
			return keyBy(KeySelectorUtil.getSelectorForArray(fields, getType()));
		} else {
			return keyBy(new Keys.ExpressionKeys<>(fields, getType()));
		}
	}"
"public static <C, A> Callbacks<C, A> callbacks(Class<C> callbackType,
			Collection<? extends C> callbackInstances, A argument,
			Object... additionalArguments) {
		Assert.notNull(callbackType, ""CallbackType must not be null"");
		Assert.notNull(callbackInstances, ""CallbackInstances must not be null"");
		return new Callbacks<>(callbackType, callbackInstances, argument,
				additionalArguments);
	}"
"public WebDriver build() {
    if (options.isEmpty() && additionalCapabilities.isEmpty()) {
      throw new SessionNotCreatedException(""Refusing to create session without any capabilities"");
    }

    Plan plan = getPlan();

    CommandExecutor executor;
    if (plan.isUsingDriverService()) {
      AtomicReference<DriverService> serviceRef = new AtomicReference<>();

      executor = new SpecCompliantExecutor(
          () -> {
            if (serviceRef.get() != null && serviceRef.get().isRunning()) {
              throw new SessionNotCreatedException(
                  ""Attempt to start the underlying service more than once"");
            }
            try {
              DriverService service = plan.getDriverService();
              serviceRef.set(service);
              service.start();
              return service.getUrl();
            } catch (IOException e) {
              throw new SessionNotCreatedException(e.getMessage(), e);
            }
          },
          plan::writePayload,
          () -> serviceRef.get().stop());
    } else {
      executor = new SpecCompliantExecutor(() -> remoteHost, plan::writePayload, () -> {});
    }

    return new RemoteWebDriver(executor, new ImmutableCapabilities());
  }"
"public void beginArray() throws IOException {
    int p = peeked;
    if (p == PEEKED_NONE) {
      p = doPeek();
    }
    if (p == PEEKED_BEGIN_ARRAY) {
      push(JsonScope.EMPTY_ARRAY);
      pathIndices[stackSize - 1] = 0;
      peeked = PEEKED_NONE;
    } else {
      throw new IllegalStateException(""Expected BEGIN_ARRAY but was "" + peek() + locationString());
    }
  }"
"public List<InterfaceHttpData> getData(HttpRequest request, HttpDataFactory factory) {
        List<InterfaceHttpData> data = new ArrayList<>(parts.size());
        for (Part part : parts) {
            data.add(part.getData(request, factory));
        }
        return data;
    }"
"@Restricted(DoNotUse.class) // WebOnly
    public HttpResponse doIncompleteInstallStatus() {
        try {
        Map<String,String> jobs = InstallUtil.getPersistedInstallStatus();
        if(jobs == null) {
            jobs = Collections.emptyMap();
        }
            return HttpResponses.okJSON(jobs);
        } catch (Exception e) {
            return HttpResponses.errorJSON(String.format(""ERROR: %s"", e.getMessage()));
        }
    }"
"void receiveHeaders(Headers headers, boolean inFinished) {
    assert (!Thread.holdsLock(Http2Stream.this));
    boolean open;
    synchronized (this) {
      if (!hasResponseHeaders || !inFinished) {
        hasResponseHeaders = true;
        headersQueue.add(headers);
      } else {
        this.source.trailers = headers;
      }
      if (inFinished) {
        this.source.finished = true;
      }
      open = isOpen();
      notifyAll();
    }
    if (!open) {
      connection.removeStream(id);
    }
  }"
"public void publish(ServletContext context, @CheckForNull File home) {
        LOGGER.log(Level.SEVERE, ""Failed to initialize Jenkins"",this);

        WebApp.get(context).setApp(this);
        if (home == null) {
            return;
        }
        new GroovyHookScript(""boot-failure"", context, home, BootFailure.class.getClassLoader())
                .bind(""exception"",this)
                .bind(""home"",home)
                .bind(""servletContext"", context)
                .bind(""attempts"",loadAttempts(home))
                .run();
    }"
"@Override
    public Channel getOpenChannelOrFail() throws ChannelClosedException {
        final Channel ch = getChannelOrFail();
        if (ch.isClosingOrClosed()) { // TODO: Since Remoting 2.33, we still need to explicitly declare minimum Remoting version
            throw new ChannelClosedException(new IllegalStateException(""The associated channel "" + ch + "" is closing down or has closed down"", ch.getCloseRequestCause()));
        }
        return ch;
    }"
"@Override
	public DataSet<Result<K>> runInternal(Graph<K, VV, EV> input)
			throws Exception {
		// s, t, d(t)
		DataSet<Edge<K, Tuple2<EV, LongValue>>> neighborDegree = input
			.run(new EdgeTargetDegree<K, VV, EV>()
				.setParallelism(parallelism));

		// group span, s, t, d(t)
		DataSet<Tuple4<IntValue, K, K, IntValue>> groupSpans = neighborDegree
			.groupBy(0)
			.sortGroup(1, Order.ASCENDING)
			.reduceGroup(new GenerateGroupSpans<>(groupSize))
				.setParallelism(parallelism)
				.name(""Generate group spans"");

		// group, s, t, d(t)
		DataSet<Tuple4<IntValue, K, K, IntValue>> groups = groupSpans
			.rebalance()
				.setParallelism(parallelism)
				.name(""Rebalance"")
			.flatMap(new GenerateGroups<>())
				.setParallelism(parallelism)
				.name(""Generate groups"");

		// t, u, d(t)+d(u)
		DataSet<Tuple3<K, K, IntValue>> twoPaths = groups
			.groupBy(0, 1)
			.sortGroup(2, Order.ASCENDING)
			.reduceGroup(new GenerateGroupPairs<>(groupSize))
				.name(""Generate group pairs"");

		// t, u, intersection, union
		DataSet<Result<K>> scores = twoPaths
			.groupBy(0, 1)
			.reduceGroup(new ComputeScores<>(unboundedScores,
					minimumScoreNumerator, minimumScoreDenominator,
					maximumScoreNumerator, maximumScoreDenominator))
				.name(""Compute scores"");

		if (mirrorResults) {
			scores = scores
				.flatMap(new MirrorResult<>())
					.name(""Mirror results"");
		}

		return scores;
	}"
"public static File[] getExtensionFilesToLoad(ExtensionsConfig config)
  {
    final File rootExtensionsDir = new File(config.getDirectory());
    if (rootExtensionsDir.exists() && !rootExtensionsDir.isDirectory()) {
      throw new ISE(""Root extensions directory [%s] is not a directory!?"", rootExtensionsDir);
    }
    File[] extensionsToLoad;
    final LinkedHashSet<String> toLoad = config.getLoadList();
    if (toLoad == null) {
      extensionsToLoad = rootExtensionsDir.listFiles();
    } else {
      int i = 0;
      extensionsToLoad = new File[toLoad.size()];
      for (final String extensionName : toLoad) {
        File extensionDir = new File(extensionName);
        if (!extensionDir.isAbsolute()) {
          extensionDir = new File(rootExtensionsDir, extensionName);
        }

        if (!extensionDir.isDirectory()) {
          throw new ISE(
              ""Extension [%s] specified in \""druid.extensions.loadList\"" didn't exist!?"",
              extensionDir.getAbsolutePath()
          );
        }
        extensionsToLoad[i++] = extensionDir;
      }
    }
    return extensionsToLoad == null ? new File[]{} : extensionsToLoad;
  }"
"protected boolean canMergeConfigurationWith(GraphAlgorithmWrappingBase other) {
		Preconditions.checkNotNull(other);

		return this.getClass().equals(other.getClass());
	}"
"public <T> void addValueCallback(
      final KeyPath keyPath, final T property, final LottieValueCallback<T> callback) {
    if (compositionLayer == null) {
      lazyCompositionTasks.add(new LazyCompositionTask() {
        @Override
        public void run(LottieComposition composition) {
          addValueCallback(keyPath, property, callback);
        }
      });
      return;
    }
    boolean invalidate;
    if (keyPath.getResolvedElement() != null) {
      keyPath.getResolvedElement().addValueCallback(property, callback);
      invalidate = true;
    } else {
      List<KeyPath> elements = resolveKeyPath(keyPath);

      for (int i = 0; i < elements.size(); i++) {
        //noinspection ConstantConditions
        elements.get(i).getResolvedElement().addValueCallback(property, callback);
      }
      invalidate = !elements.isEmpty();
    }
    if (invalidate) {
      invalidateSelf();
      if (property == LottieProperty.TIME_REMAP) {
        // Time remapping values are read in setProgress. In order for the new value
        // to apply, we have to re-set the progress with the current progress so that the
        // time remapping can be reapplied.
        setProgress(getProgress());
      }
    }
  }"
"public static void binary(ImageInputStream srcStream, ImageOutputStream destStream, String imageType) {
		binary(read(srcStream), destStream, imageType);
	}"
"public UnsafeSorterIterator getIterator(int startIndex) throws IOException {
    if (spillWriters.isEmpty()) {
      assert(inMemSorter != null);
      UnsafeSorterIterator iter = inMemSorter.getSortedIterator();
      moveOver(iter, startIndex);
      return iter;
    } else {
      LinkedList<UnsafeSorterIterator> queue = new LinkedList<>();
      int i = 0;
      for (UnsafeSorterSpillWriter spillWriter : spillWriters) {
        if (i + spillWriter.recordsSpilled() > startIndex) {
          UnsafeSorterIterator iter = spillWriter.getReader(serializerManager);
          moveOver(iter, startIndex - i);
          queue.add(iter);
        }
        i += spillWriter.recordsSpilled();
      }
      if (inMemSorter != null) {
        UnsafeSorterIterator iter = inMemSorter.getSortedIterator();
        moveOver(iter, startIndex - i);
        queue.add(iter);
      }
      return new ChainedIterator(queue);
    }
  }"
"public static Calendar calendar(long millis) {
		final Calendar cal = Calendar.getInstance();
		cal.setTimeInMillis(millis);
		return cal;
	}"
"public static void parseLongestText(String text, AhoCorasickDoubleArrayTrie.IHit<CoreDictionary.Attribute> processor)
    {
        if (trie != null)
        {
            final int[] lengthArray = new int[text.length()];
            final CoreDictionary.Attribute[] attributeArray = new CoreDictionary.Attribute[text.length()];
            char[] charArray = text.toCharArray();
            DoubleArrayTrie<CoreDictionary.Attribute>.Searcher searcher = dat.getSearcher(charArray, 0);
            while (searcher.next())
            {
                lengthArray[searcher.begin] = searcher.length;
                attributeArray[searcher.begin] = searcher.value;
            }
            trie.parseText(charArray, new AhoCorasickDoubleArrayTrie.IHit<CoreDictionary.Attribute>()
            {
                @Override
                public void hit(int begin, int end, CoreDictionary.Attribute value)
                {
                    int length = end - begin;
                    if (length > lengthArray[begin])
                    {
                        lengthArray[begin] = length;
                        attributeArray[begin] = value;
                    }
                }
            });
            for (int i = 0; i < charArray.length;)
            {
                if (lengthArray[i] == 0)
                {
                    ++i;
                }
                else
                {
                    processor.hit(i, i + lengthArray[i], attributeArray[i]);
                    i += lengthArray[i];
                }
            }
        }
        else
            dat.parseLongestText(text, processor);
    }"
"public Matrix timesEquals(double s)
    {
        for (int i = 0; i < m; i++)
        {
            for (int j = 0; j < n; j++)
            {
                A[i][j] = s * A[i][j];
            }
        }
        return this;
    }"
"@RequirePOST
    public HttpResponse doDiscard(StaplerRequest req, StaplerResponse rsp) {
        saveAndRemoveEntries( new Predicate<Map.Entry<SaveableReference,VersionRange>>() {
            @Override
            public boolean apply(Map.Entry<SaveableReference, VersionRange> entry) {
                return entry.getValue().max == null;
            }
        });

        return HttpResponses.forwardToPreviousPage();
    }"
"@EventListener
    public void handleConfigurationModifiedEvent(final CasConfigurationModifiedEvent event) {
        if (this.contextRefresher == null) {
            LOGGER.warn(""Unable to refresh application context, since no refresher is available"");
            return;
        }

        if (event.isEligibleForContextRefresh()) {
            LOGGER.info(""Received event [{}]. Refreshing CAS configuration..."", event);
            Collection<String> keys = null;
            try {
                keys = contextRefresher.refresh();
                LOGGER.debug(""Refreshed the following settings: [{}]."", keys);
            } catch (final Exception e) {
                LOGGER.trace(e.getMessage(), e);
            } finally {
                rebind();
                LOGGER.info(""CAS finished rebinding configuration with new settings [{}]"",
                    ObjectUtils.defaultIfNull(keys, new ArrayList<>(0)));
            }
        }
    }"
"public Node addNode(@NonNull String ip, @NonNull int port) {
        val node = Node.builder()
                .id(ip)
                .port(port)
                .upstream(null)
                .build();

         return this.addNode(node);
    }"
"public SslContextBuilder keyManager(PrivateKey key, X509Certificate... keyCertChain) {
        return keyManager(key, null, keyCertChain);
    }"
"public void setChildChannelOptions(final Map<ChannelOption, Object> channelOptions) {
        this.childChannelOptions = channelOptions == null ? Collections.<ChannelOption, Object> emptyMap()
            : channelOptions;
    }"
"@SuppressWarnings(""unchecked"")
	public static DataFormatConverter getConverterForTypeInfo(TypeInformation typeInfo) {
		DataFormatConverter converter = TYPE_INFO_TO_CONVERTER.get(typeInfo);
		if (converter != null) {
			return converter;
		}

		if (typeInfo instanceof BasicArrayTypeInfo) {
			BasicArrayTypeInfo arrayType = (BasicArrayTypeInfo) typeInfo;
			return new ObjectArrayConverter(arrayType.getTypeClass(), arrayType.getComponentInfo());
		} else if (typeInfo instanceof ObjectArrayTypeInfo) {
			ObjectArrayTypeInfo arrayType = (ObjectArrayTypeInfo) typeInfo;
			return new ObjectArrayConverter(arrayType.getTypeClass(), arrayType.getComponentInfo());
		} else if (typeInfo instanceof MapTypeInfo) {
			MapTypeInfo mapType = (MapTypeInfo) typeInfo;
			return new MapConverter(mapType.getKeyTypeInfo(), mapType.getValueTypeInfo());
		} else if (typeInfo instanceof RowTypeInfo) {
			return new RowConverter((RowTypeInfo) typeInfo);
		} else if (typeInfo instanceof PojoTypeInfo) {
			return new PojoConverter((PojoTypeInfo) typeInfo);
		} else if (typeInfo instanceof TupleTypeInfo) {
			return new TupleConverter((TupleTypeInfo) typeInfo);
		} else if (typeInfo instanceof TupleTypeInfoBase && Product.class.isAssignableFrom(typeInfo.getTypeClass())) {
			return new CaseClassConverter((TupleTypeInfoBase) typeInfo);
		} else if (typeInfo instanceof BinaryArrayTypeInfo) {
			return BinaryArrayConverter.INSTANCE;
		} else if (typeInfo instanceof BinaryMapTypeInfo) {
			return BinaryMapConverter.INSTANCE;
		} else if (typeInfo instanceof BaseRowTypeInfo) {
			return new BaseRowConverter(typeInfo.getArity());
		} else if (typeInfo.equals(BasicTypeInfo.BIG_DEC_TYPE_INFO)) {
			return new BaseRowConverter(typeInfo.getArity());
		} else if (typeInfo instanceof DecimalTypeInfo) {
			DecimalTypeInfo decimalType = (DecimalTypeInfo) typeInfo;
			return new DecimalConverter(decimalType.precision(), decimalType.scale());
		} else if (typeInfo instanceof BigDecimalTypeInfo) {
			BigDecimalTypeInfo decimalType = (BigDecimalTypeInfo) typeInfo;
			return new BigDecimalConverter(decimalType.precision(), decimalType.scale());
		} else if (typeInfo instanceof BinaryGenericTypeInfo) {
			return BinaryGenericConverter.INSTANCE;
		} else {
			return new GenericConverter(typeInfo.createSerializer(new ExecutionConfig()));
		}
	}"
"public INDArray outputSingle(DataSetIterator iterator){
        Preconditions.checkArgument(numOutputArrays == 1, ""Cannot use this method with nets that have more"" +
                "" than 1 output array. This network has %s outputs"", numOutputArrays);
        return output(iterator)[0];
    }"
"@Override
	public Socket createSocket(final String host, final int port,
			final InetAddress localAddress, final int localPort,
			final HttpConnectionParams params) throws IOException,
			UnknownHostException, ConnectTimeoutException {
		if (params == null) {
			throw new IllegalArgumentException(""Parameters may not be null"");
		}
		int timeout = params.getConnectionTimeout();
		if (timeout == 0) {
			InetAddress hostAddress = getCachedMisconfiguredHost(host, port);
			if (hostAddress != null) {
				return clientSSLSockFactory.createSocket(hostAddress, port, localAddress, localPort);
			}
			try {
				SSLSocket sslSocket = (SSLSocket) clientSSLSockFactory.createSocket(host, port, localAddress, localPort);
				sslSocket.startHandshake();

				return sslSocket;
			} catch (SSLException e) {
				if (!e.getMessage().contains(CONTENTS_UNRECOGNIZED_NAME_EXCEPTION)) {
					throw e;
				}

				hostAddress = InetAddress.getByName(host);
				cacheMisconfiguredHost(host, port, hostAddress);
				return clientSSLSockFactory.createSocket(hostAddress, port, localAddress, localPort);
			}
		}
		Socket socket = clientSSLSockFactory.createSocket();
		SocketAddress localAddr = new InetSocketAddress(localAddress, localPort);
		socket.bind(localAddr);
		SocketAddress remoteAddr = new InetSocketAddress(host, port);
		socket.connect(remoteAddr, timeout);
		
		return socket;
	}"
"public static HyperLogLogCollector makeCollector(ByteBuffer buffer)
  {
    int remaining = buffer.remaining();
    if (remaining % 3 == 0 || remaining == 1027) {
      return new VersionZeroHyperLogLogCollector(buffer);
    } else {
      return new VersionOneHyperLogLogCollector(buffer);
    }
  }"
"public static Pair<Schema,ArrowWritableRecordBatch> readFromFile(File input) throws IOException {
        return readFromFile(new FileInputStream(input));
    }"
"@Restricted(NoExternalUse.class)
    public final String getLongDescription() {
        ByteArrayOutputStream out = new ByteArrayOutputStream();
        PrintStream ps = new PrintStream(out);

        printUsageSummary(ps);
        ps.close();
        return out.toString();
    }"
"private static int spinsFor(Node pred, boolean haveData) {
        if (MP && pred != null) {
            if (pred.isData != haveData)      // phase change
                return FRONT_SPINS + CHAINED_SPINS;
            if (pred.isMatched())             // probably at front
                return FRONT_SPINS;
            if (pred.waiter == null)          // pred apparently spinning
                return CHAINED_SPINS;
        }
        return 0;
    }"
"private static Options getRunOptionsWithoutDeprecatedOptions(Options options) {
		Options o = getProgramSpecificOptionsWithoutDeprecatedOptions(options);
		o.addOption(SAVEPOINT_PATH_OPTION);
		return o.addOption(SAVEPOINT_ALLOW_NON_RESTORED_OPTION);
	}"
"public void save(File... files) throws IOException {
        Nd4j.saveBinary(getMin(), files[0]);
        Nd4j.saveBinary(getMax(), files[1]);
        if (isFitLabel()) {
            Nd4j.saveBinary(getLabelMin(), files[2]);
            Nd4j.saveBinary(getLabelMax(), files[3]);
        }
    }"
"public static String getExactlyValue(final String value) {
        return null == value ? null : CharMatcher.anyOf(""[]`'\"""").removeFrom(value);
    }"
"public void addSequenceLabel(@NonNull T label) {
        this.labels.add(label);
        if (this.label == null)
            this.label = label;
    }"
"public String readStringFix(final int length) {
        byte[] result = new byte[length];
        byteBuf.readBytes(result);
        return new String(result);
    }"
"protected void deleteExceptionByteArrayRef(JobEntity jobEntity) {
        ByteArrayRef exceptionByteArrayRef = jobEntity.getExceptionByteArrayRef();
        if (exceptionByteArrayRef != null) {
            exceptionByteArrayRef.delete();
        }
    }"
"public String add(String extension, String mimeType) {
		Mapping previous = this.map.put(extension, new Mapping(extension, mimeType));
		return (previous != null) ? previous.getMimeType() : null;
	}"
"public static Method getMethodCache(String serviceName, String methodName) {
        ConcurrentHashMap<String, Method> methods = NOT_OVERLOAD_METHOD_CACHE.get(serviceName);
        return methods == null ? null : methods.get(methodName);
    }"
"@Override
    public String getOriginalHost()
    {
        String host = getHeaders().getFirst(HttpHeaderNames.X_FORWARDED_HOST);
        if (host == null) {
            host = getHeaders().getFirst(HttpHeaderNames.HOST);
            if (host != null) {
                // Host header may have a trailing port. Strip that out if it does.
                host = PTN_COLON.split(host)[0];
            }

            if (host == null) {
                host = getServerName();
            }
        }
        return host;
    }"
"public void run() {
    MBeanServer mbs = ManagementFactory.getPlatformMBeanServer();
    ObjectName os;
    try {
      os = new ObjectName(""java.lang:type=OperatingSystem"");
    } catch( MalformedObjectNameException e ) {
      throw Log.throwErr(e);
    }
    Thread.currentThread().setPriority(Thread.MAX_PRIORITY);
    int counter = 0;
    //noinspection InfiniteLoopStatement
    while( true ) {
      // Update the interesting health self-info for publication also
      H2O cloud = H2O.CLOUD;
      HeartBeat hb = H2O.SELF._heartbeat;
      hb._hb_version = HB_VERSION++;
      hb._jvm_boot_msec= TimeLine.JVM_BOOT_MSEC;


      // Memory utilization as of last FullGC
      long kv_gc = Cleaner.KV_USED_AT_LAST_GC;
      long heap_gc = Cleaner.HEAP_USED_AT_LAST_GC;
      long pojo_gc = Math.max(heap_gc - kv_gc,0);
      long kv_mem = Cleaner.Histo.cached(); // More current than last FullGC numbers; can skyrocket
      // Since last FullGC, assuming POJO remains constant and KV changed: new free memory
      long free_mem = Math.max(MemoryManager.MEM_MAX-kv_mem-pojo_gc,0);
      long pojo_mem = MemoryManager.MEM_MAX-kv_mem-free_mem;
      hb.set_kv_mem(kv_mem);
      hb.set_pojo_mem(pojo_mem);
      hb.set_free_mem(free_mem);
      hb.set_swap_mem(Cleaner.Histo.swapped());
      hb._keys = H2O.STORE.size();

      try {
        hb._system_load_average = ((Double)mbs.getAttribute(os, ""SystemLoadAverage"")).floatValue();
        if( hb._system_load_average == -1 )  // SystemLoadAverage not available on windows
          hb._system_load_average = ((Double)mbs.getAttribute(os, ""SystemCpuLoad"")).floatValue();
      } catch( Exception e ) {/*Ignore, data probably not available on this VM*/ }

      int rpcs = 0;
      for( H2ONode h2o : cloud._memary )
        rpcs += h2o.taskSize();
      hb._rpcs       = (char)rpcs;
      // Scrape F/J pool counts
      hb._fjthrds = new short[H2O.MAX_PRIORITY+1];
      hb._fjqueue = new short[H2O.MAX_PRIORITY+1];
      for( int i=0; i<hb._fjthrds.length; i++ ) {
        hb._fjthrds[i] = (short)H2O.getWrkThrPoolSize(i);
        hb._fjqueue[i] = (short)H2O.getWrkQueueSize(i);
      }
      hb._tcps_active= (char)H2ONode.TCPS.get();

      // get the usable and total disk storage for the partition where the
      // persistent KV pairs are stored
      hb.set_free_disk(H2O.getPM().getIce().getUsableSpace());
      hb.set_max_disk (H2O.getPM().getIce().getTotalSpace() );

      // get cpu utilization for the system and for this process.  (linux only.)
      LinuxProcFileReader lpfr = new LinuxProcFileReader();
      lpfr.read();
      if (lpfr.valid()) {
        hb._system_idle_ticks = lpfr.getSystemIdleTicks();
        hb._system_total_ticks = lpfr.getSystemTotalTicks();
        hb._process_total_ticks = lpfr.getProcessTotalTicks();
        hb._process_num_open_fds = lpfr.getProcessNumOpenFds();
      }
      else {
        hb._system_idle_ticks = -1;
        hb._system_total_ticks = -1;
        hb._process_total_ticks = -1;
        hb._process_num_open_fds = -1;
      }
      hb._num_cpus = (short)Runtime.getRuntime().availableProcessors();
      hb._cpus_allowed = (short) lpfr.getProcessCpusAllowed();
      if (H2O.ARGS.nthreads < hb._cpus_allowed) {
        hb._cpus_allowed = H2O.ARGS.nthreads;
      }
      hb._nthreads = H2O.ARGS.nthreads;
      try {
        hb._pid = Integer.parseInt(lpfr.getProcessID());
      }
      catch (Exception ignore) {}

      // Announce what Cloud we think we are in.
      // Publish our health as well.
      UDPHeartbeat.build_and_multicast(cloud, hb);

      // If we have no internet connection, then the multicast goes
      // nowhere and we never receive a heartbeat from ourselves!
      // Fake it now.
      long now = System.currentTimeMillis();
      H2O.SELF._last_heard_from = now;

      // Look for napping Nodes & propose removing from Cloud
      for( H2ONode h2o : cloud._memary ) {
        long delta = now - h2o._last_heard_from;
        if( delta > SUSPECT ) {// We suspect this Node has taken a dirt nap
          if( !h2o._announcedLostContact ) {
            Paxos.print(""hart: announce suspect node"",cloud._memary,h2o.toString());
            h2o._announcedLostContact = true;
          }
        } else if( h2o._announcedLostContact ) {
          Paxos.print(""hart: regained contact with node"",cloud._memary,h2o.toString());
          h2o._announcedLostContact = false;
        }
      }

      // Run mini-benchmark every 5 mins.  However, on startup - do not have
      // all JVMs immediately launch a all-core benchmark - they will fight
      // with each other.  Stagger them using the hashcode.
      // Run this benchmark *before* testing the heap or GC, so the GC numbers
      // are current as of the send time.
      if( (counter+Math.abs(H2O.SELF.hashCode()*0xDECAF /*spread wider than 1 apart*/)) % (300/(Float.isNaN(hb._gflops)?10:1)) == 0) {
        hb._gflops   = (float)Linpack.run(hb._cpus_allowed);
        hb._membw    = (float)MemoryBandwidth.run(hb._cpus_allowed);
      }
      counter++;

      // Once per second, for the entire cloud a Node will multi-cast publish
      // itself, so other unrelated Clouds discover each other and form up.
      try { Thread.sleep(SLEEP); } // Only once-sec per entire Cloud
      catch( IllegalMonitorStateException ignore ) { }
      catch( InterruptedException ignore ) { }
    }
  }"
"@Override
	public void open(Configuration parameters) throws Exception {
		super.open(parameters);

		// check and pass the configuration properties
		KinesisProducerConfiguration producerConfig = KinesisConfigUtil.getValidatedProducerConfiguration(configProps);

		producer = getKinesisProducer(producerConfig);

		final MetricGroup kinesisMectricGroup = getRuntimeContext().getMetricGroup().addGroup(KINESIS_PRODUCER_METRIC_GROUP);
		this.backpressureCycles = kinesisMectricGroup.counter(METRIC_BACKPRESSURE_CYCLES);
		kinesisMectricGroup.gauge(METRIC_OUTSTANDING_RECORDS_COUNT, producer::getOutstandingRecordsCount);

		backpressureLatch = new TimeoutLatch();
		callback = new FutureCallback<UserRecordResult>() {
			@Override
			public void onSuccess(UserRecordResult result) {
				backpressureLatch.trigger();
				if (!result.isSuccessful()) {
					if (failOnError) {
						// only remember the first thrown exception
						if (thrownException == null) {
							thrownException = new RuntimeException(""Record was not sent successful"");
						}
					} else {
						LOG.warn(""Record was not sent successful"");
					}
				}
			}

			@Override
			public void onFailure(Throwable t) {
				backpressureLatch.trigger();
				if (failOnError) {
					thrownException = t;
				} else {
					LOG.warn(""An exception occurred while processing a record"", t);
				}
			}
		};

		if (this.customPartitioner != null) {
			this.customPartitioner.initialize(getRuntimeContext().getIndexOfThisSubtask(), getRuntimeContext().getNumberOfParallelSubtasks());
		}

		LOG.info(""Started Kinesis producer instance for region '{}'"", producerConfig.getRegion());
	}"
"public String getBaseURL(boolean proxy) {
		if (proxy) {
			return getOptionsParamApi().isSecureOnly() ? API_URL_S : API_URL;
		}

		StringBuilder strBuilder = new StringBuilder(50);
		strBuilder.append(""http"");
		if (getOptionsParamApi().isSecureOnly()) {
			strBuilder.append('s');
		}
		strBuilder.append(""://"")
				.append(getProxyParam().getProxyIp())
				.append(':')
				.append(getProxyParam().getProxyPort())
				.append('/');
		return strBuilder.toString();
	}"
"public static ByteBuf wrappedBuffer(byte[] array) {
        if (array.length == 0) {
            return EMPTY_BUFFER;
        }
        return new UnpooledHeapByteBuf(ALLOC, array, array.length);
    }"
"public static Object getInjectValue(String string) {
        Matcher m = pattern.matcher(string);
        StringBuffer sb = new StringBuffer();
        // Parse the content inside pattern ""${}"" when this pattern is found
        while (m.find()) {
            // Get parsing result
            Object value = getValue(m.group(1));
            // Return directly when the parsing result don't need to be casted to String
            if (!(value instanceof String)) {
                return value;
            }
            m.appendReplacement(sb, (String) value);
        }
        return m.appendTail(sb).toString();
    }"
"public static StreamGraph generate(StreamExecutionEnvironment env, List<StreamTransformation<?>> transformations) {
		return new StreamGraphGenerator(env).generateInternal(transformations);
	}"
"public static void cut(Image srcImage, File destFile, Rectangle rectangle) throws IORuntimeException {
		write(cut(srcImage, rectangle), destFile);
	}"
"public static String formatPercent(double number, int scale) {
		final NumberFormat format = NumberFormat.getPercentInstance();
		format.setMaximumFractionDigits(scale);
		return format.format(number);
	}"
"private void syncStage(final Long processId) {
        // 1. 根据pipelineId + processId构造对应的path
        String path = null;
        try {
            path = StagePathUtils.getProcess(getPipelineId(), processId);
            // 2. 监听当前的process列表的变化
            IZkConnection connection = zookeeper.getConnection();
            // zkclient包装的是一个持久化的zk，分布式lock只需要一次性的watcher，需要调用原始的zk链接进行操作
            ZooKeeper orginZk = ((ZooKeeperx) connection).getZookeeper();
            List<String> currentStages = orginZk.getChildren(path, new AsyncWatcher() {

                public void asyncProcess(WatchedEvent event) {
                    MDC.put(ArbitrateConstants.splitPipelineLogFileKey, String.valueOf(getPipelineId()));
                    if (isStop()) {
                        return;
                    }

                    if (event.getType() == EventType.NodeDeleted) {
                        processTermined(processId); // 触发下节点删除
                        return;
                    }

                    // 出现session expired/connection losscase下，会触发所有的watcher响应，同时老的watcher会继续保留，所以会导致出现多次watcher响应
                    boolean dataChanged = event.getType() == EventType.NodeDataChanged
                                          || event.getType() == EventType.NodeDeleted
                                          || event.getType() == EventType.NodeCreated
                                          || event.getType() == EventType.NodeChildrenChanged;
                    if (dataChanged) {
                        // boolean reply = initStage(processId);
                        // if (reply == false) {// 出现过load后就不需要再监听变化，剩下的就是节点的删除操作
                        syncStage(processId);
                        // }
                    }
                }
            });

            Collections.sort(currentStages, new StageComparator());
            List<String> lastStages = this.currentStages.get(processId);
            if (lastStages == null || !lastStages.equals(currentStages)) {
                initProcessStage(processId); // 存在差异，立马触发一下
            }

        } catch (NoNodeException e) {
            processTermined(processId); // 触发下节点删除
        } catch (KeeperException e) {
            syncStage(processId);
        } catch (InterruptedException e) {
            // ignore
        }
    }"
"private static String getLocalizedValues(final String locale, final List<?> items) {
        val foundLocale = findLocale(StringUtils.defaultString(locale, ""en""), items);
        if (foundLocale.isPresent()) {
            return foundLocale.get();
        }

        if (!items.isEmpty()) {
            val item = items.get(0);
            var value = StringUtils.EMPTY;
            if (item instanceof LocalizedName) {
                value = ((LocalizedName) item).getValue();
            }
            if (item instanceof LocalizedURI) {
                value = ((LocalizedURI) item).getValue();
            }
            if (item instanceof XSString) {
                value = ((XSString) item).getValue();
            }
            LOGGER.trace(""Loading first available locale [{}]"", value);
            return value;
        }
        return null;
    }"
"private void registerOffsetMetrics(
			MetricGroup consumerMetricGroup,
			List<KafkaTopicPartitionState<KPH>> partitionOffsetStates) {

		for (KafkaTopicPartitionState<KPH> ktp : partitionOffsetStates) {
			MetricGroup topicPartitionGroup = consumerMetricGroup
				.addGroup(OFFSETS_BY_TOPIC_METRICS_GROUP, ktp.getTopic())
				.addGroup(OFFSETS_BY_PARTITION_METRICS_GROUP, Integer.toString(ktp.getPartition()));

			topicPartitionGroup.gauge(CURRENT_OFFSETS_METRICS_GAUGE, new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET));
			topicPartitionGroup.gauge(COMMITTED_OFFSETS_METRICS_GAUGE, new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET));

			legacyCurrentOffsetsMetricGroup.gauge(getLegacyOffsetsMetricsGaugeName(ktp), new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET));
			legacyCommittedOffsetsMetricGroup.gauge(getLegacyOffsetsMetricsGaugeName(ktp), new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET));
		}
	}"
"public static INDArrayIndex[] resolveLong(long[] shapeInfo, INDArrayIndex... intendedIndexes) {
        int numSpecified = 0;
        for (int i = 0; i < intendedIndexes.length; i++) {
            if (intendedIndexes[i] instanceof SpecifiedIndex)
                numSpecified++;
        }

        if (numSpecified > 0) {
            val shape = Shape.shapeOf(shapeInfo);
            INDArrayIndex[] ret = new INDArrayIndex[intendedIndexes.length];
            for (int i = 0; i < intendedIndexes.length; i++) {
                if (intendedIndexes[i] instanceof SpecifiedIndex)
                    ret[i] = intendedIndexes[i];
                else {
                    if (intendedIndexes[i] instanceof NDArrayIndexAll) {
                        SpecifiedIndex specifiedIndex = new SpecifiedIndex(ArrayUtil.range(0L, shape[i]));
                        ret[i] = specifiedIndex;
                    } else if (intendedIndexes[i] instanceof IntervalIndex) {
                        IntervalIndex intervalIndex = (IntervalIndex) intendedIndexes[i];
                        ret[i] = new SpecifiedIndex(ArrayUtil.range(intervalIndex.begin, intervalIndex.end(),
                                        intervalIndex.stride()));
                    } else if(intendedIndexes[i] instanceof PointIndex){
                        ret[i] = intendedIndexes[i];
                    }
                }
            }

            return ret;
        }


        /**
         * If it's a vector and index asking
         * for a scalar just return the array
         */
        int rank = Shape.rank(shapeInfo);
        val shape = Shape.shapeOf(shapeInfo);
        if (intendedIndexes.length >= rank || Shape.isVector(shapeInfo) && intendedIndexes.length == 1) {
            if(Shape.rank(shapeInfo) == 1){
                //1D edge case, with 1 index
                return intendedIndexes;
            }

            if (Shape.isRowVectorShape(shapeInfo) && intendedIndexes.length == 1) {
                INDArrayIndex[] ret = new INDArrayIndex[2];
                ret[0] = NDArrayIndex.point(0);
                long size;
                if (1 == shape[0] && rank == 2)
                    size = shape[1];
                else
                    size = shape[0];
                ret[1] = validate(size, intendedIndexes[0]);
                return ret;
            }
            List<INDArrayIndex> retList = new ArrayList<>(intendedIndexes.length);
            for (int i = 0; i < intendedIndexes.length; i++) {
                if (i < rank)
                    retList.add(validate(shape[i], intendedIndexes[i]));
                else
                    retList.add(intendedIndexes[i]);
            }
            return retList.toArray(new INDArrayIndex[retList.size()]);
        }

        List<INDArrayIndex> retList = new ArrayList<>(intendedIndexes.length + 1);
        int numNewAxes = 0;

        if (Shape.isMatrix(shape) && intendedIndexes.length == 1) {
            retList.add(validate(shape[0], intendedIndexes[0]));
            retList.add(NDArrayIndex.all());
        } else {
            for (int i = 0; i < intendedIndexes.length; i++) {
                retList.add(validate(shape[i], intendedIndexes[i]));
                if (intendedIndexes[i] instanceof NewAxis)
                    numNewAxes++;
            }
        }

        int length = rank + numNewAxes;
        //fill the rest with all
        while (retList.size() < length)
            retList.add(NDArrayIndex.all());

        return retList.toArray(new INDArrayIndex[retList.size()]);
    }"
"public static JobExecutionResult execute(Program pa, String... args) throws Exception {
		return execute(pa.getPlan(args));
	}"
"public static DataSource createDataSource(final Map<String, DataSource> dataSourceMap, final File yamlFile) throws SQLException, IOException {
        YamlOrchestrationShardingRuleConfiguration config = unmarshal(yamlFile);
        return createDataSource(dataSourceMap, config.getShardingRule(), config.getProps(), config.getOrchestration());
    }"
"protected Map<String, List<Object>> collectAttributesForLdapEntry(final LdapEntry ldapEntry, final String username) {
        val attributeMap = Maps.<String, List<Object>>newHashMapWithExpectedSize(this.principalAttributeMap.size());
        LOGGER.debug(""The following attributes are requested to be retrieved and mapped: [{}]"", attributeMap.keySet());
        this.principalAttributeMap.forEach((key, attributeNames) -> {
            val attr = ldapEntry.getAttribute(key);
            if (attr != null) {
                LOGGER.debug(""Found principal attribute: [{}]"", attr);
                val names = (Collection<String>) attributeNames;
                if (names.isEmpty()) {
                    LOGGER.debug(""Principal attribute [{}] is collected as [{}]"", attr, key);
                    attributeMap.put(key, CollectionUtils.wrap(attr.getStringValues()));
                } else {
                    names.forEach(s -> {
                        LOGGER.debug(""Principal attribute [{}] is virtually remapped/renamed to [{}]"", attr, s);
                        attributeMap.put(s, CollectionUtils.wrap(attr.getStringValues()));
                    });
                }
            } else {
                LOGGER.warn(""Requested LDAP attribute [{}] could not be found on the resolved LDAP entry for [{}]"", key, ldapEntry.getDn());
            }
        });
        if (this.collectDnAttribute) {
            LOGGER.debug(""Recording principal DN attribute as [{}]"", this.principalDnAttributeName);
            attributeMap.put(this.principalDnAttributeName, CollectionUtils.wrapList(ldapEntry.getDn()));
        }
        return attributeMap;
    }"
"@SuppressWarnings(""unchecked"")
  public void updateExecutions() {
    this.updaterStage.set(""Starting update all flows."");
    final Map<Optional<Executor>, List<ExecutableFlow>> exFlowMap = getFlowToExecutorMap();
    final ArrayList<ExecutableFlow> finalizeFlows =
        new ArrayList<>();

    for (final Map.Entry<Optional<Executor>, List<ExecutableFlow>> entry : exFlowMap
        .entrySet()) {

      final Optional<Executor> executorOption = entry.getKey();
      if (!executorOption.isPresent()) {
        for (final ExecutableFlow flow : entry.getValue()) {
          logger.warn(""Finalizing execution "" + flow.getExecutionId()
              + "". Executor id of this execution doesn't exist"");
          finalizeFlows.add(flow);
        }
        continue;
      }
      final Executor executor = executorOption.get();

      this.updaterStage.set(""Starting update flows on "" + executor.getHost() + "":""
          + executor.getPort());

      Map<String, Object> results = null;
      try {
        results = this.apiGateway.updateExecutions(executor, entry.getValue());
      } catch (final ExecutorManagerException e) {
        handleException(entry, executor, e, finalizeFlows);
      }

      if (results != null) {
        final List<Map<String, Object>> executionUpdates =
            (List<Map<String, Object>>) results
                .get(ConnectorParams.RESPONSE_UPDATED_FLOWS);
        for (final Map<String, Object> updateMap : executionUpdates) {
          try {
            final ExecutableFlow flow = updateExecution(updateMap);

            this.updaterStage.set(""Updated flow "" + flow.getExecutionId());

            if (ExecutionControllerUtils.isFinished(flow)) {
              finalizeFlows.add(flow);
            }
          } catch (final ExecutorManagerException e) {
            final ExecutableFlow flow = e.getExecutableFlow();
            logger.error(e);

            if (flow != null) {
              logger.warn(""Finalizing execution "" + flow.getExecutionId());
              finalizeFlows.add(flow);
            }
          }
        }
      }
    }

    this.updaterStage.set(""Finalizing "" + finalizeFlows.size() + "" error flows."");

    for (final ExecutableFlow flow : finalizeFlows) {
      this.executionFinalizer
          .finalizeFlow(flow, ""Not running on the assigned executor (any more)"", null);
    }

    this.updaterStage.set(""Updated all active flows. Waiting for next round."");
  }"
"private DbBatch getDbBatch(HttpPipeKey key) {
        String dataUrl = key.getUrl();
        Pipeline pipeline = configClientService.findPipeline(key.getIdentity().getPipelineId());
        DataRetriever dataRetriever = dataRetrieverFactory.createRetriever(pipeline.getParameters().getRetriever(),
            dataUrl,
            downloadDir);
        File archiveFile = null;
        try {
            dataRetriever.connect();
            dataRetriever.doRetrieve();
            archiveFile = dataRetriever.getDataAsFile();
        } catch (Exception e) {
            dataRetriever.abort();
            throw new PipeException(""download_error"", e);
        } finally {
            dataRetriever.disconnect();
        }

        // 处理下有加密的数据
        if (StringUtils.isNotEmpty(key.getKey()) && StringUtils.isNotEmpty(key.getCrc())) {
            decodeFile(archiveFile, key.getKey(), key.getCrc());
        }

        InputStream input = null;
        JSONReader reader = null;
        try {
            input = new BufferedInputStream(new FileInputStream(archiveFile));
            DbBatch dbBatch = new DbBatch();
            byte[] lengthBytes = new byte[4];
            input.read(lengthBytes);
            int length = ByteUtils.bytes2int(lengthBytes);
            BatchProto.RowBatch rowbatchProto = BatchProto.RowBatch.parseFrom(new LimitedInputStream(input, length));
            // 构造原始的model对象
            RowBatch rowBatch = new RowBatch();
            rowBatch.setIdentity(build(rowbatchProto.getIdentity()));
            for (BatchProto.RowData rowDataProto : rowbatchProto.getRowsList()) {
                EventData eventData = new EventData();
                eventData.setPairId(rowDataProto.getPairId());
                eventData.setTableId(rowDataProto.getTableId());
                eventData.setTableName(rowDataProto.getTableName());
                eventData.setSchemaName(rowDataProto.getSchemaName());
                eventData.setEventType(EventType.valuesOf(rowDataProto.getEventType()));
                eventData.setExecuteTime(rowDataProto.getExecuteTime());
                // add by ljh at 2012-10-31
                if (StringUtils.isNotEmpty(rowDataProto.getSyncMode())) {
                    eventData.setSyncMode(SyncMode.valuesOf(rowDataProto.getSyncMode()));
                }
                if (StringUtils.isNotEmpty(rowDataProto.getSyncConsistency())) {
                    eventData.setSyncConsistency(SyncConsistency.valuesOf(rowDataProto.getSyncConsistency()));
                }
                // 处理主键
                List<EventColumn> keys = new ArrayList<EventColumn>();
                for (BatchProto.Column columnProto : rowDataProto.getKeysList()) {
                    keys.add(buildColumn(columnProto));
                }
                eventData.setKeys(keys);
                // 处理old主键
                if (CollectionUtils.isEmpty(rowDataProto.getOldKeysList()) == false) {
                    List<EventColumn> oldKeys = new ArrayList<EventColumn>();
                    for (BatchProto.Column columnProto : rowDataProto.getOldKeysList()) {
                        oldKeys.add(buildColumn(columnProto));
                    }
                    eventData.setOldKeys(oldKeys);
                }
                // 处理具体的column value
                List<EventColumn> columns = new ArrayList<EventColumn>();
                for (BatchProto.Column columnProto : rowDataProto.getColumnsList()) {
                    columns.add(buildColumn(columnProto));
                }
                eventData.setColumns(columns);

                eventData.setRemedy(rowDataProto.getRemedy());
                eventData.setSize(rowDataProto.getSize());
                eventData.setSql(rowDataProto.getSql());
                eventData.setDdlSchemaName(rowDataProto.getDdlSchemaName());
                eventData.setHint(rowDataProto.getHint());
                eventData.setWithoutSchema(rowDataProto.getWithoutSchema());
                // 添加到总记录
                rowBatch.merge(eventData);
            }
            dbBatch.setRowBatch(rowBatch);

            input.read(lengthBytes);
            length = ByteUtils.bytes2int(lengthBytes);
            BatchProto.FileBatch filebatchProto = BatchProto.FileBatch.parseFrom(new LimitedInputStream(input, length));
            // 构造原始的model对象
            FileBatch fileBatch = new FileBatch();
            fileBatch.setIdentity(build(filebatchProto.getIdentity()));
            for (BatchProto.FileData fileDataProto : filebatchProto.getFilesList()) {
                FileData fileData = new FileData();
                fileData.setPairId(fileDataProto.getPairId());
                fileData.setTableId(fileDataProto.getTableId());
                fileData.setEventType(EventType.valuesOf(fileDataProto.getEventType()));
                fileData.setLastModifiedTime(fileDataProto.getLastModifiedTime());
                fileData.setNameSpace(fileDataProto.getNamespace());
                fileData.setPath(fileDataProto.getPath());
                fileData.setSize(fileDataProto.getSize());
                // 添加到filebatch中
                fileBatch.getFiles().add(fileData);
            }
            dbBatch.setFileBatch(fileBatch);
            return dbBatch;
        } catch (IOException e) {
            throw new PipeException(""deserial_error"", e);
        } finally {
            IOUtils.closeQuietly(reader);
        }
    }"
"protected boolean redirectMatches(String requestedRedirect, String redirectUri) {
		UriComponents requestedRedirectUri = UriComponentsBuilder.fromUriString(requestedRedirect).build();
		UriComponents registeredRedirectUri = UriComponentsBuilder.fromUriString(redirectUri).build();

		boolean schemeMatch = isEqual(registeredRedirectUri.getScheme(), requestedRedirectUri.getScheme());
		boolean userInfoMatch = isEqual(registeredRedirectUri.getUserInfo(), requestedRedirectUri.getUserInfo());
		boolean hostMatch = hostMatches(registeredRedirectUri.getHost(), requestedRedirectUri.getHost());
		boolean portMatch = matchPorts ? registeredRedirectUri.getPort() == requestedRedirectUri.getPort() : true;
		boolean pathMatch = isEqual(registeredRedirectUri.getPath(),
				StringUtils.cleanPath(requestedRedirectUri.getPath()));
		boolean queryParamMatch = matchQueryParams(registeredRedirectUri.getQueryParams(),
				requestedRedirectUri.getQueryParams());

		return schemeMatch && userInfoMatch && hostMatch && portMatch && pathMatch && queryParamMatch;
	}"
"public List<List<Writable>> transformRawStringsToInputSequence(List<List<String>> sequence) {
        List<List<Writable>> ret = new ArrayList<>();
        for(List<String> input : sequence)
            ret.add(transformRawStringsToInputList(input));
        return ret;
    }"
"protected void configureWindowsLiveClient(final Collection<BaseClient> properties) {
        val live = pac4jProperties.getWindowsLive();
        if (StringUtils.isNotBlank(live.getId()) && StringUtils.isNotBlank(live.getSecret())) {
            val client = new WindowsLiveClient(live.getId(), live.getSecret());
            configureClient(client, live);

            LOGGER.debug(""Created client [{}] with identifier [{}]"", client.getName(), client.getKey());
            properties.add(client);
        }
    }"
"protected void checkSubjectRolesAndPermissions(final Subject currentUser) throws FailedLoginException {
        if (this.requiredRoles != null) {
            for (val role : this.requiredRoles) {
                if (!currentUser.hasRole(role)) {
                    throw new FailedLoginException(""Required role "" + role + "" does not exist"");
                }
            }
        }

        if (this.requiredPermissions != null) {
            for (val perm : this.requiredPermissions) {
                if (!currentUser.isPermitted(perm)) {
                    throw new FailedLoginException(""Required permission "" + perm + "" cannot be located"");
                }
            }
        }
    }"
"@SuppressWarnings(""ConstantConditions"")  // Complains that the code is too complex. Well duh!
  public static double scoreTree0(byte[] tree, double[] row, boolean computeLeafAssignment) {
    ByteBufferWrapper ab = new ByteBufferWrapper(tree);
    GenmodelBitSet bs = null;  // Lazily set on hitting first group test
    long bitsRight = 0;
    int level = 0;
    while (true) {
      int nodeType = ab.get1U();
      int colId = ab.get2();
      if (colId == 65535) return ab.get4f();
      int naSplitDir = ab.get1U();
      boolean naVsRest = naSplitDir == NsdNaVsRest;
      boolean leftward = naSplitDir == NsdNaLeft || naSplitDir == NsdLeft;
      int lmask = (nodeType & 51);
      int equal = (nodeType & 12);  // Can be one of 0, 8, 12
      assert equal != 4;  // no longer supported

      float splitVal = -1;
      if (!naVsRest) {
        // Extract value or group to split on
        if (equal == 0) {
          // Standard float-compare test (either < or ==)
          splitVal = ab.get4f();  // Get the float to compare
        } else {
          // Bitset test
          if (bs == null) bs = new GenmodelBitSet(0);
          if (equal == 8)
            bs.fill2(tree, ab);
          else
            bs.fill3_1(tree, ab);
        }
      }

      double d = row[colId];
      if (Double.isNaN(d)? !leftward : !naVsRest && (equal == 0? d >= splitVal : bs.contains0((int)d))) {
        // go RIGHT
        switch (lmask) {
          case 0:  ab.skip(ab.get1U());  break;
          case 1:  ab.skip(ab.get2());  break;
          case 2:  ab.skip(ab.get3());  break;
          case 3:  ab.skip(ab.get4());  break;
          case 48: ab.skip(4);  break;  // skip the prediction
          default:
            assert false : ""illegal lmask value "" + lmask + "" in tree "" + Arrays.toString(tree);
        }
        if (computeLeafAssignment && level < 64) bitsRight |= 1 << level;
        lmask = (nodeType & 0xC0) >> 2;  // Replace leftmask with the rightmask
      } else {
        // go LEFT
        if (lmask <= 3)
          ab.skip(lmask + 1);
      }

      level++;
      if ((lmask & 16) != 0) {
        if (computeLeafAssignment) {
          bitsRight |= 1 << level;  // mark the end of the tree
          return Double.longBitsToDouble(bitsRight);
        } else {
          return ab.get4f();
        }
      }
    }
  }"
"@Override
    public Collection<String> wordsNearestSum(INDArray words, int top) {
        return modelUtils.wordsNearestSum(words, top);
    }"
"private FilterChangeUserAgentDialog getFilterChangeUserAgentDialog() {
		if (filterChangeUserAgentDialog == null) {
		    filterChangeUserAgentDialog  = new FilterChangeUserAgentDialog(getView().getMainFrame(), true);
		}
		return filterChangeUserAgentDialog ;
	}"
"public static String logicDeleteColumnEqualsValue(EntityColumn column, boolean isDeleted) {
        String result = """";
        if (column.getEntityField().isAnnotationPresent(LogicDelete.class)) {
            result = column.getColumn() + "" = "" + getLogicDeletedValue(column, isDeleted);
        }
        return result;
    }"
"public void close() {
        SHUTDOWN_EXECUTOR.execute(new Runnable() {
            
            @Override
            public void run() {
                try {
                    executorService.shutdown();
                    while (!executorService.awaitTermination(5, TimeUnit.SECONDS)) {
                        executorService.shutdownNow();
                    }
                } catch (final InterruptedException ex) {
                    Thread.currentThread().interrupt();
                }
            }
        });
    }"
"public static <T> T[] toArray(Collection<T> collection, Class<T> componentType) {
		final T[] array = newArray(componentType, collection.size());
		return collection.toArray(array);
	}"
"public static <T extends Comparable<T>> RangeSet<T> unionRanges(final Iterable<Range<T>> ranges)
  {
    RangeSet<T> rangeSet = null;
    for (Range<T> range : ranges) {
      if (rangeSet == null) {
        rangeSet = TreeRangeSet.create();
      }
      rangeSet.add(range);
    }
    return rangeSet;
  }"
"public void registerView(final Class ownerClass, final Pair<View, View> view) {
        registerView(ownerClass.getSimpleName(), view);
    }"
"public AggregateOperator<T> max (int field) {
		return this.aggregate (Aggregations.MAX, field, Utils.getCallLocationName());
	}"
"public static <K, V> TimedCache<K, V> newTimedCache(long timeout){
		return new TimedCache<K, V>(timeout);
	}"
"@Override
    public @Nonnull ApplicationContextBuilder exclude(@Nullable String... configurations) {
        if (configurations != null) {
            this.configurationExcludes.addAll(Arrays.asList(configurations));
        }
        return this;
    }"
"public Conditions newConditions(final ZonedDateTime issuedAt, final String audienceUri, final long issueLength) {
        val conditions = newSamlObject(Conditions.class);
        conditions.setNotBefore(DateTimeUtils.dateTimeOf(issuedAt));
        conditions.setNotOnOrAfter(DateTimeUtils.dateTimeOf(issuedAt.plus(issueLength, ChronoUnit.SECONDS)));
        val audienceRestriction = newSamlObject(AudienceRestrictionCondition.class);
        val audience = newSamlObject(Audience.class);
        audience.setUri(audienceUri);
        audienceRestriction.getAudiences().add(audience);
        conditions.getAudienceRestrictionConditions().add(audienceRestriction);
        return conditions;
    }"
"@Override
	public void setup(AbstractInvokable parent) {
		agg = ((IterationRuntimeContext) getUdfRuntimeContext()).getIterationAggregator(BulkIterationBase.TERMINATION_CRITERION_AGGREGATOR_NAME);
	}"
"@ShellMethod(key = ""jasypt-list-providers"", value = ""List encryption providers with PBE Ciphers you can use with Jasypt"")
    public void listAlgorithms(@ShellOption(value = {""includeBC""},
        help = ""Include Bouncy Castle provider"") final boolean includeBC) {
        if (includeBC) {
            if (Security.getProvider(BouncyCastleProvider.PROVIDER_NAME) == null) {
                Security.addProvider(new BouncyCastleProvider());
            }
        } else {
            Security.removeProvider(BouncyCastleProvider.PROVIDER_NAME);
        }

        val providers = Security.getProviders();
        for (val provider : providers) {
            val services = provider.getServices();
            val algorithms =
                services.stream()
                    .filter(service -> ""Cipher"".equals(service.getType()) && service.getAlgorithm().contains(""PBE""))
                    .map(Provider.Service::getAlgorithm)
                    .collect(Collectors.toList());
            if (!algorithms.isEmpty()) {
                LOGGER.info(""Provider: Name: [{}] Class: [{}]"", provider.getName(), provider.getClass().getName());
                for (val algorithm : algorithms) {
                    LOGGER.info("" - Algorithm: [{}]"", algorithm);
                }
            }
        }
    }"
"public static List<String> getAvailableLocales() {
		List<String> locales = readAvailableLocales();
		Collections.sort(locales);

		// Always put English at the top
		locales.add(0, DEFAULT_LOCALE);

		return locales;
	}"
"public Optional<String> findGenerateKeyColumnName(final String logicTableName) {
        for (TableRule each : tableRules) {
            if (each.getLogicTable().equalsIgnoreCase(logicTableName) && null != each.getGenerateKeyColumn()) {
                return Optional.of(each.getGenerateKeyColumn());
            }
        }
        return Optional.absent();
    }"
"public void addPolicyPanel(AbstractParamPanel panel) {
        this.additionalPanels.add(panel);
        addParamPanel(ROOT, panel.getName(), panel, true);
    }"
"@Override
    public MultiDataSet next() {
        counter.incrementAndGet();

        INDArray[] features = new INDArray[baseFeatures.length];
        System.arraycopy(baseFeatures, 0, features, 0, baseFeatures.length);
        INDArray[] labels = new INDArray[baseLabels.length];
        System.arraycopy(baseLabels, 0, labels, 0, baseLabels.length);

        MultiDataSet ds = new MultiDataSet(features, labels);

        return ds;
    }"
"public static <T> File appendLines(Collection<T> list, String path, String charset) throws IORuntimeException {
		return writeLines(list, path, charset, true);
	}"
"public <OUT> DataStreamSource<OUT> fromParallelCollection(SplittableIterator<OUT> iterator, TypeInformation<OUT>
			typeInfo) {
		return fromParallelCollection(iterator, typeInfo, ""Parallel Collection Source"");
	}"
"static void initDefaultHandlers() {
		if (config != null && config.getDefaultHandlers() != null) {
			defaultHandlers = getHandlersFromExecList(config.getDefaultHandlers());
			handlerListById.put(""defaultHandlers"", defaultHandlers);
		}
	}"
"public static Channel interceptForward(Channel channel,
                                         List<? extends ClientInterceptor> interceptors) {
    List<? extends ClientInterceptor> copy = new ArrayList<>(interceptors);
    Collections.reverse(copy);
    return intercept(channel, copy);
  }"
"static RendezvousChannelUDT newRendezvousChannelUDT(
            final TypeUDT type) {
        try {
            return SelectorProviderUDT.from(type).openRendezvousChannel();
        } catch (final IOException e) {
            throw new ChannelException(""failed to open a rendezvous channel"", e);
        }
    }"
"public static void addApplicationConverters(ConverterRegistry registry) {
		addDelimitedStringConverters(registry);
		registry.addConverter(new StringToDurationConverter());
		registry.addConverter(new DurationToStringConverter());
		registry.addConverter(new NumberToDurationConverter());
		registry.addConverter(new DurationToNumberConverter());
		registry.addConverter(new StringToDataSizeConverter());
		registry.addConverter(new NumberToDataSizeConverter());
		registry.addConverterFactory(new StringToEnumIgnoringCaseConverterFactory());
	}"
"public <T extends JobProperty> T getProperty(Class<T> clazz) {
        if (clazz == BuildDiscarderProperty.class && logRotator != null) {
            return clazz.cast(new BuildDiscarderProperty(logRotator));
        }
        return _getProperty(clazz);
    }"
"@Override public void init(boolean expensive) {
    super.init(expensive);
    // Initialize local variables
    if( _parms._mtries < 1 && _parms._mtries != -1 && _parms._mtries != -2 )
      error(""_mtries"", ""mtries must be -1 (converted to sqrt(features)) or -2 (All features) or >= 1 but it is "" + _parms._mtries);
    if( _train != null ) {
      int ncols = _train.numCols();
      if( _parms._mtries != -1 && _parms._mtries != -2 && !(1 <= _parms._mtries && _parms._mtries < ncols /*ncols includes the response*/))
        error(""_mtries"",""Computed mtries should be -1 or -2 or in interval [1,""+ncols+""[ but it is "" + _parms._mtries);
    }
    if (_parms._distribution != DistributionFamily.AUTO && _parms._distribution != DistributionFamily.gaussian) {
      throw new IllegalStateException(""Isolation Forest doesn't expect the distribution to be specified by the user"");
    }
    _parms._distribution = DistributionFamily.gaussian;
  }"
"public static File copyContent(File src, File dest, boolean isOverride) throws IORuntimeException {
		return FileCopier.create(src, dest).setCopyContentIfDir(true).setOverride(isOverride).copy();
	}"
"public static String decodeHexStr(char[] hexData, Charset charset) {
		return StrUtil.str(decodeHex(hexData), charset);
	}"
"public void setProcessForm(boolean processForm) {
		this.processForm = processForm;
		getConfig().setProperty(SPIDER_PROCESS_FORM, Boolean.toString(processForm));
	}"
"public static String replace(String str, String oldStr, String replacement) {
		return str.replace(oldStr, replacement);
	}"
"@Deprecated
    public static SslContext newServerContext(SslProvider provider,
            File certChainFile, File keyFile, String keyPassword,
            Iterable<String> ciphers, CipherSuiteFilter cipherFilter, ApplicationProtocolConfig apn,
            long sessionCacheSize, long sessionTimeout) throws SSLException {
        return newServerContext(provider, null, null, certChainFile, keyFile, keyPassword, null,
                ciphers, cipherFilter, apn, sessionCacheSize, sessionTimeout);
    }"
"public static Set<Object> toCollection(final Object obj) {
        val c = new LinkedHashSet<Object>();
        if (obj == null) {
            LOGGER.trace(""Converting null obj to empty collection"");
        } else if (obj instanceof Collection) {
            c.addAll((Collection<Object>) obj);
            LOGGER.trace(""Converting multi-valued element [{}]"", obj);
        } else if (obj instanceof Map) {
            val map = (Map) obj;
            val set = (Set<Map.Entry>) map.entrySet();
            c.addAll(set.stream().map(e -> Pair.of(e.getKey(), e.getValue())).collect(Collectors.toSet()));
        } else if (obj.getClass().isArray()) {
            if (byte[].class.isInstance(obj)) {
                c.add(obj);
            } else {
                c.addAll(Arrays.stream((Object[]) obj).collect(Collectors.toSet()));
            }
            LOGGER.trace(""Converting array element [{}]"", obj);
        } else if (obj instanceof Iterator) {
            val it = (Iterator) obj;
            while (it.hasNext()) {
                c.add(it.next());
            }
        } else if (obj instanceof Enumeration) {
            val it = (Enumeration) obj;
            while (it.hasMoreElements()) {
                c.add(it.nextElement());
            }
        } else {
            c.add(obj);
            LOGGER.trace(""Converting element [{}]"", obj);
        }
        return c;
    }"
"public static byte[] defaultMachineId() {
        byte[] bestMacAddr = bestAvailableMac();
        if (bestMacAddr == null) {
            bestMacAddr = new byte[EUI64_MAC_ADDRESS_LENGTH];
            PlatformDependent.threadLocalRandom().nextBytes(bestMacAddr);
            logger.warn(
                    ""Failed to find a usable hardware address from the network interfaces; using random bytes: {}"",
                    formatAddress(bestMacAddr));
        }
        return bestMacAddr;
    }"
"public int exists(String pathInZooKeeper) throws Exception {
		checkNotNull(pathInZooKeeper, ""Path in ZooKeeper"");

		final String path = normalizePath(pathInZooKeeper);

		Stat stat = client.checkExists().forPath(path);

		if (stat != null) {
			return stat.getVersion();
		}

		return -1;
	}"
"public long getLong(int index) throws JSONException {
		Object object = get(index);
		Long result = JSON.toLong(object);
		if (result == null) {
			throw JSON.typeMismatch(index, object, ""long"");
		}
		return result;
	}"
"private static FixedBucketsHistogram fromBytesSparse(ByteBuffer buf)
  {
    double lowerLimit = buf.getDouble();
    double upperLimit = buf.getDouble();
    int numBuckets = buf.getInt();
    OutlierHandlingMode outlierHandlingMode = OutlierHandlingMode.values()[buf.get()];

    long count = buf.getLong();
    long lowerOutlierCount = buf.getLong();
    long upperOutlierCount = buf.getLong();
    long missingValueCount = buf.getLong();

    double max = buf.getDouble();
    double min = buf.getDouble();

    int nonEmptyBuckets = buf.getInt();
    long histogram[] = new long[numBuckets];
    for (int i = 0; i < nonEmptyBuckets; i++) {
      int bucket = buf.getInt();
      long bucketCount = buf.getLong();
      histogram[bucket] = bucketCount;
    }

    return new FixedBucketsHistogram(
        lowerLimit,
        upperLimit,
        numBuckets,
        outlierHandlingMode,
        histogram,
        count,
        max,
        min,
        lowerOutlierCount,
        upperOutlierCount,
        missingValueCount
    );
  }"
"protected static void checkAndNudgePoints(BitMatrix image,
                                            float[] points) throws NotFoundException {
    int width = image.getWidth();
    int height = image.getHeight();
    // Check and nudge points from start until we see some that are OK:
    boolean nudged = true;
    int maxOffset = points.length - 1; // points.length must be even
    for (int offset = 0; offset < maxOffset && nudged; offset += 2) {
      int x = (int) points[offset];
      int y = (int) points[offset + 1];
      if (x < -1 || x > width || y < -1 || y > height) {
        throw NotFoundException.getNotFoundInstance();
      }
      nudged = false;
      if (x == -1) {
        points[offset] = 0.0f;
        nudged = true;
      } else if (x == width) {
        points[offset] = width - 1;
        nudged = true;
      }
      if (y == -1) {
        points[offset + 1] = 0.0f;
        nudged = true;
      } else if (y == height) {
        points[offset + 1] = height - 1;
        nudged = true;
      }
    }
    // Check and nudge points from end:
    nudged = true;
    for (int offset = points.length - 2; offset >= 0 && nudged; offset -= 2) {
      int x = (int) points[offset];
      int y = (int) points[offset + 1];
      if (x < -1 || x > width || y < -1 || y > height) {
        throw NotFoundException.getNotFoundInstance();
      }
      nudged = false;
      if (x == -1) {
        points[offset] = 0.0f;
        nudged = true;
      } else if (x == width) {
        points[offset] = width - 1;
        nudged = true;
      }
      if (y == -1) {
        points[offset + 1] = 0.0f;
        nudged = true;
      } else if (y == height) {
        points[offset + 1] = height - 1;
        nudged = true;
      }
    }
  }"
"public static void rotate(Image image, int degree, OutputStream out) throws IORuntimeException {
		writeJpg(rotate(image, degree), getImageOutputStream(out));
	}"
"@SneakyThrows
    public static byte[] signJws(final Key key, final byte[] value, final String algHeaderValue) {
        val base64 = EncodingUtils.encodeBase64(value);
        val jws = new JsonWebSignature();
        jws.setEncodedPayload(base64);
        jws.setAlgorithmHeaderValue(algHeaderValue);
        jws.setKey(key);
        jws.setHeader(""typ"", ""JWT"");
        return jws.getCompactSerialization().getBytes(StandardCharsets.UTF_8);
    }"
"public static List<Method> getAllMethods(Class clazz) {
        List<Method> all = new ArrayList<Method>();
        for (Class<?> c = clazz; c != Object.class && c != null; c = c.getSuperclass()) {
            Method[] methods = c.getDeclaredMethods(); // 所有方法，不包含父类
            for (Method method : methods) {
                int mod = method.getModifiers();
                // native的不要
                if (Modifier.isNative(mod)) {
                    continue;
                }
                method.setAccessible(true); // 不管private还是protect都可以
                all.add(method);
            }
        }
        return all;
    }"
"public SDVariable exponential(String name, double lambda, SDVariable shape) {
        validateInteger(""exponential random"", shape);
        SDVariable ret = f().randomExponential(lambda, shape);
        return updateVariableNameAndReference(ret, name);
    }"
"public InternalRow getRow(int rowId) {
    assert(rowId >= 0 && rowId < numRows);
    row.rowId = rowId;
    return row;
  }"
"public SDVariable tile(String name, SDVariable x, int... repeat) {
        SDVariable result = f().tile(x, repeat);
        return updateVariableNameAndReference(result, name);
    }"
"protected void clearPartitions() {
		for (int i = this.partitionsBeingBuilt.size() - 1; i >= 0; --i) {
			final HashPartition<BT, PT> p = this.partitionsBeingBuilt.get(i);
			try {
				p.clearAllMemory(this.availableMemory);
			} catch (Exception e) {
				LOG.error(""Error during partition cleanup."", e);
			}
		}
		this.partitionsBeingBuilt.clear();
	}"
"public Rational add(Rational val) {
        BigInteger num = a.multiply(val.b).add(b.multiply(val.a));
        BigInteger deno = b.multiply(val.b);
        return (new Rational(num, deno));
    }"
"public void addPropertyToResolve(DifferentialFunction forFunction, String arrayName) {
        if (!propertiesToResolve.containsKey(forFunction.getOwnName())) {
            List<String> newVal = new ArrayList<>();
            newVal.add(arrayName);
            propertiesToResolve.put(forFunction.getOwnName(), newVal);
        } else {
            List<String> newVal = propertiesToResolve.get(forFunction.getOwnName());
            newVal.add(arrayName);
        }
    }"
"public static synchronized View getSingleton() {
        if (view == null) {
            if (daemon) {
                Exception e = new Exception(""Attempting to initialise View in daemon mode"");
                logger.error(e.getMessage(), e);
                return null;
            }
            
            logger.info(""Initialising View"");
            view = new View();
            view.init();
        }
        
        return view;
    }"
"public static <T> PatternStream<T> pattern(DataStream<T> input, Pattern<T, ?> pattern) {
		return new PatternStream<>(input, pattern);
	}"
"public static <T> boolean checkIfNullSupported(@Nonnull TypeSerializer<T> serializer) {
		int length = serializer.getLength() > 0 ? serializer.getLength() : 1;
		DataOutputSerializer dos = new DataOutputSerializer(length);
		try {
			serializer.serialize(null, dos);
		}
		catch (IOException | RuntimeException e) {
			return false;
		}
		checkArgument(
			serializer.getLength() < 0 || serializer.getLength() == dos.getCopyOfBuffer().length,
			""The serialized form of the null value should have the same length "" +
				""as any other if the length is fixed in the serializer"");
		DataInputDeserializer dis = new DataInputDeserializer(dos.getSharedBuffer());
		try {
			checkArgument(serializer.deserialize(dis) == null);
		}
		catch (IOException e) {
			throw new RuntimeException(
				String.format(""Unexpected failure to deserialize just serialized null value with %s"",
					serializer.getClass().getName()), e);
		}
		checkArgument(
			serializer.copy(null) == null,
			""Serializer %s has to be able properly copy null value if it can serialize it"",
			serializer.getClass().getName());
		return true;
	}"
"public void shuffle(long seed) {
        // just skip shuffle if there's only 1 example
        if (numExamples() < 2)
            return;

        //note here we use the same seed with different random objects guaranteeing same order

        List<INDArray> arrays = new ArrayList<>();
        List<int[]> dimensions = new ArrayList<>();

        arrays.add(getFeatures());
        dimensions.add(ArrayUtil.range(1, getFeatures().rank()));

        arrays.add(getLabels());
        dimensions.add(ArrayUtil.range(1, getLabels().rank()));

        if (featuresMask != null) {
            arrays.add(getFeaturesMaskArray());
            dimensions.add(ArrayUtil.range(1, getFeaturesMaskArray().rank()));
        }

        if (labelsMask != null) {
            arrays.add(getLabelsMaskArray());
            dimensions.add(ArrayUtil.range(1, getLabelsMaskArray().rank()));
        }

        Nd4j.shuffle(arrays, new Random(seed), dimensions);

        //As per CpuNDArrayFactory.shuffle(List<INDArray> arrays, Random rnd, List<int[]> dimensions) and libnd4j transforms.h shuffleKernelGeneric
        if (exampleMetaData != null) {
            int[] map = ArrayUtil.buildInterleavedVector(new Random(seed), numExamples());
            ArrayUtil.shuffleWithMap(exampleMetaData, map);
        }
    }"
"public static void main(String[] args) throws IOException, ClassNotFoundException {
		String outputDirectory = args[0];
		String rootDir = args[1];

		for (OptionsClassLocation location : LOCATIONS) {
			createTable(rootDir, location.getModule(), location.getPackage(), outputDirectory, DEFAULT_PATH_PREFIX);
		}

		generateCommonSection(rootDir, outputDirectory, LOCATIONS, DEFAULT_PATH_PREFIX);
	}"
"private ModelAndView generateErrorView(final String code, final Object[] args, final HttpServletRequest request, final WebApplicationService service) {
        val modelAndView = serviceValidateConfigurationContext.getValidationViewFactory().getModelAndView(request, false, service, getClass());
        val convertedDescription = this.applicationContext.getMessage(code, args, code, request.getLocale());
        modelAndView.addObject(CasViewConstants.MODEL_ATTRIBUTE_NAME_ERROR_CODE, StringEscapeUtils.escapeHtml4(code));
        modelAndView.addObject(CasViewConstants.MODEL_ATTRIBUTE_NAME_ERROR_DESCRIPTION, StringEscapeUtils.escapeHtml4(convertedDescription));
        return modelAndView;
    }"
"@Override
    public Properties loadRemoteConfig() {
        Properties properties = null;
        try {
            // 加载远程canal配置
            ConfigItem configItem = getRemoteCanalConfig();
            if (configItem != null) {
                if (configItem.getModifiedTime() != currentConfigTimestamp) {
                    currentConfigTimestamp = configItem.getModifiedTime();
                    overrideLocalCanalConfig(configItem.getContent());
                    properties = new Properties();
                    properties.load(new ByteArrayInputStream(configItem.getContent().getBytes(StandardCharsets.UTF_8)));
                    scanIntervalInSecond = Integer
                        .valueOf(properties.getProperty(CanalConstants.CANAL_AUTO_SCAN_INTERVAL, ""5""));
                    logger.info(""## Loaded remote canal config: canal.properties "");
                }
            }
        } catch (Exception e) {
            logger.error(e.getMessage(), e);
        }
        return properties;
    }"
"public <T> TypeSerializer<T> getRestoredNestedSerializer(int pos) {
		checkArgument(pos < nestedSnapshots.length);

		@SuppressWarnings(""unchecked"")
		TypeSerializerSnapshot<T> snapshot = (TypeSerializerSnapshot<T>) nestedSnapshots[pos];

		return snapshot.restoreSerializer();
	}"
"private PollingResult _poll(TaskListener listener, SCM scm) throws IOException, InterruptedException {
        if (scm.requiresWorkspaceForPolling()) {
            R b = getSomeBuildWithExistingWorkspace();
            if (b == null) b = getLastBuild();
            // lock the workspace for the given build
            FilePath ws=b.getWorkspace();

            WorkspaceOfflineReason workspaceOfflineReason = workspaceOffline( b );
            if ( workspaceOfflineReason != null ) {
                // workspace offline
                for (WorkspaceBrowser browser : ExtensionList.lookup(WorkspaceBrowser.class)) {
                    ws = browser.getWorkspace(this);
                    if (ws != null) {
                        return pollWithWorkspace(listener, scm, b, ws, browser.getWorkspaceList());
                    }
                }

                // At this point we start thinking about triggering a build just to get a workspace,
                // because otherwise there's no way we can detect changes.
                // However, first there are some conditions in which we do not want to do so.
                // give time for agents to come online if we are right after reconnection (JENKINS-8408)
                long running = Jenkins.getInstance().getInjector().getInstance(Uptime.class).getUptime();
                long remaining = TimeUnit.MINUTES.toMillis(10)-running;
                if (remaining>0 && /* this logic breaks tests of polling */!Functions.getIsUnitTest()) {
                    listener.getLogger().print(Messages.AbstractProject_AwaitingWorkspaceToComeOnline(remaining/1000));
                    listener.getLogger().println( "" ("" + workspaceOfflineReason.name() + "")"");
                    return NO_CHANGES;
                }

                // Do not trigger build, if no suitable agent is online
                if (workspaceOfflineReason.equals(WorkspaceOfflineReason.all_suitable_nodes_are_offline)) {
                    // No suitable executor is online
                    listener.getLogger().print(Messages.AbstractProject_AwaitingWorkspaceToComeOnline(running/1000));
                    listener.getLogger().println( "" ("" + workspaceOfflineReason.name() + "")"");
                    return NO_CHANGES;
                }

                Label label = getAssignedLabel();
                if (label != null && label.isSelfLabel()) {
                    // if the build is fixed on a node, then attempting a build will do us
                    // no good. We should just wait for the agent to come back.
                    listener.getLogger().print(Messages.AbstractProject_NoWorkspace());
                    listener.getLogger().println( "" ("" + workspaceOfflineReason.name() + "")"");
                    return NO_CHANGES;
                }

                listener.getLogger().println( ws==null
                    ? Messages.AbstractProject_WorkspaceOffline()
                    : Messages.AbstractProject_NoWorkspace());
                if (isInQueue()) {
                    listener.getLogger().println(Messages.AbstractProject_AwaitingBuildForWorkspace());
                    return NO_CHANGES;
                }

                // build now, or nothing will ever be built
                listener.getLogger().print(Messages.AbstractProject_NewBuildForWorkspace());
                listener.getLogger().println( "" ("" + workspaceOfflineReason.name() + "")"");
                return BUILD_NOW;
            } else {
                WorkspaceList l = b.getBuiltOn().toComputer().getWorkspaceList();
                return pollWithWorkspace(listener, scm, b, ws, l);
            }

        } else {
            // polling without workspace
            LOGGER.fine(""Polling SCM changes of "" + getName());
            if (pollingBaseline==null) // see NOTE-NO-BASELINE above
                calcPollingBaseline(getLastBuild(),null,listener);
            PollingResult r = scm.poll(this, null, null, listener, pollingBaseline);
            pollingBaseline = r.remote;
            return r;
        }
    }"
"public HttpHeaders set(CharSequence name, Object value) {
        return set(name.toString(), value);
    }"
"@GetMapping(path = ""/yadis.xml"")
    public void yadis(final HttpServletResponse response) throws Exception {
        val template = this.resourceLoader.getResource(""classpath:/yadis.template"");
        try (val writer = new StringWriter()) {
            IOUtils.copy(template.getInputStream(), writer, StandardCharsets.UTF_8);
            val yadis = writer.toString().replace(""$casLoginUrl"", casProperties.getServer().getLoginUrl());
            response.setContentType(""application/xrds+xml"");
            val respWriter = response.getWriter();
            respWriter.write(yadis);
            respWriter.flush();
        }
    }"
"@Override
  protected Futures remove_impl(final Futures fs) {
    for (Key<Model> k : _models.values())
      k.remove(fs);
    _models.clear();
    return fs;
  }"
"@SuppressWarnings(""unchecked"")
  private static List<Map<String, ?>> checkObjectList(List<?> rawList) {
    for (int i = 0; i < rawList.size(); i++) {
      if (!(rawList.get(i) instanceof Map)) {
        throw new ClassCastException(
            String.format(""value %s for idx %d in %s is not object"", rawList.get(i), i, rawList));
      }
    }
    return (List<Map<String, ?>>) rawList;
  }"
"public List<GraphicInfo> connectionPerfectionizer(SHAPE_TYPE sourceShapeType,
                                                      SHAPE_TYPE targetShapeType,
                                                      GraphicInfo sourceGraphicInfo,
                                                      GraphicInfo targetGraphicInfo,
                                                      List<GraphicInfo> graphicInfoList) {
        Shape shapeFirst = createShape(sourceShapeType,
                                       sourceGraphicInfo);
        Shape shapeLast = createShape(targetShapeType,
                                      targetGraphicInfo);

        if (graphicInfoList != null && graphicInfoList.size() > 0) {
            GraphicInfo graphicInfoFirst = graphicInfoList.get(0);
            GraphicInfo graphicInfoLast = graphicInfoList.get(graphicInfoList.size() - 1);
            if (shapeFirst != null) {
                graphicInfoFirst.setX(shapeFirst.getBounds2D().getCenterX());
                graphicInfoFirst.setY(shapeFirst.getBounds2D().getCenterY());
            }
            if (shapeLast != null) {
                graphicInfoLast.setX(shapeLast.getBounds2D().getCenterX());
                graphicInfoLast.setY(shapeLast.getBounds2D().getCenterY());
            }

            Point p = null;

            if (shapeFirst != null) {
                Line2D.Double lineFirst = new Line2D.Double(graphicInfoFirst.getX(),
                                                            graphicInfoFirst.getY(),
                                                            graphicInfoList.get(1).getX(),
                                                            graphicInfoList.get(1).getY());
                p = getIntersection(shapeFirst,
                                    lineFirst);
                if (p != null) {
                    graphicInfoFirst.setX(p.getX());
                    graphicInfoFirst.setY(p.getY());
                }
            }

            if (shapeLast != null) {
                Line2D.Double lineLast = new Line2D.Double(graphicInfoLast.getX(),
                                                           graphicInfoLast.getY(),
                                                           graphicInfoList.get(graphicInfoList.size() - 2).getX(),
                                                           graphicInfoList.get(graphicInfoList.size() - 2).getY());
                p = getIntersection(shapeLast,
                                    lineLast);
                if (p != null) {
                    graphicInfoLast.setX(p.getX());
                    graphicInfoLast.setY(p.getY());
                }
            }
        }

        return graphicInfoList;
    }"
"public void updateModel(@NonNull Model model) {
        if (zoo != null) {
            for (val w: zoo)
                w.updateModel(model);
        } else {
            // if zoo wasn't initalized yet - just replace model
            this.model = model;
        }
    }"
"protected void setURI() {
        // set _uri
        StringBuffer buf = new StringBuffer();
        // ^(([^:/?#]+):)?(//([^/?#]*))?([^?#]*)(\?([^#]*))?(#(.*))?
        if (_scheme != null) {
            buf.append(_scheme);
            buf.append(':');
        }
        if (_is_net_path) {
            buf.append(""//"");
            if (_authority != null) { // has_authority
                buf.append(_authority);
            }
        }
        if (_opaque != null && _is_opaque_part) {
            buf.append(_opaque);
        } else if (_path != null) {
            // _is_hier_part or _is_relativeURI
            if (_path.length != 0) {
                buf.append(_path);
            }
        }
        if (_query != null) { // has_query
            buf.append('?');
            buf.append(_query);
        }
        // ignore the fragment identifier
        _uri = buf.toString().toCharArray();
        hash = 0;
    }"
"@VisibleForTesting
	public SharedStateRegistryKey createSharedStateRegistryKeyFromFileName(StateHandleID shId) {
		return new SharedStateRegistryKey(String.valueOf(backendIdentifier) + '-' + keyGroupRange, shId);
	}"
"@PostConstruct
    public void init() {

        jfxComboBox.focusedProperty().addListener((o, oldVal, newVal) -> {
            if (!newVal) {
                jfxComboBox.validate();
            }
        });

        ChangeListener<? super Boolean> comboBoxFocus = (o, oldVal, newVal) -> {
            if (!newVal) {
                jfxEditableComboBox.validate();
            }
        };
        jfxEditableComboBox.focusedProperty().addListener(comboBoxFocus);
        jfxEditableComboBox.getEditor().focusedProperty().addListener(comboBoxFocus);
        jfxEditableComboBox.setConverter(new StringConverter<Label>() {
            @Override
            public String toString(Label object) {
                return object==null? """" : object.getText();
            }
            @Override
            public Label fromString(String string) {
                return string == null || string.isEmpty() ? null : new Label(string);
            }
        });
    }"
"private static Date getExpireAt(final Ticket ticket) {
        val expirationPolicy = ticket.getExpirationPolicy();
        val ttl = ticket instanceof TicketState
            ? expirationPolicy.getTimeToLive((TicketState) ticket)
            : expirationPolicy.getTimeToLive();

        if (ttl < 1) {
            return null;
        }

        return new Date(System.currentTimeMillis() + TimeUnit.SECONDS.toMillis(ttl));
    }"
"public void generateGetterForField(JavacNode fieldNode, DiagnosticPosition pos, AccessLevel level, boolean lazy, List<JCAnnotation> onMethod) {
		if (hasAnnotation(Getter.class, fieldNode)) {
			//The annotation will make it happen, so we can skip it.
			return;
		}
		createGetterForField(level, fieldNode, fieldNode, false, lazy, onMethod);
	}"
"public static int[] swap(int[] array, int index1, int index2) {
		if (isEmpty(array)) {
			throw new IllegalArgumentException(""Number array must not empty !"");
		}
		int tmp = array[index1];
		array[index1] = array[index2];
		array[index2] = tmp;
		return array;
	}"
"public String getBeanDefinitionQualifiedClassName() {
        String newClassName = beanDefinitionName;
        if (newClassName.endsWith(""[]"")) {
            newClassName = newClassName.substring(0, newClassName.length() - 2);
        }
        return newClassName + REF_SUFFIX;
    }"
"private void showAliasButtonActionPerformed(java.awt.event.ActionEvent evt) {//GEN-FIRST:event_showAliasButtonActionPerformed
		int keystore = keyStoreList.getSelectedIndex();
		if(keystore>=0) {
			int alias = aliasTable.getSelectedRow();
			Certificate cert = contextManager.getCertificate(keystore, alias);
			if (cert != null) {
				showCertificate(cert);
			}
		}
	}"
"public void setDeploymentInfoCustomizers(
			Collection<? extends UndertowDeploymentInfoCustomizer> customizers) {
		Assert.notNull(customizers, ""Customizers must not be null"");
		this.deploymentInfoCustomizers = new ArrayList<>(customizers);
	}"
"protected M deepClone(Key<M> result) {
    M newModel = IcedUtils.deepCopy(self());
    newModel._key = result;
    // Do not clone model metrics
    newModel._output.clearModelMetrics();
    newModel._output._training_metrics = null;
    newModel._output._validation_metrics = null;
    // Clone trees
    Key[][] treeKeys = newModel._output._treeKeys;
    for (int i = 0; i < treeKeys.length; i++) {
      for (int j = 0; j < treeKeys[i].length; j++) {
        if (treeKeys[i][j] == null) continue;
        CompressedTree ct = DKV.get(treeKeys[i][j]).get();
        CompressedTree newCt = IcedUtils.deepCopy(ct);
        newCt._key = CompressedTree.makeTreeKey(i, j);
        DKV.put(treeKeys[i][j] = newCt._key,newCt);
      }
    }
    // Clone Aux info
    Key[][] treeKeysAux = newModel._output._treeKeysAux;
    if (treeKeysAux!=null) {
      for (int i = 0; i < treeKeysAux.length; i++) {
        for (int j = 0; j < treeKeysAux[i].length; j++) {
          if (treeKeysAux[i][j] == null) continue;
          CompressedTree ct = DKV.get(treeKeysAux[i][j]).get();
          CompressedTree newCt = IcedUtils.deepCopy(ct);
          newCt._key = Key.make(createAuxKey(treeKeys[i][j].toString()));
          DKV.put(treeKeysAux[i][j] = newCt._key,newCt);
        }
      }
    }
    return newModel;
  }"
"public void execBackwards(Map<String,INDArray> placeholders, List<String> variableGradNamesList){
        if (getFunction(""grad"") == null) {
            createGradFunction();
        }

        log.trace(""About to execute backward function"");

        //Edge case: if no variables, no variable gradients to calculate...
        if(variableGradNamesList.isEmpty()){
            log.warn(""Skipping gradient calculation (backward pass) - no variables to be calculated (variableGradNamesList is empty)"");
            return;
        }

        sameDiffFunctionInstances.get(""grad"").exec(placeholders, variableGradNamesList);
    }"
"static <T> SingleObserver<T> wrap(SingleObserver<T> downstream,
                                      List<RunnableInstrumenter> instrumentations) {
        return new RxInstrumentedSingleObserver<>(downstream, instrumentations);
    }"
"public Actions keyDown(WebElement target, CharSequence key) {
    if (isBuildingActions()) {
      action.addAction(new KeyDownAction(jsonKeyboard, jsonMouse, (Locatable) target, asKeys(key)));
    }
    return focusInTicks(target)
        .addKeyAction(key, codepoint -> tick(defaultKeyboard.createKeyDown(codepoint)));
  }"
"public static boolean reflectionEquals(Object lhs, Object rhs, boolean testTransients) {
        return reflectionEquals(lhs, rhs, testTransients, null, null);
    }"
"public T getDynamic(String id) {
        // by ID
        for (T t : data)
            if(t.getDescriptor().getId().equals(id))
                return t;

        // by position
        try {
            return data.get(Integer.parseInt(id));
        } catch (NumberFormatException e) {
            // fall through
        }

        return null;
    }"
"public UTF8String toUpperCase() {
    if (numBytes == 0) {
      return EMPTY_UTF8;
    }

    byte[] bytes = new byte[numBytes];
    bytes[0] = (byte) Character.toTitleCase(getByte(0));
    for (int i = 0; i < numBytes; i++) {
      byte b = getByte(i);
      if (numBytesForFirstByte(b) != 1) {
        // fallback
        return toUpperCaseSlow();
      }
      int upper = Character.toUpperCase((int) b);
      if (upper > 127) {
        // fallback
        return toUpperCaseSlow();
      }
      bytes[i] = (byte) upper;
    }
    return fromBytes(bytes);
  }"
"public static Config build(final BaseHazelcastProperties hz, final Map<String, MapConfig> mapConfigs) {
        val cfg = build(hz);
        cfg.setMapConfigs(mapConfigs);
        return finalizeConfig(cfg, hz);
    }"
"public boolean registerSlotRequest(SlotRequest slotRequest) throws SlotManagerException {
		checkInit();

		if (checkDuplicateRequest(slotRequest.getAllocationId())) {
			LOG.debug(""Ignoring a duplicate slot request with allocation id {}."", slotRequest.getAllocationId());

			return false;
		} else {
			PendingSlotRequest pendingSlotRequest = new PendingSlotRequest(slotRequest);

			pendingSlotRequests.put(slotRequest.getAllocationId(), pendingSlotRequest);

			try {
				internalRequestSlot(pendingSlotRequest);
			} catch (ResourceManagerException e) {
				// requesting the slot failed --> remove pending slot request
				pendingSlotRequests.remove(slotRequest.getAllocationId());

				throw new SlotManagerException(""Could not fulfill slot request "" + slotRequest.getAllocationId() + '.', e);
			}

			return true;
		}
	}"
"public static void state(boolean expression, String errorMsgTemplate, Object... params) throws IllegalStateException {
		if (false == expression) {
			throw new IllegalStateException(StrUtil.format(errorMsgTemplate, params));
		}
	}"
"public void set(long index, Block value)
    {
        Block currentValue = array.get(index);
        if (currentValue != null) {
            currentValue.retainedBytesForEachPart((object, size) -> {
                if (currentValue == object) {
                    // track instance size separately as the reference count for an instance is always 1
                    sizeOfBlocks -= size;
                    return;
                }
                if (trackedObjects.decrementAndGet(object) == 0) {
                    // decrement the size only when it is the last reference
                    sizeOfBlocks -= size;
                }
            });
        }
        if (value != null) {
            value.retainedBytesForEachPart((object, size) -> {
                if (value == object) {
                    // track instance size separately as the reference count for an instance is always 1
                    sizeOfBlocks += size;
                    return;
                }
                if (trackedObjects.incrementAndGet(object) == 1) {
                    // increment the size only when it is the first reference
                    sizeOfBlocks += size;
                }
            });
        }
        array.set(index, value);
    }"
"public void setParseRobotsTxt(boolean parseRobotsTxt) {
		this.parseRobotsTxt = parseRobotsTxt;
		getConfig().setProperty(SPIDER_PARSE_ROBOTS_TXT, Boolean.toString(parseRobotsTxt));
	}"
"public MockResponse setChunkedBody(Buffer body, int maxChunkSize) {
    removeHeader(""Content-Length"");
    headers.add(CHUNKED_BODY_HEADER);

    Buffer bytesOut = new Buffer();
    while (!body.exhausted()) {
      long chunkSize = Math.min(body.size(), maxChunkSize);
      bytesOut.writeHexadecimalUnsignedLong(chunkSize);
      bytesOut.writeUtf8(""\r\n"");
      bytesOut.write(body, chunkSize);
      bytesOut.writeUtf8(""\r\n"");
    }
    bytesOut.writeUtf8(""0\r\n""); // Last chunk. Trailers follow!

    this.body = bytesOut;
    return this;
  }"
"@GuardedBy(""evictionLock"")
  void setMaximumSize(long maximum) {
    requireArgument(maximum >= 0);
    if (maximum == maximum()) {
      return;
    }

    long max = Math.min(maximum, MAXIMUM_CAPACITY);
    long window = max - (long) (PERCENT_MAIN * max);
    long mainProtected = (long) (PERCENT_MAIN_PROTECTED * (max - window));

    setMaximum(max);
    setWindowMaximum(window);
    setMainProtectedMaximum(mainProtected);

    setHitsInSample(0);
    setMissesInSample(0);
    setStepSize(-HILL_CLIMBER_STEP_PERCENT * max);

    if ((frequencySketch() != null) && !isWeighted() && (weightedSize() >= (max >>> 1))) {
      // Lazily initialize when close to the maximum size
      frequencySketch().ensureCapacity(max);
    }
  }"
"static Executor makeContextAware(Executor delegate, CurrentTraceContext currentTraceContext) {
    class TracingCurrentRequestContextExecutor implements Executor {
      @Override public void execute(Runnable task) {
        delegate.execute(RequestContext.current().makeContextAware(currentTraceContext.wrap(task)));
      }
    }
    return new TracingCurrentRequestContextExecutor();
  }"
"private JPanel getJPanel2() {
		if (jPanel2 == null) {
			jPanel2 = new JPanel();
			jPanel2.add(getBtnAccept(), null);
			jPanel2.add(getBtnDecline(), null);
		}
		return jPanel2;
	}"
"public void run() throws Exception {
    if (config == null) {
      return;
    }
    config.channels = 1;
    config.directExecutor = true;
    ManagedChannel ch = config.newChannel();
    SimpleRequest req = config.newRequest();
    LoadGenerationWorker worker =
        new LoadGenerationWorker(ch, req, config.targetQps, config.duration);
    final long start = System.nanoTime();
    Histogram histogram = worker.call();
    final long end = System.nanoTime();
    printStats(histogram, end - start);
    if (config.histogramFile != null) {
      saveHistogram(histogram, config.histogramFile);
    }
    ch.shutdown();
  }"
"@View(name = ""by_userId"", map = ""function(doc) { if(doc.token && doc.userId) { emit(doc.userId, doc) } }"")
    public List<CouchDbGoogleAuthenticatorToken> findByUserId(final String userId) {
        return queryView(""by_userId"", userId);
    }"
"void channelInputClosed(ChannelHandlerContext ctx, List<Object> out) throws Exception {
        if (cumulation != null) {
            callDecode(ctx, cumulation, out);
            decodeLast(ctx, cumulation, out);
        } else {
            decodeLast(ctx, Unpooled.EMPTY_BUFFER, out);
        }
    }"
"private static void copy(ByteBuffer dst, ByteBuffer src) {
    if (dst.hasRemaining() && src.hasRemaining()) {
      // Avoid an allocation if possible.
      if (dst.remaining() >= src.remaining()) {
        dst.put(src);
      } else {
        int count = Math.min(dst.remaining(), src.remaining());
        ByteBuffer slice = src.slice();
        slice.limit(count);
        dst.put(slice);
        src.position(src.position() + count);
      }
    }
  }"
"private void configureClearTextWithHttpUpgrade(SocketChannel ch) {
        HttpClientCodec sourceCodec = new HttpClientCodec();
        Http2ClientUpgradeCodec upgradeCodec = new Http2ClientUpgradeCodec(connectionHandler);
        HttpClientUpgradeHandler upgradeHandler = new HttpClientUpgradeHandler(sourceCodec, upgradeCodec, 65536);

        ch.pipeline().addLast(sourceCodec,
            upgradeHandler,
            new UpgradeRequestHandler(),
            new UserEventLogger());
    }"
"public int vote(Authentication authentication, Object object, Collection<ConfigAttribute> configAttributes) {
    int result = ACCESS_ABSTAIN;

    if (authentication.getDetails() instanceof OAuthAuthenticationDetails) {
      OAuthAuthenticationDetails details = (OAuthAuthenticationDetails) authentication.getDetails();
      for (Object configAttribute : configAttributes) {
        ConfigAttribute attribute = (ConfigAttribute) configAttribute;

        if (ConsumerSecurityConfig.PERMIT_ALL_ATTRIBUTE.equals(attribute)) {
          return ACCESS_GRANTED;
        }
        else if (ConsumerSecurityConfig.DENY_ALL_ATTRIBUTE.equals(attribute)) {
          return ACCESS_DENIED;
        }
        else if (supports(attribute)) {
          ConsumerSecurityConfig config = (ConsumerSecurityConfig) attribute;
          if ((config.getSecurityType() == ConsumerSecurityConfig.ConsumerSecurityType.CONSUMER_KEY)
            && (config.getAttribute().equals(details.getConsumerDetails().getConsumerKey()))) {
            return ACCESS_GRANTED;
          }
          else if (config.getSecurityType() == ConsumerSecurityConfig.ConsumerSecurityType.CONSUMER_ROLE) {
            List<GrantedAuthority> authorities = details.getConsumerDetails().getAuthorities();
            if (authorities != null) {
              for (GrantedAuthority authority : authorities) {
                if (authority.getAuthority().equals(config.getAttribute())) {
                  return ACCESS_GRANTED;
                }
              }
            }
          }
        }
      }
    }

    return result;
  }"
"public Builder traceId(long high, long low) {
      if (high == 0L && low == 0L) throw new IllegalArgumentException(""empty trace ID"");
      char[] result = new char[high != 0L ? 32 : 16];
      int pos = 0;
      if (high != 0L) {
        writeHexLong(result, pos, high);
        pos += 16;
      }
      writeHexLong(result, pos, low);
      this.traceId = new String(result);
      return this;
    }"
"@Override
    public String[] outputColumnNames() {
        List<String> l = transform(inputSchema).getColumnNames();
        return l.toArray(new String[l.size()]);
    }"
"public Decimal toDecimal(int precision, int scale) {
		ensureMaterialized();
		if (precision > Decimal.MAX_LONG_DIGITS || this.sizeInBytes > Decimal.MAX_LONG_DIGITS) {
			return toDecimalSlow(precision, scale);
		}

		// Data in Decimal is stored by one long value if `precision` <= Decimal.MAX_LONG_DIGITS.
		// In this case we can directly extract the value from memory segment.
		int size = getSegments()[0].size();
		SegmentAndOffset segmentAndOffset = startSegmentAndOffset(size);
		int totalOffset = 0;

		// Remove white spaces at the beginning
		byte b = 0;
		while (totalOffset < this.sizeInBytes) {
			b = segmentAndOffset.value();
			if (b != ' ' && b != '\n' && b != '\t') {
				break;
			}
			totalOffset++;
			segmentAndOffset.nextByte(size);
		}
		if (totalOffset == this.sizeInBytes) {
			// all whitespaces
			return null;
		}

		// ======= Significand part begin =======
		final boolean negative = b == '-';
		if (negative || b == '+') {
			segmentAndOffset.nextByte(size);
			totalOffset++;
			if (totalOffset == this.sizeInBytes) {
				// only contains prefix plus/minus
				return null;
			}
		}

		long significand = 0;
		int exp = 0;
		int significandLen = 0, pointPos = -1;

		while (totalOffset < this.sizeInBytes) {
			b = segmentAndOffset.value();
			totalOffset++;
			segmentAndOffset.nextByte(size);

			if (b >= '0' && b <= '9') {
				// No need to worry about overflow, because this.sizeInBytes <= Decimal.MAX_LONG_DIGITS
				significand = significand * 10 + (b - '0');
				significandLen++;
			} else if (b == '.') {
				if (pointPos >= 0) {
					// More than one decimal point
					return null;
				}
				pointPos = significandLen;
			} else {
				break;
			}
		}

		if (pointPos < 0) {
			pointPos = significandLen;
		}
		if (negative) {
			significand = -significand;
		}
		// ======= Significand part end =======

		// ======= Exponential part begin =======
		if ((b == 'e' || b == 'E') && totalOffset < this.sizeInBytes) {
			b = segmentAndOffset.value();
			final boolean expNegative = b == '-';
			if (expNegative || b == '+') {
				segmentAndOffset.nextByte(size);
				totalOffset++;
				if (totalOffset == this.sizeInBytes) {
					return null;
				}
			}

			int expDigits = 0;
			// As `precision` <= 18, value absolute range is limited to 10^-18 ~ 10^18.
			// The worst case is <18-digits>E-36
			final int expStopValue = 40;

			while (totalOffset < this.sizeInBytes) {
				b = segmentAndOffset.value();
				totalOffset++;
				segmentAndOffset.nextByte(size);

				if (b >= '0' && b <= '9') {
					// No need to worry about larger exponents,
					// because they will produce overflow or underflow
					if (expDigits < expStopValue) {
						expDigits = expDigits * 10 + (b - '0');
					}
				} else {
					break;
				}
			}

			if (expNegative) {
				expDigits = -expDigits;
			}
			exp += expDigits;
		}
		exp -= significandLen - pointPos;
		// ======= Exponential part end =======

		// Check for invalid character at the end
		while (totalOffset < this.sizeInBytes) {
			b = segmentAndOffset.value();
			totalOffset++;
			segmentAndOffset.nextByte(size);
			// White spaces are allowed at the end
			if (b != ' ' && b != '\n' && b != '\t') {
				return null;
			}
		}

		// Round exp to scale
		int change = exp + scale;
		if (significandLen + change > precision) {
			// Overflow
			return null;
		}
		if (change >= 0) {
			significand *= Decimal.POW10[change];
		} else {
			int k = negative ? -5 : 5;
			significand = (significand + k * Decimal.POW10[-change - 1]) / Decimal.POW10[-change];
		}
		return Decimal.fromLong(significand, precision, scale);
	}"
"public static <T extends Schema>  void setField(T o, Field f, String key, String value, boolean required, Class thisSchemaClass) throws IllegalAccessException {
    // Primitive parse by field type
    Object parse_result = parse(key, value, f.getType(), required, thisSchemaClass);
    if (parse_result != null && f.getType().isArray() && parse_result.getClass().isArray() && (f.getType().getComponentType() != parse_result.getClass().getComponentType())) {
      // We have to conform an array of primitives.  There's got to be a better way. . .
      if (parse_result.getClass().getComponentType() == int.class && f.getType().getComponentType() == Integer.class) {
        int[] from = (int[])parse_result;
        Integer[] copy = new Integer[from.length];
        for (int i = 0; i < from.length; i++)
          copy[i] = from[i];
        f.set(o, copy);
      } else if (parse_result.getClass().getComponentType() == Integer.class && f.getType().getComponentType() == int.class) {
        Integer[] from = (Integer[])parse_result;
        int[] copy = new int[from.length];
        for (int i = 0; i < from.length; i++)
          copy[i] = from[i];
        f.set(o, copy);
      } else if (parse_result.getClass().getComponentType() == Double.class && f.getType().getComponentType() == double.class) {
        Double[] from = (Double[])parse_result;
        double[] copy = new double[from.length];
        for (int i = 0; i < from.length; i++)
          copy[i] = from[i];
        f.set(o, copy);
      } else if (parse_result.getClass().getComponentType() == Float.class && f.getType().getComponentType() == float.class) {
        Float[] from = (Float[])parse_result;
        float[] copy = new float[from.length];
        for (int i = 0; i < from.length; i++)
          copy[i] = from[i];
        f.set(o, copy);
      } else {
        throw H2O.fail(""Don't know how to cast an array of: "" + parse_result.getClass().getComponentType() + "" to an array of: "" + f.getType().getComponentType());
      }
    } else {
      f.set(o, parse_result);
    }
  }"
"@Override
    public void rollback(ClientIdentity clientIdentity, Long batchId) throws CanalServerException {
        checkStart(clientIdentity.getDestination());
        CanalInstance canalInstance = canalInstances.get(clientIdentity.getDestination());

        // 因为存在第一次链接时自动rollback的情况，所以需要忽略未订阅
        boolean hasSubscribe = canalInstance.getMetaManager().hasSubscribe(clientIdentity);
        if (!hasSubscribe) {
            return;
        }
        synchronized (canalInstance) {
            // 清除batch信息
            PositionRange<LogPosition> positionRanges = canalInstance.getMetaManager().removeBatch(clientIdentity,
                batchId);
            if (positionRanges == null) { // 说明是重复的ack/rollback
                throw new CanalServerException(String.format(""rollback error, clientId:%s batchId:%d is not exist , please check"",
                    clientIdentity.getClientId(),
                    batchId));
            }

            // lastRollbackPostions.put(clientIdentity,
            // positionRanges.getEnd());// 记录一下最后rollback的位置
            // TODO 后续rollback到指定的batchId位置
            canalInstance.getEventStore().rollback();// rollback
                                                     // eventStore中的状态信息
            logger.info(""rollback successfully, clientId:{} batchId:{} position:{}"",
                clientIdentity.getClientId(),
                batchId,
                positionRanges);
        }
    }"
"public static boolean awaitInactivity(long timeout, TimeUnit unit) throws InterruptedException {
        if (unit == null) {
            throw new NullPointerException(""unit"");
        }

        Thread watcherThread = ThreadDeathWatcher.watcherThread;
        if (watcherThread != null) {
            watcherThread.join(unit.toMillis(timeout));
            return !watcherThread.isAlive();
        } else {
            return true;
        }
    }"
"private void destroy() {
        if (queue != null) {

            if (!queue.isEmpty()) {
                logger.trace(""Non-empty queue: {}"", queue);

                if (releaseMessages) {
                    Object msg;
                    while ((msg = queue.poll()) != null) {
                        ReferenceCountUtil.safeRelease(msg);
                    }
                }
            }

            queue.recycle();
            queue = null;
        }
    }"
"public Set<String> missingOnnxOps() {
        Set<String> copy = new HashSet<>(onnxOpDescriptors.keySet());
        copy.removeAll(onnxNames.keySet());
        return copy;
    }"
"public synchronized boolean migrate(File dir, @CheckForNull File jenkinsHome) {
        if (load(dir)) {
            LOGGER.log(FINER, ""migration already performed for {0}"", dir);
            return false;
        }
        if (!dir.isDirectory()) {
            LOGGER.log(/* normal during Job.movedTo */FINE, ""{0} was unexpectedly missing"", dir);
            return false;
        }
        LOGGER.log(INFO, ""Migrating build records in {0}"", dir);
        doMigrate(dir);
        save(dir);
        if (jenkinsHome != null && offeredToUnmigrate.add(jenkinsHome))
            LOGGER.log(WARNING, ""Build record migration (https://jenkins.io/redirect/build-record-migration) is one-way. If you need to downgrade Jenkins, run: {0}"", getUnmigrationCommandLine(jenkinsHome));
        return true;
    }"
"private URL extractActualUrl(URL jarUrl) throws MalformedURLException {
        String urlFile = jarUrl.getFile();
        int separatorIndex = urlFile.indexOf(""!/"");
        if (separatorIndex != -1) {
            String jarFile = urlFile.substring(0, separatorIndex);

            try {
                return new URL(jarFile);
            } catch (MalformedURLException var5) {
                if (!jarFile.startsWith(""/"")) {
                    jarFile = ""/"" + jarFile;
                }

                return new URL(""file:"" + jarFile);
            }
        } else {
            return jarUrl;
        }
    }"
"static void apply(HttpCall.Factory callFactory, String name, String indexTemplate)
      throws IOException {
    HttpUrl templateUrl = callFactory.baseUrl.newBuilder(""_template"").addPathSegment(name).build();
    Request getTemplate = new Request.Builder().url(templateUrl).tag(""get-template"").build();
    try {
      callFactory.newCall(getTemplate, BodyConverters.NULL).execute();
    } catch (IllegalStateException e) { // TODO: handle 404 slightly more nicely
      Request updateTemplate =
          new Request.Builder()
              .url(templateUrl)
              .put(RequestBody.create(ElasticsearchStorage.APPLICATION_JSON, indexTemplate))
              .tag(""update-template"")
              .build();
      callFactory.newCall(updateTemplate, BodyConverters.NULL).execute();
    }
  }"
"public static <T> File appendUtf8Lines(Collection<T> list, String path) throws IORuntimeException {
		return appendLines(list, path, CharsetUtil.CHARSET_UTF_8);
	}"
"public static <K, V> MergeResult<K, V> mergeRightIntoLeft(LinkedOptionalMap<K, V> left, LinkedOptionalMap<K, V> right) {
		LinkedOptionalMap<K, V> merged = new LinkedOptionalMap<>(left);
		merged.putAll(right);

		return new MergeResult<>(merged, isLeftPrefixOfRight(left, right));
	}"
"@StaplerDispatchable
    public Object getFingerprint( String md5sum ) throws IOException {
        Fingerprint r = fingerprintMap.get(md5sum);
        if(r==null)     return new NoFingerprintMatch(md5sum);
        else            return r;
    }"
"public static long[] getReducedShape(int[] wholeShape, int[] dimensions) {
        if (isWholeArray(wholeShape, dimensions))
            return new long[] {};
        else if (dimensions.length == 1 && wholeShape.length == 2) {
            val ret = new long[2];
            if (dimensions[0] == 1) {
                ret[0] = wholeShape[0];
                ret[1] = 1;
            } else if (dimensions[0] == 0) {
                ret[0] = 1;
                ret[1] = wholeShape[1];
            }
            return ret;
        }

        return ArrayUtil.toLongArray(ArrayUtil.removeIndex(wholeShape, dimensions));
    }"
"public static long parseSecondNano(String secondNano) throws IllegalArgumentException {
    String[] parts = secondNano.split(""\\."");
    if (parts.length == 1) {
      return toLongWithRange(""second"", parts[0], Long.MIN_VALUE / MICROS_PER_SECOND,
        Long.MAX_VALUE / MICROS_PER_SECOND) * MICROS_PER_SECOND;

    } else if (parts.length == 2) {
      long seconds = parts[0].equals("""") ? 0L : toLongWithRange(""second"", parts[0],
        Long.MIN_VALUE / MICROS_PER_SECOND, Long.MAX_VALUE / MICROS_PER_SECOND);
      long nanos = toLongWithRange(""nanosecond"", parts[1], 0L, 999999999L);
      return seconds * MICROS_PER_SECOND + nanos / 1000L;

    } else {
      throw new IllegalArgumentException(
        ""Interval string does not match second-nano format of ss.nnnnnnnnn"");
    }
  }"
"public static <T, K extends Comparable<K>> PartitionOperator<T> partitionByRange(DataSet<T> input, DataDistribution distribution, KeySelector<T, K> keyExtractor) {
		final TypeInformation<K> keyType = TypeExtractor.getKeySelectorTypes(keyExtractor, input.getType());
		return new PartitionOperator<>(input, PartitionOperatorBase.PartitionMethod.RANGE, new Keys.SelectorFunctionKeys<>(input.clean(keyExtractor), input.getType(), keyType), distribution, Utils.getCallLocationName());
	}"
"public static ChannelMatcher compose(ChannelMatcher... matchers) {
        if (matchers.length < 1) {
            throw new IllegalArgumentException(""matchers must at least contain one element"");
        }
        if (matchers.length == 1) {
            return matchers[0];
        }
        return new CompositeMatcher(matchers);
    }"
"public static boolean isDDL(final TokenType primaryTokenType, final TokenType secondaryTokenType) {
        return PRIMARY_STATEMENT_PREFIX.contains(primaryTokenType) && !NOT_SECONDARY_STATEMENT_PREFIX.contains(secondaryTokenType);
    }"
"public void setCombinable(boolean combinable) {
		// sanity check
		if (combinable && !GroupCombineFunction.class.isAssignableFrom(this.userFunction.getUserCodeClass())) {
			throw new IllegalArgumentException(""Cannot set a UDF as combinable if it does not implement the interface "" +
					GroupCombineFunction.class.getName());
		} else {
			this.combinable = combinable;
		}
	}"
"public static String notEmpty(String text, String errorMsgTemplate, Object... params) throws IllegalArgumentException {
		if (StrUtil.isEmpty(text)) {
			throw new IllegalArgumentException(StrUtil.format(errorMsgTemplate, params));
		}
		return text;
	}"
"public ClockDifference getClockDifference() throws IOException, InterruptedException {
        VirtualChannel channel = getChannel();
        if(channel==null)
            throw new IOException(getNodeName()+"" is offline"");

        return channel.call(getClockDifferenceCallable());
    }"
"public static boolean validateFalse(boolean value, String errorMsgTemplate, Object... params) throws ValidateException {
		if (isTrue(value)) {
			throw new ValidateException(errorMsgTemplate, params);
		}
		return value;
	}"
"public RpcHandler doBootstrap(Channel channel, RpcHandler rpcHandler) {
    return new SaslRpcHandler(conf, channel, rpcHandler, secretKeyHolder);
  }"
"public boolean remove(MetricName name) {
        final Metric metric = metrics.remove(name);
        if (metric != null) {
            onMetricRemoved(name, metric);
            return true;
        }
        return false;
    }"
"public void initProcessDefinitionCache() {
    if (processDefinitionCache == null) {
      if (processDefinitionCacheLimit <= 0) {
        processDefinitionCache = new DefaultDeploymentCache<ProcessDefinitionCacheEntry>();
      } else {
        processDefinitionCache = new DefaultDeploymentCache<ProcessDefinitionCacheEntry>(processDefinitionCacheLimit);
      }
    }
  }"
"public static long numVectors(INDArray arr) {
        if (arr.rank() == 1)
            return 1;
        else if (arr.rank() == 2)
            return arr.size(0);
        else {
            int prod = 1;
            for (int i = 0; i < arr.rank() - 1; i++) {
                prod *= arr.size(i);
            }

            return prod;
        }
    }"
"private List<Object> getFilePreviews(final String[] fileList, final String locationFull,
      final IStreamProvider streamProvider, final boolean renderResultsAsHtml) {
    final List<Object> files = new ArrayList<>();
    InputStream csvInputStream = null;

    try {
      for (final String fileName : fileList) {
        final Map<String, Object> file = new HashMap<>();
        file.put(""name"", fileName);

        final String filePath = locationFull + ""/"" + fileName;
        csvInputStream = streamProvider.getFileInputStream(filePath);
        final Scanner rowScanner = new Scanner(csvInputStream, StandardCharsets.UTF_8.toString());

        final List<Object> lines = new ArrayList<>();
        int lineNumber = 0;
        while (rowScanner.hasNextLine()
            && lineNumber < ReportalMailCreator.NUM_PREVIEW_ROWS) {
          final String csvLine = rowScanner.nextLine();
          final String[] data = csvLine.split(""\"",\"""");
          final List<String> line = new ArrayList<>();
          for (final String item : data) {
            String column = item.replace(""\"""", """");
            if (!renderResultsAsHtml) {
              column = StringEscapeUtils.escapeHtml(column);
            }
            line.add(column);
          }
          lines.add(line);
          lineNumber++;
        }

        file.put(""content"", lines);

        if (rowScanner.hasNextLine()) {
          file.put(""hasMore"", true);
        }

        files.add(file);
        rowScanner.close();
      }
    } catch (final Exception e) {
      logger.debug(""Error encountered while processing files in ""
          + locationFull, e);
    } finally {
      IOUtils.closeQuietly(csvInputStream);
    }

    return files;
  }"
"public static int universal(char[] key, int mask, int[] tab) {
		int hash = key.length, i, len = key.length;
		for (i = 0; i < (len << 3); i += 8) {
			char k = key[i >> 3];
			if ((k & 0x01) == 0) {
				hash ^= tab[i + 0];
			}
			if ((k & 0x02) == 0) {
				hash ^= tab[i + 1];
			}
			if ((k & 0x04) == 0) {
				hash ^= tab[i + 2];
			}
			if ((k & 0x08) == 0) {
				hash ^= tab[i + 3];
			}
			if ((k & 0x10) == 0) {
				hash ^= tab[i + 4];
			}
			if ((k & 0x20) == 0) {
				hash ^= tab[i + 5];
			}
			if ((k & 0x40) == 0) {
				hash ^= tab[i + 6];
			}
			if ((k & 0x80) == 0) {
				hash ^= tab[i + 7];
			}
		}
		return (hash & mask);
	}"
"public static <E extends Enum<E>> EnumSet<E> processBits(final Class<E> enumClass, final long value) {
		return EnumUtils.processBitVector(enumClass, value);
	}"
"public static RootUriTemplateHandler addTo(RestTemplate restTemplate,
			String rootUri) {
		Assert.notNull(restTemplate, ""RestTemplate must not be null"");
		RootUriTemplateHandler handler = new RootUriTemplateHandler(rootUri,
				restTemplate.getUriTemplateHandler());
		restTemplate.setUriTemplateHandler(handler);
		return handler;
	}"
"Map<Integer, List<Integer>> initTreeMap() {
        Map<Integer, List<Integer>> treeMap = new LinkedHashMap<>(numWorkers);
        for(int r = 0; r < numWorkers; r++) {
            treeMap.put(r, getNeighbours(r));
        }
        return treeMap;
    }"
"public SingleOutputStreamOperator<T> reduce(ReduceFunction<T> reducer) {
		return transform(""Keyed Reduce"", getType(), new StreamGroupedReduce<T>(
				clean(reducer), getType().createSerializer(getExecutionConfig())));
	}"
"@Override
  public void deselectAll() {
    if (!isMultiple()) {
      throw new UnsupportedOperationException(
        ""You may only deselect all options of a multi-select"");
    }

    for (WebElement option : getOptions()) {
      setSelected(option, false);
    }
  }"
"public static String getConfPath() {
        String classpath = CommonUtils.class.getResource(""/"").getPath();
        String confPath = classpath + ""../conf/"";
        if (new File(confPath).exists()) {
            return confPath;
        } else {
            return classpath;
        }
    }"
"@Override
    public DataSet next(int num) {
        DataSet ret = iter.next(num);
        ret.setLabels(ret.getFeatures());
        return ret;
    }"
"public StrBuilder del(int start, int end) {
		if (start < 0) {
			start = 0;
		}
		if (end > this.position) {
			end = this.position;
		}
		if (start > end) {
			throw new StringIndexOutOfBoundsException(""Start is greater than End."");
		}
		if (end == this.position) {
			this.position = start;
		}

		int len = end - start;
		if (len > 0) {
			System.arraycopy(value, start + len, value, start, this.position - end);
			this.position -= len;
		}
		return this;
	}"
"public static ValueCreator byStaticMethodInvocation(final Class<?> compatibleType, final String methodName)
    {
        return new ValueCreator()
        {
            public Object createValue(Class<?> type, String value)
            {
                Object v = null;
                if (compatibleType.isAssignableFrom(type))
                {
                    try
                    {
                        Method m = type.getMethod(methodName, String.class);
                        return m.invoke(null, value);
                    }
                    catch (NoSuchMethodException e)
                    {
                        // ignore
                    }
                    catch (Exception e)
                    {
                        throw new IllegalArgumentException(String.format(""could not invoke %s#%s to create an obejct from %s"", type.toString(), methodName, value));
                    }
                }
                return v;
            }
        };
    }"
"@Override
    public void close() throws IOException {
        if (!closed) {
            try {
                if (!eof) {
                    exhaustInputStream(this);
                }
            } finally {
                eof = true;
                closed = true;
            }
        }
    }"
"protected <T extends TicketGrantingTicket> T produceTicket(final Authentication authentication,
                                                               final String tgtId, final Class<T> clazz) {
        val result = new TicketGrantingTicketImpl(tgtId, authentication, this.ticketGrantingTicketExpirationPolicy);
        if (!clazz.isAssignableFrom(result.getClass())) {
            throw new ClassCastException(""Result ["" + result
                + "" is of type "" + result.getClass()
                + "" when we were expecting "" + clazz);
        }
        return (T) result;
    }"
"public static JobGraph createJobGraph(
		PackagedProgram packagedProgram,
		Configuration configuration,
		int defaultParallelism) throws ProgramInvocationException {
		return createJobGraph(packagedProgram, configuration, defaultParallelism, null);
	}"
"public void rmLittlePathByScore() {
        int maxTo = -1;
        Term temp = null;
        for (int i = 0; i < terms.length; i++) {
            if (terms[i] == null) {
                continue;
            }
            Term maxTerm = null;
            double maxScore = 0;
            Term term = terms[i];
            // 找到自身分数对大最长的

            do {
                if (maxTerm == null || maxScore > term.score()) {
                    maxTerm = term;
                } else if (maxScore == term.score() && maxTerm.getName().length() < term.getName().length()) {
                    maxTerm = term;
                }

            } while ((term = term.next()) != null);
            term = maxTerm;
            do {
                maxTo = term.toValue();
                maxScore = term.score();
                if (maxTo - i == 1 || i + 1 == terms.length)
                    continue;
                boolean flag = true;// 可以删除
                out: for (int j = i; j < maxTo; j++) {
                    temp = terms[j];
                    if (temp == null) {
                        continue;
                    }
                    do {
                        if (temp.toValue() > maxTo || temp.score() < maxScore) {
                            flag = false;
                            break out;
                        }
                    } while ((temp = temp.next()) != null);
                }
                // 验证通过可以删除了
                if (flag) {
                    for (int j = i + 1; j < maxTo; j++) {
                        terms[j] = null;
                    }
                }
            } while ((term = term.next()) != null);
        }
    }"
"public void learn(Graph graph, SplitWord splitWord, Forest... forests) {

        this.splitWord = splitWord;

        this.forests = forests;

        // 亚洲人名识别
        if (isAsianName) {
            findAsianPerson(graph);
        }

        // 外国人名识别
        if (isForeignName) {
            findForeignPerson(graph);
        }

    }"
"private Set<String> getJarMemberSet(String absolutePathToJar) {
		/*
		 * Note:
		 * Our implementation returns a HashSet. initialCapacity and loadFactor are carefully tweaked for speed and RAM optimization purposes.
		 * 
		 * Benchmark:
		 * The HashSet implementation is about 10% slower to build (only happens once) than the ArrayList.
		 * The HashSet with shiftBits = 1 was about 33 times(!) faster than the ArrayList for retrievals.
		 */
		try {
			int shiftBits = 1;  //  (fast, but big)  0 <= shiftBits <= 5, say  (slower & compact)
			JarFile jar = new JarFile(absolutePathToJar);
			
			/*
			 * Find the first power of 2 >= JarSize (as calculated in HashSet constructor)
			 */
			int jarSizePower2 = Integer.highestOneBit(jar.size());
			if (jarSizePower2 != jar.size()) jarSizePower2 <<= 1;
			if (jarSizePower2 == 0) jarSizePower2 = 1;
			
			Set<String> jarMembers = new HashSet<String>(jarSizePower2 >> shiftBits,  1 << shiftBits);
			try {
				Enumeration<JarEntry> entries = jar.entries();
				while (entries.hasMoreElements()) {
					JarEntry jarEntry = entries.nextElement();
					if (jarEntry.isDirectory()) continue;
					jarMembers.add(jarEntry.getName());
				}
			} catch (Exception ignore) {
				// ignored; if the jar can't be read, treating it as if the jar contains no classes is just what we want.
			} finally {
				jar.close();
			}
			return jarMembers;
		}
		catch (Exception newJarFileException) {
			return Collections.emptySet();
		}
	}"
"public static String insertColumns(Class<?> entityClass, boolean skipId, boolean notNull, boolean notEmpty) {
        StringBuilder sql = new StringBuilder();
        sql.append(""<trim prefix=\""(\"" suffix=\"")\"" suffixOverrides=\"",\"">"");
        //获取全部列
        Set<EntityColumn> columnSet = EntityHelper.getColumns(entityClass);
        //当某个列有主键策略时，不需要考虑他的属性是否为空，因为如果为空，一定会根据主键策略给他生成一个值
        for (EntityColumn column : columnSet) {
            if (!column.isInsertable()) {
                continue;
            }
            if (skipId && column.isId()) {
                continue;
            }
            if (notNull) {
                sql.append(SqlHelper.getIfNotNull(column, column.getColumn() + "","", notEmpty));
            } else {
                sql.append(column.getColumn() + "","");
            }
        }
        sql.append(""</trim>"");
        return sql.toString();
    }"
"public static <T extends Message> Marshaller<T> marshaller(final T defaultInstance) {
    return ProtoLiteUtils.marshaller(defaultInstance);
  }"
"@Override
  public UnsafeRow getKeyRow(int rowId) {
    assert(rowId >= 0);
    assert(rowId < numRows);
    if (keyRowId != rowId) { // if keyRowId == rowId, desired keyRow is already cached
      long offset = keyOffsets[rowId];
      int klen = Platform.getInt(base, offset - 4);
      keyRow.pointTo(base, offset, klen);
      // set keyRowId so we can check if desired row is cached
      keyRowId = rowId;
    }
    return keyRow;
  }"
"public boolean isRestartScheduled() {
        for (UpdateCenterJob job : getJobs()) {
            if (job instanceof RestartJenkinsJob) {
                RestartJenkinsJob.RestartJenkinsJobStatus status = ((RestartJenkinsJob) job).status;
                if (status instanceof RestartJenkinsJob.Pending
                        || status instanceof RestartJenkinsJob.Running) {
                    return true;
                }
            }
        }
        return false;
    }"
"public void putStats(String route, String cause) {
        if (route == null) route = ""UNKNOWN_ROUTE"";
        route = route.replace(""/"", ""_"");
        ConcurrentHashMap<String, ErrorStatsData> statsMap = routeMap.get(route);
        if (statsMap == null) {
            statsMap = new ConcurrentHashMap<String, ErrorStatsData>();
            routeMap.putIfAbsent(route, statsMap);
        }
        ErrorStatsData sd = statsMap.get(cause);
        if (sd == null) {
            sd = new ErrorStatsData(route, cause);
            ErrorStatsData sd1 = statsMap.putIfAbsent(cause, sd);
            if (sd1 != null) {
                sd = sd1;
            } else {
                MonitorRegistry.getInstance().registerObject(sd);
            }
        }
        sd.update();
    }"
"public static boolean isRunningInExpectedThread(@Nullable Thread expected) {
		Thread actual = Thread.currentThread();
		if (expected != actual) {

			String violationMsg = ""Violation of main thread constraint detected: expected <""
				+ expected + ""> but running in <"" + actual + "">."";

			LOG.warn(violationMsg, new Exception(violationMsg));

			return false;
		}

		return true;
	}"
"protected AuthenticationHandlerExecutionResult finalizeAuthenticationHandlerResult(final ClientCredential credentials,
                                                                                       final Principal principal,
                                                                                       final UserProfile profile,
                                                                                       final BaseClient client) {
        preFinalizeAuthenticationHandlerResult(credentials, principal, profile, client);
        return createHandlerResult(credentials, principal, new ArrayList<>(0));
    }"
"public static INDArray toMatrix(Matrix arr) {

        // we assume that Matrix always has F order
        return Nd4j.create(arr.toArray(), new int[] {arr.numRows(), arr.numCols()}, 'f');
    }"
"@Deprecated
    @CheckForNull
    public Computer getComputer() {
        for( Computer c : Jenkins.getInstance().getComputers() )
            if(c.getChannel()==channel)
                return c;
        return null;
    }"
"protected Collection<Ticket> decodeTickets(final Collection<Ticket> items) {
        return decodeTickets(items.stream()).collect(Collectors.toSet());
    }"
"public static void registerKey(Binder binder, Key<DruidNode> key)
  {
    DruidBinders.discoveryAnnouncementBinder(binder).addBinding().toInstance(new KeyHolder<>(key));
    LifecycleModule.register(binder, ServiceAnnouncer.class);
  }"
"static TimeUnit parseTimeUnit(String key, @Nullable String value) {
    requireArgument((value != null) && !value.isEmpty(), ""value of key %s omitted"", key);
    @SuppressWarnings(""NullAway"")
    char lastChar = Character.toLowerCase(value.charAt(value.length() - 1));
    switch (lastChar) {
      case 'd':
        return TimeUnit.DAYS;
      case 'h':
        return TimeUnit.HOURS;
      case 'm':
        return TimeUnit.MINUTES;
      case 's':
        return TimeUnit.SECONDS;
      default:
        throw new IllegalArgumentException(String.format(
            ""key %s invalid format; was %s, must end with one of [dDhHmMsS]"", key, value));
    }
  }"
"private static int handleParametrizationException(ProgramParametrizationException e) {
		LOG.error(""Program has not been parametrized properly."", e);
		System.err.println(e.getMessage());
		return 1;
	}"
"public static <K, V> Map<K, V> wrap(final Map<K, V> source) {
        if (source != null && !source.isEmpty()) {
            return new HashMap<>(source);
        }
        return new HashMap<>(0);
    }"
"private MethodDeclaration generateToBuilderMethod(String builderClassName, String builderImplClassName, EclipseNode type, TypeParameter[] typeParams, ASTNode source) {
		int pS = source.sourceStart, pE = source.sourceEnd;
		long p = (long) pS << 32 | pE;
		
		MethodDeclaration out = new MethodDeclaration(((CompilationUnitDeclaration) type.top().get()).compilationResult);
		out.selector = TO_BUILDER_METHOD_NAME;
		out.modifiers = ClassFileConstants.AccPublic;
		out.bits |= ECLIPSE_DO_NOT_TOUCH_FLAG;
		
		TypeReference[] wildcards = new TypeReference[] {new Wildcard(Wildcard.UNBOUND), new Wildcard(Wildcard.UNBOUND) };
		out.returnType = new ParameterizedSingleTypeReference(builderClassName.toCharArray(), mergeToTypeReferences(typeParams, wildcards), 0, p);
		
		AllocationExpression newClass = new AllocationExpression();
		newClass.type = namePlusTypeParamsToTypeReference(builderImplClassName.toCharArray(), typeParams, p);
		MessageSend invokeFillMethod = new MessageSend();
		invokeFillMethod.receiver = newClass;
		invokeFillMethod.selector = FILL_VALUES_METHOD_NAME;
		invokeFillMethod.arguments = new Expression[] {new ThisReference(0, 0)};
		out.statements = new Statement[] {new ReturnStatement(invokeFillMethod, pS, pE)};
		
		out.traverse(new SetGeneratedByVisitor(source), ((TypeDeclaration) type.get()).scope);
		return out;
	}"
"public static String getClientIdFromAuthenticatedProfile(final CommonProfile profile) {
        if (profile.containsAttribute(OAuth20Constants.CLIENT_ID)) {
            val attribute = profile.getAttribute(OAuth20Constants.CLIENT_ID);
            return CollectionUtils.toCollection(attribute, ArrayList.class).get(0).toString();
        }
        return null;
    }"
"public void set(T value) {
        HystrixRequestContext.getContextForCurrentThread().state.put(this, new LazyInitializer<T>(this, value));
    }"
"@Restricted(Beta.class)
    public void setChannel(@Nonnull ChannelBuilder cb,
                           @Nonnull CommandTransport commandTransport,
                           @CheckForNull Channel.Listener listener) throws IOException, InterruptedException {
        for (ChannelConfigurator cc : ChannelConfigurator.all()) {
            cc.onChannelBuilding(cb,this);
        }

        OutputStream headerStream = cb.getHeaderStream();
        if (headerStream == null) {
            LOGGER.log(Level.WARNING, ""No header stream defined when setting channel for computer {0}. "" +
                    ""Launch log won't be printed"", this);
        }
        Channel channel = cb.build(commandTransport);
        setChannel(channel, headerStream, listener);
    }"
"public static String whereLogicDelete(Class<?> entityClass, boolean isDeleted) {
        String value = logicDeleteColumnEqualsValue(entityClass, isDeleted);
        return """".equals(value) ? """" : "" AND "" + value;
    }"
"static void buildHashTable(Block keyBlock, int keyOffset, int keyCount, MethodHandle keyBlockHashCode, int[] outputHashTable, int hashTableOffset, int hashTableSize)
    {
        for (int i = 0; i < keyCount; i++) {
            int hash = getHashPosition(keyBlock, keyOffset + i, keyBlockHashCode, hashTableSize);
            while (true) {
                if (outputHashTable[hashTableOffset + hash] == -1) {
                    outputHashTable[hashTableOffset + hash] = i;
                    break;
                }
                hash++;
                if (hash == hashTableSize) {
                    hash = 0;
                }
            }
        }
    }"
"private void deleteIfEmpty(File dir) {
        String[] r = dir.list();
        if(r==null)     return; // can happen in a rare occasion
        if(r.length==0)
            dir.delete();
    }"
"public static <T> void forEach(Iterator<T> iterator, Consumer<T> consumer) {
		int index = 0;
		while (iterator.hasNext()) {
			consumer.accept(iterator.next(), index);
			index++;
		}
	}"
"public void registerKvState(KeyGroupRange keyGroupRange, String registrationName, InternalKvState<?, ?, ?> kvState) {
		KvStateID kvStateId = registry.registerKvState(jobId, jobVertexId, keyGroupRange, registrationName, kvState);
		registeredKvStates.add(new KvStateInfo(keyGroupRange, registrationName, kvStateId));
	}"
"@SafeVarargs
	@SuppressWarnings(""unchecked"")
	public final PythonDataStream union(PythonDataStream... streams) {
		ArrayList<DataStream<PyObject>> dsList = new ArrayList<>();
		for (PythonDataStream ps : streams) {
			dsList.add(ps.stream);
		}
		DataStream<PyObject>[] dsArray = new DataStream[dsList.size()];
		return new PythonDataStream(stream.union(dsList.toArray(dsArray)));
	}"
"private boolean blockOnPipeLine() {
    if (this.isKilled()) {
      return true;
    }

    // For pipelining of jobs. Will watch other jobs.
    if (!this.pipelineJobs.isEmpty()) {
      String blockedList = """";
      final ArrayList<BlockingStatus> blockingStatus =
          new ArrayList<>();
      for (final String waitingJobId : this.pipelineJobs) {
        final Status status = this.watcher.peekStatus(waitingJobId);
        if (status != null && !Status.isStatusFinished(status)) {
          final BlockingStatus block = this.watcher.getBlockingStatus(waitingJobId);
          blockingStatus.add(block);
          blockedList += waitingJobId + "","";
        }
      }
      if (!blockingStatus.isEmpty()) {
        this.logger.info(""Pipeline job "" + this.jobId + "" waiting on "" + blockedList
            + "" in execution "" + this.watcher.getExecId());

        for (final BlockingStatus bStatus : blockingStatus) {
          this.logger.info(""Waiting on pipelined job "" + bStatus.getJobId());
          this.currentBlockStatus = bStatus;
          bStatus.blockOnFinishedStatus();
          if (this.isKilled()) {
            this.logger.info(""Job was killed while waiting on pipeline. Quiting."");
            return true;
          } else {
            this.logger.info(""Pipelined job "" + bStatus.getJobId() + "" finished."");
          }
        }
      }
    }

    this.currentBlockStatus = null;
    return false;
  }"
"public List<Item> getQueuedItems() {
        LinkedList<Item> list = new LinkedList<>();
        for (Item item : Jenkins.getInstance().getQueue().getItems()) {
            if (item.task == owner) {
                list.addFirst(item);
            }
        }
    	return list;
    }"
"public KerasModelBuilder modelJsonInputStream(InputStream modelJsonInputStream) throws IOException {
        ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream();
        IOUtils.copy(modelJsonInputStream, byteArrayOutputStream);
        this.modelJson = new String(byteArrayOutputStream.toByteArray());
        return this;
    }"
"public boolean failAndRecycle(Throwable cause) {
        ReferenceCountUtil.release(msg);
        if (promise != null) {
            promise.setFailure(cause);
        }
        return recycle();
    }"
"private int doRegister(int registrations) {
        // adjustment to state
        long adjust = ((long)registrations << PARTIES_SHIFT) | registrations;
        final Phaser parent = this.parent;
        int phase;
        for (;;) {
            long s = (parent == null) ? state : reconcileState();
            int counts = (int)s;
            int parties = counts >>> PARTIES_SHIFT;
            int unarrived = counts & UNARRIVED_MASK;
            if (registrations > MAX_PARTIES - parties)
                throw new IllegalStateException(badRegister(s));
            phase = (int)(s >>> PHASE_SHIFT);
            if (phase < 0)
                break;
            if (counts != EMPTY) {                  // not 1st registration
                if (parent == null || reconcileState() == s) {
                    if (unarrived == 0)             // wait out advance
                        root.internalAwaitAdvance(phase, null);
                    else if (UNSAFE.compareAndSwapLong(this, stateOffset,
                                                       s, s + adjust))
                        break;
                }
            }
            else if (parent == null) {              // 1st root registration
                long next = ((long)phase << PHASE_SHIFT) | adjust;
                if (UNSAFE.compareAndSwapLong(this, stateOffset, s, next))
                    break;
            }
            else {
                synchronized (this) {               // 1st sub registration
                    if (state == s) {               // recheck under lock
                        phase = parent.doRegister(1);
                        if (phase < 0)
                            break;
                        // finish registration whenever parent registration
                        // succeeded, even when racing with termination,
                        // since these are part of the same ""transaction"".
                        while (!UNSAFE.compareAndSwapLong
                               (this, stateOffset, s,
                                ((long)phase << PHASE_SHIFT) | adjust)) {
                            s = state;
                            phase = (int)(root.state >>> PHASE_SHIFT);
                            // assert (int)s == EMPTY;
                        }
                        break;
                    }
                }
            }
        }
        return phase;
    }"
"public boolean getBoolean(String key, boolean defaultResponse) {
        Boolean b = (Boolean) get(key);
        if (b != null) {
            return b.booleanValue();
        }
        return defaultResponse;
    }"
"public static long copyByNIO(InputStream in, OutputStream out, int bufferSize, StreamProgress streamProgress) throws IORuntimeException {
		return copy(Channels.newChannel(in), Channels.newChannel(out), bufferSize, streamProgress);
	}"
"public String readStringNul() {
        byte[] result = new byte[byteBuf.bytesBefore((byte) 0)];
        byteBuf.readBytes(result);
        byteBuf.skipBytes(1);
        return new String(result);
    }"
"public static void send(MailAccount mailAccount, Collection<String> tos, String subject, String content, boolean isHtml, File... files) {
		Mail.create(mailAccount)//
				.setTos(tos.toArray(new String[tos.size()]))//
				.setTitle(subject)//
				.setContent(content)//
				.setHtml(isHtml)//
				.setFiles(files)//
				.send();
	}"
"public static Excel03SaxReader read03BySax(String path, int sheetIndex, RowHandler rowHandler) {
		try {
			return new Excel03SaxReader(rowHandler).read(path, sheetIndex);
		} catch (NoClassDefFoundError e) {
			throw new DependencyException(ObjectUtil.defaultIfNull(e.getCause(), e), PoiChecker.NO_POI_ERROR_MSG);
		}
	}"
"public static HttpResponseStatus parseLine(String line) {
        try {
            int space = line.indexOf(' ');
            return space == -1 ? valueOf(parseInt(line)) :
                    valueOf(parseInt(line.substring(0, space)), line.substring(space + 1));
        } catch (Exception e) {
            throw new IllegalArgumentException(""malformed status line: "" + line, e);
        }
    }"
"public static INDArray convn(INDArray input, INDArray kernel, Type type, int[] axes) {
        return Nd4j.getConvolution().convn(input, kernel, type, axes);
    }"
"@Override public SpanStore spanStore() {
    if (spanStore == null) {
      synchronized (this) {
        if (spanStore == null) {
          spanStore = new CassandraSpanStore(this);
        }
      }
    }
    return spanStore;
  }"
"public static int roundUpToPowerOfTwo(int x) {
		x = x - 1;
		x |= x >> 1;
		x |= x >> 2;
		x |= x >> 4;
		x |= x >> 8;
		x |= x >> 16;
		return x + 1;
	}"
"public INDArray inferVector(@NonNull List<VocabWord> document, double learningRate, double minLearningRate,
                    int iterations) {

        if (this.vocab == null || this.vocab.numWords() == 0)
            reassignExistingModel();

        SequenceLearningAlgorithm<VocabWord> learner = sequenceLearningAlgorithm;

        if (learner == null) {
            synchronized (this) {
                if (sequenceLearningAlgorithm == null) {
                    log.info(""Creating new PV-DM learner..."");
                    learner = new DM<>();
                    learner.configure(vocab, lookupTable, configuration);
                    sequenceLearningAlgorithm = learner;
                } else {
                    learner = sequenceLearningAlgorithm;
                }
            }
        }

        learner = sequenceLearningAlgorithm;



        if (document.isEmpty())
            throw new ND4JIllegalStateException(""Impossible to apply inference to empty list of words"");


        Sequence<VocabWord> sequence = new Sequence<>();
        sequence.addElements(document);
        sequence.setSequenceLabel(new VocabWord(1.0, String.valueOf(new Random().nextInt())));

        initLearners();

        INDArray inf = learner.inferSequence(sequence, seed, learningRate, minLearningRate, iterations);

        return inf;
    }"
"@Override
	public FieldList addField(Integer fieldID) {
		if (fieldID == null) {
			throw new IllegalArgumentException(""Field ID must not be null."");
		}
		
		if (size() == 0) {
			return new FieldList(fieldID);
		} else {
			ArrayList<Integer> list = new ArrayList<Integer>(size() + 1);
			list.addAll(this.collection);
			list.add(fieldID);
			return new FieldList(Collections.unmodifiableList(list));
		}
	}"
"private String setParameter(HttpMessage msg, NameValuePair originalPair, String paramName, String value, boolean escaped) {
	try {
            if (script != null) {
                currentParam = originalPair;
                script.setParameter(this, msg, paramName, value, escaped);
            }
                        
        } catch (Exception e) {
            // Catch Exception instead of ScriptException because script engine implementations might
            // throw other exceptions on script errors (e.g. jdk.nashorn.internal.runtime.ECMAException)
            extension.handleScriptException(wrapper, e);
        } finally {
            currentParam = null;
        }
        
        return value;
    }"
"public String nextString()
    {
        char[] buffer = new char[nextInt()];
        for (int i = 0; i < buffer.length; ++i)
        {
            buffer[i] = nextChar();
        }
        return new String(buffer);
    }"
"public static List<String> filterCommands(Collection<String> commands, String whitelistRegex,
      String blacklistRegex, Logger log) {
    List<String> filteredCommands = new LinkedList<String>();
    Pattern whitelistPattern = Pattern.compile(whitelistRegex);
    Pattern blacklistPattern = Pattern.compile(blacklistRegex);
    for (String command : commands) {
      if (whitelistPattern.matcher(command).matches()
          && !blacklistPattern.matcher(command).matches()) {
        filteredCommands.add(command);
      } else {
        log.warn(String.format(""Removing restricted command: %s"", command));
      }
    }
    return filteredCommands;
  }"
"protected void handleMessage(@NonNull VoidMessage message) {
        if (message == null) {
            //            log.info(""sI_{} got null message"", getShardIndex());
            return;
        }

        if (message.getTargetId() >= 0 && message.getTargetId() != shardIndex) {
            log.warn(""sI_{}: Skipping message: [{}]; TargetIdx: [{}]"", shardIndex, message.getClass().getSimpleName(),
                            message.getTargetId());
            return;
        }

        //      log.info(""sI_{}: Processing message: [{}]"", shardIndex, message.getClass().getSimpleName());

        message.attachContext(voidConfiguration, trainer, clipboard, transport, storage, nodeRole, shardIndex);
        message.processMessage();
    }"
"public static ImageWriter getWriter(String formatName) {
		ImageWriter writer = null;
		Iterator<ImageWriter> iter = ImageIO.getImageWritersByFormatName(formatName);
		if (iter.hasNext()) {
			writer = iter.next();
		}
		if (null == writer) {
			// 尝试扩展名获取
			iter = ImageIO.getImageWritersBySuffix(formatName);
			if (iter.hasNext()) {
				writer = iter.next();
			}
		}
		return writer;
	}"
"@Override
    public synchronized double learnSequence(@NonNull Sequence<T> sequence, @NonNull AtomicLong nextRandom,
                    double learningRate) {
        /*
                GloVe learning algorithm is implemented like a hack over settled ElementsLearningAlgorithm mechanics. It's called in SequenceVectors context, but actually only for the first call.
                All subsequent calls will met early termination condition, and will be successfully ignored. But since elements vectors will be updated within first call,
                this will allow compatibility with everything beyond this implementaton
         */
        if (isTerminate.get())
            return 0;

        final AtomicLong pairsCount = new AtomicLong(0);
        final Counter<Integer> errorCounter = new Counter<>();

        //List<Pair<T, T>> coList = coOccurrences.coOccurrenceList();

        for (int i = 0; i < configuration.getEpochs(); i++) {

            // TODO: shuffle should be built in another way.
            //if (shuffle)
            //Collections.shuffle(coList);

            Iterator<Pair<Pair<T, T>, Double>> pairs = coOccurrences.iterator();

            List<GloveCalculationsThread> threads = new ArrayList<>();
            for (int x = 0; x < workers; x++) {
                threads.add(x, new GloveCalculationsThread(i, x, pairs, pairsCount, errorCounter));
                threads.get(x).start();
            }



            for (int x = 0; x < workers; x++) {
                try {
                    threads.get(x).join();
                } catch (Exception e) {
                    throw new RuntimeException(e);
                }
            }

            log.info(""Processed ["" + pairsCount.get() + ""] pairs, Error was ["" + errorCounter.getCount(i) + ""]"");
        }

        isTerminate.set(true);
        return 0;
    }"
"public static <T> T readVersionAndDeSerialize(SimpleVersionedSerializer<T> serializer, DataInputView in) throws IOException {
		checkNotNull(serializer, ""serializer"");
		checkNotNull(in, ""in"");

		final int version = in.readInt();
		final int length = in.readInt();
		final byte[] data = new byte[length];
		in.readFully(data);

		return serializer.deserialize(version, data);
	}"
"public static List<List<OperatorStateHandle>> applyRepartitioner(
		OperatorStateRepartitioner opStateRepartitioner,
		List<List<OperatorStateHandle>> chainOpParallelStates,
		int oldParallelism,
		int newParallelism) {

		if (chainOpParallelStates == null) {
			return Collections.emptyList();
		}

		return opStateRepartitioner.repartitionState(
			chainOpParallelStates,
			oldParallelism,
			newParallelism);
		}"
"public static boolean isUsableLocalPort(int port) {
		if (false == isValidPort(port)) {
			// 给定的IP未在指定端口范围中
			return false;
		}
		try {
			ServerSocketFactory.getDefault().createServerSocket(port, 1, InetAddress.getByName(LOCAL_IP)).close();
			return true;
		} catch (Exception e) {
			return false;
		}
	}"
"static FileSystem wrapWithSafetyNetWhenActivated(FileSystem fs) {
		SafetyNetCloseableRegistry reg = REGISTRIES.get();
		return reg != null ? new SafetyNetWrapperFileSystem(fs, reg) : fs;
	}"
"public boolean getBoolean(String key, boolean defaultValue) {
		Object o = getRawValue(key);
		if (o == null) {
			return defaultValue;
		}

		return convertToBoolean(o);
	}"
"protected final boolean readLine() throws IOException {
		if (this.stream == null || this.overLimit) {
			return false;
		}

		int countInWrapBuffer = 0;

		// position of matching positions in the delimiter byte array
		int delimPos = 0;

		while (true) {
			if (this.readPos >= this.limit) {
				// readBuffer is completely consumed. Fill it again but keep partially read delimiter bytes.
				if (!fillBuffer(delimPos)) {
					int countInReadBuffer = delimPos;
					if (countInWrapBuffer + countInReadBuffer > 0) {
						// we have bytes left to emit
						if (countInReadBuffer > 0) {
							// we have bytes left in the readBuffer. Move them into the wrapBuffer
							if (this.wrapBuffer.length - countInWrapBuffer < countInReadBuffer) {
								// reallocate
								byte[] tmp = new byte[countInWrapBuffer + countInReadBuffer];
								System.arraycopy(this.wrapBuffer, 0, tmp, 0, countInWrapBuffer);
								this.wrapBuffer = tmp;
							}

							// copy readBuffer bytes to wrapBuffer
							System.arraycopy(this.readBuffer, 0, this.wrapBuffer, countInWrapBuffer, countInReadBuffer);
							countInWrapBuffer += countInReadBuffer;
						}

						this.offset += countInWrapBuffer;
						setResult(this.wrapBuffer, 0, countInWrapBuffer);
						return true;
					} else {
						return false;
					}
				}
			}

			int startPos = this.readPos - delimPos;
			int count;

			// Search for next occurrence of delimiter in read buffer.
			while (this.readPos < this.limit && delimPos < this.delimiter.length) {
				if ((this.readBuffer[this.readPos]) == this.delimiter[delimPos]) {
					// Found the expected delimiter character. Continue looking for the next character of delimiter.
					delimPos++;
				} else {
					// Delimiter does not match.
					// We have to reset the read position to the character after the first matching character
					//   and search for the whole delimiter again.
					readPos -= delimPos;
					delimPos = 0;
				}
				readPos++;
			}

			// check why we dropped out
			if (delimPos == this.delimiter.length) {
				// we found a delimiter
				int readBufferBytesRead = this.readPos - startPos;
				this.offset += countInWrapBuffer + readBufferBytesRead;
				count = readBufferBytesRead - this.delimiter.length;

				// copy to byte array
				if (countInWrapBuffer > 0) {
					// check wrap buffer size
					if (this.wrapBuffer.length < countInWrapBuffer + count) {
						final byte[] nb = new byte[countInWrapBuffer + count];
						System.arraycopy(this.wrapBuffer, 0, nb, 0, countInWrapBuffer);
						this.wrapBuffer = nb;
					}
					if (count >= 0) {
						System.arraycopy(this.readBuffer, 0, this.wrapBuffer, countInWrapBuffer, count);
					}
					setResult(this.wrapBuffer, 0, countInWrapBuffer + count);
					return true;
				} else {
					setResult(this.readBuffer, startPos, count);
					return true;
				}
			} else {
				// we reached the end of the readBuffer
				count = this.limit - startPos;
				
				// check against the maximum record length
				if (((long) countInWrapBuffer) + count > this.lineLengthLimit) {
					throw new IOException(""The record length exceeded the maximum record length ("" + 
							this.lineLengthLimit + "")."");
				}

				// Compute number of bytes to move to wrapBuffer
				// Chars of partially read delimiter must remain in the readBuffer. We might need to go back.
				int bytesToMove = count - delimPos;
				// ensure wrapBuffer is large enough
				if (this.wrapBuffer.length - countInWrapBuffer < bytesToMove) {
					// reallocate
					byte[] tmp = new byte[Math.max(this.wrapBuffer.length * 2, countInWrapBuffer + bytesToMove)];
					System.arraycopy(this.wrapBuffer, 0, tmp, 0, countInWrapBuffer);
					this.wrapBuffer = tmp;
				}

				// copy readBuffer to wrapBuffer (except delimiter chars)
				System.arraycopy(this.readBuffer, startPos, this.wrapBuffer, countInWrapBuffer, bytesToMove);
				countInWrapBuffer += bytesToMove;
				// move delimiter chars to the beginning of the readBuffer
				System.arraycopy(this.readBuffer, this.readPos - delimPos, this.readBuffer, 0, delimPos);

			}
		}
	}"
"public float getFloat(String key, float defaultValue) {
		String argument = getProperty(key, null);
		return argument == null
			? defaultValue
			: Float.parseFloat(argument);
	}"
"public static ValidationStatus getInfoMsgLevel(final String msg) {
    if (msg.startsWith(""ERROR"")) {
      return ValidationStatus.ERROR;
    }
    if (msg.startsWith(""WARN"")) {
      return ValidationStatus.WARN;
    }
    return ValidationStatus.PASS;
  }"
"public static String hostAndPortToUrlString(String host, int port) throws UnknownHostException {
		return ipAddressAndPortToUrlString(InetAddress.getByName(host), port);
	}"
"@Override
  public boolean loginHandler(String target, HttpServletRequest request, HttpServletResponse response) throws IOException {
    if (! isLoginTarget(target)) {
      return false;
    }

    if (isPageRequest(request)) {
      sendLoginForm(request, response);
    } else {
      ServletUtils.sendResponseError(response, HttpServletResponse.SC_UNAUTHORIZED, ""Access denied. Please login."");
    }
    return true;
  }"
"public boolean isPermittedAddress(String addr) {
        if (addr == null || addr.isEmpty()) {
            return false;
        }

        for (DomainMatcher permAddr : permittedAddressesEnabled) {
            if (permAddr.matches(addr)) {
                return true;
            }
        }
        return false;
    }"
"public Map<K, V> snapshot(boolean ascending, int limit, @NonNull Function<V, V> transformer) {
    requireArgument(limit >= 0);

    Map<K, V> map = new LinkedHashMap<>(Math.min(limit, cache.size()));
    int startLevel = ascending ? 0 : wheel.length - 1;
    for (int i = 0; i < wheel.length; i++) {
      int indexOffset = ascending ? i : -i;
      int index = startLevel + indexOffset;

      int ticks = (int) (nanos >> SHIFT[index]);
      int bucketMask = (wheel[index].length - 1);
      int startBucket = (ticks & bucketMask) + (ascending ? 1 : 0);
      for (int j = 0; j < wheel[index].length; j++) {
        int bucketOffset = ascending ? j : -j;
        Node<K, V> sentinel = wheel[index][(startBucket + bucketOffset) & bucketMask];

        for (Node<K, V> node = traverse(ascending, sentinel);
            node != sentinel; node = traverse(ascending, node)) {
          if (map.size() >= limit) {
            break;
          }

          K key = node.getKey();
          V value = transformer.apply(node.getValue());
          if ((key != null) && (value != null) && node.isAlive()) {
            map.put(key, value);
          }
        }
      }
    }
    return Collections.unmodifiableMap(map);
  }"
"@PublicEvolving
	public <KS, OUT> SingleOutputStreamOperator<OUT> process(
			final KeyedBroadcastProcessFunction<KS, IN1, IN2, OUT> function,
			final TypeInformation<OUT> outTypeInfo) {

		Preconditions.checkNotNull(function);
		Preconditions.checkArgument(inputStream1 instanceof KeyedStream,
				""A KeyedBroadcastProcessFunction can only be used on a keyed stream."");

		TwoInputStreamOperator<IN1, IN2, OUT> operator =
				new CoBroadcastWithKeyedOperator<>(clean(function), broadcastStateDescriptors);
		return transform(""Co-Process-Broadcast-Keyed"", outTypeInfo, operator);
	}"
"public void timeBagOfPrimitivesReflectionStreaming(int reps) throws Exception {
    for (int i=0; i<reps; ++i) {
      StringReader reader = new StringReader(json);
      JsonReader jr = new JsonReader(reader);
      jr.beginObject();
      BagOfPrimitives bag = new BagOfPrimitives();
      while(jr.hasNext()) {
        String name = jr.nextName();
        for (Field field : BagOfPrimitives.class.getDeclaredFields()) {
          if (field.getName().equals(name)) {
            Class<?> fieldType = field.getType();
            if (fieldType.equals(long.class)) {
              field.setLong(bag, jr.nextLong());
            } else if (fieldType.equals(int.class)) {
              field.setInt(bag, jr.nextInt());
            } else if (fieldType.equals(boolean.class)) {
              field.setBoolean(bag, jr.nextBoolean());
            } else if (fieldType.equals(String.class)) {
              field.set(bag, jr.nextString());
            } else {
              throw new RuntimeException(""Unexpected: type: "" + fieldType + "", name: "" + name);
            }
          }
        }
      }
      jr.endObject();
    }
  }"
"@Override
  public void getTopChannels(
      GetTopChannelsRequest request, StreamObserver<GetTopChannelsResponse> responseObserver) {
    InternalChannelz.RootChannelList rootChannels
        = channelz.getRootChannels(request.getStartChannelId(), maxPageSize);

    GetTopChannelsResponse resp;
    try {
      resp = ChannelzProtoUtil.toGetTopChannelResponse(rootChannels);
    } catch (StatusRuntimeException e) {
      responseObserver.onError(e);
      return;
    }

    responseObserver.onNext(resp);
    responseObserver.onCompleted();
  }"
"public void registerListenerExtensions() {
    if (listenerExtensionsRegistered) {
      throw H2O.fail(""Listeners already registered"");
    }

    long before = System.currentTimeMillis();
    ServiceLoader<H2OListenerExtension> extensionsLoader = ServiceLoader.load(H2OListenerExtension.class);
    for (H2OListenerExtension ext : extensionsLoader) {
      ext.init();
      listenerExtensions.put(ext.getName(), ext);
    }
    listenerExtensionsRegistered = true;
    registerListenerExtensionsMillis = System.currentTimeMillis() - before;
  }"
"public List<String> keysForBucket(String bucket) {
        AmazonS3 s3 = getClient();
        List<String> ret = new ArrayList<>();
        ListObjectsRequest listObjectsRequest = new ListObjectsRequest().withBucketName(bucket);
        ObjectListing objectListing;

        do {
            objectListing = s3.listObjects(listObjectsRequest);
            for (S3ObjectSummary objectSummary : objectListing.getObjectSummaries()) {
                ret.add(objectSummary.getKey());
            }
            listObjectsRequest.setMarker(objectListing.getNextMarker());
        } while (objectListing.isTruncated());

        return ret;
    }"
"@Override public void init(ProcessingEnvironment procEnv) {
		super.init(procEnv);
		String className = procEnv.getClass().getName();
		if (className.startsWith(""org.eclipse.jdt."")) {
			errorToShow = ""This version of disableCheckedExceptions is not compatible with eclipse. javac only; sorry."";
			procEnv.getMessager().printMessage(Kind.WARNING, errorToShow);
		} else if (!procEnv.getClass().getName().equals(""com.sun.tools.javac.processing.JavacProcessingEnvironment"")) {
			procEnv.getMessager().printMessage(Kind.WARNING, ""You aren't using a compiler based around javac v1.6, so disableCheckedExceptions will not work.\n"" +
					""Your processor class is: "" + className);
		} else {
			new LiveInjector().inject(ClassRootFinder.findClassRootOfClass(DisableCheckedExceptionsAgent.class));
		}
	}"
"public ChannelFuture close(Channel channel, CloseWebSocketFrame frame, ChannelPromise promise) {
        if (channel == null) {
            throw new NullPointerException(""channel"");
        }
        return channel.writeAndFlush(frame, promise).addListener(ChannelFutureListener.CLOSE);
    }"
"CharSequence buildHistory() {
    StringBuilder historyText = new StringBuilder(1000);
    SQLiteOpenHelper helper = new DBHelper(activity);
    try (SQLiteDatabase db = helper.getReadableDatabase();
         Cursor cursor = db.query(DBHelper.TABLE_NAME,
                                  COLUMNS,
                                  null, null, null, null,
                                  DBHelper.TIMESTAMP_COL + "" DESC"")) {
      DateFormat format = DateFormat.getDateTimeInstance(DateFormat.MEDIUM, DateFormat.MEDIUM);
      while (cursor.moveToNext()) {

        historyText.append('""').append(massageHistoryField(cursor.getString(0))).append(""\"","");
        historyText.append('""').append(massageHistoryField(cursor.getString(1))).append(""\"","");
        historyText.append('""').append(massageHistoryField(cursor.getString(2))).append(""\"","");
        historyText.append('""').append(massageHistoryField(cursor.getString(3))).append(""\"","");

        // Add timestamp again, formatted
        long timestamp = cursor.getLong(3);
        historyText.append('""').append(massageHistoryField(format.format(timestamp))).append(""\"","");

        // Above we're preserving the old ordering of columns which had formatted data in position 5

        historyText.append('""').append(massageHistoryField(cursor.getString(4))).append(""\""\r\n"");
      }
    } catch (SQLException sqle) {
      Log.w(TAG, sqle);
    }
    return historyText;
  }"
"static float getDecompressionRatio(ByteVec bv) {
    long totalSize = 0L;
    long totalCompSize = 0L;

    if (bv instanceof FileVec) {
      String strPath = getPathForKey(((FileVec) bv)._key);

      try {
        ZipFile zipFile = new ZipFile(strPath);

        Enumeration<? extends ZipEntry> entries = zipFile.entries();

        while (entries.hasMoreElements()) {
          ZipEntry entry = entries.nextElement();
          if (!entry.isDirectory()) {// add file to list to parse if not a directory.
            totalSize = totalSize + entry.getSize();
            totalCompSize = totalCompSize + entry.getCompressedSize();
          }
        }
        zipFile.close();
      } catch (IOException e) {
        e.printStackTrace();
      }
    }

    if (totalCompSize == 0) // something is wrong.  Return no compression.
      return 1;
    else
      return totalSize/totalCompSize;
  }"
"public static AbstractShowParser newInstance(final DatabaseType dbType, final ShardingRule shardingRule, final LexerEngine lexerEngine) {
        switch (dbType) {
            case H2:
            case MySQL:
                return new MySQLShowParser(shardingRule, lexerEngine);
            default:
                throw new UnsupportedOperationException(String.format(""Cannot support database [%s]."", dbType));
        }
    }"
"public void cancelTriggerInstance(final TriggerInstance triggerInst,
      final CancellationCause cause) {
    if (triggerInst.getStatus() == Status.RUNNING) {
      this.flowTriggerExecutorService.submit(() -> cancel(triggerInst, cause));
    }
  }"
"public static void copyAll(Resource base, Resource[] resources, File targetDir) throws IOException {
        final URL baseUrl = base.getURL();
        for (Resource resource : resources) {
            final InputStream input = resource.getInputStream();
            final File target = new File(targetDir, resource.getURL().toString().substring(baseUrl.toString().length()));
            copy(new BufferedInputStream(input), new BufferedOutputStream(Files.newOutputStream(target.toPath())));
        }
    }"
"private static int unrandomize255State(int randomizedBase256Codeword,
                                          int base256CodewordPosition) {
    int pseudoRandomNumber = ((149 * base256CodewordPosition) % 255) + 1;
    int tempVariable = randomizedBase256Codeword - pseudoRandomNumber;
    return tempVariable >= 0 ? tempVariable : tempVariable + 256;
  }"
"public void parse(final DMLStatement updateStatement) {
        lexerEngine.accept(DefaultKeyword.SET);
        do {
            parseSetItem(updateStatement);
        } while (lexerEngine.skipIfEqual(Symbol.COMMA));
    }"
"private static Integer sysctlGetInt(String sysctlKey) throws IOException {
        Process process = new ProcessBuilder(""sysctl"", sysctlKey).start();
        try {
            InputStream is = process.getInputStream();
            InputStreamReader isr = new InputStreamReader(is);
            BufferedReader br = new BufferedReader(isr);
            try {
                String line = br.readLine();
                if (line.startsWith(sysctlKey)) {
                    for (int i = line.length() - 1; i > sysctlKey.length(); --i) {
                        if (!Character.isDigit(line.charAt(i))) {
                            return Integer.valueOf(line.substring(i + 1, line.length()));
                        }
                    }
                }
                return null;
            } finally {
                br.close();
            }
        } finally {
            if (process != null) {
                process.destroy();
            }
        }
    }"
"private static byte ascToBcd(byte asc) {
		byte bcd;

		if ((asc >= '0') && (asc <= '9')) {
			bcd = (byte) (asc - '0');
		}else if ((asc >= 'A') && (asc <= 'F')) {
			bcd = (byte) (asc - 'A' + 10);
		}else if ((asc >= 'a') && (asc <= 'f')) {
			bcd = (byte) (asc - 'a' + 10);
		}else {
			bcd = (byte) (asc - 48);
		}
		return bcd;
	}"
"public File write(File destination) throws IOException {
		assertValid();
		
		if (destination.isDirectory() == true) {
			destination = new File(destination, this.header.getFileName());
		}
		if (data != null) {
			FileUtil.writeBytes(data, destination);
			data = null;
		} else {
			if (tempFile != null) {
				FileUtil.move(tempFile, destination, true);
			}
		}
		return destination;
	}"
"public Object nextEntity(char ampersand) throws JSONException {
		StringBuilder sb = new StringBuilder();
		for (;;) {
			char c = next();
			if (Character.isLetterOrDigit(c) || c == '#') {
				sb.append(Character.toLowerCase(c));
			} else if (c == ';') {
				break;
			} else {
				throw syntaxError(""Missing ';' in XML entity: &"" + sb);
			}
		}
		String string = sb.toString();
		Object object = entity.get(string);
		return object != null ? object : ampersand + string + "";"";
	}"
"@SneakyThrows
    public static byte[] verifyJwsSignature(final Key signingKey, final String asString) {
        val jws = new JsonWebSignature();
        jws.setCompactSerialization(asString);
        jws.setKey(signingKey);

        val verified = jws.verifySignature();
        if (verified) {
            val payload = jws.getEncodedPayload();
            LOGGER.trace(""Successfully decoded value. Result in Base64-encoding is [{}]"", payload);
            return EncodingUtils.decodeBase64(payload);
        }
        return null;
    }"
"private JCheckBox getChkParseRobotsTxt() {
		if (parseRobotsTxt == null) {
			parseRobotsTxt = new JCheckBox();
			parseRobotsTxt.setText(Constant.messages.getString(""spider.options.label.robotstxt""));
		}
		return parseRobotsTxt;
	}"
"public Object invokeOptionalWithoutCheckedException(T target, Object... args) {
    try {
      return invokeOptional(target, args);
    } catch (InvocationTargetException e) {
      Throwable targetException = e.getTargetException();
      if (targetException instanceof RuntimeException) {
        throw (RuntimeException) targetException;
      }
      AssertionError error = new AssertionError(""Unexpected exception"");
      error.initCause(targetException);
      throw error;
    }
  }"
"@SuppressWarnings(""resource"")
    void send(final OtpErlangPid from, final String dest,
            final OtpErlangObject msg) throws IOException {
        // encode and send the message
        sendBuf(from, dest, new OtpOutputStream(msg));
    }"
"@Override
	public void setValue(StringValue value) {
		checkNotNull(value);
		setValue(value.value, 0, value.len);
	}"
"public boolean isCollidingWith(Resource that, int count) {
        assert that!=null;
        for(Resource r=that; r!=null; r=r.parent)
            if(this.equals(r) && r.numConcurrentWrite<count)
                return true;
        for(Resource r=this; r!=null; r=r.parent)
            if(that.equals(r) && r.numConcurrentWrite<count)
                return true;
        return false;
    }"
"@Override
    public DataSet reshape(int rows, int cols) {
        DataSet ret = new DataSet(getFeatures().reshape(new long[] {rows, cols}), getLabels());
        return ret;
    }"
"public Sentence translateCompoundWordLabels()
    {
        for (IWord word : wordList)
        {
            if (word instanceof CompoundWord)
                word.setLabel(PartOfSpeechTagDictionary.translate(word.getLabel()));
        }
        return this;
    }"
"public OtpErlangPort read_port() throws OtpErlangDecodeException {
        String node;
        int id;
        int creation;
        int tag;

        tag = read1skip_version();

        if (tag != OtpExternal.portTag &&
	    tag != OtpExternal.newPortTag) {
            throw new OtpErlangDecodeException(
                    ""Wrong tag encountered, expected "" + OtpExternal.portTag
		    + "" or "" + OtpExternal.newPortTag
                            + "", got "" + tag);
        }

        node = read_atom();
        id = read4BE();
	if (tag == OtpExternal.portTag)
	    creation = read1();
	else
	    creation = read4BE();

        return new OtpErlangPort(tag, node, id, creation);
    }"
"public static ExpectedCondition<Boolean> textMatches(final By locator, final Pattern pattern) {
    return new ExpectedCondition<Boolean>() {
      private String currentValue = null;

      @Override
      public Boolean apply(WebDriver driver) {
        try {
          currentValue = driver.findElement(locator).getText();
          return pattern.matcher(currentValue).find();
        } catch (Exception e) {
          return false;
        }
      }

      @Override
      public String toString() {
        return String
          .format(""text found by %s to match pattern \""%s\"". Current text: \""%s\"""",
                  locator, pattern.pattern(), currentValue);
      }
    };
  }"
"@Override
    public INDArray convn(INDArray input, INDArray kernel, Convolution.Type type, int[] axes) {
        throw new UnsupportedOperationException();
    }"
"public static <T> List<T> reverse(List<T> list) {
		Collections.reverse(list);
		return list;
	}"
"private void modifyKeyPath(String fileName, String ice_root) throws IOException {
    FileInputStream in = null;
    Properties sslProps;
    try {
      in = new FileInputStream(fileName);
      sslProps = new Properties();
      sslProps.load(in);
    } finally {
      if (in != null) {
        in.close();
      }
    }

    subPath(""h2o_ssl_jks_internal"", sslProps, ice_root);
    subPath(""h2o_ssl_jts"", sslProps, ice_root);

    FileOutputStream out = null;
    try {
      out = new FileOutputStream(fileName);
      sslProps.store(out, null);
    } finally {
      if (out != null) {
        out.close();
      }
    }
  }"
"public void sendMailWithAttachment (String to, String subject, String content, String filename) throws MessagingException{
        Properties props = new Properties();
        props.put(""mail.smtp.user"", emailConfg.getUser());
        props.put(""mail.smtp.host"", emailConfg.getHost());
        props.put(""mail.smtp.port"", emailConfg.getPort());
        props.put(""mail.smtp.starttls.enable"",""true"");
        props.put(""mail.smtp.debug"", emailConfg.getDebug());
        props.put(""mail.smtp.auth"", emailConfg.getAuth());
        props.put(""mail.smtp.ssl.trust"", emailConfg.host);

        SMTPAuthenticator auth = new SMTPAuthenticator(emailConfg.getUser(), (String)secret.get(SecretConstants.EMAIL_PASSWORD));
        Session session = Session.getInstance(props, auth);

        MimeMessage message = new MimeMessage(session);

        message.setFrom(new InternetAddress(emailConfg.getUser()));
        message.addRecipient(Message.RecipientType.TO, new InternetAddress(to));
        message.setSubject(subject);

        // Create the message part
        BodyPart messageBodyPart = new MimeBodyPart();

        // Now set the actual message
        messageBodyPart.setText(content);

        // Create a multipar message
        Multipart multipart = new MimeMultipart();

        // Set text message part
        multipart.addBodyPart(messageBodyPart);

        // Part two is attachment
        messageBodyPart = new MimeBodyPart();
        DataSource source = new FileDataSource(filename);
        messageBodyPart.setDataHandler(new DataHandler(source));
        messageBodyPart.setFileName(filename);
        multipart.addBodyPart(messageBodyPart);

        // Send the complete message parts
        message.setContent(multipart);

        // Send message
        Transport.send(message);
        if(logger.isInfoEnabled()) logger.info(""An email has been sent to "" + to + "" with subject "" + subject);
    }"
"public ConfigurationMetadataProperty createConfigurationProperty(final FieldDeclaration fieldDecl, final String propName) {
        val variable = fieldDecl.getVariables().get(0);
        val name = StreamSupport.stream(RelaxedPropertyNames.forCamelCase(variable.getNameAsString()).spliterator(), false)
            .map(Object::toString)
            .findFirst()
            .orElseGet(variable::getNameAsString);

        val indexedGroup = propName.concat(indexNameWithBrackets ? ""[]"" : StringUtils.EMPTY);
        val indexedName = indexedGroup.concat(""."").concat(name);

        val prop = new ConfigurationMetadataProperty();
        if (fieldDecl.getJavadoc().isPresent()) {
            val description = fieldDecl.getJavadoc().get().getDescription().toText();
            prop.setDescription(description);
            prop.setShortDescription(StringUtils.substringBefore(description, "".""));
        } else {
            LOGGER.error(""No Javadoc found for field [{}]"", indexedName);
        }
        prop.setName(indexedName);
        prop.setId(indexedName);

        val elementType = fieldDecl.getElementType().asString();
        if (elementType.equals(String.class.getSimpleName())
            || elementType.equals(Integer.class.getSimpleName())
            || elementType.equals(Long.class.getSimpleName())
            || elementType.equals(Double.class.getSimpleName())
            || elementType.equals(Float.class.getSimpleName())) {
            prop.setType(""java.lang."" + elementType);
        } else {
            prop.setType(elementType);
        }

        val initializer = variable.getInitializer();
        if (initializer.isPresent()) {
            val exp = initializer.get();
            if (exp instanceof LiteralStringValueExpr) {
                prop.setDefaultValue(((LiteralStringValueExpr) exp).getValue());
            } else if (exp instanceof BooleanLiteralExpr) {
                prop.setDefaultValue(((BooleanLiteralExpr) exp).getValue());
            }
        }
        properties.add(prop);

        val grp = new ConfigurationMetadataProperty();
        grp.setId(indexedGroup);
        grp.setName(indexedGroup);
        grp.setType(parentClass);
        groups.add(grp);

        return prop;
    }"
"void start(WorkUnit task) {
        lock.writeLock().lock();
        try {
            this.workUnit = task;
            super.start();
            started = true;
        } finally {
            lock.writeLock().unlock();
        }
    }"
"private static TypeSerializer<?>[] createRegisteredSubclassSerializers(
			LinkedHashSet<Class<?>> registeredSubclasses,
			ExecutionConfig executionConfig) {

		final TypeSerializer<?>[] subclassSerializers = new TypeSerializer[registeredSubclasses.size()];

		int i = 0;
		for (Class<?> registeredClass : registeredSubclasses) {
			subclassSerializers[i] = TypeExtractor.createTypeInfo(registeredClass).createSerializer(executionConfig);
			i++;
		}

		return subclassSerializers;
	}"
"@Override public JobV3 fillFromImpl( Job job ) {
    if( job == null ) return this;
    // Handle fields in subclasses:
    PojoUtils.copyProperties(this, job, PojoUtils.FieldNaming.ORIGIN_HAS_UNDERSCORES);
    PojoUtils.copyProperties(this, job, PojoUtils.FieldNaming.CONSISTENT);  // TODO: make consistent and remove

    key = new JobKeyV3(job._key);
    description = job._description;
    warnings = job.warns();
    progress = job.progress();
    progress_msg = job.progress_msg();
    // Bogus status; Job no longer has these states, but we fake it for /3/Job poller's.
    // Notice state ""CREATED"" no long exists and is never returned.
    // Notice new state ""CANCEL_PENDING"".
    if( job.isRunning() )
      if( job.stop_requested() ) status = ""CANCEL_PENDING"";
      else status = ""RUNNING"";
    else
      if( job.stop_requested() ) status = ""CANCELLED"";
      else status = ""DONE"";
    Throwable ex = job.ex();
    if( ex != null ) status = ""FAILED"";
    exception = ex == null ? null : ex.toString();
    if (ex!=null) {
      StringWriter sw = new StringWriter();
      PrintWriter pw = new PrintWriter(sw);
      ex.printStackTrace(pw);
      stacktrace = sw.toString();
    }
    msec = job.msec();
    ready_for_view = job.readyForView();

    Keyed dest_type;
    Value value = null;
    if (job._result != null) {
      value = DKV.get(job._result);
    }
    if (value != null) {
      dest_type = (Keyed) TypeMap.theFreezable(value.type());
    } else {
      dest_type = (Keyed) TypeMap.theFreezable(job._typeid);
    }
    dest = job._result == null ? null : KeyV3.make(dest_type.makeSchema(), job._result);
    return this;
  }"
"static @CheckForNull Fingerprint load(@Nonnull File file) throws IOException {
        XmlFile configFile = getConfigFile(file);
        if(!configFile.exists())
            return null;

        long start=0;
        if(logger.isLoggable(Level.FINE))
            start = System.currentTimeMillis();

        try {
            Object loaded = configFile.read();
            if (!(loaded instanceof Fingerprint)) {
                throw new IOException(""Unexpected Fingerprint type. Expected "" + Fingerprint.class + "" or subclass but got ""
                        + (loaded != null ? loaded.getClass() : ""null""));
            }
            Fingerprint f = (Fingerprint) loaded;
            if(logger.isLoggable(Level.FINE))
                logger.fine(""Loading fingerprint ""+file+"" took ""+(System.currentTimeMillis()-start)+""ms"");
            if (f.facets==null)
                f.facets = new PersistedList<>(f);
            for (FingerprintFacet facet : f.facets)
                facet._setOwner(f);
            return f;
        } catch (IOException e) {
            if(file.exists() && file.length()==0) {
                // Despite the use of AtomicFile, there are reports indicating that people often see
                // empty XML file, presumably either due to file system corruption (perhaps by sudden
                // power loss, etc.) or abnormal program termination.
                // generally we don't want to wipe out user data just because we can't load it,
                // but if the file size is 0, which is what's reported in HUDSON-2012, then it seems
                // like recovering it silently by deleting the file is not a bad idea.
                logger.log(Level.WARNING, ""Size zero fingerprint. Disk corruption? {0}"", configFile);
                file.delete();
                return null;
            }
            String parseError = messageOfParseException(e);
            if (parseError != null) {
                logger.log(Level.WARNING, ""Malformed XML in {0}: {1}"", new Object[] {configFile, parseError});
                file.delete();
                return null;
            }
            logger.log(Level.WARNING, ""Failed to load ""+configFile,e);
            throw e;
        }
    }"
"public void write_atom(final String atom) {
        String enc_atom;
        byte[] bytes;

        if (atom.codePointCount(0, atom.length()) <= OtpExternal.maxAtomLength) {
            enc_atom = atom;
        } else {
            /*
             * Throwing an exception would be better I think, but truncation
             * seems to be the way it has been done in other parts of OTP...
             */
            enc_atom = new String(OtpErlangString.stringToCodePoints(atom), 0,
                    OtpExternal.maxAtomLength);
        }

        try {
            bytes = enc_atom.getBytes(""UTF-8"");
            final int length = bytes.length;
            if (length < 256) {
                write1(OtpExternal.smallAtomUtf8Tag);
                write1(length);
            } else {
                write1(OtpExternal.atomUtf8Tag);
                write2BE(length);
            }
            writeN(bytes);
        } catch (final java.io.UnsupportedEncodingException e) {
            /*
             * Sigh, why didn't the API designer add an OtpErlangEncodeException
             * to these encoding functions?!? Instead of changing the API we
             * write an invalid atom and let it fail for whoever trying to
             * decode this... Sigh, again...
             */
            write1(OtpExternal.smallAtomUtf8Tag);
            write1(2);
            write2BE(0xffff); /* Invalid UTF-8 */
        }
    }"
"public void addAppConfigurationEntry(String name, AppConfigurationEntry... entry) {
		final AppConfigurationEntry[] existing = dynamicEntries.get(name);
		final AppConfigurationEntry[] updated;
		if (existing == null) {
			updated = Arrays.copyOf(entry, entry.length);
		}
		else {
			updated = merge(existing, entry);
		}
		dynamicEntries.put(name, updated);
	}"
"public static String exampleCheck(Class<?> entityClass) {
        StringBuilder sql = new StringBuilder();
        sql.append(""<bind name=\""checkExampleEntityClass\"" value=\""@tk.mybatis.mapper.util.OGNL@checkExampleEntityClass(_parameter, '"");
        sql.append(entityClass.getCanonicalName());
        sql.append(""')\""/>"");
        return sql.toString();
    }"
"public static INDArray col2im(INDArray col, int sH, int sW, int ph, int pW, int kH, int kW) {
        if (col.rank() != 6)
            throw new IllegalArgumentException(""col2im input array must be rank 6"");

        INDArray output = Nd4j.create(col.dataType(), new long[]{col.size(0), col.size(1), kH, kW});

        val cfg = Conv2DConfig.builder()
                .sH(sH)
                .sW(sW)
                .dH(1)
                .dW(1)
                .kH(kH)
                .kW(kW)
                .pH(ph)
                .pW(pW)
                .build();

        Col2Im col2Im = Col2Im.builder()
                .inputArrays(new INDArray[]{col})
                .outputs(new INDArray[]{output})
                .conv2DConfig(cfg)
                .build();

        Nd4j.getExecutioner().execAndReturn(col2Im);
        return col2Im.outputArguments()[0];
    }"
"private boolean strategySupportsNormalizer(NormalizerSerializerStrategy strategy, NormalizerType normalizerType,
                                               Class<? extends Normalizer> normalizerClass) {
        if (!strategy.getSupportedType().equals(normalizerType)) {
            return false;
        }
        if (strategy.getSupportedType().equals(NormalizerType.CUSTOM)) {
            // Strategy should be instance of CustomSerializerStrategy
            if (!(strategy instanceof CustomSerializerStrategy)) {
                throw new IllegalArgumentException(
                        ""Strategies supporting CUSTOM opType must be instance of CustomSerializerStrategy, got""
                                + strategy.getClass());
            }
            return ((CustomSerializerStrategy) strategy).getSupportedClass().equals(normalizerClass);
        }
        return true;
    }"
"public void unregisterKvState(
			JobID jobId,
			JobVertexID jobVertexId,
			KeyGroupRange keyGroupRange,
			String registrationName,
			KvStateID kvStateId) {

		KvStateEntry<?, ?, ?> entry = registeredKvStates.remove(kvStateId);
		if (entry != null) {
			entry.clear();

			final KvStateRegistryListener listener = getKvStateRegistryListener(jobId);
			if (listener != null) {
				listener.notifyKvStateUnregistered(
						jobId,
						jobVertexId,
						keyGroupRange,
						registrationName);
			}
		}
	}"
"public <X extends SDVariable> X setupFunction(X function) {
        Preconditions.checkNotNull(function, ""Passed in function must not be null!"");
        if (function instanceof SDVariable) {
            if (function.getSameDiff() != this) {
                function.setSameDiff(this);
            }
            return function;
        }
        return function;
    }"
"public static <T> byte[] serializeValue(T value, TypeSerializer<T> serializer) throws IOException {
		if (value != null) {
			// Serialize
			DataOutputSerializer dos = new DataOutputSerializer(32);
			serializer.serialize(value, dos);
			return dos.getCopyOfBuffer();
		} else {
			return null;
		}
	}"
"@PublicEvolving
	static <T extends Writable> TypeInformation<T> getWritableTypeInfo(Class<T> typeClass) {
		if (Writable.class.isAssignableFrom(typeClass) && !typeClass.equals(Writable.class)) {
			return new WritableTypeInfo<T>(typeClass);
		}
		else {
			throw new InvalidTypesException(""The given class is no subclass of "" + Writable.class.getName());
		}
	}"
"private void reads() {
    int index = random.nextInt();
    for (;;) {
      Integer key = ints[index++ & MASK];
      cache.get(key);
      calls.increment();
    }
  }"
"public static EnumerationIter<URL> getResourceIter(String resource) {
		final Enumeration<URL> resources;
		try {
			resources = ClassLoaderUtil.getClassLoader().getResources(resource);
		} catch (IOException e) {
			throw new IORuntimeException(e);
		}
		return new EnumerationIter<>(resources);
	}"
"public static <MP extends Model.Parameters> Job<Grid> startGridSearch(
      final Key<Grid> destKey,
      final MP params,
      final Map<String, Object[]> hyperParams
  ) {
    return startGridSearch(
        destKey,
        params,
        hyperParams,
        new SimpleParametersBuilderFactory<MP>(),
        new HyperSpaceSearchCriteria.CartesianSearchCriteria());
  }"
"private static <T> IntermediateCompatibilityResult<T> getCompatibilityOfPreExistingFields(
			PojoSerializer<T> newPojoSerializer,
			LinkedOptionalMap<Field, TypeSerializerSnapshot<?>> fieldSerializerSnapshots) {

		// the present entries dictates the preexisting fields, because removed fields would be
		// represented as absent keys in the optional map.
		final Set<LinkedOptionalMap.KeyValue<Field, TypeSerializerSnapshot<?>>> presentFieldSnapshots =
			fieldSerializerSnapshots.getPresentEntries();

		final ArrayList<TypeSerializerSnapshot<?>> associatedFieldSerializerSnapshots = new ArrayList<>(presentFieldSnapshots.size());
		final ArrayList<TypeSerializer<?>> associatedNewFieldSerializers = new ArrayList<>(presentFieldSnapshots.size());

		final Map<Field, TypeSerializer<?>> newFieldSerializersIndex = buildNewFieldSerializersIndex(newPojoSerializer);
		for (LinkedOptionalMap.KeyValue<Field, TypeSerializerSnapshot<?>> presentFieldEntry : presentFieldSnapshots) {
			TypeSerializer<?> associatedNewFieldSerializer = newFieldSerializersIndex.get(presentFieldEntry.getKey());
			checkState(
				associatedNewFieldSerializer != null,
				""a present field should have its associated new field serializer available."");

			associatedFieldSerializerSnapshots.add(presentFieldEntry.getValue());
			associatedNewFieldSerializers.add(associatedNewFieldSerializer);
		}

		return CompositeTypeSerializerUtil.constructIntermediateCompatibilityResult(
			associatedNewFieldSerializers.toArray(new TypeSerializer<?>[associatedNewFieldSerializers.size()]),
			associatedFieldSerializerSnapshots.toArray(new TypeSerializerSnapshot<?>[associatedFieldSerializerSnapshots.size()]));
	}"
"public String parseString(String name) {
        String property = getProperties().getProperty(name);
        if (property == null) {
            throw new NullPointerException();
        }
        return property;
    }"
"@Deprecated
	public static <K, V> HashMap<K, V> newHashMap() {
		return new HashMap<K, V>();
	}"
"protected Assertion getAssertionFrom(final Map<String, Object> model) {
        return (Assertion) model.get(CasViewConstants.MODEL_ATTRIBUTE_NAME_ASSERTION);
    }"
"public static <T> SerializedCheckpointData[] fromDeque(
			ArrayDeque<Tuple2<Long, Set<T>>> checkpoints,
			TypeSerializer<T> serializer,
			DataOutputSerializer outputBuffer) throws IOException {

		SerializedCheckpointData[] serializedCheckpoints = new SerializedCheckpointData[checkpoints.size()];

		int pos = 0;
		for (Tuple2<Long, Set<T>> checkpoint : checkpoints) {
			outputBuffer.clear();
			Set<T> checkpointIds = checkpoint.f1;

			for (T id : checkpointIds) {
				serializer.serialize(id, outputBuffer);
			}

			serializedCheckpoints[pos++] = new SerializedCheckpointData(
					checkpoint.f0, outputBuffer.getCopyOfBuffer(), checkpointIds.size());
		}

		return serializedCheckpoints;
	}"
"protected ConnectionFactory prepareConnectionFactory(final String ldapURL) {
        val cc = ConnectionConfig.newConnectionConfig(this.connectionConfig);
        cc.setLdapUrl(ldapURL);
        return new DefaultConnectionFactory(cc);
    }"
"public void addParamPost(String name, String value) {
        addParam(name, value, NameValuePair.TYPE_POST_DATA);
    }"
"public ChannelFuture removeAndWrite() {
        assert ctx.executor().inEventLoop();
        PendingWrite write = head;
        if (write == null) {
            return null;
        }
        Object msg = write.msg;
        ChannelPromise promise = write.promise;
        recycle(write, true);
        return ctx.write(msg, promise);
    }"
"public final void set(V value) {
        if (value != InternalThreadLocalMap.UNSET) {
            InternalThreadLocalMap threadLocalMap = InternalThreadLocalMap.get();
            setKnownNotUnset(threadLocalMap, value);
        } else {
            remove();
        }
    }"
"@Override
  public void closeOperation(OperationHandle opHandle)
      throws HiveSQLException {
    try {
      TCloseOperationReq req  = new TCloseOperationReq(opHandle.toTOperationHandle());
      TCloseOperationResp resp = cliService.CloseOperation(req);
      checkStatus(resp.getStatus());
    } catch (HiveSQLException e) {
      throw e;
    } catch (Exception e) {
      throw new HiveSQLException(e);
    }
  }"
"public boolean complete() {
    Map<ClientTransport.PingCallback, Executor> callbacks;
    long roundTripTimeNanos;
    synchronized (this) {
      if (completed) {
        return false;
      }
      completed = true;
      roundTripTimeNanos = this.roundTripTimeNanos = stopwatch.elapsed(TimeUnit.NANOSECONDS);
      callbacks = this.callbacks;
      this.callbacks = null;
    }
    for (Map.Entry<ClientTransport.PingCallback, Executor> entry : callbacks.entrySet()) {
      doExecute(entry.getValue(), asRunnable(entry.getKey(), roundTripTimeNanos));
    }
    return true;
  }"
"public static RpcReferenceContext lastReferenceContext(boolean clear) {
        try {
            RpcInvokeContext invokeCtx = RpcInvokeContext.getContext();
            RpcReferenceContext referenceCtx = (RpcReferenceContext) invokeCtx
                .get(RemotingConstants.INVOKE_CTX_RPC_REF_CTX);
            if (referenceCtx != null) {
                String resultCode = (String) invokeCtx.get(RemotingConstants.INVOKE_CTX_RPC_RESULT_CODE);
                if (resultCode != null) {
                    referenceCtx.setResultCode(ResultCodeEnum.getResultCode(resultCode));
                }
            }
            return referenceCtx;
        } finally {
            if (clear) {
                clearReferenceContext();
            }
        }
    }"
"public String getFirstPart() {
        StringBuilder builder = new StringBuilder();

        builder.append(useHttps ? ""https"" : ""http"").append(""://"").append(address).append("":"").append(port).append("""");

        return builder.toString();
    }"
"@Deprecated
    public static TokenResponse getTokenFromSaml(SAMLBearerRequest tokenRequest) throws ClientException {
        Result<TokenResponse> responseResult = getTokenFromSamlResult(tokenRequest);
        if (responseResult.isSuccess()) {
            return responseResult.getResult();
        }
        throw new ClientException(responseResult.getError());
    }"
"@Override
	public synchronized RecordScan read(int scanId) throws DatabaseException {
		try {
			psRead.setInt(1, scanId);
			
			try (ResultSet rs = psRead.executeQuery()) {
				RecordScan result = build(rs);
				return result;
			}
		} catch (SQLException e) {
			throw new DatabaseException(e);
		}
	}"
"@PublicEvolving
	public <R> SingleOutputStreamOperator<R> reduce(
			ReduceFunction<T> reduceFunction,
			AllWindowFunction<T, R, W> function) {

		TypeInformation<T> inType = input.getType();
		TypeInformation<R> resultType = getAllWindowFunctionReturnType(function, inType);

		return reduce(reduceFunction, function, resultType);
	}"
"protected static SiteNode getSiteNode(HistoryReference historyReference) {
        SiteNode sn = historyReference.getSiteNode();
        if (sn == null) {
            sn = Model.getSingleton().getSession().getSiteTree().getSiteNode(historyReference.getHistoryId());
        }
        return sn;
    }"
"private static void validateScriptType(ScriptWrapper script, String scriptType) throws IllegalArgumentException {
		if (!scriptType.equals(script.getTypeName())) {
			throw new IllegalArgumentException(""Script "" + script.getName() + "" is not a '"" + scriptType + ""' script: ""
					+ script.getTypeName());
		}
	}"
"public InputType getOutputType(InputType... inputType) throws InvalidKerasConfigurationException {
        if (inputType.length > 1)
            throw new InvalidKerasConfigurationException(
                    ""Keras SameDiff layer accepts only one input (received "" + inputType.length + "")"");
        return this.getSameDiffLayer().getOutputType(-1, inputType[0]);
    }"
"public static void listen(ClipboardListener listener, boolean sync) {
		listen(ClipboardMonitor.DEFAULT_TRY_COUNT, ClipboardMonitor.DEFAULT_DELAY, listener, sync);
	}"
"private ChannelWithMeta mergeChannels(List<ChannelWithMeta> channelIDs) throws IOException {
		// the list with the target iterators
		List<FileIOChannel> openChannels = new ArrayList<>(channelIDs.size());
		final BinaryMergeIterator<Entry> mergeIterator =
				getMergingIterator(channelIDs, openChannels);

		// create a new channel writer
		final FileIOChannel.ID mergedChannelID = ioManager.createChannel();
		channelManager.addChannel(mergedChannelID);
		AbstractChannelWriterOutputView output = null;

		int numBytesInLastBlock;
		int numBlocksWritten;
		try {
			output = FileChannelUtil.createOutputView(
					ioManager, mergedChannelID, compressionEnable,
					compressionCodecFactory, compressionBlockSize, pageSize);
			writeMergingOutput(mergeIterator, output);
			numBytesInLastBlock = output.close();
			numBlocksWritten = output.getBlockCount();
		} catch (IOException e) {
			if (output != null) {
				output.close();
				output.getChannel().deleteChannel();
			}
			throw e;
		}

		// remove, close and delete channels
		for (FileIOChannel channel : openChannels) {
			channelManager.removeChannel(channel.getChannelID());
			try {
				channel.closeAndDelete();
			} catch (Throwable ignored) {
			}
		}

		return new ChannelWithMeta(mergedChannelID, numBlocksWritten, numBytesInLastBlock);
	}"
"public synchronized LogEntries getSessionLog(SessionId sessionId) throws IOException {
    List<LogEntry> entries = new ArrayList<>();
    for (LogRecord record : records(sessionId)) {
      if (record.getLevel().intValue() >= serverLogLevel.intValue())
        entries.add(new LogEntry(record.getLevel(), record.getMillis(), record.getMessage()));
    }
    return new LogEntries(entries);
  }"
"void enableKeepAlive(boolean enable, long keepAliveTimeNanos,
      long keepAliveTimeoutNanos, boolean keepAliveWithoutCalls) {
    enableKeepAlive = enable;
    this.keepAliveTimeNanos = keepAliveTimeNanos;
    this.keepAliveTimeoutNanos = keepAliveTimeoutNanos;
    this.keepAliveWithoutCalls = keepAliveWithoutCalls;
  }"
"public static void setKeepAlive(HttpMessage message, boolean keepAlive) {
        setKeepAlive(message.headers(), message.protocolVersion(), keepAlive);
    }"
"public static <T> T registerBeanIntoApplicationContext(final ConfigurableApplicationContext applicationContext,
                                                           final T beanInstance, final String beanId) {
        val beanFactory = applicationContext.getBeanFactory();
        if (beanFactory.containsBean(beanId)) {
            return (T) applicationContext.getBean(beanId, beanInstance.getClass());
        }
        beanFactory.initializeBean(beanInstance, beanId);
        beanFactory.autowireBean(beanInstance);
        beanFactory.registerSingleton(beanId, beanInstance);
        return beanInstance;
    }"
"public static boolean reflectionEquals(Object lhs, Object rhs, boolean testTransients, Class<?> reflectUpToClass) {
        return reflectionEquals(lhs, rhs, testTransients, reflectUpToClass, null);
    }"
"@Override
  public void aggregate(final ByteBuffer buf, final int position)
  {
    final Object value = selector.getObject();
    if (value == null) {
      return;
    }
    final Lock lock = stripedLock.getAt(lockIndex(position)).writeLock();
    lock.lock();
    try {
      final HllSketch sketch = sketchCache.get(buf).get(position);
      HllSketchBuildAggregator.updateSketch(sketch, value);
    }
    finally {
      lock.unlock();
    }
  }"
"public static void alertUserOnFlowFinished(final ExecutableFlow flow, final AlerterHolder
      alerterHolder, final String[] extraReasons) {
    final ExecutionOptions options = flow.getExecutionOptions();
    final Alerter mailAlerter = alerterHolder.get(""email"");
    if (flow.getStatus() != Status.SUCCEEDED) {
      if (options.getFailureEmails() != null && !options.getFailureEmails().isEmpty()) {
        try {
          mailAlerter.alertOnError(flow, extraReasons);
        } catch (final Exception e) {
          logger.error(""Failed to alert on error for execution "" + flow.getExecutionId(), e);
        }
      }
      if (options.getFlowParameters().containsKey(""alert.type"")) {
        final String alertType = options.getFlowParameters().get(""alert.type"");
        final Alerter alerter = alerterHolder.get(alertType);
        if (alerter != null) {
          try {
            alerter.alertOnError(flow, extraReasons);
          } catch (final Exception e) {
            logger.error(""Failed to alert on error by "" + alertType + "" for execution "" + flow
                .getExecutionId(), e);
          }
        } else {
          logger.error(""Alerter type "" + alertType + "" doesn't exist. Failed to alert."");
        }
      }
    } else {
      if (options.getSuccessEmails() != null && !options.getSuccessEmails().isEmpty()) {
        try {
          mailAlerter.alertOnSuccess(flow);
        } catch (final Exception e) {
          logger.error(""Failed to alert on success for execution "" + flow.getExecutionId(), e);
        }
      }
      if (options.getFlowParameters().containsKey(""alert.type"")) {
        final String alertType = options.getFlowParameters().get(""alert.type"");
        final Alerter alerter = alerterHolder.get(alertType);
        if (alerter != null) {
          try {
            alerter.alertOnSuccess(flow);
          } catch (final Exception e) {
            logger.error(""Failed to alert on success by "" + alertType + "" for execution "" + flow
                .getExecutionId(), e);
          }
        } else {
          logger.error(""Alerter type "" + alertType + "" doesn't exist. Failed to alert."");
        }
      }
    }
  }"
"@Override
	void releaseAllResources() throws IOException {
		if (!isReleased) {
			isReleased = true;

			ResultSubpartitionView view = subpartitionView;
			if (view != null) {
				view.releaseAllResources();
				subpartitionView = null;
			}
		}
	}"
"private static int encodeText(CharSequence msg,
                                int startpos,
                                int count,
                                StringBuilder sb,
                                int initialSubmode) {
    StringBuilder tmp = new StringBuilder(count);
    int submode = initialSubmode;
    int idx = 0;
    while (true) {
      char ch = msg.charAt(startpos + idx);
      switch (submode) {
        case SUBMODE_ALPHA:
          if (isAlphaUpper(ch)) {
            if (ch == ' ') {
              tmp.append((char) 26); //space
            } else {
              tmp.append((char) (ch - 65));
            }
          } else {
            if (isAlphaLower(ch)) {
              submode = SUBMODE_LOWER;
              tmp.append((char) 27); //ll
              continue;
            } else if (isMixed(ch)) {
              submode = SUBMODE_MIXED;
              tmp.append((char) 28); //ml
              continue;
            } else {
              tmp.append((char) 29); //ps
              tmp.append((char) PUNCTUATION[ch]);
              break;
            }
          }
          break;
        case SUBMODE_LOWER:
          if (isAlphaLower(ch)) {
            if (ch == ' ') {
              tmp.append((char) 26); //space
            } else {
              tmp.append((char) (ch - 97));
            }
          } else {
            if (isAlphaUpper(ch)) {
              tmp.append((char) 27); //as
              tmp.append((char) (ch - 65));
              //space cannot happen here, it is also in ""Lower""
              break;
            } else if (isMixed(ch)) {
              submode = SUBMODE_MIXED;
              tmp.append((char) 28); //ml
              continue;
            } else {
              tmp.append((char) 29); //ps
              tmp.append((char) PUNCTUATION[ch]);
              break;
            }
          }
          break;
        case SUBMODE_MIXED:
          if (isMixed(ch)) {
            tmp.append((char) MIXED[ch]);
          } else {
            if (isAlphaUpper(ch)) {
              submode = SUBMODE_ALPHA;
              tmp.append((char) 28); //al
              continue;
            } else if (isAlphaLower(ch)) {
              submode = SUBMODE_LOWER;
              tmp.append((char) 27); //ll
              continue;
            } else {
              if (startpos + idx + 1 < count) {
                char next = msg.charAt(startpos + idx + 1);
                if (isPunctuation(next)) {
                  submode = SUBMODE_PUNCTUATION;
                  tmp.append((char) 25); //pl
                  continue;
                }
              }
              tmp.append((char) 29); //ps
              tmp.append((char) PUNCTUATION[ch]);
            }
          }
          break;
        default: //SUBMODE_PUNCTUATION
          if (isPunctuation(ch)) {
            tmp.append((char) PUNCTUATION[ch]);
          } else {
            submode = SUBMODE_ALPHA;
            tmp.append((char) 29); //al
            continue;
          }
      }
      idx++;
      if (idx >= count) {
        break;
      }
    }
    char h = 0;
    int len = tmp.length();
    for (int i = 0; i < len; i++) {
      boolean odd = (i % 2) != 0;
      if (odd) {
        h = (char) ((h * 30) + tmp.charAt(i));
        sb.append(h);
      } else {
        h = tmp.charAt(i);
      }
    }
    if ((len % 2) != 0) {
      sb.append((char) ((h * 30) + 29)); //ps
    }
    return submode;
  }"
"public long acquireExecutionMemory(long required, MemoryConsumer consumer) {
    assert(required >= 0);
    assert(consumer != null);
    MemoryMode mode = consumer.getMode();
    // If we are allocating Tungsten pages off-heap and receive a request to allocate on-heap
    // memory here, then it may not make sense to spill since that would only end up freeing
    // off-heap memory. This is subject to change, though, so it may be risky to make this
    // optimization now in case we forget to undo it late when making changes.
    synchronized (this) {
      long got = memoryManager.acquireExecutionMemory(required, taskAttemptId, mode);

      // Try to release memory from other consumers first, then we can reduce the frequency of
      // spilling, avoid to have too many spilled files.
      if (got < required) {
        // Call spill() on other consumers to release memory
        // Sort the consumers according their memory usage. So we avoid spilling the same consumer
        // which is just spilled in last few times and re-spilling on it will produce many small
        // spill files.
        TreeMap<Long, List<MemoryConsumer>> sortedConsumers = new TreeMap<>();
        for (MemoryConsumer c: consumers) {
          if (c != consumer && c.getUsed() > 0 && c.getMode() == mode) {
            long key = c.getUsed();
            List<MemoryConsumer> list =
                sortedConsumers.computeIfAbsent(key, k -> new ArrayList<>(1));
            list.add(c);
          }
        }
        while (!sortedConsumers.isEmpty()) {
          // Get the consumer using the least memory more than the remaining required memory.
          Map.Entry<Long, List<MemoryConsumer>> currentEntry =
            sortedConsumers.ceilingEntry(required - got);
          // No consumer has used memory more than the remaining required memory.
          // Get the consumer of largest used memory.
          if (currentEntry == null) {
            currentEntry = sortedConsumers.lastEntry();
          }
          List<MemoryConsumer> cList = currentEntry.getValue();
          MemoryConsumer c = cList.get(cList.size() - 1);
          try {
            long released = c.spill(required - got, consumer);
            if (released > 0) {
              logger.debug(""Task {} released {} from {} for {}"", taskAttemptId,
                Utils.bytesToString(released), c, consumer);
              got += memoryManager.acquireExecutionMemory(required - got, taskAttemptId, mode);
              if (got >= required) {
                break;
              }
            } else {
              cList.remove(cList.size() - 1);
              if (cList.isEmpty()) {
                sortedConsumers.remove(currentEntry.getKey());
              }
            }
          } catch (ClosedByInterruptException e) {
            // This called by user to kill a task (e.g: speculative task).
            logger.error(""error while calling spill() on "" + c, e);
            throw new RuntimeException(e.getMessage());
          } catch (IOException e) {
            logger.error(""error while calling spill() on "" + c, e);
            // checkstyle.off: RegexpSinglelineJava
            throw new SparkOutOfMemoryError(""error while calling spill() on "" + c + "" : ""
              + e.getMessage());
            // checkstyle.on: RegexpSinglelineJava
          }
        }
      }

      // call spill() on itself
      if (got < required) {
        try {
          long released = consumer.spill(required - got, consumer);
          if (released > 0) {
            logger.debug(""Task {} released {} from itself ({})"", taskAttemptId,
              Utils.bytesToString(released), consumer);
            got += memoryManager.acquireExecutionMemory(required - got, taskAttemptId, mode);
          }
        } catch (ClosedByInterruptException e) {
          // This called by user to kill a task (e.g: speculative task).
          logger.error(""error while calling spill() on "" + consumer, e);
          throw new RuntimeException(e.getMessage());
        } catch (IOException e) {
          logger.error(""error while calling spill() on "" + consumer, e);
          // checkstyle.off: RegexpSinglelineJava
          throw new SparkOutOfMemoryError(""error while calling spill() on "" + consumer + "" : ""
            + e.getMessage());
          // checkstyle.on: RegexpSinglelineJava
        }
      }

      consumers.add(consumer);
      logger.debug(""Task {} acquired {} for {}"", taskAttemptId, Utils.bytesToString(got), consumer);
      return got;
    }
  }"
"public static CompiledScript compile(String script) throws ScriptRuntimeException {
		try {
			return compile(getJavaScriptEngine(), script);
		} catch (ScriptException e) {
			throw new ScriptRuntimeException(e);
		}
	}"
"public void execute() throws Exception {
        ActionRequest request = requestBuilder.request();

        //todo: maby change to instanceof multi?
        if(requestBuilder instanceof JoinRequestBuilder){
            executeJoinRequestAndSendResponse();
        }
		else if (request instanceof SearchRequest) {
			client.search((SearchRequest) request, new RestStatusToXContentListener<SearchResponse>(channel));
		} else if (requestBuilder instanceof SqlElasticDeleteByQueryRequestBuilder) {
            throw new UnsupportedOperationException(""currently not support delete on elastic 2.0.0"");
        }
        else if(request instanceof GetIndexRequest) {
            this.requestBuilder.getBuilder().execute( new GetIndexRequestRestListener(channel, (GetIndexRequest) request));
        }


		else {
			throw new Exception(String.format(""Unsupported ActionRequest provided: %s"", request.getClass().getName()));
		}
	}"
"public T getExtInstance(Class[] argTypes, Object[] args) {
        if (clazz != null) {
            try {
                if (singleton) { // 如果是单例
                    if (instance == null) {
                        synchronized (this) {
                            if (instance == null) {
                                instance = ClassUtils.newInstanceWithArgs(clazz, argTypes, args);
                            }
                        }
                    }
                    return instance; // 保留单例
                } else {
                    return ClassUtils.newInstanceWithArgs(clazz, argTypes, args);
                }
            } catch (Exception e) {
                throw new SofaRpcRuntimeException(""create "" + clazz.getCanonicalName() + "" instance error"", e);
            }
        }
        throw new SofaRpcRuntimeException(""Class of ExtensionClass is null"");
    }"
"public static long getOffset(DataBuffer shapeInformation, int dim0, int dim1, int dim2) {
        int rank = rank(shapeInformation);
        if (rank != 3)
            throw new IllegalArgumentException(
                    ""Cannot use this getOffset method on arrays of rank != 3 (rank is: "" + rank + "")"");
        return getOffsetUnsafe(shapeInformation, dim0, dim1, dim2);
    }"
"private JPanel getJPanel1() {
		if (jPanel1 == null) {
			jPanel1 = new JPanel();
			jPanel1.setLayout(new CardLayout());
			jPanel1.add(getJScrollPane(), getJScrollPane().getName());
		}
		return jPanel1;
	}"
"@Deprecated
	public void addSecondInput(Operator<IN2>... input) {
		this.input2 = Operator.createUnionCascade(this.input2, input);
	}"
"public static int stride(DataBuffer buffer, int dimension) {
        int rank = rank(buffer);
        if (dimension >= rank)
            throw new IllegalArgumentException(""Invalid dimension "" + dimension + "" for rank "" + rank + "" array"");
        return buffer.getInt(1 + rank + dimension);
    }"
"public static int log2strict(int value) throws ArithmeticException, IllegalArgumentException {
		if (value == 0) {
			throw new ArithmeticException(""Logarithm of zero is undefined."");
		}
		if ((value & (value - 1)) != 0) {
			throw new IllegalArgumentException(""The given value "" + value + "" is not a power of two."");
		}
		return 31 - Integer.numberOfLeadingZeros(value);
	}"
"public void setKey(String key) {
        if (!isValidParamKey(key)) {
            throw ExceptionUtils.buildRuntime(""param.key"", key, ""key can not start with ""
                + RpcConstants.HIDE_KEY_PREFIX + "" and "" + RpcConstants.INTERNAL_KEY_PREFIX);
        }
        this.key = key;
    }"
"public static String ipv6toStr(byte[] src) {
        assert src.length == 16;
        StringBuilder sb = new StringBuilder(39);
        ipv6toStr(sb, src, 0, 8);
        return sb.toString();
    }"
"public static boolean isDirectory(Path path, boolean isFollowLinks) {
		if (null == path) {
			return false;
		}
		final LinkOption[] options = isFollowLinks ? new LinkOption[0] : new LinkOption[] { LinkOption.NOFOLLOW_LINKS };
		return Files.isDirectory(path, options);
	}"
"private static <T> boolean newPojoSerializerIsCompatibleWithReconfiguredSerializer(
			PojoSerializer<T> newPojoSerializer,
			IntermediateCompatibilityResult<T> fieldSerializerCompatibility,
			IntermediateCompatibilityResult<T> preExistingRegistrationsCompatibility,
			LinkedOptionalMap<Class<?>, TypeSerializerSnapshot<?>> registeredSubclassSerializerSnapshots,
			LinkedOptionalMap<Class<?>, TypeSerializerSnapshot<?>> nonRegisteredSubclassSerializerSnapshots) {
		return newPojoHasDifferentSubclassRegistrationOrder(registeredSubclassSerializerSnapshots, newPojoSerializer)
			|| previousSerializerHasNonRegisteredSubclasses(nonRegisteredSubclassSerializerSnapshots)
			|| fieldSerializerCompatibility.isCompatibleWithReconfiguredSerializer()
			|| preExistingRegistrationsCompatibility.isCompatibleWithReconfiguredSerializer();
	}"
"public static boolean checkGradientsPretrainLayer(Layer layer, double epsilon, double maxRelError,
                    double minAbsoluteError, boolean print, boolean exitOnFirstError, INDArray input, int rngSeed) {

        LayerWorkspaceMgr mgr = LayerWorkspaceMgr.noWorkspaces();

        //Basic sanity checks on input:
        if (epsilon <= 0.0 || epsilon > 0.1)
            throw new IllegalArgumentException(""Invalid epsilon: expect epsilon in range (0,0.1], usually 1e-4 or so"");
        if (maxRelError <= 0.0 || maxRelError > 0.25)
            throw new IllegalArgumentException(""Invalid maxRelativeError: "" + maxRelError);

        DataType dataType = DataTypeUtil.getDtypeFromContext();
        if (dataType != DataType.DOUBLE) {
            throw new IllegalStateException(""Cannot perform gradient check: Datatype is not set to double precision (""
                            + ""is: "" + dataType + ""). Double precision must be used for gradient checks. Set ""
                            + ""DataTypeUtil.setDTypeForContext(DataType.DOUBLE); before using GradientCheckUtil"");
        }

        //Check network configuration:
        layer.setInput(input, LayerWorkspaceMgr.noWorkspaces());
        Nd4j.getRandom().setSeed(rngSeed);
        layer.computeGradientAndScore(mgr);
        Pair<Gradient, Double> gradAndScore = layer.gradientAndScore();

        Updater updater = UpdaterCreator.getUpdater(layer);
        updater.update(layer, gradAndScore.getFirst(), 0, 0, layer.batchSize(), LayerWorkspaceMgr.noWorkspaces());

        INDArray gradientToCheck = gradAndScore.getFirst().gradient().dup(); //need dup: gradients are a *view* of the full gradient array (which will change every time backprop is done)
        INDArray originalParams = layer.params().dup(); //need dup: params are a *view* of full parameters

        val nParams = originalParams.length();

        Map<String, INDArray> paramTable = layer.paramTable();
        List<String> paramNames = new ArrayList<>(paramTable.keySet());
        val paramEnds = new long[paramNames.size()];
        paramEnds[0] = paramTable.get(paramNames.get(0)).length();
        for (int i = 1; i < paramEnds.length; i++) {
            paramEnds[i] = paramEnds[i - 1] + paramTable.get(paramNames.get(i)).length();
        }


        int totalNFailures = 0;
        double maxError = 0.0;
        int currParamNameIdx = 0;

        INDArray params = layer.params(); //Assumption here: params is a view that we can modify in-place
        for (int i = 0; i < nParams; i++) {
            //Get param name
            if (i >= paramEnds[currParamNameIdx]) {
                currParamNameIdx++;
            }
            String paramName = paramNames.get(currParamNameIdx);

            //(w+epsilon): Do forward pass and score
            double origValue = params.getDouble(i);
            params.putScalar(i, origValue + epsilon);

            //TODO add a 'score' method that doesn't calculate gradients...
            Nd4j.getRandom().setSeed(rngSeed);
            layer.computeGradientAndScore(mgr);
            double scorePlus = layer.score();

            //(w-epsilon): Do forward pass and score
            params.putScalar(i, origValue - epsilon);
            Nd4j.getRandom().setSeed(rngSeed);
            layer.computeGradientAndScore(mgr);
            double scoreMinus = layer.score();

            //Reset original param value
            params.putScalar(i, origValue);

            //Calculate numerical parameter gradient:
            double scoreDelta = scorePlus - scoreMinus;

            double numericalGradient = scoreDelta / (2 * epsilon);
            if (Double.isNaN(numericalGradient))
                throw new IllegalStateException(""Numerical gradient was NaN for parameter "" + i + "" of "" + nParams);

            double backpropGradient = gradientToCheck.getDouble(i);
            //http://cs231n.github.io/neural-networks-3/#gradcheck
            //use mean centered
            double relError = Math.abs(backpropGradient - numericalGradient)
                            / (Math.abs(numericalGradient) + Math.abs(backpropGradient));
            if (backpropGradient == 0.0 && numericalGradient == 0.0)
                relError = 0.0; //Edge case: i.e., RNNs with time series length of 1.0

            if (relError > maxError)
                maxError = relError;
            if (relError > maxRelError || Double.isNaN(relError)) {
                double absError = Math.abs(backpropGradient - numericalGradient);
                if (absError < minAbsoluteError) {
                    log.info(""Param "" + i + "" ("" + paramName + "") passed: grad= "" + backpropGradient
                                    + "", numericalGrad= "" + numericalGradient + "", relError= "" + relError
                                    + ""; absolute error = "" + absError + "" < minAbsoluteError = "" + minAbsoluteError);
                } else {
                    if (print)
                        log.info(""Param "" + i + "" ("" + paramName + "") FAILED: grad= "" + backpropGradient
                                        + "", numericalGrad= "" + numericalGradient + "", relError= "" + relError
                                        + "", scorePlus="" + scorePlus + "", scoreMinus= "" + scoreMinus + "", paramValue = "" + origValue);
                    if (exitOnFirstError)
                        return false;
                    totalNFailures++;
                }
            } else if (print) {
                log.info(""Param "" + i + "" ("" + paramName + "") passed: grad= "" + backpropGradient + "", numericalGrad= ""
                                + numericalGradient + "", relError= "" + relError);
            }
        }

        if (print) {
            val nPass = nParams - totalNFailures;
            log.info(""GradientCheckUtil.checkGradients(): "" + nParams + "" params checked, "" + nPass + "" passed, ""
                            + totalNFailures + "" failed. Largest relative error = "" + maxError);
        }

        return totalNFailures == 0;
    }"
"public static ComputationGraph loadCheckpointCG(File rootDir, int checkpointNum){
        File f = getFileForCheckpoint(rootDir, checkpointNum);
        try {
            return ModelSerializer.restoreComputationGraph(f, true);
        } catch (IOException e){
            throw new RuntimeException(e);
        }
    }"
"public static void convert(File srcImageFile, File destImageFile) {
		Assert.notNull(srcImageFile);
		Assert.notNull(destImageFile);
		Assert.isFalse(srcImageFile.equals(destImageFile), ""Src file is equals to dest file!"");

		final String srcExtName = FileUtil.extName(srcImageFile);
		final String destExtName = FileUtil.extName(destImageFile);
		if (StrUtil.equalsIgnoreCase(srcExtName, destExtName)) {
			// 扩展名相同直接复制文件
			FileUtil.copy(srcImageFile, destImageFile, true);
		}

		ImageOutputStream imageOutputStream = null;
		try {
			imageOutputStream = getImageOutputStream(destImageFile);
			convert(read(srcImageFile), destExtName, imageOutputStream, StrUtil.equalsIgnoreCase(IMAGE_TYPE_PNG, srcExtName));
		} finally {
			IoUtil.close(imageOutputStream);
		}
	}"
"private void parameterize(Parameterized parameterized) {
		try {
			parameterized.configure(parameters);
		} catch (RuntimeException ex) {
			throw new ProgramParametrizationException(ex.getMessage());
		}
	}"
"public void setEnvironmentVariables(Map<String, String> environment) {
    for (Map.Entry<String, String> entry : environment.entrySet()) {
      setEnvironmentVariable(entry.getKey(), entry.getValue());
    }
  }"
"public void addParameters(NameValuePair[] parameters) {
        log.trace(""enter PostMethod.addParameters(NameValuePair[])"");

        if (parameters == null) {
            log.warn(""Attempt to addParameters(null) ignored"");
        } else {
            super.clearRequestBody();
            for (int i = 0; i < parameters.length; i++) {
                this.params.add(parameters[i]);
            }
        }
    }"
"public static void checkArgument(boolean b, String message, Object... args) {
        if (!b) {
            throwEx(message, args);
        }
    }"
"public void writeObject(Object o) throws IOException {
        ObjectOutputStream oos = AnonymousClassWarnings.checkingObjectOutputStream(out);
        oos.writeObject(o);
        // don't close oss, which will close the underlying stream
        // no need to flush either, given the way oos is implemented
    }"
"private int depth() {
        int i = 0;
        for (TreeString p = this; p != null; p = p.parent) {
            i++;
        }
        return i;
    }"
"public static <T> T invokeMethod(final Object obj, final String methodName, final Object[] args,
			final Class<?>[] parameterTypes) {
		Method method = getMethod(obj.getClass(), methodName, parameterTypes);
		if (method == null) {
			throw new IllegalArgumentException(""Could not find method ["" + methodName + ""] with parameter types:""
					+ ObjectUtil.toPrettyString(parameterTypes) + "" on class ["" + obj.getClass() + ']');
		}
		return invokeMethod(obj, method, args);
	}"
"public void setBody(byte[] contents) {
		if (contents == null) {
			return;
		}
		cachedString = null;
		
		body = new byte[contents.length];
		System.arraycopy(contents, 0, body, 0, contents.length);
		
		pos = body.length;
	}"
"public SDVariable sub(SDVariable x) {
        return sub(sameDiff.generateNewVarName(SubOp.OP_NAME,0),x);
    }"
"protected String callRestEndpointForMultifactor(final Principal principal, final Service resolvedService) {
        val restTemplate = new RestTemplate();
        val restEndpoint = casProperties.getAuthn().getMfa().getRestEndpoint();
        val entity = new RestEndpointEntity(principal.getId(), resolvedService.getId());
        val responseEntity = restTemplate.postForEntity(restEndpoint, entity, String.class);
        if (responseEntity.getStatusCode() == HttpStatus.OK) {
            return responseEntity.getBody();
        }
        return null;
    }"
"public <T0> SingleOutputStreamOperator<Tuple1<T0>> projectTuple1() {
		TypeInformation<?>[] fTypes = extractFieldTypes(fieldIndexes, dataStream.getType());
		TupleTypeInfo<Tuple1<T0>> tType = new TupleTypeInfo<Tuple1<T0>>(fTypes);

		return dataStream.transform(""Projection"", tType, new StreamProject<IN, Tuple1<T0>>(
				fieldIndexes, tType.createSerializer(dataStream.getExecutionConfig())));
	}"
"static DataBlock[] getDataBlocks(byte[] rawCodewords,
                                   Version version) {
    // Figure out the number and size of data blocks used by this version
    Version.ECBlocks ecBlocks = version.getECBlocks();

    // First count the total number of data blocks
    int totalBlocks = 0;
    Version.ECB[] ecBlockArray = ecBlocks.getECBlocks();
    for (Version.ECB ecBlock : ecBlockArray) {
       totalBlocks += ecBlock.getCount();
    }

    // Now establish DataBlocks of the appropriate size and number of data codewords
    DataBlock[] result = new DataBlock[totalBlocks];
    int numResultBlocks = 0;
    for (Version.ECB ecBlock : ecBlockArray) {
      for (int i = 0; i < ecBlock.getCount(); i++) {
        int numDataCodewords = ecBlock.getDataCodewords();
        int numBlockCodewords = ecBlocks.getECCodewords() + numDataCodewords;
        result[numResultBlocks++] = new DataBlock(numDataCodewords, new byte[numBlockCodewords]);
      }
    }

    // All blocks have the same amount of data, except that the last n
    // (where n may be 0) have 1 less byte. Figure out where these start.
    // TODO(bbrown): There is only one case where there is a difference for Data Matrix for size 144
    int longerBlocksTotalCodewords = result[0].codewords.length;
    //int shorterBlocksTotalCodewords = longerBlocksTotalCodewords - 1;

    int longerBlocksNumDataCodewords = longerBlocksTotalCodewords - ecBlocks.getECCodewords();
    int shorterBlocksNumDataCodewords = longerBlocksNumDataCodewords - 1;
    // The last elements of result may be 1 element shorter for 144 matrix
    // first fill out as many elements as all of them have minus 1
    int rawCodewordsOffset = 0;
    for (int i = 0; i < shorterBlocksNumDataCodewords; i++) {
      for (int j = 0; j < numResultBlocks; j++) {
        result[j].codewords[i] = rawCodewords[rawCodewordsOffset++];
      }
    }

    // Fill out the last data block in the longer ones
    boolean specialVersion = version.getVersionNumber() == 24;
    int numLongerBlocks = specialVersion ? 8 : numResultBlocks;
    for (int j = 0; j < numLongerBlocks; j++) {
      result[j].codewords[longerBlocksNumDataCodewords - 1] = rawCodewords[rawCodewordsOffset++];
    }

    // Now add in error correction blocks
    int max = result[0].codewords.length;
    for (int i = longerBlocksNumDataCodewords; i < max; i++) {
      for (int j = 0; j < numResultBlocks; j++) {
        int jOffset = specialVersion ? (j + 8) % numResultBlocks : j;
        int iOffset = specialVersion && jOffset > 7 ? i - 1 : i;
        result[jOffset].codewords[iOffset] = rawCodewords[rawCodewordsOffset++];
      }
    }

    if (rawCodewordsOffset != rawCodewords.length) {
      throw new IllegalArgumentException();
    }

    return result;
  }"
"synchronized public static void restart() {
		if (null != crontabSetting) {
			//重新读取配置文件
			crontabSetting.load();
		}
		if (scheduler.isStarted()) {
			//关闭并清除已有任务
			scheduler.stop(true);
		}
		
		//重新加载任务
		schedule(crontabSetting);
		//重新启动
		scheduler.start();
	}"
"public <T> T output(@NonNull ModelAdapter<T> adapter, INDArray... inputs) {
        return output(adapter, inputs, null);
    }"
"public static String renderFromStr(String templateContent, Map<String, Object> bindingMap) {
		return render(getStrTemplate(templateContent), bindingMap);
	}"
"@Deprecated
    public Applications getApplicationDeltas() {
        GET_ALL_CACHE_MISS_DELTA.increment();
        Applications apps = new Applications();
        apps.setVersion(responseCache.getVersionDelta().get());
        Map<String, Application> applicationInstancesMap = new HashMap<String, Application>();
        try {
            write.lock();
            Iterator<RecentlyChangedItem> iter = this.recentlyChangedQueue.iterator();
            logger.debug(""The number of elements in the delta queue is : {}"",
                    this.recentlyChangedQueue.size());
            while (iter.hasNext()) {
                Lease<InstanceInfo> lease = iter.next().getLeaseInfo();
                InstanceInfo instanceInfo = lease.getHolder();
                logger.debug(
                        ""The instance id {} is found with status {} and actiontype {}"",
                        instanceInfo.getId(), instanceInfo.getStatus().name(), instanceInfo.getActionType().name());
                Application app = applicationInstancesMap.get(instanceInfo
                        .getAppName());
                if (app == null) {
                    app = new Application(instanceInfo.getAppName());
                    applicationInstancesMap.put(instanceInfo.getAppName(), app);
                    apps.addApplication(app);
                }
                app.addInstance(new InstanceInfo(decorateInstanceInfo(lease)));
            }

            boolean disableTransparentFallback = serverConfig.disableTransparentFallbackToOtherRegion();

            if (!disableTransparentFallback) {
                Applications allAppsInLocalRegion = getApplications(false);

                for (RemoteRegionRegistry remoteRegistry : this.regionNameVSRemoteRegistry.values()) {
                    Applications applications = remoteRegistry.getApplicationDeltas();
                    for (Application application : applications.getRegisteredApplications()) {
                        Application appInLocalRegistry =
                                allAppsInLocalRegion.getRegisteredApplications(application.getName());
                        if (appInLocalRegistry == null) {
                            apps.addApplication(application);
                        }
                    }
                }
            }

            Applications allApps = getApplications(!disableTransparentFallback);
            apps.setAppsHashCode(allApps.getReconcileHashCode());
            return apps;
        } finally {
            write.unlock();
        }
    }"
"void initialCapacity(String key, @Nullable String value) {
    requireArgument(initialCapacity == UNSET_INT,
        ""initial capacity was already set to %,d"", initialCapacity);
    initialCapacity = parseInt(key, value);
  }"
"public void exportScores(File file, String delimiter) throws IOException {
        try (FileOutputStream fos = new FileOutputStream(file)) {
            exportScores(fos, delimiter);
        }
    }"
"public void subscribeToEvent(
			ResultPartitionID partitionId,
			EventListener<TaskEvent> eventListener,
			Class<? extends TaskEvent> eventType) {
		checkNotNull(partitionId);
		checkNotNull(eventListener);
		checkNotNull(eventType);

		TaskEventHandler taskEventHandler;
		synchronized (registeredHandlers) {
			taskEventHandler = registeredHandlers.get(partitionId);
		}
		if (taskEventHandler == null) {
			throw new IllegalStateException(
				""Partition "" + partitionId + "" not registered at task event dispatcher."");
		}
		taskEventHandler.subscribe(eventListener, eventType);
	}"
"public synchronized boolean trim() throws IOException {
        boolean modified = false;

        for (Entry<String,RangeSet> e : new Hashtable<>(usages).entrySet()) {// copy because we mutate
            Job j = Jenkins.getInstance().getItemByFullName(e.getKey(),Job.class);
            if(j==null) {// no such job any more. recycle the record
                modified = true;
                usages.remove(e.getKey());
                continue;
            }

            Run firstBuild = j.getFirstBuild();
            if(firstBuild==null) {// no builds. recycle the whole record
                modified = true;
                usages.remove(e.getKey());
                continue;
            }

            RangeSet cur = e.getValue();

            // builds that are around without the keepLog flag on are normally clustered together (in terms of build #)
            // so our basic strategy is to discard everything up to the first ephemeral build, except those builds
            // that are marked as kept
            RangeSet kept = new RangeSet();
            Run r = firstBuild;
            while (r!=null && r.isKeepLog()) {
                kept.add(r.getNumber());
                r = r.getNextBuild();
            }

            if (r==null) {
                // all the build records are permanently kept ones, so we'll just have to keep 'kept' out of whatever currently in 'cur'
                modified |= cur.retainAll(kept);
            } else {
                // otherwise we are ready to discard [0,r.number) except those marked as 'kept'
                RangeSet discarding =  new RangeSet(new Range(-1,r.getNumber()));
                discarding.removeAll(kept);
                modified |= cur.removeAll(discarding);
            }

            if (cur.isEmpty()) {
                usages.remove(e.getKey());
                modified = true;
            }
        }

        if (modified) {
            if (logger.isLoggable(Level.FINE)) {
                logger.log(Level.FINE, ""Saving trimmed {0}"", getFingerprintFile(md5sum));
            }
            save();
        }

        return modified;
    }"
"private static void validateOffset(int offset, int chunkSizeSoFar) {
        if (offset == 0) {
            throw new DecompressionException(""Offset is less than minimum permissible value"");
        }

        if (offset < 0) {
            // Due to arithmetic overflow
            throw new DecompressionException(""Offset is greater than maximum value supported by this implementation"");
        }

        if (offset > chunkSizeSoFar) {
            throw new DecompressionException(""Offset exceeds size of chunk"");
        }
    }"
"private void checkForOverride(Properties properties, String name, String attr, String value) {
		String propertyValue = properties.getProperty(attr);
		if (propertyValue != null && !propertyValue.equals(value)) {
			LOG.warn(name + "":an attempt to override final parameter: "" + attr
					+ "";  Ignoring."");
		}
	}"
"public <C extends Closeable> C register(@Nullable C closeable)
  {
    if (closeable != null) {
      stack.addFirst(closeable);
    }

    return closeable;
  }"
"public void addStr(Chunk c, long row) {
    if( c.isNA_abs(row) ) addNA();
    else { addStr(c.atStr_abs(new BufferedString(), row)); _isAllASCII &= ((CStrChunk)c)._isAllASCII; }
  }"
"@Exported
    public final Object[] getItems() {
        List<T> r = new ArrayList<>();
        for (T t : this)
            r.add(t);
        return r.toArray();
    }"
"public String apply(final JsonParser jp) throws IOException {
        return apply(jp, CacheScope.APPLICATION_SCOPE, null);
    }"
"private boolean verifySignature(Signature signature, String providedSignature) {
        // We can only make one call to Signature#verify here.
        // Since we need to potentially check two values (one decoded from hex, the other decoded from base64),
        // try hex first: It's almost certainly going to fail decoding if a base64 string was passed.
        // It is extremely unlikely for base64 strings to be a valid hex string.
        // This way, if it's base64, the #verify call will be skipped, and we continue with the #verify for decoded base64.
        // This approach might look unnecessarily clever, but short of having redundant Signature instances,
        // there doesn't seem to be a better approach for this.
        try {
            if (signature.verify(Hex.decodeHex(providedSignature.toCharArray()))) {
                return true;
            }
        } catch (SignatureException|DecoderException ignore) {
            // ignore
        }

        try {
            if (signature.verify(Base64.getDecoder().decode(providedSignature))) {
                return true;
            }
        } catch (SignatureException|IllegalArgumentException ignore) {
            // ignore
        }
        return false;
    }"
"protected void registerOptionHandlers() {
        try {
            for (Class c : Index.list(OptionHandlerExtension.class, Jenkins.getActiveInstance().pluginManager.uberClassLoader,Class.class)) {
                Type t = Types.getBaseClass(c, OptionHandler.class);
                CmdLineParser.registerHandler(Types.erasure(Types.getTypeArgument(t,0)), c);
            }
        } catch (IOException e) {
            throw new Error(e);
        }
    }"
"public static WatchMonitor createAll(URI uri, int maxDepth, Watcher watcher) {
		return createAll(Paths.get(uri), maxDepth, watcher);
	}"
"protected UpdateCenter.InstallationJob createInstallationJob(Plugin plugin, UpdateCenter uc, boolean dynamicLoad) {
        return uc.new InstallationJob(plugin, this, Jenkins.getAuthentication(), dynamicLoad);
    }"
"public void setAnimation(@RawRes final int rawRes) {
    this.animationResId = rawRes;
    animationName = null;
    setCompositionTask(LottieCompositionFactory.fromRawRes(getContext(), rawRes));
  }"
"protected ModelAndView buildCallbackUrlResponseType(final AccessTokenRequestDataHolder holder,
                                                        final String redirectUri,
                                                        final AccessToken accessToken,
                                                        final List<NameValuePair> params,
                                                        final RefreshToken refreshToken,
                                                        final J2EContext context) throws Exception {
        val attributes = holder.getAuthentication().getAttributes();
        val state = attributes.get(OAuth20Constants.STATE).get(0).toString();
        val nonce = attributes.get(OAuth20Constants.NONCE).get(0).toString();

        val builder = new URIBuilder(redirectUri);
        val stringBuilder = new StringBuilder();

        val timeToLive = accessTokenExpirationPolicy.getTimeToLive();
        stringBuilder.append(OAuth20Constants.ACCESS_TOKEN)
            .append('=')
            .append(accessToken.getId())
            .append('&')
            .append(OAuth20Constants.TOKEN_TYPE)
            .append('=')
            .append(OAuth20Constants.TOKEN_TYPE_BEARER)
            .append('&')
            .append(OAuth20Constants.EXPIRES_IN)
            .append('=')
            .append(timeToLive);

        if (refreshToken != null) {
            stringBuilder.append('&')
                .append(OAuth20Constants.REFRESH_TOKEN)
                .append('=')
                .append(refreshToken.getId());
        }

        params.forEach(p -> stringBuilder.append('&')
            .append(p.getName())
            .append('=')
            .append(p.getValue()));

        if (StringUtils.isNotBlank(state)) {
            stringBuilder.append('&')
                .append(OAuth20Constants.STATE)
                .append('=')
                .append(EncodingUtils.urlEncode(state));
        }
        if (StringUtils.isNotBlank(nonce)) {
            stringBuilder.append('&')
                .append(OAuth20Constants.NONCE)
                .append('=')
                .append(EncodingUtils.urlEncode(nonce));
        }
        builder.setFragment(stringBuilder.toString());
        val url = builder.toString();

        LOGGER.debug(""Redirecting to URL [{}]"", url);
        val parameters = new LinkedHashMap<String, String>();
        parameters.put(OAuth20Constants.ACCESS_TOKEN, accessToken.getId());
        if (refreshToken != null) {
            parameters.put(OAuth20Constants.REFRESH_TOKEN, refreshToken.getId());
        }
        parameters.put(OAuth20Constants.EXPIRES_IN, timeToLive.toString());
        parameters.put(OAuth20Constants.STATE, state);
        parameters.put(OAuth20Constants.NONCE, nonce);
        parameters.put(OAuth20Constants.CLIENT_ID, accessToken.getClientId());
        return buildResponseModelAndView(context, servicesManager, accessToken.getClientId(), url, parameters);
    }"
"public BinaryMergeIterator<Entry> getMergingIterator(
			List<ChannelWithMeta> channelIDs,
			List<FileIOChannel> openChannels)
			throws IOException {
		// create one iterator per channel id
		if (LOG.isDebugEnabled()) {
			LOG.debug(""Performing merge of "" + channelIDs.size() + "" sorted streams."");
		}

		final List<MutableObjectIterator<Entry>> iterators = new ArrayList<>(channelIDs.size() + 1);

		for (ChannelWithMeta channel : channelIDs) {
			AbstractChannelReaderInputView view = FileChannelUtil.createInputView(
					ioManager, channel, openChannels, compressionEnable, compressionCodecFactory,
					compressionBlockSize, pageSize);
			iterators.add(channelReaderInputViewIterator(view));
		}

		return new BinaryMergeIterator<>(
				iterators, mergeReusedEntries(channelIDs.size()), mergeComparator());
	}"
"private void initialize() {
		this.setTitle(Constant.messages.getString(""cfu.manage.title""));
        //this.setContentPane(getJTabbed());
        this.setContentPane(getTopPanel());
        this.pack();
        centerFrame();
        state = State.IDLE;
        
        // Handle escape key to close the dialog
        KeyStroke escape = KeyStroke.getKeyStroke(KeyEvent.VK_ESCAPE, 0, false);
        AbstractAction escapeAction = new AbstractAction() {
            private static final long serialVersionUID = 3516424501887406165L;
            @Override
            public void actionPerformed(ActionEvent e) {
                dispatchEvent(new WindowEvent(ManageAddOnsDialog.this, WindowEvent.WINDOW_CLOSING));
            }
	    };
        getRootPane().getInputMap(JComponent.WHEN_IN_FOCUSED_WINDOW).put(escape, ""ESCAPE"");
        getRootPane().getActionMap().put(""ESCAPE"",escapeAction);
	}"
"public AnnotationValueBuilder<T> member(String name, String... strings) {
        if (strings != null) {
            values.put(name, strings);
        }
        return this;
    }"
"public static FixedBucketsHistogram fromBytes(byte[] bytes)
  {
    ByteBuffer buf = ByteBuffer.wrap(bytes);
    return fromByteBuffer(buf);
  }"
"private static void tokenToAuthCookie(
      HttpServletResponse resp,
      String token,
      String domain,
      String path,
      long expires,
      boolean isCookiePersistent,
      boolean isSecure
  )
  {
    resp.addHeader(""Set-Cookie"", tokenToCookieString(token, domain, path, expires, isCookiePersistent, isSecure));
  }"
"public static int elementWiseStride(DataBuffer buffer) {
        int length2 = shapeInfoLength(buffer.getInt(0));
        return buffer.getInt(length2 - 2);
    }"
"public DatabaseMetaData filterDataBaseMetaData(JdbcTemplate jdbcTemplate, Connection con,
                                                   DatabaseMetaData databaseMetaData) throws Exception {
        return databaseMetaData;
    }"
"static String buildMessage(BeanResolutionContext resolutionContext, FieldInjectionPoint fieldInjectionPoint, String message, boolean circular) {
        StringBuilder builder = new StringBuilder(""Failed to inject value for field ["");
        String ls = System.getProperty(""line.separator"");
        builder
            .append(fieldInjectionPoint.getName()).append(""] of class: "")
            .append(fieldInjectionPoint.getDeclaringBean().getName())
            .append(ls)
            .append(ls);

        if (message != null) {
            builder.append(""Message: "").append(message).append(ls);
        }
        appendPath(resolutionContext, circular, builder, ls);
        return builder.toString();
    }"
"public Permalink findNearest(String id) {
        List<String> ids = new ArrayList<>();
        for (Permalink p : this)
            ids.add(p.getId());
        String nearest = EditDistance.findNearest(id, ids);
        if(nearest==null)   return null;
        return get(nearest);
    }"
"public static SecretKey generateDESKey(String algorithm, byte[] key) {
		if (StrUtil.isBlank(algorithm) || false == algorithm.startsWith(""DES"")) {
			throw new CryptoException(""Algorithm [{}] is not a DES algorithm!"");
		}

		SecretKey secretKey = null;
		if (null == key) {
			secretKey = generateKey(algorithm);
		} else {
			KeySpec keySpec;
			try {
				if (algorithm.startsWith(""DESede"")) {
					// DESede兼容
					keySpec = new DESedeKeySpec(key);
				} else {
					keySpec = new DESKeySpec(key);
				}
			} catch (InvalidKeyException e) {
				throw new CryptoException(e);
			}
			secretKey = generateKey(algorithm, keySpec);
		}
		return secretKey;
	}"
"public static ImageIcon getHelpIcon() {
        if (helpIcon == null) {
            helpIcon = DisplayUtils.getScaledIcon(new ImageIcon(ExtensionHelp.class.getResource(""/resource/icon/16/201.png"")));
        }
        return helpIcon;
    }"
"private void registerCleanUpTimer(Context ctx, long rowTime, boolean leftRow) throws IOException {
		if (leftRow) {
			long cleanUpTime = rowTime + leftRelativeSize + minCleanUpInterval + allowedLateness + 1;
			registerTimer(ctx, cleanUpTime);
			rightTimerState.update(cleanUpTime);
		} else {
			long cleanUpTime = rowTime + rightRelativeSize + minCleanUpInterval + allowedLateness + 1;
			registerTimer(ctx, cleanUpTime);
			leftTimerState.update(cleanUpTime);
		}
	}"
"public static void displayIOException(@Nonnull IOException e, @Nonnull TaskListener listener ) {
        String msg = getWin32ErrorMessage(e);
        if(msg!=null)
            listener.getLogger().println(msg);
    }"
"public List<KeyPath> resolveKeyPath(KeyPath keyPath) {
    if (compositionLayer == null) {
      Log.w(L.TAG, ""Cannot resolve KeyPath. Composition is not set yet."");
      return Collections.emptyList();
    }
    List<KeyPath> keyPaths = new ArrayList<>();
    compositionLayer.resolveKeyPath(keyPath, 0, keyPaths, new KeyPath());
    return keyPaths;
  }"
"public static void writePng(Image image, ImageOutputStream destImageStream) throws IORuntimeException {
		write(image, IMAGE_TYPE_PNG, destImageStream);
	}"
"public void prune(
			Collection<ComputationState> matchesToPrune,
			Collection<Map<String, List<EventId>>> matchedResult,
			SharedBufferAccessor<?> sharedBufferAccessor) throws Exception {

		EventId pruningId = getPruningId(matchedResult);
		if (pruningId != null) {
			List<ComputationState> discardStates = new ArrayList<>();
			for (ComputationState computationState : matchesToPrune) {
				if (computationState.getStartEventID() != null &&
					shouldPrune(computationState.getStartEventID(), pruningId)) {
					sharedBufferAccessor.releaseNode(computationState.getPreviousBufferEntry());
					discardStates.add(computationState);
				}
			}
			matchesToPrune.removeAll(discardStates);
		}
	}"
"@Override
    public V replace(K key, V value) {
        int hash = hash(key);
        if (value == null) {
          throw new NullPointerException();
        }
        Segment<K,V> s = segmentForHash(hash);
        return s == null ? null : s.replace(key, hash, value);
    }"
"public void shutdown() {
    logger.warn(""Shutting down FlowRunnerManager..."");
    if (this.azkabanProps.getBoolean(ConfigurationKeys.AZKABAN_POLL_MODEL, false)) {
      this.pollingService.shutdown();
    }
    this.executorService.shutdown();
    boolean result = false;
    while (!result) {
      logger.info(""Awaiting Shutdown. # of executing flows: "" + getNumRunningFlows());
      try {
        result = this.executorService.awaitTermination(1, TimeUnit.MINUTES);
      } catch (final InterruptedException e) {
        logger.error(e);
      }
    }
    logger.warn(""Shutdown FlowRunnerManager complete."");
  }"
"public HttpRequest method(Method method) {
		if (Method.PATCH == method) {
			this.method = Method.POST;
			this.header(""X-HTTP-Method-Override"", ""PATCH"");
		} else {
			this.method = method;
		}
		return this;
	}"
"public void refresh(ExtensionComponentSet delta) {
        boolean fireOnChangeListeners = false;
        synchronized (getLoadLock()) {
            if (extensions==null)
                return;     // not yet loaded. when we load it, we'll load everything visible by then, so no work needed

            Collection<ExtensionComponent<T>> found = load(delta);
            if (!found.isEmpty()) {
                List<ExtensionComponent<T>> l = Lists.newArrayList(extensions);
                l.addAll(found);
                extensions = sort(l);
                fireOnChangeListeners = true;
            }
        }
        if (fireOnChangeListeners) {
            fireOnChangeListeners();
        }
    }"
"public CorsConfigBuilder preflightResponseHeader(final CharSequence name, final Object... values) {
        if (values.length == 1) {
            preflightHeaders.put(name, new ConstantValueGenerator(values[0]));
        } else {
            preflightResponseHeader(name, Arrays.asList(values));
        }
        return this;
    }"
"static <T> PojoSerializerSnapshotData<T> createFrom(
			Class<T> pojoClass,
			Field[] fields,
			TypeSerializerSnapshot<?>[] existingFieldSerializerSnapshots,
			LinkedHashMap<Class<?>, TypeSerializerSnapshot<?>> existingRegisteredSubclassSerializerSnapshots,
			Map<Class<?>, TypeSerializerSnapshot<?>> existingNonRegisteredSubclassSerializerSnapshots) {

		final LinkedOptionalMap<Field, TypeSerializerSnapshot<?>> fieldSerializerSnapshots = new LinkedOptionalMap<>(fields.length);
		for (int i = 0; i < fields.length; i++) {
			Field field = fields[i];
			String fieldName = (field == null) ? getDummyNameForMissingField(i) : field.getName();
			fieldSerializerSnapshots.put(fieldName, field, existingFieldSerializerSnapshots[i]);
		}

		return new PojoSerializerSnapshotData<>(
			pojoClass,
			fieldSerializerSnapshots,
			optionalMapOf(existingRegisteredSubclassSerializerSnapshots, Class::getName),
			optionalMapOf(existingNonRegisteredSubclassSerializerSnapshots, Class::getName));
	}"
"public List<Extension> getExtensions () {
		List<Extension> list = new ArrayList<Extension>();
		for (AddOn addOn : getAddOnCollection().getAddOns()) {
			list.addAll(getExtensions(addOn));
        }
		
		return list;
	}"
"public static ActorSystem startActorSystem(
		Configuration configuration,
		String actorSystemName,
		String listeningAddress,
		int listeningPort,
		Logger logger,
		ActorSystemExecutorConfiguration actorSystemExecutorConfiguration) throws Exception {

		String hostPortUrl = NetUtils.unresolvedHostAndPortToNormalizedString(listeningAddress, listeningPort);
		logger.info(""Trying to start actor system at {}"", hostPortUrl);

		try {
			Config akkaConfig = AkkaUtils.getAkkaConfig(
				configuration,
				new Some<>(new Tuple2<>(listeningAddress, listeningPort)),
				actorSystemExecutorConfiguration.getAkkaConfig());

			logger.debug(""Using akka configuration\n {}"", akkaConfig);

			ActorSystem actorSystem = AkkaUtils.createActorSystem(actorSystemName, akkaConfig);

			logger.info(""Actor system started at {}"", AkkaUtils.getAddress(actorSystem));
			return actorSystem;
		}
		catch (Throwable t) {
			if (t instanceof ChannelException) {
				Throwable cause = t.getCause();
				if (cause != null && t.getCause() instanceof BindException) {
					throw new IOException(""Unable to create ActorSystem at address "" + hostPortUrl +
						"" : "" + cause.getMessage(), t);
				}
			}
			throw new Exception(""Could not create actor system"", t);
		}
	}"
"public static OffsetCommitMode fromConfiguration(
			boolean enableAutoCommit,
			boolean enableCommitOnCheckpoint,
			boolean enableCheckpointing) {

		if (enableCheckpointing) {
			// if checkpointing is enabled, the mode depends only on whether committing on checkpoints is enabled
			return (enableCommitOnCheckpoint) ? OffsetCommitMode.ON_CHECKPOINTS : OffsetCommitMode.DISABLED;
		} else {
			// else, the mode depends only on whether auto committing is enabled in the provided Kafka properties
			return (enableAutoCommit) ? OffsetCommitMode.KAFKA_PERIODIC : OffsetCommitMode.DISABLED;
		}
	}"
"private static byte[] toByteArray(InputStream is) throws IOException {
    try (ByteArrayOutputStream os = new ByteArrayOutputStream()) {
      byte[] buffer = new byte[0x2000];
      for (int len; (len = is.read(buffer)) != -1; )
        os.write(buffer, 0, len);
      return os.toByteArray();
    }
  }"
"protected INDArray outputOfLayerDetached(boolean train, @NonNull FwdPassType fwdPassType, int layerIndex, @NonNull INDArray input,
                                             INDArray featureMask, INDArray labelsMask, MemoryWorkspace outputWorkspace){
        setInput(input);
        setLayerMaskArrays(featureMask, labelsMask);

        /*
        Idea here: we want to minimize memory, and return only the final array
        Approach to do this: keep activations in memory only as long as we need them.
        In MultiLayerNetwork, the output activations of layer X are used as input to layer X+1
        Which means: the workspace for layer X has to be open for both layers X and X+1 forward pass.

        Here, we'll use two workspaces for activations:
        1. For even index layers, activations WS that opens on start of even layer fwd pass, closes at end of odd layer fwd pass
        2. For odd index layers, activations WS that opens on start of odd layer fwd pass, closes at end of even layer fwd pass

        Additionally, we'll reconfigure the workspace manager for the *final* layer, so that we don't have to detach
         */
        if(outputWorkspace == null || outputWorkspace instanceof DummyWorkspace) {
            WorkspaceUtils.assertNoWorkspacesOpen(""Expected no workspace active in outputOfLayerDetached"", true);
        } else {
            Preconditions.checkState(outputWorkspace.isScopeActive(), ""Workspace \"""" + outputWorkspace.getId() +
                    ""\"" was provided for the network/layer outputs. When provided, this workspace must be opened before "" +
                    ""calling the output method; furthermore, closing the workspace is the responsibility of the user"");
        }

        LayerWorkspaceMgr mgrEven;
        LayerWorkspaceMgr mgrOdd;

        WorkspaceMode wsm = train ? layerWiseConfigurations.getTrainingWorkspaceMode() : layerWiseConfigurations.getInferenceWorkspaceMode();
        if(wsm == WorkspaceMode.NONE){
            mgrEven = LayerWorkspaceMgr.noWorkspaces();
            mgrOdd = mgrEven;

            //Check for external workspace - doesn't make sense to have one with workspace mode NONE
            if(outputWorkspace != null && !(outputWorkspace instanceof DummyWorkspace)){
                throw new IllegalStateException(""Workspace \"""" + outputWorkspace.getId() +
                        ""\"" was provided for the network/layer outputs, however "" + (train ? ""training"" : ""inference"") +
                        "" workspace mode is set to NONE. Cannot put output activations into the specified workspace if"" +
                        ""workspaces are disabled for the network. use getConfiguration().setTraining/InferenceWorkspaceMode(WorkspaceMode.ENABLED)"");
            }
        } else {
            mgrEven = LayerWorkspaceMgr.builder()
                    .with(ArrayType.FF_WORKING_MEM, WS_LAYER_WORKING_MEM, WS_LAYER_WORKING_MEM_CONFIG)
                    .with(ArrayType.ACTIVATIONS, WS_LAYER_ACT_1, WS_LAYER_ACT_X_CONFIG)
                    .with(ArrayType.INPUT, WS_LAYER_ACT_2, WS_LAYER_ACT_X_CONFIG)            //Inputs should always be in the previous WS
                    .with(ArrayType.RNN_FF_LOOP_WORKING_MEM, WS_RNN_LOOP_WORKING_MEM, WS_RNN_LOOP_WORKING_MEM_CONFIG)
                    .build();

            mgrOdd = LayerWorkspaceMgr.builder()
                    .with(ArrayType.FF_WORKING_MEM, WS_LAYER_WORKING_MEM, WS_LAYER_WORKING_MEM_CONFIG)
                    .with(ArrayType.ACTIVATIONS, WS_LAYER_ACT_2, WS_LAYER_ACT_X_CONFIG)
                    .with(ArrayType.INPUT, WS_LAYER_ACT_1, WS_LAYER_ACT_X_CONFIG)            //Inputs should always be in the previous WS
                    .with(ArrayType.RNN_FF_LOOP_WORKING_MEM, WS_RNN_LOOP_WORKING_MEM, WS_RNN_LOOP_WORKING_MEM_CONFIG)
                    .build();
        }
        mgrEven.setHelperWorkspacePointers(helperWorkspaces);
        mgrOdd.setHelperWorkspacePointers(helperWorkspaces);

        MemoryWorkspace wsActCloseNext = null;
        MemoryWorkspace temp = null;
        MemoryWorkspace initialWorkspace = Nd4j.getMemoryManager().getCurrentWorkspace();
        try {
            for (int i = 0; i <= layerIndex; i++) {
                LayerWorkspaceMgr mgr = (i % 2 == 0 ? mgrEven : mgrOdd);

                //Edge case: for first layer with dropout, inputs can't be in previous workspace (as it hasn't been opened yet)
                //Hence: put inputs in working memory
                if(i == 0 && wsm != WorkspaceMode.NONE){
                    mgr.setWorkspace(ArrayType.INPUT, WS_LAYER_WORKING_MEM, WS_LAYER_WORKING_MEM_CONFIG);
                }

                try (MemoryWorkspace wsFFWorking = mgr.notifyScopeEntered(ArrayType.FF_WORKING_MEM)) { //Working memory: opened/closed once per layer
                    //Activations workspaces: opened/closed every second layer.
                    //So mgrEven (WS_LAYER_ACT_1) open at start of 0, 2, 4, 8; closed at end of 1, 3, 5, 7 etc
                    //and mgrOdd (WS_LAYER_ACT_2) opened at start of 1, 3, 5, 7; closed at end of 2, 4, 6, 8 etc
                    temp = mgr.notifyScopeEntered(ArrayType.ACTIVATIONS);

                    //Note that because we're opening activation workspaces not in a simple nested order, we'll manually
                    // override the previous workspace setting. Otherwise, when we close these workspaces, the ""current""
                    // workspace may be set to the incorrect one
                    temp.setPreviousWorkspace(initialWorkspace);


                    if(i == 0 && input.isAttached()){
                        //Don't leverage out of async DataSetIterator workspaces
                        mgr.setNoLeverageOverride(input.data().getParentWorkspace().getId());
                    }

                    if (getLayerWiseConfigurations().getInputPreProcess(i) != null) {
                        input = getLayerWiseConfigurations().getInputPreProcess(i).preProcess(input, getInputMiniBatchSize(), mgr);
                        //Validation: Exception if invalid (bad preprocessor implementation)
                        validateArrayWorkspaces(mgr, input, ArrayType.ACTIVATIONS, i, true, ""Output of layer (inference)"");
                    }

                    if ( i == layerIndex ) {
                        if(outputWorkspace != null && !(outputWorkspace instanceof DummyWorkspace)){
                            //Place activations in user-specified workspace
                            mgr.setWorkspace(ArrayType.ACTIVATIONS, outputWorkspace.getId(), outputWorkspace.getWorkspaceConfiguration());
                        } else {
                            //Final activations: should be detached
                            mgr.setScopedOutFor(ArrayType.ACTIVATIONS);
                        }
                    }

                    if(fwdPassType == FwdPassType.STANDARD){
                        //Standard feed-forward case
                        input = layers[i].activate(input, train, mgr);
                    } else if(fwdPassType == FwdPassType.RNN_TIMESTEP){
                        //rnnTimeStep case
                        if (layers[i] instanceof RecurrentLayer) {
                            input = ((RecurrentLayer) layers[i]).rnnTimeStep(reshapeTimeStepInput(input), mgr);
                        } else if(layers[i] instanceof BaseWrapperLayer && ((BaseWrapperLayer)layers[i]).getUnderlying() instanceof RecurrentLayer){
                            RecurrentLayer rl = ((RecurrentLayer) ((BaseWrapperLayer)layers[i]).getUnderlying());
                            input = rl.rnnTimeStep(reshapeTimeStepInput(input), mgr);
                        } else if (layers[i] instanceof MultiLayerNetwork) {
                            input = ((MultiLayerNetwork) layers[i]).rnnTimeStep(reshapeTimeStepInput(input));
                        } else {
                            input = layers[i].activate(input, false, mgr);
                        }
                    } else {
                        throw new IllegalArgumentException(""Unsupported forward pass type for this method: "" + fwdPassType);
                    }
                    layers[i].clear();
                    //Validation: Exception if invalid (bad layer implementation)
                    validateArrayWorkspaces(mgr, input, ArrayType.ACTIVATIONS, i, false, ""Output of layer (inference)"");

                    if(wsActCloseNext != null){
                        wsActCloseNext.close();
                    }
                    wsActCloseNext = temp;
                    temp = null;
                }

                //Edge case: for first layer with dropout, inputs can't be in previous workspace (as it hasn't been opened yet)
                //Hence: put inputs in working memory -> set back to default for next use of workspace mgr
                if(i == 0 && wsm != WorkspaceMode.NONE){
                    mgr.setWorkspace(ArrayType.INPUT, WS_LAYER_ACT_2, WS_LAYER_ACT_X_CONFIG);            //Inputs should always be in the previous WS
                }
            }

        } finally {
            if(wsActCloseNext != null){
                wsActCloseNext.close();
            }
            if(temp != null){
                //Should only be non-null on exception
                while(temp.isScopeActive()){
                    //For safety, should never occur in theory: a single close() call may not be sufficient, if
                    // workspace scope was borrowed and not properly closed when exception occurred
                    temp.close();
                }
            }

            Nd4j.getMemoryManager().setCurrentWorkspace(initialWorkspace);

            if(outputWorkspace == null || outputWorkspace instanceof DummyWorkspace) {
                WorkspaceUtils.assertNoWorkspacesOpen(""Expected no workspace active at the end of outputOfLayerDetached"", true);
            } else {
                Preconditions.checkState(outputWorkspace.isScopeActive(), ""Expected output workspace to still be open"" +
                        ""at end of outputOfLayerDetached, but it is closed. This suggests an implementation or layer workspace problem"");
            }
        }

        return input;
    }"
"public double getDouble(String name, double defaultValue) {
		String valueString = getTrimmed(name);
		if (valueString == null)
			return defaultValue;
		return Double.parseDouble(valueString);
	}"
"public void add(final T bagEntry)
   {
      if (closed) {
         LOGGER.info(""ConcurrentBag has been closed, ignoring add()"");
         throw new IllegalStateException(""ConcurrentBag has been closed, ignoring add()"");
      }

      sharedList.add(bagEntry);

      // spin until a thread takes it or none are waiting
      while (waiters.get() > 0 && bagEntry.getState() == STATE_NOT_IN_USE && !handoffQueue.offer(bagEntry)) {
         yield();
      }
   }"
"public <T extends ThreadPoolTaskExecutor> T configure(T taskExecutor) {
		PropertyMapper map = PropertyMapper.get().alwaysApplyingWhenNonNull();
		map.from(this.queueCapacity).to(taskExecutor::setQueueCapacity);
		map.from(this.corePoolSize).to(taskExecutor::setCorePoolSize);
		map.from(this.maxPoolSize).to(taskExecutor::setMaxPoolSize);
		map.from(this.keepAlive).asInt(Duration::getSeconds)
				.to(taskExecutor::setKeepAliveSeconds);
		map.from(this.allowCoreThreadTimeOut).to(taskExecutor::setAllowCoreThreadTimeOut);
		map.from(this.awaitTermination)
				.to(taskExecutor::setWaitForTasksToCompleteOnShutdown);
		map.from(this.awaitTerminationPeriod).asInt(Duration::getSeconds)
				.to(taskExecutor::setAwaitTerminationSeconds);
		map.from(this.threadNamePrefix).whenHasText()
				.to(taskExecutor::setThreadNamePrefix);
		map.from(this.taskDecorator).to(taskExecutor::setTaskDecorator);
		if (!CollectionUtils.isEmpty(this.customizers)) {
			this.customizers.forEach((customizer) -> customizer.customize(taskExecutor));
		}
		return taskExecutor;
	}"
"public final void putIntBigEndian(int index, int value) {
		if (LITTLE_ENDIAN) {
			putInt(index, Integer.reverseBytes(value));
		} else {
			putInt(index, value);
		}
	}"
"public StyleSet setBackgroundColor(IndexedColors backgroundColor, boolean withHeadCell) {
		if (withHeadCell) {
			StyleUtil.setColor(this.headCellStyle, backgroundColor, FillPatternType.SOLID_FOREGROUND);
		}
		StyleUtil.setColor(this.cellStyle, backgroundColor, FillPatternType.SOLID_FOREGROUND);
		StyleUtil.setColor(this.cellStyleForNumber, backgroundColor, FillPatternType.SOLID_FOREGROUND);
		StyleUtil.setColor(this.cellStyleForDate, backgroundColor, FillPatternType.SOLID_FOREGROUND);
		return this;
	}"
"public String getDriverClassName() {
        final String driverClassName = basicJdbcConfiguration.getConfiguredDriverClassName();
        if (calculatedDriverClassName == null || StringUtils.hasText(driverClassName)) {
            if (StringUtils.hasText(driverClassName)) {
                if (!driverClassIsPresent(driverClassName)) {
                    throw new ConfigurationException(String.format(""Error configuring data source '%s'. The driver class '%s' was not found on the classpath"", basicJdbcConfiguration.getName(), driverClassName));
                }
                calculatedDriverClassName = driverClassName;
            } else {
                final String url = basicJdbcConfiguration.getUrl();
                if (StringUtils.hasText(url)) {
                    JdbcDatabaseManager.findDatabase(url).ifPresent(db ->
                        calculatedDriverClassName = db.getDriverClassName());
                }

                if (!StringUtils.hasText(calculatedDriverClassName) && embeddedDatabaseConnection.isPresent()) {
                    calculatedDriverClassName = this.embeddedDatabaseConnection.get().getDriverClassName();
                }

                if (!StringUtils.hasText(calculatedDriverClassName)) {
                    throw new ConfigurationException(String.format(""Error configuring data source '%s'. No driver class name specified"", basicJdbcConfiguration.getName()));
                }
            }
        }

        return calculatedDriverClassName;
    }"
"public static String getKey(KeyRequest keyRequest, String envTag) throws ClientException {
        final Http2Client client = Http2Client.getInstance();
        final CountDownLatch latch = new CountDownLatch(1);
        final ClientConnection connection;
        try {
            if(keyRequest.getServerUrl() != null) {
                connection = client.connect(new URI(keyRequest.getServerUrl()), Http2Client.WORKER, Http2Client.SSL, Http2Client.BUFFER_POOL, keyRequest.enableHttp2 ? OptionMap.create(UndertowOptions.ENABLE_HTTP2, true): OptionMap.EMPTY).get();
            } else if(keyRequest.getServiceId() != null) {
                Cluster cluster = SingletonServiceFactory.getBean(Cluster.class);
                String url = cluster.serviceToUrl(""https"", keyRequest.getServiceId(), envTag, null);
                connection = client.connect(new URI(url), Http2Client.WORKER, Http2Client.SSL, Http2Client.BUFFER_POOL, keyRequest.enableHttp2 ? OptionMap.create(UndertowOptions.ENABLE_HTTP2, true): OptionMap.EMPTY).get();
            } else {
                // both server_url and serviceId are empty in the config.
                logger.error(""Error: both server_url and serviceId are not configured in client.yml for "" + keyRequest.getClass());
                throw new ClientException(""both server_url and serviceId are not configured in client.yml for "" + keyRequest.getClass());
            }
        } catch (Exception e) {
            throw new ClientException(e);
        }
        final AtomicReference<ClientResponse> reference = new AtomicReference<>();
        try {
            ClientRequest request = new ClientRequest().setPath(keyRequest.getUri()).setMethod(Methods.GET);

            if (keyRequest.getClientId()!=null) {
                request.getRequestHeaders().put(Headers.AUTHORIZATION, getBasicAuthHeader(keyRequest.getClientId(), keyRequest.getClientSecret()));
            }
            request.getRequestHeaders().put(Headers.HOST, ""localhost"");
            adjustNoChunkedEncoding(request, """");
            connection.sendRequest(request, client.createClientCallback(reference, latch));
            latch.await();
        } catch (Exception e) {
            logger.error(""Exception: "", e);
            throw new ClientException(e);
        } finally {
            IoUtils.safeClose(connection);
        }
        return reference.get().getAttachment(Http2Client.RESPONSE_BODY);
    }"
"@Override
  protected HandlerMethod lookupHandlerMethod(String urlPath, HttpServletRequest request) {
    logger.debug(""looking up handler for path: "" + urlPath);
    HandlerMethod handlerMethod = handlerMethods.get(urlPath);
    if (handlerMethod != null) {
      return handlerMethod;
    }
    for (String path : handlerMethods.keySet()) {
      UriTemplate template = new UriTemplate(path);
      if (template.matches(urlPath)) {
        request.setAttribute(
            HandlerMapping.URI_TEMPLATE_VARIABLES_ATTRIBUTE,
            template.match(urlPath));
        return handlerMethods.get(path);
      }
    }
    return null;
  }"
"private static Mode decodeAsciiSegment(BitSource bits,
                                         StringBuilder result,
                                         StringBuilder resultTrailer) throws FormatException {
    boolean upperShift = false;
    do {
      int oneByte = bits.readBits(8);
      if (oneByte == 0) {
        throw FormatException.getFormatInstance();
      } else if (oneByte <= 128) {  // ASCII data (ASCII value + 1)
        if (upperShift) {
          oneByte += 128;
          //upperShift = false;
        }
        result.append((char) (oneByte - 1));
        return Mode.ASCII_ENCODE;
      } else if (oneByte == 129) {  // Pad
        return Mode.PAD_ENCODE;
      } else if (oneByte <= 229) {  // 2-digit data 00-99 (Numeric Value + 130)
        int value = oneByte - 130;
        if (value < 10) { // pad with '0' for single digit values
          result.append('0');
        }
        result.append(value);
      } else {
        switch (oneByte) {
          case 230: // Latch to C40 encodation
            return Mode.C40_ENCODE;
          case 231: // Latch to Base 256 encodation
            return Mode.BASE256_ENCODE;
          case 232: // FNC1
            result.append((char) 29); // translate as ASCII 29
            break;
          case 233: // Structured Append
          case 234: // Reader Programming
            // Ignore these symbols for now
            //throw ReaderException.getInstance();
            break;
          case 235: // Upper Shift (shift to Extended ASCII)
            upperShift = true;
            break;
          case 236: // 05 Macro
            result.append(""[)>\u001E05\u001D"");
            resultTrailer.insert(0, ""\u001E\u0004"");
            break;
          case 237: // 06 Macro
            result.append(""[)>\u001E06\u001D"");
            resultTrailer.insert(0, ""\u001E\u0004"");
            break;
          case 238: // Latch to ANSI X12 encodation
            return Mode.ANSIX12_ENCODE;
          case 239: // Latch to Text encodation
            return Mode.TEXT_ENCODE;
          case 240: // Latch to EDIFACT encodation
            return Mode.EDIFACT_ENCODE;
          case 241: // ECI Character
            // TODO(bbrown): I think we need to support ECI
            //throw ReaderException.getInstance();
            // Ignore this symbol for now
            break;
          default:
            // Not to be used in ASCII encodation
            // but work around encoders that end with 254, latch back to ASCII
            if (oneByte != 254 || bits.available() != 0) {
              throw FormatException.getFormatInstance();
            }
            break;
        }
      }
    } while (bits.available() > 0);
    return Mode.ASCII_ENCODE;
  }"
"public static String[] internInPlace(String[] input) {
        if (input == null) {
            return null;
        } else if (input.length == 0) {
            return EMPTY_STRING_ARRAY;
        }
        for (int i=0; i<input.length; i++) {
            input[i] = Util.intern(input[i]);
        }
        return input;
    }"
"public static void addLast(ChannelPipeline pipeline, long timeout, TimeUnit unit, BasicCounter httpRequestReadTimeoutCounter)
    {
        HttpRequestReadTimeoutHandler handler = new HttpRequestReadTimeoutHandler(timeout, unit, httpRequestReadTimeoutCounter);
        pipeline.addLast(HANDLER_NAME, handler);
    }"
"public static DateBetween create(Date begin, Date end, boolean isAbs) {
		return new DateBetween(begin, end, isAbs);
	}"
"public Task getTask(int index) {
		final Lock readLock = lock.readLock();
		try {
			readLock.lock();
			return tasks.get(index);
		} finally {
			readLock.unlock();
		}
	}"
"public static <T> Flux<T> toFlux(EventPublisher<T> eventPublisher) {
        DirectProcessor<T> directProcessor = DirectProcessor.create();
        eventPublisher.onEvent(directProcessor::onNext);
        return directProcessor;
    }"
"@CheckForNull
    public static String fixEmptyAndTrim(@CheckForNull String s) {
        if(s==null)    return null;
        return fixEmpty(s.trim());
    }"
"public static Object eval(String script, ScriptContext context) throws ScriptRuntimeException {
		try {
			return compile(script).eval(context);
		} catch (ScriptException e) {
			throw new ScriptRuntimeException(e);
		}
	}"
"private BeanDesc init() {
		for (Field field : ReflectUtil.getFields(this.beanClass)) {
			if(false == ModifierUtil.isStatic(field)) {
				//只针对非static属性
				this.propMap.put(field.getName(), createProp(field));
			}
		}
		return this;
	}"
"public String insertList(MappedStatement ms){
        final Class<?> entityClass = getEntityClass(ms);
        //开始拼sql
        StringBuilder sql = new StringBuilder();
        sql.append(""<bind name=\""listNotEmptyCheck\"" value=\""@tk.mybatis.mapper.util.OGNL@notEmptyCollectionCheck(list, '"" + ms.getId() + "" 方法参数为空')\""/>\n"");

        sql.append(""INSERT ALL\n"");
        sql.append(""<foreach collection=\""list\"" item=\""record\"">\n"");

        String tableName = SqlHelper.getDynamicTableName(entityClass, tableName(entityClass),""list[0]"");
        String columns = SqlHelper.insertColumns(entityClass, false, false, false);
        sql.append("" INTO "").append(tableName).append("" "").append(columns).append(""\n"");
        sql.append("" VALUES "");

        sql.append(""<trim prefix=\""(\"" suffix=\"")\"" suffixOverrides=\"",\"">"");

        Set<EntityColumn> columnList = EntityHelper.getColumns(entityClass);
        //单独增加对 genId 方式的支持
        for (EntityColumn column : columnList) {
            if(column.getGenIdClass() != null){
                sql.append(""<bind name=\"""").append(column.getColumn()).append(""GenIdBind\"" value=\""@tk.mybatis.mapper.genid.GenIdUtil@genId("");
                sql.append(""record"").append("", '"").append(column.getProperty()).append(""'"");
                sql.append("", @"").append(column.getGenIdClass().getCanonicalName()).append(""@class"");
                sql.append("", '"").append(tableName(entityClass)).append(""'"");
                sql.append("", '"").append(column.getColumn()).append(""')"");
                sql.append(""\""/>"");
            }
        }
        //当某个列有主键策略时，不需要考虑他的属性是否为空，因为如果为空，一定会根据主键策略给他生成一个值
        for (EntityColumn column : columnList) {
            if (column.isInsertable()) {
                sql.append(column.getColumnHolder(""record"") + "","");
            }
        }
        sql.append(""</trim>\n"");

        sql.append(""</foreach>\n"");
        sql.append(""SELECT 1 FROM DUAL"");

        //System.out.println(""sql mapper: \n"" + sql.toString());
        return sql.toString();
    }"
"@SuppressWarnings(""unchecked"")
	@Override
	public <K, V> BroadcastState<K, V> getBroadcastState(final MapStateDescriptor<K, V> stateDescriptor) throws StateMigrationException {

		Preconditions.checkNotNull(stateDescriptor);
		String name = Preconditions.checkNotNull(stateDescriptor.getName());

		BackendWritableBroadcastState<K, V> previous =
			(BackendWritableBroadcastState<K, V>) accessedBroadcastStatesByName.get(name);

		if (previous != null) {
			checkStateNameAndMode(
					previous.getStateMetaInfo().getName(),
					name,
					previous.getStateMetaInfo().getAssignmentMode(),
					OperatorStateHandle.Mode.BROADCAST);
			return previous;
		}

		stateDescriptor.initializeSerializerUnlessSet(getExecutionConfig());
		TypeSerializer<K> broadcastStateKeySerializer = Preconditions.checkNotNull(stateDescriptor.getKeySerializer());
		TypeSerializer<V> broadcastStateValueSerializer = Preconditions.checkNotNull(stateDescriptor.getValueSerializer());

		BackendWritableBroadcastState<K, V> broadcastState =
			(BackendWritableBroadcastState<K, V>) registeredBroadcastStates.get(name);

		if (broadcastState == null) {
			broadcastState = new HeapBroadcastState<>(
					new RegisteredBroadcastStateBackendMetaInfo<>(
							name,
							OperatorStateHandle.Mode.BROADCAST,
							broadcastStateKeySerializer,
							broadcastStateValueSerializer));
			registeredBroadcastStates.put(name, broadcastState);
		} else {
			// has restored state; check compatibility of new state access

			checkStateNameAndMode(
					broadcastState.getStateMetaInfo().getName(),
					name,
					broadcastState.getStateMetaInfo().getAssignmentMode(),
					OperatorStateHandle.Mode.BROADCAST);

			RegisteredBroadcastStateBackendMetaInfo<K, V> restoredBroadcastStateMetaInfo = broadcastState.getStateMetaInfo();

			// check whether new serializers are incompatible
			TypeSerializerSchemaCompatibility<K> keyCompatibility =
				restoredBroadcastStateMetaInfo.updateKeySerializer(broadcastStateKeySerializer);
			if (keyCompatibility.isIncompatible()) {
				throw new StateMigrationException(""The new key typeSerializer for broadcast state must not be incompatible."");
			}

			TypeSerializerSchemaCompatibility<V> valueCompatibility =
				restoredBroadcastStateMetaInfo.updateValueSerializer(broadcastStateValueSerializer);
			if (valueCompatibility.isIncompatible()) {
				throw new StateMigrationException(""The new value typeSerializer for broadcast state must not be incompatible."");
			}

			broadcastState.setStateMetaInfo(restoredBroadcastStateMetaInfo);
		}

		accessedBroadcastStatesByName.put(name, broadcastState);
		return broadcastState;
	}"
"public PropertySetting propertySetting(PropertySetting setter) {
    PropertySetting previous = this.setter;
    this.setter = Objects.requireNonNull(setter);
    return previous;
  }"
"@Deprecated
    public static void setIntHeader(HttpMessage message, String name, Iterable<Integer> values) {
        message.headers().set(name, values);
    }"
"private POJOPropertyBuilder jackson27AndHigherInstance(
      MapperConfig<?> config,
      BeanPropertyDefinition beanProperty,
      AnnotationIntrospector annotationIntrospector,
      boolean forSerialization) {
    try {
      Constructor<POJOPropertyBuilder> constructor = constructorWithParams(
          MapperConfig.class,
          AnnotationIntrospector.class,
          Boolean.TYPE,
          PropertyName.class);

      return constructor.newInstance(
          config,
          annotationIntrospector,
          forSerialization,
          new PropertyName(beanProperty.getName()));
    } catch (Exception e) {
      throw new InstantiationError(""Unable to create an instance of POJOPropertyBuilder"");
    }
  }"
"public void update(long a0, long a1, long a2, long a3) {
    if (done) {
      throw new IllegalStateException(""Can compute a hash only once per instance"");
    }
    v1[0] += mul0[0] + a0;
    v1[1] += mul0[1] + a1;
    v1[2] += mul0[2] + a2;
    v1[3] += mul0[3] + a3;
    for (int i = 0; i < 4; ++i) {
      mul0[i] ^= (v1[i] & 0xffffffffL) * (v0[i] >>> 32);
      v0[i] += mul1[i];
      mul1[i] ^= (v0[i] & 0xffffffffL) * (v1[i] >>> 32);
    }
    v0[0] += zipperMerge0(v1[1], v1[0]);
    v0[1] += zipperMerge1(v1[1], v1[0]);
    v0[2] += zipperMerge0(v1[3], v1[2]);
    v0[3] += zipperMerge1(v1[3], v1[2]);
    v1[0] += zipperMerge0(v0[1], v0[0]);
    v1[1] += zipperMerge1(v0[1], v0[0]);
    v1[2] += zipperMerge0(v0[3], v0[2]);
    v1[3] += zipperMerge1(v0[3], v0[2]);
  }"
"private static boolean multiplyAndSubtractUnsignedMultiPrecision(int[] left, int leftOffset, int[] right, int length, int multiplier)
    {
        long unsignedMultiplier = multiplier & LONG_MASK;
        int leftIndex = leftOffset - length;
        long multiplyAccumulator = 0;
        long subtractAccumulator = INT_BASE;
        for (int rightIndex = 0; rightIndex < length; rightIndex++, leftIndex++) {
            multiplyAccumulator = (right[rightIndex] & LONG_MASK) * unsignedMultiplier + multiplyAccumulator;
            subtractAccumulator = (subtractAccumulator + (left[leftIndex] & LONG_MASK)) - (lowInt(multiplyAccumulator) & LONG_MASK);
            multiplyAccumulator = (multiplyAccumulator >>> 32);
            left[leftIndex] = lowInt(subtractAccumulator);
            subtractAccumulator = (subtractAccumulator >>> 32) + INT_BASE - 1;
        }
        subtractAccumulator += (left[leftIndex] & LONG_MASK) - multiplyAccumulator;
        left[leftIndex] = lowInt(subtractAccumulator);
        return highInt(subtractAccumulator) == 0;
    }"
"protected void onFatalError(Throwable t) {
		try {
			log.error(""Fatal error occurred in ResourceManager."", t);
		} catch (Throwable ignored) {}

		// The fatal error handler implementation should make sure that this call is non-blocking
		fatalErrorHandler.onFatalError(t);
	}"
"public static byte[] copyToByteArray(InputStream in) throws IOException {
        ByteArrayOutputStream out = new ByteArrayOutputStream(BUFFER_SIZE);
        copy(in, out);
        return out.toByteArray();
    }"
"protected URL configureURLForProtectedAccess(URL url, OAuthConsumerToken requestToken, ProtectedResourceDetails details, String httpMethod, Map<String, String> additionalParameters) {
    String file;
    if (!""POST"".equalsIgnoreCase(httpMethod) && !""PUT"".equalsIgnoreCase(httpMethod) && !details.isAcceptsAuthorizationHeader()) {
      StringBuilder fileb = new StringBuilder(url.getPath());
      String queryString = getOAuthQueryString(details, requestToken, url, httpMethod, additionalParameters);
      fileb.append('?').append(queryString);
      file = fileb.toString();
    }
    else {
      file = url.getFile();
    }

    try {
      if (""http"".equalsIgnoreCase(url.getProtocol())) {
        URLStreamHandler streamHandler = getStreamHandlerFactory().getHttpStreamHandler(details, requestToken, this, httpMethod, additionalParameters);
        return new URL(url.getProtocol(), url.getHost(), url.getPort(), file, streamHandler);
      }
      else if (""https"".equalsIgnoreCase(url.getProtocol())) {
        URLStreamHandler streamHandler = getStreamHandlerFactory().getHttpsStreamHandler(details, requestToken, this, httpMethod, additionalParameters);
        return new URL(url.getProtocol(), url.getHost(), url.getPort(), file, streamHandler);
      }
      else {
        throw new OAuthRequestFailedException(""Unsupported OAuth protocol: "" + url.getProtocol());
      }
    }
    catch (MalformedURLException e) {
      throw new IllegalStateException(e);
    }
  }"
"public static MultiValueMap asMultiValueMap(final String key1, final Object value1, final String key2, final Object value2) {
        val wrap = (Map) wrap(key1, wrapList(value1), key2, wrapList(value2));
        return org.springframework.util.CollectionUtils.toMultiValueMap(wrap);
    }"
"public static boolean isIPv4Host(String host) {
        return StringUtils.isNotBlank(host)
            && IPV4_PATTERN.matcher(host).matches();
    }"
"@Override
    public SameDiff importGraph(GRAPH_TYPE tfGraph) {
        return importGraph(tfGraph, Collections.<String, OpImportOverride<GRAPH_TYPE,NODE_TYPE,ATTR_TYPE>>emptyMap(), null);
    }"
"public static String removeUTF8BOM(String line)
    {
        if (line != null && line.startsWith(""\uFEFF"")) // UTF-8 byte order mark (EF BB BF)
        {
            line = line.substring(1);
        }
        return line;
    }"
"public static <E> RingBuffer<E> createMultiProducer(EventFactory<E> factory, int bufferSize)
    {
        return createMultiProducer(factory, bufferSize, new BlockingWaitStrategy());
    }"
"public void info(UserFeedbackEvent.Stage stage, String message) {
    Log.info(stage+"": ""+message);
    addEvent(new UserFeedbackEvent(autoML, UserFeedbackEvent.Level.Info, stage, message));
  }"
"protected final void putInt32(long i32) {
        ensureCapacity(position + 4);

        byte[] buf = buffer;
        buf[position++] = (byte) (i32 & 0xff);
        buf[position++] = (byte) (i32 >>> 8);
        buf[position++] = (byte) (i32 >>> 16);
        buf[position++] = (byte) (i32 >>> 24);
    }"
"private static byte[] base64Decode(String value) {
    if (value == null) {
      return null;
    }
    
    try {
      return Base64.decodeBase64(value.getBytes(""UTF-8""));
    }
    catch (UnsupportedEncodingException e) {
      throw new RuntimeException(e);
    }
  }"
"@Override
    public InputType getOutputType(InputType... inputType) throws InvalidKerasConfigurationException {
        if (inputType.length > 1)
            throw new InvalidKerasConfigurationException(
                            ""Keras ZeroPadding layer accepts only one input (received "" + inputType.length + "")"");
        return this.getZeroPadding2DLayer().getOutputType(-1, inputType[0]);
    }"
"public static Map<String, ? extends CacheConfig> fromJSON(Reader reader) throws IOException {
        return new CacheConfigSupport().fromJSON(reader);
    }"
"protected String buildAndEncodeConsentAttributes(final Map<String, List<Object>> attributes) {
        try {
            val json = MAPPER.writer(new MinimalPrettyPrinter()).writeValueAsString(attributes);
            val base64 = EncodingUtils.encodeBase64(json);
            return this.consentCipherExecutor.encode(base64);
        } catch (final Exception e) {
            throw new IllegalArgumentException(""Could not serialize attributes for consent decision"");
        }
    }"
"private static BitSet validCookieAttributeValueOctets() {
        BitSet bits = new BitSet();
        for (int i = 32; i < 127; i++) {
            bits.set(i);
        }
        bits.set(';', false);
        return bits;
    }"
"public void add(Option option) throws RequiredParametersException {
		if (!this.data.containsKey(option.getName())) {
			this.data.put(option.getName(), option);
		} else {
			throw new RequiredParametersException(""Option with key "" + option.getName() + "" already exists."");
		}
	}"
"public static Tag uri(ServerWebExchange exchange) {
		PathPattern pathPattern = exchange
				.getAttribute(HandlerMapping.BEST_MATCHING_PATTERN_ATTRIBUTE);
		if (pathPattern != null) {
			return Tag.of(""uri"", pathPattern.getPatternString());
		}
		HttpStatus status = exchange.getResponse().getStatusCode();
		if (status != null) {
			if (status.is3xxRedirection()) {
				return URI_REDIRECTION;
			}
			if (status == HttpStatus.NOT_FOUND) {
				return URI_NOT_FOUND;
			}
		}
		String path = getPathInfo(exchange);
		if (path.isEmpty()) {
			return URI_ROOT;
		}
		return URI_UNKNOWN;
	}"
"public static CellStyle cloneCellStyle(Workbook workbook, CellStyle cellStyle) {
		final CellStyle newCellStyle = workbook.createCellStyle();
		newCellStyle.cloneStyleFrom(cellStyle);
		return newCellStyle;
	}"
"@Override
    public double inverseCumulativeProbability(final double p) throws OutOfRangeException {
        if (p < 0.0 || p > 1.0) {
            throw new OutOfRangeException(p, 0, 1);
        }
        if (means != null)
            throw new IllegalStateException(""Unable to sample from more than one mean"");

        return mean + standardDeviation * SQRT2 * Erf.erfInv(2 * p - 1);
    }"
"private void hideTab(Component component) {
		if (hiddenTabs.contains(component)) {
			return;
		}
		hiddenTabs.add(component);

		int index = indexOfComponent(component);
		if (index != -1) {
			super.removeTabAt(index);
		}
		
		handleHiddenTabListTab();
	}"
"public static <T> DataSet<T> sampleWithSize(
		DataSet <T> input,
		final boolean withReplacement,
		final int numSamples) {

		return sampleWithSize(input, withReplacement, numSamples, Utils.RNG.nextLong());
	}"
"public static String STOREtoString() {
    int[] cnts = new int[1];
    Object[] kvs = H2O.STORE.raw_array();
    // Start the walk at slot 2, because slots 0,1 hold meta-data
    for( int i=2; i<kvs.length; i += 2 ) {
      // In the raw backing array, Keys and Values alternate in slots
      Object ov = kvs[i+1];
      if( !(ov instanceof Value) ) continue; // Ignore tombstones and Primes and null's
      Value val = (Value)ov;
      if( val.isNull() ) { Value.STORE_get(val._key); continue; } // Another variant of NULL
      int t = val.type();
      while( t >= cnts.length ) cnts = Arrays.copyOf(cnts,cnts.length<<1);
      cnts[t]++;
    }
    StringBuilder sb = new StringBuilder();
    for( int t=0; t<cnts.length; t++ )
      if( cnts[t] != 0 )
        sb.append(String.format(""-%30s %5d\n"",TypeMap.CLAZZES[t],cnts[t]));
    return sb.toString();
  }"
"public static Monitor createCompoundJvmMonitor(Map<String, String[]> dimensions)
  {
    return createCompoundJvmMonitor(dimensions, FeedDefiningMonitor.DEFAULT_METRICS_FEED);
  }"
"private static Node getXmlSignatureInsertLocation(final Element elem) {
        val nodeListExtensions = elem.getElementsByTagNameNS(SAMLConstants.SAML20P_NS, ""Extensions"");
        if (nodeListExtensions.getLength() != 0) {
            return nodeListExtensions.item(nodeListExtensions.getLength() - 1);
        }
        val nodeListStatus = elem.getElementsByTagNameNS(SAMLConstants.SAML20P_NS, ""Status"");
        return nodeListStatus.item(nodeListStatus.getLength() - 1);
    }"
"public static String read(Reader reader) throws IORuntimeException {
		final StringBuilder builder = StrUtil.builder();
		final CharBuffer buffer = CharBuffer.allocate(DEFAULT_BUFFER_SIZE);
		try {
			while (-1 != reader.read(buffer)) {
				builder.append(buffer.flip().toString());
			}
		} catch (IOException e) {
			throw new IORuntimeException(e);
		}
		return builder.toString();
	}"
"public static Matrix toMatrix(INDArray arr) {
        if (!arr.isMatrix()) {
            throw new IllegalArgumentException(""passed in array must be a matrix"");
        }

        // if arr is a view - we have to dup anyway
        if (arr.isView()) {
            return Matrices.dense(arr.rows(), arr.columns(), arr.dup('f').data().asDouble());
        } else // if not a view - we must ensure data is F ordered
            return Matrices.dense(arr.rows(), arr.columns(),
                            arr.ordering() == 'f' ? arr.data().asDouble() : arr.dup('f').data().asDouble());
    }"
"private static String normalisedScheme(char[] scheme) {
        if (scheme == null) {
            return """";
        }
        return new String(scheme).toLowerCase(Locale.ROOT);
    }"
"public static long betweenYear(Date beginDate, Date endDate, boolean isReset) {
		return new DateBetween(beginDate, endDate).betweenYear(isReset);
	}"
"public static RestartStrategy resolve(
			RestartStrategies.RestartStrategyConfiguration clientConfiguration,
			RestartStrategyFactory serverStrategyFactory,
			boolean isCheckpointingEnabled) {

		final RestartStrategy clientSideRestartStrategy =
			RestartStrategyFactory.createRestartStrategy(clientConfiguration);

		if (clientSideRestartStrategy != null) {
			return clientSideRestartStrategy;
		} else {
			if (serverStrategyFactory instanceof NoOrFixedIfCheckpointingEnabledRestartStrategyFactory) {
				return ((NoOrFixedIfCheckpointingEnabledRestartStrategyFactory) serverStrategyFactory)
					.createRestartStrategy(isCheckpointingEnabled);
			} else {
				return serverStrategyFactory.createRestartStrategy();
			}
		}
	}"
"@Override
    public void applyUpdate(StepFunction function, INDArray params, INDArray grad, boolean isFinalStep) {

        try {
            updatesLock.readLock().lock();

            firstOne.compareAndSet(-1L, Thread.currentThread().getId());

            if (hasSomething.get())
                function.step(params, updates);

            barrier.await();
            if (firstOne.get() == Thread.currentThread().getId()) {
                // one thread just nullifies this array
                updates.assign(0.0);
                hasSomething.set(false);

                firstOne.set(-1L);
            }

            updatesLock.readLock().unlock();
            barrier.await();
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            throw new RuntimeException(e);
        } catch (BrokenBarrierException e) {
            throw new RuntimeException(e);
        }
    }"
"boolean read_lock() {
    while( true ) {     // Repeat, in case racing GETs are bumping the counter
      int old = _rwlock.get();
      if( old == -1 ) return false; // Write-locked; no new replications.  Read fails to read *this* value
      assert old >= 0;              // Not negative
      if( RW_CAS(old,old+1,""rlock+"") ) return true;
    }
  }"
"public static void put(String key, Object value) {
		contextMap.get().put(key, value);
	}"
"public Collection<String> wordsNearestSum(Collection<String> positive, Collection<String> negative, int top) {
        return modelUtils.wordsNearestSum(positive, negative, top);
    }"
"@Restricted(NoExternalUse.class)
    public @Nonnull List<VirtualFile> listOnlyDescendants() throws IOException {
        VirtualFile[] children = list();
        List<VirtualFile> result = new ArrayList<>();
        for (VirtualFile child : children) {
            if (child.isDescendant("""")) {
                result.add(child);
            }
        }        
        return result;
    }"
"private static long getNetworkAddressCacheTtlNanos(boolean isAndroid) {
    if (isAndroid) {
      // on Android, ignore dns cache.
      return 0;
    }

    String cacheTtlPropertyValue = System.getProperty(NETWORKADDRESS_CACHE_TTL_PROPERTY);
    long cacheTtl = DEFAULT_NETWORK_CACHE_TTL_SECONDS;
    if (cacheTtlPropertyValue != null) {
      try {
        cacheTtl = Long.parseLong(cacheTtlPropertyValue);
      } catch (NumberFormatException e) {
        logger.log(
            Level.WARNING,
            ""Property({0}) valid is not valid number format({1}), fall back to default({2})"",
            new Object[] {NETWORKADDRESS_CACHE_TTL_PROPERTY, cacheTtlPropertyValue, cacheTtl});
      }
    }
    return cacheTtl > 0 ? TimeUnit.SECONDS.toNanos(cacheTtl) : cacheTtl;
  }"
"protected Map<String, List<Object>> authorizeReleaseOfAllowedAttributes(final Principal principal,
                                                                            final Map<String, List<Object>> attrs,
                                                                            final RegisteredService registeredService,
                                                                            final Service selectedService) {
        val resolvedAttributes = new TreeMap<String, List<Object>>(String.CASE_INSENSITIVE_ORDER);
        resolvedAttributes.putAll(attrs);
        val attributesToRelease = new HashMap<String, List<Object>>();
        /*
         * Map each entry in the allowed list into an array first
         * by the original key, value and the original entry itself.
         * Then process the array to populate the map for allowed attributes
         */
        getAllowedAttributes().forEach((attributeName, value) -> {
            val mappedAttributes = CollectionUtils.wrap(value);
            LOGGER.trace(""Attempting to map allowed attribute name [{}]"", attributeName);
            val attributeValue = resolvedAttributes.get(attributeName);
            mappedAttributes.forEach(mapped -> {
                val mappedAttributeName = mapped.toString();
                LOGGER.debug(""Mapping attribute [{}] to [{}] with value [{}]"", attributeName, mappedAttributeName, attributeValue);
                mapSingleAttributeDefinition(attributeName, mappedAttributeName,
                    attributeValue, resolvedAttributes, attributesToRelease);
            });
        });
        return attributesToRelease;
    }"
"public String wherePKColumns(Class<?> entityClass, boolean useVersion) {
        StringBuilder sql = new StringBuilder();
        sql.append(""<where>"");
        //获取全部列
        Set<EntityColumn> columnSet = EntityHelper.getPKColumns(entityClass);
        //当某个列有主键策略时，不需要考虑他的属性是否为空，因为如果为空，一定会根据主键策略给他生成一个值
        for (EntityColumn column : columnSet) {
            sql.append("" AND "" + column.getColumnEqualsHolder(NEWER));
        }
        if (useVersion) {
            sql.append(whereVersion(entityClass));
        }
        sql.append(""</where>"");
        return sql.toString();
    }"
"protected static void validateNumerical(String opName, SDVariable v1, SDVariable v2) {
        if (v1.dataType() == DataType.BOOL || v1.dataType() == DataType.UTF8 || v2.dataType() == DataType.BOOL || v2.dataType() == DataType.UTF8)
            throw new IllegalStateException(""Cannot perform operation \"""" + opName + ""\"" on variables  \"""" + v1.getVarName() + ""\"" and \"""" +
                    v2.getVarName() + ""\"" if one or both variables are non-numerical: "" + v1.dataType() + "" and "" + v2.dataType());
    }"
"public void releaseAll(Object owner) {
		if (owner == null) {
			return;
		}

		// -------------------- BEGIN CRITICAL SECTION -------------------
		synchronized (lock) {
			if (isShutDown) {
				throw new IllegalStateException(""Memory manager has been shut down."");
			}

			// get all segments
			final Set<MemorySegment> segments = allocatedSegments.remove(owner);

			// all segments may have been freed previously individually
			if (segments == null || segments.isEmpty()) {
				return;
			}

			// free each segment
			if (isPreAllocated) {
				for (MemorySegment seg : segments) {
					memoryPool.returnSegmentToPool(seg);
				}
			}
			else {
				for (MemorySegment seg : segments) {
					seg.free();
				}
				numNonAllocatedPages += segments.size();
			}

			segments.clear();
		}
		// -------------------- END CRITICAL SECTION -------------------
	}"
"public static long download(String url, OutputStream out, boolean isCloseOut) {
		return download(url, out, isCloseOut, null);
	}"
"public HttpMessage handleApiRequest (HttpRequestHeader requestHeader, HttpInputStream httpIn, 
			HttpOutputStream httpOut) throws IOException {
		return this.handleApiRequest(requestHeader, httpIn, httpOut, false);
	}"
"public static AltsServerBuilder forPort(int port) {
    NettyServerBuilder nettyDelegate = NettyServerBuilder.forAddress(new InetSocketAddress(port));
    return new AltsServerBuilder(nettyDelegate);
  }"
"public static Set<String> cacheNames(Config config) {
    return config.hasPath(""caffeine.jcache"")
        ? Collections.unmodifiableSet(config.getObject(""caffeine.jcache"").keySet())
        : Collections.emptySet();
  }"
"public static TimeSource getInstance(String className) {
        try {
            Class<?> c = Class.forName(className);
            Method m = c.getMethod(""getInstance"");
            return (TimeSource) m.invoke(null);
        } catch (Exception e) {
            throw new RuntimeException(""Error getting TimeSource instance for class \"""" + className + ""\"""", e);
        }
    }"
"public static DataSourceMetaData newInstance(final DatabaseType databaseType, final String url) {
        switch (databaseType) {
            case H2:
                return new H2DataSourceMetaData(url);
            case MySQL:
                return new MySQLDataSourceMetaData(url);
            case Oracle:
                return new OracleDataSourceMetaData(url);
            case PostgreSQL:
                return new PostgreSQLDataSourceMetaData(url);
            case SQLServer:
                return new SQLServerDataSourceMetaData(url);
            default:
                throw new UnsupportedOperationException(String.format(""Cannot support database [%s]."", databaseType));
        }
    }"
"@View(name = ""by_issued_date_time"", map = ""function(doc) { if(doc.token && doc.userId) { emit(doc.issuedDateTime, doc) } }"")
    public Collection<CouchDbGoogleAuthenticatorToken> findByIssuedDateTimeBefore(final LocalDateTime localDateTime) {
        val view = createQuery(""by_issued_date_time"").endKey(localDateTime);
        return db.queryView(view, CouchDbGoogleAuthenticatorToken.class);
    }"
"public static String executeGroovy(String script, @Nonnull VirtualChannel channel) throws IOException, InterruptedException {
        return channel.call(new Script(script));
    }"
"public static double entropy(double[] vector) {
        if (vector == null || vector.length < 1)
            return 0;
        else {
            double ret = 0;
            for (double d : vector)
                ret += d * Math.log(d);
            return ret;

        }
    }//end entropy

    /**
     * This returns the kronecker delta of two doubles.
     * @param i the first number to compare
     * @param j the second number to compare
     * @return 1 if they are equal, 0 otherwise
     */
    public static int kroneckerDelta(double i, double j) {
        return (i == j) ? 1 : 0;
    }

    /**
     * This calculates the adjusted r^2 including degrees of freedom.
     * Also known as calculating ""strength"" of a regression
     * @param rSquared the r squared value to calculate
     * @param numRegressors number of variables
     * @param numDataPoints size of the data applyTransformToDestination
     * @return an adjusted r^2 for degrees of freedom
     */
    public static double adjustedrSquared(double rSquared, int numRegressors, int numDataPoints) {
        double divide = (numDataPoints - 1.0) / (numDataPoints - numRegressors - 1.0);
        double rSquaredDiff = 1 - rSquared;
        return 1 - (rSquaredDiff * divide);
    }


    public static double[] normalizeToOne(double[] doubles) {
        normalize(doubles, sum(doubles));
        return doubles;
    }

    public static double min(double[] doubles) {
        double ret = doubles[0];
        for (double d : doubles)
            if (d < ret)
                ret = d;
        return ret;
    }

    public static double max(double[] doubles) {
        double ret = doubles[0];
        for (double d : doubles)
            if (d > ret)
                ret = d;
        return ret;
    }

    /**
     * Normalizes the doubles in the array using the given value.
     *
     * @param doubles the array of double
     * @param sum the value by which the doubles are to be normalized
     * @exception IllegalArgumentException if sum is zero or NaN
     */
    public static void normalize(double[] doubles, double sum) {

        if (Double.isNaN(sum)) {
            throw new IllegalArgumentException(""Can't normalize array. Sum is NaN."");
        }
        if (sum == 0) {
            // Maybe this should just be a return.
            throw new IllegalArgumentException(""Can't normalize array. Sum is zero."");
        }
        for (int i = 0; i < doubles.length; i++) {
            doubles[i] /= sum;
        }
    }//end normalize

    /**
     * Converts an array containing the natural logarithms of
     * probabilities stored in a vector back into probabilities.
     * The probabilities are assumed to sum to one.
     *
     * @param a an array holding the natural logarithms of the probabilities
     * @return the converted array
     */
    public static double[] logs2probs(double[] a) {

        double max = a[maxIndex(a)];
        double sum = 0.0;

        double[] result = new double[a.length];
        for (int i = 0; i < a.length; i++) {
            result[i] = Math.exp(a[i] - max);
            sum += result[i];
        }

        normalize(result, sum);

        return result;
    }//end logs2probs

    /**
     * This returns the entropy for a given vector of probabilities.
     * @param probabilities the probabilities to getFromOrigin the entropy for
     * @return the entropy of the given probabilities.
     */
    public static double information(double[] probabilities) {
        double total = 0.0;
        for (double d : probabilities) {
            total += (-1.0 * log2(d) * d);
        }
        return total;
    }//end information

    /**
     *
     *
     * Returns index of maximum element in a given
     * array of doubles. First maximum is returned.
     *
     * @param doubles the array of doubles
     * @return the index of the maximum element
     */
    public static /*@pure@*/ int maxIndex(double[] doubles) {

        double maximum = 0;
        int maxIndex = 0;

        for (int i = 0; i < doubles.length; i++) {
            if ((i == 0) || (doubles[i] > maximum)) {
                maxIndex = i;
                maximum = doubles[i];
            }
        }

        return maxIndex;
    }//end maxIndex

    /**
     * This will return the factorial of the given number n.
     * @param n the number to getFromOrigin the factorial for
     * @return the factorial for this number
     */
    public static double factorial(double n) {
        if (n == 1 || n == 0)
            return 1;
        for (double i = n; i > 0; i--, n *= (i > 0 ? i : 1)) {
        }
        return n;
    }//end factorial



    /** The small deviation allowed in double comparisons. */
    public static double SMALL = 1e-6;

    /**
     * Returns the log-odds for a given probability.
     *
     * @param prob the probability
     *
     * @return the log-odds after the probability has been mapped to
     * [Utils.SMALL, 1-Utils.SMALL]
     */
    public static /*@pure@*/ double probToLogOdds(double prob) {

        if (gr(prob, 1) || (sm(prob, 0))) {
            throw new IllegalArgumentException(""probToLogOdds: probability must "" + ""be in [0,1] "" + prob);
        }
        double p = SMALL + (1.0 - 2 * SMALL) * prob;
        return Math.log(p / (1 - p));
    }

    /**
     * Rounds a double to the next nearest integer value. The JDK version
     * of it doesn't work properly.
     *
     * @param value the double value
     * @return the resulting integer value
     */
    public static /*@pure@*/ int round(double value) {

        return value > 0 ? (int) (value + 0.5) : -(int) (Math.abs(value) + 0.5);
    }//end round

    /**
     * This returns the permutation of n choose r.
     * @param n the n to choose
     * @param r the number of elements to choose
     * @return the permutation of these numbers
     */
    public static double permutation(double n, double r) {
        double nFac = MathUtils.factorial(n);
        double nMinusRFac = MathUtils.factorial((n - r));
        return nFac / nMinusRFac;
    }//end permutation


    /**
     * This returns the combination of n choose r
     * @param n the number of elements overall
     * @param r the number of elements to choose
     * @return the amount of possible combinations for this applyTransformToDestination of elements
     */
    public static double combination(double n, double r) {
        double nFac = MathUtils.factorial(n);
        double rFac = MathUtils.factorial(r);
        double nMinusRFac = MathUtils.factorial((n - r));

        return nFac / (rFac * nMinusRFac);
    }//end combination


    /**
     * sqrt(a^2 + b^2) without under/overflow.
     */
    public static double hypotenuse(double a, double b) {
        double r;
        if (Math.abs(a) > Math.abs(b)) {
            r = b / a;
            r = Math.abs(a) * Math.sqrt(1 + r * r);
        } else if (b != 0) {
            r = a / b;
            r = Math.abs(b) * Math.sqrt(1 + r * r);
        } else {
            r = 0.0;
        }
        return r;
    }//end hypotenuse

    /**
     * Rounds a double to the next nearest integer value in a probabilistic
     * fashion (e.g. 0.8 has a 20% chance of being rounded down to 0 and a
     * 80% chance of being rounded up to 1). In the limit, the average of
     * the rounded numbers generated by this procedure should converge to
     * the original double.
     *
     * @param value the double value
     * @param rand the random number generator
     * @return the resulting integer value
     */
    public static int probRound(double value, Random rand) {

        if (value >= 0) {
            double lower = Math.floor(value);
            double prob = value - lower;
            if (rand.nextDouble() < prob) {
                return (int) lower + 1;
            } else {
                return (int) lower;
            }
        } else {
            double lower = Math.floor(Math.abs(value));
            double prob = Math.abs(value) - lower;
            if (rand.nextDouble() < prob) {
                return -((int) lower + 1);
            } else {
                return -(int) lower;
            }
        }
    }//end probRound

    /**
     * Rounds a double to the given number of decimal places.
     *
     * @param value the double value
     * @param afterDecimalPoint the number of digits after the decimal point
     * @return the double rounded to the given precision
     */
    public static /*@pure@*/ double roundDouble(double value, int afterDecimalPoint) {

        double mask = Math.pow(10.0, (double) afterDecimalPoint);

        return (double) (Math.round(value * mask)) / mask;
    }//end roundDouble



    /**
     * Rounds a double to the given number of decimal places.
     *
     * @param value the double value
     * @param afterDecimalPoint the number of digits after the decimal point
     * @return the double rounded to the given precision
     */
    public static /*@pure@*/ float roundFloat(float value, int afterDecimalPoint) {

        float mask = (float) Math.pow(10, (float) afterDecimalPoint);

        return (float) (Math.round(value * mask)) / mask;
    }//end roundDouble

    /**
     * This will return the bernoulli trial for the given event.
     * A bernoulli trial is a mechanism for detecting the probability
     * of a given event occurring k times in n independent trials
     * @param n the number of trials
     * @param k the number of times the target event occurs
     * @param successProb the probability of the event happening
     * @return the probability of the given event occurring k times.
     */
    public static double bernoullis(double n, double k, double successProb) {

        double combo = MathUtils.combination(n, k);
        double q = 1 - successProb;
        return combo * Math.pow(successProb, k) * Math.pow(q, n - k);
    }//end bernoullis

    /**
     * Tests if a is smaller than b.
     *
     * @param a a double
     * @param b a double
     */
    public static /*@pure@*/ boolean sm(double a, double b) {

        return (b - a > SMALL);
    }

    /**
     * Tests if a is greater than b.
     *
     * @param a a double
     * @param b a double
     */
    public static /*@pure@*/ boolean gr(double a, double b) {

        return (a - b > SMALL);
    }

    /**
     * This will take a given string and separator and convert it to an equivalent
     * double array.
     * @param data the data to separate
     * @param separator the separator to use
     * @return the new double array based on the given data
     */
    public static double[] fromString(String data, String separator) {
        String[] split = data.split(separator);
        double[] ret = new double[split.length];
        for (int i = 0; i < split.length; i++) {
            ret[i] = Double.parseDouble(split[i]);
        }
        return ret;
    }//end fromString

    /**
     * Computes the mean for an array of doubles.
     *
     * @param vector the array
     * @return the mean
     */
    public static /*@pure@*/ double mean(double[] vector) {

        double sum = 0;

        if (vector.length == 0) {
            return 0;
        }
        for (int i = 0; i < vector.length; i++) {
            sum += vector[i];
        }
        return sum / (double) vector.length;
    }//end mean

    /**
     * This will return the cholesky decomposition of
     * the given matrix
     * @param m the matrix to convert
     * @return the cholesky decomposition of the given
     * matrix.
     * See:
     * http://en.wikipedia.org/wiki/Cholesky_decomposition
     * @throws NonSquareMatrixException
     */
    public CholeskyDecomposition choleskyFromMatrix(RealMatrix m) throws Exception {
        return new CholeskyDecomposition(m);
    }//end choleskyFromMatrix



    /**
     * This will convert the given binary string to a decimal based
     * integer
     * @param binary the binary string to convert
     * @return an equivalent base 10 number
     */
    public static int toDecimal(String binary) {
        long num = Long.parseLong(binary);
        long rem;
        /* Use the remainder method to ensure validity */
        while (num > 0) {
            rem = num % 10;
            num = num / 10;
            if (rem != 0 && rem != 1) {
                System.out.println(""This is not a binary number."");
                System.out.println(""Please try once again."");
                return -1;
            }
        }
        return Integer.parseInt(binary, 2);
    }//end toDecimal


    /**
     * This will translate a vector in to an equivalent integer
     * @param vector the vector to translate
     * @return a z value such that the value is the interleaved lsd to msd for each
     * double in the vector
     */
    public static int distanceFinderZValue(double[] vector) {
        StringBuilder binaryBuffer = new StringBuilder();
        List<String> binaryReps = new ArrayList<>(vector.length);
        for (int i = 0; i < vector.length; i++) {
            double d = vector[i];
            int j = (int) d;
            String binary = Integer.toBinaryString(j);
            binaryReps.add(binary);
        }
        //append from left to right, the least to the most significant bit
        //till all strings are empty
        while (!binaryReps.isEmpty()) {
            for (int j = 0; j < binaryReps.size(); j++) {
                String curr = binaryReps.get(j);
                if (!curr.isEmpty()) {
                    char first = curr.charAt(0);
                    binaryBuffer.append(first);
                    curr = curr.substring(1);
                    binaryReps.set(j, curr);
                } else
                    binaryReps.remove(j);
            }
        }
        return Integer.parseInt(binaryBuffer.toString(), 2);

    }//end distanceFinderZValue

    /**
     * This returns the distance of two vectors
     * sum(i=1,n)   (q_i - p_i)^2
     * @param p the first vector
     * @param q the second vector
     * @return the distance between two vectors
     */
    public static double euclideanDistance(double[] p, double[] q) {

        double ret = 0;
        for (int i = 0; i < p.length; i++) {
            double diff = (q[i] - p[i]);
            double sq = Math.pow(diff, 2);
            ret += sq;
        }
        return ret;

    }//end euclideanDistance

    /**
     * This returns the distance of two vectors
     * sum(i=1,n)   (q_i - p_i)^2
     * @param p the first vector
     * @param q the second vector
     * @return the distance between two vectors
     */
    public static double euclideanDistance(float[] p, float[] q) {

        double ret = 0;
        for (int i = 0; i < p.length; i++) {
            double diff = (q[i] - p[i]);
            double sq = Math.pow(diff, 2);
            ret += sq;
        }
        return ret;

    }//end euclideanDistance

    /**
     * This will generate a series of uniformally distributed
     * numbers between l times
     * @param l the number of numbers to generate
     * @return l uniformally generated numbers
     */
    public static double[] generateUniform(int l) {
        double[] ret = new double[l];
        Random rgen = new Random();
        for (int i = 0; i < l; i++) {
            ret[i] = rgen.nextDouble();
        }
        return ret;
    }//end generateUniform


    /**
     * This will calculate the Manhattan distance between two sets of points.
     * The Manhattan distance is equivalent to:
     * 1_sum_n |p_i - q_i|
     * @param p the first point vector
     * @param q the second point vector
     * @return the Manhattan distance between two object
     */
    public static double manhattanDistance(double[] p, double[] q) {

        double ret = 0;
        for (int i = 0; i < p.length; i++) {
            double difference = p[i] - q[i];
            ret += Math.abs(difference);
        }
        return ret;
    }//end manhattanDistance



    public static double[] sampleDoublesInInterval(double[][] doubles, int l) {
        double[] sample = new double[l];
        for (int i = 0; i < l; i++) {
            int rand1 = randomNumberBetween(0, doubles.length - 1);
            int rand2 = randomNumberBetween(0, doubles[i].length);
            sample[i] = doubles[rand1][rand2];
        }

        return sample;
    }

    /**
     * Generates a random integer between the specified numbers
     * @param begin the begin of the interval
     * @param end the end of the interval
     * @return an int between begin and end
     */
    public static int randomNumberBetween(double begin, double end) {
        if (begin > end)
            throw new IllegalArgumentException(""Begin must not be less than end"");
        return (int) begin + (int) (Math.random() * ((end - begin) + 1));
    }

    /**
     * Generates a random integer between the specified numbers
     * @param begin the begin of the interval
     * @param end the end of the interval
     * @return an int between begin and end
     */
    public static int randomNumberBetween(double begin, double end, RandomGenerator rng) {
        if (begin > end)
            throw new IllegalArgumentException(""Begin must not be less than end"");
        return (int) begin + (int) (rng.nextDouble() * ((end - begin) + 1));
    }

    /**
     * Generates a random integer between the specified numbers
     * @param begin the begin of the interval
     * @param end the end of the interval
     * @return an int between begin and end
     */
    public static int randomNumberBetween(double begin, double end, org.nd4j.linalg.api.rng.Random rng) {
        if (begin > end)
            throw new IllegalArgumentException(""Begin must not be less than end"");
        return (int) begin + (int) (rng.nextDouble() * ((end - begin) + 1));
    }

    /**
     *
     * @param begin
     * @param end
     * @return
     */
    public static float randomFloatBetween(float begin, float end) {
        float rand = (float) Math.random();
        return begin + (rand * ((end - begin)));
    }

    public static double randomDoubleBetween(double begin, double end) {
        return begin + (Math.random() * ((end - begin)));
    }

    public static void shuffleArray(int[] array, long rngSeed) {
        shuffleArray(array, new Random(rngSeed));
    }

    public static void shuffleArray(int[] array, Random rng) {
        //https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle#The_modern_algorithm
        for (int i = array.length - 1; i > 0; i--) {
            int j = rng.nextInt(i + 1);
            int temp = array[j];
            array[j] = array[i];
            array[i] = temp;
        }
    }
}"
"public static void fireCompleted(Run r, @Nonnull TaskListener listener) {
        for (RunListener l : all()) {
            if(l.targetType.isInstance(r))
                try {
                    l.onCompleted(r,listener);
                } catch (Throwable e) {
                    report(e);
                }
        }
    }"
"public List<EventColumn> getUpdatedKeys() {
        List<EventColumn> columns = new ArrayList<EventColumn>();
        for (EventColumn column : this.keys) {
            if (column.isUpdate()) {
                columns.add(column);
            }
        }

        return columns;
    }"
"public static boolean checkName(String nameSpec, String identifier, LombokNode<?, ?, ?> errorNode) {
		if (identifier.isEmpty()) {
			errorNode.addError(nameSpec + "" cannot be the empty string."");
			return false;
		}
		
		if (!JavaIdentifiers.isValidJavaIdentifier(identifier)) {
			errorNode.addError(nameSpec + "" must be a valid java identifier."");
			return false;
		}
		
		return true;
	}"
"public void setHttpChannelHandlers(final List<ChannelHandler> httpChannelHandlers) {
        this.httpChannelHandlers = httpChannelHandlers == null ? Collections.<ChannelHandler> emptyList()
            : httpChannelHandlers;
    }"
"@Override
  public List<ExecutableFlow> getRunningFlows() {
    final ArrayList<ExecutableFlow> flows = new ArrayList<>();
    getActiveFlowHelper(flows, this.queuedFlows.getAllEntries());
    getActiveFlowHelper(flows, this.runningExecutions.get().values());
    return flows;
  }"
"public static <V> List<Object> fieldValueList(Iterator<V> iter, String fieldName) {
		final List<Object> result = new ArrayList<>();
		if (null != iter) {
			V value;
			while (iter.hasNext()) {
				value = iter.next();
				result.add(ReflectUtil.getFieldValue(value, fieldName));
			}
		}
		return result;
	}"
"public OperatorSubtaskState putSubtaskStateByOperatorID(
		@Nonnull OperatorID operatorID,
		@Nonnull OperatorSubtaskState state) {

		return subtaskStatesByOperatorID.put(operatorID, Preconditions.checkNotNull(state));
	}"
"public static boolean isSingle(Class<?> type) {
        for (Class<?> reactiveType : SINGLE_TYPES) {
            if (reactiveType.isAssignableFrom(type)) {
                return true;
            }
        }
        return false;
    }"
"public URLNormalizer sortQueryParameters() {
        // Does it have query parameters?
        if (!url.contains(""?"")) {
            return this;
        }
        // It does, so proceed
        List<String> keyValues = new ArrayList<>();
        String queryString = StringUtils.substringAfter(url, ""?"");

        // extract and remove any fragments
        String fragment = StringUtils.substringAfter(queryString, ""#"");
        if (StringUtils.isNotBlank(fragment)) {
            fragment = ""#"" + fragment;
        }
        queryString = StringUtils.substringBefore(queryString, ""#"");

        String[] params = StringUtils.split(queryString, '&');
        for (String param : params) {
            keyValues.add(param);
        }
        // sort it so that query string are in order
        Collections.sort(keyValues);

        String sortedQueryString = StringUtils.join(keyValues, '&');
        if (StringUtils.isNotBlank(sortedQueryString)) {
            url = StringUtils.substringBefore(
                    url, ""?"") + ""?"" + sortedQueryString + fragment;
        }

        return this;
    }"
"public static boolean isInternalSSLEnabled(Configuration sslConfig) {
		@SuppressWarnings(""deprecation"")
		final boolean fallbackFlag = sslConfig.getBoolean(SecurityOptions.SSL_ENABLED);
		return sslConfig.getBoolean(SecurityOptions.SSL_INTERNAL_ENABLED, fallbackFlag);
	}"
"private float getMaxScale(@NonNull Canvas canvas) {
    float maxScaleX = canvas.getWidth() / (float) composition.getBounds().width();
    float maxScaleY = canvas.getHeight() / (float) composition.getBounds().height();
    return Math.min(maxScaleX, maxScaleY);
  }"
"public Pair<F, S> argMax() {
        Double maxCount = -Double.MAX_VALUE;
        Pair<F, S> maxKey = null;
        for (Map.Entry<F, Counter<S>> entry : maps.entrySet()) {
            Counter<S> counter = entry.getValue();
            S localMax = counter.argMax();
            if (counter.getCount(localMax) > maxCount || maxKey == null) {
                maxKey = new Pair<F, S>(entry.getKey(), localMax);
                maxCount = counter.getCount(localMax);
            }
        }
        return maxKey;
    }"
"public F getInstance() {
		return getDateTimeInstance(DateFormat.SHORT, DateFormat.SHORT, TimeZone.getDefault(), Locale.getDefault());
	}"
"private boolean decodeBulkStringContent(ByteBuf in, List<Object> out) throws Exception {
        final int readableBytes = in.readableBytes();
        if (readableBytes == 0 || remainingBulkLength == 0 && readableBytes < RedisConstants.EOL_LENGTH) {
            return false;
        }

        // if this is last frame.
        if (readableBytes >= remainingBulkLength + RedisConstants.EOL_LENGTH) {
            ByteBuf content = in.readSlice(remainingBulkLength);
            readEndOfLine(in);
            // Only call retain after readEndOfLine(...) as the method may throw an exception.
            out.add(new DefaultLastBulkStringRedisContent(content.retain()));
            resetDecoder();
            return true;
        }

        // chunked write.
        int toRead = Math.min(remainingBulkLength, readableBytes);
        remainingBulkLength -= toRead;
        out.add(new DefaultBulkStringRedisContent(in.readSlice(toRead).retain()));
        return true;
    }"
"private void serializeComputationStates(Queue<ComputationState> states, DataOutputView target) throws IOException {
		target.writeInt(states.size());
		for (ComputationState computationState : states) {
			serializeSingleComputationState(computationState, target);
		}
	}"
"public Class<? extends AbstractInvokable> getInvokableClass(ClassLoader cl) {
		if (cl == null) {
			throw new NullPointerException(""The classloader must not be null."");
		}
		if (invokableClassName == null) {
			return null;
		}

		try {
			return Class.forName(invokableClassName, true, cl).asSubclass(AbstractInvokable.class);
		}
		catch (ClassNotFoundException e) {
			throw new RuntimeException(""The user-code class could not be resolved."", e);
		}
		catch (ClassCastException e) {
			throw new RuntimeException(""The user-code class is no subclass of "" + AbstractInvokable.class.getName(), e);
		}
	}"
"@Deprecated
    @JsonProperty
    public List<ClientTypeSignature> getTypeArguments()
    {
        List<ClientTypeSignature> result = new ArrayList<>();
        for (ClientTypeSignatureParameter argument : arguments) {
            switch (argument.getKind()) {
                case TYPE:
                    result.add(argument.getTypeSignature());
                    break;
                case NAMED_TYPE:
                    result.add(new ClientTypeSignature(argument.getNamedTypeSignature().getTypeSignature()));
                    break;
                default:
                    return new ArrayList<>();
            }
        }
        return result;
    }"
"protected InputStream readResource(ProtectedResourceDetails details, URL url, String httpMethod, OAuthConsumerToken token, Map<String, String> additionalParameters, Map<String, String> additionalRequestHeaders) {
    url = configureURLForProtectedAccess(url, token, details, httpMethod, additionalParameters);
    String realm = details.getAuthorizationHeaderRealm();
    boolean sendOAuthParamsInRequestBody = !details.isAcceptsAuthorizationHeader() && ((""POST"".equalsIgnoreCase(httpMethod) || ""PUT"".equalsIgnoreCase(httpMethod)));
    HttpURLConnection connection = openConnection(url);

    try {
      connection.setRequestMethod(httpMethod);
    }
    catch (ProtocolException e) {
      throw new IllegalStateException(e);
    }

    Map<String, String> reqHeaders = details.getAdditionalRequestHeaders();
    if (reqHeaders != null) {
      for (Map.Entry<String, String> requestHeader : reqHeaders.entrySet()) {
        connection.setRequestProperty(requestHeader.getKey(), requestHeader.getValue());
      }
    }

    if (additionalRequestHeaders != null) {
      for (Map.Entry<String, String> requestHeader : additionalRequestHeaders.entrySet()) {
        connection.setRequestProperty(requestHeader.getKey(), requestHeader.getValue());
      }
    }

    int responseCode;
    String responseMessage;
    try {
      connection.setDoOutput(sendOAuthParamsInRequestBody);
      connection.connect();
      if (sendOAuthParamsInRequestBody) {
        String queryString = getOAuthQueryString(details, token, url, httpMethod, additionalParameters);
        OutputStream out = connection.getOutputStream();
        out.write(queryString.getBytes(""UTF-8""));
        out.flush();
        out.close();
      }
      responseCode = connection.getResponseCode();
      responseMessage = connection.getResponseMessage();
      if (responseMessage == null) {
        responseMessage = ""Unknown Error"";
      }
    }
    catch (IOException e) {
      throw new OAuthRequestFailedException(""OAuth connection failed."", e);
    }

    if (responseCode >= 200 && responseCode < 300) {
      try {
        return connection.getInputStream();
      }
      catch (IOException e) {
        throw new OAuthRequestFailedException(""Unable to get the input stream from a successful response."", e);
      }
    }
    else if (responseCode == 400) {
      throw new OAuthRequestFailedException(""OAuth authentication failed: "" + responseMessage);
    }
    else if (responseCode == 401) {
      String authHeaderValue = connection.getHeaderField(""WWW-Authenticate"");
      if (authHeaderValue != null) {
        Map<String, String> headerEntries = StringSplitUtils.splitEachArrayElementAndCreateMap(StringSplitUtils.splitIgnoringQuotes(authHeaderValue, ','), ""="", ""\"""");
        String requiredRealm = headerEntries.get(""realm"");
        if ((requiredRealm != null) && (!requiredRealm.equals(realm))) {
          throw new InvalidOAuthRealmException(String.format(""Invalid OAuth realm. Provider expects \""%s\"", when the resource details specify \""%s\""."", requiredRealm, realm), requiredRealm);
        }
      }

      throw new OAuthRequestFailedException(""OAuth authentication failed: "" + responseMessage);
    }
    else {
      throw new OAuthRequestFailedException(String.format(""Invalid response code %s (%s)."", responseCode, responseMessage));
    }
  }"
"private static void reflectionAppend(
        Object lhs,
        Object rhs,
        Class<?> clazz,
        EqualsBuilder builder,
        boolean useTransients,
        String[] excludeFields) {
        Field[] fields = clazz.getDeclaredFields();
        List<String> excludedFieldList = excludeFields != null ? Arrays.asList(excludeFields) : Collections.<String>emptyList();
        AccessibleObject.setAccessible(fields, true);
        for (int i = 0; i < fields.length && builder.isEquals; i++) {
            Field f = fields[i];
            if (!excludedFieldList.contains(f.getName())
                && (f.getName().indexOf('$') == -1)
                && (useTransients || !Modifier.isTransient(f.getModifiers()))
                && (!Modifier.isStatic(f.getModifiers()))) {
                try {
                    builder.append(f.get(lhs), f.get(rhs));
                } catch (IllegalAccessException e) {
                    //this can't happen. Would get a Security exception instead
                    //throw a runtime exception in case the impossible happens.
                    throw new InternalError(""Unexpected IllegalAccessException"");
                }
            }
        }
    }"
"public boolean removeParameter(String paramName) 
    throws IllegalArgumentException {
        log.trace(""enter PostMethod.removeParameter(String)"");

        if (paramName == null) {
            throw new IllegalArgumentException(
                ""Argument passed to removeParameter(String) cannot be null"");
        }
        boolean removed = false;
        Iterator<NameValuePair> iter = this.params.iterator();

        while (iter.hasNext()) {
            NameValuePair pair = iter.next();

            if (paramName.equals(pair.getName())) {
                iter.remove();
                removed = true;
            }
        }
        return removed;
    }"
"@Override
	public void initializeGlobal(int parallelism) throws IOException {
		final Path path = getOutputFilePath();
		final FileSystem fs = path.getFileSystem();
		
		// only distributed file systems can be initialized at start-up time.
		if (fs.isDistributedFS()) {
			
			final WriteMode writeMode = getWriteMode();
			final OutputDirectoryMode outDirMode = getOutputDirectoryMode();

			if (parallelism == 1 && outDirMode == OutputDirectoryMode.PARONLY) {
				// output is not written in parallel and should be written to a single file.
				// prepare distributed output path
				if(!fs.initOutPathDistFS(path, writeMode, false)) {
					// output preparation failed! Cancel task.
					throw new IOException(""Output path could not be initialized."");
				}

			} else {
				// output should be written to a directory

				// only distributed file systems can be initialized at start-up time.
				if(!fs.initOutPathDistFS(path, writeMode, true)) {
					throw new IOException(""Output directory could not be created."");
				}
			}
		}
	}"
"@SuppressWarnings(""unchecked"")
	public static boolean isCausedBy(Throwable throwable, Class<? extends Exception>... causeClasses) {
		return null != getCausedBy(throwable, causeClasses);
	}"
"public static boolean isSupportedSchema(Schema s) {
    Schema.Type typ =  s.getType();
    switch (typ) {
      case BOOLEAN:
      case INT:
      case LONG:
      case FLOAT:
      case DOUBLE:
      case ENUM:
      case STRING:
      case NULL:
      case BYTES:
        return true;
      case UNION: // Flattenize the union
        List<Schema> unionSchemas = s.getTypes();
        if (unionSchemas.size() == 1) {
          return isSupportedSchema(unionSchemas.get(0));
        } else if (unionSchemas.size() == 2) {
          Schema s1 = unionSchemas.get(0);
          Schema s2 = unionSchemas.get(1);
          return s1.getType().equals(Schema.Type.NULL) && isSupportedSchema(s2)
                 || s2.getType().equals(Schema.Type.NULL) && isSupportedSchema(s1);
        }
      default:
        return false;
    }
  }"
"@Override
  public Long append(final byte[] key, final byte[] value) {
    checkIsInMultiOrPipeline();
    client.append(key, value);
    return client.getIntegerReply();
  }"
"public List<SCC<N>> getStronglyConnectedComponents() {
        final Map<N, Node> nodes = new HashMap<>();
        for (N n : nodes()) {
            nodes.put(n,new Node(n));
        }

        final List<SCC<N>> sccs = new ArrayList<>();

        class Tarjan {
            int index = 0;
            int sccIndex = 0;
            /**
             * Nodes not yet classified for the strongly connected components
             */
            Stack<Node> pending = new Stack<>();
            
            void traverse() {
                for (Node n : nodes.values()) {
                    if (n.index==-1)
                        visit(n);
                }
            }
            
            void visit(Node v) {
                v.index = v.lowlink = index++;
                pending.push(v);

                for (N q : v.edges()) {
                    Node w = nodes.get(q);
                    if (w.index==-1) {
                        visit(w);
                        v.lowlink = Math.min(v.lowlink,w.lowlink);
                    } else
                    if (pending.contains(w)) {
                        v.lowlink = Math.min(v.lowlink,w.index);
                    }
                }

                if (v.lowlink==v.index) {
                    // found a new SCC
                    SCC<N> scc = new SCC<>(sccIndex++);
                    sccs.add(scc);

                    Node w;
                    do {
                        w = pending.pop();
                        w.scc = scc;
                        scc.members.add(w.n);
                    } while(w!=v);
                }
            }
        }

        new Tarjan().traverse();

        Collections.reverse(sccs);

        return sccs;
    }"
"@Nonnull
	@Override
	public RunnableFuture<SnapshotResult<OperatorStateHandle>> snapshot(
		long checkpointId,
		long timestamp,
		@Nonnull CheckpointStreamFactory streamFactory,
		@Nonnull CheckpointOptions checkpointOptions) throws Exception {

		long syncStartTime = System.currentTimeMillis();

		RunnableFuture<SnapshotResult<OperatorStateHandle>> snapshotRunner =
			snapshotStrategy.snapshot(checkpointId, timestamp, streamFactory, checkpointOptions);

		snapshotStrategy.logSyncCompleted(streamFactory, syncStartTime);
		return snapshotRunner;
	}"
"public void createStateDefaultTransition(final TransitionableState state, final String targetState) {
        if (state == null) {
            LOGGER.trace(""Cannot add default transition of [{}] to the given state is null and cannot be found in the flow."", targetState);
            return;
        }
        val transition = createTransition(targetState);
        state.getTransitionSet().add(transition);
    }"
"public static <R, E extends Throwable> R withContextClassLoader(
			final ClassLoader cl,
			final SupplierWithException<R, E> s) throws E {

		try (TemporaryClassLoaderContext tmpCl = new TemporaryClassLoaderContext(cl)) {
			return s.get();
		}
	}"
"public static ExpectedCondition<Boolean> javaScriptThrowsNoExceptions(final String javaScript) {
    return new ExpectedCondition<Boolean>() {
      @Override
      public Boolean apply(WebDriver driver) {
        try {
          ((JavascriptExecutor) driver).executeScript(javaScript);
          return true;
        } catch (WebDriverException e) {
          return false;
        }
      }

      @Override
      public String toString() {
        return String.format(""js %s to be executable"", javaScript);
      }
    };
  }"
"@SuppressWarnings({""unchecked"", ""rawtypes""}) // too late to fix
    public Descriptor getDescriptor(String id) {
        // legacy descriptors that are registered manually doesn't show up in getExtensionList, so check them explicitly.
        Iterable<Descriptor> descriptors = Iterators.sequence(getExtensionList(Descriptor.class), DescriptorExtensionList.listLegacyInstances());
        for (Descriptor d : descriptors) {
            if (d.getId().equals(id)) {
                return d;
            }
        }
        Descriptor candidate = null;
        for (Descriptor d : descriptors) {
            String name = d.getId();
            if (name.substring(name.lastIndexOf('.') + 1).equals(id)) {
                if (candidate == null) {
                    candidate = d;
                } else {
                    throw new IllegalArgumentException(id + "" is ambiguous; matches both "" + name + "" and "" + candidate.getId());
                }
            }
        }
        return candidate;
    }"
"@SuppressWarnings(""unchecked"")
	public static <X> X deserializeFunction(RuntimeContext context, byte[] serFun) throws FlinkException {
		if (!jythonInitialized) {
			// This branch is only tested by end-to-end tests
			String path = context.getDistributedCache().getFile(PythonConstants.FLINK_PYTHON_DC_ID).getAbsolutePath();

			String scriptName = PythonStreamExecutionEnvironment.PythonJobParameters.getScriptName(context.getExecutionConfig().getGlobalJobParameters());

			try {
				initPythonInterpreter(
					new String[]{Paths.get(path, scriptName).toString()},
					path,
					scriptName);
			} catch (Exception e) {

				try {
					LOG.error(""Initialization of jython failed."", e);
					throw new FlinkRuntimeException(""Initialization of jython failed."", e);
				} catch (Exception ie) {
					// this may occur if the initial exception relies on jython being initialized properly
					LOG.error(""Initialization of jython failed. Could not print original stacktrace."", ie);
					throw new FlinkRuntimeException(""Initialization of jython failed. Could not print original stacktrace."");
				}
			}
		}

		try {
			return (X) SerializationUtils.deserializeObject(serFun);
		} catch (IOException | ClassNotFoundException ex) {
			throw new FlinkException(""Deserialization of user-function failed."", ex);
		}
	}"
"public boolean closeClassLoader(final ClassLoader cl) throws ValidatorManagerException {
    boolean res = false;
    if (cl == null) {
      return res;
    }
    final Class classURLClassLoader = URLClassLoader.class;
    Field f = null;
    try {
      f = classURLClassLoader.getDeclaredField(""ucp"");
    } catch (final NoSuchFieldException e) {
      throw new ValidatorManagerException(e);
    }
    if (f != null) {
      f.setAccessible(true);
      Object obj = null;
      try {
        obj = f.get(cl);
      } catch (final IllegalAccessException e) {
        throw new ValidatorManagerException(e);
      }
      if (obj != null) {
        final Object ucp = obj;
        f = null;
        try {
          f = ucp.getClass().getDeclaredField(""loaders"");
        } catch (final NoSuchFieldException e) {
          throw new ValidatorManagerException(e);
        }
        if (f != null) {
          f.setAccessible(true);
          ArrayList loaders = null;
          try {
            loaders = (ArrayList) f.get(ucp);
            res = true;
          } catch (final IllegalAccessException e) {
            throw new ValidatorManagerException(e);
          }
          for (int i = 0; loaders != null && i < loaders.size(); i++) {
            obj = loaders.get(i);
            f = null;
            try {
              f = obj.getClass().getDeclaredField(""jar"");
            } catch (final NoSuchFieldException e) {
              throw new ValidatorManagerException(e);
            }
            if (f != null) {
              f.setAccessible(true);
              try {
                obj = f.get(obj);
              } catch (final IllegalAccessException e) {
                throw new ValidatorManagerException(e);
              }
              if (obj instanceof JarFile) {
                final JarFile jarFile = (JarFile) obj;
                this.setJarFileNames2Close.add(jarFile.getName());
                try {
                  jarFile.close();
                } catch (final IOException e) {
                  throw new ValidatorManagerException(e);
                }
              }
            }
          }
        }
      }
    }
    return res;
  }"
"public String toCSV() {
        StringBuilder builder = new StringBuilder();

        // Header Row
        builder.append("",,Predicted Class,\n"");

        // Predicted Classes Header Row
        builder.append("",,"");
        for (T predicted : classes) {
            builder.append(String.format(""%s,"", predicted));
        }
        builder.append(""Total\n"");

        // Data Rows
        String firstColumnLabel = ""Actual Class,"";
        for (T actual : classes) {
            builder.append(firstColumnLabel);
            firstColumnLabel = "","";
            builder.append(String.format(""%s,"", actual));

            for (T predicted : classes) {
                builder.append(getCount(actual, predicted));
                builder.append("","");
            }
            // Actual Class Totals Column
            builder.append(getActualTotal(actual));
            builder.append(""\n"");
        }

        // Predicted Class Totals Row
        builder.append("",Total,"");
        for (T predicted : classes) {
            builder.append(getPredictedTotal(predicted));
            builder.append("","");
        }
        builder.append(""\n"");

        return builder.toString();
    }"
"public static MetricName build(String... parts) {
        if (parts == null || parts.length == 0)
            return MetricName.EMPTY;

        if (parts.length == 1)
            return new MetricName(parts[0], EMPTY_TAGS);

        return new MetricName(buildName(parts), EMPTY_TAGS);
    }"
"public static Writable min(JavaRDD<List<Writable>> allData, String columnName, Schema schema){
        int columnIdx = schema.getIndexOfColumn(columnName);
        JavaRDD<Writable> col = allData.map(new SelectColumnFunction(columnIdx));
        return col.min(Comparators.forType(schema.getType(columnName).getWritableType()));
    }"
"public static String exampleCountColumn(Class<?> entityClass) {
        StringBuilder sql = new StringBuilder();
        sql.append(""<choose>"");
        sql.append(""<when test=\""@tk.mybatis.mapper.util.OGNL@hasCountColumn(_parameter)\"">"");
        sql.append(""COUNT(<if test=\""distinct\"">distinct </if>${countColumn})"");
        sql.append(""</when>"");
        sql.append(""<otherwise>"");
        sql.append(""COUNT(*)"");
        sql.append(""</otherwise>"");
        sql.append(""</choose>"");
        return sql.toString();
    }"
"public static Map<String, Object> getRequestParameters(final Collection<String> attributes, final HttpServletRequest context) {
        return attributes.stream()
            .filter(a -> StringUtils.isNotBlank(context.getParameter(a)))
            .map(m -> {
                val values = context.getParameterValues(m);
                val valuesSet = new LinkedHashSet<Object>();
                if (values != null && values.length > 0) {
                    Arrays.stream(values).forEach(v -> valuesSet.addAll(Arrays.stream(v.split("" "")).collect(Collectors.toSet())));
                }
                return Pair.of(m, valuesSet);
            })
            .collect(Collectors.toMap(Pair::getKey, Pair::getValue));
    }"
"public static HttpFailure sendErrorResponse(int code, String body) {
    return new HttpFailure(new MockResponse().setResponseCode(code).setBody(body));
  }"
"@Override
    public void shuffle(INDArray array, Random rnd, int... dimension) {
        shuffle(Collections.singletonList(array), rnd, dimension);
    }"
"@SuppressWarnings(""unchecked"")
	public static <T> T readObjectFromXml(InputSource source) throws IOException {
		Object result = null;
		XMLDecoder xmldec = null;
		try {
			xmldec = new XMLDecoder(source);
			result = xmldec.readObject();
		} finally {
			IoUtil.close(xmldec);
		}
		return (T) result;
	}"
"protected TypeMirror interfaceGenericTypeFor(TypeElement element, Class interfaceType) {
        return interfaceGenericTypeFor(element, interfaceType.getName());
    }"
"public void setQueryable(String queryableStateName) {
		Preconditions.checkArgument(
			ttlConfig.getUpdateType() == StateTtlConfig.UpdateType.Disabled,
			""Queryable state is currently not supported with TTL"");
		if (this.queryableStateName == null) {
			this.queryableStateName = Preconditions.checkNotNull(queryableStateName, ""Registration name"");
		} else {
			throw new IllegalStateException(""Queryable state name already set"");
		}
	}"
"public ComputationGraphUpdater getUpdater(boolean initializeIfAbsent){
        if (solver == null && initializeIfAbsent) {
            solver = new Solver.Builder().configure(conf()).listeners(getListeners()).model(this).build();
            solver.getOptimizer().setUpdaterComputationGraph(new ComputationGraphUpdater(this));
        }
        if(solver != null) {
            return solver.getOptimizer().getComputationGraphUpdater();
        }
        return null;
    }"
"public void close() {
		// make sure that we close only once
		if (!this.closed.compareAndSet(false, true)) {
			return;
		}

		// clear the current probe side channel, if there is one
		if (this.currentSpilledProbeSide != null) {
			try {
				this.currentSpilledProbeSide.getChannel().closeAndDelete();
			} catch (Throwable t) {
				LOG.warn(""Could not close and delete the temp file for the current spilled partition probe side."", t);
			}
		}

		// clear the memory in the partitions
		clearPartitions();

		// return the write-behind buffers
		for (int i = 0; i < this.buildSpillRetBufferNumbers; i++) {
			try {
				this.availableMemory.add(this.buildSpillReturnBuffers.take());
			} catch (InterruptedException iex) {
				throw new RuntimeException(""Hashtable closing was interrupted"");
			}
		}
		this.buildSpillRetBufferNumbers = 0;
	}"
"public @CheckForNull Authentication authenticate(Queue.Task task) {
        if (Util.isOverridden(QueueItemAuthenticator.class, getClass(), ""authenticate"", Queue.Item.class)) {
            // Need a fake (unscheduled) item. All the other calls assume a BuildableItem but probably it does not matter.
            return authenticate(new Queue.WaitingItem(Calendar.getInstance(), task, Collections.<Action>emptyList()));
        } else {
            throw new AbstractMethodError(""you must override at least one of the QueueItemAuthenticator.authenticate methods"");
        }
    }"
"public static List<Checkpoint> availableCheckpoints(File directory){
        File checkpointRecordFile = new File(directory, ""checkpointInfo.txt"");
        Preconditions.checkState(checkpointRecordFile.exists(), ""Could not find checkpoint record file at expected path %s"", checkpointRecordFile.getAbsolutePath());

        List<String> lines;
        try(InputStream is = new BufferedInputStream(new FileInputStream(checkpointRecordFile))){
            lines = IOUtils.readLines(is);
        } catch (IOException e){
            throw new RuntimeException(""Error loading checkpoint data from file: "" + checkpointRecordFile.getAbsolutePath(), e);
        }

        List<Checkpoint> out = new ArrayList<>(lines.size()-1); //Assume first line is header
        for( int i=1; i<lines.size(); i++ ){
            Checkpoint c = Checkpoint.fromFileString(lines.get(i));
            if(new File(directory, c.getFilename()).exists()){
                out.add(c);
            }
        }
        return out;
    }"
"public double[/*actual*/][/*predicted*/] buildCM( int idx ) {
    //  \ predicted:  0   1
    //    actual  0: TN  FP
    //            1: FN  TP
    return new double[][]{{tn(idx),fp(idx)},{fn(idx),tp(idx)}};
  }"
"public AllWindowedStream<T, GlobalWindow> countWindowAll(long size) {
		return windowAll(GlobalWindows.create()).trigger(PurgingTrigger.of(CountTrigger.of(size)));
	}"
"public static boolean getBooleanValue(String primaryKey, String secondaryKey) {
        Object val = CFG.get(primaryKey);
        if (val == null) {
            val = CFG.get(secondaryKey);
            if (val == null) {
                throw new SofaRpcRuntimeException(""Not found key: "" + primaryKey + ""/"" + secondaryKey);
            }
        }
        return Boolean.valueOf(val.toString());
    }"
"private void setCellType(Attributes attribute) {
		// 重置numFmtIndex,numFmtString的值
		numFmtIndex = 0;
		numFmtString = """";
		this.cellDataType = CellDataType.of(attribute.getValue(T_ATTR_VALUE));

		// 获取单元格的xf索引，对应style.xml中cellXfs的子元素xf
		final String xfIndexStr = attribute.getValue(S_ATTR_VALUE);
		if (xfIndexStr != null) {
			int xfIndex = Integer.parseInt(xfIndexStr);
			XSSFCellStyle xssfCellStyle = stylesTable.getStyleAt(xfIndex);
			numFmtIndex = xssfCellStyle.getDataFormat();
			numFmtString = xssfCellStyle.getDataFormatString();

			if (numFmtString == null) {
				cellDataType = CellDataType.NULL;
				numFmtString = BuiltinFormats.getBuiltinFormat(numFmtIndex);
			} else if (org.apache.poi.ss.usermodel.DateUtil.isADateFormat(numFmtIndex, numFmtString)) {
				cellDataType = CellDataType.DATE;
			}
		}

	}"
"private static Credential getSigningCredential(final Resource resource) {
        try (val inputStream = resource.getInputStream()) {
            val certificateFactory = CertificateFactory.getInstance(""X.509"");
            val certificate = (X509Certificate) certificateFactory.generateCertificate(inputStream);
            val publicCredential = new BasicX509Credential(certificate);
            LOGGER.debug(""Signing credential key retrieved from [{}]."", resource);
            return publicCredential;
        } catch (final Exception ex) {
            LOGGER.error(ex.getMessage(), ex);
        }
        return null;
    }"
"public static void tail(File file, Charset charset, LineHandler handler) {
		new Tailer(file, charset, handler).start();
	}"
"@Override
  public void recordTaskParentTaskIdChange(String taskId, String parentTaskId) {
    if (isHistoryLevelAtLeast(HistoryLevel.AUDIT)) {
      HistoricTaskInstanceEntity historicTaskInstance = getHistoricTaskInstanceEntityManager().findById(taskId);
      if (historicTaskInstance != null) {
        historicTaskInstance.setParentTaskId(parentTaskId);
      }
    }
  }"
"public static void regist(EventType[] eventTypes, Object action) {
        if (eventTypes != null) {
            for (EventType eventType : eventTypes) {
                regist(eventType, action);
            }
        }
    }"
"@Override
  @Nullable
  public ServerMethodDefinition<?, ?> lookupMethod(String methodName, @Nullable String authority) {
    String serviceName = MethodDescriptor.extractFullServiceName(methodName);
    if (serviceName == null) {
      return null;
    }
    ServerServiceDefinition service = services.get(serviceName);
    if (service == null) {
      return null;
    }
    return service.getMethod(methodName);
  }"
"@InterfaceStability.Unstable
	public synchronized String[] getPropertySources(String name) {
		if (properties == null) {
			// If properties is null, it means a resource was newly added
			// but the props were cleared so as to load it upon future
			// requests. So lets force a load by asking a properties list.
			getProps();
		}
		// Return a null right away if our properties still
		// haven't loaded or the resource mapping isn't defined
		if (properties == null || updatingResource == null) {
			return null;
		} else {
			String[] source = updatingResource.get(name);
			if(source == null) {
				return null;
			} else {
				return Arrays.copyOf(source, source.length);
			}
		}
	}"
"protected SslHandler newHandler(ByteBufAllocator alloc, boolean startTls, Executor executor) {
        return new SslHandler(newEngine(alloc), startTls, executor);
    }"
"@Override
    public boolean process(Set<? extends TypeElement> annotations, RoundEnvironment roundEnv) {
        if (CollectionUtils.isNotEmpty(annotations)) {
            Set<? extends Element> elements = roundEnv.getElementsAnnotatedWith(Interceptor.class);
            try {
                parseInterceptors(elements);
            } catch (Exception e) {
                logger.error(e);
            }
            return true;
        }

        return false;
    }"
"public static synchronized NameResolverRegistry getDefaultRegistry() {
    if (instance == null) {
      List<NameResolverProvider> providerList = ServiceProviders.loadAll(
          NameResolverProvider.class,
          getHardCodedClasses(),
          NameResolverProvider.class.getClassLoader(),
          new NameResolverPriorityAccessor());
      if (providerList.isEmpty()) {
        logger.warning(""No NameResolverProviders found via ServiceLoader, including for DNS. This ""
            + ""is probably due to a broken build. If using ProGuard, check your configuration"");
      }
      instance = new NameResolverRegistry();
      for (NameResolverProvider provider : providerList) {
        logger.fine(""Service loader found "" + provider);
        if (provider.isAvailable()) {
          instance.addProvider(provider);
        }
      }
      instance.refreshProviders();
    }
    return instance;
  }"
"private static boolean isUtf8(ByteBuf buf, int index, int length) {
        final int endIndex = index + length;
        while (index < endIndex) {
            byte b1 = buf.getByte(index++);
            byte b2, b3, b4;
            if ((b1 & 0x80) == 0) {
                // 1 byte
                continue;
            }
            if ((b1 & 0xE0) == 0xC0) {
                // 2 bytes
                //
                // Bit/Byte pattern
                // 110xxxxx    10xxxxxx
                // C2..DF      80..BF
                if (index >= endIndex) { // no enough bytes
                    return false;
                }
                b2 = buf.getByte(index++);
                if ((b2 & 0xC0) != 0x80) { // 2nd byte not starts with 10
                    return false;
                }
                if ((b1 & 0xFF) < 0xC2) { // out of lower bound
                    return false;
                }
            } else if ((b1 & 0xF0) == 0xE0) {
                // 3 bytes
                //
                // Bit/Byte pattern
                // 1110xxxx    10xxxxxx    10xxxxxx
                // E0          A0..BF      80..BF
                // E1..EC      80..BF      80..BF
                // ED          80..9F      80..BF
                // E1..EF      80..BF      80..BF
                if (index > endIndex - 2) { // no enough bytes
                    return false;
                }
                b2 = buf.getByte(index++);
                b3 = buf.getByte(index++);
                if ((b2 & 0xC0) != 0x80 || (b3 & 0xC0) != 0x80) { // 2nd or 3rd bytes not start with 10
                    return false;
                }
                if ((b1 & 0x0F) == 0x00 && (b2 & 0xFF) < 0xA0) { // out of lower bound
                    return false;
                }
                if ((b1 & 0x0F) == 0x0D && (b2 & 0xFF) > 0x9F) { // out of upper bound
                    return false;
                }
            } else if ((b1 & 0xF8) == 0xF0) {
                // 4 bytes
                //
                // Bit/Byte pattern
                // 11110xxx    10xxxxxx    10xxxxxx    10xxxxxx
                // F0          90..BF      80..BF      80..BF
                // F1..F3      80..BF      80..BF      80..BF
                // F4          80..8F      80..BF      80..BF
                if (index > endIndex - 3) { // no enough bytes
                    return false;
                }
                b2 = buf.getByte(index++);
                b3 = buf.getByte(index++);
                b4 = buf.getByte(index++);
                if ((b2 & 0xC0) != 0x80 || (b3 & 0xC0) != 0x80 || (b4 & 0xC0) != 0x80) {
                    // 2nd, 3rd or 4th bytes not start with 10
                    return false;
                }
                if ((b1 & 0xFF) > 0xF4 // b1 invalid
                        || (b1 & 0xFF) == 0xF0 && (b2 & 0xFF) < 0x90    // b2 out of lower bound
                        || (b1 & 0xFF) == 0xF4 && (b2 & 0xFF) > 0x8F) { // b2 out of upper bound
                    return false;
                }
            } else {
                return false;
            }
        }
        return true;
    }"
"public void addContextDataFactory(ContextDataFactory contextDataFactory) {
        if (contextDataFactories == null) {
            contextDataFactories = new ArrayList<>();
        }
        contextDataFactories.add(contextDataFactory);
    }"
"@Override
	public void open(Configuration configuration) throws Exception {
		if (logFailuresOnly) {
			callback = new Callback() {
				@Override
				public void onCompletion(RecordMetadata metadata, Exception e) {
					if (e != null) {
						LOG.error(""Error while sending record to Kafka: "" + e.getMessage(), e);
					}
					acknowledgeMessage();
				}
			};
		}
		else {
			callback = new Callback() {
				@Override
				public void onCompletion(RecordMetadata metadata, Exception exception) {
					if (exception != null && asyncException == null) {
						asyncException = exception;
					}
					acknowledgeMessage();
				}
			};
		}

		super.open(configuration);
	}"
"@Deprecated
	public void setSecondInputs(List<Operator<IN2>> inputs) {
		this.input2 = Operator.createUnionCascade(inputs);
	}"
"void setExtensionsState(Map<String, Boolean> extensionsState) {
        if (extensionsState == null) {
            throw new IllegalArgumentException(""Parameter extensionsState must not be null."");
        }

        ((HierarchicalConfiguration) getConfig()).clearTree(ALL_EXTENSIONS_KEY);
        int enabledCount = 0;
        for (Iterator<Map.Entry<String, Boolean>> it = extensionsState.entrySet().iterator(); it.hasNext();) {
            Map.Entry<String, Boolean> entry = it.next();
            if (entry.getKey() == null || entry.getValue() == null) {
                continue;
            }

            // Don't persist if enabled, extensions are enabled by default.
            if (!entry.getValue()) {
                String elementBaseKey = ALL_EXTENSIONS_KEY + ""("" + enabledCount + "")."";
                getConfig().setProperty(elementBaseKey + EXTENSION_NAME_KEY, entry.getKey());
                getConfig().setProperty(elementBaseKey + EXTENSION_ENABLED_KEY, Boolean.FALSE);

                enabledCount++;
            }
        }
        this.extensionsState = Collections.unmodifiableMap(extensionsState);
    }"
"private static boolean containsSection(String contents, String beginToken, String endToken) {
		int idxToken;
		if ((idxToken = contents.indexOf(beginToken)) == -1 || contents.indexOf(endToken) < idxToken) {
			return false;
		}
		return true;
	}"
"@Override
	public void addConnectorCustomizers(
			TomcatConnectorCustomizer... tomcatConnectorCustomizers) {
		Assert.notNull(tomcatConnectorCustomizers,
				""TomcatConnectorCustomizers must not be null"");
		this.tomcatConnectorCustomizers.addAll(Arrays.asList(tomcatConnectorCustomizers));
	}"
"public synchronized void delete(File dir, String id) {
        if (idToNumber.remove(id) != null) {
            save(dir);
        }
    }"
"public static boolean hasColumn(final Connection connection, final String tableName, final String columnName) throws SQLException {
        boolean hasColumn = false;
        
        ResultSet rs = null;
        try {
            rs = connection.getMetaData().getColumns(null, null, tableName, columnName);
            if (rs.next()) {
                hasColumn = true;
            }
        } finally {
            try {
                if (rs != null) {
                    rs.close();
                }
            } catch (SQLException e) {
                if (logger.isDebugEnabled()) {
                    logger.debug(e.getMessage(), e);
                }
            }
        }
        
        return hasColumn;
    }"
"private void deleteExecutorDirs(String[] dirs) {
    for (String localDir : dirs) {
      try {
        JavaUtils.deleteRecursively(new File(localDir));
        logger.debug(""Successfully cleaned up directory: {}"", localDir);
      } catch (Exception e) {
        logger.error(""Failed to delete directory: "" + localDir, e);
      }
    }
  }"
"public static void write(Image image, String imageType, OutputStream out) throws IORuntimeException {
		write(image, imageType, getImageOutputStream(out));
	}"
"public SDVariable iamax(SDVariable in, boolean keepDims, int... dimensions) {
        return iamax(null, in, keepDims, dimensions);
    }"
"public void processDI() {

    if (processDefinitions.isEmpty()) {
      return;
    }

    if (!bpmnModel.getLocationMap().isEmpty()) {

      // Verify if all referenced elements exist
      for (String bpmnReference : bpmnModel.getLocationMap().keySet()) {
        if (bpmnModel.getFlowElement(bpmnReference) == null) {
          // ACT-1625: don't warn when artifacts are referenced from DI
          if (bpmnModel.getArtifact(bpmnReference) == null) {
            // Check if it's a Pool or Lane, then DI is ok
            if (bpmnModel.getPool(bpmnReference) == null && bpmnModel.getLane(bpmnReference) == null) {
              LOGGER.warn(""Invalid reference in diagram interchange definition: could not find "" + bpmnReference);
            }
          }
        } else if (!(bpmnModel.getFlowElement(bpmnReference) instanceof FlowNode)) {
          LOGGER.warn(""Invalid reference in diagram interchange definition: "" + bpmnReference + "" does not reference a flow node"");
        }
      }
      
      for (String bpmnReference : bpmnModel.getFlowLocationMap().keySet()) {
        if (bpmnModel.getFlowElement(bpmnReference) == null) {
          // ACT-1625: don't warn when artifacts are referenced from DI
          if (bpmnModel.getArtifact(bpmnReference) == null) {
            LOGGER.warn(""Invalid reference in diagram interchange definition: could not find "" + bpmnReference);
          }
        } else if (!(bpmnModel.getFlowElement(bpmnReference) instanceof SequenceFlow)) {
          LOGGER.warn(""Invalid reference in diagram interchange definition: "" + bpmnReference + "" does not reference a sequence flow"");
        }
      }

      for (Process process : bpmnModel.getProcesses()) {
        if (!process.isExecutable()) {
          continue;
        }

        // Parse diagram interchange information
        ProcessDefinitionEntity processDefinition = getProcessDefinition(process.getId());
        if (processDefinition != null) {
          processDefinition.setGraphicalNotationDefined(true);
          
          for (String edgeId : bpmnModel.getFlowLocationMap().keySet()) {
            if (bpmnModel.getFlowElement(edgeId) != null) {
              createBPMNEdge(edgeId, bpmnModel.getFlowLocationGraphicInfo(edgeId));
            }
          }
        }
      }
    }
  }"
"static void appendBytes(String content,
                          Mode mode,
                          BitArray bits,
                          String encoding) throws WriterException {
    switch (mode) {
      case NUMERIC:
        appendNumericBytes(content, bits);
        break;
      case ALPHANUMERIC:
        appendAlphanumericBytes(content, bits);
        break;
      case BYTE:
        append8BitBytes(content, bits, encoding);
        break;
      case KANJI:
        appendKanjiBytes(content, bits);
        break;
      default:
        throw new WriterException(""Invalid mode: "" + mode);
    }
  }"
"public static boolean sortingOrderHasNonGroupingFields(DefaultLimitSpec limitSpec, List<DimensionSpec> dimensions)
  {
    for (OrderByColumnSpec orderSpec : limitSpec.getColumns()) {
      int dimIndex = OrderByColumnSpec.getDimIndexForOrderBy(orderSpec, dimensions);
      if (dimIndex < 0) {
        return true;
      }
    }
    return false;
  }"
"public int compareTo(byte[] other, int off, int len) {
        return WritableComparator.compareBytes(getBytes(), 0, getLength(), other, off, len);
    }"
"@Bean(initMethod = ""start"")
  ScribeCollector scribe(
      ZipkinScribeCollectorProperties scribe,
      CollectorSampler sampler,
      CollectorMetrics metrics,
      StorageComponent storage) {
    return scribe.toBuilder().sampler(sampler).metrics(metrics).storage(storage).build();
  }"
"public static long parseTimestampLiteral(String value)
    {
        try {
            DateTime dateTime = TIMESTAMP_WITH_TIME_ZONE_FORMATTER.parseDateTime(value);
            return packDateTimeWithZone(dateTime);
        }
        catch (Exception e) {
            return TIMESTAMP_WITHOUT_TIME_ZONE_FORMATTER.parseMillis(value);
        }
    }"
"public static long getLong(Properties config, String key, long defaultValue) {
		String val = config.getProperty(key);
		if (val == null) {
			return defaultValue;
		} else {
			try {
				return Long.parseLong(val);
			} catch (NumberFormatException nfe) {
				throw new IllegalArgumentException(""Value for configuration key='"" + key + ""' is not set correctly. "" +
						""Entered value='"" + val + ""'. Default value='"" + defaultValue + ""'"");
			}
		}
	}"
"public static void main(String[] args) {
        for (Version v: identify().values()) {
            System.err.println(v);
        }
    }"
"private static ResultPoint[] expandSquare(ResultPoint[] cornerPoints, int oldSide, int newSide) {
    float ratio = newSide / (2.0f * oldSide);
    float dx = cornerPoints[0].getX() - cornerPoints[2].getX();
    float dy = cornerPoints[0].getY() - cornerPoints[2].getY();
    float centerx = (cornerPoints[0].getX() + cornerPoints[2].getX()) / 2.0f;
    float centery = (cornerPoints[0].getY() + cornerPoints[2].getY()) / 2.0f;

    ResultPoint result0 = new ResultPoint(centerx + ratio * dx, centery + ratio * dy);
    ResultPoint result2 = new ResultPoint(centerx - ratio * dx, centery - ratio * dy);

    dx = cornerPoints[1].getX() - cornerPoints[3].getX();
    dy = cornerPoints[1].getY() - cornerPoints[3].getY();
    centerx = (cornerPoints[1].getX() + cornerPoints[3].getX()) / 2.0f;
    centery = (cornerPoints[1].getY() + cornerPoints[3].getY()) / 2.0f;
    ResultPoint result1 = new ResultPoint(centerx + ratio * dx, centery + ratio * dy);
    ResultPoint result3 = new ResultPoint(centerx - ratio * dx, centery - ratio * dy);

    return new ResultPoint[]{result0, result1, result2, result3};
  }"
"private int hash(Object k) {
        int h = hashSeed;

//        if ((0 != h) && (k instanceof String)) {
//            return sun.misc.Hashing.stringHash32((String) k);
//        }

        h ^= k.hashCode();

        // Spread bits to regularize both segment and index locations,
        // using variant of single-word Wang/Jenkins hash.
        h += (h <<  15) ^ 0xffffcd7d;
        h ^= (h >>> 10);
        h += (h <<   3);
        h ^= (h >>>  6);
        h += (h <<   2) + (h << 14);
        return h ^ (h >>> 16);
    }"
"public static File createTempDir() throws IOException {
        // The previously used approach of creating a temporary file, deleting
        // it, and making a new directory having the same name in its place is
        // potentially  problematic:
        // https://stackoverflow.com/questions/617414/how-to-create-a-temporary-directory-folder-in-java
        // We can use the Java 7 Files.createTempDirectory() API, but note that
        // by default, the permissions of the created directory are 0700&(~umask)
        // whereas the old approach created a temporary directory with permissions
        // 0777&(~umask).
        // To avoid permissions problems like https://issues.jenkins-ci.org/browse/JENKINS-48407
        // we can pass POSIX file permissions as an attribute (see, for example,
        // https://github.com/jenkinsci/jenkins/pull/3161 )
        final Path tempPath;
        final String tempDirNamePrefix = ""jenkins"";
        if (FileSystems.getDefault().supportedFileAttributeViews().contains(""posix"")) {
            tempPath = Files.createTempDirectory(tempDirNamePrefix,
                    PosixFilePermissions.asFileAttribute(EnumSet.allOf(PosixFilePermission.class)));
        } else {
            tempPath = Files.createTempDirectory(tempDirNamePrefix);
        }
        return tempPath.toFile();
    }"
"public static Field[] getFieldsDirectly(Class<?> beanClass, boolean withSuperClassFieds) throws SecurityException {
		Assert.notNull(beanClass);

		Field[] allFields = null;
		Class<?> searchType = beanClass;
		Field[] declaredFields;
		while (searchType != null) {
			declaredFields = searchType.getDeclaredFields();
			if (null == allFields) {
				allFields = declaredFields;
			} else {
				allFields = ArrayUtil.append(allFields, declaredFields);
			}
			searchType = withSuperClassFieds ? searchType.getSuperclass() : null;
		}

		return allFields;
	}"
"private MinusOneFieldAndOptimizationResult runWithScrollingAndAddFilter(String firstFieldName ,String secondFieldName) throws SqlParseException {
        SearchResponse scrollResp = ElasticUtils.scrollOneTimeWithHits(this.client, this.builder.getFirstSearchRequest(),
                builder.getOriginalSelect(true), this.maxDocsToFetchOnEachScrollShard);
        Set<Object> results = new HashSet<>();
        int currentNumOfResults = 0;
        SearchHit[] hits = scrollResp.getHits().getHits();
        SearchHit someHit = null;
        if(hits.length!=0){
            //we need some hit for creating InnerResults.
            someHit = hits[0];
        }
        int totalDocsFetchedFromFirstTable = 0;
        int totalDocsFetchedFromSecondTable = 0;
        Where originalWhereSecondTable = this.builder.getOriginalSelect(false).getWhere();
        while (hits.length != 0 ) {
            totalDocsFetchedFromFirstTable+=hits.length;
            Set<Object> currentSetFromResults = new HashSet<>();
            fillSetFromHits(firstFieldName, hits, currentSetFromResults);
            //fetch from second
            Select secondQuerySelect = this.builder.getOriginalSelect(false);
            Where where = createWhereWithOrigianlAndTermsFilter(secondFieldName, originalWhereSecondTable, currentSetFromResults);
            secondQuerySelect.setWhere(where);
            DefaultQueryAction queryAction = new DefaultQueryAction(this.client, secondQuerySelect);
            queryAction.explain();
            if(totalDocsFetchedFromSecondTable > this.maxDocsToFetchOnSecondTable){
                break;
            }
            SearchResponse responseForSecondTable = ElasticUtils.scrollOneTimeWithHits(this.client, queryAction.getRequestBuilder(),secondQuerySelect,this.maxDocsToFetchOnEachScrollShard);
            SearchHits secondQuerySearchHits = responseForSecondTable.getHits();

            SearchHit[] secondQueryHits = secondQuerySearchHits.getHits();
            while(secondQueryHits.length > 0){
                totalDocsFetchedFromSecondTable+=secondQueryHits.length;
                removeValuesFromSetAccordingToHits(secondFieldName, currentSetFromResults, secondQueryHits);
                if(totalDocsFetchedFromSecondTable > this.maxDocsToFetchOnSecondTable){
                    break;
                }
                responseForSecondTable = client.prepareSearchScroll(responseForSecondTable.getScrollId()).setScroll(new TimeValue(600000)).execute().actionGet();
                secondQueryHits = responseForSecondTable.getHits().getHits();
            }
            results.addAll(currentSetFromResults);
            if(totalDocsFetchedFromFirstTable > this.maxDocsToFetchOnFirstTable){
                System.out.println(""too many results for first table, stoping at:"" + totalDocsFetchedFromFirstTable);
                break;
            }

            scrollResp = client.prepareSearchScroll(scrollResp.getScrollId()).setScroll(new TimeValue(600000)).execute().actionGet();
            hits = scrollResp.getHits().getHits();
        }
        return new MinusOneFieldAndOptimizationResult(results,someHit);


    }"
"public static String putFileType(String fileStreamHexHead, String extName) {
		return fileTypeMap.put(fileStreamHexHead.toLowerCase(), extName);
	}"
"private static <T> T executeQuery(PreparedStatement ps, RsHandler<T> rsh) throws SQLException {
		ResultSet rs = null;
		try {
			rs = ps.executeQuery();
			return rsh.handle(rs);
		} finally {
			DbUtil.close(rs);
		}
	}"
"protected String getLdapPrincipalIdentifier(final String username, final LdapEntry ldapEntry) throws LoginException {
        if (StringUtils.isNotBlank(this.principalIdAttribute)) {
            val principalAttr = ldapEntry.getAttribute(this.principalIdAttribute);
            if (principalAttr == null || principalAttr.size() == 0) {
                if (this.allowMissingPrincipalAttributeValue) {
                    LOGGER.warn(""The principal id attribute [{}] is not found. CAS cannot construct the final authenticated principal ""
                            + ""if it's unable to locate the attribute that is designated as the principal id. ""
                            + ""Attributes available on the LDAP entry are [{}]. Since principal id attribute is not available, CAS will ""
                            + ""fall back to construct the principal based on the provided user id: [{}]"",
                        this.principalIdAttribute, ldapEntry.getAttributes(), username);
                    return username;
                }
                LOGGER.error(""The principal id attribute [{}] is not found. CAS is configured to disallow missing principal attributes"",
                    this.principalIdAttribute);
                throw new LoginException(""Principal id attribute is not found for "" + principalAttr);
            }
            val value = principalAttr.getStringValue();
            if (principalAttr.size() > 1) {
                if (!this.allowMultiplePrincipalAttributeValues) {
                    throw new LoginException(""Multiple principal values are not allowed: "" + principalAttr);
                }
                LOGGER.warn(""Found multiple values for principal id attribute: [{}]. Using first value=[{}]."", principalAttr, value);
            }
            LOGGER.debug(""Retrieved principal id attribute [{}]"", value);
            return value;
        }
        LOGGER.debug(""Principal id attribute is not defined. Using the default provided user id [{}]"", username);
        return username;
    }"
"public final AutoBuffer write_impl( AutoBuffer ab ) {
    _write_lock = true;
    try {
      if (map().size() == 0) return ab.put1(0); // empty map
      Entry<K, V> entry = map().entrySet().iterator().next();
      K key = entry.getKey();
      V val = entry.getValue();
      assert key != null && val != null;
      int mode;
      if (key instanceof String) {
        if (val instanceof String) {
          mode = 1;
        } else {
          assert (val instanceof Freezable || val instanceof Freezable[]):""incompatible class "" + val.getClass();
          mode = val instanceof Freezable ? 2 : 5;
        }
      } else {
        assert key instanceof Iced;
        if (val instanceof String) {
          mode = 3;
        } else {
          assert (val instanceof Freezable || val instanceof Freezable[]);
          mode = val instanceof Freezable ? 4 : 6;
        }
      }
      ab.put1(mode);              // Type of hashmap being serialized
      writeMap(ab, mode);          // Do the hard work of writing the map
      return isStringKey(mode) ? ab.putStr(null) : ab.put(null);
    } catch(Throwable t){
      System.err.println(""Iced hash map serialization failed! "" + t.toString() + "", msg = "" + t.getMessage());
      t.printStackTrace();
      throw H2O.fail(""Iced hash map serialization failed!"" + t.toString() + "", msg = "" + t.getMessage());
    } finally {
      _write_lock = false;
    }
  }"
"@Override
	public void findIdes(List<IdeLocation> locations, List<CorruptedIdeLocationException> problems) {
		switch (OsUtils.getOS()) {
		case WINDOWS:
			new WindowsFinder().findEclipse(locations, problems);
			break;
		case MAC_OS_X:
			new MacFinder().findEclipse(locations, problems);
			break;
		default:
		case UNIX:
			new UnixFinder().findEclipse(locations, problems);
			break;
		}
	}"
"byte[] writeAndClose(byte[] payload, StreamWrapper wrapper) throws IOException {
        ByteArrayOutputStream outputStream = new ByteArrayOutputStream(512);
        OutputStream compressionStream = wrapper.wrap(outputStream);
        try {
            compressionStream.write(payload);
            compressionStream.flush();
        } finally {
            Objects.nullSafeClose(compressionStream);
        }
        return outputStream.toByteArray();
    }"
"public static ListObjectAttributesRequest getListObjectAttributesRequest(final String arnName,
                                                                             final String objectId) {
        return new ListObjectAttributesRequest()
            .withDirectoryArn(arnName)
            .withObjectReference(getObjectRefById(objectId));
    }"
"public static long murmur128AsLong(@NotNull String input) {
		return Hashing.murmur3_128(MURMUR_SEED).hashString(input, Charsets.UTF_8).asLong();
	}"
"private JPanel getPanelMisc() {
		if (panelMisc == null) {
			panelMisc = new JPanel();
			panelMisc.setLayout(new GridBagLayout());
			int y = 0;
			panelMisc.add(getChkEnabled(), LayoutHelper.getGBC(0, y++, 1, 0.5));
			panelMisc.add(getChkUiEnabled(), LayoutHelper.getGBC(0, y++, 1, 0.5));
			panelMisc.add(getChkSecureOnly(), LayoutHelper.getGBC(0, y++, 1, 0.5));
			
			panelMisc.add(new JLabel(Constant.messages.getString(""api.options.label.apiKey"")), 
					LayoutHelper.getGBC(0, y, 1, 0.5));
			panelMisc.add(getKeyField(), LayoutHelper.getGBC(1, y++, 1, 0.5));
			panelMisc.add(getGenerateKeyButton(), LayoutHelper.getGBC(1, y++, 1, 0.5));
			
			JPanel jPanel = new JPanel();
			jPanel.setLayout(new GridBagLayout());
			jPanel.setBorder(javax.swing.BorderFactory.createTitledBorder(null, 
					Constant.messages.getString(""api.options.addr.title""),
					javax.swing.border.TitledBorder.DEFAULT_JUSTIFICATION, 
					javax.swing.border.TitledBorder.DEFAULT_POSITION, 
					FontUtils.getFont(FontUtils.Size.standard), java.awt.Color.black));

			jPanel.add(getProxyPermittedAddressesPanel(), LayoutHelper.getGBC(0, 0, 1, 1.0, 1.0));
			panelMisc.add(jPanel, LayoutHelper.getGBC(0, y++, 2, 1.0, 1.0));

			JLabel warning = new JLabel(Constant.messages.getString(""api.options.label.testingWarning""));
			warning.setForeground(Color.RED);
			panelMisc.add(warning, LayoutHelper.getGBC(0, y++, 2, 0.5D));
			panelMisc.add(getDisableKey(), LayoutHelper.getGBC(0, y++, 1, 0.5));
			panelMisc.add(getNoKeyForSafeOps(), LayoutHelper.getGBC(0, y++, 1, 0.5));
			panelMisc.add(getReportPermErrors(), LayoutHelper.getGBC(0, y++, 1, 0.5));
			panelMisc.add(getIncErrorDetails(), LayoutHelper.getGBC(0, y++, 1, 0.5));
			panelMisc.add(getAutofillKey(), LayoutHelper.getGBC(0, y++, 1, 0.5));
			panelMisc.add(getEnableJSONP(), LayoutHelper.getGBC(0, y++, 1, 0.5));
			
			panelMisc.add(new JLabel(), LayoutHelper.getGBC(0, y, 1, 0.5D, 1.0D));	// Spacer
		}
		return panelMisc;
	}"
"private static FactorComparator<Executor> getNumberOfAssignedFlowComparator(final int weight) {
    return FactorComparator
        .create(NUMOFASSIGNEDFLOW_COMPARATOR_NAME, weight, new Comparator<Executor>() {

          @Override
          public int compare(final Executor o1, final Executor o2) {
            final ExecutorInfo stat1 = o1.getExecutorInfo();
            final ExecutorInfo stat2 = o2.getExecutorInfo();

            final Integer result = 0;
            if (statisticsObjectCheck(stat1, stat2, NUMOFASSIGNEDFLOW_COMPARATOR_NAME)) {
              return result;
            }
            return ((Integer) stat1.getRemainingFlowCapacity())
                .compareTo(stat2.getRemainingFlowCapacity());
          }
        });
  }"
"@PostMapping(""/etl/{type}/{key}/{task}"")
    public EtlResult etl(@PathVariable String type, @PathVariable String key, @PathVariable String task,
                         @RequestParam(name = ""params"", required = false) String params) {
        OuterAdapter adapter = loader.getExtension(type, key);
        String destination = adapter.getDestination(task);
        String lockKey = destination == null ? task : destination;

        boolean locked = etlLock.tryLock(ETL_LOCK_ZK_NODE + type + ""-"" + lockKey);
        if (!locked) {
            EtlResult result = new EtlResult();
            result.setSucceeded(false);
            result.setErrorMessage(task + "" 有其他进程正在导入中, 请稍后再试"");
            return result;
        }
        try {

            boolean oriSwitchStatus;
            if (destination != null) {
                oriSwitchStatus = syncSwitch.status(destination);
                if (oriSwitchStatus) {
                    syncSwitch.off(destination);
                }
            } else {
                // task可能为destination，直接锁task
                oriSwitchStatus = syncSwitch.status(task);
                if (oriSwitchStatus) {
                    syncSwitch.off(task);
                }
            }
            try {
                List<String> paramArray = null;
                if (params != null) {
                    paramArray = Arrays.asList(params.trim().split("";""));
                }
                return adapter.etl(task, paramArray);
            } finally {
                if (destination != null && oriSwitchStatus) {
                    syncSwitch.on(destination);
                } else if (destination == null && oriSwitchStatus) {
                    syncSwitch.on(task);
                }
            }
        } finally {
            etlLock.unlock(ETL_LOCK_ZK_NODE + type + ""-"" + lockKey);
        }
    }"
"public static int elfHash(String str) {
		int hash = 0;
		int x = 0;

		for (int i = 0; i < str.length(); i++) {
			hash = (hash << 4) + str.charAt(i);
			if ((x = (int) (hash & 0xF0000000L)) != 0) {
				hash ^= (x >> 24);
				hash &= ~x;
			}
		}

		return hash & 0x7FFFFFFF;
	}"
"public void pointTo(Object baseObject, long baseOffset, int sizeInBytes) {
    // Read the number of elements from the first 8 bytes.
    final long numElements = Platform.getLong(baseObject, baseOffset);
    assert numElements >= 0 : ""numElements ("" + numElements + "") should >= 0"";
    assert numElements <= Integer.MAX_VALUE :
      ""numElements ("" + numElements + "") should <= Integer.MAX_VALUE"";

    this.numElements = (int)numElements;
    this.baseObject = baseObject;
    this.baseOffset = baseOffset;
    this.sizeInBytes = sizeInBytes;
    this.elementOffset = baseOffset + calculateHeaderPortionInBytes(this.numElements);
  }"
"@Override
  public List<Integer> getRunningFlows(final int projectId, final String flowId) {
    final List<Integer> executionIds = new ArrayList<>();
    try {
      executionIds.addAll(getRunningFlowsHelper(projectId, flowId,
          this.executorLoader.fetchUnfinishedFlows().values()));
    } catch (final ExecutorManagerException e) {
      logger.error(""Failed to get running flows for project "" + projectId + "", flow ""
          + flowId, e);
    }
    return executionIds;
  }"
"public ProcessEngineConfiguration addWsEndpointAddress(QName endpointName, URL address) {
      this.wsOverridenEndpointAddresses.put(endpointName, address);
      return this;
  }"
"public MultiLayerNetwork fit(JavaRDD<DataSet> trainingData) {
        if (Nd4j.getExecutioner() instanceof GridExecutioner)
            ((GridExecutioner) Nd4j.getExecutioner()).flushQueue();

        trainingMaster.executeTraining(this, trainingData);
        network.incrementEpochCount();
        return network;
    }"
"@Override
	@SuppressWarnings(""unchecked"")
	public Tuple6<T0, T1, T2, T3, T4, T5> copy() {
		return new Tuple6<>(this.f0,
			this.f1,
			this.f2,
			this.f3,
			this.f4,
			this.f5);
	}"
"public void execBackwards(Map<String,INDArray> placeholders){
        if (getFunction(""grad"") == null) {
            createGradFunction();
        }

        //Collect (unique) list of gradient names...
        Set<String> varGradNames = new HashSet<>();
        for(Variable v : variables.values()){
            if(v.getVariable().getVariableType() == VariableType.VARIABLE){
                SDVariable g = v.getVariable().gradient();
                if(g != null) {
                    //Not all variables can have gradients... for example: suppose graph has 2 independent loss functions,
                    // optimizing only 1 might not require changing all variables
                    varGradNames.add(g.getVarName());
                }
            }
        }

        //Edge case: if no variables, no variable gradients to calculate...
        if(varGradNames.isEmpty()){
            log.warn(""Skipping gradient execution (backward pass) - no variables to be calculated (graph does not contain any VARIABLE type SDVariables).\n"" +
                    ""If gradients for other variables (such as placeholders) are required, use execBackwards(Map, List) instead"");
            return;
        }

        List<String> vargradNamesList = new ArrayList<>(varGradNames);
        execBackwards(placeholders, vargradNamesList);
    }"
"private void overrideLocalCanalConfig(String content) {

        try (OutputStreamWriter writer = new OutputStreamWriter(
            new FileOutputStream(CommonUtils.getConfPath() + ""application.yml""),
            StandardCharsets.UTF_8)) {
            writer.write(content);
            writer.flush();
        } catch (Exception e) {
            logger.error(e.getMessage(), e);
        }
    }"
"public synchronized boolean isJobPaused(final String jobName, final String groupName)
      throws SchedulerException {
    if (!ifJobExist(jobName, groupName)) {
      throw new SchedulerException(String.format(""Job (job name %s, group name %s) doesn't ""
          + ""exist'"", jobName, groupName));
    }
    final JobKey jobKey = new JobKey(jobName, groupName);
    final JobDetail jobDetail = this.scheduler.getJobDetail(jobKey);
    final List<? extends Trigger> triggers = this.scheduler.getTriggersOfJob(jobDetail.getKey());
    for (final Trigger trigger : triggers) {
      final TriggerState triggerState = this.scheduler.getTriggerState(trigger.getKey());
      if (TriggerState.PAUSED.equals(triggerState)) {
        return true;
      }
    }
    return false;
  }"
"@Override
  public TableSchema getResultSetMetadata(OperationHandle opHandle)
      throws HiveSQLException {
    try {
      TGetResultSetMetadataReq req = new TGetResultSetMetadataReq(opHandle.toTOperationHandle());
      TGetResultSetMetadataResp resp = cliService.GetResultSetMetadata(req);
      checkStatus(resp.getStatus());
      return new TableSchema(resp.getSchema());
    } catch (HiveSQLException e) {
      throw e;
    } catch (Exception e) {
      throw new HiveSQLException(e);
    }
  }"
"private int toNarrowWidePattern(int position) {
    int end = position + 7;
    if (end >= counterLength) {
      return -1;
    }

    int[] theCounters = counters;

    int maxBar = 0;
    int minBar = Integer.MAX_VALUE;
    for (int j = position; j < end; j += 2) {
      int currentCounter = theCounters[j];
      if (currentCounter < minBar) {
        minBar = currentCounter;
      }
      if (currentCounter > maxBar) {
        maxBar = currentCounter;
      }
    }
    int thresholdBar = (minBar + maxBar) / 2;

    int maxSpace = 0;
    int minSpace = Integer.MAX_VALUE;
    for (int j = position + 1; j < end; j += 2) {
      int currentCounter = theCounters[j];
      if (currentCounter < minSpace) {
        minSpace = currentCounter;
      }
      if (currentCounter > maxSpace) {
        maxSpace = currentCounter;
      }
    }
    int thresholdSpace = (minSpace + maxSpace) / 2;

    int bitmask = 1 << 7;
    int pattern = 0;
    for (int i = 0; i < 7; i++) {
      int threshold = (i & 1) == 0 ? thresholdBar : thresholdSpace;
      bitmask >>= 1;
      if (theCounters[position + i] > threshold) {
        pattern |= bitmask;
      }
    }

    for (int i = 0; i < CHARACTER_ENCODINGS.length; i++) {
      if (CHARACTER_ENCODINGS[i] == pattern) {
        return i;
      }
    }
    return -1;
  }"
"public void update(Instance instance)
    {
        int[] guessLabel = new int[instance.length()];
        viterbiDecode(instance, guessLabel);
        TagSet tagSet = featureMap.tagSet;
        for (int i = 0; i < instance.length(); i++)
        {
            int[] featureVector = instance.getFeatureAt(i);
            int[] goldFeature = new int[featureVector.length]; // 根据答案应当被激活的特征
            int[] predFeature = new int[featureVector.length]; // 实际预测时激活的特征
            for (int j = 0; j < featureVector.length - 1; j++)
            {
                goldFeature[j] = featureVector[j] * tagSet.size() + instance.tagArray[i];
                predFeature[j] = featureVector[j] * tagSet.size() + guessLabel[i];
            }
            goldFeature[featureVector.length - 1] = (i == 0 ? tagSet.bosId() : instance.tagArray[i - 1]) * tagSet.size() + instance.tagArray[i];
            predFeature[featureVector.length - 1] = (i == 0 ? tagSet.bosId() : guessLabel[i - 1]) * tagSet.size() + guessLabel[i];
            update(goldFeature, predFeature);
        }
    }"
"public void suspend() {
		LOG.info(""Suspending the SlotManager."");

		// stop the timeout checks for the TaskManagers and the SlotRequests
		if (taskManagerTimeoutCheck != null) {
			taskManagerTimeoutCheck.cancel(false);
			taskManagerTimeoutCheck = null;
		}

		if (slotRequestTimeoutCheck != null) {
			slotRequestTimeoutCheck.cancel(false);
			slotRequestTimeoutCheck = null;
		}

		for (PendingSlotRequest pendingSlotRequest : pendingSlotRequests.values()) {
			cancelPendingSlotRequest(pendingSlotRequest);
		}

		pendingSlotRequests.clear();

		ArrayList<InstanceID> registeredTaskManagers = new ArrayList<>(taskManagerRegistrations.keySet());

		for (InstanceID registeredTaskManager : registeredTaskManagers) {
			unregisterTaskManager(registeredTaskManager);
		}

		resourceManagerId = null;
		resourceActions = null;
		started = false;
	}"
"@Override
	public List<PlanNode> getAlternativePlans(CostEstimator estimator) {
		// check if we have a cached version
		if (this.cachedPlans != null) {
			return this.cachedPlans;
		}
		
		// calculate alternative sub-plans for predecessor
		List<? extends PlanNode> subPlans = getPredecessorNode().getAlternativePlans(estimator);
		List<PlanNode> outputPlans = new ArrayList<PlanNode>();
		
		final int parallelism = getParallelism();
		final int inDop = getPredecessorNode().getParallelism();

		final ExecutionMode executionMode = this.input.getDataExchangeMode();
		final boolean dopChange = parallelism != inDop;
		final boolean breakPipeline = this.input.isBreakingPipeline();

		InterestingProperties ips = this.input.getInterestingProperties();
		for (PlanNode p : subPlans) {
			for (RequestedGlobalProperties gp : ips.getGlobalProperties()) {
				for (RequestedLocalProperties lp : ips.getLocalProperties()) {
					Channel c = new Channel(p);
					gp.parameterizeChannel(c, dopChange, executionMode, breakPipeline);
					lp.parameterizeChannel(c);
					c.setRequiredLocalProps(lp);
					c.setRequiredGlobalProps(gp);
					
					// no need to check whether the created properties meet what we need in case
					// of ordering or global ordering, because the only interesting properties we have
					// are what we require
					outputPlans.add(new SinkPlanNode(this, ""DataSink (""+this.getOperator().getName()+"")"" ,c));
				}
			}
		}
		
		// cost and prune the plans
		for (PlanNode node : outputPlans) {
			estimator.costOperator(node);
		}
		prunePlanAlternatives(outputPlans);

		this.cachedPlans = outputPlans;
		return outputPlans;
	}"
"public static LossFunctions.LossFunction mapLossFunction(String kerasLoss, KerasLayerConfiguration conf)
            throws UnsupportedKerasConfigurationException {
        LossFunctions.LossFunction dl4jLoss;
        if (kerasLoss.equals(conf.getKERAS_LOSS_MEAN_SQUARED_ERROR()) ||
                kerasLoss.equals(conf.getKERAS_LOSS_MSE())) {
            dl4jLoss = LossFunctions.LossFunction.SQUARED_LOSS;
        } else if (kerasLoss.equals(conf.getKERAS_LOSS_MEAN_ABSOLUTE_ERROR()) ||
                kerasLoss.equals(conf.getKERAS_LOSS_MAE())) {
            dl4jLoss = LossFunctions.LossFunction.MEAN_ABSOLUTE_ERROR;
        } else if (kerasLoss.equals(conf.getKERAS_LOSS_MEAN_ABSOLUTE_PERCENTAGE_ERROR()) ||
                kerasLoss.equals(conf.getKERAS_LOSS_MAPE())) {
            dl4jLoss = LossFunctions.LossFunction.MEAN_ABSOLUTE_PERCENTAGE_ERROR;
        } else if (kerasLoss.equals(conf.getKERAS_LOSS_MEAN_SQUARED_LOGARITHMIC_ERROR()) ||
                kerasLoss.equals(conf.getKERAS_LOSS_MSLE())) {
            dl4jLoss = LossFunctions.LossFunction.MEAN_SQUARED_LOGARITHMIC_ERROR;
        } else if (kerasLoss.equals(conf.getKERAS_LOSS_SQUARED_HINGE())) {
            dl4jLoss = LossFunctions.LossFunction.SQUARED_HINGE;
        } else if (kerasLoss.equals(conf.getKERAS_LOSS_HINGE())) {
            dl4jLoss = LossFunctions.LossFunction.HINGE;
        } else if (kerasLoss.equals(conf.getKERAS_LOSS_SPARSE_CATEGORICAL_CROSSENTROPY())) {
            throw new UnsupportedKerasConfigurationException(""Loss function "" + kerasLoss + "" not supported yet."");
        } else if (kerasLoss.equals(conf.getKERAS_LOSS_BINARY_CROSSENTROPY())) {
            dl4jLoss = LossFunctions.LossFunction.XENT;
        } else if (kerasLoss.equals(conf.getKERAS_LOSS_CATEGORICAL_CROSSENTROPY())) {
            dl4jLoss = LossFunctions.LossFunction.MCXENT;
        } else if (kerasLoss.equals(conf.getKERAS_LOSS_KULLBACK_LEIBLER_DIVERGENCE()) ||
                kerasLoss.equals(conf.getKERAS_LOSS_KLD())) {
            dl4jLoss = LossFunctions.LossFunction.KL_DIVERGENCE;
        } else if (kerasLoss.equals(conf.getKERAS_LOSS_POISSON())) {
            dl4jLoss = LossFunctions.LossFunction.POISSON;
        } else if (kerasLoss.equals(conf.getKERAS_LOSS_COSINE_PROXIMITY())) {
            dl4jLoss = LossFunctions.LossFunction.COSINE_PROXIMITY;
        } else {
            throw new UnsupportedKerasConfigurationException(""Unknown Keras loss function "" + kerasLoss);
        }
        return dl4jLoss;
    }"
"public void initIdGenerator() {
    if (idGenerator == null) {
      CommandExecutor idGeneratorCommandExecutor = null;
      if (idGeneratorDataSource != null) {
        ProcessEngineConfigurationImpl processEngineConfiguration = new StandaloneProcessEngineConfiguration();
        processEngineConfiguration.setDataSource(idGeneratorDataSource);
        processEngineConfiguration.setDatabaseSchemaUpdate(DB_SCHEMA_UPDATE_FALSE);
        processEngineConfiguration.init();
        idGeneratorCommandExecutor = processEngineConfiguration.getCommandExecutor();
      } else if (idGeneratorDataSourceJndiName != null) {
        ProcessEngineConfigurationImpl processEngineConfiguration = new StandaloneProcessEngineConfiguration();
        processEngineConfiguration.setDataSourceJndiName(idGeneratorDataSourceJndiName);
        processEngineConfiguration.setDatabaseSchemaUpdate(DB_SCHEMA_UPDATE_FALSE);
        processEngineConfiguration.init();
        idGeneratorCommandExecutor = processEngineConfiguration.getCommandExecutor();
      } else {
        idGeneratorCommandExecutor = getCommandExecutor();
      }

      DbIdGenerator dbIdGenerator = new DbIdGenerator();
      dbIdGenerator.setIdBlockSize(idBlockSize);
      dbIdGenerator.setCommandExecutor(idGeneratorCommandExecutor);
      dbIdGenerator.setCommandConfig(getDefaultCommandConfig().transactionRequiresNew());
      idGenerator = dbIdGenerator;
    }
  }"
"public void execute(@Param(""clusterId"") Long clusterId, Context context, Navigator nav) throws Exception {
        AutoKeeperCluster autoKeeperCluster = autoKeeperClusterService.findAutoKeeperClusterById(clusterId);

        context.put(""autoKeeperCluster"", autoKeeperCluster);
    }"
"public static TypeSerializerSnapshot<?>[] snapshotBackwardsCompatible(
			TypeSerializer<?>... originatingSerializers) {

		return Arrays.stream(originatingSerializers)
				.map(TypeSerializerUtils::snapshotBackwardsCompatible)
				.toArray(TypeSerializerSnapshot[]::new);
	}"
"public int transition(char c, int from)
    {
        int b = from;
        int p;

        p = b + (int) (c) + 1;
        if (b == check[p])
            b = base[p];
        else
            return -1;

        return b;
    }"
"static void handle(ChannelHandlerContext ctx, Http2Connection connection,
                              Http2FrameListener listener, FullHttpMessage message) throws Http2Exception {
        try {
            int streamId = getStreamId(connection, message.headers());
            Http2Stream stream = connection.stream(streamId);
            if (stream == null) {
                stream = connection.remote().createStream(streamId, false);
            }
            message.headers().set(HttpConversionUtil.ExtensionHeaderNames.SCHEME.text(), HttpScheme.HTTP.name());
            Http2Headers messageHeaders = HttpConversionUtil.toHttp2Headers(message, true);
            boolean hasContent = message.content().isReadable();
            boolean hasTrailers = !message.trailingHeaders().isEmpty();
            listener.onHeadersRead(
                    ctx, streamId, messageHeaders, 0, !(hasContent || hasTrailers));
            if (hasContent) {
                listener.onDataRead(ctx, streamId, message.content(), 0, !hasTrailers);
            }
            if (hasTrailers) {
                Http2Headers headers = HttpConversionUtil.toHttp2Headers(message.trailingHeaders(), true);
                listener.onHeadersRead(ctx, streamId, headers, 0, true);
            }
            stream.closeRemoteSide();
        } finally {
            message.release();
        }
    }"
"public <T> T addMaybeStartStartCloseInstance(T o, Stage stage) throws Exception
  {
    addMaybeStartHandler(new StartCloseHandler(o), stage);
    return o;
  }"
"public static List<SingleLogoutRequest> getLogoutRequests(final RequestContext context) {
        return (List<SingleLogoutRequest>) context.getFlowScope().get(PARAMETER_LOGOUT_REQUESTS);
    }"
"public final AutoBuffer writeJSON_impl(AutoBuffer ab) {
    boolean isOut = direction == API.Direction.OUTPUT;
    ab.putJSONStr(""name"", name);                                      ab.put1(',');
    ab.putJSONStr(""type"", type);                                      ab.put1(',');
    ab.putJSONStrUnquoted(""is_schema"", is_schema ? ""true"" : ""false""); ab.put1(',');
    ab.putJSONStr(""schema_name"", schema_name);                        ab.put1(',');

    if (value instanceof IcedWrapper) {
      ab.putJSONStr(""value"").put1(':');
      ((IcedWrapper) value).writeUnwrappedJSON(ab);                   ab.put1(',');
    } else {
      ab.putJSONStr(""value"").put1(':').putJSON(value);                ab.put1(',');
    }

    ab.putJSONStr(""help"", help);                                      ab.put1(',');
    ab.putJSONStr(""label"", label);                                    ab.put1(',');
    ab.putJSONStrUnquoted(""required"", isOut? ""null"" : required ? ""true"" : ""false"");   ab.put1(',');
    ab.putJSONStr(""level"", level.toString());                         ab.put1(',');
    ab.putJSONStr(""direction"", direction.toString());                 ab.put1(',');
    ab.putJSONStrUnquoted(""is_inherited"", is_inherited ? ""true"" : ""false""); ab.put1(',');
    ab.putJSONStr(""inherited_from"", inherited_from); ab.put1(',');
    ab.putJSONStrUnquoted(""is_gridable"", isOut? ""null"" : is_gridable ? ""true"" : ""false""); ab.put1(',');
    ab.putJSONAStr(""values"", values);                                 ab.put1(',');
    ab.putJSONStrUnquoted(""json"", json ? ""true"" : ""false"");           ab.put1(',');
    ab.putJSONAStr(""is_member_of_frames"", is_member_of_frames);       ab.put1(',');
    ab.putJSONAStr(""is_mutually_exclusive_with"", is_mutually_exclusive_with);
    return ab;
  }"
"void markSuccess() {
    // It's possible that the dag is killed before this method is called.
    assertRunningOrKilling();
    changeStatus(Status.SUCCESS);
    for (final Node child : this.children) {
      child.runIfAllowed();
    }
    this.dag.updateDagStatus();
  }"
"public String getRawMasterDataSourceName(final String dataSourceName) {
        for (MasterSlaveRuleConfiguration each : shardingRuleConfig.getMasterSlaveRuleConfigs()) {
            if (each.getName().equals(dataSourceName)) {
                return each.getMasterDataSourceName();
            }
        }
        return dataSourceName;
    }"
"private void initListeners() {
        listViewProperty().addListener((listObj, oldList, newList) -> {
            if (newList != null) {
                if (getListView() instanceof JFXListView) {
                    ((JFXListView<?>) newList).currentVerticalGapProperty().addListener((o, oldVal, newVal) -> {
                        cellRippler.rippler.setClip(null);
                        if (newVal.doubleValue() != 0) {
                            playExpandAnimation = true;
                            getListView().requestLayout();
                        } else {
                            // fake expand state
                            double gap = clip.getY() * 2;
                            gapAnimation = new Timeline(
                                new KeyFrame(Duration.millis(240),
                                    new KeyValue(this.translateYProperty(),
                                        -gap / 2 - (gap * (getIndex())),
                                        Interpolator.EASE_BOTH)
                                ));
                            gapAnimation.play();
                            gapAnimation.setOnFinished((finish) -> {
                                requestLayout();
                                Platform.runLater(() -> getListView().requestLayout());
                            });
                        }
                    });

                    selectedProperty().addListener((o, oldVal, newVal) -> {
                        if (newVal) {
                            selectionChanged = true;
                        }
                    });
                }"
"public final SearchIndexBuilder extendSearchIndex(SearchIndexBuilder sib) {
        if (asJob().isBuildable() && asJob().hasPermission(Item.BUILD)) {
            sib.add(""build"", ""build"");
        }
        return sib;
    }"
"public SDVariable min(String name, boolean keepDims, int... dimensions){
        return sameDiff.min(name, this, keepDims, dimensions);
    }"
"@Override
    public void save() throws IOException {
        if (BulkChange.contains(this)) {
            return;
        }
        final File nodesDir = getNodesDir();
        final Set<String> existing = new HashSet<>();
        for (Node n : nodes.values()) {
            if (n instanceof EphemeralNode) {
                continue;
            }
            existing.add(n.getNodeName());
            XmlFile xmlFile = new XmlFile(Jenkins.XSTREAM, new File(new File(nodesDir, n.getNodeName()), ""config.xml""));
            xmlFile.write(n);
            SaveableListener.fireOnChange(this, xmlFile);
        }
        for (File forDeletion : nodesDir.listFiles(new FileFilter() {
            @Override
            public boolean accept(File pathname) {
                return pathname.isDirectory() && !existing.contains(pathname.getName());
            }
        })) {
            Util.deleteRecursive(forDeletion);
        }
    }"
"@Override
    public boolean canRetry(Throwable exception) {
        if (exception == null) {
            return false;
        }

        Class<? extends Throwable> exceptionClass = exception.getClass();
        if (hasIncludes && !includes.contains(exceptionClass)) {
            return false;
        } else if (hasExcludes && excludes.contains(exceptionClass)) {
            return false;
        } else {
            return this.attemptNumber.incrementAndGet() < (maxAttempts + 1) && ((maxDelay == null) || overallDelay.get() < maxDelay.toMillis());
        }
    }"
"public void addHeader(String name, String val) {
        mMsgHeader = mMsgHeader + name + "": "" + val + mLineDelimiter;
        addInternalHeaderFields(name, val);
    }"
"public static byte[] toByteArray(Serializable toSave) {
        try {
            ByteArrayOutputStream bos = new ByteArrayOutputStream();
            ObjectOutputStream os = new ObjectOutputStream(bos);
            os.writeObject(toSave);
            byte[] ret = bos.toByteArray();
            os.close();
            return ret;
        } catch (Exception e) {
            throw new RuntimeException(e);
        }

    }"
"public Vector predict(Vector point) {
        return MLLibUtil.toVector(network.output(MLLibUtil.toVector(point)));
    }"
"public void registerKvState(KeyGroupRange keyGroupRange, KvStateID kvStateId, InetSocketAddress kvStateAddress) {

		if (keyGroupRange.getStartKeyGroup() < 0 || keyGroupRange.getEndKeyGroup() >= numKeyGroups) {
			throw new IndexOutOfBoundsException(""Key group index"");
		}

		for (int kgIdx = keyGroupRange.getStartKeyGroup(); kgIdx <= keyGroupRange.getEndKeyGroup(); ++kgIdx) {

			if (kvStateIds[kgIdx] == null && kvStateAddresses[kgIdx] == null) {
				numRegisteredKeyGroups++;
			}

			kvStateIds[kgIdx] = kvStateId;
			kvStateAddresses[kgIdx] = kvStateAddress;
		}
	}"
"private byte[] decrypt(byte[] in, int inOff, int inLen) {
		// 获取曲线点
		final byte[] c1 = new byte[this.curveLength * 2 + 1];
		System.arraycopy(in, inOff, c1, 0, c1.length);

		ECPoint c1P = this.ecParams.getCurve().decodePoint(c1);
		if (c1P.multiply(this.ecParams.getH()).isInfinity()) {
			throw new CryptoException(""[h]C1 at infinity"");
		}
		c1P = c1P.multiply(((ECPrivateKeyParameters) ecKey).getD()).normalize();

		final int digestSize = this.digest.getDigestSize();

		// 解密C2数据
		final byte[] c2 = new byte[inLen - c1.length - digestSize];

		if (SM2Mode.C1C3C2 == this.mode) {
			// C2位于第三部分
			System.arraycopy(in, inOff + c1.length + digestSize, c2, 0, c2.length);
		} else {
			// C2位于第二部分
			System.arraycopy(in, inOff + c1.length, c2, 0, c2.length);
		}
		kdf(c1P, c2);

		// 使用摘要验证C2数据
		final byte[] c3 = new byte[digestSize];

		addFieldElement(c1P.getAffineXCoord());
		this.digest.update(c2, 0, c2.length);
		addFieldElement(c1P.getAffineYCoord());
		this.digest.doFinal(c3, 0);

		int check = 0;
		for (int i = 0; i != c3.length; i++) {
			check |= c3[i] ^ in[inOff + c1.length + ((SM2Mode.C1C3C2 == this.mode) ? 0 : c2.length) + i];
		}

		Arrays.fill(c1, (byte) 0);
		Arrays.fill(c3, (byte) 0);

		if (check != 0) {
			Arrays.fill(c2, (byte) 0);
			throw new CryptoException(""invalid cipher text"");
		}

		return c2;
	}"
"public double removeKey(T element) {
        AtomicDouble v = map.remove(element);
        dirty.set(true);

        if (v != null)
            return v.get();
        else
            return 0.0;
    }"
"private byte[] validateChallenge(byte[] nonce, byte[] encryptedChallenge)
    throws GeneralSecurityException {

    byte[] challenge = decrypt(encryptedChallenge);
    checkSubArray(appId, challenge, 0);
    checkSubArray(nonce, challenge, appId.length);
    return Arrays.copyOfRange(challenge, appId.length + nonce.length, challenge.length);
  }"
"public void setApplicationContextClass(
			Class<? extends ConfigurableApplicationContext> applicationContextClass) {
		this.applicationContextClass = applicationContextClass;
		this.webApplicationType = WebApplicationType
				.deduceFromApplicationContext(applicationContextClass);
	}"
"protected void putResolvedEventsAsAttribute(final RequestContext context, final Set<Event> resolvedEvents) {
        context.getAttributes().put(RESOLVED_AUTHENTICATION_EVENTS, resolvedEvents);
    }"
"public static NavigableMap<String, Integer> loadVocab(InputStream is) throws IOException {
        final TreeMap<String, Integer> map = new TreeMap<>(Collections.reverseOrder());

        try (final BufferedReader reader = new BufferedReader(new InputStreamReader(is))) {
            String token;
            int i = 0;
            while ((token = reader.readLine()) != null) {
                map.put(token, i++);
            }
        }

        return map;
    }"
"public INDArray outputSingle(MultiDataSetIterator iterator){
        Preconditions.checkArgument(numOutputArrays == 1, ""Cannot use this method with nets that have more"" +
                "" than 1 output array. This network has %s outputs"", numOutputArrays);
        return output(iterator)[0];
    }"
"public Graph<KB, VVB, Projection<KT, VVT, VVB, EV>> projectionBottomFull() {
		DataSet<Tuple5<KT, KB, EV, VVT, VVB>> edgesWithVertices	= joinEdgeWithVertices();

		DataSet<Edge<KB, Projection<KT, VVT, VVB, EV>>> newEdges = edgesWithVertices.join(edgesWithVertices)
			.where(0)
			.equalTo(0)
			.with(new ProjectionBottomFull<>())
				.name(""Full bottom projection"");

		return Graph.fromDataSet(bottomVertices, newEdges, context);
	}"
"public CorsConfig build() {
        if (preflightHeaders.isEmpty() && !noPreflightHeaders) {
            preflightHeaders.put(HttpHeaderNames.DATE, DateValueGenerator.INSTANCE);
            preflightHeaders.put(HttpHeaderNames.CONTENT_LENGTH, new ConstantValueGenerator(""0""));
        }
        return new CorsConfig(this);
    }"
"protected void logKeyFound(String key, PropertySource<?> propertySource, Object value) {
        if (logger.isDebugEnabled()) {
            logger.debug(""Found key '"" + key + ""' in PropertySource '"" + propertySource.getName()
                         + ""' with value of type "" + value.getClass().getSimpleName());
        }
    }"
"public static String getParent(String filePath, int level) {
		final File parent = getParent(file(filePath), level);
		try {
			return null == parent ? null : parent.getCanonicalPath();
		} catch (IOException e) {
			throw new IORuntimeException(e);
		}
	}"
"public RegistryConfig setParameters(Map<String, String> parameters) {
        if (this.parameters == null) {
            this.parameters = new ConcurrentHashMap<String, String>();
            this.parameters.putAll(parameters);
        }
        return this;
    }"
"@Override
	public JSONObject put(String key, Object value) throws JSONException {
		if (null == key) {
			return this;
		}

		final boolean ignoreNullValue = this.config.isIgnoreNullValue();
		if (ObjectUtil.isNull(value) && ignoreNullValue) {
			// 忽略值模式下如果值为空清除key
			this.remove(key);
		} else {
			InternalJSONUtil.testValidity(value);
			this.rawHashMap.put(key, JSONUtil.wrap(value, ignoreNullValue));
		}
		return this;
	}"
"@SuppressWarnings({""ConstantConditions"", ""deprecation""})
    @SuppressFBWarnings(""RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE"")
    public boolean replaceActions(@Nonnull Class<? extends Action> clazz, @Nonnull Action a) {
        if (clazz == null) {
            throw new IllegalArgumentException(""Action type must be non-null"");
        }
        if (a == null) {
            throw new IllegalArgumentException(""Action must be non-null"");
        }
        // CopyOnWriteArrayList does not support Iterator.remove, so need to do it this way:
        List<Action> old = new ArrayList<>();
        List<Action> current = getActions();
        boolean found = false;
        for (Action a1 : current) {
            if (!found) {
                if (a.equals(a1)) {
                    found = true;
                } else if (clazz.isInstance(a1)) {
                    old.add(a1);
                }
            } else if (clazz.isInstance(a1) && !a.equals(a1)) {
                old.add(a1);
            }
        }
        current.removeAll(old);
        if (!found) {
            addAction(a);
        }
        return !(old.isEmpty() && found);
    }"
"public void rnnClearPreviousState() {
        if (layers == null)
            return;
        for (int i = 0; i < layers.length; i++) {
            if (layers[i] instanceof RecurrentLayer)
                ((RecurrentLayer) layers[i]).rnnClearPreviousState();
            else if (layers[i] instanceof MultiLayerNetwork) {
                ((MultiLayerNetwork) layers[i]).rnnClearPreviousState();
            } else if(layers[i] instanceof BaseWrapperLayer && ((BaseWrapperLayer)layers[i]).getUnderlying() instanceof RecurrentLayer){
                ((RecurrentLayer) ((BaseWrapperLayer)layers[i]).getUnderlying()).rnnClearPreviousState();
            }
        }
    }"
"private JCheckBox getChkParseSVNEntries() {
		if (parseSVNEntries == null) {
			parseSVNEntries = new JCheckBox();
			parseSVNEntries.setText(Constant.messages.getString(""spider.options.label.svnentries""));
		}
		return parseSVNEntries;
	}"
"private void doReconnect() {
        String interfaceId = consumerConfig.getInterfaceId();
        String appName = consumerConfig.getAppName();
        int thisTime = reconnectFlag.incrementAndGet();
        boolean print = thisTime % 6 == 0; //是否打印error,每6次打印一次
        boolean isAliveEmptyFirst = isAvailableEmpty();
        // 检查可用连接  todo subHealth
        for (Map.Entry<ProviderInfo, ClientTransport> alive : aliveConnections.entrySet()) {
            ClientTransport connection = alive.getValue();
            if (connection != null && !connection.isAvailable()) {
                aliveToRetry(alive.getKey(), connection);
            }
        }
        for (Map.Entry<ProviderInfo, ClientTransport> entry : getRetryConnections()
            .entrySet()) {
            ProviderInfo providerInfo = entry.getKey();
            int providerPeriodCoefficient = CommonUtils.parseNum((Integer)
                providerInfo.getDynamicAttr(ProviderInfoAttrs.ATTR_RC_PERIOD_COEFFICIENT), 1);
            if (thisTime % providerPeriodCoefficient != 0) {
                continue; // 如果命中重连周期，则进行重连
            }
            ClientTransport transport = entry.getValue();
            if (LOGGER.isDebugEnabled(appName)) {
                LOGGER.debugWithApp(appName, ""Retry connect to {} provider:{} ..."", interfaceId, providerInfo);
            }
            try {
                transport.connect();
                if (doubleCheck(interfaceId, providerInfo, transport)) {
                    providerInfo.setDynamicAttr(ProviderInfoAttrs.ATTR_RC_PERIOD_COEFFICIENT, 1);
                    retryToAlive(providerInfo, transport);
                }
            } catch (Exception e) {
                if (print) {
                    if (LOGGER.isWarnEnabled(appName)) {
                        LOGGER.warnWithApp(appName, ""Retry connect to {} provider:{} error ! The exception is "" + e
                            .getMessage(), interfaceId, providerInfo);
                    }
                } else {
                    if (LOGGER.isDebugEnabled(appName)) {
                        LOGGER.debugWithApp(appName, ""Retry connect to {} provider:{} error ! The exception is "" + e
                            .getMessage(), interfaceId, providerInfo);
                    }
                }
            }
        }
        if (isAliveEmptyFirst && !isAvailableEmpty()) { // 原来空，变成不空
            notifyStateChangeToAvailable();
        }
    }"
"public static int bytesToCodePoint(ByteBuffer bytes) {
        bytes.mark();
        byte b = bytes.get();
        bytes.reset();
        int extraBytesToRead = bytesFromUTF8[(b & 0xFF)];
        if (extraBytesToRead < 0)
            return -1; // trailing byte!
        int ch = 0;

        switch (extraBytesToRead) {
            case 5:
                ch += (bytes.get() & 0xFF);
                ch <<= 6; /* remember, illegal UTF-8 */
            case 4:
                ch += (bytes.get() & 0xFF);
                ch <<= 6; /* remember, illegal UTF-8 */
            case 3:
                ch += (bytes.get() & 0xFF);
                ch <<= 6;
            case 2:
                ch += (bytes.get() & 0xFF);
                ch <<= 6;
            case 1:
                ch += (bytes.get() & 0xFF);
                ch <<= 6;
            case 0:
                ch += (bytes.get() & 0xFF);
        }
        ch -= offsetsFromUTF8[extraBytesToRead];

        return ch;
    }"
"@SuppressWarnings(""unused"") // called through reflection by RequestServer
  public ModelMetricsMakerSchemaV3 make(int version, ModelMetricsMakerSchemaV3 s) {
    // parameters checking:
    if (null == s.predictions_frame) throw new H2OIllegalArgumentException(""predictions_frame"", ""make"", s.predictions_frame);
    Frame pred = DKV.getGet(s.predictions_frame);
    if (null == pred) throw new H2OKeyNotFoundArgumentException(""predictions_frame"", ""make"", s.predictions_frame);

    if (null == s.actuals_frame) throw new H2OIllegalArgumentException(""actuals_frame"", ""make"", s.actuals_frame);
    Frame act = DKV.getGet(s.actuals_frame);
    if (null == act) throw new H2OKeyNotFoundArgumentException(""actuals_frame"", ""make"", s.actuals_frame);

    if (s.domain ==null) {
      if (pred.numCols()!=1) {
        throw new H2OIllegalArgumentException(""predictions_frame"", ""make"", ""For regression problems (domain=null), the predictions_frame must have exactly 1 column."");
      }
      ModelMetricsRegression mm = ModelMetricsRegression.make(pred.anyVec(), act.anyVec(), s.distribution);
      s.model_metrics = new ModelMetricsRegressionV3().fillFromImpl(mm);
    } else if (s.domain.length==2) {
      if (pred.numCols()!=1) {
        throw new H2OIllegalArgumentException(""predictions_frame"", ""make"", ""For domains with 2 class labels, the predictions_frame must have exactly one column containing the class-1 probabilities."");
      }
      ModelMetricsBinomial mm = ModelMetricsBinomial.make(pred.anyVec(), act.anyVec(), s.domain);
      s.model_metrics = new ModelMetricsBinomialV3().fillFromImpl(mm);
    } else if (s.domain.length>2){
      if (pred.numCols()!=s.domain.length) {
        throw new H2OIllegalArgumentException(""predictions_frame"", ""make"", ""For domains with "" + s.domain.length + "" class labels, the predictions_frame must have exactly "" + s.domain.length + "" columns containing the class-probabilities."");
      }

      if (s.distribution == DistributionFamily.ordinal) {
        ModelMetricsOrdinal mm = ModelMetricsOrdinal.make(pred, act.anyVec(), s.domain);
        s.model_metrics = new ModelMetricsOrdinalV3().fillFromImpl(mm);
      } else {
        ModelMetricsMultinomial mm = ModelMetricsMultinomial.make(pred, act.anyVec(), s.domain);
        s.model_metrics = new ModelMetricsMultinomialV3().fillFromImpl(mm);
      }
    } else {
      throw H2O.unimpl();
    }
    return s;
  }"
"private static void handleLegacyWeightInitFromJson(String json, Layer layer, ObjectMapper mapper, JsonNode vertices) {
        if (layer instanceof BaseLayer && ((BaseLayer) layer).getWeightInitFn() == null) {
            String layerName = layer.getLayerName();

            try {
                if (vertices == null) {
                    JsonNode jsonNode = mapper.readTree(json);
                    vertices = jsonNode.get(""vertices"");
                }

                JsonNode vertexNode = vertices.get(layerName);
                JsonNode layerVertexNode = vertexNode.get(""LayerVertex"");
                if (layerVertexNode == null || !layerVertexNode.has(""layerConf"")
                        || !layerVertexNode.get(""layerConf"").has(""layer"")) {
                    return;
                }
                JsonNode layerWrapperNode = layerVertexNode.get(""layerConf"").get(""layer"");

                if (layerWrapperNode == null || layerWrapperNode.size() != 1) {
                    return;
                }

                JsonNode layerNode = layerWrapperNode.elements().next();
                JsonNode weightInit = layerNode.get(""weightInit""); //Should only have 1 element: ""dense"", ""output"", etc
                JsonNode distribution = layerNode.get(""dist"");

                Distribution dist = null;
                if(distribution != null) {
                    dist = mapper.treeToValue(distribution, Distribution.class);
                }

                if (weightInit != null) {
                    final IWeightInit wi = WeightInit.valueOf(weightInit.asText()).getWeightInitFunction(dist);
                    ((BaseLayer) layer).setWeightInitFn(wi);
                }

            } catch (IOException e) {
                log.warn(""Layer with null ActivationFn field or pre-0.7.2 activation function detected: could not parse JSON"",
                        e);
            }
        }
    }"
"@NonNull
  public Caffeine<K, V> refreshAfterWrite(@NonNull Duration duration) {
    return refreshAfterWrite(duration.toNanos(), TimeUnit.NANOSECONDS);
  }"
"public static List<Item> normalizeFrequency(List<Item> itemList)
    {
        for (Item item : itemList)
        {
            ArrayList<Map.Entry<String, Integer>> entryArray = new ArrayList<Map.Entry<String, Integer>>(item.labelMap.entrySet());
            Collections.sort(entryArray, new Comparator<Map.Entry<String, Integer>>()
            {
                @Override
                public int compare(Map.Entry<String, Integer> o1, Map.Entry<String, Integer> o2)
                {
                    return o1.getValue().compareTo(o2.getValue());
                }
            });
            int index = 1;
            for (Map.Entry<String, Integer> pair : entryArray)
            {
                item.labelMap.put(pair.getKey(), index);
                ++index;
            }
        }
        return itemList;
    }"
"@SuppressWarnings(""deprecation"")
    public static ByteBuf writeShortBE(ByteBuf buf, int shortValue) {
        return buf.order() == ByteOrder.BIG_ENDIAN? buf.writeShort(shortValue) : buf.writeShortLE(shortValue);
    }"
"@Setup
    public void setup() {
        System.setProperty(""io.netty.buffer.checkAccessible"", checkAccessible);
        System.setProperty(""io.netty.buffer.checkBounds"", checkBounds);
        buffer = bufferType.newBuffer();
    }"
"@RequirePOST
    public HttpResponse doApprove(@QueryParameter String value) throws IOException {
        whitelisted.append(value);
        return HttpResponses.ok();
    }"
"public static LogEvent prepareLogEvent(final LogEvent logEvent) {
        val messageModified = TicketIdSanitizationUtils.sanitize(logEvent.getMessage().getFormattedMessage());
        val message = new SimpleMessage(messageModified);
        val newLogEventBuilder = Log4jLogEvent.newBuilder()
            .setLevel(logEvent.getLevel())
            .setLoggerName(logEvent.getLoggerName())
            .setLoggerFqcn(logEvent.getLoggerFqcn())
            .setContextData(new SortedArrayStringMap(logEvent.getContextData()))
            .setContextStack(logEvent.getContextStack())
            .setEndOfBatch(logEvent.isEndOfBatch())
            .setIncludeLocation(logEvent.isIncludeLocation())
            .setMarker(logEvent.getMarker())
            .setMessage(message)
            .setNanoTime(logEvent.getNanoTime())
            .setThreadName(logEvent.getThreadName())
            .setThrownProxy(logEvent.getThrownProxy())
            .setThrown(logEvent.getThrown())
            .setTimeMillis(logEvent.getTimeMillis());

        try {
            newLogEventBuilder.setSource(logEvent.getSource());
        } catch (final Exception e) {
            newLogEventBuilder.setSource(null);
        }
        return newLogEventBuilder.build();
    }"
"public static boolean isMacValid(byte[] expected, byte[] input, byte[] key) {
		byte[] actual = hmacSha1(input, key);
		return Arrays.equals(expected, actual);
	}"
"protected final void addDefaultServlet(WebAppContext context) {
		Assert.notNull(context, ""Context must not be null"");
		ServletHolder holder = new ServletHolder();
		holder.setName(""default"");
		holder.setClassName(""org.eclipse.jetty.servlet.DefaultServlet"");
		holder.setInitParameter(""dirAllowed"", ""false"");
		holder.setInitOrder(1);
		context.getServletHandler().addServletWithMapping(holder, ""/"");
		context.getServletHandler().getServletMapping(""/"").setDefault(true);
	}"
"public void snapshotState(StateSnapshotContext context) throws Exception {
		final KeyedStateBackend<?> keyedStateBackend = getKeyedStateBackend();
		//TODO all of this can be removed once heap-based timers are integrated with RocksDB incremental snapshots
		if (keyedStateBackend instanceof AbstractKeyedStateBackend &&
			((AbstractKeyedStateBackend<?>) keyedStateBackend).requiresLegacySynchronousTimerSnapshots()) {

			KeyedStateCheckpointOutputStream out;

			try {
				out = context.getRawKeyedOperatorStateOutput();
			} catch (Exception exception) {
				throw new Exception(""Could not open raw keyed operator state stream for "" +
					getOperatorName() + '.', exception);
			}

			try {
				KeyGroupsList allKeyGroups = out.getKeyGroupList();
				for (int keyGroupIdx : allKeyGroups) {
					out.startNewKeyGroup(keyGroupIdx);

					timeServiceManager.snapshotStateForKeyGroup(
						new DataOutputViewStreamWrapper(out), keyGroupIdx);
				}
			} catch (Exception exception) {
				throw new Exception(""Could not write timer service of "" + getOperatorName() +
					"" to checkpoint state stream."", exception);
			} finally {
				try {
					out.close();
				} catch (Exception closeException) {
					LOG.warn(""Could not close raw keyed operator state stream for {}. This "" +
						""might have prevented deleting some state data."", getOperatorName(), closeException);
				}
			}
		}
	}"
"long recordRead(int bufferIndex, Node<K, V> node) {
        // The location in the buffer is chosen in a racy fashion as the increment
        // is not atomic with the insertion. This means that concurrent reads can
        // overlap and overwrite one another, resulting in a lossy buffer.
        final AtomicLong counter = readBufferWriteCount[bufferIndex];
        final long writeCount = counter.get();
        counter.lazySet(writeCount + 1);

        final int index = (int) (writeCount & READ_BUFFER_INDEX_MASK);
        readBuffers[bufferIndex][index].lazySet(node);

        return writeCount;
    }"
"public static <T> Collection<T> addAll(Collection<T> collection, Iterator<T> iterator) {
		if (null != collection && null != iterator) {
			while (iterator.hasNext()) {
				collection.add(iterator.next());
			}
		}
		return collection;
	}"
"private VelocityContext toContext(Map<?, ?> bindingMap) {
		final Map<String, Object> map = Convert.convert(new TypeReference<Map<String, Object>>() {}, bindingMap);
		return new VelocityContext(map);
	}"
"@SuppressWarnings(""unchecked"")
  public <T> boolean applyValueCallback(T property, @Nullable LottieValueCallback<T> callback) {
    if (property == TRANSFORM_ANCHOR_POINT) {
      if (anchorPoint == null) {
        anchorPoint = new ValueCallbackKeyframeAnimation(callback, new PointF());
      } else {
        anchorPoint.setValueCallback((LottieValueCallback<PointF>) callback);
      }
    } else if (property == TRANSFORM_POSITION) {
      if (position == null) {
        position = new ValueCallbackKeyframeAnimation(callback, new PointF());
      } else {
        position.setValueCallback((LottieValueCallback<PointF>) callback);
      }
    } else if (property == TRANSFORM_SCALE) {
      if (scale == null) {
        scale = new ValueCallbackKeyframeAnimation(callback, new ScaleXY());
      } else {
        scale.setValueCallback((LottieValueCallback<ScaleXY>) callback);
      }
    } else if (property == TRANSFORM_ROTATION) {
      if (rotation == null) {
        rotation = new ValueCallbackKeyframeAnimation(callback, 0f);
      } else {
        rotation.setValueCallback((LottieValueCallback<Float>) callback);
      }
    } else if (property == TRANSFORM_OPACITY) {
      if (opacity == null) {
        opacity = new ValueCallbackKeyframeAnimation(callback, 100);
      } else {
        opacity.setValueCallback((LottieValueCallback<Integer>) callback);
      }
    } else if (property == TRANSFORM_START_OPACITY && startOpacity != null) {
      if (startOpacity == null) {
        startOpacity = new ValueCallbackKeyframeAnimation(callback, 100);
      } else {
        startOpacity.setValueCallback((LottieValueCallback<Float>) callback);
      }
    } else if (property == TRANSFORM_END_OPACITY && endOpacity != null) {
      if (endOpacity == null) {
        endOpacity = new ValueCallbackKeyframeAnimation(callback, 100);
      } else {
        endOpacity.setValueCallback((LottieValueCallback<Float>) callback);
      }
    } else if (property == TRANSFORM_SKEW && skew != null) {
      if (skew == null) {
        skew = new FloatKeyframeAnimation(Collections.singletonList(new Keyframe<Float>(0f)));
      }
      skew.setValueCallback((LottieValueCallback<Float>) callback);
    } else if (property == TRANSFORM_SKEW_ANGLE && skewAngle != null) {
      if (skewAngle == null) {
        skewAngle = new FloatKeyframeAnimation(Collections.singletonList(new Keyframe<Float>(0f)));
      }
      skewAngle.setValueCallback((LottieValueCallback<Float>) callback);
    } else {
      return false;
    }
    return true;
  }"
"public Writer write(Writer writer) throws JSONException {
    try {
      boolean b = false;
      int len = length();

      writer.write('[');

      for (int i = 0; i < len; i += 1) {
        if (b) {
          writer.write(',');
        }
        Object v = this.myArrayList.get(i);
        if (v instanceof JSONObject) {
          ((JSONObject) v).write(writer);
        } else if (v instanceof JSONArray) {
          ((JSONArray) v).write(writer);
        } else {
          writer.write(JSONObject.valueToString(v));
        }
        b = true;
      }
      writer.write(']');
      return writer;
    } catch (IOException e) {
      throw new JSONException(e);
    }
  }"
"protected OAuthProviderToken createOAuthToken(ConsumerAuthentication authentication) {
    return getTokenServices().createUnauthorizedRequestToken(authentication.getConsumerDetails().getConsumerKey(),
                                                             authentication.getOAuthParameters().get(OAuthConsumerParameter.oauth_callback.toString()));
  }"
"private void clearAllState(
			W window,
			AppendingState<IN, ACC> windowState,
			MergingWindowSet<W> mergingWindows) throws Exception {
		windowState.clear();
		triggerContext.clear();
		processContext.window = window;
		processContext.clear();
		if (mergingWindows != null) {
			mergingWindows.retireWindow(window);
			mergingWindows.persist();
		}
	}"
"public static ThreadPoolExecutorFactoryBean newThreadPoolExecutorFactoryBean(final long keepAlive,
                                                                                 final long maxSize) {
        val bean = new ThreadPoolExecutorFactoryBean();
        bean.setMaxPoolSize((int) maxSize);
        bean.setKeepAliveSeconds((int) keepAlive);
        return bean;
    }"
"private static int bitsToEncode(int value) {
        int highestOneBit = Integer.highestOneBit(value);
        int bitLength = 0;
        while ((highestOneBit >>= 1) != 0) {
            bitLength++;
        }

        return bitLength;
    }"
"@EachBean(Cluster.Builder.class)
    @Bean(preDestroy = ""close"")
    public Cluster cassandraCluster(Cluster.Builder builder) {
        return builder.build();
    }"
"public static String getStr(Map<?, ?> map, Object key) {
		return get(map, key, String.class);
	}"
"@Nonnull
    @Override
    public Future<?> submit(@Nonnull Runnable runnable) {
        submitted.mark();
        try {
            return delegate.submit(new InstrumentedRunnable(runnable));
        } catch (RejectedExecutionException e) {
            rejected.mark();
            throw e;
        }
    }"
"private ClientConnection createHttpClientConnection(final StreamConnection connection, final OptionMap options, final ByteBufferPool bufferPool) {
		try {
			Class<?> cls = Class.forName(""io.undertow.client.http.HttpClientConnection"");
			
			Constructor<?> o = cls.getDeclaredConstructor(StreamConnection.class, OptionMap.class, ByteBufferPool.class);
			
			o.setAccessible(true);
			
			return (ClientConnection) o.newInstance(connection, options, bufferPool);			
		}catch(Exception e) {
			logger.error(e.getMessage(), e);
		}

		return null;
	}"
"@SuppressWarnings(""unchecked"")
	public void open(File inputFile) throws IOException {
		deserializer = (Deserializer<OUT>) (readAsByteArray ? new ByteArrayDeserializer() : new TupleDeserializer());

		inputFile.getParentFile().mkdirs();

		if (inputFile.exists()) {
			inputFile.delete();
		}
		inputFile.createNewFile();
		inputRAF = new RandomAccessFile(inputFile, ""rw"");
		inputRAF.setLength(mappedFileSizeBytes);
		inputRAF.seek(mappedFileSizeBytes - 1);
		inputRAF.writeByte(0);
		inputRAF.seek(0);
		inputChannel = inputRAF.getChannel();
		fileBuffer = inputChannel.map(FileChannel.MapMode.READ_WRITE, 0, mappedFileSizeBytes);
	}"
"protected void onConnectionError(ChannelHandlerContext ctx, boolean outbound,
                                     Throwable cause, Http2Exception http2Ex) {
        if (http2Ex == null) {
            http2Ex = new Http2Exception(INTERNAL_ERROR, cause.getMessage(), cause);
        }

        ChannelPromise promise = ctx.newPromise();
        ChannelFuture future = goAway(ctx, http2Ex, ctx.newPromise());
        if (http2Ex.shutdownHint() == Http2Exception.ShutdownHint.GRACEFUL_SHUTDOWN) {
            doGracefulShutdown(ctx, future, promise);
        } else {
            future.addListener(new ClosingChannelFutureListener(ctx, promise));
        }
    }"
"public void beginType(String type, String kind, int modifiers,
      String extendsType, String... implementsTypes) throws IOException {
    indent();
    modifiers(modifiers);
    out.write(kind);
    out.write("" "");
    type(type);
    if (extendsType != null) {
      out.write(""\n"");
      indent();
      out.write(""    extends "");
      type(extendsType);
    }
    if (implementsTypes.length > 0) {
      out.write(""\n"");
      indent();
      out.write(""    implements "");
      for (int i = 0; i < implementsTypes.length; i++) {
        if (i != 0) {
          out.write("", "");
        }
        type(implementsTypes[i]);
      }
    }
    out.write("" {\n"");
    pushScope(Scope.TYPE_DECLARATION);
  }"
"private void insert(String binding) {
		currentInput.insert(cursorPos, binding);
		cursorPos += binding.length();

		// reset view
		resetMainPart();
	}"
"protected static void checkNormalWithComma(String configKey, String configValue) throws SofaRpcRuntimeException {
        checkPattern(configKey, configValue, NORMAL_COMMA, ""only allow a-zA-Z0-9 '-' '_' '.' ','"");
    }"
"public static void exportCSVSequenceLocal(File baseDir, JavaRDD<List<List<Writable>>> sequences, long seed)
                    throws Exception {
        baseDir.mkdirs();
        if (!baseDir.isDirectory())
            throw new IllegalArgumentException(""File is not a directory: "" + baseDir.toString());
        String baseDirStr = baseDir.toString();

        List<String> fileContents = sequences.map(new SequenceToStringFunction("","")).collect();
        if (!(fileContents instanceof ArrayList))
            fileContents = new ArrayList<>(fileContents);
        Collections.shuffle(fileContents, new Random(seed));

        int i = 0;
        for (String s : fileContents) {
            String path = FilenameUtils.concat(baseDirStr, i + "".csv"");
            File f = new File(path);
            FileUtils.writeStringToFile(f, s);
            i++;
        }
    }"
"public RouteMatch<?> fulfillArgumentRequirements(RouteMatch<?> route, HttpRequest<?> request, boolean satisfyOptionals) {
        Collection<Argument> requiredArguments = route.getRequiredArguments();
        Map<String, Object> argumentValues;

        if (requiredArguments.isEmpty()) {
            // no required arguments so just execute
            argumentValues = Collections.emptyMap();
        } else {
            argumentValues = new LinkedHashMap<>();
            // Begin try fulfilling the argument requirements
            for (Argument argument : requiredArguments) {
                getValueForArgument(argument, request, satisfyOptionals).ifPresent((value) ->
                    argumentValues.put(argument.getName(), value));
            }
        }

        route = route.fulfill(argumentValues);
        return route;
    }"
"public String get(CharSequence name, String defaultValue) {
        String value = get(name);
        if (value == null) {
            return defaultValue;
        }
        return value;
    }"
"public static byte[][] split(byte[] array, int len) {
		int x = array.length / len;
		int y = array.length % len;
		int z = 0;
		if (y != 0) {
			z = 1;
		}
		byte[][] arrays = new byte[x + z][];
		byte[] arr;
		for (int i = 0; i < x + z; i++) {
			arr = new byte[len];
			if (i == x + z - 1 && y != 0) {
				System.arraycopy(array, i * len, arr, 0, y);
			} else {
				System.arraycopy(array, i * len, arr, 0, len);
			}
			arrays[i] = arr;
		}
		return arrays;
	}"
"public static Object[] expandArgs(MockitoMethod method, Object[] args) {
        int nParams = method.getParameterTypes().length;
        if (args != null && args.length > nParams)
            args = Arrays.copyOf(args, nParams); // drop extra args (currently -- Kotlin continuation synthetic arg)
        return expandVarArgs(method.isVarArgs(), args);
    }"
"public static int copy(File in, File out) throws IOException {
        assert in != null : ""No input File specified"";
        assert out != null : ""No output File specified"";
        return copy(new BufferedInputStream(Files.newInputStream(in.toPath())),
            new BufferedOutputStream(Files.newOutputStream(out.toPath())));
    }"
"public static String dateSub(String dateStr, int days, TimeZone tz) {
		long ts = parseToTimeMillis(dateStr, tz);
		if (ts == Long.MIN_VALUE) {
			return null;
		}
		return dateSub(ts, days, tz);
	}"
"public static void load(String coreStopWordDictionaryPath, boolean loadCacheIfPossible)
    {
        ByteArray byteArray = loadCacheIfPossible ? ByteArray.createByteArray(coreStopWordDictionaryPath + Predefine.BIN_EXT) : null;
        if (byteArray == null)
        {
            try
            {
                dictionary = new StopWordDictionary(HanLP.Config.CoreStopWordDictionaryPath);
                DataOutputStream out = new DataOutputStream(new BufferedOutputStream(IOUtil.newOutputStream(HanLP.Config.CoreStopWordDictionaryPath + Predefine.BIN_EXT)));
                dictionary.save(out);
                out.close();
            }
            catch (Exception e)
            {
                logger.severe(""载入停用词词典"" + HanLP.Config.CoreStopWordDictionaryPath + ""失败""  + TextUtility.exceptionToString(e));
                throw new RuntimeException(""载入停用词词典"" + HanLP.Config.CoreStopWordDictionaryPath + ""失败"");
            }
        }
        else
        {
            dictionary = new StopWordDictionary();
            dictionary.load(byteArray);
        }
    }"
"public static boolean doesResourceExist(final String resource, final ResourceLoader resourceLoader) {
        try {
            if (StringUtils.isNotBlank(resource)) {
                val res = resourceLoader.getResource(resource);
                return doesResourceExist(res);
            }
        } catch (final Exception e) {
            LOGGER.warn(e.getMessage(), e);
        }
        return false;
    }"
"public void printGraph() {
        for (Term term : terms) {
            if (term == null) {
                continue;
            }
            System.out.print(term.getName() + ""\t"" + term.score() + "" ,"");
            while ((term = term.next()) != null) {
                System.out.print(term + ""\t"" + term.score() + "" ,"");
            }
            System.out.println();
        }
    }"
"public DataSink<T> write(FileOutputFormat<T> outputFormat, String filePath) {
		Preconditions.checkNotNull(filePath, ""File path must not be null."");
		Preconditions.checkNotNull(outputFormat, ""Output format must not be null."");

		outputFormat.setOutputFilePath(new Path(filePath));
		return output(outputFormat);
	}"
"public static FileUtils.FileCopyResult gunzip(final File pulledFile, File outFile)
  {
    return gunzip(Files.asByteSource(pulledFile), outFile);
  }"
"private boolean checkGroupedColumn() {
        boolean allowEdit = true;
        if (getTreeTableRow().getTreeItem() != null) {
            Object rowObject = getTreeTableRow().getTreeItem().getValue();
            if (rowObject instanceof RecursiveTreeObject && rowObject.getClass() == RecursiveTreeObject.class) {
                allowEdit = false;
            } else {
                // check grouped columns in the tableview
                if (getTableColumn() instanceof JFXTreeTableColumn && ((JFXTreeTableColumn) getTableColumn()).isGrouped()) {
                    // make sure that the object is a direct child to a group node
                    if (getTreeTableRow().getTreeItem().getParent() != null &&
                        getTreeTableRow().getTreeItem().getParent().getValue().getClass() == RecursiveTreeObject.class) {
                        allowEdit = false;
                    }
                }
            }
        }
        return allowEdit;
    }"
"public void append(final char ch) {
        final int newlen = this.len + 1;
        if (newlen > this.array.length) {
            expand(newlen);
        }
        this.array[this.len] = ch;
        this.len = newlen;
    }"
"public Session getSession(final String sessionId) {
    final Session elem = this.cache.getIfPresent(sessionId);
    return elem;
  }"
"void enqueue(Runnable runnable, boolean flush) {
    queue.add(new RunnableCommand(runnable));
    if (flush) {
      scheduleFlush();
    }
  }"
"public static String getLayerNameFromConfig(Map<String, Object> layerConfig,
                                                KerasLayerConfiguration conf)
            throws InvalidKerasConfigurationException {
        Map<String, Object> innerConfig = KerasLayerUtils.getInnerLayerConfigFromConfig(layerConfig, conf);
        if (!innerConfig.containsKey(conf.getLAYER_FIELD_NAME()))
            throw new InvalidKerasConfigurationException(""Field "" + conf.getLAYER_FIELD_NAME()
                    + "" missing from layer config"");
        return (String) innerConfig.get(conf.getLAYER_FIELD_NAME());
    }"
"public static int countUnique(Collection<?> collection) {
        HashSet<Object> set = new HashSet<>(collection);
        return set.size();
    }"
"public static long memoryAddress(ByteBuffer buffer) {
        assert buffer.isDirect();
        if (PlatformDependent.hasUnsafe()) {
            return PlatformDependent.directBufferAddress(buffer);
        }
        return memoryAddress0(buffer);
    }"
"public static Iterator<Entry<String, String>> iteratorAsString(
            Iterable<Entry<CharSequence, CharSequence>> headers) {
        return new StringEntryIterator(headers.iterator());
    }"
"public <R> SingleOutputStreamOperator<R> flatSelect(final PatternFlatSelectFunction<T, R> patternFlatSelectFunction) {
		// we have to extract the output type from the provided pattern selection function manually
		// because the TypeExtractor cannot do that if the method is wrapped in a MapFunction

		final TypeInformation<R> outTypeInfo = TypeExtractor.getUnaryOperatorReturnType(
			patternFlatSelectFunction,
			PatternFlatSelectFunction.class,
			0,
			1,
			new int[]{1, 0},
			builder.getInputType(),
			null,
			false);

		return flatSelect(patternFlatSelectFunction, outTypeInfo);
	}"
"private Configuration zeroCostDynamicOracle(Instance instance, Collection<Configuration> oracles, Collection<Configuration> newOracles)
    {
        float bestScore = Float.NEGATIVE_INFINITY;
        Configuration bestScoringOracle = null;

        for (Configuration configuration : oracles)
        {
            if (!configuration.state.isTerminalState())
            {
                State currentState = configuration.state;
                Object[] features = FeatureExtractor.extractAllParseFeatures(configuration, featureLength);
                // I only assumed that we need zero cost ones
                if (instance.actionCost(Action.Shift, -1, currentState) == 0)
                {
                    Configuration newConfig = configuration.clone();
                    float score = classifier.shiftScore(features, false);
                    ArcEager.shift(newConfig.state);
                    newConfig.addAction(0);
                    newConfig.addScore(score);
                    newOracles.add(newConfig);

                    if (newConfig.getScore(true) > bestScore)
                    {
                        bestScore = newConfig.getScore(true);
                        bestScoringOracle = newConfig;
                    }
                }
                if (ArcEager.canDo(Action.RightArc, currentState))
                {
                    float[] rightArcScores = classifier.rightArcScores(features, false);
                    for (int dependency : dependencyRelations)
                    {
                        if (instance.actionCost(Action.RightArc, dependency, currentState) == 0)
                        {
                            Configuration newConfig = configuration.clone();
                            float score = rightArcScores[dependency];
                            ArcEager.rightArc(newConfig.state, dependency);
                            newConfig.addAction(3 + dependency);
                            newConfig.addScore(score);
                            newOracles.add(newConfig);

                            if (newConfig.getScore(true) > bestScore)
                            {
                                bestScore = newConfig.getScore(true);
                                bestScoringOracle = newConfig;
                            }
                        }
                    }
                }
                if (ArcEager.canDo(Action.LeftArc, currentState))
                {
                    float[] leftArcScores = classifier.leftArcScores(features, false);

                    for (int dependency : dependencyRelations)
                    {
                        if (instance.actionCost(Action.LeftArc, dependency, currentState) == 0)
                        {
                            Configuration newConfig = configuration.clone();
                            float score = leftArcScores[dependency];
                            ArcEager.leftArc(newConfig.state, dependency);
                            newConfig.addAction(3 + dependencyRelations.size() + dependency);
                            newConfig.addScore(score);
                            newOracles.add(newConfig);

                            if (newConfig.getScore(true) > bestScore)
                            {
                                bestScore = newConfig.getScore(true);
                                bestScoringOracle = newConfig;
                            }
                        }
                    }
                }
                if (instance.actionCost(Action.Reduce, -1, currentState) == 0)
                {
                    Configuration newConfig = configuration.clone();
                    float score = classifier.reduceScore(features, false);
                    ArcEager.reduce(newConfig.state);
                    newConfig.addAction(1);
                    newConfig.addScore(score);
                    newOracles.add(newConfig);

                    if (newConfig.getScore(true) > bestScore)
                    {
                        bestScore = newConfig.getScore(true);
                        bestScoringOracle = newConfig;
                    }
                }
            }
            else
            {
                newOracles.add(configuration);
            }
        }

        return bestScoringOracle;
    }"
"private static void heapify(int[] heap, int[] reverseIndex, int count, float[] values)
  {
    int start = (count - 2) / 2;
    while (start >= 0) {
      siftDown(heap, reverseIndex, start, count - 1, values);
      start--;
    }
  }"
"public void setSequenceLabel(@NonNull T label) {
        this.label = label;
        if (!labels.contains(label))
            labels.add(label);
    }"
"public static <K, V> Map<K, V> notEmpty(Map<K, V> map, String errorMsgTemplate, Object... params) throws IllegalArgumentException {
		if (CollectionUtil.isEmpty(map)) {
			throw new IllegalArgumentException(StrUtil.format(errorMsgTemplate, params));
		}
		return map;
	}"
"protected File getMetadataBackupFile(final AbstractResource metadataResource,
                                         final SamlRegisteredService service) throws IOException {

        LOGGER.debug(""Metadata backup directory is at [{}]"", this.metadataBackupDirectory.getCanonicalPath());
        val metadataFileName = getBackupMetadataFilenamePrefix(metadataResource, service).concat(FILENAME_EXTENSION_XML);
        val backupFile = new File(this.metadataBackupDirectory, metadataFileName);
        if (backupFile.exists()) {
            LOGGER.info(""Metadata file designated for service [{}] already exists at path [{}]."", service.getName(), backupFile.getCanonicalPath());
        } else {
            LOGGER.debug(""Metadata to fetch for service [{}] will be placed at [{}]"", service.getName(), backupFile.getCanonicalPath());
        }
        return backupFile;
    }"
"public static byte[] decodeHex(char[] hexData) {

		int len = hexData.length;

		if ((len & 0x01) != 0) {
			throw new RuntimeException(""Odd number of characters."");
		}

		byte[] out = new byte[len >> 1];

		// two characters form the hex value.
		for (int i = 0, j = 0; j < len; i++) {
			int f = toDigit(hexData[j], j) << 4;
			j++;
			f = f | toDigit(hexData[j], j);
			j++;
			out[i] = (byte) (f & 0xFF);
		}

		return out;
	}"
"public static <T> File appendUtf8Lines(Collection<T> list, File file) throws IORuntimeException {
		return appendLines(list, file, CharsetUtil.CHARSET_UTF_8);
	}"
"@VisibleForTesting
	void onPartitionStateUpdate(
			IntermediateDataSetID intermediateDataSetId,
			ResultPartitionID resultPartitionId,
			ExecutionState producerState) throws IOException, InterruptedException {

		if (executionState == ExecutionState.RUNNING) {
			final SingleInputGate inputGate = inputGatesById.get(intermediateDataSetId);

			if (inputGate != null) {
				if (producerState == ExecutionState.SCHEDULED
					|| producerState == ExecutionState.DEPLOYING
					|| producerState == ExecutionState.RUNNING
					|| producerState == ExecutionState.FINISHED) {

					// Retrigger the partition request
					inputGate.retriggerPartitionRequest(resultPartitionId.getPartitionId());

				} else if (producerState == ExecutionState.CANCELING
					|| producerState == ExecutionState.CANCELED
					|| producerState == ExecutionState.FAILED) {

					// The producing execution has been canceled or failed. We
					// don't need to re-trigger the request since it cannot
					// succeed.
					if (LOG.isDebugEnabled()) {
						LOG.debug(""Cancelling task {} after the producer of partition {} with attempt ID {} has entered state {}."",
							taskNameWithSubtask,
							resultPartitionId.getPartitionId(),
							resultPartitionId.getProducerId(),
							producerState);
					}

					cancelExecution();
				} else {
					// Any other execution state is unexpected. Currently, only
					// state CREATED is left out of the checked states. If we
					// see a producer in this state, something went wrong with
					// scheduling in topological order.
					String msg = String.format(""Producer with attempt ID %s of partition %s in unexpected state %s."",
						resultPartitionId.getProducerId(),
						resultPartitionId.getPartitionId(),
						producerState);

					failExternally(new IllegalStateException(msg));
				}
			} else {
				failExternally(new IllegalStateException(""Received partition producer state for "" +
						""unknown input gate "" + intermediateDataSetId + "".""));
			}
		} else {
			LOG.debug(""Task {} ignored a partition producer state notification, because it's not running."", taskNameWithSubtask);
		}
	}"
"@Override
  protected OpenedObject<T> generateOpenObject(T object) throws IOException
  {
    final File outFile = File.createTempFile(FETCH_FILE_PREFIX, null, temporaryDirectory);
    return new OpenedObject<>(
        object,
        openObjectFunction.open(object, outFile),
        outFile::delete
    );
  }"
"private JPanel getJPanel1() {
		if (jPanel1 == null) {
			jPanel1 = new JPanel();
			jPanel1.add(getBtnFind());
			jPanel1.add(getBtnCancel());
		}
		return jPanel1;
	}"
"public static Method getMethodIgnoreCase(Class<?> clazz, String methodName, Class<?>... paramTypes) throws SecurityException {
		return getMethod(clazz, true, methodName, paramTypes);
	}"
"public static byte[] toUnsignedByteArray(BigInteger value) {
		byte[] bytes = value.toByteArray();

		if (bytes[0] == 0) {
			byte[] tmp = new byte[bytes.length - 1];
			System.arraycopy(bytes, 1, tmp, 0, tmp.length);

			return tmp;
		}

		return bytes;
	}"
"private static ThreadLocal<MessageDigest> createThreadLocalMessageDigest(final String digest) {
		return new ThreadLocal<MessageDigest>() {
			@Override
			protected MessageDigest initialValue() {
				try {
					return MessageDigest.getInstance(digest);
				} catch (NoSuchAlgorithmException e) {
					throw new RuntimeException(
							""unexpected exception creating MessageDigest instance for ["" + digest + ']', e);
				}
			}
		};
	}"
"public int compareTo(final BigInteger val) {
        final Rational val2 = new Rational(val, BigInteger.ONE);
        return (compareTo(val2));
    }"
"@SuppressWarnings(""SynchronizationOnLocalVariableOrMethodParameter"")
    public List<Connection> getConnections(final ConnectionMode connectionMode, final String dataSourceName, final int connectionSize, final TransactionType transactionType) throws SQLException {
        DataSource dataSource = dataSources.get(dataSourceName);
        if (1 == connectionSize) {
            return Collections.singletonList(createConnection(transactionType, dataSourceName, dataSource));
        }
        if (ConnectionMode.CONNECTION_STRICTLY == connectionMode) {
            return createConnections(transactionType, dataSourceName, dataSource, connectionSize);
        }
        synchronized (dataSource) {
            return createConnections(transactionType, dataSourceName, dataSource, connectionSize);
        }
    }"
"@Internal
	public static <T, F> FieldAccessor<T, F> getAccessor(TypeInformation<T> typeInfo, int pos, ExecutionConfig config){

		// In case of arrays
		if (typeInfo instanceof BasicArrayTypeInfo || typeInfo instanceof PrimitiveArrayTypeInfo) {
			return new FieldAccessor.ArrayFieldAccessor<>(pos, typeInfo);

		// In case of basic types
		} else if (typeInfo instanceof BasicTypeInfo) {
			if (pos != 0) {
				throw new CompositeType.InvalidFieldReferenceException(""The "" + ((Integer) pos).toString() + "". field selected on a "" +
					""basic type ("" + typeInfo.toString() + ""). A field expression on a basic type can only select "" +
					""the 0th field (which means selecting the entire basic type)."");
			}
			@SuppressWarnings(""unchecked"")
			FieldAccessor<T, F> result = (FieldAccessor<T, F>) new FieldAccessor.SimpleFieldAccessor<>(typeInfo);
			return result;

		// In case of case classes
		} else if (typeInfo.isTupleType() && ((TupleTypeInfoBase) typeInfo).isCaseClass()) {
			TupleTypeInfoBase tupleTypeInfo = (TupleTypeInfoBase) typeInfo;
			@SuppressWarnings(""unchecked"")
			TypeInformation<F> fieldTypeInfo = (TypeInformation<F>) tupleTypeInfo.getTypeAt(pos);
			return new FieldAccessor.RecursiveProductFieldAccessor<>(
				pos, typeInfo, new FieldAccessor.SimpleFieldAccessor<>(fieldTypeInfo), config);

		// In case of tuples
		} else if (typeInfo.isTupleType()) {
			@SuppressWarnings(""unchecked"")
			FieldAccessor<T, F> result = new FieldAccessor.SimpleTupleFieldAccessor(pos, typeInfo);
			return result;

		// Default case, PojoType is directed to this statement
		} else {
			throw new CompositeType.InvalidFieldReferenceException(""Cannot reference field by position on "" + typeInfo.toString()
				+ ""Referencing a field by position is supported on tuples, case classes, and arrays. ""
				+ ""Additionally, you can select the 0th field of a primitive/basic type (e.g. int)."");
		}
	}"
"@Override
    public boolean containsKey(T key) {
        try {
            if (emulateIsAbsent)
                lock.readLock().lock();

            return compressedEntries.containsKey(key);
        } finally {
            if (emulateIsAbsent)
                lock.readLock().unlock();
        }
    }"
"@Override
  public boolean processBytesFromPeer(ByteBuffer bytes) throws GeneralSecurityException {
    // If we're the client and we haven't given an output frame, we shouldn't be processing any
    // bytes.
    if (outputFrame == null && isClient) {
      return true;
    }
    // If we already have bytes to write, just return.
    if (outputFrame != null && outputFrame.hasRemaining()) {
      return true;
    }
    int remaining = bytes.remaining();
    // Call handshaker service to proceess the bytes.
    if (outputFrame == null) {
      checkState(!isClient, ""Client handshaker should not process any frame at the beginning."");
      outputFrame = handshaker.startServerHandshake(bytes);
    } else {
      outputFrame = handshaker.next(bytes);
    }
    // If handshake has finished or we already have bytes to write, just return true.
    if (handshaker.isFinished() || outputFrame.hasRemaining()) {
      return true;
    }
    // We have done processing input bytes, but no bytes to write. Thus we need more data.
    if (!bytes.hasRemaining()) {
      return false;
    }
    // There are still remaining bytes. Thus we need to continue processing the bytes.
    // Prevent infinite loop by checking some bytes are consumed by handshaker.
    checkState(bytes.remaining() < remaining, ""Handshaker did not consume any bytes."");
    return processBytesFromPeer(bytes);
  }"
"@UpdateHandler(name = ""update_record"", file = ""CouchDbMultifactorAuthenticationTrustRecord_update.js"")
    public void updateRecord(final CouchDbMultifactorAuthenticationTrustRecord record) {
        if (record.getCid() == null) {
            add(record);
        } else {
            db.callUpdateHandler(stdDesignDocumentId, ""update_record"", record.getCid(), CollectionUtils.wrap(""doc"", record));
        }
    }"
"private static String convertMap2Pair(Map<String, String> map) {

        if (CommonUtils.isEmpty(map)) {
            return StringUtils.EMPTY;
        }

        StringBuilder sb = new StringBuilder(128);
        for (Map.Entry<String, String> entry : map.entrySet()) {
            sb.append(getKeyPairs(entry.getKey(), entry.getValue()));
        }

        return sb.toString();
    }"
"public Gradient[] calcGradient(IDQN current, Stack<MiniTrans<Integer>> rewards) {

        MiniTrans<Integer> minTrans = rewards.pop();

        int size = rewards.size();

        int[] shape = getHistoryProcessor() == null ? mdp.getObservationSpace().getShape()
                        : getHistoryProcessor().getConf().getShape();
        int[] nshape = Learning.makeShape(size, shape);
        INDArray input = Nd4j.create(nshape);
        INDArray targets = Nd4j.create(size, mdp.getActionSpace().getSize());

        double r = minTrans.getReward();
        for (int i = size - 1; i >= 0; i--) {
            minTrans = rewards.pop();

            r = minTrans.getReward() + conf.getGamma() * r;
            input.putRow(i, minTrans.getObs());
            INDArray row = minTrans.getOutput()[0];
            row = row.putScalar(minTrans.getAction(), r);
            targets.putRow(i, row);
        }

        return current.gradient(input, targets);
    }"
"public HttpRequest basicAuth(String username, String password) {
		final String data = username.concat("":"").concat(password);
		final String base64 = Base64.encode(data, charset);

		header(""Authorization"", ""Basic "" + base64, true);

		return this;
	}"
"private String toCookieStr(Cookie[] cookies) {
    String cookieStr = """";

    for (Cookie c : cookies) {
     cookieStr += c.getName() + ""="" + c.getValue() + "" ;\n"";
    }
    return cookieStr;
  }"
"public static String objectsToString(Object[] args) {
        if (args == null) {
            return null;
        } else if (args.length == 0) {
            return ""[]"";
        } else {
            StringBuilder sb = new StringBuilder().append(""["");
            for (Object arg : args) {
                sb.append(arg.toString()).append("","");
            }
            sb.setCharAt(sb.length() - 1, ']');
            return sb.toString();
        }
    }"
"public static int copy(InputStream in, OutputStream out) throws IOException {
        assert in != null : ""No input stream specified"";
        assert out != null : ""No output stream specified"";
        try {
            int byteCount = 0;
            byte[] buffer = new byte[BUFFER_SIZE];
            int bytesRead = -1;
            while ((bytesRead = in.read(buffer)) != -1) {
                out.write(buffer, 0, bytesRead);
                byteCount += bytesRead;
            }
            out.flush();
            return byteCount;
        } finally {
            try {
                in.close();
            } catch (IOException ex) {
            }
            try {
                out.close();
            } catch (IOException ex) {
            }
        }
    }"
"public static Integer getValidMaxRowsPerSegment(IndexTuningConfig tuningConfig)
  {
    @Nullable final Integer numShards = tuningConfig.numShards;
    @Nullable final Integer maxRowsPerSegment = tuningConfig.maxRowsPerSegment;
    if (numShards == null || numShards == -1) {
      return maxRowsPerSegment == null || maxRowsPerSegment.equals(-1)
             ? IndexTuningConfig.DEFAULT_MAX_ROWS_PER_SEGMENT
             : maxRowsPerSegment;
    } else {
      return null;
    }
  }"
"public static <T> QueryPlus<T> wrap(Query<T> query)
  {
    Preconditions.checkNotNull(query);
    return new QueryPlus<>(query, null, null);
  }"
"public static TriaFrequency create(String first, char delimiter, String second, String third)
    {
        TriaFrequency triaFrequency = new TriaFrequency(first + delimiter + second + Occurrence.RIGHT + third);
        triaFrequency.first = first;
        triaFrequency.second = second;
        triaFrequency.third = third;
        triaFrequency.delimiter = delimiter;
        return triaFrequency;
    }"
"public static long getSizeOfFreeHeapMemory() {
		Runtime r = Runtime.getRuntime();
		return getMaxJvmHeapMemory() - r.totalMemory() + r.freeMemory();
	}"
"@SuppressWarnings(""unchecked"")
	public static byte[] unzipFileBytes(File zipFile, Charset charset, String name) {
		ZipFile zipFileObj = null;
		try {
			zipFileObj = new ZipFile(zipFile, charset);
			final Enumeration<ZipEntry> em = (Enumeration<ZipEntry>) zipFileObj.entries();
			ZipEntry zipEntry = null;
			while (em.hasMoreElements()) {
				zipEntry = em.nextElement();
				if (zipEntry.isDirectory()) {
					continue;
				} else if (name.equals(zipEntry.getName())) {
					return IoUtil.readBytes(zipFileObj.getInputStream(zipEntry));
				}
			}
		} catch (IOException e) {
			throw new UtilException(e);
		} finally {
			IoUtil.close(zipFileObj);
		}
		return null;
	}"
"public Postcard withBoolean(@Nullable String key, boolean value) {
        mBundle.putBoolean(key, value);
        return this;
    }"
"public WindowedStream<T, KEY, TimeWindow> timeWindow(Time size, Time slide) {
		if (environment.getStreamTimeCharacteristic() == TimeCharacteristic.ProcessingTime) {
			return window(SlidingProcessingTimeWindows.of(size, slide));
		} else {
			return window(SlidingEventTimeWindows.of(size, slide));
		}
	}"
"@Override
  public Long setnx(final byte[] key, final byte[] value) {
    checkIsInMultiOrPipeline();
    client.setnx(key, value);
    return client.getIntegerReply();
  }"
"@Override
	public synchronized void delete(int type, String url) throws DatabaseException {
    	try {
			psDeleteUrls.setInt(1, type);
			psDeleteUrls.setString(2, url);
			psDeleteUrls.executeUpdate();
		} catch (SQLException e) {
			throw new DatabaseException(e);
		}
    }"
"protected final MemorySegment nextSegment(MemorySegment current, int posInSegment) throws IOException
	{
		if (current != null) {
			writeSegment(current, posInSegment, false);
		}
		
		final MemorySegment next = this.writer.getNextReturnedBlock();
		this.blockCount++;
		return next;
	}"
"@Override
	public Map<String, String> convert(String token) {
		Map<String, String> headers;

		int headerEndIndex = token.indexOf('.');
		if (headerEndIndex == -1) {
			throw new InvalidTokenException(""Invalid JWT. Missing JOSE Header."");
		}

		byte[] decodedHeader;

		try {
			decodedHeader = Codecs.b64UrlDecode(token.substring(0, headerEndIndex));
		} catch (IllegalArgumentException ex) {
			throw new InvalidTokenException(""Invalid JWT. Malformed JOSE Header."", ex);
		}

		JsonParser parser = null;

		try {
			parser = this.factory.createParser(decodedHeader);
			headers = new HashMap<String, String>();
			if (parser.nextToken() == JsonToken.START_OBJECT) {
				while (parser.nextToken() == JsonToken.FIELD_NAME) {
					String headerName = parser.getCurrentName();
					parser.nextToken();
					String headerValue = parser.getValueAsString();
					headers.put(headerName, headerValue);
				}
			}

		} catch (IOException ex) {
			throw new InvalidTokenException(""An I/O error occurred while reading the JWT: "" + ex.getMessage(), ex);
		} finally {
			try {
				if (parser != null) parser.close();
			} catch (IOException ex) { }
		}

		return headers;
	}"
"public static NestedSerializersSnapshotDelegate legacyReadNestedSerializerSnapshots(DataInputView in, ClassLoader cl) throws IOException {
		@SuppressWarnings(""deprecation"")
		final List<Tuple2<TypeSerializer<?>, TypeSerializerSnapshot<?>>> serializersAndSnapshots =
				TypeSerializerSerializationUtil.readSerializersAndConfigsWithResilience(in, cl);

		final TypeSerializerSnapshot<?>[] nestedSnapshots = serializersAndSnapshots.stream()
				.map(t -> t.f1)
				.toArray(TypeSerializerSnapshot<?>[]::new);

		return new NestedSerializersSnapshotDelegate(nestedSnapshots);
	}"
"public static void install(AddOnClassLoader addOnClassLoader, AddOn addOn) {
        installResourceBundle(addOnClassLoader, addOn);
        installAddOnFiles(addOnClassLoader, addOn, true);
        List<Extension> listExts = installAddOnExtensions(addOn);
        installAddOnActiveScanRules(addOn, addOnClassLoader);
        installAddOnPassiveScanRules(addOn, addOnClassLoader);
 
        // postInstall actions
        for (Extension ext : listExts) {
            if (!ext.isEnabled()) {
                continue;
            }

            try {
                ext.postInstall();
            } catch (Exception e) {
                logger.error(""Post install method failed for add-on "" + addOn.getId() + "" extension "" + ext.getName());
            }
        }
    }"
"@Override
    public INDArray randn(int[] shape, org.nd4j.linalg.api.rng.Random r) {
        return r.nextGaussian(shape);
    }"
"public synchronized final void completed(@CheckForNull Throwable error) {
        if (executor!=null) {
            executor.completedAsynchronous(error);
        } else {
            result = error == null ? NULL : error;
        }
    }"
"@GET
  @Path(""/{dataSourceName}/intervals/{interval}/serverview"")
  @Produces(MediaType.APPLICATION_JSON)
  @ResourceFilters(DatasourceResourceFilter.class)
  public Response getSegmentDataSourceSpecificInterval(
      @PathParam(""dataSourceName"") String dataSourceName,
      @PathParam(""interval"") String interval,
      @QueryParam(""partial"") final boolean partial
  )
  {
    TimelineLookup<String, SegmentLoadInfo> timeline = serverInventoryView.getTimeline(
        new TableDataSource(dataSourceName)
    );
    final Interval theInterval = Intervals.of(interval.replace('_', '/'));
    if (timeline == null) {
      log.debug(""No timeline found for datasource[%s]"", dataSourceName);
      return Response.ok(new ArrayList<ImmutableSegmentLoadInfo>()).build();
    }

    Iterable<TimelineObjectHolder<String, SegmentLoadInfo>> lookup = timeline.lookupWithIncompletePartitions(theInterval);
    FunctionalIterable<ImmutableSegmentLoadInfo> retval = FunctionalIterable
        .create(lookup).transformCat(
            (TimelineObjectHolder<String, SegmentLoadInfo> input) ->
                Iterables.transform(
                    input.getObject(),
                    (PartitionChunk<SegmentLoadInfo> chunk) ->
                        chunk.getObject().toImmutableSegmentLoadInfo()
                )
        );
    return Response.ok(retval).build();
  }"
"public static String getPlatform(RemoteProxy proxy) {
    if (proxy.getTestSlots().size() == 0) {
      return ""Unknown"";
    }
    Platform res = getPlatform(proxy.getTestSlots().get(0));

    for (TestSlot slot : proxy.getTestSlots()) {
      Platform tmp = getPlatform(slot);
      if (tmp != res) {
        return ""mixed OS"";
      }
      res = tmp;
    }
    if (res == null) {
      return ""not specified"";
    }
    return res.toString();
  }"
"public <R> Stream<R> invokeAnd(Function<C, R> invoker) {
			Function<C, InvocationResult<R>> mapper = (callbackInstance) -> invoke(
					callbackInstance, () -> invoker.apply(callbackInstance));
			return this.callbackInstances.stream().map(mapper)
					.filter(InvocationResult::hasResult).map(InvocationResult::get);
		}"
"static ManagedChannelServiceConfig fromServiceConfig(
      Map<String, ?> serviceConfig,
      boolean retryEnabled,
      int maxRetryAttemptsLimit,
      int maxHedgedAttemptsLimit,
      @Nullable Object loadBalancingConfig) {
    Throttle retryThrottling = null;
    if (retryEnabled) {
      retryThrottling = ServiceConfigUtil.getThrottlePolicy(serviceConfig);
    }
    Map<String, MethodInfo> serviceMethodMap = new HashMap<>();
    Map<String, MethodInfo> serviceMap = new HashMap<>();

    // Try and do as much validation here before we swap out the existing configuration.  In case
    // the input is invalid, we don't want to lose the existing configuration.
    List<Map<String, ?>> methodConfigs =
        ServiceConfigUtil.getMethodConfigFromServiceConfig(serviceConfig);

    if (methodConfigs == null) {
      // this is surprising, but possible.
      return new ManagedChannelServiceConfig(
          serviceMethodMap, serviceMap, retryThrottling, loadBalancingConfig);
    }

    for (Map<String, ?> methodConfig : methodConfigs) {
      MethodInfo info = new MethodInfo(
          methodConfig, retryEnabled, maxRetryAttemptsLimit, maxHedgedAttemptsLimit);

      List<Map<String, ?>> nameList =
          ServiceConfigUtil.getNameListFromMethodConfig(methodConfig);

      checkArgument(
          nameList != null && !nameList.isEmpty(), ""no names in method config %s"", methodConfig);
      for (Map<String, ?> name : nameList) {
        String serviceName = ServiceConfigUtil.getServiceFromName(name);
        checkArgument(!Strings.isNullOrEmpty(serviceName), ""missing service name"");
        String methodName = ServiceConfigUtil.getMethodFromName(name);
        if (Strings.isNullOrEmpty(methodName)) {
          // Service scoped config
          checkArgument(
              !serviceMap.containsKey(serviceName), ""Duplicate service %s"", serviceName);
          serviceMap.put(serviceName, info);
        } else {
          // Method scoped config
          String fullMethodName = MethodDescriptor.generateFullMethodName(serviceName, methodName);
          checkArgument(
              !serviceMethodMap.containsKey(fullMethodName),
              ""Duplicate method name %s"",
              fullMethodName);
          serviceMethodMap.put(fullMethodName, info);
        }
      }
    }

    return new ManagedChannelServiceConfig(
        serviceMethodMap, serviceMap, retryThrottling, loadBalancingConfig);
  }"
"protected Map<String, Object> resolveBoundTypes(DeclaredType type) {
        Map<String, Object> boundTypes = new LinkedHashMap<>(2);
        TypeElement element = (TypeElement) type.asElement();

        List<? extends TypeParameterElement> typeParameters = element.getTypeParameters();
        List<? extends TypeMirror> typeArguments = type.getTypeArguments();
        if (typeArguments.size() == typeParameters.size()) {
            Iterator<? extends TypeMirror> i = typeArguments.iterator();
            for (TypeParameterElement typeParameter : typeParameters) {
                boundTypes.put(typeParameter.toString(), resolveTypeReference(i.next(), boundTypes));
            }
        }

        return boundTypes;
    }"
"public static <K, V> FIFOCache<K, V> newFIFOCache(int capacity, long timeout){
		return new FIFOCache<K, V>(capacity, timeout);
	}"
"public void setStatus(String asgName, boolean enabled) {
        String asgAccountId = getASGAccount(asgName);
        asgCache.put(new CacheKey(asgAccountId, asgName), enabled);
    }"
"public static void put(String key, String path, Forest forest) {
        DIC.put(key, KV.with(path, forest));
        MyStaticValue.ENV.put(key, path);
    }"
"public static <T> List<T> filter(List<T> list, Editor<T> editor) {
		if (null == list || null == editor) {
			return list;
		}

		final List<T> list2 = (list instanceof LinkedList) ? new LinkedList<T>() : new ArrayList<T>(list.size());
		T modified;
		for (T t : list) {
			modified = editor.edit(t);
			if (null != modified) {
				list2.add(modified);
			}
		}
		return list2;
	}"
"protected EmbeddedChannel newContentCompressor(ChannelHandlerContext ctx, CharSequence contentEncoding)
            throws Http2Exception {
        if (GZIP.contentEqualsIgnoreCase(contentEncoding) || X_GZIP.contentEqualsIgnoreCase(contentEncoding)) {
            return newCompressionChannel(ctx, ZlibWrapper.GZIP);
        }
        if (DEFLATE.contentEqualsIgnoreCase(contentEncoding) || X_DEFLATE.contentEqualsIgnoreCase(contentEncoding)) {
            return newCompressionChannel(ctx, ZlibWrapper.ZLIB);
        }
        // 'identity' or unsupported
        return null;
    }"
"@SuppressWarnings({ ""unchecked"", ""rawtypes"" })
	@Override
	public T reduce(T value1, T value2) throws Exception {

		for (int position : fields) {
			// Save position of compared key
			// Get both values - both implement comparable
			Comparable comparable1 = value1.getFieldNotNull(position);
			Comparable comparable2 = value2.getFieldNotNull(position);

			// Compare values
			int comp = comparable1.compareTo(comparable2);
			// If comp is smaller than 0 comparable 1 is smaller.
			// Return the smaller value.
			if (comp < 0) {
				return value1;
			} else if (comp > 0) {
				return value2;
			}
		}
		return value1;
	}"
"@SuppressWarnings(""unchecked"")
	@PublicEvolving
	public static <IN1, IN2, OUT> TypeInformation<OUT> getBinaryOperatorReturnType(
		Function function,
		Class<?> baseClass,
		int input1TypeArgumentIndex,
		int input2TypeArgumentIndex,
		int outputTypeArgumentIndex,
		int[] lambdaOutputTypeArgumentIndices,
		TypeInformation<IN1> in1Type,
		TypeInformation<IN2> in2Type,
		String functionName,
		boolean allowMissing) {

		Preconditions.checkArgument(in1Type == null || input1TypeArgumentIndex >= 0, ""Input 1 type argument index was not provided"");
		Preconditions.checkArgument(in2Type == null || input2TypeArgumentIndex >= 0, ""Input 2 type argument index was not provided"");
		Preconditions.checkArgument(outputTypeArgumentIndex >= 0, ""Output type argument index was not provided"");
		Preconditions.checkArgument(
			lambdaOutputTypeArgumentIndices != null,
			""Indices for output type arguments within lambda not provided"");

		// explicit result type has highest precedence
		if (function instanceof ResultTypeQueryable) {
			return ((ResultTypeQueryable<OUT>) function).getProducedType();
		}

		// perform extraction
		try {
			final LambdaExecutable exec;
			try {
				exec = checkAndExtractLambda(function);
			} catch (TypeExtractionException e) {
				throw new InvalidTypesException(""Internal error occurred."", e);
			}
			if (exec != null) {

				final Method sam = TypeExtractionUtils.getSingleAbstractMethod(baseClass);
				final int baseParametersLen = sam.getParameterTypes().length;

				// parameters must be accessed from behind, since JVM can add additional parameters e.g. when using local variables inside lambda function
				final int paramLen = exec.getParameterTypes().length;

				final Type output;
				if (lambdaOutputTypeArgumentIndices.length > 0) {
					output = TypeExtractionUtils.extractTypeFromLambda(
						baseClass,
						exec,
						lambdaOutputTypeArgumentIndices,
						paramLen,
						baseParametersLen);
				} else {
					output = exec.getReturnType();
					TypeExtractionUtils.validateLambdaType(baseClass, output);
				}

				return new TypeExtractor().privateCreateTypeInfo(
					output,
					in1Type,
					in2Type);
			}
			else {
				if (in1Type != null) {
					validateInputType(baseClass, function.getClass(), input1TypeArgumentIndex, in1Type);
				}
				if (in2Type != null) {
					validateInputType(baseClass, function.getClass(), input2TypeArgumentIndex, in2Type);
				}
				return new TypeExtractor().privateCreateTypeInfo(baseClass, function.getClass(), outputTypeArgumentIndex, in1Type, in2Type);
			}
		}
		catch (InvalidTypesException e) {
			if (allowMissing) {
				return (TypeInformation<OUT>) new MissingTypeInfo(functionName != null ? functionName : function.toString(), e);
			} else {
				throw e;
			}
		}
	}"
"public void initialize() {
        val pair = buildLoggerContext(environment, resourceLoader);
        pair.ifPresent(it -> {
            this.logConfigurationFile = it.getKey();
            this.loggerContext = it.getValue();
        });
    }"
"@Deprecated
    public static int outSize(int size, int k, int s, int p, int dilation, boolean coverAll) {
        k = effectiveKernelSize(k, dilation);

        if (coverAll)
            return (size + p * 2 - k + s - 1) / s + 1;
        else
            return (size + p * 2 - k) / s + 1;
    }"
"protected void configureContext(Context context,
			ServletContextInitializer[] initializers) {
		TomcatStarter starter = new TomcatStarter(initializers);
		if (context instanceof TomcatEmbeddedContext) {
			TomcatEmbeddedContext embeddedContext = (TomcatEmbeddedContext) context;
			embeddedContext.setStarter(starter);
			embeddedContext.setFailCtxIfServletStartFails(true);
		}
		context.addServletContainerInitializer(starter, NO_CLASSES);
		for (LifecycleListener lifecycleListener : this.contextLifecycleListeners) {
			context.addLifecycleListener(lifecycleListener);
		}
		for (Valve valve : this.contextValves) {
			context.getPipeline().addValve(valve);
		}
		for (ErrorPage errorPage : getErrorPages()) {
			new TomcatErrorPage(errorPage).addToContext(context);
		}
		for (MimeMappings.Mapping mapping : getMimeMappings()) {
			context.addMimeMapping(mapping.getExtension(), mapping.getMimeType());
		}
		configureSession(context);
		new DisableReferenceClearingContextCustomizer().customize(context);
		for (TomcatContextCustomizer customizer : this.tomcatContextCustomizers) {
			customizer.customize(context);
		}
	}"
"@Override
    public InstanceInfo getInstanceByAppAndId(String appName, String id) {
        return this.getInstanceByAppAndId(appName, id, true);
    }"
"public Base64NDArrayBody toArray(SingleCSVRecord record) throws IOException {
        List<Writable> record2 = toArrowWritablesSingle(
                toArrowColumnsStringSingle(bufferAllocator,
                        transformProcess.getInitialSchema(),record.getValues()),
                transformProcess.getInitialSchema());
        List<Writable> finalRecord = execute(Arrays.asList(record2),transformProcess).get(0);
        INDArray convert = RecordConverter.toArray(finalRecord);
        return new Base64NDArrayBody(Nd4jBase64.base64String(convert));
    }"
"private synchronized void fillPool()
   {
      final int connectionsToAdd = Math.min(config.getMaximumPoolSize() - getTotalConnections(), config.getMinimumIdle() - getIdleConnections())
                                   - addConnectionQueue.size();
      for (int i = 0; i < connectionsToAdd; i++) {
         addConnectionExecutor.submit((i < connectionsToAdd - 1) ? poolEntryCreator : postFillPoolEntryCreator);
      }
   }"
"public static boolean loadMainDictionary(String mainPath, String path[], DoubleArrayTrie<CoreDictionary.Attribute> dat, boolean isCache)
    {
        logger.info(""自定义词典开始加载:"" + mainPath);
        if (loadDat(mainPath, dat)) return true;
        TreeMap<String, CoreDictionary.Attribute> map = new TreeMap<String, CoreDictionary.Attribute>();
        LinkedHashSet<Nature> customNatureCollector = new LinkedHashSet<Nature>();
        try
        {
            //String path[] = HanLP.Config.CustomDictionaryPath;
            for (String p : path)
            {
                Nature defaultNature = Nature.n;
                File file = new File(p);
                String fileName = file.getName();
                int cut = fileName.lastIndexOf(' ');
                if (cut > 0)
                {
                    // 有默认词性
                    String nature = fileName.substring(cut + 1);
                    p = file.getParent() + File.separator + fileName.substring(0, cut);
                    try
                    {
                        defaultNature = LexiconUtility.convertStringToNature(nature, customNatureCollector);
                    }
                    catch (Exception e)
                    {
                        logger.severe(""配置文件【"" + p + ""】写错了！"" + e);
                        continue;
                    }
                }
                logger.info(""以默认词性["" + defaultNature + ""]加载自定义词典"" + p + ""中……"");
                boolean success = load(p, defaultNature, map, customNatureCollector);
                if (!success) logger.warning(""失败："" + p);
            }
            if (map.size() == 0)
            {
                logger.warning(""没有加载到任何词条"");
                map.put(Predefine.TAG_OTHER, null);     // 当作空白占位符
            }
            logger.info(""正在构建DoubleArrayTrie……"");
            dat.build(map);
            if (isCache)
            {
                // 缓存成dat文件，下次加载会快很多
                logger.info(""正在缓存词典为dat文件……"");
                // 缓存值文件
                List<CoreDictionary.Attribute> attributeList = new LinkedList<CoreDictionary.Attribute>();
                for (Map.Entry<String, CoreDictionary.Attribute> entry : map.entrySet())
                {
                    attributeList.add(entry.getValue());
                }
                DataOutputStream out = new DataOutputStream(new BufferedOutputStream(IOUtil.newOutputStream(mainPath + Predefine.BIN_EXT)));
                // 缓存用户词性
                if (customNatureCollector.isEmpty()) // 热更新
                {
                    for (int i = Nature.begin.ordinal() + 1; i < Nature.values().length; ++i)
                    {
                        customNatureCollector.add(Nature.values()[i]);
                    }
                }
                IOUtil.writeCustomNature(out, customNatureCollector);
                // 缓存正文
                out.writeInt(attributeList.size());
                for (CoreDictionary.Attribute attribute : attributeList)
                {
                    attribute.save(out);
                }
                dat.save(out);
                out.close();
            }
        }
        catch (FileNotFoundException e)
        {
            logger.severe(""自定义词典"" + mainPath + ""不存在！"" + e);
            return false;
        }
        catch (IOException e)
        {
            logger.severe(""自定义词典"" + mainPath + ""读取错误！"" + e);
            return false;
        }
        catch (Exception e)
        {
            logger.warning(""自定义词典"" + mainPath + ""缓存失败！\n"" + TextUtility.exceptionToString(e));
        }
        return true;
    }"
"public static Response failure(SessionId sessionId, Throwable reason) {
    Response response = new Response();
    response.setSessionId(sessionId != null ? sessionId.toString() : null);
    response.setValue(reason);
    response.setStatus(ERROR_CODES.toStatusCode(reason));
    response.setState(ERROR_CODES.toState(response.getStatus()));
    return response;
  }"
"public static Double toDoubleObject(@NotNull String str) {
		// 统一行为，不要有时候抛NPE，有时候抛NumberFormatException
		if (str == null) {
			throw new NumberFormatException(""null"");
		}
		return Double.valueOf(str);
	}"
"private Set<String> retrieveRedactedKeys(JSONObject jsonObject) {
        Set<String> redactedKeySet = new HashSet<>();
        if (jsonObject.has(REDACT_KEY)) {
            Object value = jsonObject.get(REDACT_KEY);
            if (value instanceof JSONArray) {
                for (Object o : jsonObject.getJSONArray(REDACT_KEY)) {
                    if (o instanceof String) {
                        redactedKeySet.add((String) o);
                    } else {
                        // array, object, null, number, boolean
                        LOGGER.log(Level.WARNING, ""Unsupported type "" + o.getClass().getName() + "" for "" + REDACT_KEY + "", please use either a single String value or an Array"");
                    }
                }
            } else if (value instanceof String) {
                redactedKeySet.add((String) value);
            } else {
                // object, null, number, boolean
                LOGGER.log(Level.WARNING, ""Unsupported type "" + value.getClass().getName() + "" for "" + REDACT_KEY + "", please use either a single String value or an Array"");
            }
        }
        return redactedKeySet;
    }"
"public static <T> Flowable<T> toFlowable(EventPublisher<T> eventPublisher) {
        PublishProcessor<T> publishProcessor = PublishProcessor.create();
        FlowableProcessor<T> flowableProcessor = publishProcessor.toSerialized();
        eventPublisher.onEvent(flowableProcessor::onNext);
        return flowableProcessor;
    }"
"public void drainAndHalt()
    {
        Sequence[] workerSequences = getWorkerSequences();
        while (ringBuffer.getCursor() > Util.getMinimumSequence(workerSequences))
        {
            Thread.yield();
        }

        for (WorkProcessor<?> processor : workProcessors)
        {
            processor.halt();
        }

        started.set(false);
    }"
"public void doIt() {
    if (nodeidx == -1) {
      GetLogsTask t = new GetLogsTask();
      t.doIt();
      bytes = t._bytes;
    }
    else {
      H2ONode node = H2O.CLOUD._memary[nodeidx];
      GetLogsTask t = new GetLogsTask();
      Log.trace(""GetLogsTask starting to node "" + nodeidx + ""..."");
      // Synchronous RPC call to get ticks from remote (possibly this) node.
      new RPC<>(node, t).call().get();
      Log.trace(""GetLogsTask completed to node "" + nodeidx);
      bytes = t._bytes;
    }
  }"
"private void setHandshakeFailure(ChannelHandlerContext ctx, Throwable cause, boolean closeInbound,
                                     boolean notify, boolean alwaysFlushAndClose) {
        try {
            // Release all resources such as internal buffers that SSLEngine
            // is managing.
            outboundClosed = true;
            engine.closeOutbound();

            if (closeInbound) {
                try {
                    engine.closeInbound();
                } catch (SSLException e) {
                    if (logger.isDebugEnabled()) {
                        // only log in debug mode as it most likely harmless and latest chrome still trigger
                        // this all the time.
                        //
                        // See https://github.com/netty/netty/issues/1340
                        String msg = e.getMessage();
                        if (msg == null || !(msg.contains(""possible truncation attack"") ||
                                msg.contains(""closing inbound before receiving peer's close_notify""))) {
                            logger.debug(""{} SSLEngine.closeInbound() raised an exception."", ctx.channel(), e);
                        }
                    }
                }
            }
            if (handshakePromise.tryFailure(cause) || alwaysFlushAndClose) {
                SslUtils.handleHandshakeFailure(ctx, cause, notify);
            }
        } finally {
            // Ensure we remove and fail all pending writes in all cases and so release memory quickly.
            releaseAndFailAll(cause);
        }
    }"
"public static INDArray toOutcomeVector(long index, long numOutcomes) {
        if (index > Integer.MAX_VALUE || numOutcomes > Integer.MAX_VALUE)
            throw new UnsupportedOperationException();

        val nums = new int[(int) numOutcomes];
        nums[(int) index] = 1;
        return NDArrayUtil.toNDArray(nums);
    }"
"public static boolean isEmpty(File file) {
		if (null == file) {
			return true;
		}

		if (file.isDirectory()) {
			String[] subFiles = file.list();
			if (ArrayUtil.isEmpty(subFiles)) {
				return true;
			}
		} else if (file.isFile()) {
			return file.length() <= 0;
		}

		return false;
	}"
"protected void createCreateTicketGrantingTicketAction(final Flow flow) {
        val action = createActionState(flow, CasWebflowConstants.STATE_ID_CREATE_TICKET_GRANTING_TICKET, CasWebflowConstants.ACTION_ID_CREATE_TICKET_GRANTING_TICKET);
        createTransitionForState(action, CasWebflowConstants.TRANSITION_ID_SUCCESS_WITH_WARNINGS, CasWebflowConstants.STATE_ID_SHOW_AUTHN_WARNING_MSGS);
        createTransitionForState(action, CasWebflowConstants.TRANSITION_ID_SUCCESS, CasWebflowConstants.STATE_ID_SEND_TICKET_GRANTING_TICKET);
    }"
"private static <T> Class<T> readTypeClass(DataInputView in, ClassLoader userCodeClassLoader) throws IOException {
		return InstantiationUtil.resolveClassByName(in, userCodeClassLoader);
	}"
"public static CharSequence subSequence(final CharSequence cs, final int start) {
        return cs == null ? null : cs.subSequence(start, cs.length());
    }"
"public void set(long index, T value)
    {
        array[segment(index)][offset(index)] = value;
    }"
"public static BufferedOutputStream toBuffered(OutputStream out) {
		return (out instanceof BufferedOutputStream) ? (BufferedOutputStream) out : new BufferedOutputStream(out);
	}"
"public static <T> List<T> toList(JSONArray jsonArray, Class<T> elementType) {
		return null == jsonArray ? null : jsonArray.toList(elementType);
	}"
"public final void sendingResponse(HttpTrace trace, TraceableResponse response,
			Supplier<Principal> principal, Supplier<String> sessionId) {
		setIfIncluded(Include.TIME_TAKEN,
				() -> System.currentTimeMillis() - trace.getTimestamp().toEpochMilli(),
				trace::setTimeTaken);
		setIfIncluded(Include.SESSION_ID, sessionId, trace::setSessionId);
		setIfIncluded(Include.PRINCIPAL, principal, trace::setPrincipal);
		trace.setResponse(
				new HttpTrace.Response(new FilteredTraceableResponse(response)));
	}"
"@ReadOperation
    public Ticket getToken(@Selector final String ticketId) {
        var ticket = (Ticket) ticketRegistry.getTicket(ticketId, AccessToken.class);
        if (ticket == null) {
            ticket = ticketRegistry.getTicket(ticketId, RefreshToken.class);
        }
        if (ticket == null) {
            LOGGER.debug(""Ticket [{}] is not found"", ticketId);
            return null;
        }
        if (ticket.isExpired()) {
            LOGGER.debug(""Ticket [{}] is has expired"", ticketId);
            return null;
        }
        return ticket;
    }"
"@Override
    protected boolean shouldDoSpnego(final String remoteIp) {
        val ipCheck = ipPatternCanBeChecked(remoteIp);
        if (ipCheck && !ipPatternMatches(remoteIp)) {
            return false;
        }
        val hostName = getRemoteHostName(remoteIp);
        LOGGER.debug(""Retrieved host name for the remote ip is [{}]"", hostName);
        return this.hostNamePatternString.matcher(hostName).find();
    }"
"private void fillBlankCell(String preCoordinate, String curCoordinate, boolean isEnd) {
		if (false == curCoordinate.equals(preCoordinate)) {
			int len = ExcelSaxUtil.countNullCell(preCoordinate, curCoordinate);
			if (isEnd) {
				len++;
			}
			while (len-- > 0) {
				rowCellList.add(curCell++, """");
			}
		}
	}"
"@SuppressWarnings({ ""unchecked"", ""rawtypes"" })
    public void add(Future future) {
        checkAddAllowed();
        checkInEventLoop();
        ++expectedCount;
        future.addListener(listener);
    }"
"public boolean canPing() {
        try {
            val connection = (HttpURLConnection) new URL(this.swivelUrl).openConnection();
            connection.setRequestMethod(HttpMethod.GET.name());
            connection.connect();
            return connection.getResponseCode() == HttpStatus.SC_OK;
        } catch (final Exception e) {
            LOGGER.warn(e.getMessage(), e);
        }
        return false;
    }"
"protected boolean isTargetUriInScope(String uri) {
		if (uri == null) {
			return false;
		}
		return getModel().getSession().isInScope(uri);
	}"
"public void transfer(E e) throws InterruptedException {
        if (xfer(e, true, SYNC, 0) != null) {
            Thread.interrupted(); // failure possible only due to interrupt
            throw new InterruptedException();
        }
    }"
"public void nodeSelected(SiteNode node) {
		if (node != null) {
			siteModel.setSelectedItem(ScanPanel.cleanSiteName(node, true));
		}
	}"
"public AsciiString replace(char oldChar, char newChar) {
        if (oldChar > MAX_CHAR_VALUE) {
            return this;
        }

        final byte oldCharAsByte = c2b0(oldChar);
        final byte newCharAsByte = c2b(newChar);
        final int len = offset + length;
        for (int i = offset; i < len; ++i) {
            if (value[i] == oldCharAsByte) {
                byte[] buffer = PlatformDependent.allocateUninitializedArray(length());
                System.arraycopy(value, offset, buffer, 0, i - offset);
                buffer[i - offset] = newCharAsByte;
                ++i;
                for (; i < len; ++i) {
                    byte oldValue = value[i];
                    buffer[i - offset] = oldValue != oldCharAsByte ? oldValue : newCharAsByte;
                }
                return new AsciiString(buffer, false);
            }
        }
        return this;
    }"
"protected void buildEntityCriteriaForSigningCredential(final RequestAbstractType profileRequest, final CriteriaSet criteriaSet) {
        criteriaSet.add(new EntityIdCriterion(SamlIdPUtils.getIssuerFromSamlObject(profileRequest)));
        criteriaSet.add(new EntityRoleCriterion(SPSSODescriptor.DEFAULT_ELEMENT_NAME));
    }"
"@SuppressWarnings(""UnusedParameters"")
    protected ByteBuf extractObject(ChannelHandlerContext ctx, ByteBuf buffer, int index, int length) {
        return buffer.retainedSlice(index, length);
    }"
"@Override
	protected List<OUT> executeOnCollections(List<IN> inputData, RuntimeContext ctx, ExecutionConfig executionConfig) throws Exception {
		GroupReduceFunction<IN, OUT> function = this.userFunction.getUserCodeObject();

		UnaryOperatorInformation<IN, OUT> operatorInfo = getOperatorInfo();
		TypeInformation<IN> inputType = operatorInfo.getInputType();

		int[] keyColumns = getKeyColumns(0);
		int[] sortColumns = keyColumns;
		boolean[] sortOrderings = new boolean[sortColumns.length];

		if (groupOrder != null) {
			sortColumns = ArrayUtils.addAll(sortColumns, groupOrder.getFieldPositions());
			sortOrderings = ArrayUtils.addAll(sortOrderings, groupOrder.getFieldSortDirections());
		}

		if(sortColumns.length == 0) { // => all reduce. No comparator
			checkArgument(sortOrderings.length == 0);
		} else {
			final TypeComparator<IN> sortComparator = getTypeComparator(inputType, sortColumns, sortOrderings, executionConfig);
			Collections.sort(inputData, new Comparator<IN>() {
				@Override
				public int compare(IN o1, IN o2) {
					return sortComparator.compare(o1, o2);
				}
			});
		}

		FunctionUtils.setFunctionRuntimeContext(function, ctx);
		FunctionUtils.openFunction(function, this.parameters);
		
		ArrayList<OUT> result = new ArrayList<OUT>();

		if (inputData.size() > 0) {
			final TypeSerializer<IN> inputSerializer = inputType.createSerializer(executionConfig);
			if (keyColumns.length == 0) {
				TypeSerializer<OUT> outSerializer = getOperatorInfo().getOutputType().createSerializer(executionConfig);
				List<IN> inputDataCopy = new ArrayList<IN>(inputData.size());
				for (IN in : inputData) {
					inputDataCopy.add(inputSerializer.copy(in));
				}
				CopyingListCollector<OUT> collector = new CopyingListCollector<OUT>(result, outSerializer);

				function.reduce(inputDataCopy, collector);
			} else {
				boolean[] keyOrderings = new boolean[keyColumns.length];
				final TypeComparator<IN> comparator = getTypeComparator(inputType, keyColumns, keyOrderings, executionConfig);

				ListKeyGroupedIterator<IN> keyedIterator = new ListKeyGroupedIterator<IN>(inputData, inputSerializer, comparator);

				TypeSerializer<OUT> outSerializer = getOperatorInfo().getOutputType().createSerializer(executionConfig);
				CopyingListCollector<OUT> collector = new CopyingListCollector<OUT>(result, outSerializer);

				while (keyedIterator.nextKey()) {
					function.reduce(keyedIterator.getValues(), collector);
				}
			}
		}

		FunctionUtils.closeFunction(function);
		return result;
	}"
"private void restoreKeyGroupsInStateHandle()
		throws IOException, StateMigrationException, RocksDBException {
		try {
			currentStateHandleInStream = currentKeyGroupsStateHandle.openInputStream();
			cancelStreamRegistry.registerCloseable(currentStateHandleInStream);
			currentStateHandleInView = new DataInputViewStreamWrapper(currentStateHandleInStream);
			restoreKVStateMetaData();
			restoreKVStateData();
		} finally {
			if (cancelStreamRegistry.unregisterCloseable(currentStateHandleInStream)) {
				IOUtils.closeQuietly(currentStateHandleInStream);
			}
		}
	}"
"public String getCookieValue(String name) {
		HttpCookie cookie = getCookie(name);
		return (null == cookie) ? null : cookie.getValue();
	}"
"private State updateStateWithBackOff(final long timeoutInNanos) {
        AtomicRateLimiter.State prev;
        AtomicRateLimiter.State next;
        do {
            prev = state.get();
            next = calculateNextState(timeoutInNanos, prev);
        } while (!compareAndSet(prev, next));
        return next;
    }"
"@Override
  protected Map<String, String> getLagPerPartition(Map<String, String> currentOffsets)
  {
    return ImmutableMap.of();
  }"
"@Override
  public boolean moveToNext()
  {
    clearCombinedRowsInfo();
    if (nextRowPointer == null) {
      currentTimeAndDimsPointer = null;
      return false;
    }
    // This line implicitly uses the property of RowIterator.getPointer() (see [*] below), that it's still valid after
    // RowPointer.moveToNext() returns false. mergingIterator.moveToNext() could have returned false during the previous
    // call to this method, RowCombiningTimeAndDimsIterator.moveToNext().
    startNewTimeAndDims(nextRowPointer);
    nextRowPointer = null;
    // [1] -- see comment in startNewTimeAndDims()
    mergingIterator.mark();
    // [2] -- see comment in startNewTimeAndDims()
    while (mergingIterator.moveToNext()) {
      if (mergingIterator.hasTimeAndDimsChangedSinceMark()) {
        nextRowPointer = mergingIterator.getPointer(); // [*]
        return true;
      } else {
        combineToCurrentTimeAndDims(mergingIterator.getPointer());
      }
    }
    // No more rows left in mergingIterator
    nextRowPointer = null;
    return true;
  }"
"public PythonSingleOutputStreamOperator filter(FilterFunction<PyObject> filter) throws IOException {
		return new PythonSingleOutputStreamOperator(stream.filter(new PythonFilterFunction(filter)));
	}"
"public static void putRecaptchaPropertiesFlowScope(final RequestContext context, final GoogleRecaptchaProperties googleRecaptcha) {
        val flowScope = context.getFlowScope();
        flowScope.put(""recaptchaSiteKey"", googleRecaptcha.getSiteKey());
        flowScope.put(""recaptchaInvisible"", googleRecaptcha.isInvisible());
        flowScope.put(""recaptchaPosition"", googleRecaptcha.getPosition());
        flowScope.put(""recaptchaVersion"", googleRecaptcha.getVersion().name().toLowerCase());
    }"
"public SDVariable gt(String name, SDVariable other){
        return sameDiff.gt(name, this, other);
    }"
"@Override
	public void clearPartitions() {
		// clear the iterators, so the next call to next() will notice
		this.bucketIterator = null;
		this.probeIterator = null;

		for (int i = this.partitionsBeingBuilt.size() - 1; i >= 0; --i) {
			final BinaryHashPartition p = this.partitionsBeingBuilt.get(i);
			try {
				p.clearAllMemory(this.availableMemory);
			} catch (Exception e) {
				LOG.error(""Error during partition cleanup."", e);
			}
		}
		this.partitionsBeingBuilt.clear();

		// clear the partitions that are still to be done (that have files on disk)
		for (final BinaryHashPartition p : this.partitionsPending) {
			p.clearAllMemory(this.availableMemory);
		}
	}"
"private static List<Integer> parseRange(String value, int step, ValueParser parser) {
		final List<Integer> results = new ArrayList<>();
		
		// 全部匹配形式
		if (value.length() <= 2) {
			//根据步进的第一个数字确定起始时间，类似于 12/3则从12（秒、分等）开始
			int minValue = parser.getMin();
			if(false == isMatchAllStr(value)) {
				minValue = Math.max(minValue, parser.parse(value));
			}else {
				//在全匹配模式下，如果步进不存在，表示步进为1
				if(step < 1) {
					step = 1;
				}
			}
			if(step > 0) {
				final int maxValue = parser.getMax();
				if(minValue > maxValue) {
					throw new CronException(""Invalid value {} > {}"", minValue, maxValue);
				}
				//有步进
				for (int i = minValue; i <= maxValue; i+=step) {
					results.add(i);
				}
			} else {
				//固定时间
				results.add(minValue);
			}
			return results;
		}

		//Range模式
		List<String> parts = StrUtil.split(value, '-');
		int size = parts.size();
		if (size == 1) {// 普通值
			final int v1 = parser.parse(value);
			if(step > 0) {//类似 20/2的形式
				NumberUtil.appendRange(v1, parser.getMax(), step, results);
			}else {
				results.add(v1);
			}
		} else if (size == 2) {// range值
			final int v1 = parser.parse(parts.get(0));
			final int v2 = parser.parse(parts.get(1));
			if(step < 1) {
				//在range模式下，如果步进不存在，表示步进为1
				step = 1;
			}
			if (v1 < v2) {// 正常范围，例如：2-5
				NumberUtil.appendRange(v1, v2, step, results);
			} else if (v1 > v2) {// 逆向范围，反选模式，例如：5-2
				NumberUtil.appendRange(v1, parser.getMax(), step, results);
				NumberUtil.appendRange(parser.getMin(), v2, step, results);
			} else {// v1 == v2，此时与单值模式一致
				if(step > 0) {//类似 20/2的形式
					NumberUtil.appendRange(v1, parser.getMax(), step, results);
				}else {
					results.add(v1);
				}
			}
		} else {
			throw new CronException(""Invalid syntax of field: [{}]"", value);
		}
		return results;
	}"
"private Class findClassInComponents(String name)
        throws ClassNotFoundException {
        // we need to search the components of the path to see if
        // we can find the class we want.
        String classFilename = getClassFilename(name);
        Enumeration e = pathComponents.elements();
        while (e.hasMoreElements()) {
            File pathComponent = (File) e.nextElement();
            try (final InputStream stream = getResourceStream(pathComponent, classFilename)) {
                if (stream != null) {
                    log(""Loaded from "" + pathComponent + "" ""
                        + classFilename, Project.MSG_DEBUG);
                    return getClassFromStream(stream, name, pathComponent);
                }
            } catch (SecurityException se) {
                throw se;
            } catch (IOException ioe) {
                // ioe.printStackTrace();
                log(""Exception reading component "" + pathComponent + "" (reason: ""
                        + ioe.getMessage() + "")"", Project.MSG_VERBOSE);
            }
        }
        throw new ClassNotFoundException(name);
    }"
"@JsonCreator
  public static PolygonBound from(
      @JsonProperty(""abscissa"") float[] abscissa,
      @JsonProperty(""ordinate"") float[] ordinate,
      @JsonProperty(""limit"") int limit
  )
  {
    Preconditions.checkArgument(abscissa.length == ordinate.length); //abscissa and ordinate should be the same length
    Preconditions.checkArgument(abscissa.length > 2); //a polygon should have more than 2 corners
    return new PolygonBound(abscissa, ordinate, limit);
  }"
"@VisibleForTesting
  Set<DataSegment> refreshSegments(final Set<DataSegment> segments) throws IOException
  {
    final Set<DataSegment> retVal = new HashSet<>();

    // Organize segments by dataSource.
    final Map<String, TreeSet<DataSegment>> segmentMap = new TreeMap<>();

    for (DataSegment segment : segments) {
      segmentMap.computeIfAbsent(segment.getDataSource(), x -> new TreeSet<>(SEGMENT_ORDER))
                .add(segment);
    }

    for (Map.Entry<String, TreeSet<DataSegment>> entry : segmentMap.entrySet()) {
      final String dataSource = entry.getKey();
      retVal.addAll(refreshSegmentsForDataSource(dataSource, entry.getValue()));
    }

    return retVal;
  }"
"public void delete() throws IOException {
        String idKey = idStrategy().keyFor(id);
        File existingUserFolder = getExistingUserFolder();
        UserIdMapper.getInstance().remove(id);
        AllUsers.remove(id);
        deleteExistingUserFolder(existingUserFolder);
        UserDetailsCache.get().invalidate(idKey);
    }"
"public static BitMatrix encode(String content, QrConfig config) {
		return encode(content, BarcodeFormat.QR_CODE, config);
	}"
"public void setUpdateIssues(String updateIssues, boolean addOnIssues) {
		Validate.notNull(updateIssues, ""Parameter updateIssues must not be null."");

		this.updateIssues = updateIssues;
		this.addOnUpdateIssues = addOnIssues;
	}"
"private static <T> List<TableFactory> filterByFactoryClass(
		Class<T> factoryClass,
		Map<String, String> properties,
		List<TableFactory> foundFactories) {

		List<TableFactory> classFactories = foundFactories.stream()
			.filter(p -> factoryClass.isAssignableFrom(p.getClass()))
			.collect(Collectors.toList());

		if (classFactories.isEmpty()) {
			throw new NoMatchingTableFactoryException(
				String.format(""No factory implements '%s'."", factoryClass.getCanonicalName()),
				factoryClass,
				foundFactories,
				properties);
		}

		return classFactories;
	}"
"public static Set<String> getFileNameByPackageName(Context context, final String packageName) throws PackageManager.NameNotFoundException, IOException, InterruptedException {
        final Set<String> classNames = new HashSet<>();

        List<String> paths = getSourcePaths(context);
        final CountDownLatch parserCtl = new CountDownLatch(paths.size());

        for (final String path : paths) {
            DefaultPoolExecutor.getInstance().execute(new Runnable() {
                @Override
                public void run() {
                    DexFile dexfile = null;

                    try {
                        if (path.endsWith(EXTRACTED_SUFFIX)) {
                            //NOT use new DexFile(path), because it will throw ""permission error in /data/dalvik-cache""
                            dexfile = DexFile.loadDex(path, path + "".tmp"", 0);
                        } else {
                            dexfile = new DexFile(path);
                        }

                        Enumeration<String> dexEntries = dexfile.entries();
                        while (dexEntries.hasMoreElements()) {
                            String className = dexEntries.nextElement();
                            if (className.startsWith(packageName)) {
                                classNames.add(className);
                            }
                        }
                    } catch (Throwable ignore) {
                        Log.e(""ARouter"", ""Scan map file in dex files made error."", ignore);
                    } finally {
                        if (null != dexfile) {
                            try {
                                dexfile.close();
                            } catch (Throwable ignore) {
                            }
                        }

                        parserCtl.countDown();
                    }
                }
            });
        }

        parserCtl.await();

        Log.d(Consts.TAG, ""Filter "" + classNames.size() + "" classes by packageName <"" + packageName + "">"");
        return classNames;
    }"
"public LogicSchema getLogicSchema(final String schemaName) {
        return Strings.isNullOrEmpty(schemaName) ? null : logicSchemas.get(schemaName);
    }"
"public void append(int element)
    {
        if (this.size == this.data.length)
        {
            expand();
        }
        this.data[this.size] = element;
        this.size += 1;
    }"
"@DELETE
    public Response cancelLease(
            @HeaderParam(PeerEurekaNode.HEADER_REPLICATION) String isReplication) {
        try {
            boolean isSuccess = registry.cancel(app.getName(), id,
                ""true"".equals(isReplication));

            if (isSuccess) {
                logger.debug(""Found (Cancel): {} - {}"", app.getName(), id);
                return Response.ok().build();
            } else {
                logger.info(""Not Found (Cancel): {} - {}"", app.getName(), id);
                return Response.status(Status.NOT_FOUND).build();
            }
        } catch (Throwable e) {
            logger.error(""Error (cancel): {} - {}"", app.getName(), id, e);
            return Response.serverError().build();
        }

    }"
"public void show() {
		appWindow.setVisible(true);
		if (OsUtils.getOS() == OS.MAC_OS_X) {
			try {
				AppleNativeLook.go();
			} catch (Throwable ignore) {
				//We're just prettying up the app. If it fails, meh.
			}
		}
	}"
"public String decodeSamlAuthnRequest(final String encodedRequestXmlString) {
        if (StringUtils.isEmpty(encodedRequestXmlString)) {
            return null;
        }

        val decodedBytes = EncodingUtils.decodeBase64(encodedRequestXmlString);
        if (decodedBytes == null) {
            return null;
        }

        return inflateAuthnRequest(decodedBytes);
    }"
"private static FactorFilter<Executor, ExecutableFlow> getCpuStatusFilter() {
    return FactorFilter
        .create(CPUSTATUS_FILTER_NAME, new FactorFilter.Filter<Executor, ExecutableFlow>() {
          private static final int MAX_CPU_CURRENT_USAGE = 95;

          @Override
          public boolean filterTarget(final Executor filteringTarget,
              final ExecutableFlow referencingObject) {
            if (null == filteringTarget) {
              logger.debug(String
                  .format(""%s : filtering out the target as it is null."", CPUSTATUS_FILTER_NAME));
              return false;
            }

            final ExecutorInfo stats = filteringTarget.getExecutorInfo();
            if (null == stats) {
              logger.debug(String.format(""%s : filtering out %s as it's stats is unavailable."",
                  CPUSTATUS_FILTER_NAME,
                  filteringTarget.toString()));
              return false;
            }
            return stats.getCpuUsage() < MAX_CPU_CURRENT_USAGE;
          }
        });
  }"
"@Bean
  @Order(1)
  ArmeriaServerConfigurator notFoundMetricCollector() {
    // Use glob instead of catch-all to avoid adding it to the trie router.
    return sb -> sb.service(PathMapping.ofGlob(""/**""), (ctx, req) -> HttpResponse.of(HttpStatus.NOT_FOUND));
  }"
"public static String getJavaVersionIssue(AddOn.BaseRunRequirements requirements) {
        if (!requirements.isNewerJavaVersionRequired()) {
            return null;
        }

        if (requirements.getAddOn() != requirements.getAddOnMinimumJavaVersion()) {
            return MessageFormat.format(
                    ""Minimum Java version: {0} (\""{1}\"" add-on)"",
                    requirements.getMinimumJavaVersion(),
                    requirements.getAddOnMinimumJavaVersion().getName());
        }
        return MessageFormat.format(""Minimum Java version: {0}"", requirements.getMinimumJavaVersion());
    }"
"public static String md5Hex(String data, String charset) {
		return new MD5().digestHex(data, charset);
	}"
"public JobSubmissionResult run(PackagedProgram prog, int parallelism)
			throws ProgramInvocationException, ProgramMissingJobException {
		Thread.currentThread().setContextClassLoader(prog.getUserCodeClassLoader());
		if (prog.isUsingProgramEntryPoint()) {

			final JobWithJars jobWithJars = prog.getPlanWithJars();

			return run(jobWithJars, parallelism, prog.getSavepointSettings());
		}
		else if (prog.isUsingInteractiveMode()) {
			log.info(""Starting program in interactive mode (detached: {})"", isDetached());

			final List<URL> libraries = prog.getAllLibraries();

			ContextEnvironmentFactory factory = new ContextEnvironmentFactory(this, libraries,
					prog.getClasspaths(), prog.getUserCodeClassLoader(), parallelism, isDetached(),
					prog.getSavepointSettings());
			ContextEnvironment.setAsContext(factory);

			try {
				// invoke main method
				prog.invokeInteractiveModeForExecution();
				if (lastJobExecutionResult == null && factory.getLastEnvCreated() == null) {
					throw new ProgramMissingJobException(""The program didn't contain a Flink job."");
				}
				if (isDetached()) {
					// in detached mode, we execute the whole user code to extract the Flink job, afterwards we run it here
					return ((DetachedEnvironment) factory.getLastEnvCreated()).finalizeExecute();
				}
				else {
					// in blocking mode, we execute all Flink jobs contained in the user code and then return here
					return this.lastJobExecutionResult;
				}
			}
			finally {
				ContextEnvironment.unsetContext();
			}
		}
		else {
			throw new ProgramInvocationException(""PackagedProgram does not have a valid invocation mode."");
		}
	}"
"public Token getMatchedToken(final int tokenType) throws RecognitionException {
        Token result = parser.getCurrentToken();
        boolean isIdentifierCompatible = false;
        if (identifierTokenIndex == tokenType && identifierTokenIndex > result.getType()) {
            isIdentifierCompatible = true;
        }
        if (result.getType() == tokenType || isIdentifierCompatible) {
            if (Token.EOF != tokenType && isIdentifierCompatible && result instanceof CommonToken) {
                ((CommonToken) result).setType(identifierTokenIndex);
            }
            parser.getErrorHandler().reportMatch(parser);
            parser.consume();
        } else {
            result = parser.getErrorHandler().recoverInline(parser);
            if (parser.getBuildParseTree() && -1 == result.getTokenIndex()) {
                parser.getContext().addErrorNode(parser.createErrorNode(parser.getContext(), result));
            }
        }
        return result;
    }"
"protected int findBucketWithAutoGrowth(
      final ByteBuffer keyBuffer,
      final int keyHash
  )
  {
    int bucket = findBucket(canAllowNewBucket(), maxBuckets, tableBuffer, keyBuffer, keyHash);

    if (bucket < 0) {
      if (size < maxSizeForTesting) {
        adjustTableWhenFull();
        bucket = findBucket(size < regrowthThreshold, maxBuckets, tableBuffer, keyBuffer, keyHash);
      }
    }

    return bucket;
  }"
"public float[] getQuantiles(float[] probabilities)
  {
    for (float p : probabilities) {
      Preconditions.checkArgument(0 < p && p < 1, ""quantile probabilities must be strictly between 0 and 1"");
    }

    float[] quantiles = new float[probabilities.length];
    Arrays.fill(quantiles, Float.NaN);

    if (this.count() == 0) {
      return quantiles;
    }

    final long[] bins = this.bins();

    for (int j = 0; j < probabilities.length; ++j) {
      // Adapted from Ben-Haiv/Tom-Tov (Algorithm 4: Uniform Procedure)
      // Our histogram has a set of bins {(p1, m1), (p2, m2), ... (pB, mB)}
      // and properties of min and max saved during construction, such
      // that min <= p1 and pB <= max.
      //
      // When min < p1 or pB < max, these are special cases of using the
      // dummy bins (p0, 0) or (pB+1, 0) respectively, where p0 == min
      // and pB+1 == max.
      //
      // This histogram gives an ordered set of numbers {pi, pi+1, ..., pn},
      // such that min <= pi < pn <= max, and n is the sum({m1, ..., mB}).
      // We use s to determine which pairs of (pi, mi), (pi+1, mi+1) to
      // calculate our quantile from by computing sum([pi,mi]) < s < sum
      // ([pi+1, mi+1])
      final double s = probabilities[j] * this.count();

      int i = 0;
      int sum = 0;
      int k = 1;
      long count;
      while (k <= this.binCount()) {
        count = bins[k - 1];
        if (sum + count > s) {
          i = k - 1;
          break;
        } else {
          sum += count;
        }
        ++k;
      }

      if (i == 0) {
        // At the first bin, there are no points to the left of p (min)
        quantiles[j] = this.min();
      } else {
        final double d = s - sum;
        final double c = -2 * d;
        final long a = bins[i] - bins[i - 1];
        final long b = 2 * bins[i - 1];
        double z;
        if (a == 0) {
          z = -c / b;
        } else {
          z = (-b + Math.sqrt(b * b - 4 * a * c)) / (2 * a);
        }
        final double uj = this.positions[i - 1] + (this.positions[i] - this.positions[i - 1]) * z;
        // A given bin (p, m) has m/2 points to the left and right of p, and
        // uj could be one of those points. However, uj is still subject to:
        // [min] (p0, 0) < uj < (p, m) or
        //                      (p, m) < uj < (pB+1, 0) [max]
        quantiles[j] = ((float) uj < this.max()) ? (float) uj : this.max();
      }
    }

    return quantiles;
  }"
"public final String functionIdentifier() {
		final String md5 = EncodingUtils.hex(EncodingUtils.md5(EncodingUtils.encodeObjectToString(this)));
		return getClass().getCanonicalName().replace('.', '$').concat(""$"").concat(md5);
	}"
"public void addTextFieldReadOnly(int tabIndex, String fieldLabel, String value) {
		addTextComponent(tabIndex, new ZapLabel(), fieldLabel, value);
	}"
"public static boolean parseBoolean(String bool, boolean defaultInt) {
        if (bool == null) {
            return defaultInt;
        } else {
            return Boolean.parseBoolean(bool);
        }
    }"
"private ByteBuf decodeStruct(ChannelHandlerContext ctx, ByteBuf buffer) throws Exception {
        final int eoh = findEndOfHeader(buffer);
        if (!discarding) {
            if (eoh >= 0) {
                final int length = eoh - buffer.readerIndex();
                if (length > v2MaxHeaderSize) {
                    buffer.readerIndex(eoh);
                    failOverLimit(ctx, length);
                    return null;
                }
                return buffer.readSlice(length);
            } else {
                final int length = buffer.readableBytes();
                if (length > v2MaxHeaderSize) {
                    discardedBytes = length;
                    buffer.skipBytes(length);
                    discarding = true;
                    failOverLimit(ctx, ""over "" + discardedBytes);
                }
                return null;
            }
        } else {
            if (eoh >= 0) {
                buffer.readerIndex(eoh);
                discardedBytes = 0;
                discarding = false;
            } else {
                discardedBytes = buffer.readableBytes();
                buffer.skipBytes(discardedBytes);
            }
            return null;
        }
    }"
"public static List<String> extract(String text, int size)
    {
        IPhraseExtractor extractor = new MutualInformationEntropyPhraseExtractor();
        return extractor.extractPhrase(text, size);
    }"
"public static IActivation getIActivationFromConfig(Map<String, Object> layerConfig, KerasLayerConfiguration conf)
            throws InvalidKerasConfigurationException, UnsupportedKerasConfigurationException {
        return getActivationFromConfig(layerConfig, conf).getActivationFunction();
    }"
"public <T> T setIfNull(Class<T> type, T instance) {
        Object o = data.putIfAbsent(type, instance);
        if (o!=null)    return type.cast(o);
        return instance;
    }"
"public static String toIpString(InetSocketAddress address) {
        if (address == null) {
            return null;
        } else {
            InetAddress inetAddress = address.getAddress();
            return inetAddress == null ? address.getHostName() :
                inetAddress.getHostAddress();
        }
    }"
"private void rename(File legacyFile, File newFile) throws IOException {
        if (!legacyFile.exists())   return;
        if (newFile.exists()) {
            Util.deleteFile(newFile);
        }
        if (!legacyFile.renameTo(newFile)) {
            LOGGER.warning(""Failed to rename "" + legacyFile + "" to "" + newFile);
        }
    }"
"public static void adjustNoChunkedEncoding(ClientRequest request, String requestBody) {
        String fixedLengthString = request.getRequestHeaders().getFirst(Headers.CONTENT_LENGTH);
        String transferEncodingString = request.getRequestHeaders().getLast(Headers.TRANSFER_ENCODING);
        if(transferEncodingString != null) {
            request.getRequestHeaders().remove(Headers.TRANSFER_ENCODING);
        }
        //if already specify a content-length, should use what they provided
        if(fixedLengthString != null && Long.parseLong(fixedLengthString) > 0) {
            return;
        }
        if(!StringUtils.isEmpty(requestBody)) {
            long contentLength = requestBody.getBytes(UTF_8).length;
            request.getRequestHeaders().put(Headers.CONTENT_LENGTH, contentLength);
        }

    }"
"public static <K, V> LRUCache<K, V> newLRUCache(int capacity, long timeout){
		return new LRUCache<K, V>(capacity, timeout);
	}"
"@Restricted(NoExternalUse.class)
    public boolean hasFreshToken(@Nonnull User user, @Nullable ApiTokenProperty.TokenInfoAndStats legacyStats) {
        if (legacyStats == null) {
            return false;
        }
        
        ApiTokenProperty apiTokenProperty = user.getProperty(ApiTokenProperty.class);
        
        return apiTokenProperty.getTokenList().stream()
                .filter(token -> !token.isLegacy)
                .anyMatch(token -> {
                    Date creationDate = token.creationDate;
                    Date lastUseDate = legacyStats.lastUseDate;
                    if (lastUseDate == null) {
                        lastUseDate = legacyStats.creationDate;
                    }
                    return creationDate != null && lastUseDate != null && creationDate.after(lastUseDate);
                });
    }"
"public static DataSource createDataSource(final byte[] yamlBytes) throws SQLException, IOException {
        YamlOrchestrationShardingRuleConfiguration config = unmarshal(yamlBytes);
        return createDataSource(config.getDataSources(), config.getShardingRule(), config.getProps(), config.getOrchestration());
    }"
"public static List<ListViewColumn> createDefaultInitialColumnList(View view) {
        return createDefaultInitialColumnList(DescriptorVisibilityFilter.apply(view, ListViewColumn.all()));
    }"
"@Override
    public boolean cancel(boolean mayInterruptIfRunning) {
        if (RESULT_UPDATER.compareAndSet(this, null, CANCELLATION_CAUSE_HOLDER)) {
            if (checkNotifyWaiters()) {
                notifyListeners();
            }
            return true;
        }
        return false;
    }"
"public static PlanNodeStatsEstimate subtractSubsetStats(PlanNodeStatsEstimate superset, PlanNodeStatsEstimate subset)
    {
        if (superset.isOutputRowCountUnknown() || subset.isOutputRowCountUnknown()) {
            return PlanNodeStatsEstimate.unknown();
        }

        double supersetRowCount = superset.getOutputRowCount();
        double subsetRowCount = subset.getOutputRowCount();
        double outputRowCount = max(supersetRowCount - subsetRowCount, 0);

        // everything will be filtered out after applying negation
        if (outputRowCount == 0) {
            return createZeroStats(superset);
        }

        PlanNodeStatsEstimate.Builder result = PlanNodeStatsEstimate.builder();
        result.setOutputRowCount(outputRowCount);

        superset.getSymbolsWithKnownStatistics().forEach(symbol -> {
            SymbolStatsEstimate supersetSymbolStats = superset.getSymbolStatistics(symbol);
            SymbolStatsEstimate subsetSymbolStats = subset.getSymbolStatistics(symbol);

            SymbolStatsEstimate.Builder newSymbolStats = SymbolStatsEstimate.builder();

            // for simplicity keep the average row size the same as in the input
            // in most cases the average row size doesn't change after applying filters
            newSymbolStats.setAverageRowSize(supersetSymbolStats.getAverageRowSize());

            // nullsCount
            double supersetNullsCount = supersetSymbolStats.getNullsFraction() * supersetRowCount;
            double subsetNullsCount = subsetSymbolStats.getNullsFraction() * subsetRowCount;
            double newNullsCount = max(supersetNullsCount - subsetNullsCount, 0);
            newSymbolStats.setNullsFraction(min(newNullsCount, outputRowCount) / outputRowCount);

            // distinctValuesCount
            double supersetDistinctValues = supersetSymbolStats.getDistinctValuesCount();
            double subsetDistinctValues = subsetSymbolStats.getDistinctValuesCount();
            double newDistinctValuesCount;
            if (isNaN(supersetDistinctValues) || isNaN(subsetDistinctValues)) {
                newDistinctValuesCount = NaN;
            }
            else if (supersetDistinctValues == 0) {
                newDistinctValuesCount = 0;
            }
            else if (subsetDistinctValues == 0) {
                newDistinctValuesCount = supersetDistinctValues;
            }
            else {
                double supersetNonNullsCount = supersetRowCount - supersetNullsCount;
                double subsetNonNullsCount = subsetRowCount - subsetNullsCount;
                double supersetValuesPerDistinctValue = supersetNonNullsCount / supersetDistinctValues;
                double subsetValuesPerDistinctValue = subsetNonNullsCount / subsetDistinctValues;
                if (supersetValuesPerDistinctValue <= subsetValuesPerDistinctValue) {
                    newDistinctValuesCount = max(supersetDistinctValues - subsetDistinctValues, 0);
                }
                else {
                    newDistinctValuesCount = supersetDistinctValues;
                }
            }
            newSymbolStats.setDistinctValuesCount(newDistinctValuesCount);

            // range
            newSymbolStats.setLowValue(supersetSymbolStats.getLowValue());
            newSymbolStats.setHighValue(supersetSymbolStats.getHighValue());

            result.addSymbolStatistics(symbol, newSymbolStats.build());
        });

        return result.build();
    }"
"private JTextPane getTxtLicense() {
		if (txtLicense == null) {
			txtLicense = new JTextPane();
			txtLicense.setName(""txtLicense"");
			txtLicense.setEditable(false);
		}
		return txtLicense;
	}"
"protected NumberRule selectNumberRule(final int field, final int padding) {
		switch (padding) {
			case 1:
				return new UnpaddedNumberField(field);
			case 2:
				return new TwoDigitNumberField(field);
			default:
				return new PaddedNumberField(field, padding);
		}
	}"
"private void cancelInvokable(AbstractInvokable invokable) {
		// in case of an exception during execution, we still call ""cancel()"" on the task
		if (invokable != null && invokableHasBeenCanceled.compareAndSet(false, true)) {
			try {
				invokable.cancel();
			}
			catch (Throwable t) {
				LOG.error(""Error while canceling task {}."", taskNameWithSubtask, t);
			}
		}
	}"
"public static void writeModel(@NonNull Model model, @NonNull OutputStream stream, boolean saveUpdater,DataNormalization dataNormalization)
            throws IOException {
        ZipOutputStream zipfile = new ZipOutputStream(new CloseShieldOutputStream(stream));

        // Save configuration as JSON
        String json = """";
        if (model instanceof MultiLayerNetwork) {
            json = ((MultiLayerNetwork) model).getLayerWiseConfigurations().toJson();
        } else if (model instanceof ComputationGraph) {
            json = ((ComputationGraph) model).getConfiguration().toJson();
        }

        ZipEntry config = new ZipEntry(CONFIGURATION_JSON);
        zipfile.putNextEntry(config);
        zipfile.write(json.getBytes());

        // Save parameters as binary
        ZipEntry coefficients = new ZipEntry(COEFFICIENTS_BIN);
        zipfile.putNextEntry(coefficients);
        DataOutputStream dos = new DataOutputStream(new BufferedOutputStream(zipfile));
        INDArray params = model.params();
        if(params != null) {
            try {
                Nd4j.write(model.params(), dos);
            } finally {
                dos.flush();
            }
        } else {
            ZipEntry noParamsMarker = new ZipEntry(NO_PARAMS_MARKER);
            zipfile.putNextEntry(noParamsMarker);
        }

        if (saveUpdater) {
            INDArray updaterState = null;
            if (model instanceof MultiLayerNetwork) {
                updaterState = ((MultiLayerNetwork) model).getUpdater().getStateViewArray();
            } else if (model instanceof ComputationGraph) {
                updaterState = ((ComputationGraph) model).getUpdater().getStateViewArray();
            }

            if (updaterState != null && updaterState.length() > 0) {
                ZipEntry updater = new ZipEntry(UPDATER_BIN);
                zipfile.putNextEntry(updater);

                try {
                    Nd4j.write(updaterState, dos);
                } finally {
                    dos.flush();
                }
            }
        }


        if(dataNormalization != null) {
            // now, add our normalizer as additional entry
            ZipEntry nEntry = new ZipEntry(NORMALIZER_BIN);
            zipfile.putNextEntry(nEntry);
            NormalizerSerializer.getDefault().write(dataNormalization, zipfile);
        }

        dos.close();
        zipfile.close();
    }"
"final void runWorker(WorkQueue w) {
        w.growArray(false);         // initialize queue array in this thread
        do { w.runTask(scan(w)); } while (w.runState >= 0);
    }"
"public NameID getNameID(final String nameIdFormat, final String nameIdValue) {
        val nameId = newSamlObject(NameID.class);
        nameId.setFormat(nameIdFormat);
        nameId.setValue(nameIdValue);
        return nameId;
    }"
"public void unregisterTaskManager(InstanceID instanceId, boolean terminated){
		Instance instance = registeredHostsById.get(instanceId);

		if (instance != null){
			registeredHostsById.remove(instance.getId());
			registeredHostsByResource.remove(instance.getTaskManagerID());

			if (terminated) {
				deadHosts.add(instance.getTaskManagerID());
			}

			instance.markDead();

			totalNumberOfAliveTaskSlots -= instance.getTotalNumberOfSlots();

			notifyDeadInstance(instance);

			LOG.info(
				""Unregistered task manager "" + instance.getTaskManagerLocation().addressString() +
				"". Number of registered task managers "" + getNumberOfRegisteredTaskManagers() +
				"". Number of available slots "" + getTotalNumberOfSlots() + ""."");
		} else {
			LOG.warn(""Tried to unregister instance {} but it is not registered."", instanceId);
		}
	}"
"public static SPSSODescriptor getSPSsoDescriptor(final EntityDescriptor entityDescriptor) {
        LOGGER.trace(""Locating SP SSO descriptor for SAML2 protocol..."");
        var spssoDescriptor = entityDescriptor.getSPSSODescriptor(SAMLConstants.SAML20P_NS);
        if (spssoDescriptor == null) {
            LOGGER.trace(""Locating SP SSO descriptor for SAML11 protocol..."");
            spssoDescriptor = entityDescriptor.getSPSSODescriptor(SAMLConstants.SAML11P_NS);
        }
        if (spssoDescriptor == null) {
            LOGGER.trace(""Locating SP SSO descriptor for SAML1 protocol..."");
            spssoDescriptor = entityDescriptor.getSPSSODescriptor(SAMLConstants.SAML10P_NS);
        }
        LOGGER.trace(""SP SSO descriptor resolved to be [{}]"", spssoDescriptor);
        return spssoDescriptor;
    }"
"static RowBlock createRowBlockInternal(int startOffset, int positionCount, @Nullable boolean[] rowIsNull, int[] fieldBlockOffsets, Block[] fieldBlocks)
    {
        validateConstructorArguments(startOffset, positionCount, rowIsNull, fieldBlockOffsets, fieldBlocks);
        return new RowBlock(startOffset, positionCount, rowIsNull, fieldBlockOffsets, fieldBlocks);
    }"
"public static void compareProviders(List<ProviderInfo> oldList, List<ProviderInfo> newList,
                                        List<ProviderInfo> add, List<ProviderInfo> remove) {
        // 比较老列表和当前列表
        if (CommonUtils.isEmpty(oldList)) {
            // 空变成非空
            if (CommonUtils.isNotEmpty(newList)) {
                add.addAll(newList);
            }
            // 空到空，忽略
        } else {
            // 非空变成空
            if (CommonUtils.isEmpty(newList)) {
                remove.addAll(oldList);
            } else {
                // 非空变成非空，比较
                if (CommonUtils.isNotEmpty(oldList)) {
                    List<ProviderInfo> tmpList = new ArrayList<ProviderInfo>(newList);
                    // 遍历老的
                    for (ProviderInfo oldProvider : oldList) {
                        if (tmpList.contains(oldProvider)) {
                            tmpList.remove(oldProvider);
                        } else {
                            // 新的没有，老的有，删掉
                            remove.add(oldProvider);
                        }
                    }
                    add.addAll(tmpList);
                }
            }
        }
    }"
"public boolean exists(ResourcePatternResolver resolver) {
		Assert.notNull(resolver, ""Resolver must not be null"");
		if (resolver.getResource(this.path).exists()) {
			return true;
		}
		try {
			return anyExists(resolver);
		}
		catch (IOException ex) {
			return false;
		}
	}"
"public ResponseType execute() {
        try {
            return queue().get();
        } catch (Throwable e) {
            if (e instanceof HystrixRuntimeException) {
                throw (HystrixRuntimeException) e;
            }
            // if we have an exception we know about we'll throw it directly without the threading wrapper exception
            if (e.getCause() instanceof HystrixRuntimeException) {
                throw (HystrixRuntimeException) e.getCause();
            }
            // we don't know what kind of exception this is so create a generic message and throw a new HystrixRuntimeException
            String message = getClass().getSimpleName() + "" HystrixCollapser failed while executing."";
            logger.debug(message, e); // debug only since we're throwing the exception and someone higher will do something with it
            //TODO should this be made a HystrixRuntimeException?
            throw new RuntimeException(message, e);
        }
    }"
"public void start() {
        if (hasRedissonInstance) {
            redisson = Redisson.create(config);
        }
        
        retrieveAddresses();
        
        if (config.getRedissonNodeInitializer() != null) {
            config.getRedissonNodeInitializer().onStartup(this);
        }
        
        int mapReduceWorkers = config.getMapReduceWorkers();
        if (mapReduceWorkers != -1) {
            if (mapReduceWorkers == 0) {
                mapReduceWorkers = Runtime.getRuntime().availableProcessors();
            }
            redisson.getExecutorService(RExecutorService.MAPREDUCE_NAME).registerWorkers(mapReduceWorkers);
            log.info(""{} map reduce worker(s) registered"", mapReduceWorkers);
        }
        
        for (Entry<String, Integer> entry : config.getExecutorServiceWorkers().entrySet()) {
            String name = entry.getKey();
            int workers = entry.getValue();
            redisson.getExecutorService(name).registerWorkers(workers);
            log.info(""{} worker(s) for '{}' ExecutorService registered"", workers, name);
        }

        log.info(""Redisson node started!"");
    }"
"public static File mkdirs(File dir) throws IOException {
        try {
            return Files.createDirectories(fileToPath(dir)).toFile();
        } catch (UnsupportedOperationException e) {
            throw new IOException(e);
        }
    }"
"public RestTemplateBuilder messageConverters(
			Collection<? extends HttpMessageConverter<?>> messageConverters) {
		Assert.notNull(messageConverters, ""MessageConverters must not be null"");
		return new RestTemplateBuilder(this.detectRequestFactory, this.rootUri,
				Collections.unmodifiableSet(
						new LinkedHashSet<HttpMessageConverter<?>>(messageConverters)),
				this.requestFactorySupplier, this.uriTemplateHandler, this.errorHandler,
				this.basicAuthentication, this.restTemplateCustomizers,
				this.requestFactoryCustomizer, this.interceptors);
	}"
"@Override
    public InterfaceHttpData getBodyHttpData(String name) {
        checkDestroyed();

        if (!isLastChunk) {
            throw new NotEnoughDataDecoderException();
        }
        List<InterfaceHttpData> list = bodyMapHttpData.get(name);
        if (list != null) {
            return list.get(0);
        }
        return null;
    }"
"private int getStatement() {
        checkValue = baseValue;
        baseValue = DATDictionary.getItem(checkValue).getBase() + charHashCode;
        if (baseValue < DATDictionary.arrayLength && (DATDictionary.getItem(baseValue).getCheck() == checkValue
                        || DATDictionary.getItem(baseValue).getCheck() == -1)) {
            return DATDictionary.getItem(baseValue).getStatus();
        }
        return 0;
    }"
"public void init(Session session, Charset charset) {
		this.session = session;
		init(JschUtil.openSftp(session), charset);
	}"
"public FilterInfo verifyFilter(String sFilterCode) throws org.codehaus.groovy.control.CompilationFailedException, IllegalAccessException, InstantiationException {
        Class groovyClass = compileGroovy(sFilterCode);
        Object instance = instanciateClass(groovyClass);
        checkZuulFilterInstance(instance);
        BaseFilter filter = (BaseFilter) instance;


        String filter_id = FilterInfo.buildFilterID(ZuulApplicationInfo.getApplicationName(), filter.filterType(), groovyClass.getSimpleName());

        return new FilterInfo(filter_id, sFilterCode, filter.filterType(), groovyClass.getSimpleName(), filter.disablePropertyName(), """" + filter.filterOrder(), ZuulApplicationInfo.getApplicationName());
    }"
"public @Nonnull <U extends T> U getInstance(@Nonnull Class<U> type) throws IllegalStateException {
        for (T ext : this)
            if(ext.getClass()==type)
                return type.cast(ext);
        
        throw new IllegalStateException(""The class "" + type.getName() + "" was not found, potentially not yet loaded"");
    }"
"public void threadDump(String reasonMsg) {
		logger.info(""Thread dump by ThreadDumpper"" + (reasonMsg != null ? ("" for "" + reasonMsg) : """"));

		Map<Thread, StackTraceElement[]> threads = Thread.getAllStackTraces();
		// 两条日志间的时间间隔，是VM被thread dump堵塞的时间.
		logger.info(""Finish the threads snapshot"");

		StringBuilder sb = new StringBuilder(8192 * 20).append('\n');

		for (Entry<Thread, StackTraceElement[]> entry : threads.entrySet()) {
			dumpThreadInfo(entry.getKey(), entry.getValue(), sb);
		}
		logger.info(sb.toString());
	}"
"public ListIterator<IWord> findFirstWordIteratorByLabel(String label)
    {
        ListIterator<IWord> listIterator = this.wordList.listIterator();
        while (listIterator.hasNext())
        {
            IWord word = listIterator.next();
            if (label.equals(word.getLabel()))
            {
                return listIterator;
            }
        }
        return null;
    }"
"public boolean hasToken() {
        if (getParameter(RpcConstants.HIDDEN_KEY_TOKEN) != null) {
            return true;
        }
        if (CommonUtils.isNotEmpty(methods)) {
            for (MethodConfig methodConfig : methods.values()) {
                if (methodConfig.getParameter(RpcConstants.HIDDEN_KEY_TOKEN) != null) {
                    return true;
                }
            }
        }
        return false;
    }"
"public static void cut(ImageInputStream srcStream, ImageOutputStream destStream, Rectangle rectangle) {
		cut(read(srcStream), destStream, rectangle);
	}"
"public static String getZodiac(Calendar calendar) {
		if (null == calendar) {
			return null;
		}
		return getZodiac(calendar.get(Calendar.MONTH), calendar.get(Calendar.DAY_OF_MONTH));
	}"
"@Override
    public void onOnline(Computer c, TaskListener listener) throws IOException, InterruptedException {
        synchronized(this) {
            future.cancel(false);
            future = Timer.get().schedule(MONITOR_UPDATER, 5, TimeUnit.SECONDS);
        }
    }"
"public static List<String> toLines(final InputStream input) throws IOException {
		return CharStreams.readLines(new BufferedReader(new InputStreamReader(input, Charsets.UTF_8)));
	}"
"@Override
    public List<Record> loadFromMetaData(List<RecordMetaData> recordMetaDatas) throws IOException {
        return recordReader.loadFromMetaData(recordMetaDatas);
    }"
"public void freeMemory(AllocationPoint point) {
        if (point.getAllocationStatus() == AllocationStatus.DEVICE) {
            this.getMemoryHandler().getMemoryProvider().free(point);
            point.setAllocationStatus(AllocationStatus.HOST);
            this.getMemoryHandler().getMemoryProvider().free(point);
            this.getMemoryHandler().forget(point, AllocationStatus.DEVICE);
        } else {
            // call it only once
            this.getMemoryHandler().getMemoryProvider().free(point);
            this.getMemoryHandler().forget(point, AllocationStatus.HOST);
        }

        allocationsMap.remove(point.getObjectId());
    }"
"@View(name = ""by_type_for_principal_id_since"", map = ""function(doc) { emit([doc.type, doc.principal, doc.creationTime], doc) }"")
    public Collection<CouchDbCasEvent> findByTypeForPrincipalSince(final String type, final String principalId, final LocalDateTime localDeateTime) {
        val view = createQuery(""by_type_for_principal_id_since"").startKey(ComplexKey.of(type, principalId, localDeateTime))
            .endKey(ComplexKey.of(type, principalId, LocalDateTime.now()));
        return db.queryView(view, CouchDbCasEvent.class);
    }"
"public ParameterParser getFormParamParser(String url) {
		List<Context> contexts = getContextsForUrl(url);
		if (contexts.size() > 0) {
			return contexts.get(0).getPostParamParser();
		}
		return this.defaultParamParser;
	}"
"public static Config fromJSON(String content) throws IOException {
        ConfigSupport support = new ConfigSupport();
        return support.fromJSON(content, Config.class);
    }"
"public static int jodaToCalciteDate(final DateTime dateTime, final DateTimeZone timeZone)
  {
    final DateTime date = dateTime.withZone(timeZone).dayOfMonth().roundFloorCopy();
    return Days.daysBetween(DateTimes.EPOCH, date.withZoneRetainFields(DateTimeZone.UTC)).getDays();
  }"
"public JSONArray put(int index, boolean value) throws JSONException {
    put(index, value ? Boolean.TRUE : Boolean.FALSE);
    return this;
  }"
"public static Font getFont (Font font, Size size) {
		float s;
		switch (size) {
		case smallest:		s = (float) (font.getSize() * 0.5); break;
		case much_smaller:	s = (float) (font.getSize() * 0.7); break;
		case smaller:		s = (float) (font.getSize() * 0.8); break;
		case standard:		s = (float) font.getSize(); break;
		case larger:		s = (float) (font.getSize() * 1.5); break;
		case much_larger:	s = (float) (font.getSize() * 3); break;
		case huge:			s = (float) (font.getSize() * 4); break;
		default: 			s = (float) (font.getSize()); break;
		}
		return font.deriveFont(s);
	}"
"public HttpRequest form(String name, File file, String fileName) {
		if (null != file) {
			form(name, new FileResource(file, fileName));
		}
		return this;
	}"
"public static void serverReceived(NettyHttpRequest request) {
        try {
            SofaRequest sofaRequest = new SofaRequest();

            HttpHeaders headers = request.getHttpHeaders();
            String rpcTraceContext = headers.getHeaderString(RemotingConstants.NEW_RPC_TRACE_NAME);
            if (StringUtils.isNotBlank(rpcTraceContext)) {
                // 新格式
                sofaRequest.addRequestProp(RemotingConstants.NEW_RPC_TRACE_NAME, rpcTraceContext);
            } else {
                String traceIdKey = headers.getHeaderString(RemotingConstants.HTTP_HEADER_TRACE_ID_KEY);
                String rpcIdKey = headers.getHeaderString(RemotingConstants.HTTP_HEADER_RPC_ID_KEY);
                if (StringUtils.isEmpty(rpcIdKey)) {
                    rpcIdKey = request.getUri().getQueryParameters().getFirst(RemotingConstants.RPC_ID_KEY);
                }
                if (StringUtils.isEmpty(traceIdKey)) {
                    traceIdKey = request.getUri().getQueryParameters().getFirst(RemotingConstants.TRACE_ID_KEY);
                }

                if (StringUtils.isNotEmpty(traceIdKey) && StringUtils.isNotEmpty(rpcIdKey)) {
                    Map<String, String> map = new HashMap<String, String>();
                    map.put(RemotingConstants.TRACE_ID_KEY, traceIdKey);
                    map.put(RemotingConstants.RPC_ID_KEY, rpcIdKey);
                    String penAttrs = headers.getHeaderString(RemotingConstants.PEN_ATTRS_KEY);
                    map.put(RemotingConstants.PEN_ATTRS_KEY, penAttrs);
                    sofaRequest.addRequestProp(RemotingConstants.RPC_TRACE_NAME, map);
                }
            }
            Tracers.serverReceived(sofaRequest);
        } catch (Throwable t) {
            if (LOGGER.isWarnEnabled()) {
                LOGGER.warn(""the process of rest tracer server receive occur error "", t);
            }
        }
    }"
"public static <T> ConsoleAnnotator<T> combine(Collection<? extends ConsoleAnnotator<? super T>> all) {
        switch (all.size()) {
        case 0:     return null;    // none
        case 1:     return  cast(all.iterator().next()); // just one
        }

        return new ConsoleAnnotatorAggregator<>(all);
    }"
"@Override
  public SessionHandle openSessionWithImpersonation(String username, String password, Map<String, String> configuration,
      String delegationToken) throws HiveSQLException {
    SessionHandle sessionHandle = sessionManager.openSession(SERVER_VERSION, username, password, null, configuration,
        true, delegationToken);
    LOG.debug(sessionHandle + "": openSession()"");
    return sessionHandle;
  }"
"protected void initClusters() {
        log.info(""Generating initial clusters"");
        List<Point> points = new ArrayList<>(initialPoints);

        //Initialize the ClusterSet with a single cluster center (based on position of one of the points chosen randomly)
        val random = Nd4j.getRandom();
        Distance distanceFn = clusteringStrategy.getDistanceFunction();
        int initialClusterCount = clusteringStrategy.getInitialClusterCount();
        clusterSet = new ClusterSet(distanceFn,
                        clusteringStrategy.inverseDistanceCalculation(), new long[]{initialClusterCount, points.get(0).getArray().length()});
        clusterSet.addNewClusterWithCenter(points.remove(random.nextInt(points.size())));


        //dxs: distances between
        // each point and nearest cluster to that point
        INDArray dxs = Nd4j.create(points.size());
        dxs.addi(clusteringStrategy.inverseDistanceCalculation() ? -Double.MAX_VALUE : Double.MAX_VALUE);

        //Generate the initial cluster centers, by randomly selecting a point between 0 and max distance
        //Thus, we are more likely to select (as a new cluster center) a point that is far from an existing cluster
        while (clusterSet.getClusterCount() < initialClusterCount && !points.isEmpty()) {
            dxs = ClusterUtils.computeSquareDistancesFromNearestCluster(clusterSet, points, dxs, exec);
            double r = random.nextFloat() * dxs.maxNumber().doubleValue();
            for (int i = 0; i < dxs.length(); i++) {
                double distance = dxs.getDouble(i);
                Preconditions.checkState(distance >= 0, ""Encountered negative distance: distance function is not valid? Distance "" +
                        ""function must return values >= 0, got distance %s for function s"", distance, distanceFn);
                if (dxs.getDouble(i) >= r) {
                    clusterSet.addNewClusterWithCenter(points.remove(i));
                    dxs = Nd4j.create(ArrayUtils.remove(dxs.data().asDouble(), i));
                    break;
                }
            }
        }

        ClusterSetInfo initialClusterSetInfo = ClusterUtils.computeClusterSetInfo(clusterSet);
        iterationHistory.getIterationsInfos().put(currentIteration,
                        new IterationInfo(currentIteration, initialClusterSetInfo));
    }"
"private static void validateFormatForViewAction(Format format) throws ApiException {
		switch (format) {
		case JSON:
		case JSONP:
		case XML:
		case HTML:
			return;
		default:
			throw new ApiException(ApiException.Type.BAD_FORMAT, ""The format OTHER should not be used with views and actions."");
		}
	}"
"private boolean upgrade(final ChannelHandlerContext ctx, final FullHttpRequest request) {
        // Select the best protocol based on those requested in the UPGRADE header.
        final List<CharSequence> requestedProtocols = splitHeader(request.headers().get(HttpHeaderNames.UPGRADE));
        final int numRequestedProtocols = requestedProtocols.size();
        UpgradeCodec upgradeCodec = null;
        CharSequence upgradeProtocol = null;
        for (int i = 0; i < numRequestedProtocols; i ++) {
            final CharSequence p = requestedProtocols.get(i);
            final UpgradeCodec c = upgradeCodecFactory.newUpgradeCodec(p);
            if (c != null) {
                upgradeProtocol = p;
                upgradeCodec = c;
                break;
            }
        }

        if (upgradeCodec == null) {
            // None of the requested protocols are supported, don't upgrade.
            return false;
        }

        // Make sure the CONNECTION header is present.
        List<String> connectionHeaderValues = request.headers().getAll(HttpHeaderNames.CONNECTION);

        if (connectionHeaderValues == null) {
            return false;
        }

        final StringBuilder concatenatedConnectionValue = new StringBuilder(connectionHeaderValues.size() * 10);
        for (CharSequence connectionHeaderValue : connectionHeaderValues) {
            concatenatedConnectionValue.append(connectionHeaderValue).append(COMMA);
        }
        concatenatedConnectionValue.setLength(concatenatedConnectionValue.length() - 1);

        // Make sure the CONNECTION header contains UPGRADE as well as all protocol-specific headers.
        Collection<CharSequence> requiredHeaders = upgradeCodec.requiredUpgradeHeaders();
        List<CharSequence> values = splitHeader(concatenatedConnectionValue);
        if (!containsContentEqualsIgnoreCase(values, HttpHeaderNames.UPGRADE) ||
                !containsAllContentEqualsIgnoreCase(values, requiredHeaders)) {
            return false;
        }

        // Ensure that all required protocol-specific headers are found in the request.
        for (CharSequence requiredHeader : requiredHeaders) {
            if (!request.headers().contains(requiredHeader)) {
                return false;
            }
        }

        // Prepare and send the upgrade response. Wait for this write to complete before upgrading,
        // since we need the old codec in-place to properly encode the response.
        final FullHttpResponse upgradeResponse = createUpgradeResponse(upgradeProtocol);
        if (!upgradeCodec.prepareUpgradeResponse(ctx, request, upgradeResponse.headers())) {
            return false;
        }

        // Create the user event to be fired once the upgrade completes.
        final UpgradeEvent event = new UpgradeEvent(upgradeProtocol, request);

        // After writing the upgrade response we immediately prepare the
        // pipeline for the next protocol to avoid a race between completion
        // of the write future and receiving data before the pipeline is
        // restructured.
        try {
            final ChannelFuture writeComplete = ctx.writeAndFlush(upgradeResponse);
            // Perform the upgrade to the new protocol.
            sourceCodec.upgradeFrom(ctx);
            upgradeCodec.upgradeTo(ctx, request);

            // Remove this handler from the pipeline.
            ctx.pipeline().remove(HttpServerUpgradeHandler.this);

            // Notify that the upgrade has occurred. Retain the event to offset
            // the release() in the finally block.
            ctx.fireUserEventTriggered(event.retain());

            // Add the listener last to avoid firing upgrade logic after
            // the channel is already closed since the listener may fire
            // immediately if the write failed eagerly.
            writeComplete.addListener(ChannelFutureListener.CLOSE_ON_FAILURE);
        } finally {
            // Release the event if the upgrade event wasn't fired.
            event.release();
        }
        return true;
    }"
"protected static DefaultProcessDiagramCanvas.SHAPE_TYPE getShapeType(BaseElement baseElement) {
        if (baseElement instanceof Task || baseElement instanceof Activity || baseElement instanceof TextAnnotation) {
            return DefaultProcessDiagramCanvas.SHAPE_TYPE.Rectangle;
        } else if (baseElement instanceof Gateway) {
            return DefaultProcessDiagramCanvas.SHAPE_TYPE.Rhombus;
        } else if (baseElement instanceof Event) {
            return DefaultProcessDiagramCanvas.SHAPE_TYPE.Ellipse;
        }
        // unknown source element, just do not correct coordinates
        return null;
    }"
"@SuppressWarnings(""unchecked"")
    private Set<Field> scan() {
        Set<Field> mockDependentFields = new HashSet<Field>();
        Field[] fields = clazz.getDeclaredFields();
        for (Field field : fields) {
            if (null != field.getAnnotation(InjectMocks.class)) {
                assertNoAnnotations(field, Mock.class, Captor.class);
                mockDependentFields.add(field);
            }
        }

        return mockDependentFields;
    }"
"public boolean hasValidKey(HttpMessage msg) {
		try {
			HttpRequestHeader requestHeader = msg.getRequestHeader();
			return this.hasValidKey(requestHeader, getParams(requestHeader));
		} catch (ApiException e) {
			logger.error(e.getMessage(), e);
			return false;
		}
	}"
"public void addPolicies(final RegisteredServiceAttributeReleasePolicy... policies) {
        this.policies.addAll(Arrays.stream(policies).collect(Collectors.toList()));
    }"
"private void doPut(List<Event> data) {
        long current = putSequence.get();
        long end = current + data.size();

        // 先写数据，再更新对应的cursor,并发度高的情况，putSequence会被get请求可见，拿出了ringbuffer中的老的Entry值
        for (long next = current + 1; next <= end; next++) {
            entries[getIndex(next)] = data.get((int) (next - current - 1));
        }

        putSequence.set(end);

        // 记录一下gets memsize信息，方便快速检索
        if (batchMode.isMemSize()) {
            long size = 0;
            for (Event event : data) {
                size += calculateSize(event);
            }

            putMemSize.getAndAdd(size);
        }
        profiling(data, OP.PUT);
        // tell other threads that store is not empty
        notEmpty.signal();
    }"
"@Override
	public void write(DataOutputView out) throws IOException {
		out.writeInt(position);

		for (int i = 0; i < position; i++) {
			out.writeByte(data[i]);
		}
	}"
"public void hideWithAnimation() {
        if (transition == null || transition.getStatus().equals(Animation.Status.STOPPED)) {
            JFXAlertAnimation currentAnimation = getCurrentAnimation();
            Animation animation = currentAnimation.createHidingAnimation(getDialogPane().getContent(), getDialogPane());
            if (animation != null) {
                transition = animation;
                animation.setOnFinished(finish -> {
                    animateClosing = false;
                    hide();
                    transition = null;
                });
                animation.play();
            } else {
                animateClosing = false;
                transition = null;
                Platform.runLater(this::hide);
            }
        }
    }"
"private BasicTimeChecker getBasicTimeChecker(final Map<String, ConditionChecker> checkers) {
    for (final ConditionChecker checker : checkers.values()) {
      if (checker.getType().equals(BasicTimeChecker.type)) {
        return (BasicTimeChecker) checker;
      }
    }
    return null;
  }"
"public static <T> T[] concat(@Nullable T element, T[] array) {
		return ObjectArrays.concat(element, array);
	}"
"@PublicEvolving
	public void setResources(ResourceSpec minResources, ResourceSpec preferredResources) {
		this.minResources = minResources;
		this.preferredResources = preferredResources;
	}"
"@Override
	public boolean tryAssignPayload(Payload payload) {
		Preconditions.checkNotNull(payload);

		// check that we can actually run in this slot
		if (isCanceled()) {
			return false;
		}

		// atomically assign the vertex
		if (!PAYLOAD_UPDATER.compareAndSet(this, null, payload)) {
			return false;
		}

		// we need to do a double check that we were not cancelled in the meantime
		if (isCanceled()) {
			this.payload = null;
			return false;
		}

		return true;
	}"
"@Override
    public INDArray getParam(String param) {
        //Get params for MultiLayerNetwork sub layers.
        int idx = param.indexOf('_');
        if (idx == -1)
            throw new IllegalStateException(""Invalid param key: does not have layer separator: \"""" + param + ""\"""");
        int layerIdx = Integer.parseInt(param.substring(0, idx));
        String newKey = param.substring(idx + 1);

        return layers[layerIdx].getParam(newKey);
    }"
"private static JobVertexBackPressureInfo.VertexBackPressureLevel getBackPressureLevel(double backPressureRatio) {
		if (backPressureRatio <= 0.10) {
			return JobVertexBackPressureInfo.VertexBackPressureLevel.OK;
		} else if (backPressureRatio <= 0.5) {
			return JobVertexBackPressureInfo.VertexBackPressureLevel.LOW;
		} else {
			return JobVertexBackPressureInfo.VertexBackPressureLevel.HIGH;
		}
	}"
"void appendFailedModelParameters(Object[] rawParams, Exception e) {
    assert rawParams != null : ""Raw parameters should be always != null !"";
    appendFailedModelParameters(null, ArrayUtils.toString(rawParams), e.getMessage(), StringUtils.toString(e));
  }"
"public static final TracerFactory instance() {
        if(INSTANCE == null) throw new IllegalStateException(String.format(""%s not initialized"", TracerFactory.class.getSimpleName()));
        return INSTANCE;
    }"
"@SuppressWarnings(""unchecked"")
	public static <T extends Throwable> T wrap(Throwable throwable, Class<T> wrapThrowable) {
		if (wrapThrowable.isInstance(throwable)) {
			return (T) throwable;
		}
		return ReflectUtil.newInstance(wrapThrowable, throwable);
	}"
"public static Object getByXPath(String expression, Object source, QName returnType) {
		final XPath xPath = createXPath();
		try {
			if (source instanceof InputSource) {
				return xPath.evaluate(expression, (InputSource) source, returnType);
			} else {
				return xPath.evaluate(expression, source, returnType);
			}
		} catch (XPathExpressionException e) {
			throw new UtilException(e);
		}
	}"
"private static <T> T loadAndInstantiateClassImpl(
            AddOnClassLoader addOnClassLoader,
            String classname,
            Class<T> clazz,
            String type) {
        Class<?> cls;
        try {
            cls = addOnClassLoader.loadClass(classname);
        } catch (ClassNotFoundException e) {
            LOGGER.error(""Declared \"""" + type + ""\"" was not found: "" + classname, e);
            return null;
        } catch (LinkageError e) {
            LOGGER.error(""Declared \"""" + type + ""\"" could not be loaded: "" + classname, e);
            return null;
        }

        if (Modifier.isAbstract(cls.getModifiers()) || Modifier.isInterface(cls.getModifiers())) {
            LOGGER.error(""Declared \"""" + type + ""\"" is abstract or an interface: "" + classname);
            return null;
        }

        if (!clazz.isAssignableFrom(cls)) {
            LOGGER.error(""Declared \"""" + type + ""\"" is not of type \"""" + clazz.getName() + ""\"": "" + classname);
            return null;
        }

        try {
            @SuppressWarnings(""unchecked"")
            Constructor<T> c = (Constructor<T>) cls.getConstructor();
            return c.newInstance();
        } catch (LinkageError | Exception e) {
            LOGGER.error(""Failed to initialise: "" + classname, e);
        }
        return null;
    }"
"public CheckMethod getCheckMethod(String fieldName) {
        CheckMethod method = checkMethods.get(fieldName);
        if(method==null) {
            method = new CheckMethod(this,fieldName);
            checkMethods.put(fieldName,method);
        }

        return method;
    }"
"@Override
    public void collect(INDArray... arrays) {
        // we basically want to free memory, without touching INDArray itself.
        // so we don't care when gc is going to release object: memory is already cached

        Nd4j.getExecutioner().commit();

        int cnt = -1;
        AtomicAllocator allocator = AtomicAllocator.getInstance();
        for (INDArray array : arrays) {
            cnt++;
            // we don't collect views, since they don't have their own memory
            if (array == null || array.isView())
                continue;

            AllocationPoint point = allocator.getAllocationPoint(array);

            if (point.getAllocationStatus() == AllocationStatus.HOST)
                allocator.getMemoryHandler().free(point, AllocationStatus.HOST);
            else if (point.getAllocationStatus() == AllocationStatus.DEVICE) {
                allocator.getMemoryHandler().free(point, AllocationStatus.DEVICE);
                allocator.getMemoryHandler().free(point, AllocationStatus.HOST);
            } else if (point.getAllocationStatus() == AllocationStatus.DEALLOCATED) {
                // do nothing
            } else
                throw new RuntimeException(
                                ""Unknown AllocationStatus: "" + point.getAllocationStatus() + "" for argument: "" + cnt);

            point.setAllocationStatus(AllocationStatus.DEALLOCATED);
        }
    }"
"public static DescriptorExtensionList<SecurityRealm,Descriptor<SecurityRealm>> all() {
        return Jenkins.getInstance().<SecurityRealm,Descriptor<SecurityRealm>>getDescriptorList(SecurityRealm.class);
    }"
"public static EntryResolver newLdaptiveSearchEntryResolver(final AbstractLdapAuthenticationProperties l,
                                                               final PooledConnectionFactory factory) {
        if (StringUtils.isBlank(l.getBaseDn())) {
            throw new IllegalArgumentException(""To create a search entry resolver, base dn cannot be empty/blank "");
        }
        if (StringUtils.isBlank(l.getSearchFilter())) {
            throw new IllegalArgumentException(""To create a search entry resolver, user filter cannot be empty/blank"");
        }

        val entryResolver = new BinaryAttributeAwarePooledSearchEntryResolver();
        entryResolver.setBaseDn(l.getBaseDn());
        entryResolver.setUserFilter(l.getSearchFilter());
        entryResolver.setSubtreeSearch(l.isSubtreeSearch());
        entryResolver.setConnectionFactory(factory);
        entryResolver.setAllowMultipleEntries(l.isAllowMultipleEntries());
        entryResolver.setBinaryAttributes(l.getBinaryAttributes());

        if (StringUtils.isNotBlank(l.getDerefAliases())) {
            entryResolver.setDerefAliases(DerefAliases.valueOf(l.getDerefAliases()));
        }
        val handlers = new ArrayList<SearchEntryHandler>();
        l.getSearchEntryHandlers().forEach(h -> {
            switch (h.getType()) {
                case CASE_CHANGE:
                    val eh = new CaseChangeEntryHandler();
                    val caseChange = h.getCaseChange();
                    eh.setAttributeNameCaseChange(CaseChangeEntryHandler.CaseChange.valueOf(caseChange.getAttributeNameCaseChange()));
                    eh.setAttributeNames(caseChange.getAttributeNames().toArray(ArrayUtils.EMPTY_STRING_ARRAY));
                    eh.setAttributeValueCaseChange(CaseChangeEntryHandler.CaseChange.valueOf(caseChange.getAttributeValueCaseChange()));
                    eh.setDnCaseChange(CaseChangeEntryHandler.CaseChange.valueOf(caseChange.getDnCaseChange()));
                    handlers.add(eh);
                    break;
                case DN_ATTRIBUTE_ENTRY:
                    val ehd = new DnAttributeEntryHandler();
                    val dnAttribute = h.getDnAttribute();
                    ehd.setAddIfExists(dnAttribute.isAddIfExists());
                    ehd.setDnAttributeName(dnAttribute.getDnAttributeName());
                    handlers.add(ehd);
                    break;
                case MERGE:
                    val ehm = new MergeAttributeEntryHandler();
                    val mergeAttribute = h.getMergeAttribute();
                    ehm.setAttributeNames(mergeAttribute.getAttributeNames().toArray(ArrayUtils.EMPTY_STRING_ARRAY));
                    ehm.setMergeAttributeName(mergeAttribute.getMergeAttributeName());
                    handlers.add(ehm);
                    break;
                case OBJECT_GUID:
                    handlers.add(new ObjectGuidHandler());
                    break;
                case OBJECT_SID:
                    handlers.add(new ObjectSidHandler());
                    break;
                case PRIMARY_GROUP:
                    val ehp = new PrimaryGroupIdHandler();
                    val primaryGroupId = h.getPrimaryGroupId();
                    ehp.setBaseDn(primaryGroupId.getBaseDn());
                    ehp.setGroupFilter(primaryGroupId.getGroupFilter());
                    handlers.add(ehp);
                    break;
                case RANGE_ENTRY:
                    handlers.add(new RangeEntryHandler());
                    break;
                case RECURSIVE_ENTRY:
                    val recursive = h.getRecursive();
                    handlers.add(new RecursiveEntryHandler(recursive.getSearchAttribute(), recursive.getMergeAttributes().toArray(ArrayUtils.EMPTY_STRING_ARRAY)));
                    break;
                default:
                    break;
            }
        });

        if (!handlers.isEmpty()) {
            LOGGER.debug(""Search entry handlers defined for the entry resolver of [{}] are [{}]"", l.getLdapUrl(), handlers);
            entryResolver.setSearchEntryHandlers(handlers.toArray(SearchEntryHandler[]::new));
        }
        if (l.isFollowReferrals()) {
            entryResolver.setReferralHandler(new SearchReferralHandler());
        }
        return entryResolver;
    }"
"@Deprecated
    public static long parseTimeLiteral(TimeZoneKey timeZoneKey, String value)
    {
        try {
            return parseTimeWithTimeZone(value);
        }
        catch (Exception e) {
            return parseTimeWithoutTimeZone(timeZoneKey, value);
        }
    }"
"public static <T> Collection<T> addAll(Collection<T> collection, Iterable<T> iterable) {
		return addAll(collection, iterable.iterator());
	}"
"@SuppressWarnings(""unchecked"")
    protected List<RunT> getEstimatedDurationCandidates() {
        List<RunT> candidates = new ArrayList<>(3);
        RunT lastSuccessful = getLastSuccessfulBuild();
        int lastSuccessfulNumber = -1;
        if (lastSuccessful != null) {
            candidates.add(lastSuccessful);
            lastSuccessfulNumber = lastSuccessful.getNumber();
        }

        int i = 0;
        RunT r = getLastBuild();
        List<RunT> fallbackCandidates = new ArrayList<>(3);
        while (r != null && candidates.size() < 3 && i < 6) {
            if (!r.isBuilding() && r.getResult() != null && r.getNumber() != lastSuccessfulNumber) {
                Result result = r.getResult();
                if (result.isBetterOrEqualTo(Result.UNSTABLE)) {
                    candidates.add(r);
                } else if (result.isCompleteBuild()) {
                    fallbackCandidates.add(r);
                }
            }
            i++;
            r = r.getPreviousBuild();
        }
        
        while (candidates.size() < 3) {
            if (fallbackCandidates.isEmpty())
                break;
            RunT run = fallbackCandidates.remove(0);
            candidates.add(run);
        }
        
        return candidates;
    }"
"private void swap(int i, int j, int[] sbox) {
		int temp = sbox[i];
		sbox[i] = sbox[j];
		sbox[j] = temp;
	}"
"@SneakyThrows
    public void commitAll(final String message) {
        this.gitInstance.add().addFilepattern(""."").call();
        this.gitInstance.commit()
            .setMessage(message)
            .setAll(true)
            .setAuthor(""CAS"", ""cas@apereo.org"")
            .call();
    }"
"private static int getWebSocketContentLength(HttpMessage message) {
        // WebSocket messages have constant content-lengths.
        HttpHeaders h = message.headers();
        if (message instanceof HttpRequest) {
            HttpRequest req = (HttpRequest) message;
            if (HttpMethod.GET.equals(req.method()) &&
                    h.contains(HttpHeaderNames.SEC_WEBSOCKET_KEY1) &&
                    h.contains(HttpHeaderNames.SEC_WEBSOCKET_KEY2)) {
                return 8;
            }
        } else if (message instanceof HttpResponse) {
            HttpResponse res = (HttpResponse) message;
            if (res.status().code() == 101 &&
                    h.contains(HttpHeaderNames.SEC_WEBSOCKET_ORIGIN) &&
                    h.contains(HttpHeaderNames.SEC_WEBSOCKET_LOCATION)) {
                return 16;
            }
        }

        // Not a web socket message
        return -1;
    }"
"public static IntIterator mergeAscending(List<IntIterator> iterators)
  {
    if (iterators.isEmpty()) {
      return IntIterators.EMPTY_ITERATOR;
    }
    if (iterators.size() == 1) {
      return iterators.get(0);
    }
    return new MergeIntIterator(iterators);
  }"
"Long fit(long start, long duration, int n) {
        OUTER:
        while (true) {
            long t = start;
            // check if 'start' satisfies the two conditions by moving t across [start,start+duration)
            while ((t-start)<duration) {
                if (at(t)>n) {
                    // value too big. what's the next t that's worth trying?
                    Long nxt = next(t);
                    if (nxt==null)  return null;
                    start = nxt;
                    continue OUTER;
                } else {
                    Long nxt = next(t);
                    if (nxt==null) t = Long.MAX_VALUE;
                    else           t = nxt;
                }
            }
            // q(t) looks good at the entire [start,start+duration)
            return start;
        }
    }"
"public static <T extends Comparable<T>> RangeSet<T> unionRangeSets(final Iterable<RangeSet<T>> rangeSets)
  {
    final RangeSet<T> rangeSet = TreeRangeSet.create();
    for (RangeSet<T> set : rangeSets) {
      rangeSet.addAll(set);
    }
    return rangeSet;
  }"
"public static void slowLog(Logger logger, long duration, long threshold) {
		if (duration > threshold) {
			logger.warn(""[Performance Warning]  use {}ms, slow than {}ms"", duration, threshold);
		}
	}"
"public static void replaceWhere(@NonNull INDArray to, @NonNull INDArray from, @NonNull Condition condition) {
        if (!(condition instanceof BaseCondition))
            throw new UnsupportedOperationException(""Only static Conditions are supported"");

        if (to.length() != from.length())
            throw new IllegalStateException(""Mis matched length for to and from"");

        Nd4j.getExecutioner().exec(new CompareAndReplace(to, from, condition));
    }"
"private V replaceNoCopyOrAwait(K key, V value) {
    requireNonNull(value);
    V copy = copyOf(value);
    @SuppressWarnings(""unchecked"")
    V[] replaced = (V[]) new Object[1];
    cache.asMap().computeIfPresent(key, (k, expirable) -> {
      if (!expirable.isEternal() && expirable.hasExpired(currentTimeMillis())) {
        dispatcher.publishExpired(this, key, expirable.get());
        statistics.recordEvictions(1L);
        return null;
      }

      publishToCacheWriter(writer::write, () -> new EntryProxy<>(key, value));
      long expireTimeMS = getWriteExpireTimeMS(/* created */ false);
      if (expireTimeMS == Long.MIN_VALUE) {
        expireTimeMS = expirable.getExpireTimeMS();
      }
      dispatcher.publishUpdated(this, key, expirable.get(), copy);
      replaced[0] = expirable.get();
      return new Expirable<>(copy, expireTimeMS);
    });
    return replaced[0];
  }"
"static AnimatableValue<PointF, PointF> parseSplitPath(
      JsonReader reader, LottieComposition composition) throws IOException {

    AnimatablePathValue pathAnimation = null;
    AnimatableFloatValue xAnimation = null;
    AnimatableFloatValue yAnimation = null;

    boolean hasExpressions = false;

    reader.beginObject();
    while (reader.peek() != JsonToken.END_OBJECT) {
      switch (reader.nextName()) {
        case ""k"":
          pathAnimation = AnimatablePathValueParser.parse(reader, composition);
          break;
        case ""x"":
          if (reader.peek() == JsonToken.STRING) {
            hasExpressions = true;
            reader.skipValue();
          } else {
            xAnimation = AnimatableValueParser.parseFloat(reader, composition);
          }
          break;
        case ""y"":
          if (reader.peek() == JsonToken.STRING) {
            hasExpressions = true;
            reader.skipValue();
          } else {
            yAnimation = AnimatableValueParser.parseFloat(reader, composition);
          }
          break;
        default:
          reader.skipValue();
      }
    }
    reader.endObject();

    if (hasExpressions) {
      composition.addWarning(""Lottie doesn't support expressions."");
    }

    if (pathAnimation != null) {
      return pathAnimation;
    }
    return new AnimatableSplitDimensionPathValue(xAnimation, yAnimation);
  }"
"public static void cut(File srcImgFile, File destImgFile, Rectangle rectangle) {
		cut(read(srcImgFile), destImgFile, rectangle);
	}"
"protected long seekUnusedDevice(Long threadId, Integer deviceId, Aggressiveness aggressiveness) {
        AtomicLong freeSpace = new AtomicLong(0);


        //  int initialSize = allocations.size();

        // these 2 variables will contain jvm-wise memory access frequencies
        float shortAverage = deviceShort.getAverage();
        float longAverage = deviceLong.getAverage();

        // threshold is calculated based on agressiveness specified via configuration
        float shortThreshold = shortAverage / (Aggressiveness.values().length - aggressiveness.ordinal());
        float longThreshold = longAverage / (Aggressiveness.values().length - aggressiveness.ordinal());

        AtomicInteger elementsDropped = new AtomicInteger(0);
        AtomicInteger elementsMoved = new AtomicInteger(0);
        AtomicInteger elementsSurvived = new AtomicInteger(0);

        for (Long object : memoryHandler.getDeviceTrackingPoints(deviceId)) {
            AllocationPoint point = getAllocationPoint(object);

            //            if (point.getAccessState().isToeAvailable()) {
            //                point.getAccessState().requestToe();

            /*
                Check if memory points to non-existant buffer, using externals.
                If externals don't have specified buffer - delete reference.
             */
            if (point.getBuffer() == null) {
                if (point.getAllocationStatus() == AllocationStatus.DEVICE) {
                    // we deallocate device memory
                    purgeDeviceObject(threadId, deviceId, object, point, false);
                    freeSpace.addAndGet(AllocationUtils.getRequiredMemory(point.getShape()));

                    // and we deallocate host memory, since object is dereferenced
                    purgeZeroObject(point.getBucketId(), object, point, false);

                    elementsDropped.incrementAndGet();
                    continue;
                } ;
            } else {
                elementsSurvived.incrementAndGet();
            }

            /*
                Check, if memory can be removed from allocation.
                To check it, we just compare average rates for few tens of latest calls
             */
            /*
                long millisecondsTTL = configuration.getMinimumTTLMilliseconds();
                if (point.getRealDeviceAccessTime() < System.currentTimeMillis() - millisecondsTTL) {
                    // we could remove device allocation ONLY if it's older then minimum TTL
                    if (point.getTimerLong().getFrequencyOfEvents() < longThreshold && point.getTimerShort().getFrequencyOfEvents() < shortThreshold) {
                        //log.info(""Removing object: "" + object);
            
                        purgeDeviceObject(threadId, deviceId, object, point, true);
            
                        freeSpace.addAndGet(AllocationUtils.getRequiredMemory(point.getShape()));
            
                        elementsMoved.incrementAndGet();
            
                        //purgeDeviceObject(threadId, deviceId, object, point, true);
                    }
                }
            */
            //  point.getAccessState().releaseToe();
            //}
        }

        log.debug(""Thread/Device ["" + threadId + ""/"" + deviceId + ""] elements purged: ["" + elementsDropped.get()
                        + ""]; Relocated: ["" + elementsMoved.get() + ""]; Survivors: ["" + elementsSurvived.get() + ""]"");

        return freeSpace.get();
    }"
"@SuppressFBWarnings(""PRMC_POSSIBLY_REDUNDANT_METHOD_CALLS"")
    public void initServiceRegistryIfNecessary() {
        val size = this.serviceRegistry.size();
        LOGGER.trace(""Service registry contains [{}] service definition(s)"", size);

        LOGGER.warn(""Service registry [{}] will be auto-initialized from JSON service definitions. ""
            + ""This behavior is only useful for testing purposes and MAY NOT be appropriate for production. ""
            + ""Consider turning off this behavior via the setting [cas.serviceRegistry.initFromJson=false] ""
            + ""and explicitly register definitions in the services registry."", this.serviceRegistry.getName());

        val servicesLoaded = this.jsonServiceRegistry.load();
        LOGGER.debug(""Loaded JSON services are [{}]"", servicesLoaded.stream().map(RegisteredService::getName).collect(Collectors.joining("","")));

        servicesLoaded
            .forEach(r -> {
                if (!findExistingMatchForService(r)) {
                    LOGGER.debug(""Initializing service registry with the [{}] JSON service definition..."", r.getName());
                    this.serviceRegistry.save(r);
                }
            });
        this.servicesManager.load();
        LOGGER.info(""Service registry [{}] contains [{}] service definitions"", this.serviceRegistry.getName(), this.servicesManager.count());

    }"
"public static JarClassLoader load(File dir) {
		final JarClassLoader loader = new JarClassLoader();
		loader.addJar(dir);//查找加载所有jar
		loader.addURL(dir);//查找加载所有class
		return loader;
	}"
"private void encodeContentsFromShareIntent(Intent intent) throws WriterException {
    // Check if this is a plain text encoding, or contact
    if (intent.hasExtra(Intent.EXTRA_STREAM)) {
      encodeFromStreamExtra(intent);
    } else {
      encodeFromTextExtras(intent);
    }
  }"
"public static Class<?> getPluginClass(final String pluginClass, final File pluginDir,
      final List<String> extLibClassPaths, ClassLoader parentClassLoader) {

    URLClassLoader urlClassLoader =
        getURLClassLoader(pluginDir, extLibClassPaths, parentClassLoader);

    return getPluginClass(pluginClass, urlClassLoader);
  }"
"public static FastByteArrayOutputStream read(InputStream in) throws IORuntimeException {
		final FastByteArrayOutputStream out = new FastByteArrayOutputStream();
		copy(in, out);
		return out;
	}"
"@SuppressWarnings(""WeakerAccess"")
    @Internal
    protected final Stream streamOfTypeForMethodArgument(BeanResolutionContext resolutionContext, BeanContext context, MethodInjectionPoint injectionPoint, Argument argument) {
        return resolveBeanWithGenericsFromMethodArgument(resolutionContext, injectionPoint, argument, (beanType, qualifier) ->
                ((DefaultBeanContext) context).streamOfType(resolutionContext, beanType, qualifier)
        );
    }"
"@ShellMethod(key = ""validate-endpoint"", value = ""Test connections to an endpoint to verify connectivity, SSL, etc"")
    public void validateEndpoint(
        @ShellOption(value = {""url""},
            help = ""Endpoint URL to test"") final String url,
        @ShellOption(value = {""proxy""},
            help = ""Proxy address to use when testing the endpoint url"") final String proxy,
        @ShellOption(value = {""timeout""},
            help = ""Timeout to use in milliseconds when testing the url"",
            defaultValue = ""5000"") final int timeout) {

        try {
            LOGGER.info(""Trying to connect to [{}]"", url);
            val conn = createConnection(url, proxy);

            LOGGER.info(""Setting connection timeout to [{}]"", timeout);
            conn.setConnectTimeout(timeout);

            try (val reader = new InputStreamReader(conn.getInputStream(), StandardCharsets.UTF_8);
                 val in = new BufferedReader(reader)) {
                in.readLine();

                if (conn instanceof HttpURLConnection) {
                    val code = ((HttpURLConnection) conn).getResponseCode();
                    LOGGER.info(""Response status code received: [{}]"", code);
                }
                LOGGER.info(""Successfully connected to url [{}]"", url);
            }
        } catch (final Exception e) {
            LOGGER.info(""Could not connect to the host address [{}]"", url);
            LOGGER.info(""The error is: [{}]"", e.getMessage());
            LOGGER.info(""Here are the details:"");
            LOGGER.error(consolidateExceptionMessages(e));
            testBadTlsConnection(url, proxy);
        }
    }"
"private List<Pair<String, String>> loadFeatureName(Map<String, Integer> featureIndex, BufferedReader br)
                    throws Exception {
        String temp = br.readLine();// #qrk#num
        int featureNum = ObjConver.getIntValue(StringUtil.matcherFirst(""\\d+"", temp)); // 找到特征个数

        List<Pair<String, String>> featureNames = new ArrayList<>();

        for (int i = 0; i < featureNum; i++) {
            temp = br.readLine();

            String[] split = temp.split("":"");

            if (split.length == 2) {
                featureNames.add(Pair.with(split[1], """"));
                continue;
            } else {

                String name = split[2];

                if (split.length > 3) {
                    for (int j = 3; j < split.length; j++) {
                        name += "":"" + split[j];
                    }
                }

                // 去掉最后的空格
                name = name.substring(0, name.length() - 1);

                int lastFeatureId = featureIndex.get(split[1]);

                if (""/"".equals(name)) {
                    name = ""//"";
                }

                if (name.contains(""//"")) {
                    name = name.replaceAll(""//"", ""/XIEGANG/"");
                }
                String featureName = toFeatureName(name.trim().split(""/""), lastFeatureId);

                featureNames.add(Pair.with(split[1], featureName));

            }
        }

        return featureNames;

    }"
"public void revertFeatures(@NonNull INDArray[] features, INDArray[] maskArrays, int input) {
        NormalizerStrategy strategy = getStrategy(globalInputStrategy, perInputStrategies, input);
        if (strategy != null) {
            INDArray mask = (maskArrays == null ? null : maskArrays[input]);
            //noinspection unchecked
            strategy.revert(features[input], mask, getInputStats(input));
        }
    }"
"public static JSONObject toJSONObject(XMLTokener x) throws JSONException {
    return (JSONObject) parse(x, false, null);
  }"
"protected int transitionWithRoot(int nodePos, char c)
    {
        int b = base[nodePos];
        int p;

        p = b + c + 1;
        if (b != check[p])
        {
            if (nodePos == 0) return 0;
            return -1;
        }

        return p;
    }"
"public static V1BinaryAnnotation createString(String key, String value, Endpoint endpoint) {
    if (value == null) throw new NullPointerException(""value == null"");
    return new V1BinaryAnnotation(key, value, endpoint);
  }"
"protected Map<String, List<Object>> returnFinalAttributesCollection(final Map<String, List<Object>> attributesToRelease, final RegisteredService service) {
        LOGGER.debug(""Final collection of attributes allowed are: [{}]"", attributesToRelease);
        return attributesToRelease;
    }"
"private JCheckBox getChkProxyOnly() {
		if (proxyOnlyCheckbox == null) {
			proxyOnlyCheckbox = new JCheckBox();
			proxyOnlyCheckbox.setText(Constant.messages.getString(""httpsessions.options.label.proxyOnly""));
		}
		return proxyOnlyCheckbox;
	}"
"public static List<String> getServerAddrs() {
        Node node = ArbitrateConfigRegistry.getConfig().currentNode();
        if (node != null) {
            String addr = StringUtils.join(node.getParameters().getZkCluster().getServerList(), ',');
            return Arrays.asList(addr);
        } else {
            return new ArrayList<String>();
        }
    }"
"private static List<File> loopJar(File file) {
		return FileUtil.loopFiles(file, new FileFilter() {
			@Override
			public boolean accept(File file) {
				return isJarFile(file);
			}
		});
	}"
"public final long getBeUint32() {
        if (position + 3 >= origin + limit) throw new IllegalArgumentException(""limit excceed: ""
                                                                               + (position - origin + 3));

        byte[] buf = buffer;
        return ((long) (0xff & buf[position++]) << 24) | ((long) (0xff & buf[position++]) << 16)
               | ((long) (0xff & buf[position++]) << 8) | ((long) (0xff & buf[position++]));
    }"
"public static void assignIf(@NonNull INDArray to, @NonNull INDArray from, @NonNull Condition condition) {
        if (!(condition instanceof BaseCondition))
            throw new UnsupportedOperationException(""Only static Conditions are supported"");

        if (to.length() != from.length())
            throw new IllegalStateException(""Mis matched length for to and from"");

        Nd4j.getExecutioner().exec(new CompareAndSet(to, from, condition));
    }"
"private String getProxyUser(String realUser, Map<String, String> sessionConf,
      String ipAddress) throws HiveSQLException {
    String proxyUser = null;
    // Http transport mode.
    // We set the thread local proxy username, in ThriftHttpServlet.
    if (cliService.getHiveConf().getVar(
        ConfVars.HIVE_SERVER2_TRANSPORT_MODE).equalsIgnoreCase(""http"")) {
      proxyUser = SessionManager.getProxyUserName();
      LOG.debug(""Proxy user from query string: "" + proxyUser);
    }

    if (proxyUser == null && sessionConf != null && sessionConf.containsKey(HiveAuthFactory.HS2_PROXY_USER)) {
      String proxyUserFromThriftBody = sessionConf.get(HiveAuthFactory.HS2_PROXY_USER);
      LOG.debug(""Proxy user from thrift body: "" + proxyUserFromThriftBody);
      proxyUser = proxyUserFromThriftBody;
    }

    if (proxyUser == null) {
      return realUser;
    }

    // check whether substitution is allowed
    if (!hiveConf.getBoolVar(HiveConf.ConfVars.HIVE_SERVER2_ALLOW_USER_SUBSTITUTION)) {
      throw new HiveSQLException(""Proxy user substitution is not allowed"");
    }

    // If there's no authentication, then directly substitute the user
    if (HiveAuthFactory.AuthTypes.NONE.toString()
        .equalsIgnoreCase(hiveConf.getVar(ConfVars.HIVE_SERVER2_AUTHENTICATION))) {
      return proxyUser;
    }

    // Verify proxy user privilege of the realUser for the proxyUser
    HiveAuthFactory.verifyProxyAccess(realUser, proxyUser, ipAddress, hiveConf);
    LOG.debug(""Verified proxy user: "" + proxyUser);
    return proxyUser;
  }"
"public static JsonNode readMetadataUrl(URL url, int connectionTimeoutMs, int readTimeoutMs, ObjectMapper objectMapper, Map<String, String> requestProperties) throws IOException {
        URLConnection urlConnection = url.openConnection();

        if (url.getProtocol().equalsIgnoreCase(""file"")) {
            urlConnection.connect();
            try (InputStream in = urlConnection.getInputStream()) {
                return objectMapper.readTree(in);
            }
        } else {
            HttpURLConnection uc = (HttpURLConnection) urlConnection;
            uc.setConnectTimeout(connectionTimeoutMs);
            requestProperties.forEach(uc::setRequestProperty);
            uc.setReadTimeout(readTimeoutMs);
            uc.setRequestMethod(HttpMethod.GET.name());
            uc.setDoOutput(true);
            int responseCode = uc.getResponseCode();
            try (InputStream in = uc.getInputStream()) {
                return objectMapper.readTree(in);
            }
        }
    }"
"public static BufferedWriter asBufferedWriter(String fileName) throws IOException {
		Validate.notBlank(fileName, ""filename is blank"");
		return Files.newBufferedWriter(getPath(fileName), Charsets.UTF_8);
	}"
"@Override
	public Excel03SaxReader read(File file, int sheetIndex) throws POIException {
		try {
			return read(new POIFSFileSystem(file), sheetIndex);
		} catch (IOException e) {
			throw new POIException(e);
		}
	}"
"@Override
    public final void setEnabledProtocols(String[] protocols) {
        if (protocols == null) {
            // This is correct from the API docs
            throw new IllegalArgumentException();
        }
        int minProtocolIndex = OPENSSL_OP_NO_PROTOCOLS.length;
        int maxProtocolIndex = 0;
        for (String p: protocols) {
            if (!OpenSsl.SUPPORTED_PROTOCOLS_SET.contains(p)) {
                throw new IllegalArgumentException(""Protocol "" + p + "" is not supported."");
            }
            if (p.equals(PROTOCOL_SSL_V2)) {
                if (minProtocolIndex > OPENSSL_OP_NO_PROTOCOL_INDEX_SSLV2) {
                    minProtocolIndex = OPENSSL_OP_NO_PROTOCOL_INDEX_SSLV2;
                }
                if (maxProtocolIndex < OPENSSL_OP_NO_PROTOCOL_INDEX_SSLV2) {
                    maxProtocolIndex = OPENSSL_OP_NO_PROTOCOL_INDEX_SSLV2;
                }
            } else if (p.equals(PROTOCOL_SSL_V3)) {
                if (minProtocolIndex > OPENSSL_OP_NO_PROTOCOL_INDEX_SSLV3) {
                    minProtocolIndex = OPENSSL_OP_NO_PROTOCOL_INDEX_SSLV3;
                }
                if (maxProtocolIndex < OPENSSL_OP_NO_PROTOCOL_INDEX_SSLV3) {
                    maxProtocolIndex = OPENSSL_OP_NO_PROTOCOL_INDEX_SSLV3;
                }
            } else if (p.equals(PROTOCOL_TLS_V1)) {
                if (minProtocolIndex > OPENSSL_OP_NO_PROTOCOL_INDEX_TLSv1) {
                    minProtocolIndex = OPENSSL_OP_NO_PROTOCOL_INDEX_TLSv1;
                }
                if (maxProtocolIndex < OPENSSL_OP_NO_PROTOCOL_INDEX_TLSv1) {
                    maxProtocolIndex = OPENSSL_OP_NO_PROTOCOL_INDEX_TLSv1;
                }
            } else if (p.equals(PROTOCOL_TLS_V1_1)) {
                if (minProtocolIndex > OPENSSL_OP_NO_PROTOCOL_INDEX_TLSv1_1) {
                    minProtocolIndex = OPENSSL_OP_NO_PROTOCOL_INDEX_TLSv1_1;
                }
                if (maxProtocolIndex < OPENSSL_OP_NO_PROTOCOL_INDEX_TLSv1_1) {
                    maxProtocolIndex = OPENSSL_OP_NO_PROTOCOL_INDEX_TLSv1_1;
                }
            } else if (p.equals(PROTOCOL_TLS_V1_2)) {
                if (minProtocolIndex > OPENSSL_OP_NO_PROTOCOL_INDEX_TLSv1_2) {
                    minProtocolIndex = OPENSSL_OP_NO_PROTOCOL_INDEX_TLSv1_2;
                }
                if (maxProtocolIndex < OPENSSL_OP_NO_PROTOCOL_INDEX_TLSv1_2) {
                    maxProtocolIndex = OPENSSL_OP_NO_PROTOCOL_INDEX_TLSv1_2;
                }
            } else if (p.equals(PROTOCOL_TLS_V1_3)) {
                if (minProtocolIndex > OPENSSL_OP_NO_PROTOCOL_INDEX_TLSv1_3) {
                    minProtocolIndex = OPENSSL_OP_NO_PROTOCOL_INDEX_TLSv1_3;
                }
                if (maxProtocolIndex < OPENSSL_OP_NO_PROTOCOL_INDEX_TLSv1_3) {
                    maxProtocolIndex = OPENSSL_OP_NO_PROTOCOL_INDEX_TLSv1_3;
                }
            }
        }
        synchronized (this) {
            if (!isDestroyed()) {
                // Clear out options which disable protocols
                SSL.clearOptions(ssl, SSL.SSL_OP_NO_SSLv2 | SSL.SSL_OP_NO_SSLv3 | SSL.SSL_OP_NO_TLSv1 |
                                      SSL.SSL_OP_NO_TLSv1_1 | SSL.SSL_OP_NO_TLSv1_2 | SSL.SSL_OP_NO_TLSv1_3);

                int opts = 0;
                for (int i = 0; i < minProtocolIndex; ++i) {
                    opts |= OPENSSL_OP_NO_PROTOCOLS[i];
                }
                assert maxProtocolIndex != MAX_VALUE;
                for (int i = maxProtocolIndex + 1; i < OPENSSL_OP_NO_PROTOCOLS.length; ++i) {
                    opts |= OPENSSL_OP_NO_PROTOCOLS[i];
                }

                // Disable protocols we do not want
                SSL.setOptions(ssl, opts);
            } else {
                throw new IllegalStateException(""failed to enable protocols: "" + Arrays.asList(protocols));
            }
        }
    }"
"public static DataBuffer createShapeInformation(int[] shape, int[] stride, long offset, int elementWiseStride, char order) {
        if (shape.length != stride.length)
            throw new IllegalStateException(""Shape and stride must be the same length"");

        int rank = shape.length;
        int shapeBuffer[] = new int[rank * 2 + 4];
        shapeBuffer[0] = rank;
        int count = 1;
        for (int e = 0; e < shape.length; e++)
            shapeBuffer[count++] = shape[e];

        for (int e = 0; e < stride.length; e++)
            shapeBuffer[count++] = stride[e];

        shapeBuffer[count++] = (int) offset;
        shapeBuffer[count++] = elementWiseStride;
        shapeBuffer[count] = (int) order;

        DataBuffer ret = Nd4j.createBufferDetached(shapeBuffer);
        ret.setConstant(true);

        return ret;
    }"
"public Set<Class<?>> scan() {
		for (URL url : ResourceUtil.getResourceIter(this.packagePath)) {
			switch (url.getProtocol()) {
			case ""file"":
				scanFile(new File(URLUtil.decode(url.getFile(), this.charset.name())), null);
				break;
			case ""jar"":
				scanJar(URLUtil.getJarFile(url));
				break;
			}
		}
		
		if(CollUtil.isEmpty(this.classes)) {
			scanJavaClassPaths();
		}
		
		return Collections.unmodifiableSet(this.classes);
	}"
"public void delete() {
       if (historyId > 0) {
           try {
        	   // ZAP: Support for multiple tags
               staticTableTag.deleteTagsForHistoryID(historyId);
               staticTableHistory.delete(historyId);
               notifyEvent(HistoryReferenceEventPublisher.EVENT_REMOVED);
           } catch (DatabaseException e) {
        	   log.error(e.getMessage(), e);
           }
       }
   }"
"@Path(""{id}"")
    public InstanceResource getInstanceInfo(@PathParam(""id"") String id) {
        return new InstanceResource(this, id, serverConfig, registry);
    }"
"private ServerReflectionIndex updateIndexIfNecessary() {
    synchronized (lock) {
      if (serverReflectionIndex == null) {
        serverReflectionIndex =
            new ServerReflectionIndex(server.getImmutableServices(), server.getMutableServices());
        return serverReflectionIndex;
      }

      Set<FileDescriptor> serverFileDescriptors = new HashSet<>();
      Set<String> serverServiceNames = new HashSet<>();
      List<ServerServiceDefinition> serverMutableServices = server.getMutableServices();
      for (ServerServiceDefinition mutableService : serverMutableServices) {
        io.grpc.ServiceDescriptor serviceDescriptor = mutableService.getServiceDescriptor();
        if (serviceDescriptor.getSchemaDescriptor() instanceof ProtoFileDescriptorSupplier) {
          String serviceName = serviceDescriptor.getName();
          FileDescriptor fileDescriptor =
              ((ProtoFileDescriptorSupplier) serviceDescriptor.getSchemaDescriptor())
                  .getFileDescriptor();
          serverFileDescriptors.add(fileDescriptor);
          serverServiceNames.add(serviceName);
        }
      }

      // Replace the index if the underlying mutable services have changed. Check both the file
      // descriptors and the service names, because one file descriptor can define multiple
      // services.
      FileDescriptorIndex mutableServicesIndex = serverReflectionIndex.getMutableServicesIndex();
      if (!mutableServicesIndex.getServiceFileDescriptors().equals(serverFileDescriptors)
          || !mutableServicesIndex.getServiceNames().equals(serverServiceNames)) {
        serverReflectionIndex =
            new ServerReflectionIndex(server.getImmutableServices(), serverMutableServices);
      }

      return serverReflectionIndex;
    }
  }"
"public static INDArray greaterThanOrEqual(INDArray first, INDArray ndArray, boolean dup) {
        return exec(new OldGreaterThanOrEqual(first, ndArray, Nd4j.createUninitialized(DataType.BOOL, first.shape(), first.ordering())));

    }"
"protected void readStatusLine(HttpState state, HttpConnection conn)
    throws IOException, HttpException {
        LOG.trace(""enter HttpMethodBase.readStatusLine(HttpState, HttpConnection)"");

        final int maxGarbageLines = getParams().
            getIntParameter(HttpMethodParams.STATUS_LINE_GARBAGE_LIMIT, Integer.MAX_VALUE);

        //read out the HTTP status string
        int count = 0;
        String s;
        do {
            s = conn.readLine(getParams().getHttpElementCharset());
            if (s == null && count == 0) {
                // The server just dropped connection on us
                throw new NoHttpResponseException(""The server "" + conn.getHost() + 
                    "" failed to respond"");
            }
            if (s != null && StatusLine.startsWithHTTP(s)) {
                // Got one
                break;
            } else if (s == null || count >= maxGarbageLines) {
                // Giving up
                throw new ProtocolException(""The server "" + conn.getHost() + 
                        "" failed to respond with a valid HTTP response"");
            }
            count++;
        } while(true);

        //create the status line from the status string
        statusLine = new StatusLine(s);

        //check for a valid HTTP-Version
        String versionStr = statusLine.getHttpVersion();
        if (getParams().isParameterFalse(HttpMethodParams.UNAMBIGUOUS_STATUS_LINE) 
           && versionStr.equals(""HTTP"")) {
            getParams().setVersion(HttpVersion.HTTP_1_0);
            if (LOG.isWarnEnabled()) {
                LOG.warn(""Ambiguous status line (HTTP protocol version missing):"" +
                statusLine.toString());
            }
        } else {
            this.effectiveVersion = HttpVersion.parse(versionStr);
        }

    }"
"@Override
	public void report() {
		// we do not need to lock here, because the dropwizard registry is
		// internally a concurrent map
		@SuppressWarnings(""rawtypes"")
		final SortedMap<String, com.codahale.metrics.Gauge> gauges = registry.getGauges();
		final SortedMap<String, com.codahale.metrics.Counter> counters = registry.getCounters();
		final SortedMap<String, com.codahale.metrics.Histogram> histograms = registry.getHistograms();
		final SortedMap<String, com.codahale.metrics.Meter> meters = registry.getMeters();
		final SortedMap<String, com.codahale.metrics.Timer> timers = registry.getTimers();

		this.reporter.report(gauges, counters, histograms, meters, timers);
	}"
"public int read4BE() throws OtpErlangDecodeException {
        final byte[] b = new byte[4];
        try {
            super.read(b);
        } catch (final IOException e) {
            throw new OtpErlangDecodeException(""Cannot read from input stream"");
        }
        return (b[0] << 24 & 0xff000000) + (b[1] << 16 & 0xff0000)
                + (b[2] << 8 & 0xff00) + (b[3] & 0xff);
    }"
"public void addTargetRequest(String requestString) {
        if (StringUtils.isBlank(requestString) || requestString.equals(""#"")) {
            return;
        }
        requestString = UrlUtils.canonicalizeUrl(requestString, url.toString());
        targetRequests.add(new Request(requestString));
    }"
"public void do_not_split( ) {
      if( _pid == NO_PARENT) return; // skip root
      DecidedNode dn = _tree.decided(_pid);
      for( int i=0; i<dn._nids.length; i++ )
        if( dn._nids[i]==_nid )
          { dn._nids[i] = ScoreBuildHistogram.UNDECIDED_CHILD_NODE_ID; return; }
      throw H2O.fail();
    }"
"public static SQLExecuteCallback<Boolean> getPreparedSQLExecuteCallback(final DatabaseType databaseType, final boolean isExceptionThrown) {
        return new SQLExecuteCallback<Boolean>(databaseType, isExceptionThrown) {
            
            @Override
            protected Boolean executeSQL(final RouteUnit routeUnit, final Statement statement, final ConnectionMode connectionMode) throws SQLException {
                return ((PreparedStatement) statement).execute();
            }
        };
    }"
"public static Pair<List<Pinyin>, List<Boolean>> convert2Pair(String complexText, boolean removeTone)
    {
        List<Pinyin> pinyinList = new LinkedList<Pinyin>();
        List<Boolean> booleanList = new LinkedList<Boolean>();
        Collection<Token> tokenize = trie.tokenize(complexText);
        for (Token token : tokenize)
        {
            String fragment = token.getFragment();
            if (token.isMatch())
            {
                // 是拼音或拼音的一部分，用map转
                Pinyin pinyin = convertSingle(fragment);
                pinyinList.add(pinyin);
                if (fragment.length() == pinyin.getPinyinWithoutTone().length())
                {
                    booleanList.add(true);
                }
                else
                {
                    booleanList.add(false);
                }
            }
            else
            {
                List<Pinyin> pinyinListFragment = PinyinDictionary.convertToPinyin(fragment);
                pinyinList.addAll(pinyinListFragment);
                for (int i = 0; i < pinyinListFragment.size(); ++i)
                {
                    booleanList.add(true);
                }
            }
        }
        makeToneToTheSame(pinyinList);
        return new Pair<List<Pinyin>, List<Boolean>>(pinyinList, booleanList);
    }"
"@Override
    public void initialize(UimaContext context) throws ResourceInitializationException {

        super.initialize(context);

        this.context = context;

        this.logger = context.getLogger();

        if (this.logger.isLoggable(Level.INFO)) {
            this.logger.log(Level.INFO, ""Initializing the OpenNLP "" + ""Part of Speech annotator."");
        }

        POSModel model;

        try {
            POSModelResource modelResource = (POSModelResource) context.getResourceObject(UimaUtil.MODEL_PARAMETER);

            model = modelResource.getModel();
        } catch (ResourceAccessException e) {
            throw new ResourceInitializationException(e);
        }

        Integer beamSize = AnnotatorUtil.getOptionalIntegerParameter(context, UimaUtil.BEAM_SIZE_PARAMETER);

        if (beamSize == null)
            beamSize = POSTaggerME.DEFAULT_BEAM_SIZE;

        this.posTagger = new POSTaggerME(model, beamSize, 0);
    }"
"public static boolean canProduceEmptyMatches(final Pattern<?, ?> pattern) {
		NFAFactoryCompiler<?> compiler = new NFAFactoryCompiler<>(checkNotNull(pattern));
		compiler.compileFactory();
		State<?> startState = compiler.getStates().stream().filter(State::isStart).findFirst().orElseThrow(
			() -> new IllegalStateException(""Compiler produced no start state. It is a bug. File a jira.""));

		Set<State<?>> visitedStates = new HashSet<>();
		final Stack<State<?>> statesToCheck = new Stack<>();
		statesToCheck.push(startState);
		while (!statesToCheck.isEmpty()) {
			final State<?> currentState = statesToCheck.pop();
			if (visitedStates.contains(currentState)) {
				continue;
			} else {
				visitedStates.add(currentState);
			}

			for (StateTransition<?> transition : currentState.getStateTransitions()) {
				if (transition.getAction() == StateTransitionAction.PROCEED) {
					if (transition.getTargetState().isFinal()) {
						return true;
					} else {
						statesToCheck.push(transition.getTargetState());
					}
				}
			}
		}

		return false;
	}"
"public static BufferedImage generate(String content, QrConfig config) {
		return generate(content, BarcodeFormat.QR_CODE, config);
	}"
"public static <K, VV, EV> Graph<K, VV, EV> fromDataSet(DataSet<Edge<K, EV>> edges,
			final MapFunction<K, VV> vertexValueInitializer, ExecutionEnvironment context) {

		TypeInformation<K> keyType = ((TupleTypeInfo<?>) edges.getType()).getTypeAt(0);

		TypeInformation<VV> valueType = TypeExtractor.createTypeInfo(
				MapFunction.class, vertexValueInitializer.getClass(), 1, keyType, null);

		@SuppressWarnings({ ""unchecked"", ""rawtypes"" })
		TypeInformation<Vertex<K, VV>> returnType = (TypeInformation<Vertex<K, VV>>) new TupleTypeInfo(
				Vertex.class, keyType, valueType);

		DataSet<Vertex<K, VV>> vertices = edges
			.flatMap(new EmitSrcAndTargetAsTuple1<>())
				.name(""Source and target IDs"")
			.distinct()
				.name(""IDs"")
			.map(new MapFunction<Tuple1<K>, Vertex<K, VV>>() {
				private Vertex<K, VV> output = new Vertex<>();

				public Vertex<K, VV> map(Tuple1<K> value) throws Exception {
					output.f0 = value.f0;
					output.f1 = vertexValueInitializer.map(value.f0);
					return output;
				}
			}).returns(returnType).withForwardedFields(""f0"").name(""Initialize vertex values"");

		return new Graph<>(vertices, edges, context);
	}"
"public static <T> T query(PreparedStatement ps, RsHandler<T> rsh, Object... params) throws SQLException {
		StatementUtil.fillParams(ps, params);
		return executeQuery(ps, rsh);
	}"
"private String getPrefixKey(String key, SortedMap<String, ?> whiteList)
  {
    String prefixKey = null;
    if (whiteList.containsKey(key)) {
      return key;
    }
    SortedMap<String, ?> headMap = whiteList.headMap(key);
    if (!headMap.isEmpty() && key.startsWith(headMap.lastKey())) {
      prefixKey = headMap.lastKey();
    }
    return prefixKey;
  }"
"private int sampleLine(ResultPoint p1, ResultPoint p2, int size) {
    int result = 0;

    float d = distance(p1, p2);
    float moduleSize = d / size;
    float px = p1.getX();
    float py = p1.getY();
    float dx = moduleSize * (p2.getX() - p1.getX()) / d;
    float dy = moduleSize * (p2.getY() - p1.getY()) / d;
    for (int i = 0; i < size; i++) {
      if (image.get(MathUtils.round(px + i * dx), MathUtils.round(py + i * dy))) {
        result |= 1 << (size - i - 1);
      }
    }
    return result;
  }"
"@Override
    public Pair<Boolean, Optional<MultifactorAuthenticationProvider>> validate(final Authentication authentication,
                                                                               final String requestedContext,
                                                                               final RegisteredService service) {
        val attributes = authentication.getAttributes();
        val ctxAttr = attributes.get(this.authenticationContextAttribute);
        val contexts = CollectionUtils.toCollection(ctxAttr);
        LOGGER.trace(""Attempting to match requested authentication context [{}] against [{}]"", requestedContext, contexts);
        val providerMap = MultifactorAuthenticationUtils.getAvailableMultifactorAuthenticationProviders(this.applicationContext);
        LOGGER.trace(""Available MFA providers are [{}]"", providerMap.values());
        val requestedProvider = locateRequestedProvider(providerMap.values(), requestedContext);
        if (requestedProvider.isEmpty()) {
            LOGGER.debug(""Requested authentication provider cannot be recognized."");
            return Pair.of(Boolean.FALSE, Optional.empty());
        }
        LOGGER.debug(""Requested context is [{}] and available contexts are [{}]"", requestedContext, contexts);
        if (contexts.stream().anyMatch(ctx -> ctx.toString().equals(requestedContext))) {
            LOGGER.debug(""Requested authentication context [{}] is satisfied"", requestedContext);
            return Pair.of(Boolean.TRUE, requestedProvider);
        }
        if (StringUtils.isNotBlank(this.mfaTrustedAuthnAttributeName) && attributes.containsKey(this.mfaTrustedAuthnAttributeName)) {
            LOGGER.debug(""Requested authentication context [{}] is satisfied since device is already trusted"", requestedContext);
            return Pair.of(Boolean.TRUE, requestedProvider);
        }
        val satisfiedProviders = getSatisfiedAuthenticationProviders(authentication, providerMap.values());
        if (satisfiedProviders != null && !satisfiedProviders.isEmpty()) {
            val providers = satisfiedProviders.toArray(MultifactorAuthenticationProvider[]::new);
            OrderComparator.sortIfNecessary(providers);
            val result = Arrays.stream(providers)
                .filter(provider -> {
                    val p = requestedProvider.get();
                    return provider.equals(p) || provider.getOrder() >= p.getOrder();
                })
                .findFirst();
            if (result.isPresent()) {
                LOGGER.debug(""Current provider [{}] already satisfies the authentication requirements of [{}]; proceed with flow normally."",
                    result.get(), requestedProvider);
                return Pair.of(Boolean.TRUE, requestedProvider);
            }
        }
        val provider = requestedProvider.get();
        LOGGER.debug(""No multifactor providers could be located to satisfy the requested context for [{}]"", provider);
        return Pair.of(Boolean.FALSE, requestedProvider);
    }"
"protected void parseAuthority(String original, boolean escaped)
        throws URIException {

        // Reset flags
        _is_reg_name = _is_server =
        _is_hostname = _is_IPv4address = _is_IPv6reference = false;

        // set the charset to do escape encoding
        String charset = getProtocolCharset();

        boolean hasPort = true;
        int from = 0;
        int next = original.indexOf('@');
        if (next != -1) { // neither -1 and 0
            // each protocol extented from URI supports the specific userinfo
            _userinfo = (escaped) ? original.substring(0, next).toCharArray() 
                : encode(original.substring(0, next), allowed_userinfo,
                        charset);
            from = next + 1;
        }
        next = original.indexOf('[', from);
        if (next >= from) {
            next = original.indexOf(']', from);
            if (next == -1) {
                throw new URIException(URIException.PARSING, ""IPv6reference"");
            } else {
                next++;
            }
            // In IPv6reference, '[', ']' should be excluded
            _host = (escaped) ? original.substring(from, next).toCharArray() 
                : encode(original.substring(from, next), allowed_IPv6reference,
                        charset);
            // Set flag
            _is_IPv6reference = true;
        } else { // only for !_is_IPv6reference
            next = original.indexOf(':', from);
            if (next == -1) {
                next = original.length();
                hasPort = false;
            }
            // REMINDME: it doesn't need the pre-validation
            _host = original.substring(from, next).toCharArray();
            if (validate(_host, IPv4address)) {
                // Set flag
                _is_IPv4address = true;
            } else if (validate(_host, hostname)) {
                // Set flag
                _is_hostname = true;
            } else {
                // Set flag
                _is_reg_name = true;
            }
        }
        if (_is_reg_name) {
            // Reset flags for a server-based naming authority
            _is_server = _is_hostname = _is_IPv4address =
            _is_IPv6reference = false;
            // set a registry-based naming authority
            if (escaped) {
                _authority = original.toCharArray();
                if (!validate(_authority, reg_name)) {
                    throw new URIException(""Invalid authority"");
                }
            } else {
                _authority = encode(original, allowed_reg_name, charset);
            }
        } else {
            if (original.length() - 1 > next && hasPort 
                && original.charAt(next) == ':') { // not empty
                from = next + 1;
                try {
                    _port = Integer.parseInt(original.substring(from));
                } catch (NumberFormatException error) {
                    throw new URIException(URIException.PARSING,
                            ""invalid port number"");
                }
            }
            // set a server-based naming authority
            StringBuffer buf = new StringBuffer();
            if (_userinfo != null) { // has_userinfo
                buf.append(_userinfo);
                buf.append('@');
            }
            if (_host != null) {
                buf.append(_host);
                if (_port != -1) {
                    buf.append(':');
                    buf.append(_port);
                }
            }
            _authority = buf.toString().toCharArray();
            // Set flag
            _is_server = true;
        }
    }"
"public static JobManagerSharedServices fromConfiguration(
			Configuration config,
			BlobServer blobServer) throws Exception {

		checkNotNull(config);
		checkNotNull(blobServer);

		final String classLoaderResolveOrder =
			config.getString(CoreOptions.CLASSLOADER_RESOLVE_ORDER);

		final String[] alwaysParentFirstLoaderPatterns = CoreOptions.getParentFirstLoaderPatterns(config);

		final BlobLibraryCacheManager libraryCacheManager =
			new BlobLibraryCacheManager(
				blobServer,
				FlinkUserCodeClassLoaders.ResolveOrder.fromString(classLoaderResolveOrder),
				alwaysParentFirstLoaderPatterns);

		final FiniteDuration timeout;
		try {
			timeout = AkkaUtils.getTimeout(config);
		} catch (NumberFormatException e) {
			throw new IllegalConfigurationException(AkkaUtils.formatDurationParsingErrorMessage());
		}

		final ScheduledExecutorService futureExecutor = Executors.newScheduledThreadPool(
				Hardware.getNumberCPUCores(),
				new ExecutorThreadFactory(""jobmanager-future""));

		final StackTraceSampleCoordinator stackTraceSampleCoordinator =
			new StackTraceSampleCoordinator(futureExecutor, timeout.toMillis());
		final int cleanUpInterval = config.getInteger(WebOptions.BACKPRESSURE_CLEANUP_INTERVAL);
		final BackPressureStatsTrackerImpl backPressureStatsTracker = new BackPressureStatsTrackerImpl(
			stackTraceSampleCoordinator,
			cleanUpInterval,
			config.getInteger(WebOptions.BACKPRESSURE_NUM_SAMPLES),
			config.getInteger(WebOptions.BACKPRESSURE_REFRESH_INTERVAL),
			Time.milliseconds(config.getInteger(WebOptions.BACKPRESSURE_DELAY)));

		futureExecutor.scheduleWithFixedDelay(
			backPressureStatsTracker::cleanUpOperatorStatsCache,
			cleanUpInterval,
			cleanUpInterval,
			TimeUnit.MILLISECONDS);

		return new JobManagerSharedServices(
			futureExecutor,
			libraryCacheManager,
			RestartStrategyFactory.createRestartStrategyFactory(config),
			stackTraceSampleCoordinator,
			backPressureStatsTracker,
			blobServer);
	}"
"public <X> DataSource<X> fromCollection(Iterator<X> data, Class<X> type) {
		return fromCollection(data, TypeExtractor.getForClass(type));
	}"
"@Benchmark
  @BenchmarkMode(Mode.SampleTime)
  @OutputTimeUnit(TimeUnit.NANOSECONDS)
  public Attributes chain() {
    Attributes attr = base;
    for (int i = 0; i < iterations; i++) {
      attr = attr.toBuilder().set(keys[i], new Object()).build();
    }
    return attr;
  }"
"private void addToClassPath(Set<String> cp, String entries) {
    if (isEmpty(entries)) {
      return;
    }
    String[] split = entries.split(Pattern.quote(File.pathSeparator));
    for (String entry : split) {
      if (!isEmpty(entry)) {
        if (new File(entry).isDirectory() && !entry.endsWith(File.separator)) {
          entry += File.separator;
        }
        cp.add(entry);
      }
    }
  }"
"public static <T> TypeSerializerSchemaCompatibility<T> delegateCompatibilityCheckToNewSnapshot(
			TypeSerializer<T> newSerializer,
			CompositeTypeSerializerSnapshot<T, ? extends TypeSerializer> newCompositeSnapshot,
			TypeSerializerSnapshot<?>... legacyNestedSnapshots) {

		checkArgument(legacyNestedSnapshots.length > 0);
		return newCompositeSnapshot.internalResolveSchemaCompatibility(newSerializer, legacyNestedSnapshots);
	}"
"public static PrivateKey generatePrivateKey(String algorithm, KeySpec keySpec) {
		if (null == keySpec) {
			return null;
		}
		algorithm = getAlgorithmAfterWith(algorithm);
		try {
			return getKeyFactory(algorithm).generatePrivate(keySpec);
		} catch (Exception e) {
			throw new CryptoException(e);
		}
	}"
"protected CompletableFuture<Void> shutDownInternal() {

		synchronized (lock) {

			CompletableFuture<?> channelFuture = new CompletableFuture<>();
			if (serverChannel != null) {
				serverChannel.close().addListener(finished -> {
					if (finished.isSuccess()) {
						channelFuture.complete(null);
					} else {
						channelFuture.completeExceptionally(finished.cause());
					}
				});
				serverChannel = null;
			}

			final CompletableFuture<Void> channelTerminationFuture = new CompletableFuture<>();

			channelFuture.thenRun(() -> {
				CompletableFuture<?> groupFuture = new CompletableFuture<>();
				CompletableFuture<?> childGroupFuture = new CompletableFuture<>();
				final Time gracePeriod = Time.seconds(10L);

				if (bootstrap != null) {
					final ServerBootstrapConfig config = bootstrap.config();
					final EventLoopGroup group = config.group();
					if (group != null) {
						group.shutdownGracefully(0L, gracePeriod.toMilliseconds(), TimeUnit.MILLISECONDS)
							.addListener(finished -> {
								if (finished.isSuccess()) {
									groupFuture.complete(null);
								} else {
									groupFuture.completeExceptionally(finished.cause());
								}
							});
					} else {
						groupFuture.complete(null);
					}

					final EventLoopGroup childGroup = config.childGroup();
					if (childGroup != null) {
						childGroup.shutdownGracefully(0L, gracePeriod.toMilliseconds(), TimeUnit.MILLISECONDS)
							.addListener(finished -> {
								if (finished.isSuccess()) {
									childGroupFuture.complete(null);
								} else {
									childGroupFuture.completeExceptionally(finished.cause());
								}
							});
					} else {
						childGroupFuture.complete(null);
					}

					bootstrap = null;
				} else {
					// complete the group futures since there is nothing to stop
					groupFuture.complete(null);
					childGroupFuture.complete(null);
				}

				CompletableFuture<Void> combinedFuture = FutureUtils.completeAll(Arrays.asList(groupFuture, childGroupFuture));

				combinedFuture.whenComplete(
					(Void ignored, Throwable throwable) -> {
						if (throwable != null) {
							channelTerminationFuture.completeExceptionally(throwable);
						} else {
							channelTerminationFuture.complete(null);
						}
					});
			});

			return channelTerminationFuture;
		}
	}"
"private void initialize() {
        this.setContentPane(getJPanel());
        this.setVisible(false);
        this.setTitle(Constant.messages.getString(""history.filter.title""));
        if (Model.getSingleton().getOptionsParam().getViewParam().getWmUiHandlingOption() == 0) {
        	this.setSize(600, 300);
        }
        centreDialog();
        this.getRootPane().setDefaultButton(btnApply);
        this.pack();
	}"
"@Beta
  protected Reader onlyOverrideThisIfYouKnowWhatYouAreDoing() {
    URL resource = Resources.getResource(FirefoxProfile.class, defaultPrefs);
    try {
      return new InputStreamReader(resource.openStream());
    } catch (IOException e) {
      throw new WebDriverException(e);
    }
  }"
"public List<INDArray> feedForwardToLayer(int layerNum, INDArray input) {
        try{
            return ffToLayerActivationsDetached(false, FwdPassType.STANDARD, false, layerNum, input, mask, null, true);
        } catch (OutOfMemoryError e) {
            CrashReportingUtil.writeMemoryCrashDump(this, e);
            throw e;
        }
    }"
"@PublicEvolving
	public <W extends Window> WindowedStream<T, KEY, W> window(WindowAssigner<? super T, W> assigner) {
		return new WindowedStream<>(this, assigner);
	}"
"private void initProcess(List<String> currentProcesses) {
        // 3. 循环处理每个process
        List<Long> processIds = new ArrayList<Long>();
        for (String process : currentProcesses) {
            processIds.add(StagePathUtils.getProcessId(process));
        }
        Collections.sort(processIds); // 排序一下
        if (logger.isDebugEnabled()) {
            logger.debug(""pipeline[{}] old processIds{},current processIds{}"", new Object[] { getPipelineId(),
                    currentProcessIds, processIds });
        }

        // if (!processIds.equals(currentProcessIds) || currentProcessIds.isEmpty()) {// 不相同，说明有变化
        processChanged(processIds);// 通知变化
        // }

        currentProcessIds = processIds; // 切换引用，需设置为volatile保证线程安全&可见性
    }"
"public T setDeployMode(String mode) {
    checkNotNull(mode, ""mode"");
    builder.deployMode = mode;
    return self();
  }"
"@Override
    public INDArray randn(long rows, long columns, long seed) {
        Nd4j.getRandom().setSeed(seed);
        return randn(new long[] {rows, columns}, Nd4j.getRandom());
    }"
"private boolean streamHasMoreTokens() {
        if (streamTokenizer.ttype != StreamTokenizer.TT_EOF) {
            try {
                streamTokenizer.nextToken();
            } catch (IOException e1) {
                throw new RuntimeException(e1);
            }
        }
        return streamTokenizer.ttype != StreamTokenizer.TT_EOF && streamTokenizer.ttype != -1;
    }"
"public PopulateResult populate(final ByteSource source, final Map<K, V> map) throws IOException
  {
    return source.asCharSource(StandardCharsets.UTF_8).readLines(
        new LineProcessor<PopulateResult>()
        {
          private int lines = 0;
          private int entries = 0;

          @Override
          public boolean processLine(String line)
          {
            if (lines == Integer.MAX_VALUE) {
              throw new ISE(""Cannot read more than %,d lines"", Integer.MAX_VALUE);
            }
            final Map<K, V> kvMap = parser.parseToMap(line);
            map.putAll(kvMap);
            lines++;
            entries += kvMap.size();
            return true;
          }

          @Override
          public PopulateResult getResult()
          {
            return new PopulateResult(lines, entries);
          }
        }
    );
  }"
"private String getLogString(String message) {
		return BatchTask.constructLogString(message, this.getEnvironment().getTaskInfo().getTaskName(), this);
	}"
"public static BatchCSVRecord fromWritables(List<List<Writable>> batch) {
        List <SingleCSVRecord> records = new ArrayList<>(batch.size());
        for(List<Writable> list : batch) {
            List<String> add = new ArrayList<>(list.size());
            for(Writable writable : list) {
                add.add(writable.toString());
            }
            records.add(new SingleCSVRecord(add));
        }

        return BatchCSVRecord.builder().records(records).build();
    }"
"private List<Routee> makeRoutes() {
    return Registry.policies(settings).stream().map(policy -> {
      ActorRef actorRef = context().actorOf(Props.create(PolicyActor.class, policy));
      context().watch(actorRef);
      return new ActorRefRoutee(actorRef);
    }).collect(toList());
  }"
"private static CaseInsensitiveStringMap catalogOptions(String name, SQLConf conf) {
    Map<String, String> allConfs = mapAsJavaMapConverter(conf.getAllConfs()).asJava();
    Pattern prefix = Pattern.compile(""^spark\\.sql\\.catalog\\."" + name + ""\\.(.+)"");

    HashMap<String, String> options = new HashMap<>();
    for (Map.Entry<String, String> entry : allConfs.entrySet()) {
      Matcher matcher = prefix.matcher(entry.getKey());
      if (matcher.matches() && matcher.groupCount() > 0) {
        options.put(matcher.group(1), entry.getValue());
      }
    }

    return new CaseInsensitiveStringMap(options);
  }"
"@Override
    public ValNums apply(Env env, Env.StackHelp stk, AstRoot asts[]) {
        Frame fr = stk.track(asts[1].exec(env)).getFrame();
        String type = stk.track(asts[2].exec(env)).getStr();
        DType dtype;
        switch (type) {
            case ""numeric"": // Numeric, but not categorical or time
                dtype = DType.Numeric;
                break;
            case ""categorical"": // Integer, with a categorical/factor String mapping
                dtype = DType.Categorical;
                break;
            case ""string"": // String
                dtype = DType.String;
                break;
            case ""time"": // Long msec since the Unix Epoch - with a variety of display/parse options
                dtype = DType.Time;
                break;
            case ""uuid"": // UUID
                dtype = DType.UUID;
                break;
            case ""bad"": // No none-NA rows (triple negative! all NAs or zero rows)
                dtype = DType.Bad;
                break;
            default:
                throw new IllegalArgumentException(""unknown data type to filter by: "" + type);
        }
        Vec vecs[] = fr.vecs();
        ArrayList<Double> idxs = new ArrayList<>();
        for (double i = 0; i < fr.numCols(); i++)
            if (dtype.equals(DType.Numeric) && vecs[(int) i].isNumeric()){
                    idxs.add(i);
            }
            else if (dtype.equals(DType.Categorical) && vecs[(int) i].isCategorical()){
                idxs.add(i);
            }
            else if (dtype.equals(DType.String) && vecs[(int) i].isString()){
                idxs.add(i);
            }
            else if (dtype.equals(DType.Time) && vecs[(int) i].isTime()){
                idxs.add(i);
            }
            else if (dtype.equals(DType.UUID) && vecs[(int) i].isUUID()){
                idxs.add(i);
            } else if (dtype.equals(DType.Bad) && vecs[(int) i].isBad()){
                idxs.add(i);
            }

        double[] include_cols = new double[idxs.size()];
        int i = 0;
        for (double d : idxs)
            include_cols[i++] = (int) d;
        return new ValNums(include_cols);
    }"
"public static LongStream scrambledZipfian(int items, double constant, int events) {
    return generate(new ScrambledZipfianGenerator(0, items - 1, constant), events);
  }"
"public static boolean isValidParamKey(String paramkey) {
        char c = paramkey.charAt(0);
        return c != RpcConstants.HIDE_KEY_PREFIX && c != RpcConstants.INTERNAL_KEY_PREFIX;
    }"
"public static double fBeta(double beta, long tp, long fp, long fn) {
        double prec = tp / ((double) tp + fp);
        double recall = tp / ((double) tp + fn);
        return fBeta(beta, prec, recall);
    }"
"public void startQueryService(RpcService rpcService, ResourceID resourceID) {
		synchronized (lock) {
			Preconditions.checkState(!isShutdown(), ""The metric registry has already been shut down."");

			try {
				metricQueryServiceRpcService = rpcService;
				queryService = MetricQueryService.createMetricQueryService(rpcService, resourceID, maximumFramesize);
				queryService.start();
			} catch (Exception e) {
				LOG.warn(""Could not start MetricDumpActor. No metrics will be submitted to the WebInterface."", e);
			}
		}
	}"
"public <NEW> Graph<NEW, VV, EV> translateGraphIds(TranslateFunction<K, NEW> translator) throws Exception {
		return run(new TranslateGraphIds<>(translator));
	}"
"protected CommonProfile getAuthenticatedProfile(final HttpServletRequest request,
                                                    final HttpServletResponse response,
                                                    final String requiredPermission) {
        val context = new J2EContext(request, response, getUmaConfigurationContext().getSessionStore());
        val manager = new ProfileManager<>(context, context.getSessionStore());
        val profile = manager.get(true).orElse(null);
        if (profile == null) {
            throw new AuthenticationException(""Unable to locate authenticated profile"");
        }
        if (!profile.getPermissions().contains(requiredPermission)) {
            throw new AuthenticationException(""Authenticated profile does not carry the UMA protection scope"");
        }
        return profile;
    }"
"public static boolean checkMmul(INDArray first, INDArray second, double maxRelativeDifference,
                    double minAbsDifference) {
        if (first.size(1) != second.size(0))
            throw new IllegalArgumentException(""first.columns != second.rows"");
        RealMatrix rmFirst = convertToApacheMatrix(first);
        RealMatrix rmSecond = convertToApacheMatrix(second);

        INDArray result = first.mmul(second);
        RealMatrix rmResult = rmFirst.multiply(rmSecond);

        if (!checkShape(rmResult, result))
            return false;
        boolean ok = checkEntries(rmResult, result, maxRelativeDifference, minAbsDifference);
        if (!ok) {
            INDArray onCopies = Shape.toOffsetZeroCopy(first).mmul(Shape.toOffsetZeroCopy(second));
            printFailureDetails(first, second, rmResult, result, onCopies, ""mmul"");
        }
        return ok;
    }"
"@Override
   public int getLoginTimeout() throws SQLException
   {
      HikariPool p = pool;
      return (p != null ? p.getUnwrappedDataSource().getLoginTimeout() : 0);
   }"
"protected void setSessionValue(final HttpServletRequest request, final String key,
      final Object value) {
    request.getSession(true).setAttribute(key, value);
  }"
"private void setLimit(int from, int size) {
		request.setFrom(from);

		if (size > -1) {
			request.setSize(size);
		}
	}"
"public int chunkFetchHandlerThreads() {
    if (!this.getModuleName().equalsIgnoreCase(""shuffle"")) {
      return 0;
    }
    int chunkFetchHandlerThreadsPercent =
      conf.getInt(""spark.shuffle.server.chunkFetchHandlerThreadsPercent"", 100);
    int threads =
      this.serverThreads() > 0 ? this.serverThreads() : 2 * NettyRuntime.availableProcessors();
    return (int) Math.ceil(threads * (chunkFetchHandlerThreadsPercent / 100.0));
  }"
"public static PublicKey decodeECPoint(String encode, String curveName) {
		return BCUtil.decodeECPoint(encode, curveName);
	}"
"private void initialize()
    {
        activeOperators.stream()
                .map(Operator::getOperatorContext)
                .forEach(operatorContext -> operatorContext.setMemoryRevocationRequestListener(() -> driverBlockedFuture.get().set(null)));
    }"
"private static boolean isDefaultHttpOrHttpsPort(String scheme, int port) {
        if (port == DEFAULT_HTTP_PORT && isHttp(scheme)) {
            return true;
        }
        if (port == DEFAULT_HTTPS_PORT && isHttps(scheme)) {
            return true;
        }
        return false;
    }"
"public boolean loadTxt(String path)
    {
        IOUtil.LineIterator lineIterator = new IOUtil.LineIterator(path);
        model_header = lineIterator.next();
        if (model_header == null) return false;
        root = lineIterator.next();
        use_distance = ""1"".equals(lineIterator.next());
        use_valency = ""1"".equals(lineIterator.next());
        use_cluster = ""1"".equals(lineIterator.next());

        W1 = read_matrix(lineIterator);
        W2 = read_matrix(lineIterator);
        E = read_matrix(lineIterator);
        b1 = read_vector(lineIterator);
        saved = read_matrix(lineIterator);

        forms_alphabet = read_alphabet(lineIterator);
        postags_alphabet = read_alphabet(lineIterator);
        deprels_alphabet = read_alphabet(lineIterator);

        precomputation_id_encoder = read_map(lineIterator);

        if (use_cluster)
        {
            cluster4_types_alphabet = read_alphabet(lineIterator);
            cluster6_types_alphabet = read_alphabet(lineIterator);
            cluster_types_alphabet = read_alphabet(lineIterator);

            form_to_cluster4 = read_map(lineIterator);
            form_to_cluster6 = read_map(lineIterator);
            form_to_cluster = read_map(lineIterator);
        }

        assert !lineIterator.hasNext() : ""文件有残留，可能是读取逻辑不对"";

        classifier = new NeuralNetworkClassifier(W1, W2, E, b1, saved, precomputation_id_encoder);
        classifier.canonical();

        return true;
    }"
"public static void cut(Image srcImage, OutputStream out, Rectangle rectangle) throws IORuntimeException {
		cut(srcImage, getImageOutputStream(out), rectangle);
	}"
"@Override
    public boolean hasNext() {
        boolean has = true;

        for (val i: iterators)
            if (!i.hasNext()) {
                has = false;
                break;
            }

        return has;
    }"
"public void setReadPosition(long pointer) {
		final int bufferNum = (int) (pointer >>> this.segmentSizeBits);
		final int offset = (int) (pointer & (this.memorySegmentSize - 1));
		
		this.currentBufferNum = bufferNum;
		seekInput(this.partitionBuffers[bufferNum], offset,
					bufferNum < this.partitionBuffers.length-1 ? this.memorySegmentSize : this.finalBufferLimit);
		
	}"
"public static Row fromString(RowSchema schema, String str, char delimiter)
    {
        Row row = new Row();

        ImmutableList.Builder<String> builder = ImmutableList.builder();
        List<String> fields = builder.addAll(Splitter.on(delimiter).split(str)).build();

        if (fields.size() != schema.getLength()) {
            throw new PrestoException(INVALID_FUNCTION_ARGUMENT, format(""Number of split tokens is not equal to schema length. Expected %s received %s. Schema: %s, fields {%s}, delimiter %s"", schema.getLength(), fields.size(), schema, StringUtils.join(fields, "",""), delimiter));
        }

        for (int i = 0; i < fields.size(); ++i) {
            Type type = schema.getColumn(i).getType();
            row.addField(valueFromString(fields.get(i), type), type);
        }

        return row;
    }"
"@SuppressWarnings(""unchecked"")
	private <IN1, IN2, OUT> TypeInformation<OUT> privateCreateTypeInfo(Type returnType, TypeInformation<IN1> in1Type, TypeInformation<IN2> in2Type) {
		ArrayList<Type> typeHierarchy = new ArrayList<Type>();

		// get info from hierarchy
		return (TypeInformation<OUT>) createTypeInfoWithTypeHierarchy(typeHierarchy, returnType, in1Type, in2Type);
	}"
"@VisibleForTesting
    /*private*/ static void checkRawBuildsDir(String newBuildsDirValue) throws InvalidBuildsDir {

        // do essentially what expandVariablesForDirectory does, without an Item
        String replacedValue = expandVariablesForDirectory(newBuildsDirValue,
                                                           ""doCheckRawBuildsDir-Marker:foo"",
                                                           Jenkins.getInstance().getRootDir().getPath() + ""/jobs/doCheckRawBuildsDir-Marker$foo"");

        File replacedFile = new File(replacedValue);
        if (!replacedFile.isAbsolute()) {
            throw new InvalidBuildsDir(newBuildsDirValue + "" does not resolve to an absolute path"");
        }

        if (!replacedValue.contains(""doCheckRawBuildsDir-Marker"")) {
            throw new InvalidBuildsDir(newBuildsDirValue + "" does not contain ${ITEM_FULL_NAME} or ${ITEM_ROOTDIR}, cannot distinguish between projects"");
        }

        if (replacedValue.contains(""doCheckRawBuildsDir-Marker:foo"")) {
            // make sure platform can handle colon
            try {
                File tmp = File.createTempFile(""Jenkins-doCheckRawBuildsDir"", ""foo:bar"");
                tmp.delete();
            } catch (IOException e) {
                throw new InvalidBuildsDir(newBuildsDirValue +  "" contains ${ITEM_FULLNAME} but your system does not support it (JENKINS-12251). Use ${ITEM_FULL_NAME} instead"");
            }
        }

        File d = new File(replacedValue);
        if (!d.isDirectory()) {
            // if dir does not exist (almost guaranteed) need to make sure nearest existing ancestor can be written to
            d = d.getParentFile();
            while (!d.exists()) {
                d = d.getParentFile();
            }
            if (!d.canWrite()) {
                throw new InvalidBuildsDir(newBuildsDirValue +  "" does not exist and probably cannot be created"");
            }
        }
    }"
"public static Collection<Comparable<?>> getTableShardingValues(final String logicTable) {
        return null == HINT_MANAGER_HOLDER.get() ? Collections.<Comparable<?>>emptyList() : HINT_MANAGER_HOLDER.get().tableShardingValues.get(logicTable);
    }"
"public Graph<KT, VVT, Tuple2<EV, EV>> projectionTopSimple() {
		DataSet<Edge<KT, Tuple2<EV, EV>>> newEdges = edges.join(edges)
			.where(1)
			.equalTo(1)
			.with(new ProjectionTopSimple<>())
				.name(""Simple top projection"");

		return Graph.fromDataSet(topVertices, newEdges, context);
	}"
"private void addAttributes(PublisherRegistration publisherRegistration, String group) {
        // if group == null; group = ""DEFAULT_GROUP""
        if (StringUtils.isNotEmpty(group)) {
            publisherRegistration.setGroup(group);
        }

    }"
"public Set<Map.Entry<String, V>> entrySet()
    {
        Set<Map.Entry<String, V>> entrySet = new TreeSet<Map.Entry<String, V>>();
        StringBuilder sb = new StringBuilder();
        for (BaseNode node : child)
        {
            if (node == null) continue;
            node.walk(new StringBuilder(sb.toString()), entrySet);
        }
        return entrySet;
    }"
"public static long sliceOffsetForTensor(int index, INDArray arr, int[] tensorShape) {
        long tensorLength = ArrayUtil.prodLong(tensorShape);
        long lengthPerSlice = NDArrayMath.lengthPerSlice(arr);
        long offset = index * tensorLength / lengthPerSlice;
        return offset;
    }"
"static <T> List<T> list(T... elements) {
    return new ArrayList<>(Arrays.asList(elements));
  }"
"public static long calculateCutoffMB(Configuration config, long containerMemoryMB) {
		Preconditions.checkArgument(containerMemoryMB > 0);

		// (1) check cutoff ratio
		final float memoryCutoffRatio = config.getFloat(
			ResourceManagerOptions.CONTAINERIZED_HEAP_CUTOFF_RATIO);

		if (memoryCutoffRatio >= 1 || memoryCutoffRatio <= 0) {
			throw new IllegalArgumentException(""The configuration value '""
				+ ResourceManagerOptions.CONTAINERIZED_HEAP_CUTOFF_RATIO.key() + ""' must be between 0 and 1. Value given=""
				+ memoryCutoffRatio);
		}

		// (2) check min cutoff value
		final int minCutoff = config.getInteger(
			ResourceManagerOptions.CONTAINERIZED_HEAP_CUTOFF_MIN);

		if (minCutoff >= containerMemoryMB) {
			throw new IllegalArgumentException(""The configuration value '""
				+ ResourceManagerOptions.CONTAINERIZED_HEAP_CUTOFF_MIN.key() + ""'='"" + minCutoff
				+ ""' is larger than the total container memory "" + containerMemoryMB);
		}

		// (3) check between heap and off-heap
		long cutoff = (long) (containerMemoryMB * memoryCutoffRatio);
		if (cutoff < minCutoff) {
			cutoff = minCutoff;
		}
		return cutoff;
	}"
"public static SecretKey hmacShaKeyFor(byte[] bytes) throws WeakKeyException {

        if (bytes == null) {
            throw new InvalidKeyException(""SecretKey byte array cannot be null."");
        }

        int bitLength = bytes.length * 8;

        for (SignatureAlgorithm alg : PREFERRED_HMAC_ALGS) {
            if (bitLength >= alg.getMinKeyLength()) {
                return new SecretKeySpec(bytes, alg.getJcaName());
            }
        }

        String msg = ""The specified key byte array is "" + bitLength + "" bits which "" +
            ""is not secure enough for any JWT HMAC-SHA algorithm.  The JWT "" +
            ""JWA Specification (RFC 7518, Section 3.2) states that keys used with HMAC-SHA algorithms MUST have a "" +
            ""size >= 256 bits (the key size must be greater than or equal to the hash "" +
            ""output size).  Consider using the "" + Keys.class.getName() + ""#secretKeyFor(SignatureAlgorithm) method "" +
            ""to create a key guaranteed to be secure enough for your preferred HMAC-SHA algorithm.  See "" +
            ""https://tools.ietf.org/html/rfc7518#section-3.2 for more information."";
        throw new WeakKeyException(msg);
    }"
"public ExcelWriter setColumnWidth(int columnIndex, int width) {
		if (columnIndex < 0) {
			this.sheet.setDefaultColumnWidth(width);
		} else {
			this.sheet.setColumnWidth(columnIndex, width * 256);
		}
		return this;
	}"
"public static CanalConnector newClusterConnector(List<? extends SocketAddress> addresses, String destination,
                                                     String username, String password) {
        ClusterCanalConnector canalConnector = new ClusterCanalConnector(username,
            password,
            destination,
            new SimpleNodeAccessStrategy(addresses));
        canalConnector.setSoTimeout(60 * 1000);
        canalConnector.setIdleTimeout(60 * 60 * 1000);
        return canalConnector;
    }"
"public static BigDecimal roundHalfEven(BigDecimal value, int scale) {
		return round(value, scale, RoundingMode.HALF_EVEN);
	}"
"public Edge getEdge(Node from, Node to)
    {
        // 首先尝试词+词
        Attribute attribute = get(from.compiledWord, to.compiledWord);
        if (attribute == null) attribute = get(from.compiledWord, WordNatureWeightModelMaker.wrapTag(to.label));
        if (attribute == null) attribute = get(WordNatureWeightModelMaker.wrapTag(from.label), to.compiledWord);
        if (attribute == null) attribute = get(WordNatureWeightModelMaker.wrapTag(from.label), WordNatureWeightModelMaker.wrapTag(to.label));
        if (attribute == null)
        {
            attribute = Attribute.NULL;
        }
        if (HanLP.Config.DEBUG)
        {
            System.out.println(from + "" 到 "" + to + "" : "" + attribute);
        }
        return new Edge(from.id, to.id, attribute.dependencyRelation[0], attribute.p[0]);
    }"
"private static BitSet validCookieValueOctets() {
        BitSet bits = new BitSet(8);
        for (int i = 35; i < 127; i++) {
            // US-ASCII characters excluding CTLs (%x00-1F / %x7F)
            bits.set(i);
        }
        bits.set('""', false);  // exclude DQUOTE = %x22
        bits.set(',', false);  // exclude comma = %x2C
        bits.set(';', false);  // exclude semicolon = %x3B
        bits.set('\\', false); // exclude backslash = %x5C
        return bits;
    }"
"@CheckForNull
    public PluginWrapper getPlugin(String shortName) {
        for (PluginWrapper p : getPlugins()) {
            if(p.getShortName().equals(shortName))
                return p;
        }
        return null;
    }"
"public
    // end of [PATCH]
    static String unicodeToASCII(String input) {
        if (isOnlyASCII(input)) { // skip possibly expensive processing
            return input;
        }
        try {
            final String ascii = IDN.toASCII(input);
            if (DomainValidator.IDNBUGHOLDER.IDN_TOASCII_PRESERVES_TRAILING_DOTS) {
                return ascii;
            }
            final int length = input.length();
            if (length == 0) {// check there is a last character
                return input;
            }
            // RFC3490 3.1. 1)
            //            Whenever dots are used as label separators, the following
            //            characters MUST be recognized as dots: U+002E (full stop), U+3002
            //            (ideographic full stop), U+FF0E (fullwidth full stop), U+FF61
            //            (halfwidth ideographic full stop).
            char lastChar = input.charAt(length-1);// fetch original last char
            switch(lastChar) {
                case '\u002E': // ""."" full stop
                case '\u3002': // ideographic full stop
                case '\uFF0E': // fullwidth full stop
                case '\uFF61': // halfwidth ideographic full stop
                    return ascii + "".""; // restore the missing stop
                default:
                    return ascii;
            }
        } catch (IllegalArgumentException e) { // input is not valid
            return input;
        }
    }"
"private static String fullQualifiedName(Tree tree) {
		if (tree.is(Tree.Kind.IDENTIFIER)) {
			return ((IdentifierTree) tree).name();
		} else if (tree.is(Tree.Kind.MEMBER_SELECT)) {
			MemberSelectExpressionTree m = (MemberSelectExpressionTree) tree;
			return fullQualifiedName(m.expression()) + ""."" + m.identifier().name();
		}
		throw new UnsupportedOperationException(String.format(""Kind/Class '%s' not supported"", tree.getClass()));
	}"
"@Override
  public long scanAndAggregate(
      HistoricalDimensionSelector dimensionSelector,
      HistoricalColumnSelector metricSelector,
      SimpleDoubleBufferAggregator aggregator,
      int aggregatorSize,
      HistoricalCursor cursor,
      int[] positions,
      ByteBuffer resultsBuffer
  )
  {
    // See TopNUtils.copyOffset() for explanation
    Offset offset = (Offset) TopNUtils.copyOffset(cursor);
    long processedRows = 0;
    int positionToAllocate = 0;
    while (offset.withinBounds() && !Thread.currentThread().isInterrupted()) {
      int rowNum = offset.getOffset();
      double metric = metricSelector.getDouble(rowNum);
      final IndexedInts dimValues = dimensionSelector.getRow(rowNum);
      final int dimSize = dimValues.size();
      for (int i = 0; i < dimSize; i++) {
        int dimIndex = dimValues.get(i);
        int position = positions[dimIndex];
        if (position >= 0) {
          aggregator.aggregate(resultsBuffer, position, metric);
        } else if (position == TopNAlgorithm.INIT_POSITION_VALUE) {
          positions[dimIndex] = positionToAllocate;
          aggregator.putFirst(resultsBuffer, positionToAllocate, metric);
          positionToAllocate += aggregatorSize;
        }
      }
      processedRows++;
      offset.increment();
    }
    return processedRows;
  }"
"@Override
    public void save(INDArray save, String id) throws SQLException, IOException {
        doSave(save, id);

    }"
"public static boolean isInEc2(InstanceInfo instanceInfo) {
        if (instanceInfo.getDataCenterInfo() instanceof AmazonInfo) {
            String instanceId = ((AmazonInfo) instanceInfo.getDataCenterInfo()).getId();
            if (instanceId != null && instanceId.startsWith(""i-"")) {
                return true;
            }
        }
        return false;
    }"
"public static void main(String[] args) throws IOException {
        if (args.length < 2) {
            System.err.println(""Usage:\n""
                            + ""mvn exec:java -Dexec.mainClass=\""org.nd4j.tensorflow.conversion.ProtoBufToFlatBufConversion\"" -Dexec.args=\""<input_file.pb> <output_file.fb>\""\n"");
        } else {
            convert(args[0], args[1]);
        }
    }"
"public void importContext() {
		JFileChooser chooser = new JFileChooser(Constant.getContextsDir());
		File file = null;
	    chooser.setFileFilter(new FileFilter() {
	           @Override
	           public boolean accept(File file) {
	                if (file.isDirectory()) {
	                    return true;
	                } else if (file.isFile() && file.getName().endsWith("".context"")) {
	                    return true;
	                }
	                return false;
	            }
	           @Override
	           public String getDescription() {
	               return Constant.messages.getString(""file.format.zap.context"");
	           }
	    });
	    
	    int rc = chooser.showOpenDialog(View.getSingleton().getMainFrame());
	    if(rc == JFileChooser.APPROVE_OPTION) {
			try {
	    		file = chooser.getSelectedFile();
	    		if (file == null || ! file.exists()) {
	    			return;
	    		}
	    		// Import the context
				Model.getSingleton().getSession().importContext(file);
				
				// Show the dialog
			    View.getSingleton().showSessionDialog(
			    		Model.getSingleton().getSession(), 
			    		Constant.messages.getString(""context.list""), true);
				
			} catch (IllegalContextNameException e) {
				String detailError;
				if (e.getReason() == IllegalContextNameException.Reason.EMPTY_NAME) {
					detailError = Constant.messages.getString(""context.error.name.empty"");
				} else if (e.getReason() == IllegalContextNameException.Reason.DUPLICATED_NAME) {
					detailError = Constant.messages.getString(""context.error.name.duplicated"");
				} else {
					detailError = Constant.messages.getString(""context.error.name.unknown"");
				}
				View.getSingleton().showWarningDialog(Constant.messages.getString(""context.import.error"", detailError));
			} catch (Exception e1) {
				log.error(e1.getMessage(), e1);
				View.getSingleton().showWarningDialog(Constant.messages.getString(""context.import.error"", e1.getMessage()));
			}
	    }
	}"
"protected void subscribeConfig(final AbstractInterfaceConfig config, ConfigListener listener) {
        try {
            if (configObserver == null) { // 初始化
                configObserver = new ZookeeperConfigObserver();
            }
            configObserver.addConfigListener(config, listener);
            final String configPath = buildConfigPath(rootPath, config);
            // 监听配置节点下 子节点增加、子节点删除、子节点Data修改事件
            PathChildrenCache pathChildrenCache = new PathChildrenCache(zkClient, configPath, true);
            pathChildrenCache.getListenable().addListener(new PathChildrenCacheListener() {
                @Override
                public void childEvent(CuratorFramework client1, PathChildrenCacheEvent event) throws Exception {
                    if (LOGGER.isDebugEnabled(config.getAppName())) {
                        LOGGER.debug(""Receive zookeeper event: "" + ""type=["" + event.getType() + ""]"");
                    }
                    switch (event.getType()) {
                        case CHILD_ADDED: //新增接口级配置
                            configObserver.addConfig(config, configPath, event.getData());
                            break;
                        case CHILD_REMOVED: //删除接口级配置
                            configObserver.removeConfig(config, configPath, event.getData());
                            break;
                        case CHILD_UPDATED:// 更新接口级配置
                            configObserver.updateConfig(config, configPath, event.getData());
                            break;
                        default:
                            break;
                    }
                }
            });
            pathChildrenCache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);
            INTERFACE_CONFIG_CACHE.put(configPath, pathChildrenCache);
            configObserver.updateConfigAll(config, configPath, pathChildrenCache.getCurrentData());
        } catch (Exception e) {
            throw new SofaRpcRuntimeException(""Failed to subscribe provider config from zookeeperRegistry!"", e);
        }
    }"
"private void handleEIPBinding() throws InterruptedException {
        int retries = serverConfig.getEIPBindRebindRetries();
        // Bind to EIP if needed
        for (int i = 0; i < retries; i++) {
            try {
                if (isEIPBound()) {
                    break;
                } else {
                    bindEIP();
                }
            } catch (Throwable e) {
                logger.error(""Cannot bind to EIP"", e);
                Thread.sleep(EIP_BIND_SLEEP_TIME_MS);
            }
        }
        // Schedule a timer which periodically checks for EIP binding.
        timer.schedule(new EIPBindingTask(), serverConfig.getEIPBindingRetryIntervalMsWhenUnbound());
    }"
"private JSplitPane createStatusPanelsSplit() {
		JSplitPane splitVert = new JSplitPane();

		splitVert.setDividerLocation(restoreDividerLocation(DIVIDER_VERTICAL, 300));
		splitVert.addPropertyChangeListener(JSplitPane.DIVIDER_LOCATION_PROPERTY, new DividerResizedListener(DIVIDER_VERTICAL));

		splitVert.setDividerSize(3);
		splitVert.setOrientation(JSplitPane.VERTICAL_SPLIT);
		splitVert.setResizeWeight(0.5D);

		switch (layout) {
		case EXPAND_SELECT:
			splitVert.setTopComponent(getPaneWork());
			break;
		case EXPAND_STATUS:
		default:
			splitVert.setTopComponent(createSelectPanelsSplit());
			break;
		}
		splitVert.setBottomComponent(getPaneStatus());
		splitVert.setContinuousLayout(false);
		splitVert.setBorder(BorderFactory.createEmptyBorder(0, 0, 0, 0));
		return splitVert;
	}"
"public static ConversionService getSharedInstance() {
		ApplicationConversionService sharedInstance = ApplicationConversionService.sharedInstance;
		if (sharedInstance == null) {
			synchronized (ApplicationConversionService.class) {
				sharedInstance = ApplicationConversionService.sharedInstance;
				if (sharedInstance == null) {
					sharedInstance = new ApplicationConversionService();
					ApplicationConversionService.sharedInstance = sharedInstance;
				}
			}
		}
		return sharedInstance;
	}"
"private void openAllOperators() throws Exception {
		for (StreamOperator<?> operator : operatorChain.getAllOperators()) {
			if (operator != null) {
				operator.open();
			}
		}
	}"
"public boolean healthy() {
    long now = System.currentTimeMillis();
    for (H2ONode node : H2O.CLOUD.members())
      if (!node.isHealthy(now))
        return false;
    return true;
  }"
"void finishStream(
      int streamId,
      @Nullable Status status,
      RpcProgress rpcProgress,
      boolean stopDelivery,
      @Nullable ErrorCode errorCode,
      @Nullable Metadata trailers) {
    synchronized (lock) {
      OkHttpClientStream stream = streams.remove(streamId);
      if (stream != null) {
        if (errorCode != null) {
          frameWriter.rstStream(streamId, ErrorCode.CANCEL);
        }
        if (status != null) {
          stream
              .transportState()
              .transportReportStatus(
                  status,
                  rpcProgress,
                  stopDelivery,
                  trailers != null ? trailers : new Metadata());
        }
        if (!startPendingStreams()) {
          stopIfNecessary();
          maybeClearInUse(stream);
        }
      }
    }
  }"
"private static Charset extractCharset(Metadata headers) {
    String contentType = headers.get(GrpcUtil.CONTENT_TYPE_KEY);
    if (contentType != null) {
      String[] split = contentType.split(""charset="", 2);
      try {
        return Charset.forName(split[split.length - 1].trim());
      } catch (Exception t) {
        // Ignore and assume UTF-8
      }
    }
    return Charsets.UTF_8;
  }"
"private static boolean doesNameMatchPattern(final Principal principal, final Pattern pattern) {
        if (pattern != null) {
            val name = principal.getName();
            val result = pattern.matcher(name).matches();
            LOGGER.debug(""[{}] matches [{}] == [{}]"", pattern.pattern(), name, result);
            return result;
        }
        return true;
    }"
"@Override
    public void fit(DataSet dataSet) {
        featureStats = (S) newBuilder().addFeatures(dataSet).build();
        if (isFitLabel()) {
            labelStats = (S) newBuilder().addLabels(dataSet).build();
        }
    }"
"@VisibleForTesting
    public static ParametricAggregation parseFunctionDefinitionWithTypesConstraint(Class<?> clazz, TypeSignature returnType, List<TypeSignature> argumentTypes)
    {
        requireNonNull(returnType, ""returnType is null"");
        requireNonNull(argumentTypes, ""argumentTypes is null"");
        for (ParametricAggregation aggregation : parseFunctionDefinitions(clazz)) {
            if (aggregation.getSignature().getReturnType().equals(returnType) &&
                    aggregation.getSignature().getArgumentTypes().equals(argumentTypes)) {
                return aggregation;
            }
        }
        throw new IllegalArgumentException(String.format(""No method with return type %s and arguments %s"", returnType, argumentTypes));
    }"
"@Override
	public Iterator<FeatureDescriptor> getFeatureDescriptors(ELContext context, Object base) {
		if (isResolvable(base)) {
			JsonNode node = (JsonNode) base;
			final Iterator<String> keys = node.fieldNames();
			return new Iterator<FeatureDescriptor>() {
				@Override
				public boolean hasNext() {
					return keys.hasNext();
				}

				@Override
				public FeatureDescriptor next() {
					Object key = keys.next();
					FeatureDescriptor feature = new FeatureDescriptor();
					feature.setDisplayName(key == null ? ""null"" : key.toString());
					feature.setName(feature.getDisplayName());
					feature.setShortDescription("""");
					feature.setExpert(true);
					feature.setHidden(false);
					feature.setPreferred(true);
					feature.setValue(TYPE, key == null ? ""null"" : key.getClass());
					feature.setValue(RESOLVABLE_AT_DESIGN_TIME, true);
					return feature;

				}

				@Override
				public void remove() {
					throw new UnsupportedOperationException(""cannot remove"");
				}
			};
		}
		return null;
	}"
"@Nonnull
    public static List<SCMDecisionHandler> listShouldPollVetos(@Nonnull Item item) {
        List<SCMDecisionHandler> result = new ArrayList<>();
        for (SCMDecisionHandler handler : all()) {
            if (!handler.shouldPoll(item)) {
                result.add(handler);
            }
        }
        return result;
    }"
"@Override
    public V get(Object key) {
        Segment<K,V> s; // manually integrate access methods to reduce overhead
        HashEntry<K,V>[] tab;
        int h = hash(key);
        long u = (((h >>> segmentShift) & segmentMask) << SSHIFT) + SBASE;
        if ((s = (Segment<K,V>)UNSAFE.getObjectVolatile(segments, u)) != null &&
            (tab = s.table) != null) {
            for (HashEntry<K,V> e = (HashEntry<K,V>) UNSAFE.getObjectVolatile
                     (tab, ((long)(((tab.length - 1) & h)) << TSHIFT) + TBASE);
                 e != null; e = e.next) {
                K k;
                if ((k = e.key) == key || (e.hash == h && key.equals(k))) {
                  return e.value;
                }
            }
        }
        return null;
    }"
"protected void configureFacebookClient(final Collection<BaseClient> properties) {
        val fb = pac4jProperties.getFacebook();
        if (StringUtils.isNotBlank(fb.getId()) && StringUtils.isNotBlank(fb.getSecret())) {
            val client = new FacebookClient(fb.getId(), fb.getSecret());

            configureClient(client, fb);
            if (StringUtils.isNotBlank(fb.getScope())) {
                client.setScope(fb.getScope());
            }

            if (StringUtils.isNotBlank(fb.getFields())) {
                client.setFields(fb.getFields());
            }
            LOGGER.debug(""Created client [{}] with identifier [{}]"", client.getName(), client.getKey());
            properties.add(client);
        }
    }"
"protected final void addDefaultAnnotationValues(String annotation, Map<CharSequence, Object> values) {
        if (annotation != null) {
            Map<String, Map<CharSequence, Object>> annotationDefaults = this.annotationDefaultValues;
            if (annotationDefaults == null) {
                this.annotationDefaultValues = new HashMap<>();
                annotationDefaults = this.annotationDefaultValues;
            }

            putValues(annotation, values, annotationDefaults);
        }
    }"
"public Method unbride(final Method bridgeMethod, Class<?> aClass) throws IOException, NoSuchMethodException, ClassNotFoundException {
        if (bridgeMethod.isBridge() && bridgeMethod.isSynthetic()) {
            if (cache.containsKey(bridgeMethod)) {
                return cache.get(bridgeMethod);
            }

            ClassReader classReader = new ClassReader(aClass.getName());
            final MethodSignature methodSignature = new MethodSignature();
            classReader.accept(new ClassVisitor(ASM5) {
                @Override
                public MethodVisitor visitMethod(int access, String name, String desc, String signature, String[] exceptions) {
                    boolean bridge = (access & ACC_BRIDGE) != 0 && (access & ACC_SYNTHETIC) != 0;
                    if (bridge && bridgeMethod.getName().equals(name) && getParameterCount(desc) == bridgeMethod.getParameterTypes().length) {
                        return new MethodFinder(methodSignature);
                    }
                    return super.visitMethod(access, name, desc, signature, exceptions);
                }
            }, 0);
            Method method = aClass.getDeclaredMethod(methodSignature.name, methodSignature.getParameterTypes());
            cache.put(bridgeMethod, method);
            return method;

        } else {
            return bridgeMethod;
        }
    }"
"public void toBytesSparse(ByteBuffer buf)
  {
    buf.putInt(size);
    buf.putInt(-1 * binCount); // use negative binCount to indicate sparse storage
    for (int i = 0; i < binCount; ++i) {
      buf.putFloat(positions[i]);
    }
    for (int i = 0; i < binCount; ++i) {
      buf.putLong(bins[i]);
    }
    buf.putFloat(min);
    buf.putFloat(max);
  }"
"@Override
    protected List<Term> segSentence(char[] sentence)
    {
        if (sentence.length == 0) return Collections.emptyList();
        List<Term> termList = roughSegSentence(sentence);
        if (!(config.ner || config.useCustomDictionary || config.speechTagging))
            return termList;
        List<Vertex> vertexList = toVertexList(termList, true);
        if (config.speechTagging)
        {
            Viterbi.compute(vertexList, CoreDictionaryTransformMatrixDictionary.transformMatrixDictionary);
            int i = 0;
            for (Term term : termList)
            {
                if (term.nature != null) term.nature = vertexList.get(i + 1).guessNature();
                ++i;
            }
        }
        if (config.useCustomDictionary)
        {
            combineByCustomDictionary(vertexList);
            termList = convert(vertexList, config.offset);
        }
        return termList;
    }"
"@Override
  public Session create(CassandraStorage cassandra) {
    Closer closer = Closer.create();
    try {
      Cluster cluster = closer.register(buildCluster(cassandra));
      cluster.register(new QueryLogger.Builder().build());
      Session session;
      String keyspace = cassandra.keyspace();
      if (cassandra.ensureSchema()) {
        session = closer.register(cluster.connect());
        Schema.ensureExists(keyspace, cassandra.searchEnabled(), session);
        session.execute(""USE "" + keyspace);
      } else {
        LOG.debug(""Skipping schema check on keyspace {} as ensureSchema was false"", keyspace);
        session = cluster.connect(keyspace);
      }

      initializeUDTs(session);

      return session;
    } catch (RuntimeException e) {
      try {
        closer.close();
      } catch (IOException ignored) {
      }
      throw e;
    }
  }"
"public void start() {
		checkState(!closed, ""The RPC connection is already closed"");
		checkState(!isConnected() && pendingRegistration == null, ""The RPC connection is already started"");

		final RetryingRegistration<F, G, S> newRegistration = createNewRegistration();

		if (REGISTRATION_UPDATER.compareAndSet(this, null, newRegistration)) {
			newRegistration.startRegistration();
		} else {
			// concurrent start operation
			newRegistration.cancel();
		}
	}"
"public static String ipAddressToUrlString(InetAddress address) {
		if (address == null) {
			throw new NullPointerException(""address is null"");
		}
		else if (address instanceof Inet4Address) {
			return address.getHostAddress();
		}
		else if (address instanceof Inet6Address) {
			return getIPv6UrlRepresentation((Inet6Address) address);
		}
		else {
			throw new IllegalArgumentException(""Unrecognized type of InetAddress: "" + address);
		}
	}"
"private boolean explanSpecialCondWithBothSidesAreLiterals(SQLBinaryOpExpr bExpr, Where where) throws SqlParseException {
        if ((bExpr.getLeft() instanceof SQLNumericLiteralExpr || bExpr.getLeft() instanceof SQLCharExpr) &&
                (bExpr.getRight() instanceof SQLNumericLiteralExpr || bExpr.getRight() instanceof SQLCharExpr)
                ) {
            SQLMethodInvokeExpr sqlMethodInvokeExpr = new SQLMethodInvokeExpr(""script"", null);
            String operator = bExpr.getOperator().getName();
            if (operator.equals(""="")) {
                operator = ""=="";
            }
            sqlMethodInvokeExpr.addParameter(
                    new SQLCharExpr(Util.expr2Object(bExpr.getLeft(), ""'"") +
                            "" "" + operator + "" "" +
                            Util.expr2Object(bExpr.getRight(), ""'""))
            );

            explanCond(""AND"", sqlMethodInvokeExpr, where);
            return true;
        }
        return false;
    }"
"public void doSchema(StaplerRequest req, StaplerResponse rsp) throws IOException, ServletException {
        setHeaders(rsp);
        rsp.setContentType(""application/xml"");
        StreamResult r = new StreamResult(rsp.getOutputStream());
        new SchemaGenerator(new ModelBuilder().get(bean.getClass())).generateSchema(r);
        r.getOutputStream().close();
    }"
"public static boolean isElement(Node node) {
		return (null == node) ? false : Node.ELEMENT_NODE == node.getNodeType();
	}"
"private List<TopLevelItem> getItems(boolean recurse) {
        SortedSet<String> names;
        List<TopLevelItem> items = new ArrayList<>();

        synchronized (this) {
            names = new TreeSet<>(jobNames);
        }

        ItemGroup<? extends TopLevelItem> parent = getOwner().getItemGroup();
        List<TopLevelItem> parentItems = new ArrayList<>(parent.getItems());
        includeItems(parent, parentItems, names);

        Boolean statusFilter = this.statusFilter; // capture the value to isolate us from concurrent update
        Iterable<? extends TopLevelItem> candidates;
        if (recurse) {
            candidates = parent.getAllItems(TopLevelItem.class);
        } else {
            candidates = parent.getItems();
        }
        for (TopLevelItem item : candidates) {
            if (!names.contains(item.getRelativeNameFrom(getOwner().getItemGroup()))) continue;
            // Add if no status filter or filter matches enabled/disabled status:
            if(statusFilter == null || !(item instanceof ParameterizedJobMixIn.ParameterizedJob) // TODO or better to call the more generic Job.isBuildable?
                              || ((ParameterizedJobMixIn.ParameterizedJob)item).isDisabled() ^ statusFilter)
                items.add(item);
        }

        // check the filters
        Iterable<ViewJobFilter> jobFilters = getJobFilters();
        List<TopLevelItem> allItems = new ArrayList<>(parentItems);
        if (recurse) allItems = expand(allItems, new ArrayList<>());
    	for (ViewJobFilter jobFilter: jobFilters) {
    		items = jobFilter.filter(items, allItems, this);
    	}
        // for sanity, trim off duplicates
        items = new ArrayList<>(new LinkedHashSet<>(items));
        
        return items;
    }"
"public static synchronized Properties getConfig() {
        if (config == null) {
            try {
                String rpcConfig = ""config/rpc-config.properties"";
                InputStream ins = SofaConfigs.class.getClassLoader().getResourceAsStream(rpcConfig);
                if (ins == null) {
                    ins = Thread.currentThread().getContextClassLoader()
                        .getResourceAsStream(rpcConfig);
                }

                config = new Properties();
                config.load(ins);
            } catch (Exception e) {
                config = new Properties();
                if (LOGGER.isDebugEnabled()) {
                    LOGGER.debug(LogCodes.getLog(LogCodes.ERROR_RPC_CONFIG_LOAD));
                }
            }
        }

        return config;
    }"
"public void streamClosed(Status status) {
    if (closed.compareAndSet(false, true)) {
      for (StreamTracer tracer : tracers) {
        tracer.streamClosed(status);
      }
    }
  }"
"private ServerAddress createServerAddress(String group) {
		final Setting setting = checkSetting();

		if (group == null) {
			group = StrUtil.EMPTY;
		}

		final String tmpHost = setting.getByGroup(""host"", group);
		if (StrUtil.isBlank(tmpHost)) {
			throw new NotInitedException(""Host name is empy of group: {}"", group);
		}

		final int defaultPort = setting.getInt(""port"", group, 27017);
		return new ServerAddress(NetUtil.buildInetSocketAddress(tmpHost, defaultPort));
	}"
"public WebServiceTemplateBuilder setFaultMessageResolver(
			FaultMessageResolver faultMessageResolver) {
		return new WebServiceTemplateBuilder(this.detectHttpMessageSender,
				this.interceptors,
				append(this.internalCustomizers,
						new FaultMessageResolverCustomizer(faultMessageResolver)),
				this.customizers, this.messageSenders, this.marshaller, this.unmarshaller,
				this.destinationProvider, this.transformerFactoryClass,
				this.messageFactory);
	}"
"public void fill3_1(byte[] bits, ByteBufferWrapper ab) {
      int bitoff = ab.get2();
      int nbytes = ab.get2();
      fill_1(bits, ab.position(), nbytes<<3, bitoff);
      ab.skip(nbytes);  // Skip inline bitset
    }"
"public static <T> Publisher<T> then(Publisher<T> publisher, Consumer<T> consumer) {
        return actual -> publisher.subscribe(new CompletionAwareSubscriber<T>() {
            @Override
            protected void doOnSubscribe(Subscription subscription) {
                actual.onSubscribe(subscription);
            }

            @Override
            protected void doOnNext(T message) {
                try {
                    actual.onNext(message);
                    consumer.accept(message);
                } catch (Throwable e) {
                    onError(e);
                }
            }

            @Override
            protected void doOnError(Throwable t) {
                actual.onError(t);
            }

            @Override
            protected void doOnComplete() {
                actual.onComplete();
            }
        });
    }"
"@Inject
    public void setReporterConfiguration(@Nullable Configuration.ReporterConfiguration reporterConfiguration) {
        if (reporterConfiguration != null) {
            configuration.withReporter(reporterConfiguration);
        }
    }"
"public static void saveLastExecVersion() {
        if (Jenkins.VERSION.equals(Jenkins.UNCOMPUTED_VERSION)) {
            // This should never happen!! Only adding this check in case someone moves the call to this method to the wrong place.
            throw new IllegalStateException(""Unexpected call to InstallUtil.saveLastExecVersion(). Jenkins.VERSION has not been initialized. Call computeVersion() first."");
        }
        saveLastExecVersion(Jenkins.VERSION);
    }"
"private void issueStreamError(ChannelHandlerContext ctx, int streamId, SpdyStreamStatus status) {
        boolean fireChannelRead = !spdySession.isRemoteSideClosed(streamId);
        ChannelPromise promise = ctx.newPromise();
        removeStream(streamId, promise);

        SpdyRstStreamFrame spdyRstStreamFrame = new DefaultSpdyRstStreamFrame(streamId, status);
        ctx.writeAndFlush(spdyRstStreamFrame, promise);
        if (fireChannelRead) {
            ctx.fireChannelRead(spdyRstStreamFrame);
        }
    }"
"public SQLUnit generateSQL(final TableUnit tableUnit, final SQLBuilder sqlBuilder, final ShardingDataSourceMetaData shardingDataSourceMetaData) {
        return sqlBuilder.toSQL(tableUnit, getTableTokens(tableUnit), shardingRule, shardingDataSourceMetaData);
    }"
"public static void useNioTransport(NettyChannelBuilder builder) {
    builder.channelType(NioSocketChannel.class);
    builder
        .eventLoopGroupPool(SharedResourcePool.forResource(Utils.NIO_WORKER_EVENT_LOOP_GROUP));
  }"
"public static boolean checkUnsupportedJava() {
    if (Boolean.getBoolean(H2O.OptArgs.SYSTEM_PROP_PREFIX + ""debug.noJavaVersionCheck"")) {
      return false;
    }

    // Notes: 
    // - make sure that the following whitelist is logically consistent with whitelist in R code - see function .h2o.check_java_version in connection.R
    // - upgrade of the javassist library should be considered when adding support for a new java version
    if (JAVA_VERSION.isKnown() && !isUserEnabledJavaVersion() && (JAVA_VERSION.getMajor()<7 || JAVA_VERSION.getMajor()>12)) {
      System.err.println(""Only Java 7, 8, 9, 10, 11 and 12 are supported, system version is "" + System.getProperty(""java.version""));
      return true;
    }
    String vmName = System.getProperty(""java.vm.name"");
    if (vmName != null && vmName.equals(""GNU libgcj"")) {
      System.err.println(""GNU gcj is not supported"");
      return true;
    }
    return false;
  }"
"public void setFailure(Throwable cause) {
        if (this.isCancelled()) {
            this.releaseIfNeed(result);
            return;
        }
        if (setFailure0(cause)) {
            notifyListeners();
            return;
        }
        throw new IllegalStateException(""complete already: "" + this, cause);
    }"
"@Override
    public CrossoverResult crossover() {
        double[][] parents = parentSelection.selectParents();

        boolean isModified = false;
        double[] resultGenes = parents[0];

        if (rng.nextDouble() < crossoverRate) {
            // Select crossover points
            Deque<Integer> crossoverPoints = getCrossoverPointsGenerator(parents[0].length).getCrossoverPoints();

            // Crossover
            resultGenes = new double[parents[0].length];
            int currentParent = 0;
            int nextCrossover = crossoverPoints.pop();
            for (int i = 0; i < resultGenes.length; ++i) {
                if (i == nextCrossover) {
                    currentParent = currentParent == 0 ? 1 : 0;
                    nextCrossover = crossoverPoints.pop();
                }
                resultGenes[i] = parents[currentParent][i];
            }
            isModified = true;
        }

        return new CrossoverResult(isModified, resultGenes);
    }"
"public static boolean haveBackend() {
    for (DeepWaterParameters.Backend b : DeepWaterParameters.Backend.values()) {
      if (DeepwaterMojoModel.createDeepWaterBackend(b.toString()) != null) return true;
    }
    return false;
  }"
"@Override
	protected List<OUT> executeOnCollections(List<IN> inputData, RuntimeContext ctx, ExecutionConfig executionConfig) throws Exception {
		MapPartitionFunction<IN, OUT> function = this.userFunction.getUserCodeObject();
		
		FunctionUtils.setFunctionRuntimeContext(function, ctx);
		FunctionUtils.openFunction(function, this.parameters);
		
		ArrayList<OUT> result = new ArrayList<OUT>(inputData.size() / 4);

		TypeSerializer<IN> inSerializer = getOperatorInfo().getInputType().createSerializer(executionConfig);
		TypeSerializer<OUT> outSerializer = getOperatorInfo().getOutputType().createSerializer(executionConfig);

		CopyingIterator<IN> source = new CopyingIterator<IN>(inputData.iterator(), inSerializer);
		CopyingListCollector<OUT> resultCollector = new CopyingListCollector<OUT>(result, outSerializer);

		function.mapPartition(source, resultCollector);

		result.trimToSize();
		FunctionUtils.closeFunction(function);
		return result;
	}"
"public static String getBindCache(EntityColumn column) {
        StringBuilder sql = new StringBuilder();
        sql.append(""<bind name=\"""");
        sql.append(column.getProperty()).append(""_cache\"" "");
        sql.append(""value=\"""").append(column.getProperty()).append(""\""/>"");
        return sql.toString();
    }"
"public void initFunctionFromProperties(String mappedTfName, DifferentialFunction on, Map<String, AttrValue> attributesForNode, NodeDef node, GraphDef graph) {
        val properties = on.mappingsForFunction();
        val tfProperties = properties.get(mappedTfName);
        val fields = DifferentialFunctionClassHolder.getInstance().getFieldsForFunction(on);
        val attributeAdapters = on.attributeAdaptersForFunction();

        // if there's no properties announced for this function - just return
        if (tfProperties == null)
            return;

        //Can't execute in just any order: sometimes there are dependencies between attribute mappings
        //For example, conv2d strides depend on data format -> need to map data format before mapping strides
        //Solution: map nodes without adapters before nodes with adapters. This doesn't guarantee we'll always be
        // mapping in the right order (for example, we might have adapter(x) depends on adapter(y)) but it should catch most cases
        Map<String,PropertyMapping> map;
        if(attributeAdapters == null || !attributeAdapters.containsKey(mappedTfName)) {
            map = tfProperties;
        } else {
            map = new LinkedHashMap<>();
            for (Map.Entry<String, PropertyMapping> e : tfProperties.entrySet()) {
                if (!attributeAdapters.get(mappedTfName).containsKey(e.getKey())) {
                    //No adapter for this attribute
                    map.put(e.getKey(), e.getValue());
                }
            }
            for (Map.Entry<String, PropertyMapping> e : tfProperties.entrySet()) {
                if (!map.containsKey(e.getKey())) {
                    //Not added on first pass -> must have attribute mapper
                    map.put(e.getKey(), e.getValue());
                }
            }
        }

        for(Map.Entry<String,PropertyMapping> entry : map.entrySet()){
            val tfAttrName = entry.getValue().getTfAttrName();
            val currentField = fields.get(entry.getKey());

            AttributeAdapter adapter = null;
            if(attributeAdapters != null && !attributeAdapters.isEmpty()) {
                val mappers = attributeAdapters.get(mappedTfName);
                val adapterFor = mappers.get(entry.getKey());
                adapter = adapterFor;
            }


            if(tfAttrName != null) {
                if(currentField == null) {
                    continue;
                }

                if(attributesForNode.containsKey(tfAttrName)) {
                    val attr = attributesForNode.get(tfAttrName);
                    switch (attr.getValueCase()) {
                        case B:
                            if (adapter != null) {
                                adapter.mapAttributeFor(attr.getB(), currentField, on);
                            }
                            break;
                        case F: break;
                        case FUNC: break;
                        case S:
                            val setString = attr.getS().toStringUtf8();
                            if(adapter != null) {
                                adapter.mapAttributeFor(setString,currentField,on);
                            }
                            else
                                on.setValueFor(currentField,setString);
                            break;
                        case I:
                            val setInt = (int) attr.getI();
                            if(adapter != null) {
                                adapter.mapAttributeFor(setInt,currentField,on);
                            }
                            else
                                on.setValueFor(currentField,setInt);
                            break;
                        case SHAPE:
                            val shape = attr.getShape().getDimList();
                            int[] dimsToSet = new int[shape.size()];
                            for(int i = 0; i < dimsToSet.length; i++) {
                                dimsToSet[i] = (int) shape.get(i).getSize();
                            }

                            if(adapter != null) {
                                adapter.mapAttributeFor(dimsToSet,currentField,on);
                            }

                            else
                                on.setValueFor(currentField,dimsToSet);
                            break;
                        case VALUE_NOT_SET:break;
                        case PLACEHOLDER: break;
                        case LIST:
                            val setList = attr.getList();
                            if(!setList.getIList().isEmpty()) {
                                val intList = Ints.toArray(setList.getIList());
                                if(adapter != null) {
                                    adapter.mapAttributeFor(intList,currentField,on);
                                }
                                else
                                    on.setValueFor(currentField,intList);
                            }
                            else if(!setList.getBList().isEmpty()) {
                                break;
                            }
                            else if(!setList.getFList().isEmpty()) {
                                val floats = Floats.toArray(setList.getFList());
                                if(adapter != null) {
                                    adapter.mapAttributeFor(floats,currentField,on);
                                }

                                else
                                    on.setValueFor(currentField,floats);
                                break;
                            }
                            else if(!setList.getFuncList().isEmpty()) {
                                break;
                            }
                            else if(!setList.getTensorList().isEmpty()) {
                                break;
                            }
                            break;
                        case TENSOR:
                            val tensorToGet = TFGraphMapper.getInstance().mapTensorProto(attr.getTensor());
                            if(adapter != null) {
                                adapter.mapAttributeFor(tensorToGet,currentField,on);
                            }
                            else
                                on.setValueFor(currentField,tensorToGet);
                            break;
                        case TYPE:
                            if (adapter != null) {
                                adapter.mapAttributeFor(attr.getType(), currentField, on);
                            }
                            break;
                    }
                }
            }

            else if(entry.getValue().getTfInputPosition() != null) {


                int position = entry.getValue().getTfInputPosition();
                if(position < 0) {
                    position += node.getInputCount();
                }

                val inputFromNode = TFGraphMapper.getInstance().getNodeWithNameFromGraph(graph,node.getInput(position));
                INDArray tensor = inputFromNode != null ? TFGraphMapper.getInstance().getNDArrayFromTensor(""value"",inputFromNode,graph) : null;
                if(tensor == null) {
                    tensor = on.getSameDiff().getArrForVarName(getNodeName(node.getInput(position)));
                }


                if(tensor != null) {
                    //use adapter instead of direct mapping just like above
                    if(adapter != null) {
                        adapter.mapAttributeFor(tensor,currentField,on);
                    }
                    else {
                        if(currentField.getType().equals(int[].class)) {
                            on.setValueFor(currentField,tensor.data().asInt());
                        }
                        else if(currentField.getType().equals(double[].class)) {
                            on.setValueFor(currentField,tensor.data().asDouble());

                        }
                        else if(currentField.getType().equals(float[].class)) {
                            on.setValueFor(currentField,tensor.data().asFloat());

                        }
                        else if(currentField.getType().equals(INDArray.class)) {
                            on.setValueFor(currentField,tensor);
                        }
                        else if(currentField.getType().equals(int.class)) {
                            on.setValueFor(currentField,tensor.getInt(0));
                        }
                        else if(currentField.getType().equals(double.class)) {
                            on.setValueFor(currentField,tensor.getDouble(0));
                        }
                        else if(currentField.getType().equals(float.class)) {
                            on.setValueFor(currentField,tensor.getFloat(0));
                        }
                    }
                } else {
                    on.getSameDiff().addPropertyToResolve(on,entry.getKey());
                }
            }
        }
    }"
"private void repartitionBroadcastState(
			Map<String, List<Tuple2<StreamStateHandle, OperatorStateHandle.StateMetaInfo>>> broadcastState,
			List<Map<StreamStateHandle, OperatorStateHandle>> mergeMapList) {

		int newParallelism = mergeMapList.size();
		for (int i = 0; i < newParallelism; ++i) {

			final Map<StreamStateHandle, OperatorStateHandle> mergeMap = mergeMapList.get(i);

			// for each name, pick the i-th entry
			for (Map.Entry<String, List<Tuple2<StreamStateHandle, OperatorStateHandle.StateMetaInfo>>> e :
					broadcastState.entrySet()) {

				int previousParallelism = e.getValue().size();

				Tuple2<StreamStateHandle, OperatorStateHandle.StateMetaInfo> handleWithMetaInfo =
					e.getValue().get(i % previousParallelism);

				OperatorStateHandle operatorStateHandle = mergeMap.get(handleWithMetaInfo.f0);
				if (operatorStateHandle == null) {
					operatorStateHandle = new OperatorStreamStateHandle(
						new HashMap<>(broadcastState.size()),
						handleWithMetaInfo.f0);
					mergeMap.put(handleWithMetaInfo.f0, operatorStateHandle);
				}
				operatorStateHandle.getStateNameToPartitionOffsets().put(e.getKey(), handleWithMetaInfo.f1);
			}
		}
	}"
"public static String getAuthority(String site) {
		String authority = site;
		boolean isSecure = false;
		// Remove http(s)://
		if (authority.toLowerCase(Locale.ROOT).startsWith(""http://"")) {
			authority = authority.substring(7);
		} else if (authority.toLowerCase(Locale.ROOT).startsWith(""https://"")) {
			authority = authority.substring(8);
			isSecure = true;
		}
		// Remove trailing chrs
		int idx = authority.indexOf('/');
		if (idx > 0) {
			authority = authority.substring(0, idx);
		}
		if (!authority.isEmpty() && authority.indexOf(':') == -1) {
			if (isSecure) {
				return authority + "":443"";
			}
			return authority + "":80"";
		}
		return authority;
	}"
"private void correctErrors(byte[] codewordBytes, int numDataCodewords) throws ChecksumException {
    int numCodewords = codewordBytes.length;
    // First read into an array of ints
    int[] codewordsInts = new int[numCodewords];
    for (int i = 0; i < numCodewords; i++) {
      codewordsInts[i] = codewordBytes[i] & 0xFF;
    }
    try {
      rsDecoder.decode(codewordsInts, codewordBytes.length - numDataCodewords);
    } catch (ReedSolomonException ignored) {
      throw ChecksumException.getChecksumInstance();
    }
    // Copy back into array of bytes -- only need to worry about the bytes that were data
    // We don't care about errors in the error-correction codewords
    for (int i = 0; i < numDataCodewords; i++) {
      codewordBytes[i] = (byte) codewordsInts[i];
    }
  }"
"public static AuthenticationResult authenticationResultFromRequest(final HttpServletRequest request)
  {
    final AuthenticationResult authenticationResult = (AuthenticationResult) request.getAttribute(
        AuthConfig.DRUID_AUTHENTICATION_RESULT
    );

    if (authenticationResult == null) {
      throw new ISE(""Null authentication result"");
    }

    return authenticationResult;
  }"
"@Override
    public void setRequestHeader(Header header) {
        
        Header[] headers = getRequestHeaderGroup().getHeaders(header.getName());
        
        for (int i = 0; i < headers.length; i++) {
            getRequestHeaderGroup().removeHeader(headers[i]);
        }
        
        getRequestHeaderGroup().addHeader(header);
        
    }"
"public static int indexOf(ByteBuf buffer, int fromIndex, int toIndex, byte value) {
        if (fromIndex <= toIndex) {
            return firstIndexOf(buffer, fromIndex, toIndex, value);
        } else {
            return lastIndexOf(buffer, fromIndex, toIndex, value);
        }
    }"
"public Result getResult(boolean percentage)
    {
        float p = A_cap_B_size / (float) B_size;
        float r = A_cap_B_size / (float) A_size;
        if (percentage)
        {
            p *= 100;
            r *= 100;
        }
        float oov_r = Float.NaN;
        if (OOV > 0)
        {
            oov_r = OOV_R / (float) OOV;
            if (percentage)
                oov_r *= 100;
        }
        float iv_r = Float.NaN;
        if (IV > 0)
        {
            iv_r = IV_R / (float) IV;
            if (percentage)
                iv_r *= 100;
        }
        return new Result(p, r, 2 * p * r / (p + r), oov_r, iv_r);
    }"
"public short[] interpolate(int oldSampleRate, int newSampleRate, short[] samples) {

        if (oldSampleRate == newSampleRate) {
            return samples;
        }

        int newLength = Math.round(((float) samples.length / oldSampleRate * newSampleRate));
        float lengthMultiplier = (float) newLength / samples.length;
        short[] interpolatedSamples = new short[newLength];

        // interpolate the value by the linear equation y=mx+c        
        for (int i = 0; i < newLength; i++) {

            // get the nearest positions for the interpolated point
            float currentPosition = i / lengthMultiplier;
            int nearestLeftPosition = (int) currentPosition;
            int nearestRightPosition = nearestLeftPosition + 1;
            if (nearestRightPosition >= samples.length) {
                nearestRightPosition = samples.length - 1;
            }

            float slope = samples[nearestRightPosition] - samples[nearestLeftPosition]; // delta x is 1
            float positionFromLeft = currentPosition - nearestLeftPosition;

            interpolatedSamples[i] = (short) (slope * positionFromLeft + samples[nearestLeftPosition]); // y=mx+c
        }

        return interpolatedSamples;
    }"
"public String getQueryParameter(String name) {
    Iterable<String> allParams = getQueryParameters(name);
    if (allParams == null) {
      return null;
    }
    Iterator<String> iterator = allParams.iterator();
    return iterator.hasNext() ? iterator.next() : null;
  }"
"public OtpErlangObject receive() throws OtpErlangExit,
            OtpErlangDecodeException {
        try {
            return receiveMsg().getMsg();
        } catch (final OtpErlangExit e) {
            throw e;
        } catch (final OtpErlangDecodeException f) {
            throw f;
        }
    }"
"@SuppressWarnings(""unused"") // used by jelly
    public boolean isUsingSecurityToken() {
        try {
            return !Jenkins.get().getInstallState().isSetupComplete()
                    && isUsingSecurityDefaults();
        } catch (Exception e) {
            // ignore
        }
        return false;
    }"
"@Override
  public String quit() {
    checkIsInMultiOrPipeline();
    client.quit();
    String quitReturn = client.getStatusCodeReply();
    client.disconnect();
    return quitReturn;
  }"
"public static ValueMatcher makeValueMatcher(
      final ColumnSelectorFactory columnSelectorFactory,
      final String columnName,
      final String value
  )
  {
    final ColumnSelectorPlus<ValueMatcherColumnSelectorStrategy> selector =
        DimensionHandlerUtils.createColumnSelectorPlus(
            ValueMatcherColumnSelectorStrategyFactory.instance(),
            DefaultDimensionSpec.of(columnName),
            columnSelectorFactory
        );

    return selector.getColumnSelectorStrategy().makeValueMatcher(selector.getSelector(), value);
  }"
"@Override
    public DataBuffer createHalf(long offset, byte[] data, int length) {
        return new CudaHalfDataBuffer(ArrayUtil.toFloatArray(data), true, offset);
    }"
"public static int[] validate3(int[] data, String paramName){
        if(data == null) {
            return null;
        }

        Preconditions.checkArgument(data.length == 1 || data.length == 3,
                ""Need either 1 or 3 %s values, got %s values: %s"",
                paramName, data.length, data);

        if(data.length == 1){
            return new int[]{data[0], data[0], data[0]};
        } else {
            return data;
        }
    }"
"final List<? extends E> get(String hostname) {
        Entries entries = resolveCache.get(hostname);
        return entries == null ? null : entries.get();
    }"
"private Object handleJoinPointCompletableFuture(ProceedingJoinPoint proceedingJoinPoint, io.github.resilience4j.ratelimiter.RateLimiter rateLimiter) {
		return rateLimiter.executeCompletionStage(() -> {
			try {
				return (CompletionStage<?>) proceedingJoinPoint.proceed();
			} catch (Throwable throwable) {
				throw new CompletionException(throwable);
			}
		});
	}"
"protected BaseClient<Credentials, CommonProfile> findDelegatedClientByName(final HttpServletRequest request, final String clientName, final Service service) {
        val client = (BaseClient<Credentials, CommonProfile>) this.clients.findClient(clientName);
        LOGGER.debug(""Delegated authentication client is [{}] with service [{}}"", client, service);
        if (service != null) {
            request.setAttribute(CasProtocolConstants.PARAMETER_SERVICE, service.getId());
            if (!isDelegatedClientAuthorizedForService(client, service)) {
                LOGGER.warn(""Delegated client [{}] is not authorized by service [{}]"", client, service);
                throw new UnauthorizedServiceException(UnauthorizedServiceException.CODE_UNAUTHZ_SERVICE, StringUtils.EMPTY);
            }
        }
        return client;
    }"
"public static INDArray getAllCandidates(INDArray x,List<RPTree> trees,String similarityFunction) {
        List<Integer> candidates = getCandidates(x,trees,similarityFunction);
        Collections.sort(candidates);

        int prevIdx = -1;
        int idxCount = 0;
        List<Pair<Integer,Integer>> scores = new ArrayList<>();
        for(int i = 0; i < candidates.size(); i++) {
            if(candidates.get(i) == prevIdx) {
                idxCount++;
            }
            else if(prevIdx != -1) {
                scores.add(Pair.of(idxCount,prevIdx));
                idxCount = 1;
            }

            prevIdx = i;
        }


        scores.add(Pair.of(idxCount,prevIdx));

        INDArray arr = Nd4j.create(scores.size());
        for(int i = 0; i < scores.size(); i++) {
            arr.putScalar(i,scores.get(i).getSecond());
        }

        return arr;
    }"
"public static Collection<IteratorSetting> getMetricIterators(AccumuloTable table)
    {
        String cardQualifier = new String(CARDINALITY_CQ);
        String rowsFamily = new String(METRICS_TABLE_ROWS_CF.array());

        // Build a string for all columns where the summing combiner should be applied,
        // i.e. all indexed columns
        StringBuilder cardBuilder = new StringBuilder(rowsFamily + "":"" + cardQualifier + "","");
        for (String s : getLocalityGroups(table).keySet()) {
            cardBuilder.append(s).append("":"").append(cardQualifier).append(',');
        }
        cardBuilder.deleteCharAt(cardBuilder.length() - 1);

        // Configuration rows for the Min/Max combiners
        String firstRowColumn = rowsFamily + "":"" + new String(METRICS_TABLE_FIRST_ROW_CQ.array());
        String lastRowColumn = rowsFamily + "":"" + new String(METRICS_TABLE_LAST_ROW_CQ.array());

        // Summing combiner for cardinality columns
        IteratorSetting s1 = new IteratorSetting(1, SummingCombiner.class, ImmutableMap.of(""columns"", cardBuilder.toString(), ""type"", ""STRING""));

        // Min/Max combiner for the first/last rows of the table
        IteratorSetting s2 = new IteratorSetting(2, MinByteArrayCombiner.class, ImmutableMap.of(""columns"", firstRowColumn));
        IteratorSetting s3 = new IteratorSetting(3, MaxByteArrayCombiner.class, ImmutableMap.of(""columns"", lastRowColumn));

        return ImmutableList.of(s1, s2, s3);
    }"
"public <T> DataSet<T> groupReduceOnEdges(EdgesFunction<K, EV, T> edgesFunction,
			EdgeDirection direction, TypeInformation<T> typeInfo) throws IllegalArgumentException {

		switch (direction) {
			case IN:
				return edges.map(new ProjectVertexIdMap<>(1)).name(""Vertex ID"")
						.withForwardedFields(""f1->f0"")
						.groupBy(0).reduceGroup(new ApplyGroupReduceFunction<>(edgesFunction))
							.name(""GroupReduce on in-edges"").returns(typeInfo);
			case OUT:
				return edges.map(new ProjectVertexIdMap<>(0)).name(""Vertex ID"")
						.withForwardedFields(""f0"")
						.groupBy(0).reduceGroup(new ApplyGroupReduceFunction<>(edgesFunction))
							.name(""GroupReduce on out-edges"").returns(typeInfo);
			case ALL:
				return edges.flatMap(new EmitOneEdgePerNode<>()).name(""Emit edge"")
						.groupBy(0).reduceGroup(new ApplyGroupReduceFunction<>(edgesFunction))
							.name(""GroupReduce on in- and out-edges"").returns(typeInfo);
			default:
				throw new IllegalArgumentException(""Illegal edge direction"");
		}
	}"
"@Override
	public void close() throws Exception {
		synchronized (lock) {
			if (!isShutDown()) {
				// stop all job manager leader services
				for (EmbeddedLeaderService service : jobManagerLeaderServices.values()) {
					service.shutdown();
				}
				jobManagerLeaderServices.clear();

				resourceManagerLeaderService.shutdown();

				webMonitorLeaderService.shutdown();
			}

			super.close();
		}
	}"
"public static Class<?> typeToClass(Type t) {
		if (t instanceof Class) {
			return (Class<?>)t;
		}
		else if (t instanceof ParameterizedType) {
			return ((Class<?>) ((ParameterizedType) t).getRawType());
		}
		throw new IllegalArgumentException(""Cannot convert type to class"");
	}"
"@PublicEvolving
	public double getDouble(ConfigOption<Double> configOption) {
		Object o = getValueOrDefaultFromOption(configOption);
		return convertToDouble(o, configOption.defaultValue());
	}"
"private boolean notifyPersistentConnectionListener(HttpMessage httpMessage, Socket inSocket, ZapGetMethod method) {
        boolean keepSocketOpen = false;
        PersistentConnectionListener listener = null;
        synchronized (persistentConnectionListener) {
            for (int i = 0; i < persistentConnectionListener.size(); i++) {
                listener = persistentConnectionListener.get(i);
                try {
                    if (listener.onHandshakeResponse(httpMessage, inSocket, method)) {
                        // inform as long as one listener wishes to overtake the connection
                        keepSocketOpen = true;
                        break;
                    }
                } catch (Exception e) {
                    logger.warn(e.getMessage(), e);
                }
            }
        }

        return keepSocketOpen;
    }"
"public void doSave(@Param(""dataMediaPairId"") Long dataMediaPairId, @Param(""submitKey"") String submitKey,
                       @Param(""channelId"") Long channelId, @Param(""pipelineId"") Long pipelineId,
                       @Param(""sourceMediaId"") Long sourceMediaId, @Param(""targetMediaId"") Long targetMediaId,
                       @FormGroup(""columnPairInfo"") Group columnPairInfo,
                       @FormField(name = ""formColumnPairError"", group = ""columnPairInfo"") CustomErrors err,
                       Navigator nav) throws Exception {
        String[] sourceColumns = columnPairInfo.getField(""dltTarget_l"").getStringValues();
        String[] targetColumns = columnPairInfo.getField(""dltTarget_r"").getStringValues();
        List<String> sourceColumnNames = new ArrayList<String>();
        List<String> targetColumnNames = new ArrayList<String>();
        for (String sourceColumn : sourceColumns) {
            sourceColumnNames.add(sourceColumn);
        }

        for (String targetColumn : targetColumns) {
            targetColumnNames.add(targetColumn);
        }

        DataMedia targetMedia = dataMediaPairService.findById(dataMediaPairId).getTarget();

        if (!targetMedia.getSource().getType().isNapoli() && sourceColumnNames.size() != targetColumnNames.size()) {
            err.setMessage(""invalidColumnPair"");
            return;
        }
        List<ColumnPair> columnPairsInDb = dataColumnPairService.listByDataMediaPairId(dataMediaPairId);
        List<ColumnPair> columnPairsTemp = new ArrayList<ColumnPair>();
        List<String> columnPairsNameSource = new ArrayList<String>();
        List<String> columnPairsNameTarget = new ArrayList<String>();
        List<ColumnPair> columnPairs = new ArrayList<ColumnPair>();

        if (targetMedia.getSource().getType().isNapoli()) {
            for (ColumnPair columnPair : columnPairsInDb) {
                for (String sourceColumnName : sourceColumnNames) {
                    if (StringUtils.isEquals(columnPair.getSourceColumn().getName(), sourceColumnName)) {
                        columnPairsTemp.add(columnPair);
                        columnPairsNameSource.add(sourceColumnName);
                    }
                }
            }
            // 要从数据库中删除这些columnPair
            columnPairsInDb.removeAll(columnPairsTemp);
            sourceColumnNames.removeAll(columnPairsNameSource);

            for (String columnName : sourceColumnNames) {
                ColumnPair columnPair = new ColumnPair();
                columnPair.setSourceColumn(new Column(columnName));
                columnPair.setDataMediaPairId(dataMediaPairId);
                columnPairs.add(columnPair);
            }
        } else if (targetMedia.getSource().getType().isMysql() || targetMedia.getSource().getType().isOracle()) {
            for (ColumnPair columnPair : columnPairsInDb) {
                int i = 0;
                for (String sourceColumnName : sourceColumnNames) {
                    if (StringUtils.isEquals(columnPair.getSourceColumn().getName(), sourceColumnName)
                        && StringUtils.isEquals(columnPair.getTargetColumn().getName(), targetColumnNames.get(i))) {
                        columnPairsTemp.add(columnPair);
                        columnPairsNameSource.add(sourceColumnName);
                        columnPairsNameTarget.add(targetColumnNames.get(i));
                    }
                    i++;
                }
            }
            // 要从数据库中删除这些columnPair
            columnPairsInDb.removeAll(columnPairsTemp);
            sourceColumnNames.removeAll(columnPairsNameSource);
            targetColumnNames.removeAll(columnPairsNameTarget);

            int i = 0;
            for (String columnName : sourceColumnNames) {
                ColumnPair columnPair = new ColumnPair();
                columnPair.setSourceColumn(new Column(columnName));
                columnPair.setTargetColumn(new Column(targetColumnNames.get(i)));
                columnPair.setDataMediaPairId(dataMediaPairId);
                columnPairs.add(columnPair);
                i++;
            }
        }

        for (ColumnPair columnPair : columnPairsInDb) {
            dataColumnPairService.remove(columnPair.getId());
        }

        dataColumnPairService.createBatch(columnPairs);

        if (submitKey.equals(""保存"")) {
            nav.redirectToLocation(""dataMediaPairList.htm?pipelineId="" + pipelineId);
        } else if (submitKey.equals(""下一步"")) {
            nav.redirectToLocation(""addColumnPairGroup.htm?dataMediaPairId="" + dataMediaPairId + ""&channelId=""
                                   + channelId + ""&pipelineId="" + pipelineId + ""&sourceMediaId="" + sourceMediaId
                                   + ""&targetMediaId="" + targetMediaId);
        }
    }"
"public static KeyPairGenerator getKeyPairGenerator(String algorithm) {
		final Provider provider = GlobalBouncyCastleProvider.INSTANCE.getProvider();

		KeyPairGenerator keyPairGen;
		try {
			keyPairGen = (null == provider) //
					? KeyPairGenerator.getInstance(getMainAlgorithm(algorithm)) //
					: KeyPairGenerator.getInstance(getMainAlgorithm(algorithm), provider);//
		} catch (NoSuchAlgorithmException e) {
			throw new CryptoException(e);
		}
		return keyPairGen;
	}"
"public @Nonnull String getRootUrlFromRequest() {
        StaplerRequest req = Stapler.getCurrentRequest();
        if (req == null) {
            throw new IllegalStateException(""cannot call getRootUrlFromRequest from outside a request handling thread"");
        }
        StringBuilder buf = new StringBuilder();
        String scheme = getXForwardedHeader(req, ""X-Forwarded-Proto"", req.getScheme());
        buf.append(scheme).append(""://"");
        String host = getXForwardedHeader(req, ""X-Forwarded-Host"", req.getServerName());
        int index = host.indexOf(':');
        int port = req.getServerPort();
        if (index == -1) {
            // Almost everyone else except Nginx put the host and port in separate headers
            buf.append(host);
        } else {
            // Nginx uses the same spec as for the Host header, i.e. hostname:port
            buf.append(host.substring(0, index));
            if (index + 1 < host.length()) {
                try {
                    port = Integer.parseInt(host.substring(index + 1));
                } catch (NumberFormatException e) {
                    // ignore
                }
            }
            // but if a user has configured Nginx with an X-Forwarded-Port, that will win out.
        }
        String forwardedPort = getXForwardedHeader(req, ""X-Forwarded-Port"", null);
        if (forwardedPort != null) {
            try {
                port = Integer.parseInt(forwardedPort);
            } catch (NumberFormatException e) {
                // ignore
            }
        }
        if (port != (""https"".equals(scheme) ? 443 : 80)) {
            buf.append(':').append(port);
        }
        buf.append(req.getContextPath()).append('/');
        return buf.toString();
    }"
"public REQ deserializeRequest(final ByteBuf buf) {
		Preconditions.checkNotNull(buf);
		return requestDeserializer.deserializeMessage(buf);
	}"
"protected Credentials getCredentialsFromDelegatedClient(final J2EContext webContext, final BaseClient<Credentials, CommonProfile> client) {
        val credentials = client.getCredentials(webContext);
        LOGGER.debug(""Retrieved credentials from client as [{}]"", credentials);
        if (credentials == null) {
            throw new IllegalArgumentException(""Unable to determine credentials from the context with client "" + client.getName());
        }
        return credentials;
    }"
"public void setUseGlobalState(boolean enableGlobalState) {
		if (enableGlobalState) {
			checkState();
		} else {
			client.setState(new HttpState());
			clientViaProxy.setState(new HttpState());
			setClientsCookiePolicy(CookiePolicy.BROWSER_COMPATIBILITY);
		}
	}"
"public static long distance(CommonSynonymDictionary.SynonymItem itemA, CommonSynonymDictionary.SynonymItem itemB)
    {
        return itemA.distance(itemB);
    }"
"public static ComputationGraphConfiguration importKerasModelConfiguration(String modelJsonFilename)
            throws IOException, InvalidKerasConfigurationException, UnsupportedKerasConfigurationException {
        KerasModel kerasModel = new KerasModel().modelBuilder().modelJsonFilename(modelJsonFilename)
                .enforceTrainingConfig(false).buildModel();
        return kerasModel.getComputationGraphConfiguration();
    }"
"public <O> ListenableFuture<O> borrowBatchAsync(int maxSize, Function<List<T>, BorrowResult<T, O>> function)
    {
        checkArgument(maxSize >= 0, ""maxSize must be at least 0"");

        ListenableFuture<List<T>> borrowedListFuture;
        synchronized (this) {
            List<T> list = getBatch(maxSize);
            if (!list.isEmpty()) {
                borrowedListFuture = immediateFuture(list);
                borrowerCount++;
            }
            else if (finishing && borrowerCount == 0) {
                borrowedListFuture = immediateFuture(ImmutableList.of());
            }
            else {
                borrowedListFuture = Futures.transform(
                        notEmptySignal,
                        ignored -> {
                            synchronized (this) {
                                List<T> batch = getBatch(maxSize);
                                if (!batch.isEmpty()) {
                                    borrowerCount++;
                                }
                                return batch;
                            }
                        },
                        executor);
            }
        }

        return Futures.transform(
                borrowedListFuture,
                elements -> {
                    // The borrowerCount field was only incremented for non-empty lists.
                    // Decrements should only happen for non-empty lists.
                    // When it should, it must always happen even if the caller-supplied function throws.
                    try {
                        BorrowResult<T, O> borrowResult = function.apply(elements);
                        if (elements.isEmpty()) {
                            checkArgument(borrowResult.getElementsToInsert().isEmpty(), ""Function must not insert anything when no element is borrowed"");
                            return borrowResult.getResult();
                        }
                        for (T element : borrowResult.getElementsToInsert()) {
                            offer(element);
                        }
                        return borrowResult.getResult();
                    }
                    finally {
                        if (!elements.isEmpty()) {
                            synchronized (this) {
                                borrowerCount--;
                                signalIfFinishing();
                            }
                        }
                    }
                }, directExecutor());
    }"
"public synchronized void add(T actual, T predicted, int count) {
        if (matrix.containsKey(actual)) {
            matrix.get(actual).add(predicted, count);
        } else {
            Multiset<T> counts = HashMultiset.create();
            counts.add(predicted, count);
            matrix.put(actual, counts);
        }
    }"
"public static void putCredential(final RequestContext context, final Credential c) {
        if (c == null) {
            context.getRequestScope().remove(PARAMETER_CREDENTIAL);
            context.getFlowScope().remove(PARAMETER_CREDENTIAL);
            context.getConversationScope().remove(PARAMETER_CREDENTIAL);
        } else {
            context.getRequestScope().put(PARAMETER_CREDENTIAL, c);
            context.getFlowScope().put(PARAMETER_CREDENTIAL, c);
            context.getConversationScope().put(PARAMETER_CREDENTIAL, c);
        }
    }"
"public static String channelToString(SocketAddress local1, SocketAddress remote1) {
        try {
            InetSocketAddress local = (InetSocketAddress) local1;
            InetSocketAddress remote = (InetSocketAddress) remote1;
            return toAddressString(local) + "" -> "" + toAddressString(remote);
        } catch (Exception e) {
            return local1 + ""->"" + remote1;
        }
    }"
"public AnnotationMetadata buildForMethod(T element) {
        final AnnotationMetadata existing = MUTATED_ANNOTATION_METADATA.get(element);
        if (existing != null) {
            return existing;
        } else {
            DefaultAnnotationMetadata annotationMetadata = new DefaultAnnotationMetadata();
            return buildInternal(null, element, annotationMetadata, false, false);
        }
    }"
"public MatchIterator get(long key, int hashCode) {
		int bucket = hashCode & numBucketsMask;

		int bucketOffset = bucket << 4;
		MemorySegment segment = buckets[bucketOffset >>> segmentSizeBits];
		int segOffset = bucketOffset & segmentSizeMask;

		while (true) {
			long address = segment.getLong(segOffset + 8);
			if (address != INVALID_ADDRESS) {
				if (segment.getLong(segOffset) == key) {
					return valueIter(address);
				} else {
					bucket = (bucket + 1) & numBucketsMask;
					if (segOffset + 16 < segmentSize) {
						segOffset += 16;
					} else {
						bucketOffset = bucket << 4;
						segOffset = bucketOffset & segmentSizeMask;
						segment = buckets[bucketOffset >>> segmentSizeBits];
					}
				}
			} else {
				return valueIter(INVALID_ADDRESS);
			}
		}
	}"
"public static MultiLayerNetwork importKerasSequentialModelAndWeights(String modelHdf5Filename,
                                                                         int[] inputShape,
                                                                         boolean enforceTrainingConfig)
            throws IOException, InvalidKerasConfigurationException, UnsupportedKerasConfigurationException {
        KerasSequentialModel kerasModel = new KerasSequentialModel().modelBuilder().modelHdf5Filename(modelHdf5Filename)
                .enforceTrainingConfig(enforceTrainingConfig).inputShape(inputShape).buildSequential();
        return kerasModel.getMultiLayerNetwork();
    }"
"protected boolean loadDat(ByteArray byteArray)
    {
        V[] valueArray = loadValueArray(byteArray);
        if (valueArray == null)
        {
            return false;
        }
        return trie.load(byteArray.getBytes(), byteArray.getOffset(), valueArray);
    }"
"@SuppressWarnings(""unchecked"")
    static void registerAnnotationType(AnnotationClassValue<?> annotationClassValue) {
        final String name = annotationClassValue.getName();
        if (!ANNOTATION_TYPES.containsKey(name)) {
            annotationClassValue.getType().ifPresent((Consumer<Class<?>>) aClass -> {
                if (Annotation.class.isAssignableFrom(aClass)) {
                    ANNOTATION_TYPES.put(name, (Class<? extends Annotation>) aClass);
                }
            });
        }
    }"
"public String serializeReducerList(List<IAssociativeReducer> list) {
        ObjectMapper om = getObjectMapper();
        try {
            return om.writeValueAsString(new ListWrappers.ReducerList(list));
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    }"
"public static void pressImage(InputStream srcStream, OutputStream destStream, Image pressImg, int x, int y, float alpha) {
		pressImage(read(srcStream), getImageOutputStream(destStream), pressImg, x, y, alpha);
	}"
"public static Protos.Resource ranges(String name, String role, Protos.Value.Range... ranges) {
		checkNotNull(name);
		checkNotNull(role);
		checkNotNull(ranges);
		return Protos.Resource.newBuilder()
			.setName(name)
			.setType(Protos.Value.Type.RANGES)
			.setRanges(Protos.Value.Ranges.newBuilder().addAllRange(Arrays.asList(ranges)).build())
			.setRole(role)
			.build();
	}"
"public INDArray reconstructionError(INDArray data) {
        if (!hasLossFunction()) {
            throw new IllegalStateException(
                            ""Cannot use reconstructionError method unless the variational autoencoder is ""
                                            + ""configured with a standard loss function (via LossFunctionWrapper). For VAEs utilizing a reconstruction ""
                                            + ""distribution, use the reconstructionProbability or reconstructionLogProbability methods ""
                                            + layerId());
        }

        INDArray pZXMean = activate(data, false, LayerWorkspaceMgr.noWorkspaces());
        INDArray reconstruction = generateAtMeanGivenZ(pZXMean); //Not probabilistic -> ""mean"" == output

        if (reconstructionDistribution instanceof CompositeReconstructionDistribution) {
            CompositeReconstructionDistribution c = (CompositeReconstructionDistribution) reconstructionDistribution;
            return c.computeLossFunctionScoreArray(data, reconstruction);
        } else {

            LossFunctionWrapper lfw = (LossFunctionWrapper) reconstructionDistribution;
            ILossFunction lossFunction = lfw.getLossFunction();

            //Re: the activation identity here - the reconstruction array already has the activation function applied,
            // so we don't want to apply it again. i.e., we are passing the output, not the pre-output.
            return lossFunction.computeScoreArray(data, reconstruction, new ActivationIdentity(), null);
        }
    }"
"@Override
    public void save() {
        List<Object> contextSpecificObjects = new ArrayList<Object>();

        techTreeState = getTechTree().getTechSet();

        if (!this.getBoolValue(FIELD_ADVANCED)) {
            contextSpecificObjects.add(scanPolicy);
        } else {
            contextSpecificObjects.add(policyPanel.getScanPolicy());
        	
        	if (target == null && this.customPanels != null) {
        		// One of the custom scan panels must have specified a target 
            	for (CustomScanPanel customPanel : this.customPanels) {
                    target = customPanel.getTarget();
                    if (target != null) {
                    	break;
                    }
            	}
        	}

            // Save all Variant configurations
            getVariantPanel().saveParam(scannerParam);
            
            // If all other vectors has been disabled
            // force all injectable params and rpc model to NULL
            if (getDisableNonCustomVectors().isSelected()) {
                scannerParam.setTargetParamsInjectable(0);
                scannerParam.setTargetParamsEnabledRPC(0);                
            }
            
            if (!getBoolValue(FIELD_RECURSE) && injectionPointModel.getSize() > 0) {
                int[][] injPoints = new int[injectionPointModel.getSize()][];
                for (int i = 0; i < injectionPointModel.getSize(); i++) {
                    Highlight hl = injectionPointModel.elementAt(i);
                    injPoints[i] = new int[2];
                    injPoints[i][0] = hl.getStartOffset();
                    injPoints[i][1] = hl.getEndOffset();
                }

                try {
                    if (target != null && target.getStartNode() != null) {
                        VariantUserDefined.setInjectionPoints(
                                this.target.getStartNode().getHistoryReference().getURI().toString(),
                                injPoints);

                        enableUserDefinedRPC();
                    }

                } catch (Exception e) {
                    logger.error(e.getMessage(), e);
                }
            }

            scannerParam.setHostPerScan(extension.getScannerParam().getHostPerScan());
            scannerParam.setThreadPerHost(extension.getScannerParam().getThreadPerHost());
            scannerParam.setHandleAntiCSRFTokens(extension.getScannerParam().getHandleAntiCSRFTokens());
            scannerParam.setMaxResultsToList(extension.getScannerParam().getMaxResultsToList());


            contextSpecificObjects.add(scannerParam);
            contextSpecificObjects.add(techTreeState);
            
            if (this.customPanels != null) {
            	for (CustomScanPanel customPanel : this.customPanels) {
                    Object[] objs = customPanel.getContextSpecificObjects();
                    if (objs != null) {
                    	for (Object obj : objs) {
                            contextSpecificObjects.add(obj);
                    	}
                    }
            	}
            }
        }

        target.setRecurse(this.getBoolValue(FIELD_RECURSE));

        if (target.getContext() == null && getSelectedContext() != null) {
            target.setContext(getSelectedContext());
        }

        this.extension.startScan(
                target,
                getSelectedUser(),
                contextSpecificObjects.toArray());
    }"
"private boolean isExcluded(String uri) {
		if (excludeList == null || excludeList.isEmpty()) {
			return false;
		}

		for (String ex : excludeList) {
			if (uri.matches(ex)) {
				return true;
			}
		}
		return false;
	}"
"public static Headers varyHeaders(Headers requestHeaders, Headers responseHeaders) {
    Set<String> varyFields = varyFields(responseHeaders);
    if (varyFields.isEmpty()) return EMPTY_HEADERS;

    Headers.Builder result = new Headers.Builder();
    for (int i = 0, size = requestHeaders.size(); i < size; i++) {
      String fieldName = requestHeaders.name(i);
      if (varyFields.contains(fieldName)) {
        result.add(fieldName, requestHeaders.value(i));
      }
    }
    return result.build();
  }"
"protected void configureEndpointAccessByFormLogin(final ExpressionUrlAuthorizationConfigurer<HttpSecurity>.ExpressionInterceptUrlRegistry requests) throws Exception {
        requests.and()
            .formLogin()
            .loginPage(ENDPOINT_URL_ADMIN_FORM_LOGIN)
            .permitAll();
    }"
"protected Set<Resource> doFindPathMatchingFileResources(Resource rootDirResource, String subPattern)
        throws IOException {

        File rootDir;
        try {
            rootDir = rootDirResource.getFile().getAbsoluteFile();
        } catch (IOException ex) {
            return Collections.emptySet();
        }
        return doFindMatchingFileSystemResources(rootDir, subPattern);
    }"
"private void updateDelta(Applications delta) {
        int deltaCount = 0;
        for (Application app : delta.getRegisteredApplications()) {
            for (InstanceInfo instance : app.getInstances()) {
                ++deltaCount;
                if (ActionType.ADDED.equals(instance.getActionType())) {
                    Application existingApp = getApplications()
                            .getRegisteredApplications(instance.getAppName());
                    if (existingApp == null) {
                        getApplications().addApplication(app);
                    }
                    logger.debug(""Added instance {} to the existing apps "",
                            instance.getId());
                    getApplications().getRegisteredApplications(
                            instance.getAppName()).addInstance(instance);
                } else if (ActionType.MODIFIED.equals(instance.getActionType())) {
                    Application existingApp = getApplications()
                            .getRegisteredApplications(instance.getAppName());
                    if (existingApp == null) {
                        getApplications().addApplication(app);
                    }
                    logger.debug(""Modified instance {} to the existing apps "",
                            instance.getId());

                    getApplications().getRegisteredApplications(
                            instance.getAppName()).addInstance(instance);

                } else if (ActionType.DELETED.equals(instance.getActionType())) {
                    Application existingApp = getApplications()
                            .getRegisteredApplications(instance.getAppName());
                    if (existingApp == null) {
                        getApplications().addApplication(app);
                    }
                    logger.debug(""Deleted instance {} to the existing apps "",
                            instance.getId());
                    getApplications().getRegisteredApplications(
                            instance.getAppName()).removeInstance(instance);
                }
            }
        }
        logger.debug(
                ""The total number of instances fetched by the delta processor : {}"",
                deltaCount);

    }"
"public final void sendMessageToAllNeighbors(Message m) {
		verifyEdgeUsage();
		outMsg.f1 = m;
		while (edges.hasNext()) {
			Tuple next = edges.next();
			outMsg.f0 = next.getField(1);
			out.collect(Either.Right(outMsg));
		}
	}"
"static <IN> PatternStreamBuilder<IN> forStreamAndPattern(final DataStream<IN> inputStream, final Pattern<IN, ?> pattern) {
		return new PatternStreamBuilder<>(inputStream, pattern, null, null);
	}"
"private JSplitPane createSelectPanelsSplit() {
		JSplitPane splitHoriz = new JSplitPane();
		splitHoriz.setLeftComponent(getPaneSelect());
		switch (layout) {
		case EXPAND_SELECT:
			splitHoriz.setRightComponent(createStatusPanelsSplit());
			break;
		case EXPAND_STATUS:
		default:
			splitHoriz.setRightComponent(getPaneWork());
			break;
		}

		splitHoriz.setDividerLocation(restoreDividerLocation(DIVIDER_HORIZONTAL, 300));
		splitHoriz.addPropertyChangeListener(JSplitPane.DIVIDER_LOCATION_PROPERTY, new DividerResizedListener(DIVIDER_HORIZONTAL));

		splitHoriz.setDividerSize(3);
		splitHoriz.setResizeWeight(0.3D);
		splitHoriz.setContinuousLayout(false);
		splitHoriz.setBorder(BorderFactory.createEmptyBorder(0, 0, 0, 0));
		return splitHoriz;
	}"
"@Override
    public Collection<String> wordsNearest(String label, int n) {
        if (!vocabCache.hasToken(label))
            return new ArrayList<>();

        Collection<String> collection = wordsNearest(Arrays.asList(label), new ArrayList<String>(), n + 1);
        if (collection.contains(label))
            collection.remove(label);

        return collection;
    }"
"public PartitionOperator<T> partitionByRange(int... fields) {
		return new PartitionOperator<>(this, PartitionMethod.RANGE, new Keys.ExpressionKeys<>(fields, getType()), Utils.getCallLocationName());
	}"
"@Override
    public HttpContent readChunk(ByteBufAllocator allocator) throws Exception {
        if (isLastChunkSent) {
            return null;
        } else {
            HttpContent nextChunk = nextChunk();
            globalProgress += nextChunk.content().readableBytes();
            return nextChunk;
        }
    }"
"void unregisterInputStream(InStream stream) {
		lock.lock();
		try {
			// only decrement if we actually remove the stream
			if (openInputStreams.remove(stream)) {
				numReservedInputStreams--;
				available.signalAll();
			}
		}
		finally {
			lock.unlock();
		}
	}"
"void deleteProjectDirsIfNecessary(final long newProjectSizeInBytes) {
    final long projectCacheMaxSizeInByte =
        (long) (this.projectCacheDir.getTotalSpace() * this.percentageOfDisk);

    final long start = System.currentTimeMillis();
    final List<ProjectDirectoryMetadata> allProjects = loadAllProjects();
    log.info(""Loading {} project dirs metadata completed in {} sec(s)"",
        allProjects.size(), (System.currentTimeMillis() - start) / 1000);

    final long currentSpaceInBytes = getProjectDirsTotalSizeInBytes(allProjects);
    if (currentSpaceInBytes + newProjectSizeInBytes >= projectCacheMaxSizeInByte) {
      log.info(
          ""Project cache usage[{} MB] >= cache limit[{} MB], start cleaning up project dirs"",
          (currentSpaceInBytes + newProjectSizeInBytes) / (1024 * 1024),
          projectCacheMaxSizeInByte / (1024 * 1024));

      final long freeCacheSpaceInBytes = projectCacheMaxSizeInByte - currentSpaceInBytes;

      deleteLeastRecentlyUsedProjects(newProjectSizeInBytes - freeCacheSpaceInBytes, allProjects);
    }
  }"
"public boolean toLong(LongWrapper toLongResult) {
    if (numBytes == 0) {
      return false;
    }

    byte b = getByte(0);
    final boolean negative = b == '-';
    int offset = 0;
    if (negative || b == '+') {
      offset++;
      if (numBytes == 1) {
        return false;
      }
    }

    final byte separator = '.';
    final int radix = 10;
    final long stopValue = Long.MIN_VALUE / radix;
    long result = 0;

    while (offset < numBytes) {
      b = getByte(offset);
      offset++;
      if (b == separator) {
        // We allow decimals and will return a truncated integral in that case.
        // Therefore we won't throw an exception here (checking the fractional
        // part happens below.)
        break;
      }

      int digit;
      if (b >= '0' && b <= '9') {
        digit = b - '0';
      } else {
        return false;
      }

      // We are going to process the new digit and accumulate the result. However, before doing
      // this, if the result is already smaller than the stopValue(Long.MIN_VALUE / radix), then
      // result * 10 will definitely be smaller than minValue, and we can stop.
      if (result < stopValue) {
        return false;
      }

      result = result * radix - digit;
      // Since the previous result is less than or equal to stopValue(Long.MIN_VALUE / radix), we
      // can just use `result > 0` to check overflow. If result overflows, we should stop.
      if (result > 0) {
        return false;
      }
    }

    // This is the case when we've encountered a decimal separator. The fractional
    // part will not change the number, but we will verify that the fractional part
    // is well formed.
    while (offset < numBytes) {
      byte currentByte = getByte(offset);
      if (currentByte < '0' || currentByte > '9') {
        return false;
      }
      offset++;
    }

    if (!negative) {
      result = -result;
      if (result < 0) {
        return false;
      }
    }

    toLongResult.value = result;
    return true;
  }"
"private void computeMap( String[] from, String[] to, boolean fromIsBad ) {
    // Identity? Build the cheapo non-map
    if( from==to || Arrays.equals(from,to) ) {
      _map = ArrayUtils.seq(0,to.length);
      setDomain(to);
      return;
    }

    // The source Vec does not have a domain, hence is an integer column.  The
    // to[] mapping has the set of unique numbers, we need to map from those
    // numbers to the index to the numbers.
    if( from==null) {
      setDomain(to);
      if( fromIsBad ) { _map = new int[0]; return; }
      int min = Integer.valueOf(to[0]);
      int max = Integer.valueOf(to[to.length-1]);
      Vec mvec = masterVec();
      if( !(mvec.isInt() && mvec.min() >= min && mvec.max() <= max) )
        throw new NumberFormatException(); // Unable to figure out a valid mapping

      // FIXME this is a bit of a hack to allow adapTo calls to play nice with negative ints in the domain...
      if( Integer.valueOf(to[0]) < 0 ) {
        _p=Math.max(0,max);
        _map = new int[(_p /*positive array of values*/) + (-1*min /*negative array of values*/) + 1 /*one more to store ""max"" value*/];
        for(int i=0;i<to.length;++i) {
          int v = Integer.valueOf(to[i]);
          if( v < 0 ) v = -1*v+_p;
          _map[v] = i;
        }
        return;
      }

      _map = new int[max+1];
      for( int i=0; i<to.length; i++ )
        _map[Integer.valueOf(to[i])] = i;
      return;
    }

    // The desired result Vec does not have a domain, hence is a numeric
    // column.  For classification of numbers, we did an original toCategoricalVec
    // wrapping the numeric values up as Strings for the classes.  Unwind that,
    // converting numeric strings back to their original numbers.
    _map = new int[from.length];
    if( to == null ) {
      for( int i=0; i<from.length; i++ )
        _map[i] = Integer.valueOf(from[i]);
      return;
    }
    // Full string-to-string mapping
    HashMap<String,Integer> h = new HashMap<>();
    for( int i=0; i<to.length; i++ ) h.put(to[i],i);
    String[] ss = to;
    int extra = to.length;
    int actualLen = extra;
    for( int j=0; j<from.length; j++ ) {
      Integer x = h.get(from[j]);
      if( x!=null ) _map[j] = x;
      else {
        _map[j] = extra++;
        if (extra > ss.length) {
          ss = Arrays.copyOf(ss, 2*ss.length);
        }
        ss[extra-1] = from[j];
        actualLen = extra;
      }
    }
    setDomain(Arrays.copyOf(ss, actualLen));
  }"
"public Object getValue(Object object) throws IllegalAccessException, InvocationTargetException {
        Object result = null;
        if (getter != null) {
            result = getter.invoke(object);
        } else if (field != null) {
            if(!field.isAccessible()){
                field.setAccessible(true);
            }
            result = field.get(object);
        }
        return result;
    }"
"private ChannelFuture respond(Encodable result) {
    SocketAddress remoteAddress = channel.remoteAddress();
    return channel.writeAndFlush(result).addListener(future -> {
      if (future.isSuccess()) {
        logger.trace(""Sent result {} to client {}"", result, remoteAddress);
      } else {
        logger.error(String.format(""Error sending result %s to %s; closing connection"",
          result, remoteAddress), future.cause());
        channel.close();
      }
    });
  }"
"public static List<Pinyin> convert(String complexText)
    {
        List<Pinyin> pinyinList = new LinkedList<Pinyin>();
        Collection<Token> tokenize = trie.tokenize(complexText);
//        System.out.println(tokenize);
        for (Token token : tokenize)
        {
            String fragment = token.getFragment();
            if (token.isMatch())
            {
                // 是拼音或拼音的一部分，用map转
                pinyinList.add(convertSingle(fragment));
            }
            else
            {
                pinyinList.addAll(PinyinDictionary.convertToPinyin(fragment));
            }
        }

        return pinyinList;
    }"
"public static int varintSizeInBytes(long v) {
    if ((v & (0xffffffffffffffffL << 7)) == 0) return 1;
    if ((v & (0xffffffffffffffffL << 14)) == 0) return 2;
    if ((v & (0xffffffffffffffffL << 21)) == 0) return 3;
    if ((v & (0xffffffffffffffffL << 28)) == 0) return 4;
    if ((v & (0xffffffffffffffffL << 35)) == 0) return 5;
    if ((v & (0xffffffffffffffffL << 42)) == 0) return 6;
    if ((v & (0xffffffffffffffffL << 49)) == 0) return 7;
    if ((v & (0xffffffffffffffffL << 56)) == 0) return 8;
    if ((v & (0xffffffffffffffffL << 63)) == 0) return 9;
    return 10;
  }"
"public static byte[] decode(String source, String charset) {
		return decode(StrUtil.bytes(source, charset));
	}"
"@Override
   public boolean add(T element)
   {
      if (size < elementData.length) {
         elementData[size++] = element;
      }
      else {
         // overflow-conscious code
         final int oldCapacity = elementData.length;
         final int newCapacity = oldCapacity << 1;
         @SuppressWarnings(""unchecked"")
         final T[] newElementData = (T[]) Array.newInstance(clazz, newCapacity);
         System.arraycopy(elementData, 0, newElementData, 0, oldCapacity);
         newElementData[size++] = element;
         elementData = newElementData;
      }

      return true;
   }"
"public <E> void setComboBoxModel(String fieldLabel, ComboBoxModel<E> comboBoxModel) {
		Component c = this.fieldMap.get(fieldLabel);
		if (c instanceof JComboBox) {
			@SuppressWarnings(""unchecked"")
			JComboBox<E> comboBox = (JComboBox<E>) c;
			comboBox.setModel(comboBoxModel);
		} else if (c == null) {
			// Ignore - could be during init
			logger.debug(""No field for "" + fieldLabel);
		} else {
			handleUnexpectedFieldClass(fieldLabel, c);
		}
	}"
"@Override
    public <T> EventPoller<T> newPoller(DataProvider<T> dataProvider, Sequence... gatingSequences)
    {
        return EventPoller.newInstance(dataProvider, this, new Sequence(), cursor, gatingSequences);
    }"
"public Map<String, INDArray> feedForward(boolean train) {
        try {
            return ffToLayerActivationsDetached(train, FwdPassType.STANDARD, false, vertices.length - 1,
                    null, inputs, inputMaskArrays, labelMaskArrays, true);
        } catch (OutOfMemoryError e){
            CrashReportingUtil.writeMemoryCrashDump(this, e);
            throw e;
        }
    }"
"public MultinomialModelPrediction predictMultinomial(RowData data, double offset) throws PredictException {
    double[] preds = preamble(ModelCategory.Multinomial, data, offset);

    MultinomialModelPrediction p = new MultinomialModelPrediction();
    if (enableLeafAssignment) { // only get leaf node assignment if enabled
      SharedTreeMojoModel.LeafNodeAssignments assignments = leafNodeAssignmentExtended(data);
      p.leafNodeAssignments = assignments._paths;
      p.leafNodeAssignmentIds = assignments._nodeIds;
    }
    p.classProbabilities = new double[m.getNumResponseClasses()];
    p.labelIndex = (int) preds[0];
    String[] domainValues = m.getDomainValues(m.getResponseIdx());
    p.label = domainValues[p.labelIndex];
    System.arraycopy(preds, 1, p.classProbabilities, 0, p.classProbabilities.length);
    if (enableStagedProbabilities) {
        double[] rawData = nanArray(m.nfeatures());
        rawData = fillRawData(data, rawData);
        p.stageProbabilities = ((SharedTreeMojoModel) m).scoreStagedPredictions(rawData, preds.length);
    }
    return p;
  }"
"@Override
	public void createPartition(ObjectPath tablePath, CatalogPartitionSpec partitionSpec, CatalogPartition partition, boolean ignoreIfExists)
			throws TableNotExistException, TableNotPartitionedException, PartitionSpecInvalidException, PartitionAlreadyExistsException, CatalogException {
		throw new UnsupportedOperationException();
	}"
"public StaticResourceServerWebExchange at(Set<StaticResourceLocation> locations) {
		Assert.notNull(locations, ""Locations must not be null"");
		return new StaticResourceServerWebExchange(new LinkedHashSet<>(locations));
	}"
"protected void destroyApplicationSession(final HttpServletRequest request, final HttpServletResponse response) {
        LOGGER.trace(""Destroying application session"");
        val context = new J2EContext(request, response, new J2ESessionStore());
        val manager = new ProfileManager<>(context, context.getSessionStore());
        manager.logout();

        val session = request.getSession(false);
        if (session != null) {
            val requestedUrl = session.getAttribute(Pac4jConstants.REQUESTED_URL);
            session.invalidate();
            if (requestedUrl != null && !requestedUrl.equals(StringUtils.EMPTY)) {
                request.getSession(true).setAttribute(Pac4jConstants.REQUESTED_URL, requestedUrl);
            }
        }
    }"
"public void sort(final IndexedSortable s, int p, int r) {
		int recordsPerSegment = s.recordsPerSegment();
		int recordSize = s.recordSize();
		int maxOffset = recordSize * (recordsPerSegment - 1);

		int pN = p / recordsPerSegment;
		int pO = (p % recordsPerSegment) * recordSize;

		int rN = r / recordsPerSegment;
		int rO = (r % recordsPerSegment) * recordSize;

		sortInternal(s, recordsPerSegment, recordSize, maxOffset, p, pN, pO, r, rN, rO, getMaxDepth(r - p));
	}"
"public void update(List<UninstallationProgressEvent> events) {
        if (!isVisible()) {
            if ((System.currentTimeMillis() - startTime) >= MS_TO_WAIT_BEFORE_SHOW) {
                if (!done && !setVisibleInvoked) {
                    setVisibleInvoked = true;
                    EventQueue.invokeLater(new Runnable() {

                        @Override
                        public void run() {
                            if (!done) {
                                UninstallationProgressDialogue.super.setVisible(true);
                            }
                        }
                    });
                }
            }
        }

        int totalAmount = 0;
        AddOn addOn = null;

        for (UninstallationProgressEvent event : events) {
            totalAmount += event.getAmount();
            if (UninstallationProgressEvent.Type.FINISHED_ADD_ON == event.getType()) {
                for (AddOnUninstallListener listener : listeners) {
                    failedUninstallations = !event.isUninstalled();
                    listener.addOnUninstalled(currentAddOn, update, event.isUninstalled());
                }
            } else if (UninstallationProgressEvent.Type.ADD_ON == event.getType()) {
                addOn = event.getAddOn();
                currentAddOn = addOn;
                update = event.isUpdate();

                for (AddOnUninstallListener listener : listeners) {
                    listener.uninstallingAddOn(addOn, update);
                }
            }
        }

        UninstallationProgressEvent last = events.get(events.size() - 1);

        if (addOn != null) {
            setCurrentAddOn(addOn);
        }

        if (totalAmount != 0) {
            incrementProgress(totalAmount);
        }

        if (currentType != last.getType()) {
            String keyMessage;
            switch (last.getType()) {
            case FILE:
                keyMessage = ""cfu.uninstallation.progress.dialogue.uninstallingFile"";
                break;
            case ACTIVE_RULE:
                keyMessage = ""cfu.uninstallation.progress.dialogue.uninstallingActiveScanner"";
                break;
            case PASSIVE_RULE:
                keyMessage = ""cfu.uninstallation.progress.dialogue.uninstallingPassiveScanner"";
                break;
            case EXTENSION:
                keyMessage = ""cfu.uninstallation.progress.dialogue.uninstallingExtension"";
                break;
            default:
                keyMessage = """";
                break;
            }
            currentType = last.getType();
            keyBaseStatusMessage = keyMessage;
        }

        if (keyBaseStatusMessage.isEmpty()) {
            setCustomMessage("""");
        } else {
            setCustomMessage(
                    Constant.messages
                            .getString(keyBaseStatusMessage, last.getValue(), last.getMax()));
        }
    }"
"public static int totalPage(int totalCount, int pageSize) {
		if (pageSize == 0) {
			return 0;
		}
		return totalCount % pageSize == 0 ? (totalCount / pageSize) : (totalCount / pageSize + 1);
	}"
"public void setControl(Node control) {
        if (control != null) {
            this.control = control;
            this.badge = new Group();
            this.getChildren().add(control);
            this.getChildren().add(badge);

            // if the control got resized the badge must be rest
            if (control instanceof Region) {
                ((Region) control).widthProperty().addListener((o, oldVal, newVal) -> refreshBadge());
                ((Region) control).heightProperty().addListener((o, oldVal, newVal) -> refreshBadge());
            }
            text.addListener((o, oldVal, newVal) -> refreshBadge());
        }
    }"
"public static String replaceFirst(final String text, final Pattern regex, final String replacement) {
        if (text == null || regex == null|| replacement == null ) {
            return text;
        }
        return regex.matcher(text).replaceFirst(replacement);
    }"
"public int size() {
		int ret = anyMethodRouter.size();

		for (MethodlessRouter<T> router : routers.values()) {
			ret += router.size();
		}

		return ret;
	}"
"public ConnectedStreams<IN1, IN2> keyBy(int[] keyPositions1, int[] keyPositions2) {
		return new ConnectedStreams<>(environment, inputStream1.keyBy(keyPositions1),
				inputStream2.keyBy(keyPositions2));
	}"
"static SSLHandshakeException toSSLHandshakeException(Throwable e) {
        if (e instanceof SSLHandshakeException) {
            return (SSLHandshakeException) e;
        }

        return (SSLHandshakeException) new SSLHandshakeException(e.getMessage()).initCause(e);
    }"
"private SegmentIdWithShardSpec getSegment(
      final InputRow row,
      final String sequenceName,
      final boolean skipSegmentLineageCheck
  ) throws IOException
  {
    synchronized (segments) {
      final DateTime timestamp = row.getTimestamp();
      final SegmentIdWithShardSpec existing = getAppendableSegment(timestamp, sequenceName);
      if (existing != null) {
        return existing;
      } else {
        // Allocate new segment.
        final SegmentsForSequence segmentsForSequence = segments.get(sequenceName);
        final SegmentIdWithShardSpec newSegment = segmentAllocator.allocate(
            row,
            sequenceName,
            segmentsForSequence == null ? null : segmentsForSequence.lastSegmentId,
            // send lastSegmentId irrespective of skipSegmentLineageCheck so that
            // unique constraint for sequence_name_prev_id_sha1 does not fail for
            // allocatePendingSegment in IndexerSQLMetadataStorageCoordinator
            skipSegmentLineageCheck
        );

        if (newSegment != null) {
          for (SegmentIdWithShardSpec identifier : appenderator.getSegments()) {
            if (identifier.equals(newSegment)) {
              throw new ISE(
                  ""WTF?! Allocated segment[%s] which conflicts with existing segment[%s]."",
                  newSegment,
                  identifier
              );
            }
          }

          log.info(""New segment[%s] for row[%s] sequenceName[%s]."", newSegment, row, sequenceName);
          addSegment(sequenceName, newSegment);
        } else {
          // Well, we tried.
          log.warn(""Cannot allocate segment for timestamp[%s], sequenceName[%s]. "", timestamp, sequenceName);
        }

        return newSegment;
      }
    }
  }"
"public SDVariable avgPooling2d(SDVariable input, Pooling2DConfig pooling2DConfig) {
        AvgPooling2D avgPooling2D = AvgPooling2D.builder()
                .input(input)
                .sameDiff(sameDiff())
                .config(pooling2DConfig)
                .build();

        return avgPooling2D.outputVariable();
    }"
"public static byte[] strToBcd(String asc) {
		int len = asc.length();
		int mod = len % 2;
		if (mod != 0) {
			asc = ""0"" + asc;
			len = asc.length();
		}
		byte abt[] = new byte[len];
		if (len >= 2) {
			len >>= 1;
		}
		byte bbt[] = new byte[len];
		abt = asc.getBytes();
		int j;
		int k;
		for (int p = 0; p < asc.length() / 2; p++) {
			if ((abt[2 * p] >= '0') && (abt[2 * p] <= '9')) {
				j = abt[2 * p] - '0';
			} else if ((abt[2 * p] >= 'a') && (abt[2 * p] <= 'z')) {
				j = abt[2 * p] - 'a' + 0x0a;
			} else {
				j = abt[2 * p] - 'A' + 0x0a;
			}
			if ((abt[2 * p + 1] >= '0') && (abt[2 * p + 1] <= '9')) {
				k = abt[2 * p + 1] - '0';
			} else if ((abt[2 * p + 1] >= 'a') && (abt[2 * p + 1] <= 'z')) {
				k = abt[2 * p + 1] - 'a' + 0x0a;
			} else {
				k = abt[2 * p + 1] - 'A' + 0x0a;
			}
			int a = (j << 4) + k;
			byte b = (byte) a;
			bbt[p] = b;
		}
		return bbt;
	}"
"@Override
    public boolean hasMoreTokens() {
        log.info(""Tokens size: ["" + tokens.size() + ""], position: ["" + position.get() + ""]"");
        if (!tokens.isEmpty())
            return position.get() < tokens.size();
        else
            return streamHasMoreTokens();
    }"
"public static FlinkJoinType getFlinkJoinType(Join join) {
		if (join instanceof SemiJoin) {
			// TODO supports ANTI
			return FlinkJoinType.SEMI;
		} else {
			return toFlinkJoinType(join.getJoinType());
		}
	}"
"private boolean hasSameHost(URI uri) {
        try {
            return host.equals(normalisedHost(uri));
        } catch (URIException e) {
            LOGGER.warn(""Failed to normalise host: "" + Arrays.toString(uri.getRawHost()), e);
        }
        return false;
    }"
"@Override
    public void applyUpdater(INDArray gradient, int iteration, int epoch) {
        if (v == null)
            throw new IllegalStateException(""Updater has not been initialized with view state"");

        double momentum = config.currentMomentum(iteration, epoch);
        double learningRate = config.getLearningRate(iteration, epoch);

        //reference https://cs231n.github.io/neural-networks-3/#sgd 2nd equation
        //DL4J default is negative step function thus we flipped the signs:
        // x += mu * v_prev + (-1 - mu) * v
        //i.e., we do params -= updatedGradient, not params += updatedGradient

        //v = mu * v - lr * gradient
        INDArray vPrev = v.dup(gradientReshapeOrder);
        v.muli(momentum).subi(gradient.dup(gradientReshapeOrder).muli(learningRate)); //Modify state array in-place

        /*
        Next line is equivalent to:
        INDArray ret = vPrev.muli(momentum).addi(v.mul(-momentum - 1));
        gradient.assign(ret);
        */
        Nd4j.getExecutioner().exec(new OldAddOp(vPrev.muli(momentum), v.mul(-momentum - 1), gradient));
    }"
"public static <T extends Collection<String>> T readLines(Reader reader, final T collection) throws IORuntimeException {
		readLines(reader, new LineHandler() {
			@Override
			public void handle(String line) {
				collection.add(line);
			}
		});
		return collection;
	}"
"public static Color getColor(String colorName) {
		if (StrUtil.isBlank(colorName)) {
			return null;
		}
		colorName = colorName.toUpperCase();

		if (""BLACK"".equals(colorName)) {
			return Color.BLACK;
		} else if (""WHITE"".equals(colorName)) {
			return Color.WHITE;
		} else if (""LIGHTGRAY"".equals(colorName) || ""LIGHT_GRAY"".equals(colorName)) {
			return Color.LIGHT_GRAY;
		} else if (""GRAY"".equals(colorName)) {
			return Color.GRAY;
		} else if (""DARK_GRAY"".equals(colorName) || ""DARK_GRAY"".equals(colorName)) {
			return Color.DARK_GRAY;
		} else if (""RED"".equals(colorName)) {
			return Color.RED;
		} else if (""PINK"".equals(colorName)) {
			return Color.PINK;
		} else if (""ORANGE"".equals(colorName)) {
			return Color.ORANGE;
		} else if (""YELLOW"".equals(colorName)) {
			return Color.YELLOW;
		} else if (""GREEN"".equals(colorName)) {
			return Color.GREEN;
		} else if (""MAGENTA"".equals(colorName)) {
			return Color.MAGENTA;
		} else if (""CYAN"".equals(colorName)) {
			return Color.CYAN;
		} else if (""BLUE"".equals(colorName)) {
			return Color.BLUE;
		} else if (""DARKGOLD"".equals(colorName)) {
			// 暗金色
			return hexToColor(""#9e7e67"");
		} else if (""LIGHTGOLD"".equals(colorName)) {
			// 亮金色
			return hexToColor(""#ac9c85"");
		} else if (StrUtil.startWith(colorName, '#')) {
			return hexToColor(colorName);
		} else if (StrUtil.startWith(colorName, '$')) {
			// 由于#在URL传输中无法传输，因此用$代替#
			return hexToColor(""#"" + colorName.substring(1));
		} else {
			// rgb值
			final List<String> rgb = StrUtil.split(colorName, ',');
			if (3 == rgb.size()) {
				final Integer r = Convert.toInt(rgb.get(0));
				final Integer g = Convert.toInt(rgb.get(1));
				final Integer b = Convert.toInt(rgb.get(2));
				if (false == ArrayUtil.hasNull(r, g, b)) {
					return new Color(r, g, b);
				}
			} else {
				return null;
			}
		}
		return null;
	}"
"public static void rightClick() {
		robot.mousePress(InputEvent.BUTTON1_MASK);
		robot.mouseRelease(InputEvent.BUTTON1_MASK);
		delay();
	}"
"public void setDetail(String description, String uri, String param, String attack, String otherInfo, 
			String solution, String reference, String evidence, int cweId, int wascId, HttpMessage msg) {
		setDescription(description);
		setUri(uri);
		setParam(param);
		setAttack(attack);
		setOtherInfo(otherInfo);
		setSolution(solution);
		setReference(reference);
		setMessage(msg);
		setEvidence(evidence);
		setCweId(cweId);
		setWascId(wascId);
		if (msg != null) {
			setHistoryRef(msg.getHistoryRef());
		}
	}"
"private DataSegment mergeAndPush(final SegmentIdWithShardSpec identifier, final Sink sink, final boolean useUniquePath)
  {
    // Bail out if this sink is null or otherwise not what we expect.
    if (sinks.get(identifier) != sink) {
      log.warn(""Sink for segment[%s] no longer valid, bailing out of mergeAndPush."", identifier);
      return null;
    }

    // Use a descriptor file to indicate that pushing has completed.
    final File persistDir = computePersistDir(identifier);
    final File mergedTarget = new File(persistDir, ""merged"");
    final File descriptorFile = computeDescriptorFile(identifier);

    // Sanity checks
    for (FireHydrant hydrant : sink) {
      if (sink.isWritable()) {
        throw new ISE(""WTF?! Expected sink to be no longer writable before mergeAndPush. Segment[%s]."", identifier);
      }

      synchronized (hydrant) {
        if (!hydrant.hasSwapped()) {
          throw new ISE(""WTF?! Expected sink to be fully persisted before mergeAndPush. Segment[%s]."", identifier);
        }
      }
    }

    try {
      if (descriptorFile.exists()) {
        // Already pushed.

        if (useUniquePath) {
          // Don't reuse the descriptor, because the caller asked for a unique path. Leave the old one as-is, since
          // it might serve some unknown purpose.
          log.info(""Pushing segment[%s] again with new unique path."", identifier);
        } else {
          log.info(""Segment[%s] already pushed."", identifier);
          return objectMapper.readValue(descriptorFile, DataSegment.class);
        }
      }

      log.info(""Pushing merged index for segment[%s]."", identifier);

      removeDirectory(mergedTarget);

      if (mergedTarget.exists()) {
        throw new ISE(""Merged target[%s] exists after removing?!"", mergedTarget);
      }

      final File mergedFile;
      List<QueryableIndex> indexes = new ArrayList<>();
      Closer closer = Closer.create();
      try {
        for (FireHydrant fireHydrant : sink) {
          Pair<Segment, Closeable> segmentAndCloseable = fireHydrant.getAndIncrementSegment();
          final QueryableIndex queryableIndex = segmentAndCloseable.lhs.asQueryableIndex();
          log.info(""Adding hydrant[%s]"", fireHydrant);
          indexes.add(queryableIndex);
          closer.register(segmentAndCloseable.rhs);
        }

        mergedFile = indexMerger.mergeQueryableIndex(
            indexes,
            schema.getGranularitySpec().isRollup(),
            schema.getAggregators(),
            mergedTarget,
            tuningConfig.getIndexSpec(),
            tuningConfig.getSegmentWriteOutMediumFactory()
        );
      }
      catch (Throwable t) {
        throw closer.rethrow(t);
      }
      finally {
        closer.close();
      }

      // Retry pushing segments because uploading to deep storage might fail especially for cloud storage types
      final DataSegment segment = RetryUtils.retry(
          // The appenderator is currently being used for the local indexing task and the Kafka indexing task. For the
          // Kafka indexing task, pushers must use unique file paths in deep storage in order to maintain exactly-once
          // semantics.
          () -> dataSegmentPusher.push(
              mergedFile,
              sink.getSegment().withDimensions(IndexMerger.getMergedDimensionsFromQueryableIndexes(indexes)),
              useUniquePath
          ),
          exception -> exception instanceof Exception,
          5
      );

      objectMapper.writeValue(descriptorFile, segment);

      log.info(""Pushed merged index for segment[%s], descriptor is: %s"", identifier, segment);

      return segment;
    }
    catch (Exception e) {
      metrics.incrementFailedHandoffs();
      log.warn(e, ""Failed to push merged index for segment[%s]."", identifier);
      throw new RuntimeException(e);
    }
  }"
"protected SqlBuilder wrapPageSql(SqlBuilder find, Page page) {
		// limit A offset B 表示：A就是你需要多少行，B就是查询的起点位置。
		return find.append("" limit "").append(page.getPageSize()).append("" offset "").append(page.getStartPosition());
	}"
"@SuppressWarnings(""unchecked"")
    public static <T> T touch(T msg, Object hint) {
        if (msg instanceof ReferenceCounted) {
            return (T) ((ReferenceCounted) msg).touch(hint);
        }
        return msg;
    }"
"public int indexOf(char ch, int start) {
        if (ch > MAX_CHAR_VALUE) {
            return INDEX_NOT_FOUND;
        }

        if (start < 0) {
            start = 0;
        }

        final byte chAsByte = c2b0(ch);
        final int len = offset + length;
        for (int i = start + offset; i < len; ++i) {
            if (value[i] == chAsByte) {
                return i - offset;
            }
        }
        return INDEX_NOT_FOUND;
    }"
"public String nextString(char quote) throws JSONException {
		/*
		 * For strings that are free of escape sequences, we can just extract the result
		 * as a substring of the input. But if we encounter an escape sequence, we need to
		 * use a StringBuilder to compose the result.
		 */
		StringBuilder builder = null;

		/* the index of the first character not yet appended to the builder. */
		int start = this.pos;

		while (this.pos < this.in.length()) {
			int c = this.in.charAt(this.pos++);
			if (c == quote) {
				if (builder == null) {
					// a new string avoids leaking memory
					return new String(this.in.substring(start, this.pos - 1));
				}
				else {
					builder.append(this.in, start, this.pos - 1);
					return builder.toString();
				}
			}

			if (c == '\\') {
				if (this.pos == this.in.length()) {
					throw syntaxError(""Unterminated escape sequence"");
				}
				if (builder == null) {
					builder = new StringBuilder();
				}
				builder.append(this.in, start, this.pos - 1);
				builder.append(readEscapeCharacter());
				start = this.pos;
			}
		}

		throw syntaxError(""Unterminated string"");
	}"
"protected static List<CoreDictionary.Attribute> combineWithCustomDictionary(List<String> vertexList)
    {
        String[] wordNet = new String[vertexList.size()];
        vertexList.toArray(wordNet);
        CoreDictionary.Attribute[] attributeArray = new CoreDictionary.Attribute[wordNet.length];
        // DAT合并
        DoubleArrayTrie<CoreDictionary.Attribute> dat = CustomDictionary.dat;
        int length = wordNet.length;
        for (int i = 0; i < length; ++i)
        {
            int state = 1;
            state = dat.transition(wordNet[i], state);
            if (state > 0)
            {
                int to = i + 1;
                int end = to;
                CoreDictionary.Attribute value = dat.output(state);
                for (; to < length; ++to)
                {
                    state = dat.transition(wordNet[to], state);
                    if (state < 0) break;
                    CoreDictionary.Attribute output = dat.output(state);
                    if (output != null)
                    {
                        value = output;
                        end = to + 1;
                    }
                }
                if (value != null)
                {
                    combineWords(wordNet, i, end, attributeArray, value);
                    i = end - 1;
                }
            }
        }
        // BinTrie合并
        if (CustomDictionary.trie != null)
        {
            for (int i = 0; i < length; ++i)
            {
                if (wordNet[i] == null) continue;
                BaseNode<CoreDictionary.Attribute> state = CustomDictionary.trie.transition(wordNet[i], 0);
                if (state != null)
                {
                    int to = i + 1;
                    int end = to;
                    CoreDictionary.Attribute value = state.getValue();
                    for (; to < length; ++to)
                    {
                        if (wordNet[to] == null) continue;
                        state = state.transition(wordNet[to], 0);
                        if (state == null) break;
                        if (state.getValue() != null)
                        {
                            value = state.getValue();
                            end = to + 1;
                        }
                    }
                    if (value != null)
                    {
                        combineWords(wordNet, i, end, attributeArray, value);
                        i = end - 1;
                    }
                }
            }
        }
        vertexList.clear();
        List<CoreDictionary.Attribute> attributeList = new LinkedList<CoreDictionary.Attribute>();
        for (int i = 0; i < wordNet.length; i++)
        {
            if (wordNet[i] != null)
            {
                vertexList.add(wordNet[i]);
                attributeList.add(attributeArray[i]);
            }
        }
        return attributeList;
    }"
"public static JsonParser getJsonParser() {
		if (ClassUtils.isPresent(""com.fasterxml.jackson.databind.ObjectMapper"", null)) {
			return new JacksonJsonParser();
		}
		if (ClassUtils.isPresent(""com.google.gson.Gson"", null)) {
			return new GsonJsonParser();
		}
		if (ClassUtils.isPresent(""org.yaml.snakeyaml.Yaml"", null)) {
			return new YamlJsonParser();
		}
		return new BasicJsonParser();
	}"
"public @CheckForNull PropertyType getPropertyType(@Nonnull Object instance, @Nonnull String field) {
        // in global.jelly, instance==descriptor
        return instance==this ? getGlobalPropertyType(field) : getPropertyType(field);
    }"
"@DELETE
  @Deprecated
  @Path(""/{dataSourceName}"")
  @ResourceFilters(DatasourceResourceFilter.class)
  @Produces(MediaType.APPLICATION_JSON)
  public Response deleteDataSource(
      @PathParam(""dataSourceName"") final String dataSourceName,
      @QueryParam(""kill"") final String kill,
      @QueryParam(""interval"") final String interval
  )
  {
    if (indexingServiceClient == null) {
      return Response.ok(ImmutableMap.of(""error"", ""no indexing service found"")).build();
    }

    if (kill != null && Boolean.valueOf(kill)) {
      try {
        indexingServiceClient.killSegments(dataSourceName, Intervals.of(interval));
      }
      catch (IllegalArgumentException e) {
        return Response.status(Response.Status.BAD_REQUEST)
                       .entity(
                           ImmutableMap.of(
                               ""error"",
                               ""Exception occurred. Probably the interval is invalid"",
                               ""message"",
                               e.toString()
                           )
                       )
                       .build();
      }
      catch (Exception e) {
        return Response.serverError().entity(
            ImmutableMap.of(
                ""error"",
                ""Exception occurred. Are you sure you have an indexing service?"",
                ""message"",
                e.toString()
            )
        )
                       .build();
      }
    } else {
      if (!databaseSegmentManager.removeDataSource(dataSourceName)) {
        return Response.noContent().build();
      }
    }

    return Response.ok().build();
  }"
"public static BigDecimal div(String v1, String v2, int scale) {
		return div(v1, v2, scale, RoundingMode.HALF_UP);
	}"
"public static double subtract(double minuend, double reduction, int scale) {
        BigDecimal minuendBd = new BigDecimal(Double.toString(minuend));
        BigDecimal reductionBd = new BigDecimal(Double.toString(reduction));
        MathContext mathContext = new MathContext(scale, RoundingMode.HALF_UP);
        return minuendBd.subtract(reductionBd, mathContext).doubleValue();
    }"
"protected DataStream<T> setConnectionType(StreamPartitioner<T> partitioner) {
		return new DataStream<>(this.getExecutionEnvironment(), new PartitionTransformation<>(this.getTransformation(), partitioner));
	}"
"public static int getIntegerValue(String appName, String key, int defaultValue) {
        String ret = getStringValue0(appName, key);
        return StringUtils.isEmpty(ret) ? defaultValue : CommonUtils.parseInt(ret, defaultValue);
    }"
"public static List<List<List<Writable>>> toArrowWritablesTimeSeries(List<FieldVector> fieldVectors,Schema schema,int timeSeriesLength) {
        ArrowWritableRecordTimeSeriesBatch arrowWritableRecordBatch = new ArrowWritableRecordTimeSeriesBatch(fieldVectors,schema,timeSeriesLength);
        return arrowWritableRecordBatch;
    }"
"public boolean replace( Long key, TypeV oldValue, TypeV newValue ) {
    return replace(key.longValue(), oldValue, newValue);
  }"
"private String getSparkHome(final String sparkVersion) {
    String sparkHome = getSysProps().get(""spark."" + sparkVersion + "".home"");
    if (sparkHome == null) {
      info(""Couldn't find spark."" + sparkVersion + "".home property."");
      final String sparkDir = getSysProps().get(SPARK_BASE_DIR);
      final String sparkHomePrefix =
          getSysProps().get(SPARK_HOME_PREFIX) != null ? getSysProps().get(SPARK_HOME_PREFIX) : ""*"";
      final String replaceTo = getSysProps().get(SPARK_VERSION_REGEX_TO_REPLACE);
      final String replaceWith =
          getSysProps().get(SPARK_VERSION_REGEX_TO_REPLACE_WITH) != null ? getSysProps()
              .get(SPARK_VERSION_REGEX_TO_REPLACE_WITH) : """";
      final String versionPatterToMatch =
          sparkHomePrefix + (replaceTo != null ? sparkVersion
              .replace(replaceTo, replaceWith) : sparkVersion) + ""*"";
      info(""Looking for spark at  "" + sparkDir + "" directory with "" + sparkHomePrefix
          + "" prefix for "" + sparkVersion
          + "" version."");
      final DirectoryScanner scanner = new DirectoryScanner();
      scanner.setBasedir(sparkDir);
      scanner.setIncludes(new String[]{versionPatterToMatch});
      scanner.scan();
      final String[] directories = scanner.getIncludedDirectories();
      if (directories != null && directories.length > 0) {
        sparkHome = sparkDir + ""/"" + directories[directories.length - 1];
      } else {
        final String sparkReferenceDoc = getSysProps().get(SPARK_REFERENCE_DOCUMENT);
        final String exceptionMessage =
            sparkReferenceDoc == null ? ""SPARK version specified by User is not available.""
                : ""SPARK version specified by User is not available. Available versions are mentioned at: ""
                    + sparkReferenceDoc;
        throw new RuntimeException(exceptionMessage);
      }
    }
    return sparkHome;
  }"
"public static void setBoolean(MemorySegment[] segments, int offset, boolean value) {
		if (inFirstSegment(segments, offset, 1)) {
			segments[0].putBoolean(offset, value);
		} else {
			setBooleanMultiSegments(segments, offset, value);
		}
	}"
"public void setAnimation(JsonReader reader, @Nullable String cacheKey) {
    setCompositionTask(LottieCompositionFactory.fromJsonReader(reader, cacheKey));
  }"
"@Override
  @TearDown(Level.Trial)
  public void teardown() throws Exception {
    completed.set(true);
    if (!latch.await(5, TimeUnit.SECONDS)) {
      System.err.println(""Failed to shutdown all calls."");
    }
    super.teardown();
  }"
"protected void redirectUser(UserRedirectRequiredException e,
			HttpServletRequest request, HttpServletResponse response)
			throws IOException {

		String redirectUri = e.getRedirectUri();
		UriComponentsBuilder builder = UriComponentsBuilder
				.fromHttpUrl(redirectUri);
		Map<String, String> requestParams = e.getRequestParams();
		for (Map.Entry<String, String> param : requestParams.entrySet()) {
			builder.queryParam(param.getKey(), param.getValue());
		}

		if (e.getStateKey() != null) {
			builder.queryParam(""state"", e.getStateKey());
		}

		this.redirectStrategy.sendRedirect(request, response, builder.build()
				.encode().toUriString());
	}"
"public static String getConfigurationDirectoryFromEnv() {
		String location = System.getenv(ConfigConstants.ENV_FLINK_CONF_DIR);

		if (location != null) {
			if (new File(location).exists()) {
				return location;
			}
			else {
				throw new RuntimeException(""The configuration directory '"" + location + ""', specified in the '"" +
					ConfigConstants.ENV_FLINK_CONF_DIR + ""' environment variable, does not exist."");
			}
		}
		else if (new File(CONFIG_DIRECTORY_FALLBACK_1).exists()) {
			location = CONFIG_DIRECTORY_FALLBACK_1;
		}
		else if (new File(CONFIG_DIRECTORY_FALLBACK_2).exists()) {
			location = CONFIG_DIRECTORY_FALLBACK_2;
		}
		else {
			throw new RuntimeException(""The configuration directory was not specified. "" +
					""Please specify the directory containing the configuration file through the '"" +
				ConfigConstants.ENV_FLINK_CONF_DIR + ""' environment variable."");
		}
		return location;
	}"
"@SuppressWarnings(""unchecked"")
    public static List<String> findSchemas(JdbcTemplate jdbcTemplate, final String schemaPattern) {
        try {
            if (StringUtils.isEmpty(schemaPattern)) {
                return jdbcTemplate.query(""show databases"", new SingleColumnRowMapper(String.class));
            }
            return jdbcTemplate.query(""show databases like ?"",
                new Object[] { schemaPattern },
                new SingleColumnRowMapper(String.class));
        } catch (Exception e) {
            logger.error(e.getMessage(), e);
            return new ArrayList<String>();
        }
    }"
"public static <T extends CharSequence> T validateUrl(T value, String errorMsg) throws ValidateException {
		if (false == isUrl(value)) {
			throw new ValidateException(errorMsg);
		}
		return value;
	}"
"public static <T> CompletableFuture<T> orTimeout(
		CompletableFuture<T> future,
		long timeout,
		TimeUnit timeUnit,
		Executor timeoutFailExecutor) {

		if (!future.isDone()) {
			final ScheduledFuture<?> timeoutFuture = Delayer.delay(
				() -> timeoutFailExecutor.execute(new Timeout(future)), timeout, timeUnit);

			future.whenComplete((T value, Throwable throwable) -> {
				if (!timeoutFuture.isDone()) {
					timeoutFuture.cancel(false);
				}
			});
		}

		return future;
	}"
"@Exported(name=""property"",inline=true)
    public List<JobProperty<? super JobT>> getAllProperties() {
        return properties.getView();
    }"
"private static boolean statisticsObjectCheck(final ExecutorInfo statisticsObj1,
      final ExecutorInfo statisticsObj2, final String caller) {
    // both doesn't expose the info
    if (null == statisticsObj1 && null == statisticsObj2) {
      logger.debug(String.format(""%s : neither of the executors exposed statistics info."",
          caller));
      return true;
    }

    //right side doesn't expose the info.
    if (null == statisticsObj2) {
      logger.debug(String.format(
          ""%s : choosing left side and the right side executor doesn't expose statistics info"",
          caller));
      return true;
    }

    //left side doesn't expose the info.
    if (null == statisticsObj1) {
      logger.debug(String.format(
          ""%s : choosing right side and the left side executor doesn't expose statistics info"",
          caller));
      return true;
    }

    // both not null
    return false;
  }"
"public static String blobToStr(Blob blob, Charset charset) {
		InputStream in = null;
		try {
			in = blob.getBinaryStream();
			return IoUtil.read(in, charset);
		} catch (SQLException e) {
			throw new DbRuntimeException(e);
		} finally {
			IoUtil.close(in);
		}
	}"
"public Event buildAuthenticationRequestEvent(final RequestContext context) {
        val clients = new ArrayList<WsFedClient>();
        val request = WebUtils.getHttpServletRequestFromExternalWebflowContext(context);
        val service = (Service) context.getFlowScope().get(CasProtocolConstants.PARAMETER_SERVICE);
        this.configurations.forEach(cfg -> {
            val c = new WsFedClient();
            c.setName(cfg.getName());
            val id = UUID.randomUUID().toString();
            val rpId = wsFederationHelper.getRelyingPartyIdentifier(service, cfg);
            c.setAuthorizationUrl(cfg.getAuthorizationUrl(rpId, id));
            c.setReplyingPartyId(rpId);
            c.setId(id);
            c.setRedirectUrl(getRelativeRedirectUrlFor(cfg, service, request));
            c.setAutoRedirect(cfg.isAutoRedirect());
            clients.add(c);

            if (cfg.isAutoRedirect()) {
                WebUtils.putDelegatedAuthenticationProviderPrimary(context, cfg);
            }
        });
        context.getFlowScope().put(PARAMETER_NAME_WSFED_CLIENTS, clients);
        return new EventFactorySupport().event(this, CasWebflowConstants.TRANSITION_ID_PROCEED);
    }"
"public static HystrixThreadPoolProperties getThreadPoolProperties(HystrixThreadPoolKey key, HystrixThreadPoolProperties.Setter builder) {
        HystrixPropertiesStrategy hystrixPropertiesStrategy = HystrixPlugins.getInstance().getPropertiesStrategy();
        String cacheKey = hystrixPropertiesStrategy.getThreadPoolPropertiesCacheKey(key, builder);
        if (cacheKey != null) {
            HystrixThreadPoolProperties properties = threadPoolProperties.get(cacheKey);
            if (properties != null) {
                return properties;
            } else {
                if (builder == null) {
                    builder = HystrixThreadPoolProperties.Setter();
                }
                // create new instance
                properties = hystrixPropertiesStrategy.getThreadPoolProperties(key, builder);
                // cache and return
                HystrixThreadPoolProperties existing = threadPoolProperties.putIfAbsent(cacheKey, properties);
                if (existing == null) {
                    return properties;
                } else {
                    return existing;
                }
            }
        } else {
            // no cacheKey so we generate it with caching
            return hystrixPropertiesStrategy.getThreadPoolProperties(key, builder);
        }
    }"
"@Override
  public MutableCapabilities merge(Capabilities extraCapabilities) {
    if (extraCapabilities == null) {
      return this;
    }

    extraCapabilities.asMap().forEach(this::setCapability);

    return this;
  }"
"public static String getScriptName(String name) {
        if (name == null) {
            return null;
        }

        if (name.endsWith("".groovy"")) {
            name = name.substring(0, name.length() - 7);
        }
        return getNaturalName(name).replaceAll(""\\s"", ""-"").toLowerCase();
    }"
"public static SuggestedItem build(SearchableModelObject searchContext, SearchItem si) {
        if (si instanceof Item) {
            return build(searchContext, (Item)si);
        }
        return new SuggestedItem(si);
    }"
"public static CellStyle createHeadCellStyle(Workbook workbook) {
		final CellStyle cellStyle = workbook.createCellStyle();
		setAlign(cellStyle, HorizontalAlignment.CENTER, VerticalAlignment.CENTER);
		setBorder(cellStyle, BorderStyle.THIN, IndexedColors.BLACK);
		setColor(cellStyle, IndexedColors.GREY_25_PERCENT, FillPatternType.SOLID_FOREGROUND);
		return cellStyle;
	}"
"public SDVariable or(String name, SDVariable x, SDVariable y) {
        validateBool(""or"", x, y);
        SDVariable result = f().or(x, y);
        return updateVariableNameAndReference(result, name);
    }"
"public static <T> HashSet<T> newHashSet(boolean isSorted, Enumeration<T> enumration) {
		if (null == enumration) {
			return newHashSet(isSorted, (T[]) null);
		}
		final HashSet<T> set = isSorted ? new LinkedHashSet<T>() : new HashSet<T>();
		while (enumration.hasMoreElements()) {
			set.add(enumration.nextElement());
		}
		return set;
	}"
"public static DescriptorExtensionList<LabelAtomProperty,LabelAtomPropertyDescriptor> all() {
        return Jenkins.getInstance().<LabelAtomProperty,LabelAtomPropertyDescriptor>getDescriptorList(LabelAtomProperty.class);
    }"
"@Override
	public Tuple2<K, V> deserialize(ConsumerRecord<byte[], byte[]> record) throws Exception {
		K key = null;
		V value = null;

		if (record.key() != null) {
			inputDeserializer.setBuffer(record.key());
			key = keySerializer.deserialize(inputDeserializer);
		}
		if (record.value() != null) {
			inputDeserializer.setBuffer(record.value());
			value = valueSerializer.deserialize(inputDeserializer);
		}
		return new Tuple2<>(key, value);
	}"
"public static byte[] changeC1C2C3ToC1C3C2(byte[] c1c2c3, ECDomainParameters ecDomainParameters) {
		// sm2p256v1的这个固定65。可看GMNamedCurves、ECCurve代码。
		final int c1Len = (ecDomainParameters.getCurve().getFieldSize() + 7) / 8 * 2 + 1;
		final int c3Len = 32; // new SM3Digest().getDigestSize();
		byte[] result = new byte[c1c2c3.length];
		System.arraycopy(c1c2c3, 0, result, 0, c1Len); // c1
		System.arraycopy(c1c2c3, c1c2c3.length - c3Len, result, c1Len, c3Len); // c3
		System.arraycopy(c1c2c3, c1Len, result, c1Len + c3Len, c1c2c3.length - c1Len - c3Len); // c2
		return result;
	}"
"public T get(Object key) {
		if (circle.isEmpty()) {
			return null;
		}
		int hash = hashFunc.hash(key);
		if (!circle.containsKey(hash)) {
			SortedMap<Integer, T> tailMap = circle.tailMap(hash);	//返回此映射的部分视图，其键大于等于 hash
			hash = tailMap.isEmpty() ? circle.firstKey() : tailMap.firstKey();
		}
		//正好命中
		return circle.get(hash);
	}"
"public static H2OFailException fail(String msg, Throwable cause) {
    Log.fatal(msg);
    if (null != cause) Log.fatal(cause);
    Log.fatal(""Stacktrace: "");
    Log.fatal(Arrays.toString(Thread.currentThread().getStackTrace()));

    // H2O fail() exists because of coding errors - but what if usage of fail() was itself a coding error?
    // Property ""suppress.shutdown.on.failure"" can be used in the case when someone is seeing shutdowns on production
    // because a developer incorrectly used fail() instead of just throwing a (recoverable) exception
    boolean suppressShutdown = getSysBoolProperty(""suppress.shutdown.on.failure"", false);
    if (! suppressShutdown) {
      H2O.shutdown(-1);
    } else {
      throw new IllegalStateException(""Suppressed shutdown for failure: "" + msg, cause);
    }

    // unreachable
    return new H2OFailException(msg);
  }"
"public void insertOrReplaceRecord(T record) throws IOException {
		if (this.closed) {
			return;
		}

		final int searchHashCode = MathUtils.jenkinsHash(this.buildSideComparator.hash(record));
		final int posHashCode = searchHashCode % this.numBuckets;
		
		// get the bucket for the given hash code
		final MemorySegment originalBucket = this.buckets[posHashCode >> this.bucketsPerSegmentBits];
		final int originalBucketOffset = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS;
		
		MemorySegment bucket = originalBucket;
		int bucketInSegmentOffset = originalBucketOffset;
		
		// get the basic characteristics of the bucket
		final int partitionNumber = bucket.get(bucketInSegmentOffset + HEADER_PARTITION_OFFSET);
		final InMemoryPartition<T> partition = this.partitions.get(partitionNumber);
		final MemorySegment[] overflowSegments = partition.overflowSegments;
		
		this.buildSideComparator.setReference(record);
		
		int countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET);
		int numInSegment = 0;
		int posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH;

		// loop over all segments that are involved in the bucket (original bucket plus overflow buckets)
		while (true) {
			
			while (numInSegment < countInSegment) {
				
				final int thisCode = bucket.getInt(posInSegment);
				posInSegment += HASH_CODE_LEN;
					
				// check if the hash code matches
				if (thisCode == searchHashCode) {
					// get the pointer to the pair
					final int pointerOffset = bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (numInSegment * POINTER_LEN);
					final long pointer = bucket.getLong(pointerOffset);
					
					// deserialize the key to check whether it is really equal, or whether we had only a hash collision
					T valueAtPosition = partition.readRecordAt(pointer);
					if (this.buildSideComparator.equalToReference(valueAtPosition)) {
						long newPointer = insertRecordIntoPartition(record, partition, true);
						bucket.putLong(pointerOffset, newPointer);
						return;
					}
				}
				numInSegment++;
			}
			
			// this segment is done. check if there is another chained bucket
			long newForwardPointer = bucket.getLong(bucketInSegmentOffset + HEADER_FORWARD_OFFSET);
			if (newForwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {
				
				// nothing found. append and insert
				long pointer = insertRecordIntoPartition(record, partition, false);

				if (countInSegment < NUM_ENTRIES_PER_BUCKET) {
					// we are good in our current bucket, put the values
					bucket.putInt(bucketInSegmentOffset + BUCKET_HEADER_LENGTH + (countInSegment * HASH_CODE_LEN), searchHashCode); // hash code
					bucket.putLong(bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (countInSegment * POINTER_LEN), pointer); // pointer
					bucket.putInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET, countInSegment + 1); // update count
				}
				else {
					insertBucketEntryFromStart(originalBucket, originalBucketOffset, searchHashCode, pointer, partitionNumber);
				}
				return;
			}
			
			final int overflowSegNum = (int) (newForwardPointer >>> 32);
			bucket = overflowSegments[overflowSegNum];
			bucketInSegmentOffset = (int) newForwardPointer;
			countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET);
			posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH;
			numInSegment = 0;
		}
	}"
"public static ZooKeeperLeaderElectionService createLeaderElectionService(
			CuratorFramework client,
			Configuration configuration) throws Exception {

		return createLeaderElectionService(client, configuration, """");
	}"
"protected boolean acceptCustomWord(int begin, int end, CoreDictionary.Attribute value)
    {
        return config.forceCustomDictionary || (end - begin >= 4 && !value.hasNatureStartsWith(""nr"") && !value.hasNatureStartsWith(""ns"") && !value.hasNatureStartsWith(""nt""));
    }"
"public boolean replace    ( TypeK  key, TypeV  oldValue, TypeV newValue ) {
    return putIfMatch( key, newValue, oldValue ) == oldValue;
  }"
"public CompositeByteBuf removeComponent(int cIndex) {
        checkComponentIndex(cIndex);
        Component comp = components[cIndex];
        if (lastAccessed == comp) {
            lastAccessed = null;
        }
        comp.free();
        removeComp(cIndex);
        if (comp.length() > 0) {
            // Only need to call updateComponentOffsets if the length was > 0
            updateComponentOffsets(cIndex);
        }
        return this;
    }"
"public long getQueuedTaskCount() {
        long count = 0;
        WorkQueue[] ws; WorkQueue w;
        if ((ws = workQueues) != null) {
            for (int i = 1; i < ws.length; i += 2) {
                if ((w = ws[i]) != null)
                    count += w.queueSize();
            }
        }
        return count;
    }"
"public AnnotationMetadata getAnnotationMetadata(Element parent, Element element) {
        return newAnnotationBuilder().buildForParent(parent, element);
    }"
"private PropDesc createProp(Field field) {
		final String fieldName = field.getName();
		final Class<?> fieldType = field.getType();
		final boolean isBooeanField = BooleanUtil.isBoolean(fieldType);

		Method getter = null;
		Method setter = null;

		String methodName;
		Class<?>[] parameterTypes;
		for (Method method : ReflectUtil.getMethods(this.beanClass)) {
			parameterTypes = method.getParameterTypes();
			if (parameterTypes.length > 1) {
				// 多于1个参数说明非Getter或Setter
				continue;
			}

			methodName = method.getName();
			if (parameterTypes.length == 0) {
				// 无参数，可能为Getter方法
				if (isMatchGetter(methodName, fieldName, isBooeanField)) {
					// 方法名与字段名匹配，则为Getter方法
					getter = method;
				}
			} else if (isMatchSetter(methodName, fieldName, isBooeanField)) {
				// 只有一个参数的情况下方法名与字段名对应匹配，则为Setter方法
				setter = method;
			}
			if (null != getter && null != setter) {
				// 如果Getter和Setter方法都找到了，不再继续寻找
				break;
			}
		}
		return new PropDesc(field, getter, setter);
	}"
"public static String getTaskManagerShellCommand(
			Configuration flinkConfig,
			ContaineredTaskManagerParameters tmParams,
			String configDirectory,
			String logDirectory,
			boolean hasLogback,
			boolean hasLog4j,
			boolean hasKrb5,
			Class<?> mainClass) {

		final Map<String, String> startCommandValues = new HashMap<>();
		startCommandValues.put(""java"", ""$JAVA_HOME/bin/java"");

		ArrayList<String> params = new ArrayList<>();
		params.add(String.format(""-Xms%dm"", tmParams.taskManagerHeapSizeMB()));
		params.add(String.format(""-Xmx%dm"", tmParams.taskManagerHeapSizeMB()));

		if (tmParams.taskManagerDirectMemoryLimitMB() >= 0) {
			params.add(String.format(""-XX:MaxDirectMemorySize=%dm"",
				tmParams.taskManagerDirectMemoryLimitMB()));
		}

		startCommandValues.put(""jvmmem"", StringUtils.join(params, ' '));

		String javaOpts = flinkConfig.getString(CoreOptions.FLINK_JVM_OPTIONS);
		if (flinkConfig.getString(CoreOptions.FLINK_TM_JVM_OPTIONS).length() > 0) {
			javaOpts += "" "" + flinkConfig.getString(CoreOptions.FLINK_TM_JVM_OPTIONS);
		}
		//applicable only for YarnMiniCluster secure test run
		//krb5.conf file will be available as local resource in JM/TM container
		if (hasKrb5) {
			javaOpts += "" -Djava.security.krb5.conf=krb5.conf"";
		}
		startCommandValues.put(""jvmopts"", javaOpts);

		String logging = """";
		if (hasLogback || hasLog4j) {
			logging = ""-Dlog.file="" + logDirectory + ""/taskmanager.log"";
			if (hasLogback) {
				logging +=
					"" -Dlogback.configurationFile=file:"" + configDirectory +
						""/logback.xml"";
			}
			if (hasLog4j) {
				logging += "" -Dlog4j.configuration=file:"" + configDirectory +
					""/log4j.properties"";
			}
		}

		startCommandValues.put(""logging"", logging);
		startCommandValues.put(""class"", mainClass.getName());
		startCommandValues.put(""redirects"",
			""1> "" + logDirectory + ""/taskmanager.out "" +
			""2> "" + logDirectory + ""/taskmanager.err"");
		startCommandValues.put(""args"", ""--configDir "" + configDirectory);

		final String commandTemplate = flinkConfig
			.getString(ConfigConstants.YARN_CONTAINER_START_COMMAND_TEMPLATE,
				ConfigConstants.DEFAULT_YARN_CONTAINER_START_COMMAND_TEMPLATE);
		String startCommand = getStartCommand(commandTemplate, startCommandValues);
		LOG.debug(""TaskManager start command: "" + startCommand);

		return startCommand;
	}"
"public double[] formNNInputs() {
    double[] input2ActFun = new double[_outSize];
    int cols = _inputs.length;
    int rows = input2ActFun.length;
    int extra=cols-cols%8;
    int multiple = (cols/8)*8-1;
    int idx = 0;
    for (int row = 0; row < rows; row++) {
      double psum0 = 0, psum1 = 0, psum2 = 0, psum3 = 0, psum4 = 0, psum5 = 0, psum6 = 0, psum7 = 0;

      for (int col=0; col < multiple; col+=8) {
        int off=idx+col;
        psum0 += _weightsAndBias._wValues[off    ] * _inputs[col    ];
        psum1 += _weightsAndBias._wValues[off + 1] * _inputs[col + 1];
        psum2 += _weightsAndBias._wValues[off + 2] * _inputs[col + 2];
        psum3 += _weightsAndBias._wValues[off + 3] * _inputs[col + 3];
        psum4 += _weightsAndBias._wValues[off + 4] * _inputs[col + 4];
        psum5 += _weightsAndBias._wValues[off + 5] * _inputs[col + 5];
        psum6 += _weightsAndBias._wValues[off + 6] * _inputs[col + 6];
        psum7 += _weightsAndBias._wValues[off + 7] * _inputs[col + 7];
      }
      input2ActFun[row] += psum0+psum1+psum2+psum3;
      input2ActFun[row] += psum4+psum5+psum6+psum7;

      for (int col = extra; col<cols;col++) {
        input2ActFun[row] += _weightsAndBias._wValues[idx+col]*_inputs[col];
      }
      input2ActFun[row] += _weightsAndBias._bValues[row];
      idx += cols;
    }
    return input2ActFun;
  }"
"public void close() throws ZkInterruptedException {
        if (_connection == null) {
            return;
        }
        LOG.debug(""Closing ZkClient..."");
        getEventLock().lock();
        try {
            setShutdownTrigger(true);
            _eventThread.interrupt();
            _eventThread.join(2000);
            _connection.close();
            _connection = null;
        } catch (InterruptedException e) {
            throw new ZkInterruptedException(e);
        } finally {
            getEventLock().unlock();
        }
        LOG.debug(""Closing ZkClient...done"");
    }"
"public RestTemplateBuilder additionalMessageConverters(
			Collection<? extends HttpMessageConverter<?>> messageConverters) {
		Assert.notNull(messageConverters, ""MessageConverters must not be null"");
		return new RestTemplateBuilder(this.detectRequestFactory, this.rootUri,
				append(this.messageConverters, messageConverters),
				this.requestFactorySupplier, this.uriTemplateHandler, this.errorHandler,
				this.basicAuthentication, this.restTemplateCustomizers,
				this.requestFactoryCustomizer, this.interceptors);
	}"
"@Override
	public boolean remove(@Nonnull T toRemove) {
		T storedElement = getDedupMapForElement(toRemove).remove(toRemove);
		return storedElement != null && super.remove(storedElement);
	}"
"public RunList<R> newBuilds() {
        GregorianCalendar cal = new GregorianCalendar();
        cal.add(Calendar.DAY_OF_YEAR, -7);
        final long t = cal.getTimeInMillis();

        // can't publish on-going builds
        return filter(new Predicate<R>() {
            public boolean apply(R r) {
                return !r.isBuilding();
            }
        })
        // put at least 10 builds, but otherwise ignore old builds
        .limit(new CountingPredicate<R>() {
            public boolean apply(int index, R r) {
                return index < 10 || r.getTimeInMillis() >= t;
            }
        });
    }"
"public void merge(UnsafeExternalSorter other) throws IOException {
    other.spill();
    spillWriters.addAll(other.spillWriters);
    // remove them from `spillWriters`, or the files will be deleted in `cleanupResources`.
    other.spillWriters.clear();
    other.cleanupResources();
  }"
"public static void main(String[] args) throws Exception {

		// Checking input parameters
		final ParameterTool params = ParameterTool.fromArgs(args);
		System.out.println(""Usage: TwitterExample [--output <path>] "" +
				""[--twitter-source.consumerKey <key> --twitter-source.consumerSecret <secret> --twitter-source.token <token> --twitter-source.tokenSecret <tokenSecret>]"");

		// set up the execution environment
		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

		// make parameters available in the web interface
		env.getConfig().setGlobalJobParameters(params);

		env.setParallelism(params.getInt(""parallelism"", 1));

		// get input data
		DataStream<String> streamSource;
		if (params.has(TwitterSource.CONSUMER_KEY) &&
				params.has(TwitterSource.CONSUMER_SECRET) &&
				params.has(TwitterSource.TOKEN) &&
				params.has(TwitterSource.TOKEN_SECRET)
				) {
			streamSource = env.addSource(new TwitterSource(params.getProperties()));
		} else {
			System.out.println(""Executing TwitterStream example with default props."");
			System.out.println(""Use --twitter-source.consumerKey <key> --twitter-source.consumerSecret <secret> "" +
					""--twitter-source.token <token> --twitter-source.tokenSecret <tokenSecret> specify the authentication info."");
			// get default test text data
			streamSource = env.fromElements(TwitterExampleData.TEXTS);
		}

		DataStream<Tuple2<String, Integer>> tweets = streamSource
				// selecting English tweets and splitting to (word, 1)
				.flatMap(new SelectEnglishAndTokenizeFlatMap())
				// group by words and sum their occurrences
				.keyBy(0).sum(1);

		// emit result
		if (params.has(""output"")) {
			tweets.writeAsText(params.get(""output""));
		} else {
			System.out.println(""Printing result to stdout. Use --output to specify output path."");
			tweets.print();
		}

		// execute program
		env.execute(""Twitter Streaming Example"");
	}"
"private synchronized void dumpMessages(Message message, String startPosition, String endPosition, int total) {
        try {
            MDC.put(OtterConstants.splitPipelineSelectLogFileKey, String.valueOf(pipelineId));
            logger.info(SEP + ""****************************************************"" + SEP);
            logger.info(MessageDumper.dumpMessageInfo(message, startPosition, endPosition, total));
            logger.info(""****************************************************"" + SEP);
            if (dumpDetail) {// 判断一下是否需要打印详细信息
                dumpEventDatas(message.getDatas());
                logger.info(""****************************************************"" + SEP);
            }
        } finally {
            MDC.remove(OtterConstants.splitPipelineSelectLogFileKey);
        }
    }"
"public static <K, V> HashMap<K, V> of(K key, V value) {
		return of(key, value, false);
	}"
"private static com.jfinal.template.Engine createEngine(TemplateConfig config) {
		Assert.notNull(config, ""Template config is null !"");
		final com.jfinal.template.Engine engine = com.jfinal.template.Engine.create(""Hutool-Enjoy-Engine-"" + config.toString());
		engine.setEncoding(config.getCharsetStr());

		switch (config.getResourceMode()) {
		case STRING:
			// 默认字符串类型资源:
			break;
		case CLASSPATH:
			engine.setToClassPathSourceFactory();
			engine.setBaseTemplatePath(config.getPath());
			break;
		case FILE:
			engine.setSourceFactory(new FileSourceFactory());
			engine.setBaseTemplatePath(config.getPath());
			break;
		case WEB_ROOT:
			engine.setSourceFactory(new FileSourceFactory());
			engine.setBaseTemplatePath(FileUtil.getAbsolutePath(FileUtil.getWebRoot()));
			break;
		default:
			break;
		}

		return engine;
	}"
"public Multimap<Long, AccumuloColumnConstraint> getCardinalities(String schema, String table, Authorizations auths, Multimap<AccumuloColumnConstraint, Range> idxConstraintRangePairs, long earlyReturnThreshold, Duration pollingDuration)
    {
        // Submit tasks to the executor to fetch column cardinality, adding it to the Guava cache if necessary
        CompletionService<Pair<Long, AccumuloColumnConstraint>> executor = new ExecutorCompletionService<>(executorService);
        idxConstraintRangePairs.asMap().forEach((key, value) -> executor.submit(() -> {
            long cardinality = getColumnCardinality(schema, table, auths, key.getFamily(), key.getQualifier(), value);
            LOG.debug(""Cardinality for column %s is %s"", key.getName(), cardinality);
            return Pair.of(cardinality, key);
        }));

        // Create a multi map sorted by cardinality
        ListMultimap<Long, AccumuloColumnConstraint> cardinalityToConstraints = MultimapBuilder.treeKeys().arrayListValues().build();
        try {
            boolean earlyReturn = false;
            int numTasks = idxConstraintRangePairs.asMap().entrySet().size();
            do {
                // Sleep for the polling duration to allow concurrent tasks to run for this time
                Thread.sleep(pollingDuration.toMillis());

                // Poll each task, retrieving the result if it is done
                for (int i = 0; i < numTasks; ++i) {
                    Future<Pair<Long, AccumuloColumnConstraint>> futureCardinality = executor.poll();
                    if (futureCardinality != null && futureCardinality.isDone()) {
                        Pair<Long, AccumuloColumnConstraint> columnCardinality = futureCardinality.get();
                        cardinalityToConstraints.put(columnCardinality.getLeft(), columnCardinality.getRight());
                    }
                }

                // If the smallest cardinality is present and below the threshold, set the earlyReturn flag
                Optional<Entry<Long, AccumuloColumnConstraint>> smallestCardinality = cardinalityToConstraints.entries().stream().findFirst();
                if (smallestCardinality.isPresent()) {
                    if (smallestCardinality.get().getKey() <= earlyReturnThreshold) {
                        LOG.info(""Cardinality %s, is below threshold. Returning early while other tasks finish"", smallestCardinality);
                        earlyReturn = true;
                    }
                }
            }
            while (!earlyReturn && cardinalityToConstraints.entries().size() < numTasks);
        }
        catch (ExecutionException | InterruptedException e) {
            if (e instanceof InterruptedException) {
                Thread.currentThread().interrupt();
            }
            throw new PrestoException(UNEXPECTED_ACCUMULO_ERROR, ""Exception when getting cardinality"", e);
        }

        // Create a copy of the cardinalities
        return ImmutableMultimap.copyOf(cardinalityToConstraints);
    }"
"protected boolean enoughAttributesAvailableToProcess(final String principal, final Map<String, Object> principalAttributes) {
        if (!enoughRequiredAttributesAvailableToProcess(principalAttributes, this.requiredAttributes)) {
            return false;
        }
        if (principalAttributes.size() < this.rejectedAttributes.size()) {
            LOGGER.debug(""The size of the principal attributes that are [{}] does not match defined rejected attributes, ""
                + ""which means the principal is not carrying enough data to grant authorization"", principalAttributes);
            return false;
        }
        return true;
    }"
"public Val end(Val returning) {
    sanity_check_refs(returning);
    // Remove all temp frames
    Futures fs = new Futures();
    for (Frame fr : FRAMES.values()) {
      fs = downRefCnt(fr, fs);   // Remove internal Vecs one by one
      DKV.remove(fr._key, fs);   // Shallow remove, internal Vecs removed 1-by-1
    }
    fs.blockForPending();
    FRAMES.clear();             // No more temp frames
    // Copy (as needed) so the returning Frame is completely independent of the
    // (disappearing) session.
    if (returning != null && returning.isFrame()) {
      Frame fr = returning.getFrame();
      Key<Vec>[] vecs = fr.keys();
      for (int i = 0; i < vecs.length; i++) {
        _addRefCnt(vecs[i], -1); // Returning frame has refcnt +1, lower it now; should go to zero internal refcnts.
        if (GLOBALS.contains(vecs[i])) // Copy if shared with globals
          fr.replace(i, vecs[i].get().makeCopy());
      }
    }
    GLOBALS.clear();            // No longer tracking globals
    sanity_check_refs(null);
    REFCNTS.clear();
    return returning;
  }"
"public void addConnectionRequestProxyListener(ConnectRequestProxyListener listener) {
        if (listener == null) {
            throw new IllegalArgumentException(""Parameter listener must not be null."");
        }

        if (connectRequestProxyListeners == null) {
            connectRequestProxyListeners = new ArrayList<>();
        }
        connectRequestProxyListeners.add(listener);
    }"
"@Exported(name = ""property"", inline = true)
    public List<UserProperty> getAllProperties() {
        if (hasPermission(Jenkins.ADMINISTER)) {
            return Collections.unmodifiableList(properties);
        }

        return Collections.emptyList();
    }"
"public boolean stop(Long channelId, boolean needTermin) {
        // stop优先级高于pause
        updateStatus(channelId, ChannelStatus.STOP);

        boolean result = !needTermin;

        if (needTermin) {
            try {
                result |= termin(channelId, TerminType.SHUTDOWN);
            } catch (Throwable e) {
                updateStatus(channelId, ChannelStatus.STOP); // 出错了，直接挂起
                throw new ArbitrateException(e);
            }
        }

        return result;
    }"
"public INDArray rnnTimeStep(INDArray input, MemoryWorkspace outputWorkspace ) {
        try {
            boolean inputIs2d = input.rank() == 2;
            INDArray out = outputOfLayerDetached(false, FwdPassType.RNN_TIMESTEP, layers.length - 1, input, null, null, outputWorkspace);
            if (inputIs2d && out.rank() == 3 && layers[layers.length - 1].type() == Type.RECURRENT) {
                //Return 2d output with shape [miniBatchSize,nOut]
                // instead of 3d output with shape [miniBatchSize,nOut,1]
                return out.tensorAlongDimension(0, 1, 0);
            }
            return out;
        } catch (OutOfMemoryError e){
            CrashReportingUtil.writeMemoryCrashDump(this, e);
            throw e;
        }
    }"
"public void addSpillIfNotEmpty(UnsafeSorterIterator spillReader) throws IOException {
    if (spillReader.hasNext()) {
      // We only add the spillReader to the priorityQueue if it is not empty. We do this to
      // make sure the hasNext method of UnsafeSorterIterator returned by getSortedIterator
      // does not return wrong result because hasNext will return true
      // at least priorityQueue.size() times. If we allow n spillReaders in the
      // priorityQueue, we will have n extra empty records in the result of UnsafeSorterIterator.
      spillReader.loadNext();
      priorityQueue.add(spillReader);
      numRecords += spillReader.getNumRecords();
    }
  }"
"public static List<WordInfo> extractWords(BufferedReader reader, int size) throws IOException
    {
        return extractWords(reader, size, false);
    }"
"public static String getPinYin(String chinese) {
		final StrBuilder result = StrUtil.strBuilder();
		String strTemp = null;
		int len = chinese.length();
		for (int j = 0; j < len; j++) {
			strTemp = chinese.substring(j, j + 1);
			int ascii = getChsAscii(strTemp);
			if (ascii > 0) {
				//非汉字
				result.append((char)ascii);
			} else {
				for (int i = pinyinValue.length - 1; i >= 0; i--) {
					if (pinyinValue[i] <= ascii) {
						result.append(pinyinStr[i]);
						break;
					}
				}
			}
		}
		return result.toString();
	}"
"public static int divisor(int m, int n) {
		while (m % n != 0) {
			int temp = m % n;
			m = n;
			n = temp;
		}
		return n;
	}"
"@Override
  public void recordActivityEnd(ExecutionEntity executionEntity, String deleteReason) {
    if (isHistoryLevelAtLeast(HistoryLevel.ACTIVITY)) {
      HistoricActivityInstanceEntity historicActivityInstance = findActivityInstance(executionEntity, false, true);
      if (historicActivityInstance != null) {
        historicActivityInstance.markEnded(deleteReason);
        
        // Fire event
        ActivitiEventDispatcher activitiEventDispatcher = getEventDispatcher();
        if (activitiEventDispatcher != null && activitiEventDispatcher.isEnabled()) {
          activitiEventDispatcher.dispatchEvent(
              ActivitiEventBuilder.createEntityEvent(ActivitiEventType.HISTORIC_ACTIVITY_INSTANCE_ENDED, historicActivityInstance));
        }
      }
    }
  }"
"public static short[] unWrap(Short... values) {
		if (null == values) {
			return null;
		}
		final int length = values.length;
		if (0 == length) {
			return new short[0];
		}

		final short[] array = new short[length];
		for (int i = 0; i < length; i++) {
			array[i] = values[i].shortValue();
		}
		return array;
	}"
"private void registerChannel(Selector selector, SelectableChannel channel, Operation ops) {
		if (channel == null) {
			return;
		}

		try {
			channel.configureBlocking(false);
			// 注册通道
			channel.register(selector, ops.getValue());
		} catch (IOException e) {
			throw new IORuntimeException(e);
		}
	}"
"public static <T> T[] setOrAppend(T[] buffer, int index, T value) {
		if(index < buffer.length) {
			Array.set(buffer, index, value);
			return buffer;
		}else {
			return append(buffer, value);
		}
	}"
"public static boolean getBooleanValue(String appName, String key, boolean defaultValue) {
        String ret = getStringValue0(appName, key);
        return StringUtils.isEmpty(ret) ? defaultValue : CommonUtils.parseBoolean(ret, defaultValue);
    }"
"public static DataSource createDataSource(final Map<String, DataSource> dataSourceMap, final MasterSlaveRuleConfiguration masterSlaveRuleConfig, 
                                              final Properties props, final OrchestrationConfiguration orchestrationConfig) throws SQLException {
        if (null == masterSlaveRuleConfig || null == masterSlaveRuleConfig.getMasterDataSourceName()) {
            return createDataSource(orchestrationConfig);
        }
        MasterSlaveDataSource masterSlaveDataSource = new MasterSlaveDataSource(dataSourceMap, masterSlaveRuleConfig, props);
        return new OrchestrationMasterSlaveDataSource(masterSlaveDataSource, orchestrationConfig);
    }"
"static INDArray createMask(DataType dataType, long[] shape){
        switch (shape.length){
            case 2: // FF-Type input
                return Nd4j.ones(dataType,shape[0], 1);
            case 3: // RNN-Type input
                return Nd4j.ones(dataType, shape[0], shape[2]);
            case 4: //CNN input
                return Nd4j.ones(dataType, shape[0], 1, 1, 1);
            default:
                Preconditions.throwEx(""Can not create all-ones-mask for given input shape %s."", Arrays.toString(shape));
                return null;
        }
    }"
"public FormValidation doCheckDisplayName(@QueryParameter String displayName,
            @QueryParameter String jobName) {
        displayName = displayName.trim();

        if(LOGGER.isLoggable(Level.FINE)) {
            LOGGER.log(Level.FINE, ""Current job name is "" + jobName);
        }

        if(!isNameUnique(displayName, jobName)) {
            return FormValidation.warning(Messages.Jenkins_CheckDisplayName_NameNotUniqueWarning(displayName));
        }
        else if(!isDisplayNameUnique(displayName, jobName)){
            return FormValidation.warning(Messages.Jenkins_CheckDisplayName_DisplayNameNotUniqueWarning(displayName));
        }
        else {
            return FormValidation.ok();
        }
    }"
"public DetectorResult detect() throws NotFoundException {

    ResultPoint[] cornerPoints = rectangleDetector.detect();

    ResultPoint[] points = detectSolid1(cornerPoints);
    points = detectSolid2(points);
    points[3] = correctTopRight(points);
    if (points[3] == null) {
      throw NotFoundException.getNotFoundInstance();
    }
    points = shiftToModuleCenter(points);

    ResultPoint topLeft = points[0];
    ResultPoint bottomLeft = points[1];
    ResultPoint bottomRight = points[2];
    ResultPoint topRight = points[3];

    int dimensionTop = transitionsBetween(topLeft, topRight) + 1;
    int dimensionRight = transitionsBetween(bottomRight, topRight) + 1;
    if ((dimensionTop & 0x01) == 1) {
      dimensionTop += 1;
    }
    if ((dimensionRight & 0x01) == 1) {
      dimensionRight += 1;
    }

    if (4 * dimensionTop < 7 * dimensionRight && 4 * dimensionRight < 7 * dimensionTop) {
      // The matrix is square
      dimensionTop = dimensionRight = Math.max(dimensionTop, dimensionRight);
    }

    BitMatrix bits = sampleGrid(image, 
                                topLeft,
                                bottomLeft,
                                bottomRight,
                                topRight,
                                dimensionTop,
                                dimensionRight);

    return new DetectorResult(bits, new ResultPoint[]{topLeft, bottomLeft, bottomRight, topRight});
  }"
"@Override
  public List<ExecutableFlow> fetchRecentlyFinishedFlows(final Duration maxAge)
      throws ExecutorManagerException {
    return this.executionFlowDao.fetchRecentlyFinishedFlows(maxAge);
  }"
"private static String truncateErrorMsg(String errorMsg)
  {
    if (errorMsg != null && errorMsg.length() > MAX_ERROR_MSG_LENGTH) {
      return errorMsg.substring(0, MAX_ERROR_MSG_LENGTH) + ""..."";
    } else {
      return errorMsg;
    }
  }"
"public static void convert(Image srcImage, String formatName, ImageOutputStream destImageStream, boolean isSrcPng) {
		try {
			ImageIO.write(isSrcPng ? copyImage(srcImage, BufferedImage.TYPE_INT_RGB) : toBufferedImage(srcImage), formatName, destImageStream);
		} catch (IOException e) {
			throw new IORuntimeException(e);
		}
	}"
"private RpcServerLookoutModel createServerMetricsModel(SofaRequest request, SofaResponse response) {

        RpcServerLookoutModel rpcServerMetricsModel = new RpcServerLookoutModel();

        RpcInternalContext context = RpcInternalContext.getContext();

        String app = request.getTargetAppName();
        String service = request.getTargetServiceUniqueName();
        String method = request.getMethodName();
        String protocol = getStringAvoidNull(request.getRequestProp(RemotingConstants.HEAD_PROTOCOL));
        String invokeType = request.getInvokeType();
        String callerApp = getStringAvoidNull(request.getRequestProp(RemotingConstants.HEAD_APP_NAME));
        Long elapsedTime = getLongAvoidNull(context.getAttachment(RpcConstants.INTERNAL_KEY_IMPL_ELAPSE));
        boolean success = response != null && !response.isError() && response.getErrorMsg() == null &&
            (!(response.getAppResponse() instanceof Throwable));

        rpcServerMetricsModel.setApp(app);
        rpcServerMetricsModel.setService(service);
        rpcServerMetricsModel.setMethod(method);
        rpcServerMetricsModel.setProtocol(protocol);
        rpcServerMetricsModel.setInvokeType(invokeType);
        rpcServerMetricsModel.setCallerApp(callerApp);
        rpcServerMetricsModel.setElapsedTime(elapsedTime);
        rpcServerMetricsModel.setSuccess(success);

        return rpcServerMetricsModel;
    }"
"protected static FixedBucketsHistogram fromByteBufferFullNoSerdeHeader(ByteBuffer buf)
  {
    double lowerLimit = buf.getDouble();
    double upperLimit = buf.getDouble();
    int numBuckets = buf.getInt();
    OutlierHandlingMode outlierHandlingMode = OutlierHandlingMode.values()[buf.get()];

    long count = buf.getLong();
    long lowerOutlierCount = buf.getLong();
    long upperOutlierCount = buf.getLong();
    long missingValueCount = buf.getLong();

    double max = buf.getDouble();
    double min = buf.getDouble();

    long histogram[] = new long[numBuckets];
    buf.asLongBuffer().get(histogram);
    buf.position(buf.position() + Long.BYTES * histogram.length);

    return new FixedBucketsHistogram(
        lowerLimit,
        upperLimit,
        numBuckets,
        outlierHandlingMode,
        histogram,
        count,
        max,
        min,
        lowerOutlierCount,
        upperOutlierCount,
        missingValueCount
    );
  }"
"@JsonValue
  public String toBase64()
  {
    byte[] asBytes = toBytes();
    return StringUtils.fromUtf8(StringUtils.encodeBase64(asBytes));
  }"
"private boolean isAddToLoadBalancerSuspended(String asgAccountId, String asgName) {
        AutoScalingGroup asg;
        if(asgAccountId == null || asgAccountId.equals(accountId)) {
            asg = retrieveAutoScalingGroup(asgName);
        } else {
            asg = retrieveAutoScalingGroupCrossAccount(asgAccountId, asgName);
        }
        if (asg == null) {
            logger.warn(""The ASG information for {} could not be found. So returning false."", asgName);
            return false;
        }
        return isAddToLoadBalancerSuspended(asg);
    }"
"public double fBeta(double beta, EvaluationAveraging averaging) {
        if(getNumRowCounter() == 0.0){
            return Double.NaN;  //No data
        }
        int nClasses = confusion().getClasses().size();

        if (nClasses == 2) {
            return EvaluationUtils.fBeta(beta, (long) truePositives.getCount(1), (long) falsePositives.getCount(1),
                            (long) falseNegatives.getCount(1));
        }

        if (averaging == EvaluationAveraging.Macro) {
            double macroFBeta = 0.0;
            int count = 0;
            for (int i = 0; i < nClasses; i++) {
                double thisFBeta = fBeta(beta, i, -1);
                if (thisFBeta != -1) {
                    macroFBeta += thisFBeta;
                    count++;
                }
            }
            macroFBeta /= count;
            return macroFBeta;
        } else if (averaging == EvaluationAveraging.Micro) {
            long tpCount = 0;
            long fpCount = 0;
            long fnCount = 0;
            for (int i = 0; i < nClasses; i++) {
                tpCount += truePositives.getCount(i);
                fpCount += falsePositives.getCount(i);
                fnCount += falseNegatives.getCount(i);
            }
            return EvaluationUtils.fBeta(beta, tpCount, fpCount, fnCount);
        } else {
            throw new UnsupportedOperationException(""Unknown averaging approach: "" + averaging);
        }
    }"
"public static String replaceAll(CharSequence str, String regex, Func1<Matcher, String> replaceFun) {
		return replaceAll(str, Pattern.compile(regex), replaceFun);
	}"
"public static AzkabanDataSource getMySQLDataSource(final String host, final Integer port,
      final String dbName, final String user, final String password, final Integer numConnections) {
    return new MySQLBasicDataSource(host, port, dbName, user, password,
        numConnections);
  }"
"public void sendAlarm(AlarmMessage data) {
        try {
            if (!queue.offer(data, 2, TimeUnit.SECONDS)) {
                logger.error(String.format(""alarm sent to queue error : [%s]"", data.toString()));
            }
        } catch (Exception e) {
            logger.error(String.format(""send alarm [%s] to drgoon agent error!"", data.toString()), e);
        }
    }"
"public String selectBasicTransform() {
    if( _ignored )                 return ""ignored"";
    if( _v.isBinary() )            return ""none"";
    if( _v.isTime() || _isDate )   return ""time"";  // actually we have a time/date column, so apply some time transforms
    if( _v.max() - _v.min() > 1e4) return ""log"";   // take a log if spans more than 2 orders
    if( _v.isNumeric() && !_v.isInt() ) return ""recip""; // try the reciprocal!
    return ""none"";                                 // no transform if not interesting
  }"
"public PythonStreamExecutionEnvironment create_local_execution_environment(int parallelism, Configuration config) {
		return new PythonStreamExecutionEnvironment(
			StreamExecutionEnvironment.createLocalEnvironment(parallelism, config), new Path(localTmpPath), scriptName);
	}"
"public static Throwable stripException(Throwable throwableToStrip, Class<? extends Throwable> typeToStrip) {
		while (typeToStrip.isAssignableFrom(throwableToStrip.getClass()) && throwableToStrip.getCause() != null) {
			throwableToStrip = throwableToStrip.getCause();
		}

		return throwableToStrip;
	}"
"public void buildEnvironment(Run<?,?> build, EnvVars env) {
        if (build instanceof AbstractBuild) {
            buildEnvVars((AbstractBuild) build, env);
        }
        // else do not know how to do it
    }"
"@Deprecated
	public <T> TypeSerializerSchemaCompatibility<T> resolveCompatibilityWithNested(
			TypeSerializerSchemaCompatibility<?> outerCompatibility,
			TypeSerializer<?>... newNestedSerializers) {

		checkArgument(newNestedSerializers.length == nestedSnapshots.length,
				""Different number of new serializers and existing serializer configuration snapshots"");

		// compatibility of the outer serializer's format
		if (outerCompatibility.isIncompatible()) {
			return TypeSerializerSchemaCompatibility.incompatible();
		}

		// check nested serializers for compatibility
		boolean nestedSerializerRequiresMigration = false;
		for (int i = 0; i < nestedSnapshots.length; i++) {
			TypeSerializerSchemaCompatibility<?> compatibility =
					resolveCompatibility(newNestedSerializers[i], nestedSnapshots[i]);

			if (compatibility.isIncompatible()) {
				return TypeSerializerSchemaCompatibility.incompatible();
			}
			if (compatibility.isCompatibleAfterMigration()) {
				nestedSerializerRequiresMigration = true;
			}
		}

		return (nestedSerializerRequiresMigration || !outerCompatibility.isCompatibleAsIs()) ?
				TypeSerializerSchemaCompatibility.compatibleAfterMigration() :
				TypeSerializerSchemaCompatibility.compatibleAsIs();
	}"
"public @CheckForNull User getUser(String name) {
        return User.get(name, User.ALLOW_USER_CREATION_VIA_URL && hasPermission(ADMINISTER));
    }"
"public CompareToBuilder append(final Object lhs, final Object rhs, final Comparator<?> comparator) {
        if (comparison != 0) {
            return this;
        }
        if (lhs == rhs) {
            return this;
        }
        if (lhs == null) {
            comparison = -1;
            return this;
        }
        if (rhs == null) {
            comparison = +1;
            return this;
        }
        if (lhs.getClass().isArray()) {
            // switch on type of array, to dispatch to the correct handler
            // handles multi dimensional arrays
            // throws a ClassCastException if rhs is not the correct array type
            if (lhs instanceof long[]) {
                append((long[]) lhs, (long[]) rhs);
            } else if (lhs instanceof int[]) {
                append((int[]) lhs, (int[]) rhs);
            }"
"public List<INDArray> feedForward(INDArray input) {
        if (input == null)
            throw new IllegalStateException(""Unable to perform feed forward; no input found"");
        setInput(input);
        return feedForward();
    }"
"public void setHints(Map<DecodeHintType,?> hints) {
    this.hints = hints;

    boolean tryHarder = hints != null && hints.containsKey(DecodeHintType.TRY_HARDER);
    @SuppressWarnings(""unchecked"")
    Collection<BarcodeFormat> formats =
        hints == null ? null : (Collection<BarcodeFormat>) hints.get(DecodeHintType.POSSIBLE_FORMATS);
    Collection<Reader> readers = new ArrayList<>();
    if (formats != null) {
      boolean addOneDReader =
          formats.contains(BarcodeFormat.UPC_A) ||
          formats.contains(BarcodeFormat.UPC_E) ||
          formats.contains(BarcodeFormat.EAN_13) ||
          formats.contains(BarcodeFormat.EAN_8) ||
          formats.contains(BarcodeFormat.CODABAR) ||
          formats.contains(BarcodeFormat.CODE_39) ||
          formats.contains(BarcodeFormat.CODE_93) ||
          formats.contains(BarcodeFormat.CODE_128) ||
          formats.contains(BarcodeFormat.ITF) ||
          formats.contains(BarcodeFormat.RSS_14) ||
          formats.contains(BarcodeFormat.RSS_EXPANDED);
      // Put 1D readers upfront in ""normal"" mode
      if (addOneDReader && !tryHarder) {
        readers.add(new MultiFormatOneDReader(hints));
      }
      if (formats.contains(BarcodeFormat.QR_CODE)) {
        readers.add(new QRCodeReader());
      }
      if (formats.contains(BarcodeFormat.DATA_MATRIX)) {
        readers.add(new DataMatrixReader());
      }
      if (formats.contains(BarcodeFormat.AZTEC)) {
        readers.add(new AztecReader());
      }
      if (formats.contains(BarcodeFormat.PDF_417)) {
         readers.add(new PDF417Reader());
      }
      if (formats.contains(BarcodeFormat.MAXICODE)) {
         readers.add(new MaxiCodeReader());
      }
      // At end in ""try harder"" mode
      if (addOneDReader && tryHarder) {
        readers.add(new MultiFormatOneDReader(hints));
      }
    }
    if (readers.isEmpty()) {
      if (!tryHarder) {
        readers.add(new MultiFormatOneDReader(hints));
      }

      readers.add(new QRCodeReader());
      readers.add(new DataMatrixReader());
      readers.add(new AztecReader());
      readers.add(new PDF417Reader());
      readers.add(new MaxiCodeReader());

      if (tryHarder) {
        readers.add(new MultiFormatOneDReader(hints));
      }
    }
    this.readers = readers.toArray(EMPTY_READER_ARRAY);
  }"
"public static void set(Object baseObject, long baseOffset, int index) {
    assert index >= 0 : ""index ("" + index + "") should >= 0"";
    final long mask = 1L << (index & 0x3f);  // mod 64 and shift
    final long wordOffset = baseOffset + (index >> 6) * WORD_SIZE;
    final long word = Platform.getLong(baseObject, wordOffset);
    Platform.putLong(baseObject, wordOffset, word | mask);
  }"
"@Deprecated
  private void emitJvmMemMetrics(ServiceEmitter emitter)
  {
    // I have no idea why, but jvm/mem is slightly more than the sum of jvm/pool. Let's just include
    // them both.
    final Map<String, MemoryUsage> usages = ImmutableMap.of(
        ""heap"", ManagementFactory.getMemoryMXBean().getHeapMemoryUsage(),
        ""nonheap"", ManagementFactory.getMemoryMXBean().getNonHeapMemoryUsage()
    );
    for (Map.Entry<String, MemoryUsage> entry : usages.entrySet()) {
      final String kind = entry.getKey();
      final MemoryUsage usage = entry.getValue();
      final ServiceMetricEvent.Builder builder = builder().setDimension(""memKind"", kind);
      MonitorUtils.addDimensionsToBuilder(builder, dimensions);

      emitter.emit(builder.build(""jvm/mem/max"", usage.getMax()));
      emitter.emit(builder.build(""jvm/mem/committed"", usage.getCommitted()));
      emitter.emit(builder.build(""jvm/mem/used"", usage.getUsed()));
      emitter.emit(builder.build(""jvm/mem/init"", usage.getInit()));
    }

    // jvm/pool
    for (MemoryPoolMXBean pool : ManagementFactory.getMemoryPoolMXBeans()) {
      final String kind = pool.getType() == MemoryType.HEAP ? ""heap"" : ""nonheap"";
      final MemoryUsage usage = pool.getUsage();
      final ServiceMetricEvent.Builder builder = builder()
          .setDimension(""poolKind"", kind)
          .setDimension(""poolName"", pool.getName());
      MonitorUtils.addDimensionsToBuilder(builder, dimensions);

      emitter.emit(builder.build(""jvm/pool/max"", usage.getMax()));
      emitter.emit(builder.build(""jvm/pool/committed"", usage.getCommitted()));
      emitter.emit(builder.build(""jvm/pool/used"", usage.getUsed()));
      emitter.emit(builder.build(""jvm/pool/init"", usage.getInit()));
    }
  }"
"public static File writeFromStream(InputStream in, String fullFilePath) throws IORuntimeException {
		return writeFromStream(in, touch(fullFilePath));
	}"
"private R load(int n, Index editInPlace) {
        assert Thread.holdsLock(this);
        assert dir != null;
        R v = load(new File(dir, String.valueOf(n)), editInPlace);
        if (v==null && editInPlace!=null) {
            // remember the failure.
            // if editInPlace==null, we can create a new copy for this, but not sure if it's worth doing,
            // TODO should we also update numberOnDisk?
            editInPlace.byNumber.put(n, null);
        }
        return v;
    }"
"public <T> AioClient setOption(SocketOption<T> name, T value) throws IOException {
		this.session.getChannel().setOption(name, value);
		return this;
	}"
"Exchange newExchange(Interceptor.Chain chain, boolean doExtensiveHealthChecks) {
    synchronized (connectionPool) {
      if (noMoreExchanges) {
        throw new IllegalStateException(""released"");
      }
      if (exchange != null) {
        throw new IllegalStateException(""cannot make a new request because the previous response ""
            + ""is still open: please call response.close()"");
      }
    }

    ExchangeCodec codec = exchangeFinder.find(client, chain, doExtensiveHealthChecks);
    Exchange result = new Exchange(this, call, eventListener, exchangeFinder, codec);

    synchronized (connectionPool) {
      this.exchange = result;
      this.exchangeRequestDone = false;
      this.exchangeResponseDone = false;
      return result;
    }
  }"
"@Override
    public synchronized void incrementWordCount(String word, int increment) {
        if (word == null || word.isEmpty())
            throw new IllegalArgumentException(""Word can't be empty or null"");
        wordFrequencies.incrementCount(word, increment);

        if (hasToken(word)) {
            VocabWord token = tokenFor(word);
            token.increaseElementFrequency(increment);
        }
        totalWordOccurrences.set(totalWordOccurrences.get() + increment);
    }"
"public CirculantGraph addRange(long offset, long length) {
		Preconditions.checkArgument(offset >= MINIMUM_OFFSET,
			""Range offset must be at least "" + MINIMUM_OFFSET);
		Preconditions.checkArgument(length <= vertexCount - offset,
			""Range length must not be greater than the vertex count minus the range offset."");

		offsetRanges.add(new OffsetRange(offset, length));

		return this;
	}"
"Map<K, V> fixedSnapshot(Supplier<Iterator<Node<K, V>>> iteratorSupplier,
      int limit, Function<V, V> transformer) {
    requireArgument(limit >= 0);
    evictionLock.lock();
    try {
      maintenance(/* ignored */ null);

      int initialCapacity = Math.min(limit, size());
      Iterator<Node<K, V>> iterator = iteratorSupplier.get();
      Map<K, V> map = new LinkedHashMap<>(initialCapacity);
      while ((map.size() < limit) && iterator.hasNext()) {
        Node<K, V> node = iterator.next();
        K key = node.getKey();
        V value = transformer.apply(node.getValue());
        if ((key != null) && (value != null) && node.isAlive()) {
          map.put(key, value);
        }
      }
      return Collections.unmodifiableMap(map);
    } finally {
      evictionLock.unlock();
    }
  }"
"public String getBackupVersion() {
        try {
            try (JarFile backupWar = new JarFile(new File(Lifecycle.get().getHudsonWar() + "".bak""))) {
                Attributes attrs = backupWar.getManifest().getMainAttributes();
                String v = attrs.getValue(""Jenkins-Version"");
                if (v == null)   v = attrs.getValue(""Hudson-Version"");
                return v;
            }
        } catch (IOException e) {
            LOGGER.log(Level.WARNING, ""Failed to read backup version "", e);
            return null;}

    }"
"synchronized public static void start(boolean isDeamon) {
		if (null == crontabSetting) {
			// 尝试查找config/cron.setting
			setCronSetting(CRONTAB_CONFIG_PATH);
		}
		// 尝试查找cron.setting
		if (null == crontabSetting) {
			setCronSetting(CRONTAB_CONFIG_PATH2);
		}
		if (scheduler.isStarted()) {
			throw new UtilException(""Scheduler has been started, please stop it first!"");
		}

		schedule(crontabSetting);
		scheduler.start(isDeamon);
	}"
"protected boolean doPrincipalAttributesAllowSurrogateServiceAccess(final Map<String, Object> principalAttributes) {
        if (!enoughRequiredAttributesAvailableToProcess(principalAttributes, this.surrogateRequiredAttributes)) {
            LOGGER.debug(""Surrogate access is denied. There are not enough attributes available to satisfy the requirements [{}]"",
                this.surrogateRequiredAttributes);
            return false;
        }
        if (!doRequiredAttributesAllowPrincipalAccess(principalAttributes, this.surrogateRequiredAttributes)) {
            LOGGER.debug(""Surrogate access is denied. The principal does not have the required attributes [{}] specified by this strategy"",
                this.surrogateRequiredAttributes);
            return false;
        }
        return true;
    }"
"public String determineDriverClassName() {
		if (StringUtils.hasText(this.driverClassName)) {
			Assert.state(driverClassIsLoadable(),
					() -> ""Cannot load driver class: "" + this.driverClassName);
			return this.driverClassName;
		}
		String driverClassName = null;
		if (StringUtils.hasText(this.url)) {
			driverClassName = DatabaseDriver.fromJdbcUrl(this.url).getDriverClassName();
		}
		if (!StringUtils.hasText(driverClassName)) {
			driverClassName = this.embeddedDatabaseConnection.getDriverClassName();
		}
		if (!StringUtils.hasText(driverClassName)) {
			throw new DataSourceBeanCreationException(
					""Failed to determine a suitable driver class"", this,
					this.embeddedDatabaseConnection);
		}
		return driverClassName;
	}"
"@GuardedBy(""tasks"")
  private void saveRunningTasks()
  {
    final File restoreFile = getRestoreFile();
    final List<String> theTasks = new ArrayList<>();
    for (ForkingTaskRunnerWorkItem forkingTaskRunnerWorkItem : tasks.values()) {
      theTasks.add(forkingTaskRunnerWorkItem.getTaskId());
    }

    try {
      Files.createParentDirs(restoreFile);
      jsonMapper.writeValue(restoreFile, new TaskRestoreInfo(theTasks));
    }
    catch (Exception e) {
      log.warn(e, ""Failed to save tasks to restore file[%s]. Skipping this save."", restoreFile);
    }
  }"
"public static String hex(String x) {
		return EncodingUtils.hex(x.getBytes(StandardCharsets.UTF_8)).toUpperCase();
	}"
"public void parameterizeChannel(Channel channel, boolean globalDopChange,
									ExecutionMode exchangeMode, boolean breakPipeline) {

		// safety check. Fully replicated input must be preserved.
		if (channel.getSource().getGlobalProperties().isFullyReplicated() &&
				!(this.partitioning == PartitioningProperty.FULL_REPLICATION ||
					this.partitioning == PartitioningProperty.ANY_DISTRIBUTION))
		{
			throw new CompilerException(""Fully replicated input must be preserved "" +
					""and may not be converted into another global property."");
		}

		// if we request nothing, then we need no special strategy. forward, if the number of instances remains
		// the same, randomly repartition otherwise
		if (isTrivial() || this.partitioning == PartitioningProperty.ANY_DISTRIBUTION) {
			ShipStrategyType shipStrategy = globalDopChange ? ShipStrategyType.PARTITION_RANDOM :
																ShipStrategyType.FORWARD;

			DataExchangeMode em = DataExchangeMode.select(exchangeMode, shipStrategy, breakPipeline);
			channel.setShipStrategy(shipStrategy, em);
			return;
		}
		
		final GlobalProperties inGlobals = channel.getSource().getGlobalProperties();
		// if we have no global parallelism change, check if we have already compatible global properties
		if (!globalDopChange && isMetBy(inGlobals)) {
			DataExchangeMode em = DataExchangeMode.select(exchangeMode, ShipStrategyType.FORWARD, breakPipeline);
			channel.setShipStrategy(ShipStrategyType.FORWARD, em);
			return;
		}
		
		// if we fall through the conditions until here, we need to re-establish
		ShipStrategyType shipType;
		FieldList partitionKeys;
		boolean[] sortDirection;
		Partitioner<?> partitioner;

		switch (this.partitioning) {
			case FULL_REPLICATION:
				shipType = ShipStrategyType.BROADCAST;
				partitionKeys = null;
				sortDirection = null;
				partitioner = null;
				break;

			case ANY_PARTITIONING:
			case HASH_PARTITIONED:
				shipType = ShipStrategyType.PARTITION_HASH;
				partitionKeys = Utils.createOrderedFromSet(this.partitioningFields);
				sortDirection = null;
				partitioner = null;
				break;
			
			case RANGE_PARTITIONED:
				shipType = ShipStrategyType.PARTITION_RANGE;
				partitionKeys = this.ordering.getInvolvedIndexes();
				sortDirection = this.ordering.getFieldSortDirections();
				partitioner = null;

				if (this.dataDistribution != null) {
					channel.setDataDistribution(this.dataDistribution);
				}
				break;

			case FORCED_REBALANCED:
				shipType = ShipStrategyType.PARTITION_FORCED_REBALANCE;
				partitionKeys = null;
				sortDirection = null;
				partitioner = null;
				break;

			case CUSTOM_PARTITIONING:
				shipType = ShipStrategyType.PARTITION_CUSTOM;
				partitionKeys = Utils.createOrderedFromSet(this.partitioningFields);
				sortDirection = null;
				partitioner = this.customPartitioner;
				break;

			default:
				throw new CompilerException(""Invalid partitioning to create through a data exchange: ""
											+ this.partitioning.name());
		}

		DataExchangeMode exMode = DataExchangeMode.select(exchangeMode, shipType, breakPipeline);
		channel.setShipStrategy(shipType, partitionKeys, sortDirection, partitioner, exMode);
	}"
"public static Tuple2<String, Integer> getJobManagerAddress(Configuration configuration) throws ConfigurationException {

		final String hostname = configuration.getString(JobManagerOptions.ADDRESS);
		final int port = configuration.getInteger(JobManagerOptions.PORT);

		if (hostname == null) {
			throw new ConfigurationException(""Config parameter '"" + JobManagerOptions.ADDRESS +
				""' is missing (hostname/address of JobManager to connect to)."");
		}

		if (port <= 0 || port >= 65536) {
			throw new ConfigurationException(""Invalid value for '"" + JobManagerOptions.PORT +
				""' (port of the JobManager actor system) : "" + port +
				"".  it must be greater than 0 and less than 65536."");
		}

		return Tuple2.of(hostname, port);
	}"
"public ProviderInfo setStaticAttrs(Map<String, String> staticAttrs) {
        this.staticAttrs.clear();
        this.staticAttrs.putAll(staticAttrs);
        return this;
    }"
"@Override
	public void setEnvironment(ConfigurableEnvironment environment) {
		super.setEnvironment(environment);
		this.reader.setEnvironment(environment);
		this.scanner.setEnvironment(environment);
	}"
"public JavaType buildMapType(Class<? extends Map> mapClass, Class<?> keyClass, Class<?> valueClass) {
		return mapper.getTypeFactory().constructMapType(mapClass, keyClass, valueClass);
	}"
"public Class getReqClass(String service, String methodName) {

        String key = buildMethodKey(service, methodName);
        Class reqClass = requestClassCache.get(key);
        if (reqClass == null) {
            // 读取接口里的方法参数和返回值
            String interfaceClass = ConfigUniqueNameGenerator.getInterfaceName(service);
            Class clazz = ClassUtils.forName(interfaceClass, true);
            loadProtoClassToCache(key, clazz, methodName);
        }
        return requestClassCache.get(key);
    }"
"public int readInt(InputStream in) throws IOException {
        return ((byte) in.read() & 0xff) << 24
            | ((byte) in.read() & 0xff) << 16
            | ((byte) in.read() & 0xff) << 8
            | (byte) in.read() & 0xff;
    }"
"public void saveFingerprintAsFile(byte[] fingerprint, String filename) {

        FileOutputStream fileOutputStream;
        try {
            fileOutputStream = new FileOutputStream(filename);
            fileOutputStream.write(fingerprint);
            fileOutputStream.close();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }"
"@CheckForNull
    public static Boolean optBoolean(String name) {
        String v = getString(name);
        return v == null ? null : Boolean.parseBoolean(v);
    }"
"public static Type extractTypeFromLambda(
		Class<?> baseClass,
		LambdaExecutable exec,
		int[] lambdaTypeArgumentIndices,
		int paramLen,
		int baseParametersLen) {
		Type output = exec.getParameterTypes()[paramLen - baseParametersLen + lambdaTypeArgumentIndices[0]];
		for (int i = 1; i < lambdaTypeArgumentIndices.length; i++) {
			validateLambdaType(baseClass, output);
			output = extractTypeArgument(output, lambdaTypeArgumentIndices[i]);
		}
		validateLambdaType(baseClass, output);
		return output;
	}"
"public <T> T query(final String baseQuery, final ResultSetHandler<T> resultHandler,
      final Object... params)
      throws SQLException {
    try {
      return this.queryRunner.query(baseQuery, resultHandler, params);
    } catch (final SQLException ex) {
      // todo kunkun-tang: Retry logics should be implemented here.
      logger.error(""query failed"", ex);
      if (this.dbMetrics != null) {
        this.dbMetrics.markDBFailQuery();
      }
      throw ex;
    }
  }"
"@com.netflix.servo.annotations.Monitor(name = ""numOfRenewsInLastMin"",
            description = ""Number of total heartbeats received in the last minute"", type = DataSourceType.GAUGE)
    @Override
    public long getNumOfRenewsInLastMin() {
        return renewsLastMin.getCount();
    }"
"public Double getAvgDelayNumber() {
        Double avgDelayNumber = 0.0;
        if (items.size() != 0) {
            for (DelayStat item : items) {
                avgDelayNumber += item.getDelayNumber();
            }
            avgDelayNumber = avgDelayNumber / items.size();
        }
        return avgDelayNumber;
    }"
"public ConverterRegistry putCustom(Type type, Class<? extends Converter<?>> converterClass) {
		return putCustom(type, ReflectUtil.newInstance(converterClass));
	}"
"private static Map<Long, Long> parseAlert(String alert) {
        if (alert == null) {
            return null;
        }

        Map<Long, Long> alertMap = new HashMap<Long, Long>();
        String[] alerts = alert.split("","");

        for (int i = 0; i < alerts.length; i++) {
            String[] ncidAlert = alerts[i].split(""-"");

            alertMap.put(NumberUtils.toLong(ncidAlert[0], 0), NumberUtils.toLong(ncidAlert[1], 0));

            if (logger.isInfoEnabled()) {
                logger.info(ncidAlert[0] + "" : "" + ncidAlert[1]);
            }
        }

        return alertMap;
    }"
"public static INDArray activate(INDArray boundingBoxPriors, INDArray input) {
        return activate(boundingBoxPriors, input, LayerWorkspaceMgr.noWorkspaces());
    }"
"@WebMethod(name = ""config.xml"")
    public HttpResponse doConfigDotXml(StaplerRequest req) throws IOException {
        if (req.getMethod().equals(""GET"")) {
            // read
            checkPermission(READ);
            return new HttpResponse() {
                public void generateResponse(StaplerRequest req, StaplerResponse rsp, Object node) throws IOException, ServletException {
                    rsp.setContentType(""application/xml"");
                    View.this.writeXml(rsp.getOutputStream());
                }
            };
        }
        if (req.getMethod().equals(""POST"")) {
            // submission
            updateByXml(new StreamSource(req.getReader()));
            return HttpResponses.ok();
        }

        // huh?
        return HttpResponses.error(SC_BAD_REQUEST, ""Unexpected request method "" + req.getMethod());
    }"
"@View(name = ""by_throttle_params"", map = ""classpath:CouchDbAuditActionContext_by_throttle_params.js"")
    public List<CouchDbAuditActionContext> findByThrottleParams(final String remoteAddress, final String username, final String failureCode,
                                                                final String applicationCode, final LocalDateTime cutoffTime) {
        val view = createQuery(""by_throttle_params"").startKey(ComplexKey.of(remoteAddress, username, failureCode, applicationCode, cutoffTime))
            .endKey(ComplexKey.of(remoteAddress, username, failureCode, applicationCode, ""999999""));
        return db.queryView(view, CouchDbAuditActionContext.class);
    }"
"public DeweyNumber increase(int times) {
		int[] newDeweyNumber = Arrays.copyOf(deweyNumber, deweyNumber.length);
		newDeweyNumber[deweyNumber.length - 1] += times;

		return new DeweyNumber(newDeweyNumber);
	}"
"protected Boolean _hasPermission(@Nonnull Authentication a, Permission permission) {
        // ACL entries for this principal takes precedence
        Boolean b = hasPermission(new PrincipalSid(a),permission);
        if(LOGGER.isLoggable(FINER))
            LOGGER.finer(""hasPermission(PrincipalSID:""+a.getPrincipal()+"",""+permission+"")=>""+b);
        if(b!=null)
            return b;

        // after that, we check if the groups this principal belongs to
        // has any ACL entries.
        // here we are using GrantedAuthority as a group
        for(GrantedAuthority ga : a.getAuthorities()) {
            b = hasPermission(new GrantedAuthoritySid(ga),permission);
            if(LOGGER.isLoggable(FINER))
                LOGGER.finer(""hasPermission(GroupSID:""+ga.getAuthority()+"",""+permission+"")=>""+b);
            if(b!=null)
                return b;
        }

        // permissions granted to 'everyone' and 'anonymous' users are granted to everyone
        for (Sid sid : AUTOMATIC_SIDS) {
            b = hasPermission(sid,permission);
            if(LOGGER.isLoggable(FINER))
                LOGGER.finer(""hasPermission(""+sid+"",""+permission+"")=>""+b);
            if(b!=null)
                return b;
        }

        return null;
    }"
"protected X509CRL fetchX509CRLFromAttribute(final LdapAttribute aval) throws CertificateException, IOException, CRLException {
        if (aval != null && aval.isBinary()) {
            val val = aval.getBinaryValue();
            if (val == null || val.length == 0) {
                throw new CertificateException(""Empty attribute. Can not download CRL from ldap"");
            }
            val decoded64 = EncodingUtils.decodeBase64(val);
            if (decoded64 == null) {
                throw new CertificateException(""Could not decode the attribute value to base64"");
            }
            LOGGER.debug(""Retrieved CRL from ldap as byte array decoded in base64. Fetching..."");
            return super.fetch(new ByteArrayResource(decoded64));
        }
        throw new CertificateException(""Attribute not found. Can not retrieve CRL"");
    }"
"public static <TERM> Map<TERM, Double> idf(Iterable<Iterable<TERM>> documentVocabularies,
                                               boolean smooth, boolean addOne)
    {
        Map<TERM, Integer> df = new HashMap<TERM, Integer>();
        int d = smooth ? 1 : 0;
        int a = addOne ? 1 : 0;
        int n = d;
        for (Iterable<TERM> documentVocabulary : documentVocabularies)
        {
            n += 1;
            for (TERM term : documentVocabulary)
            {
                Integer t = df.get(term);
                if (t == null) t = d;
                df.put(term, t + 1);
            }
        }
        Map<TERM, Double> idf = new HashMap<TERM, Double>();
        for (Map.Entry<TERM, Integer> e : df.entrySet())
        {
            TERM term = e.getKey();
            double f = e.getValue();
            idf.put(term, Math.log(n / f) + a);
        }
        return idf;
    }"
"public RegisteredServiceDocument get(final long id) {
        try {
            return this.get(String.valueOf(id));
        } catch (final DocumentNotFoundException e) {
            LOGGER.debug(""Service [{}] not found. [{}]"", id, e.getMessage());
            return null;
        }
    }"
"public LongShapeDescriptor asDataType(DataType dataType){
        long extras = 0L;
        extras = ArrayOptionsHelper.setOptionBit(extras, dataType);
        if(isEmpty()){
            extras = ArrayOptionsHelper.setOptionBit(extras, ArrayType.EMPTY);
        }
        return new LongShapeDescriptor(shape, stride, offset, ews, order, extras);
    }"
"@SneakyThrows
    protected SAMLObject encryptAssertion(final Assertion assertion,
                                          final HttpServletRequest request,
                                          final HttpServletResponse response,
                                          final SamlRegisteredService service,
                                          final SamlRegisteredServiceServiceProviderMetadataFacade adaptor) throws SamlException {

        if (service.isEncryptAssertions()) {
            LOGGER.debug(""SAML service [{}] requires assertions to be encrypted"", adaptor.getEntityId());
            return samlResponseBuilderConfigurationContext.getSamlObjectEncrypter().encode(assertion, service, adaptor);
        }
        LOGGER.debug(""SAML registered service [{}] does not require assertions to be encrypted"", adaptor.getEntityId());
        return assertion;

    }"
"public static void writeObjectToFile(String path, Object toWrite, Configuration hadoopConfig) throws IOException {
        FileSystem fileSystem = FileSystem.get(hadoopConfig);
        try (BufferedOutputStream bos = new BufferedOutputStream(fileSystem.create(new Path(path)))) {
            ObjectOutputStream oos = new ObjectOutputStream(bos);
            oos.writeObject(toWrite);
        }
    }"
"public static Set<Policy> policies(Config config) {
    FullySegmentedWindowTinyLfuSettings settings = new FullySegmentedWindowTinyLfuSettings(config);
    return settings.percentMain().stream()
        .map(percentMain -> new FullySegmentedWindowTinyLfuPolicy(percentMain, settings))
        .collect(toSet());
  }"
"void handleMBeans(final HikariPool hikariPool, final boolean register)
   {
      if (!config.isRegisterMbeans()) {
         return;
      }

      try {
         final MBeanServer mBeanServer = ManagementFactory.getPlatformMBeanServer();

         final ObjectName beanConfigName = new ObjectName(""com.zaxxer.hikari:type=PoolConfig ("" + poolName + "")"");
         final ObjectName beanPoolName = new ObjectName(""com.zaxxer.hikari:type=Pool ("" + poolName + "")"");
         if (register) {
            if (!mBeanServer.isRegistered(beanConfigName)) {
               mBeanServer.registerMBean(config, beanConfigName);
               mBeanServer.registerMBean(hikariPool, beanPoolName);
            } else {
               logger.error(""{} - JMX name ({}) is already registered."", poolName, poolName);
            }
         }
         else if (mBeanServer.isRegistered(beanConfigName)) {
            mBeanServer.unregisterMBean(beanConfigName);
            mBeanServer.unregisterMBean(beanPoolName);
         }
      }
      catch (Exception e) {
         logger.warn(""{} - Failed to {} management beans."", poolName, (register ? ""register"" : ""unregister""), e);
      }
   }"
"private static void encodeBinary(byte[] bytes,
                                   int startpos,
                                   int count,
                                   int startmode,
                                   StringBuilder sb) {
    if (count == 1 && startmode == TEXT_COMPACTION) {
      sb.append((char) SHIFT_TO_BYTE);
    } else {
      if ((count % 6) == 0) {
        sb.append((char) LATCH_TO_BYTE);
      } else {
        sb.append((char) LATCH_TO_BYTE_PADDED);
      }
    }

    int idx = startpos;
    // Encode sixpacks
    if (count >= 6) {
      char[] chars = new char[5];
      while ((startpos + count - idx) >= 6) {
        long t = 0;
        for (int i = 0; i < 6; i++) {
          t <<= 8;
          t += bytes[idx + i] & 0xff;
        }
        for (int i = 0; i < 5; i++) {
          chars[i] = (char) (t % 900);
          t /= 900;
        }
        for (int i = chars.length - 1; i >= 0; i--) {
          sb.append(chars[i]);
        }
        idx += 6;
      }
    }
    //Encode rest (remaining n<5 bytes if any)
    for (int i = idx; i < startpos + count; i++) {
      int ch = bytes[i] & 0xff;
      sb.append((char) ch);
    }
  }"
"public void build(Trie trie) {
        ProgressLog.begin(""building "" + (compact ? ""compact"" : ""sparse"") + "" trie"");
        baseBuffer = IntBuffer.allocate(BASE_CHECK_INITIAL_SIZE);
        baseBuffer.put(0, 1);
        checkBuffer = IntBuffer.allocate(BASE_CHECK_INITIAL_SIZE);
        tailBuffer = CharBuffer.allocate(TAIL_INITIAL_SIZE);
        add(-1, 0, trie.getRoot());
        reportUtilizationRate();
        ProgressLog.end();
    }"
"public static File convert(File file, Charset srcCharset, Charset destCharset) {
		final String str = FileUtil.readString(file, srcCharset);
		return FileUtil.writeString(str, file, destCharset);
	}"
"@Override
	public void close() throws IOException {
		try {
			if (session != null) {
				session.close();
			}
		} catch (Exception e) {
			LOG.error(""Error while closing session."", e);
		}

		try {
			if (cluster != null) {
				cluster.close();
			}
		} catch (Exception e) {
			LOG.error(""Error while closing cluster."", e);
		}
	}"
"public static void copy(Path sourcePath, Path targetPath, boolean executable) throws IOException {
		// we unwrap the file system to get raw streams without safety net
		FileSystem sFS = FileSystem.getUnguardedFileSystem(sourcePath.toUri());
		FileSystem tFS = FileSystem.getUnguardedFileSystem(targetPath.toUri());
		if (!tFS.exists(targetPath)) {
			if (sFS.getFileStatus(sourcePath).isDir()) {
				internalCopyDirectory(sourcePath, targetPath, executable, sFS, tFS);
			} else {
				internalCopyFile(sourcePath, targetPath, executable, sFS, tFS);
			}
		}
	}"
"public long rowsWithNa() {
    if( _rowsWithNa!=-1 ) return _rowsWithNa;
    String x = String.format(""(na.omit %s)"", _fr._key);
    Val res = Rapids.exec(x);
    Frame f = res.getFrame();
    long cnt = _fr.numRows()  -  f.numRows();
    f.delete();
    return (_rowsWithNa=cnt);

  }"
"private static void visitColumn(SQLExpr expr, FieldItem fieldItem) {
        if (expr instanceof SQLIdentifierExpr) {
            // 无owner
            SQLIdentifierExpr identifierExpr = (SQLIdentifierExpr) expr;
            if (fieldItem.getFieldName() == null) {
                fieldItem.setFieldName(identifierExpr.getName());
                fieldItem.setExpr(identifierExpr.toString());
            }
            ColumnItem columnItem = new ColumnItem();
            columnItem.setColumnName(identifierExpr.getName());
            fieldItem.getOwners().add(null);
            fieldItem.addColumn(columnItem);
        } else if (expr instanceof SQLPropertyExpr) {
            // 有owner
            SQLPropertyExpr sqlPropertyExpr = (SQLPropertyExpr) expr;
            if (fieldItem.getFieldName() == null) {
                fieldItem.setFieldName(sqlPropertyExpr.getName());
                fieldItem.setExpr(sqlPropertyExpr.toString());
            }
            fieldItem.getOwners().add(sqlPropertyExpr.getOwnernName());
            ColumnItem columnItem = new ColumnItem();
            columnItem.setColumnName(sqlPropertyExpr.getName());
            columnItem.setOwner(sqlPropertyExpr.getOwnernName());
            fieldItem.addColumn(columnItem);
        } else if (expr instanceof SQLMethodInvokeExpr) {
            SQLMethodInvokeExpr methodInvokeExpr = (SQLMethodInvokeExpr) expr;
            fieldItem.setMethod(true);
            for (SQLExpr sqlExpr : methodInvokeExpr.getArguments()) {
                visitColumn(sqlExpr, fieldItem);
            }
        } else if (expr instanceof SQLBinaryOpExpr) {
            SQLBinaryOpExpr sqlBinaryOpExpr = (SQLBinaryOpExpr) expr;
            fieldItem.setBinaryOp(true);
            visitColumn(sqlBinaryOpExpr.getLeft(), fieldItem);
            visitColumn(sqlBinaryOpExpr.getRight(), fieldItem);
        } else if (expr instanceof SQLCaseExpr) {
            SQLCaseExpr sqlCaseExpr = (SQLCaseExpr) expr;
            fieldItem.setMethod(true);
            sqlCaseExpr.getItems().forEach(item-> visitColumn(item.getConditionExpr(), fieldItem));
        }
    }"
"final int helpJoinOnce(WorkQueue joiner, ForkJoinTask<?> task) {
        int s;
        while ((s = task.status) >= 0 &&
               (joiner.isEmpty() ?
                tryHelpStealer(joiner, task) :
                joiner.tryRemoveAndExec(task)) != 0)
            ;
        return s;
    }"
"@PublicEvolving
	public <R> SingleOutputStreamOperator<R> process(ProcessAllWindowFunction<T, R, W> function) {
		String callLocation = Utils.getCallLocationName();
		function = input.getExecutionEnvironment().clean(function);
		TypeInformation<R> resultType = getProcessAllWindowFunctionReturnType(function, getInputType());
		return apply(new InternalIterableProcessAllWindowFunction<>(function), resultType, callLocation);
	}"
"public final boolean equalsFields(int[] positions, Value[] searchValues, Value[] deserializationHolders) {
		for (int i = 0; i < positions.length; i++) {
			final Value v = getField(positions[i], deserializationHolders[i]);
			if (v == null || (!v.equals(searchValues[i]))) {
				return false;
			}
		}
		return true;
	}"
"public static int getMinY(Graphics g) {
		// 获取允许文字最小高度
		FontMetrics metrics = null;
		try {
			metrics = g.getFontMetrics();
		} catch (Exception e) {
			// 此处报告bug某些情况下会抛出IndexOutOfBoundsException，在此做容错处理
		}
		int minY;
		if (null != metrics) {
			minY = metrics.getAscent() - metrics.getLeading() - metrics.getDescent();
		} else {
			minY = -1;
		}
		return minY;
	}"
"private <T> Sequence<T> run(
      final QueryPlus<T> queryPlus,
      final Map<String, Object> responseContext,
      final UnaryOperator<TimelineLookup<String, ServerSelector>> timelineConverter
  )
  {
    return new SpecificQueryRunnable<>(queryPlus, responseContext).run(timelineConverter);
  }"
"public static long[] sortAndFilterThreadIdsByValue(LongObjectMap map, int threadLimit) {
		int max = Math.min(threadLimit, map.size());
		List<Map.Entry> list = new LinkedList(map.entrySet());
		Collections.sort(list, new Comparator() {
			@Override
			public int compare(Object o1, Object o2) {
				return ((Comparable) ((Map.Entry) (o2)).getValue()).compareTo(((Map.Entry) (o1)).getValue());
			}
		});

		long[] topTidArray = new long[max];
		int i = 0;
		for (Map.Entry entry : list) {
			topTidArray[i] = (Long) entry.getKey();
			if (++i >= max) {
				break;
			}
		}

		return topTidArray;
	}"
"public static void createHtmlSequencePlotFile(String title, Schema schema, List<List<Writable>> sequence,
                    File output) throws Exception {
        String s = createHtmlSequencePlots(title, schema, sequence);
        FileUtils.writeStringToFile(output, s, StandardCharsets.UTF_8);
    }"
"public static NFSFileVec make(File f, Futures fs) {
    if( !f.exists() ) throw new IllegalArgumentException(""File not found: ""+f.toString());
    long size = f.length();
    Key k = Vec.newKey(PersistNFS.decodeFile(f));
    // Insert the top-level FileVec key into the store
    NFSFileVec nfs = new NFSFileVec(k,size);
    DKV.put(k,nfs,fs);
    return nfs;
  }"
"public static void putInitialHttpRequestPostParameters(final RequestContext context) {
        val request = getHttpServletRequestFromExternalWebflowContext(context);
        context.getFlashScope().put(""httpRequestInitialPostParameters"", request.getParameterMap());
    }"
"public  String sessionOptionsToJson() {
        try {
            return JsonFormat.printer().print(protoBufConfigProto);
        } catch (Exception e) {
            e.printStackTrace();
        }

        return null;
    }"
"@Override
    @SuppressWarnings(""unchecked"")
    protected List<Object> run() throws Exception {
        Object[] args = toArgs(getCollapsedRequests());
        return (List) process(args);
    }"
"public static @CheckForNull String hashify(String spec) {
        if (spec.contains(""H"")) {
            // if someone is already using H, presumably he knows what it is, so a warning is likely false positive
            return null;
        } else if (spec.startsWith(""*/"")) {// ""*/15 ...."" (every N minutes) to hash
            return ""H"" + spec.substring(1);
        } else if (spec.matches(""\\d+ .+"")) {// ""0 ..."" (certain minute) to hash
            return ""H "" + spec.substring(spec.indexOf(' ') + 1);
        } else {
            Matcher m = Pattern.compile(""0(,(\\d+)(,\\d+)*)( .+)"").matcher(spec);
            if (m.matches()) { // 0,15,30,45 to H/15
                int period = Integer.parseInt(m.group(2));
                if (period > 0) {
                    StringBuilder b = new StringBuilder();
                    for (int i = period; i < 60; i += period) {
                        b.append(',').append(i);
                    }
                    if (b.toString().equals(m.group(1))) {
                        return ""H/"" + period + m.group(4);
                    }
                }
            }
            return null;
        }
    }"
"public static BufferedImage read(InputStream imageStream) {
		try {
			return ImageIO.read(imageStream);
		} catch (IOException e) {
			throw new IORuntimeException(e);
		}
	}"
"public void addApplication(Application app) {
        appNameApplicationMap.put(app.getName().toUpperCase(Locale.ROOT), app);
        addInstancesToVIPMaps(app, this.virtualHostNameAppMap, this.secureVirtualHostNameAppMap);
        applications.add(app);
    }"
"@Override
    public void update(NDArrayMessage message) {
        updateStorage.addUpdate(message);
        INDArray arr = message.getArr();
        //of note for ndarrays
        int[] dimensions = message.getDimensions();
        boolean whole = dimensions.length == 1 && dimensions[0] == -1;

        if (!whole)
            partialUpdate(arr, ndArrayHolder.get(), message.getIndex(), dimensions);
        else
            update(arr, ndArrayHolder.get());
    }"
"public static boolean varyMatches(
      Response cachedResponse, Headers cachedRequest, Request newRequest) {
    for (String field : varyFields(cachedResponse)) {
      if (!Objects.equals(cachedRequest.values(field), newRequest.headers(field))) return false;
    }
    return true;
  }"
"@Override
    public void putStaticInfo(Persistable staticInfo) {
        List<StatsStorageEvent> sses = checkStorageEvents(staticInfo);
        if (!sessionIDs.contains(staticInfo.getSessionID())) {
            sessionIDs.add(staticInfo.getSessionID());
        }
        SessionTypeWorkerId id = new SessionTypeWorkerId(staticInfo.getSessionID(), staticInfo.getTypeID(),
                        staticInfo.getWorkerID());

        this.staticInfo.put(id, staticInfo);
        db.commit(); //For write ahead log: need to ensure that we persist all data to disk...
        StatsStorageEvent sse = null;
        if (!listeners.isEmpty())
            sse = new StatsStorageEvent(this, StatsStorageListener.EventType.PostStaticInfo, staticInfo.getSessionID(),
                            staticInfo.getTypeID(), staticInfo.getWorkerID(), staticInfo.getTimeStamp());
        for (StatsStorageListener l : listeners) {
            l.notify(sse);
        }

        notifyListeners(sses);
    }"
"private static Class<?> translateFromPrimitive(Class<?> primitive) {
        if (!primitive.isPrimitive()) {
            return primitive;
        }

        if (Boolean.TYPE.equals(primitive)) {
            return Boolean.class;
        }
        if (Character.TYPE.equals(primitive)) {
            return Character.class;
        }
        if (Byte.TYPE.equals(primitive)) {
            return Byte.class;
        }
        if (Short.TYPE.equals(primitive)) {
            return Short.class;
        }
        if (Integer.TYPE.equals(primitive)) {
            return Integer.class;
        }
        if (Long.TYPE.equals(primitive)) {
            return Long.class;
        }
        if (Float.TYPE.equals(primitive)) {
            return Float.class;
        }
        if (Double.TYPE.equals(primitive)) {
            return Double.class;
        }

        throw new RuntimeException(""Error translating type:"" + primitive);
    }"
"@Override
    public void clear() {
        final Segment<K,V>[] segments = this.segments;
        for (int j = 0; j < segments.length; ++j) {
            Segment<K,V> s = segmentAt(segments, j);
            if (s != null) {
              s.clear();
            }
        }
    }"
"public static LongStream uniform(int lowerBound, int upperBound, int events) {
    return generate(new UniformLongGenerator(lowerBound, upperBound), events);
  }"
"public void evaluate(DataSetIterator iterator, String outputVariable, IEvaluation... evaluations) {
        Preconditions.checkArgument(evaluations != null && evaluations.length > 0, ""No evaluations were passed to the evaluate method"");
        evaluate(new MultiDataSetIteratorAdapter(iterator), Collections.singletonMap(outputVariable, Arrays.asList(evaluations)),
                Collections.singletonMap(outputVariable, 0));
    }"
"private static void appendDigits(final Appendable buffer, final int value) throws IOException {
		buffer.append((char) (value / 10 + '0'));
		buffer.append((char) (value % 10 + '0'));
	}"
"@Nonnull
	public final TypeSerializer<T> currentSchemaSerializer() {
		if (registeredSerializer != null) {
			checkState(
				!isRegisteredWithIncompatibleSerializer,
				""Unable to provide a serializer with the current schema, because the restored state was "" +
					""registered with a new serializer that has incompatible schema."");

			return registeredSerializer;
		}

		// if we are not yet registered with a new serializer,
		// we can just use the restore serializer to read / write the state.
		return previousSchemaSerializer();
	}"
"private ObjectNode convertRow(ObjectNode reuse, RowTypeInfo info, Row row) {
		if (reuse == null) {
			reuse = mapper.createObjectNode();
		}
		final String[] fieldNames = info.getFieldNames();
		final TypeInformation<?>[] fieldTypes = info.getFieldTypes();

		// validate the row
		if (row.getArity() != fieldNames.length) {
			throw new IllegalStateException(String.format(
				""Number of elements in the row '%s' is different from number of field names: %d"", row, fieldNames.length));
		}

		for (int i = 0; i < fieldNames.length; i++) {
			final String name = fieldNames[i];

			final JsonNode fieldConverted = convert(reuse, reuse.get(name), fieldTypes[i], row.getField(i));
			reuse.set(name, fieldConverted);
		}

		return reuse;
	}"
"@Override
  @Nullable
  public Object startJob()
  {
    final Object metadata = appenderator.startJob();
    if (metadata != null) {
      throw new ISE(""Metadata should be null because BatchAppenderatorDriver never persists it"");
    }
    return null;
  }"
"@Override
    public Record nextRecord() {
        Record next = sequenceRecordReader.nextRecord();
        next.setRecord(transformProcess.execute(next.getRecord()));
        return next;
    }"
"protected ProcessedClaim createProcessedClaim(final Claim requestClaim, final ClaimsParameters parameters) {
        val claim = new ProcessedClaim();
        claim.setClaimType(createProcessedClaimType(requestClaim, parameters));
        claim.setIssuer(this.issuer);
        claim.setOriginalIssuer(this.issuer);
        claim.setValues(requestClaim.getValues());
        return claim;
    }"
"@Override
    public void onNDArrayPartial(INDArray arr, long idx, int... dimensions) {
        INDArray get = this.arr.get();
        get.tensorAlongDimension((int) idx, dimensions).assign(arr);

    }"
"public BitArray getRow(int y, BitArray row) {
    if (row == null || row.getSize() < width) {
      row = new BitArray(width);
    } else {
      row.clear();
    }
    int offset = y * rowSize;
    for (int x = 0; x < rowSize; x++) {
      row.setBulk(x * 32, bits[offset + x]);
    }
    return row;
  }"
"public Collection<String> values(String group) {
		group = StrUtil.nullToEmpty(group).trim();
		readLock.lock();
		try {
			final LinkedHashMap<String, String> valueMap = this.get(group);
			if (MapUtil.isNotEmpty(valueMap)) {
				return valueMap.values();
			}
		} finally {
			readLock.unlock();
		}
		return Collections.emptyList();
	}"
"@Override
	@Nullable
	public String getMetricQueryServiceGatewayRpcAddress() {
		if (queryService != null) {
			return queryService.getSelfGateway(MetricQueryServiceGateway.class).getAddress();
		} else {
			return null;
		}
	}"
"private static synchronized SmartForest<List<String>> init(String key, KV<String, SmartForest<List<String>>> kv,
                    boolean reload) {

        SmartForest<List<String>> forest = kv.getV();

        if (forest != null) {
            if (reload) {
                forest.clear();
            } else {
                return forest;
            }
        } else {
            forest = new SmartForest<>();
        }

        LOG.debug(""begin init synonyms "" + kv.getK());
        long start = System.currentTimeMillis();

        try (BufferedReader reader = IOUtil.getReader(PathToStream.stream(kv.getK()), IOUtil.UTF8)) {
            String temp = null;
            while ((temp = reader.readLine()) != null) {
                if (StringUtil.isBlank(temp)) {
                    continue;
                }
                String[] split = temp.split(""\t"");

                List<String> list = new ArrayList<>();
                for (String word : split) {
                    if (StringUtil.isBlank(word)) {
                        continue;
                    }
                    list.add(word);
                }

                if (split.length <= 1) {
                    LOG.warn(temp + "" in synonymsLibrary not in to library !"");
                    continue;
                }

                for (int i = 0; i < split.length; i++) {
                    forest.add(split[i], list);
                }
            }
            kv.setV(forest);
            LOG.info(""load synonyms use time:"" + (System.currentTimeMillis() - start) + "" path is : "" + kv.getK());
            return forest;
        } catch (Exception e) {
            LOG.error(""Init synonyms library error :"" + e.getMessage() + "", path: "" + kv.getK());
            SYNONYMS.remove(key);
            return null;
        }
    }"
"public static int toJavacModifier(AccessLevel accessLevel) {
		switch (accessLevel) {
		case MODULE:
		case PACKAGE:
			return 0;
		default:
		case PUBLIC:
			return Flags.PUBLIC;
		case NONE:
		case PRIVATE:
			return Flags.PRIVATE;
		case PROTECTED:
			return Flags.PROTECTED;
		}
	}"
"public static Slice serialize(Geometry geometry)
    {
        requireNonNull(geometry, ""input is null"");
        DynamicSliceOutput output = new DynamicSliceOutput(100);
        writeGeometry(geometry, output);
        return output.slice();
    }"
"public void pointTo(Object baseObject, long baseOffset, int sizeInBytes) {
    assert numFields >= 0 : ""numFields ("" + numFields + "") should >= 0"";
    assert sizeInBytes % 8 == 0 : ""sizeInBytes ("" + sizeInBytes + "") should be a multiple of 8"";
    this.baseObject = baseObject;
    this.baseOffset = baseOffset;
    this.sizeInBytes = sizeInBytes;
  }"
"public String toHtml(MemoryUsage usage) {
        if(usage.availableSwapSpace==-1)
            return ""N/A"";

       String humanReadableSpace = Functions.humanReadableByteSize(usage.availableSwapSpace);
       
        long free = usage.availableSwapSpace;
        free/=1024L;   // convert to KB
        free/=1024L;   // convert to MB
        if(free>256 || usage.totalSwapSpace<usage.availableSwapSpace*5)
            return humanReadableSpace; // if we have more than 256MB free or less than 80% filled up, it's OK

        // Otherwise considered dangerously low.
        return Util.wrapToErrorSpan(humanReadableSpace);
    }"
"protected void interruptThread() {
        Thread currentThread = thread;
        if (currentThread == null) {
            interrupted = true;
        } else {
            currentThread.interrupt();
        }
    }"
"public int numChars() {
		ensureMaterialized();
		if (inFirstSegment()) {
			int len = 0;
			for (int i = 0; i < sizeInBytes; i += numBytesForFirstByte(getByteOneSegment(i))) {
				len++;
			}
			return len;
		} else {
			return numCharsSlow();
		}
	}"
"public boolean containsColumn(final String tableName, final String column) {
        return containsTable(tableName) && tables.get(tableName).getColumns().keySet().contains(column.toLowerCase());
    }"
"public final void writeAndRemoveAll(ChannelHandlerContext ctx) {
        decrementReadableBytes(readableBytes);
        Throwable pending = null;
        ByteBuf previousBuf = null;
        for (;;) {
            Object entry = bufAndListenerPairs.poll();
            try {
                if (entry == null) {
                    if (previousBuf != null) {
                        ctx.write(previousBuf, ctx.voidPromise());
                    }
                    break;
                }

                if (entry instanceof ByteBuf) {
                    if (previousBuf != null) {
                        ctx.write(previousBuf, ctx.voidPromise());
                    }
                    previousBuf = (ByteBuf) entry;
                } else if (entry instanceof ChannelPromise) {
                    ctx.write(previousBuf, (ChannelPromise) entry);
                    previousBuf = null;
                } else {
                    ctx.write(previousBuf).addListener((ChannelFutureListener) entry);
                    previousBuf = null;
                }
            } catch (Throwable t) {
                if (pending == null) {
                    pending = t;
                } else {
                    logger.info(""Throwable being suppressed because Throwable {} is already pending"", pending, t);
                }
            }
        }
        if (pending != null) {
            throw new IllegalStateException(pending);
        }
    }"
"public <T extends IEvaluation> Map<Integer, T[]> evaluate(MultiDataSetIterator iterator, Map<Integer,T[]> evaluations){
        try{
            return doEvaluationHelper(iterator, evaluations);
        } catch (OutOfMemoryError e){
            CrashReportingUtil.writeMemoryCrashDump(this, e);
            throw e;
        }
    }"
"public static void putServiceOriginalUrlIntoRequestScope(final RequestContext requestContext, final WebApplicationService service) {
        requestContext.getRequestScope().put(""originalUrl"", service.getOriginalUrl());
    }"
"public static String sha512(final String data) {
        return digest(MessageDigestAlgorithms.SHA_512, data.getBytes(StandardCharsets.UTF_8));
    }"
"public static String notContain(String textToSearch, String substring) throws IllegalArgumentException {
		return notContain(textToSearch, substring, ""[Assertion failed] - this String argument must not contain the substring [{}]"", substring);
	}"
"private static void renderException(final Map model, final HttpServletResponse response) {
        response.setStatus(HttpServletResponse.SC_BAD_REQUEST);
        model.put(""status"", HttpServletResponse.SC_BAD_REQUEST);
        render(model, response);
    }"
"public void writeIntLenenc(final long value) {
        if (value < 0xfb) {
            byteBuf.writeByte((int) value);
            return;
        }
        if (value < Math.pow(2, 16)) {
            byteBuf.writeByte(0xfc);
            byteBuf.writeShortLE((int) value);
            return;
        }
        if (value < Math.pow(2, 24)) {
            byteBuf.writeByte(0xfd);
            byteBuf.writeMediumLE((int) value);
            return;
        }
        byteBuf.writeByte(0xfe);
        byteBuf.writeLongLE(value);
    }"
"public Set<String> subprotocols() {
        Set<String> ret = new LinkedHashSet<String>();
        Collections.addAll(ret, subprotocols);
        return ret;
    }"
"public void doPython(StaplerRequest req, StaplerResponse rsp) throws IOException, ServletException {
        setHeaders(rsp);
        rsp.serveExposedBean(req,bean, Flavor.PYTHON);
    }"
"private Collection<String> getEIPsFromServiceUrls(List<String> ec2Urls) {
        List<String> returnedUrls = new ArrayList<String>();
        String region = clientConfig.getRegion();
        String regionPhrase = """";
        if (!US_EAST_1.equals(region)) {
            regionPhrase = ""."" + region;
        }
        for (String cname : ec2Urls) {
            int beginIndex = cname.indexOf(""ec2-"");

            if (-1 < beginIndex) {
                // CNAME contains ""ec2-""
                int endIndex = cname.indexOf(regionPhrase + "".compute"");
                String eipStr = cname.substring(beginIndex + 4, endIndex);
                String eip = eipStr.replaceAll(""\\-"", ""."");
                returnedUrls.add(eip);
            }
            
            // Otherwise, if CNAME doesn't contain, do nothing.
            // Handle case where there are no cnames containing ""ec2-"". Reasons include:
            //  Systems without public addresses - purely attached to corp lan via AWS Direct Connect
            //  Use of EC2 network adapters that are attached to an instance after startup
        }
        return returnedUrls;
    }"
"public static PublicKey generatePublicKey(String algorithm, KeySpec keySpec) {
		if (null == keySpec) {
			return null;
		}
		algorithm = getAlgorithmAfterWith(algorithm);
		try {
			return getKeyFactory(algorithm).generatePublic(keySpec);
		} catch (Exception e) {
			throw new CryptoException(e);
		}
	}"
"private HttpSession getMatchingHttpSession(List<HttpCookie> cookies, final HttpSessionTokensSet siteTokens) {
		Collection<HttpSession> sessionsCopy;
		synchronized (sessions) {
			sessionsCopy = new ArrayList<>(sessions);
		}
		return CookieBasedSessionManagementHelper.getMatchingHttpSession(sessionsCopy, cookies, siteTokens);
	}"
"@Override
	public void characters(char[] ch, int start, int length) throws SAXException {
		// 得到单元格内容的值
		lastContent = lastContent.concat(new String(ch, start, length));
	}"
"public SDVariable bernoulli(String name, double p, long... shape) {
        SDVariable ret = f().randomBernoulli(p, shape);
        return updateVariableNameAndReference(ret, name);
    }"
"@Override
  public Object get(final ByteBuffer buf, final int position)
  {
    final WritableMemory mem = WritableMemory.wrap(buf, ByteOrder.LITTLE_ENDIAN);
    final WritableMemory region = mem.writableRegion(position, maxIntermediateSize);
    final Lock lock = stripedLock.getAt(ArrayOfDoublesSketchBuildBufferAggregator.lockIndex(position)).readLock();
    lock.lock();
    try {
      final ArrayOfDoublesUnion union = ArrayOfDoublesSketches.wrapUnion(region);
      return union.getResult();
    }
    finally {
      lock.unlock();
    }
  }"
"protected Set<Event> getResolvedEventsAsAttribute(final RequestContext context) {
        return context.getAttributes().get(RESOLVED_AUTHENTICATION_EVENTS, Set.class);
    }"
"public List<List<List<String>>> getRecordsAsString() {
        if(records == null)
            Collections.emptyList();
        List<List<List<String>>> ret = new ArrayList<>(records.size());
        for(List<BatchCSVRecord> record : records) {
            List<List<String>> add = new ArrayList<>();
            for(BatchCSVRecord batchCSVRecord : record) {
                for (SingleCSVRecord singleCSVRecord : batchCSVRecord.getRecords()) {
                    add.add(singleCSVRecord.getValues());
                }
            }

            ret.add(add);
        }

        return ret;
    }"
"private URL getResourceFromLocation(String name, String altName, File location) {
		if (location.isDirectory()) {
			try {
				if (altName != null) {
					File f = new File(location, altName);
					if (f.isFile() && f.canRead()) return f.toURI().toURL();
				}
				
				File f = new File(location, name);
				if (f.isFile() && f.canRead()) return f.toURI().toURL();
				return null;
			} catch (MalformedURLException e) {
				return null;
			}
		}
		
		if (!location.isFile() || !location.canRead()) return null;
		
		File absoluteFile; {
			try {
				absoluteFile = location.getCanonicalFile();
			} catch (Exception e) {
				absoluteFile = location.getAbsoluteFile();
			}
		}
		Set<String> jarContents = getOrMakeJarListing(absoluteFile.getAbsolutePath());
		
		String absoluteUri = absoluteFile.toURI().toString();
		
		try {
			if (jarContents.contains(altName)) {
				return new URI(""jar:"" + absoluteUri + ""!/"" + altName).toURL();
			}
		} catch (Exception ignore) {
			// intentional fallthrough
		}
		
		try {
			if (jarContents.contains(name)) {
				return new URI(""jar:"" + absoluteUri + ""!/"" + name).toURL();
			}
		} catch(Exception ignore) {
			// intentional fallthrough
		}
		
		return null;
	}"
"public static Method getMethodByNameIgnoreCase(Class<?> clazz, String methodName) throws SecurityException {
		return getMethodByName(clazz, true, methodName);
	}"
"private Object[] convertToSingleElementArray(Object value) {
		final Object[] singleElementArray = ArrayUtil.newArray(targetComponentType, 1);
		singleElementArray[0] = ConverterRegistry.getInstance().convert(targetComponentType, value);
		return singleElementArray;
	}"
"private static Date parse(String dateStr, DateParser parser) {
		Assert.notNull(parser, ""Parser or DateFromat must be not null !"");
		Assert.notBlank(dateStr, ""Date String must be not blank !"");
		try {
			return parser.parse(dateStr);
		} catch (Exception e) {
			throw new DateException(""Parse [{}] with format [{}] error!"", dateStr, parser.getPattern(), e);
		}
	}"
"public static <K, V> Map<K, List<V>> toListMap(Iterable<? extends Map<K, V>> mapList) {
		return MapUtil.toListMap(mapList);
	}"
"public static String [] getTLDEntries(DomainValidator.ArrayType table) {
        final String[] array;
        switch(table) {
            case COUNTRY_CODE_MINUS:
                array = countryCodeTLDsMinus;
                break;
            case COUNTRY_CODE_PLUS:
                array = countryCodeTLDsPlus;
                break;
            case GENERIC_MINUS:
                array = genericTLDsMinus;
                break;
            case GENERIC_PLUS:
                array = genericTLDsPlus;
                break;
            case GENERIC_RO:
                array = GENERIC_TLDS;
                break;
            case COUNTRY_CODE_RO:
                array = COUNTRY_CODE_TLDS;
                break;
            case INFRASTRUCTURE_RO:
                array = INFRASTRUCTURE_TLDS;
                break;
            case LOCAL_RO:
                array = LOCAL_TLDS;
                break;
            default:
                throw new IllegalArgumentException(""Unexpected enum value: "" + table);
        }
        return Arrays.copyOf(array, array.length); // clone the array
    }"
"private static int parseNanos(long serialized)
    {
        int zeros = ((int) serialized) & 0b111;
        int result = (int) (serialized >>> 3);
        if (zeros != 0) {
            for (int i = 0; i <= zeros; ++i) {
                result *= 10;
            }
        }
        return result;
    }"
"public Collection<String> getActualDatasourceNames() {
        Collection<String> result = new LinkedHashSet<>(actualDataNodes.size());
        for (DataNode each : actualDataNodes) {
            result.add(each.getDataSourceName());
        }
        return result;
    }"
"public void initialize(InputSplit split, ImageTransform imageTransform) throws IOException {
        this.imageLoader = null;
        this.imageTransform = imageTransform;
        initialize(split);
    }"
"public static FastDateFormat getTimeInstance(final int style, final TimeZone timeZone, final Locale locale) {
		return cache.getTimeInstance(style, timeZone, locale);
	}"
"public static Database getDatabase(DataSource dataSource) {
		if (dataSource == null) {
			return Database.DEFAULT;
		}
		try {
			String url = JdbcUtils.extractDatabaseMetaData(dataSource, ""getURL"");
			DatabaseDriver driver = DatabaseDriver.fromJdbcUrl(url);
			Database database = LOOKUP.get(driver);
			if (database != null) {
				return database;
			}
		}
		catch (MetaDataAccessException ex) {
			logger.warn(""Unable to determine jdbc url from datasource"", ex);
		}
		return Database.DEFAULT;
	}"
"public double norm1()
    {
        double f = 0;
        for (int j = 0; j < n; j++)
        {
            double s = 0;
            for (int i = 0; i < m; i++)
            {
                s += Math.abs(A[i][j]);
            }
            f = Math.max(f, s);
        }
        return f;
    }"
"public static <T> ExtensionLoader<T> getExtensionLoader(Class<T> clazz) {
        return getExtensionLoader(clazz, null);
    }"
"public SDVariable gt(SDVariable x, SDVariable y) {
        return gt(null, x, y);
    }"
"public static Sequence[] getSequencesFor(final EventProcessor... processors)
    {
        Sequence[] sequences = new Sequence[processors.length];
        for (int i = 0; i < sequences.length; i++)
        {
            sequences[i] = processors[i].getSequence();
        }

        return sequences;
    }"
"private void printLirs() {
    System.out.println(""** LIRS stack TOP **"");
    for (Node n = headS.nextS; n != headS; n = n.nextS) {
      checkState(n.isInS);
      if (n.status == Status.HIR_NON_RESIDENT) {
        System.out.println(""<NR> "" + n.key);
      } else if (n.status == Status.HIR_RESIDENT) {
        System.out.println(""<RH> "" + n.key);
      } else {
        System.out.println(""<RL> "" + n.key);
      }
    }
    System.out.println(""** LIRS stack BOTTOM **"");

    System.out.println(""\n** LIRS queue END **"");
    for (Node n = headQ.nextQ; n != headQ; n = n.nextQ) {
      checkState(n.isInQ);
      System.out.println(n.key);
    }
    System.out.println(""** LIRS queue front **"");

    System.out.println(""\nLIRS EVICTED PAGE sequence:"");
    for (int i = 0; i < evicted.size(); i++) {
      System.out.println(""<"" + i + ""> "" + evicted.get(i));
    }
  }"
"void linkFirst(final E e) {
    final E f = first;
    first = e;

    if (f == null) {
      last = e;
    } else {
      setPrevious(f, e);
      setNext(e, f);
    }
  }"
"public static String marshalToString(Object obj, String... fliterFields) {
        final List<String> propertyFliters = Arrays.asList(fliterFields);
        SerializeWriter out = new SerializeWriter();
        try {
            JSONSerializer serializer = new JSONSerializer(out);
            serializer.getPropertyFilters().add(new PropertyFilter() {

                public boolean apply(Object source, String name, Object value) {
                    return !propertyFliters.contains(name);
                }

            });
            serializer.write(obj);
            return out.toString();
        } finally {
            out.close();
        }
    }"
"public String join(String separator) throws JSONException {
		int len = this.rawList.size();
		StringBuilder sb = new StringBuilder();

		for (int i = 0; i < len; i += 1) {
			if (i > 0) {
				sb.append(separator);
			}
			sb.append(InternalJSONUtil.valueToString(this.rawList.get(i)));
		}
		return sb.toString();
	}"
"public static boolean commonSuffixOfLength(String s, String p, int len) {
        return s != null && p != null && len >= 0 && s.regionMatches(s.length() - len, p, p.length() - len, len);
    }"
"public void remove(final Long pipelineId) {
        Assert.assertNotNull(pipelineId);
        transactionTemplate.execute(new TransactionCallbackWithoutResult() {

            @Override
            protected void doInTransactionWithoutResult(TransactionStatus status) {
                try {
                    PipelineDO pipelineDO = pipelineDao.findById(pipelineId);
                    if (pipelineDO != null) {
                        pipelineDao.delete(pipelineId);
                        pipelineNodeRelationDao.deleteByPipelineId(pipelineId);
                        // 删除历史cursor
                        String destination = pipelineDO.getParameters().getDestinationName();
                        short clientId = pipelineDO.getId().shortValue();
                        arbitrateViewService.removeCanal(destination, clientId);
                        arbitrateManageService.pipelineEvent().destory(pipelineDO.getChannelId(), pipelineId);
                    }
                } catch (Exception e) {
                    logger.error(""ERROR ## remove the pipeline("" + pipelineId + "") has an exception!"");
                    throw new ManagerException(e);
                }
            }
        });
    }"
"public static Props fromJSONString(final String json) throws IOException {
    final Map<String, String> obj = (Map<String, String>) JSONUtils.parseJSONFromString(json);
    final Props props = new Props(null, obj);
    return props;
  }"
"static ParseSetup guessSetup(ByteVec bv, byte[] bits, byte sep, boolean singleQuotes, String[] columnNames, String[][] naStrings,
                               byte[] nonDataLineMarkers) {
    if (columnNames != null) throw new UnsupportedOperationException(""ARFFParser doesn't accept columnNames."");
    if (nonDataLineMarkers == null)
      nonDataLineMarkers = NON_DATA_LINE_MARKERS_DEFAULT;

    // Parse all lines starting with @ until EOF or @DATA
    boolean haveData = false;
    String[][] data = new String[0][];
    String[] labels;
    String[][] domains;
    String[] headerlines = new String[0];
    byte[] ctypes;

    // header section
    ArrayList<String> header = new ArrayList<>();

    int offset = 0;
    int chunk_idx = 0; //relies on the assumption that bits param have been extracted from first chunk: cf. ParseSetup#map
    boolean readHeader = true;
    while (readHeader) {
      offset = readArffHeader(0, header, bits, singleQuotes);
      if (isValidHeader(header)) {
        String lastHeader = header.get(header.size() - 1);
        if (INCOMPLETE_HEADER.equals(lastHeader) || SKIP_NEXT_HEADER.equals(lastHeader)) {
          bits = bv.chunkForChunkIdx(++chunk_idx).getBytes();
          continue;
        }
      } else if (chunk_idx > 0) { //first chunk parsed correctly, but not the next => formatting issue
        throw new H2OUnsupportedDataFileException(
            ""Arff parsing: Invalid header. If compressed file, please try without compression"",
            ""First chunk was parsed correctly, but a following one failed, common with archives as only first chunk in decompressed"");
      }
      readHeader = false;
    }

    if (offset < bits.length && !CsvParser.isEOL(bits[offset]))
      haveData = true; //more than just the header

    if (header.size() == 0)
      throw new ParseDataset.H2OParseException(""No data!"");

    headerlines = header.toArray(headerlines);

    // process header
    int ncols = headerlines.length;
    labels = new String[ncols];
    domains = new String[ncols][];
    ctypes = new byte[ncols];
    processArffHeader(ncols, headerlines, labels, domains, ctypes);

    // data section (for preview)
    if (haveData) {
      final int preview_max_length = 10;
      ArrayList<String> datablock = new ArrayList<>();
      //Careful! the last data line could be incomplete too (cf. readArffHeader)
      while (offset < bits.length && datablock.size() < preview_max_length) {
        int lineStart = offset;
        while (offset < bits.length && !CsvParser.isEOL(bits[offset])) ++offset;
        int lineEnd = offset;
        ++offset;
        // For Windoze, skip a trailing LF after CR
        if ((offset < bits.length) && (bits[offset] == CsvParser.CHAR_LF)) ++offset;
        if (ArrayUtils.contains(nonDataLineMarkers, bits[lineStart])) continue;
        if (lineEnd > lineStart) {
          String str = new String(bits, lineStart, lineEnd - lineStart).trim();
          if (!str.isEmpty()) datablock.add(str);
        }
      }
      if (datablock.size() == 0)
        throw new ParseDataset.H2OParseException(""Unexpected line."");

      // process data section
      String[] datalines = datablock.toArray(new String[datablock.size()]);
      data = new String[datalines.length][];

      // First guess the field separator by counting occurrences in first few lines
      if (datalines.length == 1) {
        if (sep == GUESS_SEP) {
          //could be a bit more robust than just counting commas?
          if (datalines[0].split("","").length > 2) sep = ',';
          else if (datalines[0].split("" "").length > 2) sep = ' ';
          else throw new ParseDataset.H2OParseException(""Failed to detect separator."");
        }
        data[0] = determineTokens(datalines[0], sep, singleQuotes);
        ncols = (ncols > 0) ? ncols : data[0].length;
        labels = null;
      } else {                    // 2 or more lines
        if (sep == GUESS_SEP) {   // first guess the separator
          //FIXME if last line is incomplete, this logic fails
          sep = guessSeparator(datalines[0], datalines[1], singleQuotes);
          if (sep == GUESS_SEP && datalines.length > 2) {
            sep = guessSeparator(datalines[1], datalines[2], singleQuotes);
            if (sep == GUESS_SEP) sep = guessSeparator(datalines[0], datalines[2], singleQuotes);
          }
          if (sep == GUESS_SEP) sep = (byte) ' '; // Bail out, go for space
        }

        for (int i = 0; i < datalines.length; ++i) {
          data[i] = determineTokens(datalines[i], sep, singleQuotes);
        }
      }
    }

    naStrings = addDefaultNAs(naStrings, ncols);

    // Return the final setup
    return new ParseSetup(ARFF_INFO, sep, singleQuotes, ParseSetup.NO_HEADER, ncols, labels, ctypes, domains, naStrings, data, nonDataLineMarkers);
  }"
"protected void subHealthToRetry(ProviderInfo providerInfo, ClientTransport transport) {
        providerLock.lock();
        try {
            if (subHealthConnections.remove(providerInfo) != null) {
                retryConnections.put(providerInfo, transport);
            }
        } finally {
            providerLock.unlock();
        }
    }"
"private boolean isAggregationDistinctSelectItem(final String innerExpression) {
        String pattern = ""\\(\\s*DISTINCT\\s+.*\\)"";
        return Pattern.matches(pattern, innerExpression.toUpperCase());
    }"
"@Override
  public void doBootstrap(TransportClient client, Channel channel) {
    SparkSaslClient saslClient = new SparkSaslClient(appId, secretKeyHolder, conf.saslEncryption());
    try {
      byte[] payload = saslClient.firstToken();

      while (!saslClient.isComplete()) {
        SaslMessage msg = new SaslMessage(appId, payload);
        ByteBuf buf = Unpooled.buffer(msg.encodedLength() + (int) msg.body().size());
        msg.encode(buf);
        buf.writeBytes(msg.body().nioByteBuffer());

        ByteBuffer response = client.sendRpcSync(buf.nioBuffer(), conf.authRTTimeoutMs());
        payload = saslClient.response(JavaUtils.bufferToArray(response));
      }

      client.setClientId(appId);

      if (conf.saslEncryption()) {
        if (!SparkSaslServer.QOP_AUTH_CONF.equals(saslClient.getNegotiatedProperty(Sasl.QOP))) {
          throw new RuntimeException(
            new SaslException(""Encryption requests by negotiated non-encrypted connection.""));
        }

        SaslEncryption.addToChannel(channel, saslClient, conf.maxSaslEncryptedBlockSize());
        saslClient = null;
        logger.debug(""Channel {} configured for encryption."", client);
      }
    } catch (IOException ioe) {
      throw new RuntimeException(ioe);
    } finally {
      if (saslClient != null) {
        try {
          // Once authentication is complete, the server will trust all remaining communication.
          saslClient.dispose();
        } catch (RuntimeException e) {
          logger.error(""Error while disposing SASL client"", e);
        }
      }
    }
  }"
"@WriteOperation
    public void updateLoggerLevel(@Selector final String loggerName,
                                  final String loggerLevel,
                                  final boolean additive) {


        val loggerConfigs = getLoggerConfigurations();
        loggerConfigs.stream()
            .filter(cfg -> cfg.getName().equals(loggerName))
            .forEachOrdered(cfg -> {
                cfg.setLevel(Level.getLevel(loggerLevel));
                cfg.setAdditive(additive);
            });
        this.loggerContext.updateLoggers();
    }"
"public void addPathElement(String pathElement) throws BuildException {
        File pathComponent = project != null ? project.resolveFile(pathElement) : new File(
                pathElement);
        try {
            addPathFile(pathComponent);
        } catch (IOException e) {
            throw new BuildException(e);
        }
    }"
"public FileAppender append(String line) {
		if (list.size() >= capacity) {
			flush();
		}
		list.add(line);
		return this;
	}"
"public static String formatChineseDate(Date date, boolean isUppercase) {
		if (null == date) {
			return null;
		}

		String format = DatePattern.CHINESE_DATE_FORMAT.format(date);
		if (isUppercase) {
			final StringBuilder builder = StrUtil.builder(format.length());
			builder.append(Convert.numberToChinese(Integer.parseInt(format.substring(0, 1)), false));
			builder.append(Convert.numberToChinese(Integer.parseInt(format.substring(1, 2)), false));
			builder.append(Convert.numberToChinese(Integer.parseInt(format.substring(2, 3)), false));
			builder.append(Convert.numberToChinese(Integer.parseInt(format.substring(3, 4)), false));
			builder.append(format.substring(4, 5));
			builder.append(Convert.numberToChinese(Integer.parseInt(format.substring(5, 7)), false));
			builder.append(format.substring(7, 8));
			builder.append(Convert.numberToChinese(Integer.parseInt(format.substring(8, 10)), false));
			builder.append(format.substring(10));
			format = builder.toString().replace('零', '〇');
		}
		return format;
	}"
"private void onProbationHit(Node node) {
    node.remove();
    node.status = Status.PROTECTED;
    node.appendToTail(headProtected);

    sizeProtected++;
    demoteProtected();
  }"
"public static String getModuleNameFor(Op op) {
        //String functionName = op instanceof TransformOp || op instanceof ReduceOp || op instanceof IndexAccumulation ? op.opName() + ""_strided"" : op.opName();
        String moduleName = null;
        if (op instanceof ReduceOp) {

            moduleName = ""reduce"";

            // FIXME: special case for reduce3
            if (op.opName().equals(""cosinesimilarity"")) {
                moduleName = ""reduce3"";
            } else if (op.opName().equals(""euclidean"")) {
                moduleName = ""reduce3"";
            } else if (op.opName().equals(""manhattan"")) {
                moduleName = ""reduce3"";
            }

        } else if (op instanceof TransformOp) {
            // FIXME: we need special case for pairwise transforms for now. Later we should make them separate kernel call
            if (op.opName().equals(""add"")) {
                moduleName = ""pairWiseTransform"";
            } else if (op.opName().equals(""copy"")) {
                moduleName = ""pairWiseTransform"";
            } else if (op.opName().equals(""div"")) {
                moduleName = ""pairWiseTransform"";
            } else if (op.opName().equals(""mul"")) {
                moduleName = ""pairWiseTransform"";
            } else if (op.opName().equals(""rdiv"")) {
                moduleName = ""pairWiseTransform"";
            } else if (op.opName().equals(""rsub"")) {
                moduleName = ""pairWiseTransform"";
            } else if (op.opName().equals(""sub"")) {
                moduleName = ""pairWiseTransform"";

            } else {
                moduleName = ""transform"";
            }
        } else if (op instanceof ScalarOp) {
            moduleName = ""scalar"";
        } else if (op instanceof BroadcastOp) {
            moduleName = ""broadcast"";
        } else if (op instanceof IndexAccumulation) {
            moduleName = ""indexReduce"";
        }
        return moduleName;
    }"
"private void checkIdentity(SSLSession session, X509Certificate cert) throws CertificateException {
		if (session == null) {
			throw new CertificateException(""No handshake session"");
		}

		if (EndpointIdentificationAlgorithm.HTTPS == identityAlg) {
			String hostname = session.getPeerHost();
			APINameChecker.verifyAndThrow(hostname, cert);
		}
	}"
"public static boolean isNumber(String str) {
		if (StrUtil.isBlank(str)) {
			return false;
		}
		char[] chars = str.toCharArray();
		int sz = chars.length;
		boolean hasExp = false;
		boolean hasDecPoint = false;
		boolean allowSigns = false;
		boolean foundDigit = false;
		// deal with any possible sign up front
		int start = (chars[0] == '-') ? 1 : 0;
		if (sz > start + 1) {
			if (chars[start] == '0' && chars[start + 1] == 'x') {
				int i = start + 2;
				if (i == sz) {
					return false; // str == ""0x""
				}
				// checking hex (it can't be anything else)
				for (; i < chars.length; i++) {
					if ((chars[i] < '0' || chars[i] > '9') && (chars[i] < 'a' || chars[i] > 'f') && (chars[i] < 'A' || chars[i] > 'F')) {
						return false;
					}
				}
				return true;
			}
		}
		sz--; // don't want to loop to the last char, check it afterwords
				// for type qualifiers
		int i = start;
		// loop to the next to last char or to the last char if we need another digit to
		// make a valid number (e.g. chars[0..5] = ""1234E"")
		while (i < sz || (i < sz + 1 && allowSigns && !foundDigit)) {
			if (chars[i] >= '0' && chars[i] <= '9') {
				foundDigit = true;
				allowSigns = false;

			} else if (chars[i] == '.') {
				if (hasDecPoint || hasExp) {
					// two decimal points or dec in exponent
					return false;
				}
				hasDecPoint = true;
			} else if (chars[i] == 'e' || chars[i] == 'E') {
				// we've already taken care of hex.
				if (hasExp) {
					// two E's
					return false;
				}
				if (!foundDigit) {
					return false;
				}
				hasExp = true;
				allowSigns = true;
			} else if (chars[i] == '+' || chars[i] == '-') {
				if (!allowSigns) {
					return false;
				}
				allowSigns = false;
				foundDigit = false; // we need a digit after the E
			} else {
				return false;
			}
			i++;
		}
		if (i < chars.length) {
			if (chars[i] >= '0' && chars[i] <= '9') {
				// no type qualifier, OK
				return true;
			}
			if (chars[i] == 'e' || chars[i] == 'E') {
				// can't have an E at the last byte
				return false;
			}
			if (chars[i] == '.') {
				if (hasDecPoint || hasExp) {
					// two decimal points or dec in exponent
					return false;
				}
				// single trailing decimal point after non-exponent is ok
				return foundDigit;
			}
			if (!allowSigns && (chars[i] == 'd' || chars[i] == 'D' || chars[i] == 'f' || chars[i] == 'F')) {
				return foundDigit;
			}
			if (chars[i] == 'l' || chars[i] == 'L') {
				// not allowing L with an exponent
				return foundDigit && !hasExp;
			}
			// last character is illegal
			return false;
		}
		// allowSigns is true iff the val ends in 'E'
		// found digit it to make sure weird stuff like '.' and '1E-' doesn't pass
		return !allowSigns && foundDigit;
	}"
"public static Long executeAutoCount(Dialect dialect, Executor executor, MappedStatement countMs,
                                        Object parameter, BoundSql boundSql,
                                        RowBounds rowBounds, ResultHandler resultHandler) throws SQLException {
        Map<String, Object> additionalParameters = getAdditionalParameter(boundSql);
        //创建 count 查询的缓存 key
        CacheKey countKey = executor.createCacheKey(countMs, parameter, RowBounds.DEFAULT, boundSql);
        //调用方言获取 count sql
        String countSql = dialect.getCountSql(countMs, boundSql, parameter, rowBounds, countKey);
        //countKey.update(countSql);
        BoundSql countBoundSql = new BoundSql(countMs.getConfiguration(), countSql, boundSql.getParameterMappings(), parameter);
        //当使用动态 SQL 时，可能会产生临时的参数，这些参数需要手动设置到新的 BoundSql 中
        for (String key : additionalParameters.keySet()) {
            countBoundSql.setAdditionalParameter(key, additionalParameters.get(key));
        }
        //执行 count 查询
        Object countResultList = executor.query(countMs, parameter, RowBounds.DEFAULT, resultHandler, countKey, countBoundSql);
        Long count = (Long) ((List) countResultList).get(0);
        return count;
    }"
"public void fit(@NonNull DataSetIterator iterator, int numEpochs){
        Preconditions.checkArgument(numEpochs > 0, ""Number of epochs much be > 0. Got numEpochs = %s"", numEpochs);
        Preconditions.checkArgument(numEpochs == 1 || iterator.resetSupported(), ""Cannot perform multiple epochs training using"" +
                ""iterator thas does not support resetting (iterator.resetSupported() returned false)"");

        for(int i=0; i<numEpochs; i++ ){
            fit(iterator);
        }
    }"
"public long optLong(String name, long fallback) {
		Object object = opt(name);
		Long result = JSON.toLong(object);
		return result != null ? result : fallback;
	}"
"public void dequeue(final int executionId) {
    if (this.queuedFlowMap.containsKey(executionId)) {
      this.queuedFlowList.remove(this.queuedFlowMap.get(executionId));
      this.queuedFlowMap.remove(executionId);
    }
  }"
"private void drawInterfere(Graphics2D g) {
		final ThreadLocalRandom random = RandomUtil.getRandom();
		// 干扰线
		for (int i = 0; i < this.interfereCount; i++) {
			int xs = random.nextInt(width);
			int ys = random.nextInt(height);
			int xe = xs + random.nextInt(width / 8);
			int ye = ys + random.nextInt(height / 8);
			g.setColor(ImgUtil.randomColor(random));
			g.drawLine(xs, ys, xe, ye);
		}
	}"
"public static HystrixThreadPoolMetrics getInstance(HystrixThreadPoolKey key, ThreadPoolExecutor threadPool, HystrixThreadPoolProperties properties) {
        // attempt to retrieve from cache first
        HystrixThreadPoolMetrics threadPoolMetrics = metrics.get(key.name());
        if (threadPoolMetrics != null) {
            return threadPoolMetrics;
        } else {
            synchronized (HystrixThreadPoolMetrics.class) {
                HystrixThreadPoolMetrics existingMetrics = metrics.get(key.name());
                if (existingMetrics != null) {
                    return existingMetrics;
                } else {
                    HystrixThreadPoolMetrics newThreadPoolMetrics = new HystrixThreadPoolMetrics(key, threadPool, properties);
                    metrics.putIfAbsent(key.name(), newThreadPoolMetrics);
                    return newThreadPoolMetrics;
                }
            }
        }
    }"
"public static Method[] getMethods(Class<?> clazz, Filter<Method> filter) throws SecurityException {
		if (null == clazz) {
			return null;
		}
		return ArrayUtil.filter(getMethods(clazz), filter);
	}"
"public void compress2( AutoBuffer ab ) {
    assert max() <= 32;          // Expect a larger format
    assert _byteoff == 0;       // This is only set on loading a pre-existing IcedBitSet
    assert _val.length==4;
    ab.putA1(_val,4);
  }"
"public void sendTaskEvent(ResultPartitionID partitionId, TaskEvent event, final RemoteInputChannel inputChannel) throws IOException {
		checkNotClosed();

		tcpChannel.writeAndFlush(new TaskEventRequest(event, partitionId, inputChannel.getInputChannelId()))
				.addListener(
						new ChannelFutureListener() {
							@Override
							public void operationComplete(ChannelFuture future) throws Exception {
								if (!future.isSuccess()) {
									SocketAddress remoteAddr = future.channel().remoteAddress();
									inputChannel.onError(new LocalTransportException(
										String.format(""Sending the task event to '%s' failed."", remoteAddr),
										future.channel().localAddress(), future.cause()
									));
								}
							}
						});
	}"
"public PropertySource<?> remove(String name) {
        if (logger.isDebugEnabled()) {
            logger.debug(""Removing PropertySource '"" + name + ""'"");
        }
        int index = this.propertySourceList.indexOf(PropertySource.named(name));
        return (index != -1 ? this.propertySourceList.remove(index) : null);
    }"
"public <T extends RestTemplate> T configure(T restTemplate) {
		configureRequestFactory(restTemplate);
		if (!CollectionUtils.isEmpty(this.messageConverters)) {
			restTemplate.setMessageConverters(new ArrayList<>(this.messageConverters));
		}
		if (this.uriTemplateHandler != null) {
			restTemplate.setUriTemplateHandler(this.uriTemplateHandler);
		}
		if (this.errorHandler != null) {
			restTemplate.setErrorHandler(this.errorHandler);
		}
		if (this.rootUri != null) {
			RootUriTemplateHandler.addTo(restTemplate, this.rootUri);
		}
		if (this.basicAuthentication != null) {
			restTemplate.getInterceptors().add(this.basicAuthentication);
		}
		restTemplate.getInterceptors().addAll(this.interceptors);
		if (!CollectionUtils.isEmpty(this.restTemplateCustomizers)) {
			for (RestTemplateCustomizer customizer : this.restTemplateCustomizers) {
				customizer.customize(restTemplate);
			}
		}
		return restTemplate;
	}"
"public static DataMedia<? extends DataMediaSource> findSourceDataMedia(Pipeline pipeline, String namespace,
                                                                           String name, boolean notExistReturnNull) {
        for (DataMediaPair pair : pipeline.getPairs()) {
            if (isMatch(pair.getSource(), namespace, name)) {
                return pair.getSource();
            }
        }

        if (notExistReturnNull) {
            return null;
        } else {
            throw new ConfigException(""no such DataMedia , the namespace = "" + namespace + "" name = "" + name);
        }
    }"
"private boolean verifyIpAddress(String ipAddress, X509Certificate certificate) {
    List<String> altNames = getSubjectAltNames(certificate, ALT_IPA_NAME);
    for (int i = 0, size = altNames.size(); i < size; i++) {
      if (ipAddress.equalsIgnoreCase(altNames.get(i))) {
        return true;
      }
    }
    return false;
  }"
"public static String[] toStringArray(Enumeration<String> enumeration) {
        if (enumeration == null) {
            return null;
        }
        List<String> list = java.util.Collections.list(enumeration);
        return list.toArray(new String[list.size()]);
    }"
"public INDArray params(boolean backwardOnly) {
        if (backwardOnly)
            return params();

        List<INDArray> params = new ArrayList<>();
        for (Layer layer : getLayers()) {
            INDArray layerParams = layer.params();
            if (layerParams != null)
                params.add(layerParams); //may be null: subsampling etc layers
        }

        return Nd4j.toFlattened('f', params);
    }"
"private boolean hasSameStatus(Plugin scanner, String status) {
        if (status.equals(Constant.messages.getString(""ascan.policy.table.quality.all""))) {
            return true;
        }
        return status.equals(View.getSingleton().getStatusUI(scanner.getStatus()).toString());
    }"
"public static ClassResolver weakCachingConcurrentResolver(ClassLoader classLoader) {
        return new CachingClassResolver(
                new ClassLoaderClassResolver(defaultClassLoader(classLoader)),
                new WeakReferenceMap<String, Class<?>>(
                        PlatformDependent.<String, Reference<Class<?>>>newConcurrentHashMap()));
    }"
"private void receive() {
    try {
      Socket socket = null;
      BufferedReader reader = null;
      try {
        // connect to the server
        socket = new Socket(host, port);
        reader = new BufferedReader(
            new InputStreamReader(socket.getInputStream(), StandardCharsets.UTF_8));
        // Until stopped or connection broken continue reading
        String userInput;
        while (!isStopped() && (userInput = reader.readLine()) != null) {
          System.out.println(""Received data '"" + userInput + ""'"");
          store(userInput);
        }
      } finally {
        Closeables.close(reader, /* swallowIOException = */ true);
        Closeables.close(socket,  /* swallowIOException = */ true);
      }
      // Restart in an attempt to connect again when server is active again
      restart(""Trying to connect again"");
    } catch(ConnectException ce) {
      // restart if could not connect to server
      restart(""Could not connect"", ce);
    } catch(Throwable t) {
      restart(""Error receiving data"", t);
    }
  }"
"public static boolean isXls(InputStream in) {
		final PushbackInputStream pin = IoUtil.toPushbackStream(in, 8);
		try {
			return FileMagic.valueOf(pin) == FileMagic.OLE2;
		} catch (IOException e) {
			throw new IORuntimeException(e);
		}
	}"
"private void utah(int row, int col, int pos) {
    module(row - 2, col - 2, pos, 1);
    module(row - 2, col - 1, pos, 2);
    module(row - 1, col - 2, pos, 3);
    module(row - 1, col - 1, pos, 4);
    module(row - 1, col, pos, 5);
    module(row, col - 2, pos, 6);
    module(row, col - 1, pos, 7);
    module(row, col, pos, 8);
  }"
"public void unPublishPort() {
        // unregister with epmd
        OtpEpmd.unPublishPort(this);

        // close the local descriptor (if we have one)
        try {
            if (super.epmd != null) {
                super.epmd.close();
            }
        } catch (final IOException e) {/* ignore close errors */
        }
        super.epmd = null;
    }"
"@Override
	public synchronized void deleteAllDataForContext(int contextId) throws DatabaseException {
    	SqlPreparedStatementWrapper psDeleteAllDataForContext = null;
    	try {
        	psDeleteAllDataForContext = DbSQL.getSingleton().getPreparedStatement(""context.ps.deletealldataforcontext"");
			psDeleteAllDataForContext.getPs().setInt(1, contextId);
			psDeleteAllDataForContext.getPs().executeUpdate();
		} catch (SQLException e) {
			throw new DatabaseException(e);
		} finally {
			DbSQL.getSingleton().releasePreparedStatement(psDeleteAllDataForContext);
		}
    }"
"private void configureClearText(SocketChannel ch) {
        final ChannelPipeline p = ch.pipeline();
        final HttpServerCodec sourceCodec = new HttpServerCodec();

        p.addLast(sourceCodec);
        p.addLast(new HttpServerUpgradeHandler(sourceCodec, upgradeCodecFactory));
        p.addLast(new SimpleChannelInboundHandler<HttpMessage>() {
            @Override
            protected void channelRead0(ChannelHandlerContext ctx, HttpMessage msg) throws Exception {
                // If this handler is hit then no upgrade has been attempted and the client is just talking HTTP.
                System.err.println(""Directly talking: "" + msg.protocolVersion() + "" (no upgrade was attempted)"");
                ChannelPipeline pipeline = ctx.pipeline();
                ChannelHandlerContext thisCtx = pipeline.context(this);
                pipeline.addAfter(thisCtx.name(), null, new HelloWorldHttp1Handler(""Direct. No Upgrade Attempted.""));
                pipeline.replace(this, null, new HttpObjectAggregator(maxHttpContentLength));
                ctx.fireChannelRead(ReferenceCountUtil.retain(msg));
            }
        });

        p.addLast(new UserEventLogger());
    }"
"private void releaseAndOfferIfHealthy(Channel channel, Promise<Void> promise, Future<Boolean> future)
            throws Exception {
        if (future.getNow()) { //channel turns out to be healthy, offering and releasing it.
            releaseAndOffer(channel, promise);
        } else { //channel not healthy, just releasing it.
            handler.channelReleased(channel);
            promise.setSuccess(null);
        }
    }"
"protected static int compareStrings(int offset_1, byte[] key, ByteBuffer bb) {
    offset_1 += bb.getInt(offset_1);
    int len_1 = bb.getInt(offset_1);
    int len_2 = key.length;
    int startPos_1 = offset_1 + Constants.SIZEOF_INT;
    int len = Math.min(len_1, len_2);
    for (int i = 0; i < len; i++) {
      if (bb.get(i + startPos_1) != key[i])
        return bb.get(i + startPos_1) - key[i];
    }
    return len_1 - len_2;
  }"
"private Publisher<List<String>> convertServiceIds(ListServicesResult listServicesResult) {
        List<ServiceSummary> services = listServicesResult.getServices();
        List<String> serviceIds = new ArrayList<>();

        for (ServiceSummary service : services) {
            serviceIds.add(service.getId());
        }
        return Publishers.just(
                serviceIds
        );

    }"
"public Option choices(String... choices) throws RequiredParametersException {
		if (this.defaultValue != null) {
			if (Arrays.asList(choices).contains(defaultValue)) {
				Collections.addAll(this.choices, choices);
			} else {
				throw new RequiredParametersException(""Valid values for option "" + this.longName +
						"" do not contain defined default value "" + defaultValue);
			}
		} else {
			Collections.addAll(this.choices, choices);
		}
		return this;
	}"
"public static String formatFriendlyTimeSpanByNow(long timeStampMillis) {
		long now = ClockUtil.currentTimeMillis();
		long span = now - timeStampMillis;
		if (span < 0) {
			// 'c' 日期和时间，被格式化为 ""%ta %tb %td %tT %tZ %tY""，例如 ""Sun Jul 20 16:17:00 EDT 1969""。
			return String.format(""%tc"", timeStampMillis);
		}
		if (span < DateUtil.MILLIS_PER_SECOND) {
			return ""刚刚"";
		} else if (span < DateUtil.MILLIS_PER_MINUTE) {
			return String.format(""%d秒前"", span / DateUtil.MILLIS_PER_SECOND);
		} else if (span < DateUtil.MILLIS_PER_HOUR) {
			return String.format(""%d分钟前"", span / DateUtil.MILLIS_PER_MINUTE);
		}
		// 获取当天00:00
		long wee = DateUtil.beginOfDate(new Date(now)).getTime();
		if (timeStampMillis >= wee) {
			// 'R' 24 小时制的时间，被格式化为 ""%tH:%tM""
			return String.format(""今天%tR"", timeStampMillis);
		} else if (timeStampMillis >= wee - DateUtil.MILLIS_PER_DAY) {
			return String.format(""昨天%tR"", timeStampMillis);
		} else {
			// 'F' ISO 8601 格式的完整日期，被格式化为 ""%tY-%tm-%td""。
			return String.format(""%tF"", timeStampMillis);
		}
	}"
"public void onHttpClientUpgrade() throws Http2Exception {
        if (connection().isServer()) {
            throw connectionError(PROTOCOL_ERROR, ""Client-side HTTP upgrade requested for a server"");
        }
        if (!prefaceSent()) {
            // If the preface was not sent yet it most likely means the handler was not added to the pipeline before
            // calling this method.
            throw connectionError(INTERNAL_ERROR, ""HTTP upgrade must occur after preface was sent"");
        }
        if (decoder.prefaceReceived()) {
            throw connectionError(PROTOCOL_ERROR, ""HTTP upgrade must occur before HTTP/2 preface is received"");
        }

        // Create a local stream used for the HTTP cleartext upgrade.
        connection().local().createStream(HTTP_UPGRADE_STREAM_ID, true);
    }"
"public OperaOptions addExtensions(List<File> paths) {
    for (File path : paths) {
      checkNotNull(path);
      checkArgument(path.exists(), ""%s does not exist"", path.getAbsolutePath());
      checkArgument(!path.isDirectory(), ""%s is a directory"",
          path.getAbsolutePath());
    }
    extensionFiles.addAll(paths);
    return this;
  }"
"@Deprecated
    public void showOverlay() {
        if (rippler.overlayRect != null) {
            rippler.overlayRect.outAnimation.stop();
        }
        rippler.createOverlay();
        rippler.overlayRect.inAnimation.play();
    }"
"public static <T> RuntimeTypeAdapterFactory<T> of(Class<T> baseType) {
    return new RuntimeTypeAdapterFactory<T>(baseType, ""type"", false);
  }"
"public void setStrictlyCoLocatedWith(JobVertex strictlyCoLocatedWith) {
		if (this.slotSharingGroup == null || this.slotSharingGroup != strictlyCoLocatedWith.slotSharingGroup) {
			throw new IllegalArgumentException(""Strict co-location requires that both vertices are in the same slot sharing group."");
		}

		CoLocationGroup thisGroup = this.coLocationGroup;
		CoLocationGroup otherGroup = strictlyCoLocatedWith.coLocationGroup;

		if (otherGroup == null) {
			if (thisGroup == null) {
				CoLocationGroup group = new CoLocationGroup(this, strictlyCoLocatedWith);
				this.coLocationGroup = group;
				strictlyCoLocatedWith.coLocationGroup = group;
			}
			else {
				thisGroup.addVertex(strictlyCoLocatedWith);
				strictlyCoLocatedWith.coLocationGroup = thisGroup;
			}
		}
		else {
			if (thisGroup == null) {
				otherGroup.addVertex(this);
				this.coLocationGroup = otherGroup;
			}
			else {
				// both had yet distinct groups, we need to merge them
				thisGroup.mergeInto(otherGroup);
			}
		}
	}"
"public SDVariable invoke(Op op, SDVariable x) {
        return invoke(op, x, null);
    }"
"public void setParseGit(boolean parseGit) {
		this.parseGit = parseGit;
		getConfig().setProperty(SPIDER_PARSE_GIT, Boolean.toString(parseGit));
	}"
"private JsonWriter close(int empty, int nonempty, String closeBracket)
      throws IOException {
    int context = peek();
    if (context != nonempty && context != empty) {
      throw new IllegalStateException(""Nesting problem."");
    }
    if (deferredName != null) {
      throw new IllegalStateException(""Dangling name: "" + deferredName);
    }

    stackSize--;
    if (context == nonempty) {
      newline();
    }
    out.write(closeBracket);
    return this;
  }"
"public boolean writeOutbound(Object... msgs) {
        ensureOpen();
        if (msgs.length == 0) {
            return isNotEmpty(outboundMessages);
        }

        RecyclableArrayList futures = RecyclableArrayList.newInstance(msgs.length);
        try {
            for (Object m: msgs) {
                if (m == null) {
                    break;
                }
                futures.add(write(m));
            }

            flushOutbound0();

            int size = futures.size();
            for (int i = 0; i < size; i++) {
                ChannelFuture future = (ChannelFuture) futures.get(i);
                if (future.isDone()) {
                    recordException(future);
                } else {
                    // The write may be delayed to run later by runPendingTasks()
                    future.addListener(recordExceptionListener);
                }
            }

            checkException();
            return isNotEmpty(outboundMessages);
        } finally {
            futures.recycle();
        }
    }"
"public static long downloadFile(String url, File destFile, int timeout) {
		return downloadFile(url, destFile, timeout, null);
	}"
"@Override
    public DataSet get(int[] i) {
        List<DataSet> list = new ArrayList<>();
        for(int ex : i){
            list.add(get(ex));
        }
        return DataSet.merge(list);
    }"
"@ExperimentalApi(""https://github.com/grpc/grpc-java/issues/1869"")
  @SuppressWarnings(""unchecked"")
  public <T> T getOption(Key<T> key) {
    Preconditions.checkNotNull(key, ""key"");
    for (int i = 0; i < customOptions.length; i++) {
      if (key.equals(customOptions[i][0])) {
        return (T) customOptions[i][1];
      }
    }
    return key.defaultValue;
  }"
"protected final FilterArtifacts getFilters(ArtifactsFilter... additionalFilters) {
		FilterArtifacts filters = new FilterArtifacts();
		for (ArtifactsFilter additionalFilter : additionalFilters) {
			filters.addFilter(additionalFilter);
		}
		filters.addFilter(
				new MatchingGroupIdFilter(cleanFilterConfig(this.excludeGroupIds)));
		if (this.includes != null && !this.includes.isEmpty()) {
			filters.addFilter(new IncludeFilter(this.includes));
		}
		if (this.excludes != null && !this.excludes.isEmpty()) {
			filters.addFilter(new ExcludeFilter(this.excludes));
		}
		return filters;
	}"
"public void saveWithTrainingConfig(OutputStream outputStream) throws IOException {
        if(this.trainingConfig == null) {
            throw new IllegalStateException(""No training configuration found!"");
        }

        saveWithTrainingConfig(this.trainingConfig,outputStream);
    }"
"public String determineUsername() {
		if (StringUtils.hasText(this.username)) {
			return this.username;
		}
		if (EmbeddedDatabaseConnection.isEmbedded(determineDriverClassName())) {
			return ""sa"";
		}
		return null;
	}"
"public static Map<String,Set<Writable>> getUniqueSequence(List<String> columnNames, Schema schema,
                                                               SequenceRecordReader sequenceData) {
        Map<String,Set<Writable>> m = new HashMap<>();
        for(String s : columnNames){
            m.put(s, new HashSet<>());
        }
        while(sequenceData.hasNext()){
            List<List<Writable>> next = sequenceData.sequenceRecord();
            for(List<Writable> step : next) {
                for (String s : columnNames) {
                    int idx = schema.getIndexOfColumn(s);
                    m.get(s).add(step.get(idx));
                }
            }
        }
        return m;
    }"
"public static void flip(Image image, File outFile) throws IORuntimeException {
		write(flip(image), outFile);
	}"
"public static byte[] sub(byte[] array, int start, int end) {
		int length = length(array);
		if (start < 0) {
			start += length;
		}
		if (end < 0) {
			end += length;
		}
		if (start == length) {
			return new byte[0];
		}
		if (start > end) {
			int tmp = start;
			start = end;
			end = tmp;
		}
		if (end > length) {
			if (start >= length) {
				return new byte[0];
			}
			end = length;
		}
		return Arrays.copyOfRange(array, start, end);
	}"
"public static MultiLayerConfiguration fromJson(String json) {
        MultiLayerConfiguration conf;
        ObjectMapper mapper = NeuralNetConfiguration.mapper();
        try {
            conf = mapper.readValue(json, MultiLayerConfiguration.class);
        } catch (IOException e) {
            //Check if this exception came from legacy deserializer...
            String msg = e.getMessage();
            if (msg != null && msg.contains(""legacy"")) {
                throw new RuntimeException(""Error deserializing MultiLayerConfiguration - configuration may have a custom "" +
                        ""layer, vertex or preprocessor, in pre version 1.0.0-alpha JSON format. These layers can be "" +
                        ""deserialized by first registering them with NeuralNetConfiguration.registerLegacyCustomClassesForJSON(Class...)"", e);
            }
            throw new RuntimeException(e);
        }


        //To maintain backward compatibility after loss function refactoring (configs generated with v0.5.0 or earlier)
        // Previously: enumeration used for loss functions. Now: use classes
        // IN the past, could have only been an OutputLayer or RnnOutputLayer using these enums
        int layerCount = 0;
        JsonNode confs = null;
        for (NeuralNetConfiguration nnc : conf.getConfs()) {
            Layer l = nnc.getLayer();
            if (l instanceof BaseOutputLayer && ((BaseOutputLayer) l).getLossFn() == null) {
                //lossFn field null -> may be an old config format, with lossFunction field being for the enum
                //if so, try walking the JSON graph to extract out the appropriate enum value

                BaseOutputLayer ol = (BaseOutputLayer) l;
                try {
                    JsonNode jsonNode = mapper.readTree(json);
                    if (confs == null) {
                        confs = jsonNode.get(""confs"");
                    }
                    if (confs instanceof ArrayNode) {
                        ArrayNode layerConfs = (ArrayNode) confs;
                        JsonNode outputLayerNNCNode = layerConfs.get(layerCount);
                        if (outputLayerNNCNode == null)
                            return conf; //Should never happen...
                        JsonNode outputLayerNode = outputLayerNNCNode.get(""layer"");

                        JsonNode lossFunctionNode = null;
                        if (outputLayerNode.has(""output"")) {
                            lossFunctionNode = outputLayerNode.get(""output"").get(""lossFunction"");
                        } else if (outputLayerNode.has(""rnnoutput"")) {
                            lossFunctionNode = outputLayerNode.get(""rnnoutput"").get(""lossFunction"");
                        }

                        if (lossFunctionNode != null) {
                            String lossFunctionEnumStr = lossFunctionNode.asText();
                            LossFunctions.LossFunction lossFunction = null;
                            try {
                                lossFunction = LossFunctions.LossFunction.valueOf(lossFunctionEnumStr);
                            } catch (Exception e) {
                                log.warn(""OutputLayer with null LossFunction or pre-0.6.0 loss function configuration detected: could not parse JSON"",
                                        e);
                            }

                            if (lossFunction != null) {
                                switch (lossFunction) {
                                    case MSE:
                                        ol.setLossFn(new LossMSE());
                                        break;
                                    case XENT:
                                        ol.setLossFn(new LossBinaryXENT());
                                        break;
                                    case NEGATIVELOGLIKELIHOOD:
                                        ol.setLossFn(new LossNegativeLogLikelihood());
                                        break;
                                    case MCXENT:
                                        ol.setLossFn(new LossMCXENT());
                                        break;

                                    //Remaining: TODO
                                    case EXPLL:
                                    case RMSE_XENT:
                                    case SQUARED_LOSS:
                                    case RECONSTRUCTION_CROSSENTROPY:
                                    case CUSTOM:
                                    default:
                                        log.warn(""OutputLayer with null LossFunction or pre-0.6.0 loss function configuration detected: could not set loss function for {}"",
                                                lossFunction);
                                        break;
                                }
                            }
                        }

                    } else {
                        log.warn(""OutputLayer with null LossFunction or pre-0.6.0 loss function configuration detected: could not parse JSON: layer 'confs' field is not an ArrayNode (is: {})"",
                                (confs != null ? confs.getClass() : null));
                    }
                } catch (IOException e) {
                    log.warn(""OutputLayer with null LossFunction or pre-0.6.0 loss function configuration detected: could not parse JSON"",
                            e);
                    break;
                }
            }

            //Also, pre 0.7.2: activation functions were Strings (""activationFunction"" field), not classes (""activationFn"")
            //Try to load the old format if necessary, and create the appropriate IActivation instance
            if ((l instanceof BaseLayer) && ((BaseLayer) l).getActivationFn() == null) {
                try {
                    JsonNode jsonNode = mapper.readTree(json);
                    if (confs == null) {
                        confs = jsonNode.get(""confs"");
                    }
                    if (confs instanceof ArrayNode) {
                        ArrayNode layerConfs = (ArrayNode) confs;
                        JsonNode outputLayerNNCNode = layerConfs.get(layerCount);
                        if (outputLayerNNCNode == null)
                            return conf; //Should never happen...
                        JsonNode layerWrapperNode = outputLayerNNCNode.get(""layer"");

                        if (layerWrapperNode == null || layerWrapperNode.size() != 1) {
                            continue;
                        }

                        JsonNode layerNode = layerWrapperNode.elements().next();
                        JsonNode activationFunction = layerNode.get(""activationFunction""); //Should only have 1 element: ""dense"", ""output"", etc

                        if (activationFunction != null) {
                            IActivation ia = Activation.fromString(activationFunction.asText()).getActivationFunction();
                            ((BaseLayer) l).setActivationFn(ia);
                        }
                    }

                } catch (IOException e) {
                    log.warn(""Layer with null ActivationFn field or pre-0.7.2 activation function detected: could not parse JSON"",
                            e);
                }
            }

            if(!handleLegacyWeightInitFromJson(json, l, mapper, confs, layerCount)) {
                return conf;
            }

            layerCount++;
        }
        return conf;
    }"
"private Object readResolve() throws java.io.ObjectStreamException {
        return Nd4j.create(data, arrayShape, Nd4j.getStrides(arrayShape, arrayOrdering), 0, arrayOrdering);
    }"
"void add(AbstractEpollChannel ch) throws IOException {
        assert inEventLoop();
        int fd = ch.socket.intValue();
        Native.epollCtlAdd(epollFd.intValue(), fd, ch.flags);
        channels.put(fd, ch);
    }"
"public static PrivateKey generatePrivateKey(KeyStore keyStore, String alias, char[] password) {
		try {
			return (PrivateKey) keyStore.getKey(alias, password);
		} catch (Exception e) {
			throw new CryptoException(e);
		}
	}"
"public void complete(Void mustBeNull) {
        CountedCompleter p;
        onCompletion(this);
        quietlyComplete();
        if ((p = completer) != null)
            p.tryComplete();
    }"
"private boolean isCertExpired(X509Certificate cert) {
		if (cert != null && cert.getNotAfter().before(new Date())) {
			return true;
		}
		return false;
	}"
"@Override
   public void clear()
   {
      for (int i = 0; i < size; i++) {
         elementData[i] = null;
      }

      size = 0;
   }"
"@Deprecated
    public FormValidation doFieldCheck(@QueryParameter(fixEmpty=true) String value,
                                       @QueryParameter(fixEmpty=true) String type,
                                       @QueryParameter(fixEmpty=true) String errorText,
                                       @QueryParameter(fixEmpty=true) String warningText) {
        if (value == null) {
            if (errorText != null)
                return FormValidation.error(errorText);
            if (warningText != null)
                return FormValidation.warning(warningText);
            return FormValidation.error(""No error or warning text was set for fieldCheck()."");
        }

        if (type != null) {
            try {
                if (type.equalsIgnoreCase(""number"")) {
                    NumberFormat.getInstance().parse(value);
                } else if (type.equalsIgnoreCase(""number-positive"")) {
                    if (NumberFormat.getInstance().parse(value).floatValue() <= 0)
                        return FormValidation.error(Messages.Hudson_NotAPositiveNumber());
                } else if (type.equalsIgnoreCase(""number-negative"")) {
                    if (NumberFormat.getInstance().parse(value).floatValue() >= 0)
                        return FormValidation.error(Messages.Hudson_NotANegativeNumber());
                }
            } catch (ParseException e) {
                return FormValidation.error(Messages.Hudson_NotANumber());
            }
        }

        return FormValidation.ok();
    }"
"public final S withDeadline(@Nullable Deadline deadline) {
    return build(channel, callOptions.withDeadline(deadline));
  }"
"public void rnnSetPreviousState(int layer, Map<String, INDArray> state) {
        rnnSetPreviousState(layers[layer].conf().getLayer().getLayerName(), state);
    }"
"public Impl embedded(CharSequence ref, List<Resource> resourceList) {
        if (StringUtils.isNotEmpty(ref) && resourceList != null) {
            List<Resource> resources = this.embeddedMap.computeIfAbsent(ref, charSequence -> new ArrayList<>());
            resources.addAll(resourceList);
        }
        return (Impl) this;
    }"
"public static ByteBuf copyShort(short... values) {
        if (values == null || values.length == 0) {
            return EMPTY_BUFFER;
        }
        ByteBuf buffer = buffer(values.length * 2);
        for (int v: values) {
            buffer.writeShort(v);
        }
        return buffer;
    }"
"protected L putInMap(L node) {
		nodeMap.put(node.get(), node);
		identityDetector.put(node.get(), node.get());
		return node;
	}"
"protected void notifyListenersPostResourceFound(HttpMessage message, int depth, String uri,
			String requestBody) {
		for (SpiderParserListener l : listeners) {
			l.resourcePostURIFound(message, depth, uri, requestBody);
		}
	}"
"public static String secondToTime(int seconds) {
		if (seconds < 0) {
			throw new IllegalArgumentException(""Seconds must be a positive number!"");
		}

		int hour = seconds / 3600;
		int other = seconds % 3600;
		int minute = other / 60;
		int second = other % 60;
		final StringBuilder sb = new StringBuilder();
		if (hour < 10) {
			sb.append(""0"");
		}
		sb.append(hour);
		sb.append("":"");
		if (minute < 10) {
			sb.append(""0"");
		}
		sb.append(minute);
		sb.append("":"");
		if (second < 10) {
			sb.append(""0"");
		}
		sb.append(second);
		return sb.toString();
	}"
"public <T> T safeGet(String fieldName){
		try {
			return get(fieldName);
		} catch (Exception e) {
			return null;
		}
	}"
"HystrixMetricsPublisherCommand getPublisherForCommand(HystrixCommandKey commandKey, HystrixCommandGroupKey commandOwner, HystrixCommandMetrics metrics, HystrixCircuitBreaker circuitBreaker, HystrixCommandProperties properties) {
        // attempt to retrieve from cache first
        HystrixMetricsPublisherCommand publisher = commandPublishers.get(commandKey.name());
        if (publisher != null) {
            return publisher;
        } else {
            synchronized (this) {
                HystrixMetricsPublisherCommand existingPublisher = commandPublishers.get(commandKey.name());
                if (existingPublisher != null) {
                    return existingPublisher;
                } else {
                    HystrixMetricsPublisherCommand newPublisher = HystrixPlugins.getInstance().getMetricsPublisher().getMetricsPublisherForCommand(commandKey, commandOwner, metrics, circuitBreaker, properties);
                    commandPublishers.putIfAbsent(commandKey.name(), newPublisher);
                    newPublisher.initialize();
                    return newPublisher;
                }
            }
        }
    }"
"@Nullable V removeWithWriter(Object key) {
    @SuppressWarnings(""unchecked"")
    K castKey = (K) key;
    @SuppressWarnings({""unchecked"", ""rawtypes""})
    Node<K, V>[] node = new Node[1];
    @SuppressWarnings(""unchecked"")
    V[] oldValue = (V[]) new Object[1];
    RemovalCause[] cause = new RemovalCause[1];

    data.computeIfPresent(nodeFactory.newLookupKey(key), (k, n) -> {
      synchronized (n) {
        oldValue[0] = n.getValue();
        if (oldValue[0] == null) {
          cause[0] = RemovalCause.COLLECTED;
        } else if (hasExpired(n, expirationTicker().read())) {
          cause[0] = RemovalCause.EXPIRED;
        } else {
          cause[0] = RemovalCause.EXPLICIT;
        }
        writer.delete(castKey, oldValue[0], cause[0]);
        n.retire();
      }
      node[0] = n;
      return null;
    });

    if (cause[0] != null) {
      afterWrite(new RemovalTask(node[0]));
      if (hasRemovalListener()) {
        notifyRemoval(castKey, oldValue[0], cause[0]);
      }
    }
    return (cause[0] == RemovalCause.EXPLICIT) ? oldValue[0] : null;
  }"
"@SuppressWarnings(""WeakerAccess"")
    protected Object resolveModel(Object responseBody) {
        if (responseBody instanceof ModelAndView) {
            return ((ModelAndView) responseBody).getModel().orElse(null);
        }
        return responseBody;
    }"
"public static double add(float v1, float v2) {
		return add(Float.toString(v1), Float.toString(v2)).doubleValue();
	}"
"public <R> MapPartitionOperator<T, R> mapPartition(MapPartitionFunction<T, R> mapPartition) {
		if (mapPartition == null) {
			throw new NullPointerException(""MapPartition function must not be null."");
		}

		String callLocation = Utils.getCallLocationName();
		TypeInformation<R> resultType = TypeExtractor.getMapPartitionReturnTypes(mapPartition, getType(), callLocation, true);
		return new MapPartitionOperator<>(this, resultType, clean(mapPartition), callLocation);
	}"
"@Override
    public void displayFile(FileSystem fs, Path path, OutputStream outStream,
        int startLine, int endLine) throws IOException {
        if (logger.isDebugEnabled()) {
            logger.debug(""displaying orc file:"" + path.toUri().getPath());
        }
        StringBuilder ret = new StringBuilder();
        Reader orcreader = null;
        RecordReader reader = null;
        Object row = null;
        try {
            int lineNum = 1;

            orcreader = OrcFile.createReader(fs, path);
            reader = orcreader.rows(null);
            long endTime = System.currentTimeMillis() + STOP_TIME;
            while (reader.hasNext() && lineNum <= endLine
                && System.currentTimeMillis() <= endTime) {
                row = reader.next(row);
                if (lineNum >= startLine) {
                    ret.append(String.format(""Record %d:\n"", lineNum));
                    String jsonString =
                        SerDeUtilsWrapper.getJSON(row,
                            orcreader.getObjectInspector());
                    try {
                        JSONObject jsonobj = new JSONObject(jsonString);
                        ret.append(jsonobj.toString(JSON_INDENT));
                    } catch (JSONException e) {
                        logger.error(""Failed to parse json as JSONObject"", e);
                        // default to unformatted json string
                        ret.append(jsonString);
                    }
                    ret.append(""\n\n"");
                }
                lineNum++;
            }
            outStream.write(ret.toString().getBytes(StandardCharsets.UTF_8));
        } catch (IOException e) {
            outStream.write((""Error in display orc file: "" + e
                .getLocalizedMessage()).getBytes(""UTF-8""));
            throw e;
        } finally {
            if (reader != null) {
                reader.close();
            }
        }
    }"
"public static Map<String, Object> getAnnotationValueMap(AnnotatedElement annotationEle, Class<? extends Annotation> annotationType) throws UtilException {
		final Annotation annotation = getAnnotation(annotationEle, annotationType);
		if (null == annotation) {
			return null;
		}

		final Method[] methods = ReflectUtil.getMethods(annotationType, new Filter<Method>() {
			@Override
			public boolean accept(Method t) {
				if (ArrayUtil.isEmpty(t.getParameterTypes())) {
					// 只读取无参方法
					final String name = t.getName();
					if (""hashCode"".equals(name) || ""toString"".equals(name) || ""annotationType"".equals(name)) {
						// 跳过自有的几个方法
						return false;
					}
					return true;
				}
				return false;
			}
		});

		final HashMap<String, Object> result = new HashMap<>(methods.length, 1);
		for (Method method : methods) {
			result.put(method.getName(), ReflectUtil.invoke(annotation, method));
		}
		return result;
	}"
"public static String join(Collection collection, String separator) {
        if (isEmpty(collection)) {
            return StringUtils.EMPTY;
        }
        StringBuilder sb = new StringBuilder();
        for (Object object : collection) {
            if (object != null) {
                String string = StringUtils.toString(object);
                if (string != null) {
                    sb.append(string).append(separator);
                }
            }
        }
        return sb.length() > 0 ? sb.substring(0, sb.length() - separator.length()) : StringUtils.EMPTY;
    }"
"protected void writeRequest(HttpState state, HttpConnection conn)
    throws IOException, HttpException {
        LOG.trace(
            ""enter HttpMethodBase.writeRequest(HttpState, HttpConnection)"");
        writeRequestLine(state, conn);
        writeRequestHeaders(state, conn);
        conn.writeLine(); // close head
        if (Wire.HEADER_WIRE.enabled()) {
            Wire.HEADER_WIRE.output(""\r\n"");
        }

        HttpVersion ver = getParams().getVersion();
        Header expectheader = getRequestHeader(""Expect"");
        String expectvalue = null;
        if (expectheader != null) {
            expectvalue = expectheader.getValue();
        }
        if ((expectvalue != null) 
         && (expectvalue.compareToIgnoreCase(""100-continue"") == 0)) {
            if (ver.greaterEquals(HttpVersion.HTTP_1_1)) {

                // make sure the status line and headers have been sent
                conn.flushRequestOutputStream();
                
                int readTimeout = conn.getParams().getSoTimeout();
                try {
                    conn.setSocketTimeout(RESPONSE_WAIT_TIME_MS);
                    readStatusLine(state, conn);
                    processStatusLine(state, conn);
                    readResponseHeaders(state, conn);
                    processResponseHeaders(state, conn);

                    if (this.statusLine.getStatusCode() == HttpStatus.SC_CONTINUE) {
                        // Discard status line
                        this.statusLine = null;
                        LOG.debug(""OK to continue received"");
                    } else {
                        return;
                    }
                } catch (InterruptedIOException e) {
                    if (!ExceptionUtil.isSocketTimeoutException(e)) {
                        throw e;
                    }
                    // Most probably Expect header is not recongnized
                    // Remove the header to signal the method 
                    // that it's okay to go ahead with sending data
                    removeRequestHeader(""Expect"");
                    LOG.info(""100 (continue) read timeout. Resume sending the request"");
                } finally {
                    conn.setSocketTimeout(readTimeout);
                }
                
            } else {
                removeRequestHeader(""Expect"");
                LOG.info(""'Expect: 100-continue' handshake is only supported by ""
                    + ""HTTP/1.1 or higher"");
            }
        }

        writeRequestBody(state, conn);
        // make sure the entire request body has been sent
        conn.flushRequestOutputStream();
    }"
"private void serializeMasterState(MasterState state, DataOutputStream dos) throws IOException {
		// magic number for error detection
		dos.writeInt(MASTER_STATE_MAGIC_NUMBER);

		// for safety, we serialize first into an array and then write the array and its
		// length into the checkpoint
		final ByteArrayOutputStream baos = new ByteArrayOutputStream();
		final DataOutputStream out = new DataOutputStream(baos);

		out.writeInt(state.version());
		out.writeUTF(state.name());

		final byte[] bytes = state.bytes();
		out.writeInt(bytes.length);
		out.write(bytes, 0, bytes.length);

		out.close();
		byte[] data = baos.toByteArray();

		dos.writeInt(data.length);
		dos.write(data, 0, data.length);
	}"
"public File append(byte[] data, int off, int len) throws IORuntimeException {
		return write(data, off, len, true);
	}"
"private List<String> getAdditionalJarsList() {

    List<String> wholeAdditionalJarsList = new ArrayList<>();

    List<String> jobAdditionalJars =
        getJobProps().getStringList(PIG_ADDITIONAL_JARS, null, "","");

    List<String> jobDefinedDefaultJars =
        getJobProps().getStringList(DEFAULT_PIG_ADDITIONAL_JARS, null, "","");
    List<String> systemDefinedDefaultJars =
        getSysProps().getStringList(DEFAULT_PIG_ADDITIONAL_JARS, null, "","");

    /*
      if user defines the custom default pig Jar, we only incorporate the user
      settings; otherwise, only when system configurations have it, we add the system
      additional jar settings. We don't accept both at the same time.
     */
    if (jobAdditionalJars != null) {
      wholeAdditionalJarsList.addAll(jobAdditionalJars);
    }

    if (jobDefinedDefaultJars != null) {
      wholeAdditionalJarsList.addAll(jobDefinedDefaultJars);
    } else if (systemDefinedDefaultJars != null) {
      wholeAdditionalJarsList.addAll(systemDefinedDefaultJars);
    }
    return wholeAdditionalJarsList;
  }"
"private JCheckBox getChkParseGit() {
		if (parseGit == null) {
			parseGit = new JCheckBox();
			parseGit.setText(Constant.messages.getString(""spider.options.label.git""));
		}
		return parseGit;
	}"
"public static int extractVersionFromSchemaName(String clz_name) {
    int idx = clz_name.lastIndexOf('V');
    if (idx == -1) return -1;
    try { return Integer.valueOf(clz_name.substring(idx+1)); }
    catch( NumberFormatException ex) { return -1; }
  }"
"void remove_document(int index)
    {
        ListIterator<Document<K>> listIterator = documents_.listIterator(index);
        Document<K> document = listIterator.next();
        listIterator.set(null);
        composite_.sub_vector(document.feature());
    }"
"public static <T> void setEndFrames(List<? extends Keyframe<T>> keyframes) {
    int size = keyframes.size();
    for (int i = 0; i < size - 1; i++) {
      // In the json, the keyframes only contain their starting frame.
      Keyframe<T> keyframe = keyframes.get(i);
      Keyframe<T> nextKeyframe = keyframes.get(i + 1);
      keyframe.endFrame = nextKeyframe.startFrame;
      if (keyframe.endValue == null && nextKeyframe.startValue != null) {
        keyframe.endValue = nextKeyframe.startValue;
        if (keyframe instanceof PathKeyframe) {
          ((PathKeyframe) keyframe).createPath();
        }
      }
    }
    Keyframe<?> lastKeyframe = keyframes.get(size - 1);
    if ((lastKeyframe.startValue == null || lastKeyframe.endValue == null) && keyframes.size() > 1) {
      // The only purpose the last keyframe has is to provide the end frame of the previous
      // keyframe.
      //noinspection SuspiciousMethodCalls
      keyframes.remove(lastKeyframe);
    }
  }"
"void quietlyCloseConnection(final Connection connection, final String closureReason)
   {
      if (connection != null) {
         try {
            logger.debug(""{} - Closing connection {}: {}"", poolName, connection, closureReason);

            try {
               setNetworkTimeout(connection, SECONDS.toMillis(15));
            }
            catch (SQLException e) {
               // ignore
            }
            finally {
               connection.close(); // continue with the close even if setNetworkTimeout() throws
            }
         }
         catch (Exception e) {
            logger.debug(""{} - Closing connection {} failed"", poolName, connection, e);
         }
      }
   }"
"public static Buffer toBuffer(AbstractEvent event) throws IOException {
		final ByteBuffer serializedEvent = EventSerializer.toSerializedEvent(event);

		MemorySegment data = MemorySegmentFactory.wrap(serializedEvent.array());

		final Buffer buffer = new NetworkBuffer(data, FreeingBufferRecycler.INSTANCE, false);
		buffer.setSize(serializedEvent.remaining());

		return buffer;
	}"
"public static int hashUnsafeBytes(Object base, long offset, int lengthInBytes) {
		return hashUnsafeBytes(base, offset, lengthInBytes, DEFAULT_SEED);
	}"
"private static void handleSingletonClass(String key, String value) throws Exception {
        Object object = handleValue(value);
        if(key.contains("","")) {
            String[] interfaces = key.split("","");
            for (String anInterface : interfaces) {
                serviceMap.put(anInterface, object);
            }
        } else {
            serviceMap.put(key, object);
        }
    }"
"private NettyClientStream.TransportState clientStream(Http2Stream stream) {
    return stream == null ? null : (NettyClientStream.TransportState) stream.getProperty(streamKey);
  }"
"private void retractRecordWithRowNumber(
			SortedMap<BaseRow, Long> sortedMap, BaseRow sortKey, BaseRow inputRow, Collector<BaseRow> out)
			throws Exception {
		Iterator<Map.Entry<BaseRow, Long>> iterator = sortedMap.entrySet().iterator();
		long curRank = 0L;
		boolean findsSortKey = false;
		while (iterator.hasNext() && isInRankEnd(curRank)) {
			Map.Entry<BaseRow, Long> entry = iterator.next();
			BaseRow key = entry.getKey();
			if (!findsSortKey && key.equals(sortKey)) {
				List<BaseRow> inputs = dataState.get(key);
				if (inputs == null) {
					// Skip the data if it's state is cleared because of state ttl.
					if (lenient) {
						LOG.warn(STATE_CLEARED_WARN_MSG);
					} else {
						throw new RuntimeException(STATE_CLEARED_WARN_MSG);
					}
				} else {
					Iterator<BaseRow> inputIter = inputs.iterator();
					while (inputIter.hasNext() && isInRankEnd(curRank)) {
						curRank += 1;
						BaseRow prevRow = inputIter.next();
						if (!findsSortKey && equaliser.equalsWithoutHeader(prevRow, inputRow)) {
							delete(out, prevRow, curRank);
							curRank -= 1;
							findsSortKey = true;
							inputIter.remove();
						} else if (findsSortKey) {
							retract(out, prevRow, curRank + 1);
							collect(out, prevRow, curRank);
						}
					}
					if (inputs.isEmpty()) {
						dataState.remove(key);
					} else {
						dataState.put(key, inputs);
					}
				}
			} else if (findsSortKey) {
				List<BaseRow> inputs = dataState.get(key);
				int i = 0;
				while (i < inputs.size() && isInRankEnd(curRank)) {
					curRank += 1;
					BaseRow prevRow = inputs.get(i);
					retract(out, prevRow, curRank + 1);
					collect(out, prevRow, curRank);
					i++;
				}
			} else {
				curRank += entry.getValue();
			}
		}
	}"
"public static Status fromThrowable(Throwable t) {
    Throwable cause = checkNotNull(t, ""t"");
    while (cause != null) {
      if (cause instanceof StatusException) {
        return ((StatusException) cause).getStatus();
      } else if (cause instanceof StatusRuntimeException) {
        return ((StatusRuntimeException) cause).getStatus();
      }
      cause = cause.getCause();
    }
    // Couldn't find a cause with a Status
    return UNKNOWN.withCause(t);
  }"
"public int size() {
		int size = 0;
		for (SourceFolder sourceFolder : this.sourceFolders.values()) {
			size += sourceFolder.getFiles().size();
		}
		return size;
	}"
"public Map<String, String> encode(Map<String, Object> tableProperties)
    {
        return ImmutableMap.of();
    }"
"public static BufferRecycler instance() {
        SoftReference<BufferRecycler> ref = recyclerRef.get();

        BufferRecycler bufferRecycler;
        if (ref == null) {
            bufferRecycler = null;
        } else {
            bufferRecycler = ref.get();
        }

        if (bufferRecycler == null) {
            bufferRecycler = new BufferRecycler();
            recyclerRef.set(new SoftReference<BufferRecycler>(bufferRecycler));
        }
        return bufferRecycler;
    }"
"public static boolean verify(final String name, final X509Certificate cert) {
        try {
        	verifier.verify(name, cert);
            return true;
        } catch (final SSLException ex) {
        	// this is only logged here because eventually a CertificateException will be throw in verifyAndThrow.
        	// If this method is called in another method, the caller should be responsible to throw exceptions,
            logger.error(ex.getMessage(), ex);
            
            return false;
        }
    }"
"static void allocateHuffmanCodeLengths(final int[] array, final int maximumLength) {
        switch (array.length) {
            case 2:
                array[1] = 1;
                // fall through
            case 1:
                array[0] = 1;
                return;
        }

        /* Pass 1 : Set extended parent pointers */
        setExtendedParentPointers(array);

        /* Pass 2 : Find number of nodes to relocate in order to achieve maximum code length */
        int nodesToRelocate = findNodesToRelocate(array, maximumLength);

        /* Pass 3 : Generate code lengths */
        if (array[0] % array.length >= nodesToRelocate) {
            allocateNodeLengths(array);
        } else {
            int insertDepth = maximumLength - (32 - Integer.numberOfLeadingZeros(nodesToRelocate - 1));
            allocateNodeLengthsWithRelocation(array, nodesToRelocate, insertDepth);
        }
    }"
"@SuppressWarnings(""PMD.ConfusingTernary"")
  final void expandOrRetry(E e, boolean wasUncontended) {
    int h;
    if ((h = getProbe()) == 0) {
      ThreadLocalRandom.current(); // force initialization
      h = getProbe();
      wasUncontended = true;
    }
    boolean collide = false; // True if last slot nonempty
    for (int attempt = 0; attempt < ATTEMPTS; attempt++) {
      Buffer<E>[] buffers;
      Buffer<E> buffer;
      int n;
      if (((buffers = table) != null) && ((n = buffers.length) > 0)) {
        if ((buffer = buffers[(n - 1) & h]) == null) {
          if ((tableBusy == 0) && casTableBusy()) { // Try to attach new Buffer
            boolean created = false;
            try { // Recheck under lock
              Buffer<E>[] rs;
              int mask, j;
              if (((rs = table) != null) && ((mask = rs.length) > 0)
                  && (rs[j = (mask - 1) & h] == null)) {
                rs[j] = create(e);
                created = true;
              }
            } finally {
              tableBusy = 0;
            }
            if (created) {
              break;
            }
            continue; // Slot is now non-empty
          }
          collide = false;
        } else if (!wasUncontended) { // CAS already known to fail
          wasUncontended = true;      // Continue after rehash
        } else if (buffer.offer(e) != Buffer.FAILED) {
          break;
        } else if (n >= MAXIMUM_TABLE_SIZE || table != buffers) {
          collide = false; // At max size or stale
        } else if (!collide) {
          collide = true;
        } else if (tableBusy == 0 && casTableBusy()) {
          try {
            if (table == buffers) { // Expand table unless stale
              table = Arrays.copyOf(buffers, n << 1);
            }
          } finally {
            tableBusy = 0;
          }
          collide = false;
          continue; // Retry with expanded table
        }
        h = advanceProbe(h);
      } else if ((tableBusy == 0) && (table == buffers) && casTableBusy()) {
        boolean init = false;
        try { // Initialize table
          if (table == buffers) {
            @SuppressWarnings({""unchecked"", ""rawtypes""})
            Buffer<E>[] rs = new Buffer[1];
            rs[0] = create(e);
            table = rs;
            init = true;
          }
        } finally {
          tableBusy = 0;
        }
        if (init) {
          break;
        }
      }
    }
  }"
"public boolean containsLong(long value) {
		for (int i = 1; i < maxPoolSize; i++) {
			if (types[i] == LONG && readLong(i) == value) return true;
		}
		return false;
	}"
"@Override
	public int compareTo(ValueArray<DoubleValue> o) {
		DoubleValueArray other = (DoubleValueArray) o;

		int min = Math.min(position, other.position);
		for (int i = 0; i < min; i++) {
			int cmp = Double.compare(data[i], other.data[i]);

			if (cmp != 0) {
				return cmp;
			}
		}

		return Integer.compare(position, other.position);
	}"
"@Override
    public void onFragment(DirectBuffer buffer, int offset, int length, Header header) {
        if (buffer != null && length > 0) {
            ByteBuffer byteBuffer = buffer.byteBuffer().order(ByteOrder.nativeOrder());
            byteBuffer.position(offset);
            byte[] b = new byte[length];
            byteBuffer.get(b);
            String hostPort = new String(b);
            System.out.println(""Host port "" + hostPort + "" offset "" + offset + "" length "" + length);
            String[] split = hostPort.split("":"");
            if (split == null || split.length != 3) {
                System.err.println(""no host port stream found"");
                return;
            }

            int port = Integer.parseInt(split[1]);
            int streamToPublish = Integer.parseInt(split[2]);
            String channel = AeronUtil.aeronChannel(split[0], port);
            INDArray arrGet = holder.get();
            AeronNDArrayPublisher publisher = AeronNDArrayPublisher.builder().streamId(streamToPublish).aeron(aeron)
                            .channel(channel).build();
            try {
                publisher.publish(arrGet);
            } catch (Exception e) {
                e.printStackTrace();
            }

            try {
                publisher.close();
            } catch (Exception e) {

            }
        }
    }"
"public static StatusRuntimeException toStatusRuntimeException(com.google.rpc.Status statusProto) {
    return toStatus(statusProto).asRuntimeException(toMetadata(statusProto));
  }"
"private static void fillColumnWithRepeatingValue(Object[] vals, int fieldIdx, Object repeatingValue, int childCount) {

		if (fieldIdx == -1) {
			// set value as an object
			Arrays.fill(vals, 0, childCount, repeatingValue);
		} else {
			// set value as a field of Row
			Row[] rows = (Row[]) vals;
			for (int i = 0; i < childCount; i++) {
				rows[i].setField(fieldIdx, repeatingValue);
			}
		}
	}"
"public void save(ObjectOutputStream out) throws IOException
    {
        out.writeObject(base);
        out.writeObject(check);
        out.writeObject(fail);
        out.writeObject(output);
        out.writeObject(l);
    }"
"public static double recall(long tpCount, long fnCount, double edgeCase) {
        //Edge case
        if (tpCount == 0 && fnCount == 0) {
            return edgeCase;
        }

        return tpCount / (double) (tpCount + fnCount);
    }"
"public static synchronized void registerSystemPropertiesListener(PropertiesListener listener) {
		Properties currentProperties = System.getProperties();

		// 将System的properties实现替换为ListenableProperties
		if (!(currentProperties instanceof ListenableProperties)) {
			ListenableProperties newProperties = new ListenableProperties(currentProperties);
			System.setProperties(newProperties);
			currentProperties = newProperties;
		}

		((ListenableProperties) currentProperties).register(listener);
	}"
"public static <T> T createProxy(T target, Class<? extends Aspect> aspectClass){
		return createProxy(target, ReflectUtil.newInstance(aspectClass));
	}"
"public static void parseNature(Term term) {
        if (!Nature.NW.equals(term.natrue())) {
            return;
        }

        String name = term.getName();

        if (name.length() <= 3) {
            return;
        }

        // 是否是外国人名
        if (ForeignPersonRecognition.isFName(name)) {
            term.setNature(NatureLibrary.getNature(""nrf""));
            return;
        }

        List<Term> subTerm = term.getSubTerm();

        // 判断是否是机构名
        term.setSubTerm(subTerm);
        Term first = subTerm.get(0);
        Term last = subTerm.get(subTerm.size() - 1);
        int[] is = companyMap.get(first.getName());
        int all = 0;

        is = companyMap.get(last.getName());
        if (is != null) {
            all += is[1];
        }

        if (all > 1000) {
            term.setNature(NatureLibrary.getNature(""nt""));
            return;
        }
    }"
"private void complete() {
		if (stopped) {
			return;
		}

		log.info(""Spidering process is complete. Shutting down..."");
		this.stopped = true;
		if (httpSender != null) {
			this.getHttpSender().shutdown();
			httpSender = null;
		}

		// Notify the controller to clean up memory
		controller.reset();

		// Issue the shutdown command on a separate thread, as the current thread is most likely one
		// from the pool
		new Thread(new Runnable() {
			@Override
			public void run() {
				if (threadPool != null) {
					threadPool.shutdown();
				}
				// Notify the listeners -- in the meanwhile
				notifyListenersSpiderComplete(true);
				controller.reset();
				threadPool = null;
			}
		}, ""ZAP-SpiderShutdownThread-"" + id).start();
	}"
"public Excel07SaxReader read(OPCPackage opcPackage, int sheetIndex) throws POIException {
		InputStream sheetInputStream = null;
		try {
			final XSSFReader xssfReader = new XSSFReader(opcPackage);

			// 获取共享样式表
			stylesTable = xssfReader.getStylesTable();
			// 获取共享字符串表
			this.sharedStringsTable = xssfReader.getSharedStringsTable();

			if (sheetIndex > -1) {
				this.sheetIndex = sheetIndex;
				// 根据 rId# 或 rSheet# 查找sheet
				sheetInputStream = xssfReader.getSheet(RID_PREFIX + (sheetIndex + 1));
				parse(sheetInputStream);
			} else {
				this.sheetIndex = -1;
				// 遍历所有sheet
				final Iterator<InputStream> sheetInputStreams = xssfReader.getSheetsData();
				while (sheetInputStreams.hasNext()) {
					// 重新读取一个sheet时行归零
					curRow = 0;
					this.sheetIndex++;
					sheetInputStream = sheetInputStreams.next();
					parse(sheetInputStream);
				}
			}
		} catch (DependencyException e) {
			throw e;
		} catch (Exception e) {
			throw ExceptionUtil.wrap(e, POIException.class);
		} finally {
			IoUtil.close(sheetInputStream);
		}
		return this;
	}"
"public void setTokenValue(String tokenName, Cookie value) {
		if (value == null) {
			tokenValues.remove(tokenName);
		} else {
			tokenValues.put(tokenName, value);
		}
	}"
"public static void pickupFromRequest(RpcInvokeContext context, SofaRequest request, boolean init) {
        if (context == null && !init) {
            return;
        }
        // 解析请求 
        Map<String, String> requestBaggage = (Map<String, String>) request
            .getRequestProp(RemotingConstants.RPC_REQUEST_BAGGAGE);
        if (CommonUtils.isNotEmpty(requestBaggage)) {
            if (context == null) {
                context = RpcInvokeContext.getContext();
            }
            context.putAllRequestBaggage(requestBaggage);
        }
    }"
"@Deprecated
    public void kill(Process proc, Map<String, String> modelEnvVars) throws InterruptedException {
        ProcessTree pt = ProcessTree.get();
        if(proc!=null)
            pt.get(proc).killRecursively();
        if(modelEnvVars!=null)
            pt.killAll(modelEnvVars);
    }"
"@Override
    public Object map(Object input) {
        return new Text(map.get(input.toString()));
    }"
"public void setAnyPartitioning(FieldSet partitionedFields) {
		if (partitionedFields == null) {
			throw new NullPointerException();
		}
		this.partitioning = PartitioningProperty.ANY_PARTITIONING;
		this.partitioningFields = partitionedFields;
		this.ordering = null;
	}"
"private StreamGraph generateInternal(List<StreamTransformation<?>> transformations) {
		for (StreamTransformation<?> transformation: transformations) {
			transform(transformation);
		}
		return streamGraph;
	}"
"private static boolean containsIgnoreCase(List<String> names, String nameToFind) {
		if (CollUtil.isEmpty(names)) {
			return false;
		}
		if (StrUtil.isEmpty(nameToFind)) {
			return false;
		}
		for (String name : names) {
			if (nameToFind.equalsIgnoreCase(name)) {
				return true;
			}
		}
		return false;
	}"
"public AndCondition optimize() {
        AndCondition result = new AndCondition();
        for (Condition each : conditions) {
            if (Condition.class.equals(each.getClass())) {
                result.getConditions().add(each);
            }
        }
        if (result.getConditions().isEmpty()) {
            result.getConditions().add(new NullCondition());
        }
        return result;
    }"
"private double getMomentumFromConfig(Map<String, Object> layerConfig) throws InvalidKerasConfigurationException {
        Map<String, Object> innerConfig = KerasLayerUtils.getInnerLayerConfigFromConfig(layerConfig, conf);
        if (!innerConfig.containsKey(LAYER_FIELD_MOMENTUM))
            throw new InvalidKerasConfigurationException(
                    ""Keras BatchNorm layer config missing "" + LAYER_FIELD_MOMENTUM + "" field"");
        return (double) innerConfig.get(LAYER_FIELD_MOMENTUM);
    }"
"private synchronized Jwt getJwt(ICacheStrategy cacheStrategy, Jwt.Key key) {
        Jwt result = cacheStrategy.getCachedJwt(key);
        if(result == null) {
            //cache an empty JWT first.
            result = new Jwt(key);
            cacheStrategy.cacheJwt(key, result);
        }
        return result;
    }"
"public int getIntValue(Keyframe<Integer> keyframe, float keyframeProgress) {
    if (keyframe.startValue == null || keyframe.endValue == null) {
      throw new IllegalStateException(""Missing values for keyframe."");
    }
    int startColor = keyframe.startValue;
    int endColor = keyframe.endValue;

    if (valueCallback != null) {
      //noinspection ConstantConditions
      Integer value = valueCallback.getValueInternal(keyframe.startFrame, keyframe.endFrame, startColor,
              endColor, keyframeProgress, getLinearCurrentKeyframeProgress(), getProgress());
      if (value != null) {
        return value;
      }
    }

    return GammaEvaluator.evaluate(MiscUtils.clamp(keyframeProgress, 0f, 1f), startColor, endColor);
  }"
"public TProcessorFactory getAuthProcFactory(ThriftCLIService service) throws LoginException {
    if (authTypeStr.equalsIgnoreCase(AuthTypes.KERBEROS.getAuthName())) {
      return KerberosSaslHelper.getKerberosProcessorFactory(saslServer, service);
    } else {
      return PlainSaslHelper.getPlainProcessorFactory(service);
    }
  }"
"@Exported(name=""actions"")
    @Nonnull
    public final List<? extends Action> getAllActions() {
        List<Action> _actions = getActions();
        boolean adding = false;
        for (TransientActionFactory<?> taf : TransientActionFactory.factoriesFor(getClass(), Action.class)) {
            Collection<? extends Action> additions = createFor(taf);
            if (!additions.isEmpty()) {
                if (!adding) { // need to make a copy
                    adding = true;
                    _actions = new ArrayList<>(_actions);
                }
                _actions.addAll(additions);
            }
        }
        return Collections.unmodifiableList(_actions);
    }"
"@JsonIgnore
    public boolean isValid() {
        return StringUtils.isNotBlank(getMetadata())
            && StringUtils.isNotBlank(getSigningCertificate())
            && StringUtils.isNotBlank(getSigningKey())
            && StringUtils.isNotBlank(getEncryptionCertificate())
            && StringUtils.isNotBlank(getEncryptionKey());
    }"
"void writeSnapshotData(DataOutputView out) throws IOException {
		out.writeUTF(pojoClass.getName());
		writeOptionalMap(out, fieldSerializerSnapshots, PojoFieldUtils::writeField, TypeSerializerSnapshot::writeVersionedSnapshot);
		writeOptionalMap(out, registeredSubclassSerializerSnapshots, NoOpWriter.noopWriter(), TypeSerializerSnapshot::writeVersionedSnapshot);
		writeOptionalMap(out, nonRegisteredSubclassSerializerSnapshots, NoOpWriter.noopWriter(), TypeSerializerSnapshot::writeVersionedSnapshot);
	}"
"private void replaceOrRegister(MDAGNode originNode, String str)
    {
        char transitionLabelChar = str.charAt(0);
        MDAGNode relevantTargetNode = originNode.transition(transitionLabelChar);

        //If relevantTargetNode has transitions and there is at least one char left to process, recursively call 
        //this on the next char in order to further processing down the _transition path corresponding to str
        if (relevantTargetNode.hasTransitions() && !str.substring(1).isEmpty())
            replaceOrRegister(relevantTargetNode, str.substring(1));
        /////

        //Get the node representing the equivalence class that relevantTargetNode belongs to. MDAGNodes hash on the
        //transitions paths that can be traversed from them and nodes able to be reached from them;
        //nodes with the same equivalence classes will hash to the same bucket.
        MDAGNode equivalentNode = equivalenceClassMDAGNodeHashMap.get(relevantTargetNode);

        if (equivalentNode == null)  //if there is no node with the same right language as relevantTargetNode
            equivalenceClassMDAGNodeHashMap.put(relevantTargetNode, relevantTargetNode);
        else if (equivalentNode != relevantTargetNode)   //if there is another node with the same right language as relevantTargetNode, reassign the
        {                                               //_transition between originNode and relevantTargetNode, to originNode and the node representing the equivalence class of interest
            relevantTargetNode.decrementTargetIncomingTransitionCounts();
            transitionCount -= relevantTargetNode.getOutgoingTransitionCount(); //Since this method is recursive, the outgoing transitions of all of relevantTargetNode's child nodes have already been reassigned, 
            //so we only need to decrement the _transition count by the relevantTargetNode's outgoing _transition count
            originNode.reassignOutgoingTransition(transitionLabelChar, relevantTargetNode, equivalentNode);
        }
    }"
"public final int getBeInt24(final int pos) {
        final int position = origin + pos;

        if (pos + 2 >= limit || pos < 0) throw new IllegalArgumentException(""limit excceed: ""
                                                                            + (pos < 0 ? pos : (pos + 2)));

        byte[] buf = buffer;
        return (0xff & buf[position + 2]) | ((0xff & buf[position + 1]) << 8) | ((buf[position]) << 16);
    }"
"@SuppressWarnings({""cast"", ""unchecked""})
    public static <E> Weigher<? super Iterable<E>> iterable() {
        return (Weigher<Iterable<E>>) (Weigher<?>) IterableWeigher.INSTANCE;
    }"
"@SuppressWarnings(""rawtypes"")
	public static boolean isEmpty(Object obj) {
		if(null == obj) {
			return true;
		}
		
		if(obj instanceof CharSequence) {
			return StrUtil.isEmpty((CharSequence)obj);
		}else if(obj instanceof Map) {
			return MapUtil.isEmpty((Map)obj);
		}else if(obj instanceof Iterable) {
			return IterUtil.isEmpty((Iterable)obj);
		}else if(obj instanceof Iterator) {
			return IterUtil.isEmpty((Iterator)obj);
		}else if(ArrayUtil.isArray(obj)) {
			return ArrayUtil.isEmpty(obj);
		}
		
		return false;
	}"
"public void addStr(Object str) {
    if(_id == null || str != null) {
      if(_is == null || _sparseLen >= _is.length) {
        append2slowstr();
        addStr(str);
        assert _sparseLen <= _len;
        return;
      }
      if (str != null) {
        if(_id != null)_id[_sparseLen] = _len;
        _is[_sparseLen] = _sslen;
        _sparseLen++;
        if (str instanceof BufferedString)
          append_ss((BufferedString) str);
        else // this spares some callers from an unneeded conversion to BufferedString first
          append_ss((String) str);
      } else if (_id == null) {
        _is[_sparseLen] = CStrChunk.NA;
        set_sparseLen(_sparseLen + 1);
      }
    }
    set_len(_len + 1);
    assert _sparseLen <= _len;
  }"
"@SuppressWarnings(""unchecked"")
	public <T> Converter<T> getCustomConverter(Type type) {
		return (null == customConverterMap) ? null : (Converter<T>) customConverterMap.get(type);
	}"
"public static void assertNOutSet(String layerType, String layerName, long layerIndex, long nOut) {
        if (nOut <= 0) {
            if (layerName == null)
                layerName = ""(name not set)"";
            throw new DL4JInvalidConfigException(layerType + "" (index="" + layerIndex + "", name="" + layerName + "") nOut=""
                            + nOut + ""; nOut must be > 0"");
        }
    }"
"public void generateAPIFiles(List<ApiImplementor> implementors) throws IOException {
        for (ApiImplementor implementor : implementors) {
            this.generateAPIFiles(implementor);
        }
    }"
"public void setPath(String path) throws URIException {

        if (path == null || path.length() == 0) {
            _path = _opaque = (path == null) ? null : path.toCharArray();
            setURI();
            return;
        }
        // set the charset to do escape encoding
        String charset = getProtocolCharset();

        if (_is_net_path || _is_abs_path) {
            _path = encode(path, allowed_abs_path, charset);
        } else if (_is_rel_path) {
            StringBuffer buff = new StringBuffer(path.length());
            int at = path.indexOf('/');
            if (at == 0) { // never 0
                throw new URIException(URIException.PARSING,
                        ""incorrect relative path"");
            }
            if (at > 0) {
                buff.append(encode(path.substring(0, at), allowed_rel_path,
                            charset));
                buff.append(encode(path.substring(at), allowed_abs_path,
                            charset));
            } else {
                buff.append(encode(path, allowed_rel_path, charset));
            }
            _path = buff.toString().toCharArray();
        } else if (_is_opaque_part) {
            StringBuffer buf = new StringBuffer();
            buf.insert(0, encode(path.substring(0, 1), uric_no_slash, charset));
            buf.insert(1, encode(path.substring(1), uric, charset));
            _opaque = buf.toString().toCharArray();
        } else {
            throw new URIException(URIException.PARSING, ""incorrect path"");
        }
        setURI();
    }"
"@SuppressWarnings(""unchecked"")
	public static <T> TypeInformation<T> convertToTypeInfo(String avroSchemaString) {
		Preconditions.checkNotNull(avroSchemaString, ""Avro schema must not be null."");
		final Schema schema;
		try {
			schema = new Schema.Parser().parse(avroSchemaString);
		} catch (SchemaParseException e) {
			throw new IllegalArgumentException(""Could not parse Avro schema string."", e);
		}
		return (TypeInformation<T>) convertToTypeInfo(schema);
	}"
"public FlinkKafkaConsumerBase<T> setStartFromGroupOffsets() {
		this.startupMode = StartupMode.GROUP_OFFSETS;
		this.startupOffsetsTimestamp = null;
		this.specificStartupOffsets = null;
		return this;
	}"
"public FormValidation doCheckHome(@QueryParameter File value) {
        // this can be used to check the existence of a file on the server, so needs to be protected
        Jenkins.getInstance().checkPermission(Jenkins.ADMINISTER);

        if (value.getPath().isEmpty()) {
            return FormValidation.ok();
        }

        if (!value.isDirectory()) {
            return FormValidation.warning(Messages.ToolDescriptor_NotADirectory(value));
        }

        return checkHomeDirectory(value);
    }"
"@Override
    public void accumulateChunk(NDArrayMessageChunk chunk) {
        String id = chunk.getId();
        if (!chunks.containsKey(id)) {
            List<NDArrayMessageChunk> list = new ArrayList<>();
            list.add(chunk);
            chunks.put(id, list);
        } else {
            List<NDArrayMessageChunk> chunkList = chunks.get(id);
            chunkList.add(chunk);
        }

        log.debug(""Accumulating chunk for id "" + chunk.getId());


    }"
"private static InetAddress buildBenchmarkAddr() {
    InetAddress tmp = null;
    try {
      Enumeration<NetworkInterface> networkInterfaces = NetworkInterface.getNetworkInterfaces();
      outer: while (networkInterfaces.hasMoreElements()) {
        NetworkInterface networkInterface = networkInterfaces.nextElement();
        if (!networkInterface.isLoopback()) {
          continue;
        }
        Enumeration<NetworkInterface> subInterfaces = networkInterface.getSubInterfaces();
        while (subInterfaces.hasMoreElements()) {
          NetworkInterface subLoopback = subInterfaces.nextElement();
          if (subLoopback.getDisplayName().contains(""benchmark"")) {
            tmp = subLoopback.getInetAddresses().nextElement();
            System.out.println(""\nResolved benchmark address to "" + tmp + "" on ""
                + subLoopback.getDisplayName() + ""\n\n"");
            break outer;
          }
        }
      }
    } catch (SocketException se) {
      System.out.println(""\nWARNING: Error trying to resolve benchmark interface \n"" +  se);
    }
    if (tmp == null) {
      try {
        System.out.println(
            ""\nWARNING: Unable to resolve benchmark interface, defaulting to localhost"");
        tmp = InetAddress.getLocalHost();
      } catch (UnknownHostException uhe) {
        throw new RuntimeException(uhe);
      }
    }
    return tmp;
  }"
"@Nullable
  private static Object convertPrimitiveField(Group g, int fieldIndex, int index, boolean binaryAsString)
  {
    PrimitiveType pt = (PrimitiveType) g.getType().getFields().get(fieldIndex);
    OriginalType ot = pt.getOriginalType();

    try {
      if (ot != null) {
        // convert logical types
        switch (ot) {
          case DATE:
            long ts = g.getInteger(fieldIndex, index) * MILLIS_IN_DAY;
            return ts;
          case TIME_MICROS:
            return g.getLong(fieldIndex, index);
          case TIME_MILLIS:
            return g.getInteger(fieldIndex, index);
          case TIMESTAMP_MICROS:
            return TimeUnit.MILLISECONDS.convert(g.getLong(fieldIndex, index), TimeUnit.MICROSECONDS);
          case TIMESTAMP_MILLIS:
            return g.getLong(fieldIndex, index);
          case INTERVAL:
          /*
          INTERVAL is used for an interval of time. It must annotate a fixed_len_byte_array of length 12.
          This array stores three little-endian unsigned integers that represent durations at different
          granularities of time. The first stores a number in months, the second stores a number in days,
          and the third stores a number in milliseconds. This representation is independent of any particular
          timezone or date.

          Each component in this representation is independent of the others. For example, there is no
          requirement that a large number of days should be expressed as a mix of months and days because there is
          not a constant conversion from days to months.

          The sort order used for INTERVAL is undefined. When writing data, no min/max statistics should be
           saved for this type and if such non-compliant statistics are found during reading, they must be ignored.
           */
            Binary intervalVal = g.getBinary(fieldIndex, index);
            IntBuffer intBuf = intervalVal.toByteBuffer().order(ByteOrder.LITTLE_ENDIAN).asIntBuffer();
            int months = intBuf.get(0);
            int days = intBuf.get(1);
            int millis = intBuf.get(2);
            StringBuilder periodBuilder = new StringBuilder(""P"");
            if (months > 0) {
              periodBuilder.append(months).append(""M"");
            }
            if (days > 0) {
              periodBuilder.append(days).append(""D"");
            }
            if (periodBuilder.length() > 1) {
              Period p = Period.parse(periodBuilder.toString());
              Duration d = p.toStandardDuration().plus(millis);
              return d;
            } else {
              return new Duration(millis);
            }
          case INT_8:
          case INT_16:
          case INT_32:
            return g.getInteger(fieldIndex, index);
          case INT_64:
            return g.getLong(fieldIndex, index);
          // todo: idk wtd about unsigned
          case UINT_8:
          case UINT_16:
          case UINT_32:
            return g.getInteger(fieldIndex, index);
          case UINT_64:
            return g.getLong(fieldIndex, index);
          case DECIMAL:
          /*
            DECIMAL can be used to annotate the following types:
              int32: for 1 <= precision <= 9
              int64: for 1 <= precision <= 18; precision < 10 will produce a warning
              fixed_len_byte_array: precision is limited by the array size. Length n can
                store <= floor(log_10(2^(8*n - 1) - 1)) base-10 digits
              binary: precision is not limited, but is required. The minimum number of bytes to store
                the unscaled value should be used.
           */
            int precision = pt.asPrimitiveType().getDecimalMetadata().getPrecision();
            int scale = pt.asPrimitiveType().getDecimalMetadata().getScale();
            switch (pt.getPrimitiveTypeName()) {
              case INT32:
                return new BigDecimal(g.getInteger(fieldIndex, index));
              case INT64:
                return new BigDecimal(g.getLong(fieldIndex, index));
              case FIXED_LEN_BYTE_ARRAY:
              case BINARY:
                Binary value = g.getBinary(fieldIndex, index);
                return convertBinaryToDecimal(value, precision, scale);
              default:
                throw new RE(
                    ""Unknown 'DECIMAL' type supplied to primitive conversion: %s (this should never happen)"",
                    pt.getPrimitiveTypeName()
                );
            }
          case UTF8:
          case ENUM:
          case JSON:
            return g.getString(fieldIndex, index);
          case LIST:
          case MAP:
          case MAP_KEY_VALUE:
          case BSON:
          default:
            throw new RE(
                ""Non-primitive supplied to primitive conversion: %s (this should never happen)"",
                ot.name()
            );
        }
      } else {
        // fallback to handling the raw primitive type if no logical type mapping
        switch (pt.getPrimitiveTypeName()) {
          case BOOLEAN:
            return g.getBoolean(fieldIndex, index);
          case INT32:
            return g.getInteger(fieldIndex, index);
          case INT64:
            return g.getLong(fieldIndex, index);
          case FLOAT:
            return g.getFloat(fieldIndex, index);
          case DOUBLE:
            return g.getDouble(fieldIndex, index);
          case INT96:
            Binary tsBin = g.getInt96(fieldIndex, index);
            return convertInt96BinaryToTimestamp(tsBin);
          case FIXED_LEN_BYTE_ARRAY:
          case BINARY:
            Binary bin = g.getBinary(fieldIndex, index);
            byte[] bytes = bin.getBytes();
            if (binaryAsString) {
              return StringUtils.fromUtf8(bytes);
            } else {
              return bytes;
            }
          default:
            throw new RE(""Unknown primitive conversion: %s"", ot.name());
        }
      }
    }
    catch (Exception ex) {
      return null;
    }
  }"
"public static byte[] toByteArray(Writable... writables) {
        final DataOutputBuffer out = new DataOutputBuffer();
        try {
            for (Writable w : writables) {
                w.write(out);
            }
            out.close();
        } catch (IOException e) {
            throw new RuntimeException(""Fail to convert writables to a byte array"", e);
        }
        return out.getData();
    }"
"protected void processCookieHeaders(
            final CookieSpec parser, 
            final Header[] headers, 
            final HttpState state, 
            final HttpConnection conn) {
        LOG.trace(""enter HttpMethodBase.processCookieHeaders(Header[], HttpState, ""
                  + ""HttpConnection)"");

        String host = this.params.getVirtualHost();
        if (host == null) {
            host = conn.getHost();
        }
        for (int i = 0; i < headers.length; i++) {
            Header header = headers[i];
            Cookie[] cookies = null;
            try {
                cookies = parser.parse(
                  host,
                  conn.getPort(),
                  getPath(),
                  conn.isSecure(),
                  header);
            } catch (MalformedCookieException e) {
                if (LOG.isWarnEnabled()) {
                    LOG.warn(""Invalid cookie header: \"""" 
                        + header.getValue() 
                        + ""\"". "" + e.getMessage());
                }
            }
            if (cookies != null) {
                for (int j = 0; j < cookies.length; j++) {
                    Cookie cookie = cookies[j];
                    try {
                        parser.validate(
                          host,
                          conn.getPort(),
                          getPath(),
                          conn.isSecure(),
                          cookie);
                        state.addCookie(cookie);
                        if (LOG.isDebugEnabled()) {
                            LOG.debug(""Cookie accepted: \"""" 
                                + parser.formatCookie(cookie) + ""\"""");
                        }
                    } catch (MalformedCookieException e) {
                        if (LOG.isWarnEnabled()) {
                            LOG.warn(""Cookie rejected: \"""" + parser.formatCookie(cookie) 
                                + ""\"". "" + e.getMessage());
                        }
                    }
                }
            }
        }
    }"
"public MockResponse setHeader(String name, Object value) {
    removeHeader(name);
    return addHeader(name, value);
  }"
"@SneakyThrows
    public static String getCasServerHostName() {
        val hostName = InetAddress.getLocalHost().getHostName();
        val index = hostName.indexOf('.');
        if (index > 0) {
            return hostName.substring(0, index);
        }
        return hostName;
    }"
"@Override public Word2VecModel createImpl() {
    Word2VecModel.Word2VecParameters parms = parameters.createImpl();
    return new Word2VecModel( model_id.key(), parms, null);
  }"
"static void ensurePrincipalAccessIsAllowedForService(final Service service, final RegisteredService registeredService,
                                                         final TicketGrantingTicket ticketGrantingTicket,
                                                         final boolean retrievePrincipalAttributesFromReleasePolicy)
        throws UnauthorizedServiceException, PrincipalException {
        ensurePrincipalAccessIsAllowedForService(service, registeredService,
            ticketGrantingTicket.getRoot().getAuthentication(), retrievePrincipalAttributesFromReleasePolicy);

    }"
"public static Config fromYAML(URL url) throws IOException {
        ConfigSupport support = new ConfigSupport();
        return support.fromYAML(url, Config.class);
    }"
"@Override
    public void merge(Evaluation other) {
        if (other == null)
            return;

        truePositives.incrementAll(other.truePositives);
        falsePositives.incrementAll(other.falsePositives);
        trueNegatives.incrementAll(other.trueNegatives);
        falseNegatives.incrementAll(other.falseNegatives);

        if (confusion == null) {
            if (other.confusion != null)
                confusion = new ConfusionMatrix<>(other.confusion);
        } else {
            if (other.confusion != null)
                confusion().add(other.confusion);
        }
        numRowCounter += other.numRowCounter;
        if (labelsList.isEmpty())
            labelsList.addAll(other.labelsList);

        if (topN != other.topN) {
            log.warn(""Different topN values ({} vs {}) detected during Evaluation merging. Top N accuracy may not be accurate."",
                            topN, other.topN);
        }
        this.topNCorrectCount += other.topNCorrectCount;
        this.topNTotalCount += other.topNTotalCount;
    }"
"private static void enlargeTables(float[][] data, int[][] rowIndex, int cols, int currentRow, int currentCol) {
        while (data[currentRow].length < currentCol + cols) {
            if(data[currentRow].length == SPARSE_MATRIX_DIM) {
                currentCol = 0;
                cols -= (data[currentRow].length - currentCol);
                currentRow++;
                data[currentRow] = malloc4f(ALLOCATED_ARRAY_LEN);
                rowIndex[currentRow] = malloc4(ALLOCATED_ARRAY_LEN);
            } else {
                int newLen = (int) Math.min((long) data[currentRow].length << 1L, (long) SPARSE_MATRIX_DIM);
                data[currentRow] = Arrays.copyOf(data[currentRow], newLen);
                rowIndex[currentRow] = Arrays.copyOf(rowIndex[currentRow], newLen);
            }
        }
    }"
"public static String encodeColor(Color color, String prefix) {
		final StringBuffer builder = new StringBuffer(prefix);
		String colorHex;
		colorHex = Integer.toHexString(color.getRed());
		if (1 == colorHex.length()) {
			builder.append('0');
		}
		builder.append(colorHex);
		colorHex = Integer.toHexString(color.getGreen());
		if (1 == colorHex.length()) {
			builder.append('0');
		}
		builder.append(colorHex);
		colorHex = Integer.toHexString(color.getBlue());
		if (1 == colorHex.length()) {
			builder.append('0');
		}
		builder.append(colorHex);
		return builder.toString();
	}"
"public Docket genericModelSubstitutes(Class... genericClasses) {
    for (Class clz : genericClasses) {
      this.ruleBuilders.add(newGenericSubstitutionFunction(clz));
    }
    return this;
  }"
"public static String translate(String tag)
    {
        String cn = translator.get(tag);
        if (cn == null) return tag;
        return cn;
    }"
"private boolean isHtml() {
        StaplerRequest req = Stapler.getCurrentRequest();
        return req!=null && req.getAttribute(""html"")!=null;
    }"
"private static long getHashCode(Object key)
    {
        // identityHashCode of two objects are not guaranteed to be different.
        // Any additional identity information can reduce collisions.
        // In the most cases below, we use size of an object to be the extra identity.
        // Experiments show that with 100 million objects created, using identityHashCode has a collision rate around 2.5%.
        // However, if these 100 million objects are combined with 10 different sizes, the collision rate is around 0.1%.
        // The collision rate can be lower than 0.001% if there are 1000 different sizes.
        int extraIdentity;
        if (key == null) {
            extraIdentity = 0;
        }
        else if (key instanceof Block) {
            extraIdentity = (int) ((Block) key).getRetainedSizeInBytes();
        }
        else if (key instanceof Slice) {
            extraIdentity = (int) ((Slice) key).getRetainedSize();
        }
        else if (key.getClass().isArray()) {
            extraIdentity = getLength(key);
        }
        else if (key instanceof AbstractMapBlock.HashTables) {
            extraIdentity = (int) ((AbstractMapBlock.HashTables) key).getRetainedSizeInBytes();
        }
        else {
            throw new IllegalArgumentException(format(""Unsupported type for %s"", key));
        }
        return (((long) System.identityHashCode(key)) << Integer.SIZE) + extraIdentity;
    }"
"@Deprecated
	public static <T> T load(ReaderHandler<T> readerHandler, String path, String charset) throws IORuntimeException {
		return FileReader.create(file(path), CharsetUtil.charset(charset)).read(readerHandler);
	}"
"protected boolean registerAllRequestsProcessedListener(NotificationListener listener) throws IOException {
		checkNotNull(listener);

		synchronized (listenerLock) {
			if (allRequestsProcessedListener == null) {
				// There was a race with the processing of the last outstanding request
				if (requestsNotReturned.get() == 0) {
					return false;
				}

				allRequestsProcessedListener = listener;

				return true;
			}
		}

		throw new IllegalStateException(""Already subscribed."");
	}"
"@Override
    public int wordFrequency(@NonNull String word) {
        // TODO: proper wordFrequency impl should return long, instead of int
        T element = extendedVocabulary.get(word);
        if (element != null)
            return (int) element.getElementFrequency();
        return 0;
    }"
"public static SlotProfile priorAllocation(ResourceProfile resourceProfile, Collection<AllocationID> priorAllocations) {
		return new SlotProfile(resourceProfile, Collections.emptyList(), priorAllocations);
	}"
"public DocumentationContext configure(DocumentationContextBuilder builder) {
    return builder
        .apiInfo(apiInfo)
        .selector(apiSelector)
        .applyDefaultResponseMessages(applyDefaultResponseMessages)
        .additionalResponseMessages(responseMessages)
        .additionalOperationParameters(globalOperationParameters)
        .additionalIgnorableTypes(ignorableParameterTypes)
        .ruleBuilders(ruleBuilders)
        .groupName(groupName)
        .pathProvider(pathProvider)
        .securityContexts(securityContexts)
        .securitySchemes(securitySchemes)
        .apiListingReferenceOrdering(apiListingReferenceOrdering)
        .apiDescriptionOrdering(apiDescriptionOrdering)
        .operationOrdering(operationOrdering)
        .produces(produces)
        .consumes(consumes)
        .host(host)
        .protocols(protocols)
        .genericsNaming(genericsNamingStrategy)
        .pathMapping(pathMapping)
        .enableUrlTemplating(enableUrlTemplating)
        .additionalModels(additionalModels)
        .tags(tags)
        .vendorExtentions(vendorExtensions)
        .build();
  }"
"public static void injectResources(Props props) {
    // Add mapred, yarn and hdfs site configs (in addition to core-site, which
    // is automatically added) as default resources before we add the injected
    // configuration. This will cause the injected properties to override the
    // default site properties (instead of vice-versa). This is safe to do,
    // even when these site files don't exist for your Hadoop installation.
    if (props.getBoolean(""azkaban.inject.hadoop-site.configs"", true)) {
      Configuration.addDefaultResource(""mapred-default.xml"");
      Configuration.addDefaultResource(""mapred-site.xml"");
      Configuration.addDefaultResource(""yarn-default.xml"");
      Configuration.addDefaultResource(""yarn-site.xml"");
      Configuration.addDefaultResource(""hdfs-default.xml"");
      Configuration.addDefaultResource(""hdfs-site.xml"");
    }
    Configuration.addDefaultResource(INJECT_FILE);
  }"
"@Override
  public Call<Void> accept(List<Span> rawSpans) {
    V2SpanConverter converter = V2SpanConverter.create();
    V1ThriftSpanWriter encoder = new V1ThriftSpanWriter();

    Set<InsertTrace.Input> insertTraces = new LinkedHashSet<>();
    Set<String> insertServiceNames = new LinkedHashSet<>();
    Set<InsertRemoteServiceName.Input> insertRemoteServiceNames = new LinkedHashSet<>();
    Set<InsertSpanName.Input> insertSpanNames = new LinkedHashSet<>();
    Set<Map.Entry<String, String>> autocompleteTags = new LinkedHashSet<>();

    List<Call<Void>> calls = new ArrayList<>();
    for (Span v2 : rawSpans) {
      V1Span span = converter.convert(v2);
      // indexing occurs by timestamp, so derive one if not present.
      long ts_micro = v2.timestampAsLong();
      if (ts_micro == 0L) ts_micro = guessTimestamp(v2);

      insertTraces.add(insertTrace.newInput(span, encoder.write(v2), ts_micro));

      if (!searchEnabled) continue;

      if (insertAutocompleteValue != null) {
        for (Map.Entry<String, String> entry : v2.tags().entrySet()) {
          if (autocompleteKeys.contains(entry.getKey())) autocompleteTags.add(entry);
        }
      }

      // service span and remote service indexes is refreshed regardless of timestamp
      String serviceName = v2.localServiceName();
      if (serviceName != null) {
        insertServiceNames.add(serviceName);
        if (v2.name() != null) insertSpanNames.add(insertSpanName.newInput(serviceName, v2.name()));
        if (insertRemoteServiceName != null && v2.remoteServiceName() != null) {
          insertRemoteServiceNames.add(
            insertRemoteServiceName.newInput(serviceName, v2.remoteServiceName()));
        }
      }

      if (ts_micro == 0L) continue; // search is only valid with a timestamp, don't index w/o it!
      indexer.index(v2, calls);
    }

    for (InsertTrace.Input insert : insertTraces) {
      calls.add(insertTrace.create(insert));
    }
    for (String insert : insertServiceNames) {
      insertServiceName.maybeAdd(insert, calls);
    }
    for (InsertRemoteServiceName.Input insert : insertRemoteServiceNames) {
      insertRemoteServiceName.maybeAdd(insert, calls);
    }
    for (InsertSpanName.Input insert : insertSpanNames) {
      insertSpanName.maybeAdd(insert, calls);
    }
    for (Map.Entry<String, String> autocompleteTag : autocompleteTags) {
      insertAutocompleteValue.maybeAdd(autocompleteTag, calls);
    }
    return calls.isEmpty() ? Call.create(null) : AggregateCall.newVoidCall(calls);
  }"
"public <T> T execute(long wait, int maxAttempts, Callable<T> callback)
			throws Exception {
		getLog().debug(""Waiting for spring application to start..."");
		for (int i = 0; i < maxAttempts; i++) {
			T result = callback.call();
			if (result != null) {
				return result;
			}
			String message = ""Spring application is not ready yet, waiting "" + wait
					+ ""ms (attempt "" + (i + 1) + "")"";
			getLog().debug(message);
			synchronized (this.lock) {
				try {
					this.lock.wait(wait);
				}
				catch (InterruptedException ex) {
					Thread.currentThread().interrupt();
					throw new IllegalStateException(
							""Interrupted while waiting for Spring Boot app to start."");
				}
			}
		}
		throw new MojoExecutionException(
				""Spring application did not start before the configured "" + ""timeout (""
						+ (wait * maxAttempts) + ""ms"");
	}"
"public void showAlertAddDialog(HistoryReference ref) {
        if (dialogAlertAdd == null || !dialogAlertAdd.isVisible()) {
            dialogAlertAdd = new AlertAddDialog(getView().getMainFrame(), false);
            dialogAlertAdd.setVisible(true);
            dialogAlertAdd.setHistoryRef(ref);
        }
    }"
"private void updateCount() {
		if (scanStatus == null) {
			return;
		}

		long now = System.currentTimeMillis();
		if (now - this.lastUpdated > 200) {
			// Dont update too frequently, eg using the spider could hammer the UI unnecessarily
			this.lastUpdated = now;
			SwingUtilities.invokeLater(new Runnable(){
				@Override
				public void run() {
					scanStatus.setScanCount(nodeStack.size());
				}});
		}
	}"
"@Override public void init(boolean expensive) {
    super.init(expensive);
    for( double p : _parms._probs )
      if( p < 0.0 || p > 1.0 )
        error(""_probs"",""Probabilities must be between 0 and 1"");
    _ncols = train().numCols()-numSpecialCols(); //offset/weights/nfold - should only ever be weights
    if ( numSpecialCols() == 1 && _weights == null)
      throw new IllegalArgumentException(""The only special Vec that is supported for Quantiles is observation weights."");
    if ( numSpecialCols() >1 ) throw new IllegalArgumentException(""Cannot handle more than 1 special vec (weights)"");
  }"
"public static <T> ScopedBindingBuilder createChoice(
      Binder binder,
      String property,
      Key<T> interfaceKey,
      @Nullable Key<? extends T> defaultKey
  )
  {
    ConfiggedProvider<T> provider = new ConfiggedProvider<>(interfaceKey, property, defaultKey, null);
    return binder.bind(interfaceKey).toProvider(provider);
  }"
"public void registerRestApiExtensions() {
    if (restApiExtensionsRegistered) {
      throw H2O.fail(""APIs already registered"");
    }

    // Log core extension registrations here so the message is grouped in the right spot.
    for (AbstractH2OExtension e : getCoreExtensions()) {
      e.printInitialized();
    }
    Log.info(""Registered "" + coreExtensions.size() + "" core extensions in: "" + registerCoreExtensionsMillis + ""ms"");
    Log.info(""Registered H2O core extensions: "" + Arrays.toString(getCoreExtensionNames()));

    if(listenerExtensions.size() > 0) {
      Log.info(""Registered: "" + listenerExtensions.size() + "" listener extensions in: "" + registerListenerExtensionsMillis + ""ms"");
      Log.info(""Registered Listeners extensions: "" + Arrays.toString(getListenerExtensionNames()));
    }
    if(authExtensions.size() > 0) {
      Log.info(""Registered: "" + authExtensions.size() + "" auth extensions in: "" + registerAuthExtensionsMillis + ""ms"");
      Log.info(""Registered Auth extensions: "" + Arrays.toString(getAuthExtensionNames()));
    }
    long before = System.currentTimeMillis();
    RequestServer.DummyRestApiContext dummyRestApiContext = new RequestServer.DummyRestApiContext();
    ServiceLoader<RestApiExtension> restApiExtensionLoader = ServiceLoader.load(RestApiExtension.class);
    for (RestApiExtension r : restApiExtensionLoader) {
      try {
        if (isEnabled(r)) {
          r.registerEndPoints(dummyRestApiContext);
          r.registerSchemas(dummyRestApiContext);
          restApiExtensions.put(r.getName(), r);
        }
      } catch (Exception e) {
        Log.info(""Cannot register extension: "" + r + "". Skipping it..."");
      }
    }

    restApiExtensionsRegistered = true;

    long registerApisMillis = System.currentTimeMillis() - before;
    Log.info(""Registered: "" + RequestServer.numRoutes() + "" REST APIs in: "" + registerApisMillis + ""ms"");
    Log.info(""Registered REST API extensions: "" + Arrays.toString(getRestApiExtensionNames()));

    // Register all schemas
    SchemaServer.registerAllSchemasIfNecessary(dummyRestApiContext.getAllSchemas());
  }"
"private JSONArray readArray() throws JSONException {
		JSONArray result = new JSONArray();

		/* to cover input that ends with "",]"". */
		boolean hasTrailingSeparator = false;

		while (true) {
			switch (nextCleanInternal()) {
			case -1:
				throw syntaxError(""Unterminated array"");
			case ']':
				if (hasTrailingSeparator) {
					result.put(null);
				}
				return result;
			case ',':
			case ';':
				/* A separator without a value first means ""null"". */
				result.put(null);
				hasTrailingSeparator = true;
				continue;
			default:
				this.pos--;
			}

			result.put(nextValue());

			switch (nextCleanInternal()) {
			case ']':
				return result;
			case ',':
			case ';':
				hasTrailingSeparator = true;
				continue;
			default:
				throw syntaxError(""Unterminated array"");
			}
		}
	}"
"public static void tarGzExtractSingleFile(File tarGz, File destination, String pathInTarGz) throws IOException {
        try(TarArchiveInputStream tin = new TarArchiveInputStream(new GZIPInputStream(new BufferedInputStream(new FileInputStream(tarGz))))) {
            ArchiveEntry entry;
            List<String> out = new ArrayList<>();
            boolean extracted = false;
            while((entry = tin.getNextTarEntry()) != null){
                String name = entry.getName();
                if(pathInTarGz.equals(name)){
                    try(OutputStream os = new BufferedOutputStream(new FileOutputStream(destination))){
                        IOUtils.copy(tin, os);
                    }
                    extracted = true;
                }
            }
            Preconditions.checkState(extracted, ""No file was extracted. File not found? %s"", pathInTarGz);
        }
    }"
"public static Font createFont(InputStream fontStream) {
		try {
			return Font.createFont(Font.TRUETYPE_FONT, fontStream);
		} catch (FontFormatException e) {
			// True Type字体无效时使用Type1字体
			try {
				return Font.createFont(Font.TYPE1_FONT, fontStream);
			} catch (Exception e1) {
				throw new UtilException(e1);
			}
		} catch (IOException e) {
			throw new IORuntimeException(e);
		}
	}"
"public static <T0, T1> Tuple2<T0, T1> of(T0 value0, T1 value1) {
		return new Tuple2<>(value0,
			value1);
	}"
"public static InternalLogId allocate(String typeName, @Nullable String details) {
    return new InternalLogId(typeName, details, getNextId());
  }"
"public void pretrainLayer(String layerName, MultiDataSetIterator iter) {
        try{
            pretrainLayerHelper(layerName, iter, 1);
        } catch (OutOfMemoryError e){
            CrashReportingUtil.writeMemoryCrashDump(this, e);
            throw e;
        }
    }"
"public SDVariable permute(String name, SDVariable x, int... dimensions) {
        SDVariable result = f().permute(x, dimensions);
        return updateVariableNameAndReference(result, name);
    }"
"public static RelDataType createSqlType(final RelDataTypeFactory typeFactory, final SqlTypeName typeName)
  {
    return createSqlTypeWithNullability(typeFactory, typeName, false);
  }"
"private void internalRequestSlot(PendingSlotRequest pendingSlotRequest) throws ResourceManagerException {
		final ResourceProfile resourceProfile = pendingSlotRequest.getResourceProfile();
		TaskManagerSlot taskManagerSlot = findMatchingSlot(resourceProfile);

		if (taskManagerSlot != null) {
			allocateSlot(taskManagerSlot, pendingSlotRequest);
		} else {
			Optional<PendingTaskManagerSlot> pendingTaskManagerSlotOptional = findFreeMatchingPendingTaskManagerSlot(resourceProfile);

			if (!pendingTaskManagerSlotOptional.isPresent()) {
				pendingTaskManagerSlotOptional = allocateResource(resourceProfile);
			}

			pendingTaskManagerSlotOptional.ifPresent(pendingTaskManagerSlot -> assignPendingTaskManagerSlot(pendingSlotRequest, pendingTaskManagerSlot));
		}
	}"
"public HttpRequest form(String name, File... files) {
		if (1 == files.length) {
			final File file = files[0];
			return form(name, file, file.getName());
		}
		return form(name, new MultiFileResource(files));
	}"
"private static Charset getCharset(final int flags) throws AuthenticationException
    {
        if ((flags & FLAG_REQUEST_UNICODE_ENCODING) == 0) {
            return DEFAULT_CHARSET;
        } else {
            if (UNICODE_LITTLE_UNMARKED == null) {
                throw new AuthenticationException( ""Unicode not supported"" );
            }
            return UNICODE_LITTLE_UNMARKED;
        }
    }"
"public static LoadBalancer getLoadBalancer(ConsumerBootstrap consumerBootstrap) {
        try {
            String loadBalancer = consumerBootstrap.getConsumerConfig().getLoadBalancer();
            ExtensionClass<LoadBalancer> ext = ExtensionLoaderFactory
                .getExtensionLoader(LoadBalancer.class).getExtensionClass(loadBalancer);
            if (ext == null) {
                throw ExceptionUtils.buildRuntime(""consumer.loadBalancer"",
                    loadBalancer, ""Unsupported loadBalancer of client!"");
            }
            return ext.getExtInstance(new Class[] { ConsumerBootstrap.class }, new Object[] { consumerBootstrap });
        } catch (SofaRpcRuntimeException e) {
            throw e;
        } catch (Throwable e) {
            throw new SofaRpcRuntimeException(e.getMessage(), e);
        }
    }"
"void finish() {
		synchronized (this.monitor) {
			if (!isFinished()) {
				this.logger = DeferredLog.replay(this.logger,
						LogFactory.getLog(getClass()));
				this.finished = true;
			}
		}
	}"
"public synchronized Lease allocate(@Nonnull FilePath base, Object context) throws InterruptedException {
        for (int i=1; ; i++) {
            FilePath candidate = i==1 ? base : base.withSuffix(COMBINATOR+i);
            Entry e = inUse.get(candidate.getRemote());
            if(e!=null && !e.quick && e.context!=context)
                continue;
            return acquire(candidate,false,context);
        }
    }"
"public static ByteBuf copyMedium(int... values) {
        if (values == null || values.length == 0) {
            return EMPTY_BUFFER;
        }
        ByteBuf buffer = buffer(values.length * 3);
        for (int v: values) {
            buffer.writeMedium(v);
        }
        return buffer;
    }"
"protected int getAccessTokenValiditySeconds(OAuth2Request clientAuth) {
		if (clientDetailsService != null) {
			ClientDetails client = clientDetailsService.loadClientByClientId(clientAuth.getClientId());
			Integer validity = client.getAccessTokenValiditySeconds();
			if (validity != null) {
				return validity;
			}
		}
		return accessTokenValiditySeconds;
	}"
"@Override
	public void log(cn.hutool.log.level.Level level, String format, Object... arguments) {
		log(level, null, format, arguments);
	}"
"public static long nextPowOf2(long v) {
        v--;
        v |= v >> 1;
        v |= v >> 2;
        v |= v >> 4;
        v |= v >> 8;
        v |= v >> 16;
        v++;
        return v;

    }"
"static void checkState(boolean check, String msg, Object... args) {
    if (!check) {
      throw new IllegalStateException(String.format(msg, args));
    }
  }"
"public static ConnectionConfig newLdaptiveConnectionConfig(final AbstractLdapProperties l) {
        if (StringUtils.isBlank(l.getLdapUrl())) {
            throw new IllegalArgumentException(""LDAP url cannot be empty/blank"");
        }

        LOGGER.debug(""Creating LDAP connection configuration for [{}]"", l.getLdapUrl());
        val cc = new ConnectionConfig();

        val urls = l.getLdapUrl().contains("" "")
            ? l.getLdapUrl()
            : String.join("" "", l.getLdapUrl().split("",""));
        LOGGER.debug(""Transformed LDAP urls from [{}] to [{}]"", l.getLdapUrl(), urls);
        cc.setLdapUrl(urls);

        cc.setUseSSL(l.isUseSsl());
        cc.setUseStartTLS(l.isUseStartTls());
        cc.setConnectTimeout(Beans.newDuration(l.getConnectTimeout()));
        cc.setResponseTimeout(Beans.newDuration(l.getResponseTimeout()));

        if (StringUtils.isNotBlank(l.getConnectionStrategy())) {
            val strategy = AbstractLdapProperties.LdapConnectionStrategy.valueOf(l.getConnectionStrategy());
            switch (strategy) {
                case RANDOM:
                    cc.setConnectionStrategy(new RandomConnectionStrategy());
                    break;
                case DNS_SRV:
                    cc.setConnectionStrategy(new DnsSrvConnectionStrategy());
                    break;
                case ACTIVE_PASSIVE:
                    cc.setConnectionStrategy(new ActivePassiveConnectionStrategy());
                    break;
                case ROUND_ROBIN:
                    cc.setConnectionStrategy(new RoundRobinConnectionStrategy());
                    break;
                case DEFAULT:
                default:
                    cc.setConnectionStrategy(new DefaultConnectionStrategy());
                    break;
            }
        }

        if (l.getTrustCertificates() != null) {
            LOGGER.debug(""Creating LDAP SSL configuration via trust certificates [{}]"", l.getTrustCertificates());
            val cfg = new X509CredentialConfig();
            cfg.setTrustCertificates(l.getTrustCertificates());
            cc.setSslConfig(new SslConfig(cfg));
        } else if (l.getTrustStore() != null || l.getKeystore() != null) {
            val cfg = new KeyStoreCredentialConfig();
            if (l.getTrustStore() != null) {
                LOGGER.trace(""Creating LDAP SSL configuration with truststore [{}]"", l.getTrustStore());
                cfg.setTrustStore(l.getTrustStore());
                cfg.setTrustStoreType(l.getTrustStoreType());
                cfg.setTrustStorePassword(l.getTrustStorePassword());
            }
            if (l.getKeystore() != null) {
                LOGGER.trace(""Creating LDAP SSL configuration via keystore [{}]"", l.getKeystore());
                cfg.setKeyStore(l.getKeystore());
                cfg.setKeyStorePassword(l.getKeystorePassword());
                cfg.setKeyStoreType(l.getKeystoreType());
            }
            cc.setSslConfig(new SslConfig(cfg));
        } else {
            LOGGER.debug(""Creating LDAP SSL configuration via the native JVM truststore"");
            cc.setSslConfig(new SslConfig());
        }

        val sslConfig = cc.getSslConfig();
        if (sslConfig != null) {
            switch (l.getHostnameVerifier()) {
                case ANY:
                    sslConfig.setHostnameVerifier(new AllowAnyHostnameVerifier());
                    break;
                case DEFAULT:
                default:
                    sslConfig.setHostnameVerifier(new DefaultHostnameVerifier());
                    break;
            }
        }

        if (StringUtils.isNotBlank(l.getSaslMechanism())) {
            LOGGER.debug(""Creating LDAP SASL mechanism via [{}]"", l.getSaslMechanism());

            val bc = new BindConnectionInitializer();
            val sc = getSaslConfigFrom(l);

            if (StringUtils.isNotBlank(l.getSaslAuthorizationId())) {
                sc.setAuthorizationId(l.getSaslAuthorizationId());
            }
            sc.setMutualAuthentication(l.getSaslMutualAuth());
            if (StringUtils.isNotBlank(l.getSaslQualityOfProtection())) {
                sc.setQualityOfProtection(QualityOfProtection.valueOf(l.getSaslQualityOfProtection()));
            }
            if (StringUtils.isNotBlank(l.getSaslSecurityStrength())) {
                sc.setSecurityStrength(SecurityStrength.valueOf(l.getSaslSecurityStrength()));
            }
            bc.setBindSaslConfig(sc);
            cc.setConnectionInitializer(bc);
        } else if (StringUtils.equals(l.getBindCredential(), ""*"") && StringUtils.equals(l.getBindDn(), ""*"")) {
            LOGGER.debug(""Creating LDAP fast-bind connection initializer"");
            cc.setConnectionInitializer(new FastBindOperation.FastBindConnectionInitializer());
        } else if (StringUtils.isNotBlank(l.getBindDn()) && StringUtils.isNotBlank(l.getBindCredential())) {
            LOGGER.debug(""Creating LDAP bind connection initializer via [{}]"", l.getBindDn());
            cc.setConnectionInitializer(new BindConnectionInitializer(l.getBindDn(), new Credential(l.getBindCredential())));
        }
        return cc;
    }"
"public static INDArray concat(INDArray[] history) {
        INDArray arr = Nd4j.concat(0, history);
        return arr;
    }"
"private void advanceBufferIfNecessary() {
    ReadableBuffer buffer = buffers.peek();
    if (buffer.readableBytes() == 0) {
      buffers.remove().close();
    }
  }"
"protected String format(ChannelHandlerContext ctx, String eventName, Object arg) {
        if (arg instanceof ByteBuf) {
            return formatByteBuf(ctx, eventName, (ByteBuf) arg);
        } else if (arg instanceof ByteBufHolder) {
            return formatByteBufHolder(ctx, eventName, (ByteBufHolder) arg);
        } else {
            return formatSimple(ctx, eventName, arg);
        }
    }"
"void removeLocality(final Locality locality) {
    ClientLoadCounter counter = localityLoadCounters.get(locality);
    checkState(counter != null && counter.isActive(),
        ""No active ClientLoadCounter for locality %s exists"", locality);
    counter.setActive(false);
  }"
"public static String getUniqueNameProtocol(ProviderConfig providerConfig, String protocol) {
        if (StringUtils.isNotEmpty(protocol)) {
            return getUniqueName(providerConfig) + ""@"" + protocol;
        } else {
            return getUniqueName(providerConfig);
        }
    }"
"void addInProgressCheckpoint(PendingCheckpointStats pending) {
		if (readOnly) {
			throw new UnsupportedOperationException(""Can't create a snapshot of a read-only history."");
		}

		if (maxSize == 0) {
			return;
		}

		checkNotNull(pending, ""Pending checkpoint"");

		// Grow the array if required. This happens only for the first entries
		// and makes the iterator logic easier, because we don't have any
		// null elements with the growing array.
		if (checkpointsArray.length < maxSize) {
			checkpointsArray = Arrays.copyOf(checkpointsArray, checkpointsArray.length + 1);
		}

		// Wrap around if we are at the end. The next pos is the least recently
		// added checkpoint.
		if (nextPos == checkpointsArray.length) {
			nextPos = 0;
		}

		checkpointsArray[nextPos++] = pending;
	}"
"static void fireChannelRead(ChannelHandlerContext ctx, List<Object> msgs, int numElements) {
        if (msgs instanceof CodecOutputList) {
            fireChannelRead(ctx, (CodecOutputList) msgs, numElements);
        } else {
            for (int i = 0; i < numElements; i++) {
                ctx.fireChannelRead(msgs.get(i));
            }
        }
    }"
"public static void closeSilently(Closeable...closeable) {
    for(Closeable c : closeable)
      try { if( c != null ) c.close(); } catch( IOException xe ) { }
  }"
"@Nullable
    public ExecutableElement concreteConstructorFor(TypeElement classElement, AnnotationUtils annotationUtils) {
        List<ExecutableElement> constructors = findNonPrivateConstructors(classElement);
        if (constructors.isEmpty()) {
            return null;
        }
        if (constructors.size() == 1) {
            return constructors.get(0);
        }

        Optional<ExecutableElement> element = constructors.stream().filter(ctor -> {
                    final AnnotationMetadata annotationMetadata = annotationUtils.getAnnotationMetadata(ctor);
                    return annotationMetadata.hasStereotype(Inject.class) || annotationMetadata.hasStereotype(Creator.class);
                }
        ).findFirst();
        if (!element.isPresent()) {
            element = constructors.stream().filter(ctor ->
                ctor.getModifiers().contains(PUBLIC)
            ).findFirst();
        }
        return element.orElse(null);
    }"
"protected void pauseScan(Context context) {
		log.debug(""Access Control pause on Context: "" + context);
		threadManager.getScannerThread(context.getIndex()).pauseScan();
	}"
"@Override
	public void monitorTarget(ResourceID resourceID, HeartbeatTarget<O> heartbeatTarget) {
		if (!stopped) {
			if (heartbeatTargets.containsKey(resourceID)) {
				log.debug(""The target with resource ID {} is already been monitored."", resourceID);
			} else {
				HeartbeatManagerImpl.HeartbeatMonitor<O> heartbeatMonitor = new HeartbeatManagerImpl.HeartbeatMonitor<>(
					resourceID,
					heartbeatTarget,
					scheduledExecutor,
					heartbeatListener,
					heartbeatTimeoutIntervalMs);

				heartbeatTargets.put(
					resourceID,
					heartbeatMonitor);

				// check if we have stopped in the meantime (concurrent stop operation)
				if (stopped) {
					heartbeatMonitor.cancel();

					heartbeatTargets.remove(resourceID);
				}
			}
		}
	}"
"public SimpleSlot getSlotForTask(CoLocationConstraint constraint, Iterable<TaskManagerLocation> locationPreferences) {
		synchronized (lock) {
			if (constraint.isAssignedAndAlive()) {
				// the shared slot of the co-location group is initialized and set we allocate a sub-slot
				final SharedSlot shared = constraint.getSharedSlot();
				SimpleSlot subslot = shared.allocateSubSlot(null);
				subslot.setLocality(Locality.LOCAL);
				return subslot;
			}
			else if (constraint.isAssigned()) {
				// we had an assignment before.
				
				SharedSlot previous = constraint.getSharedSlot();
				if (previous == null) {
					throw new IllegalStateException(""Bug: Found assigned co-location constraint without a slot."");
				}

				TaskManagerLocation location = previous.getTaskManagerLocation();
				Tuple2<SharedSlot, Locality> p = getSharedSlotForTask(
						constraint.getGroupId(), Collections.singleton(location), true);

				if (p == null) {
					return null;
				}
				else {
					SharedSlot newSharedSlot = p.f0;

					// allocate the co-location group slot inside the shared slot
					SharedSlot constraintGroupSlot = newSharedSlot.allocateSharedSlot(constraint.getGroupId());
					if (constraintGroupSlot != null) {
						constraint.setSharedSlot(constraintGroupSlot);

						// the sub slots in the co location constraint slot have no group that they belong to
						// (other than the co-location-constraint slot)
						SimpleSlot subSlot = constraintGroupSlot.allocateSubSlot(null);
						subSlot.setLocality(Locality.LOCAL);
						return subSlot;
					}
					else {
						// could not allocate the co-location-constraint shared slot
						return null;
					}
				}
			}
			else {
				// the location constraint has not been associated with a shared slot, yet.
				// grab a new slot and initialize the constraint with that one.
				// preferred locations are defined by the vertex
				Tuple2<SharedSlot, Locality> p =
						getSharedSlotForTask(constraint.getGroupId(), locationPreferences, false);
				if (p == null) {
					// could not get a shared slot for this co-location-group
					return null;
				}
				else {
					final SharedSlot availableShared = p.f0;
					final Locality l = p.f1;

					// allocate the co-location group slot inside the shared slot
					SharedSlot constraintGroupSlot = availableShared.allocateSharedSlot(constraint.getGroupId());
					
					// IMPORTANT: We do not lock the location, yet, since we cannot be sure that the
					//            caller really sticks with the slot we picked!
					constraint.setSharedSlot(constraintGroupSlot);
					
					// the sub slots in the co location constraint slot have no group that they belong to
					// (other than the co-location-constraint slot)
					SimpleSlot sub = constraintGroupSlot.allocateSubSlot(null);
					sub.setLocality(l);
					return sub;
				}
			}
		}
	}"
"@RequirePOST
    public void doUpdateNow( StaplerRequest req, StaplerResponse rsp ) throws IOException, ServletException {
        Jenkins.getInstance().checkPermission(Jenkins.ADMINISTER);
        
        for (NodeMonitor nodeMonitor : NodeMonitor.getAll()) {
            Thread t = nodeMonitor.triggerUpdate();
            String columnCaption = nodeMonitor.getColumnCaption();
            if (columnCaption != null) {
                t.setName(columnCaption);
            }
        }
        rsp.forwardToPreviousPage(req);
    }"
"private static void encodeHeader(DnsQuery query, ByteBuf buf) {
        buf.writeShort(query.id());
        int flags = 0;
        flags |= (query.opCode().byteValue() & 0xFF) << 14;
        if (query.isRecursionDesired()) {
            flags |= 1 << 8;
        }
        buf.writeShort(flags);
        buf.writeShort(query.count(DnsSection.QUESTION));
        buf.writeShort(0); // answerCount
        buf.writeShort(0); // authorityResourceCount
        buf.writeShort(query.count(DnsSection.ADDITIONAL));
    }"
"final void signalWork() {
        long c; int u;
        while ((u = (int)((c = ctl) >>> 32)) < 0) {     // too few active
            WorkQueue[] ws = workQueues; int e, i; WorkQueue w; Thread p;
            if ((e = (int)c) > 0) {                     // at least one waiting
                if (ws != null && (i = e & SMASK) < ws.length &&
                    (w = ws[i]) != null && w.eventCount == (e | INT_SIGN)) {
                    long nc = (((long)(w.nextWait & E_MASK)) |
                               ((long)(u + UAC_UNIT) << 32));
                    if (U.compareAndSwapLong(this, CTL, c, nc)) {
                        w.eventCount = (e + E_SEQ) & E_MASK;
                        if ((p = w.parker) != null)
                            U.unpark(p);                // activate and release
                        break;
                    }
                }
                else
                    break;
            }
            else if (e == 0 && (u & SHORT_SIGN) != 0) { // too few total
                long nc = (long)(((u + UTC_UNIT) & UTC_MASK) |
                                 ((u + UAC_UNIT) & UAC_MASK)) << 32;
                if (U.compareAndSwapLong(this, CTL, c, nc)) {
                    addWorker();
                    break;
                }
            }
            else
                break;
        }
    }"
"public static double similarity(String s1, String s2) {
    if (s1.equals(s2))
      return 1.0;

    // ensure that s1 is shorter than or same length as s2
    if (s1.length() > s2.length()) {
      String tmp = s2;
      s2 = s1;
      s1 = tmp;
    }
    /*
     * this list of Boolean values is used for avoiding duplicated count of
     * common characters in S2
     */
    List<Boolean> isCommonCharInS2 = new ArrayList<Boolean>();
    for (int i=0; i<s2.length(); i++) {
      isCommonCharInS2.add(false);
    }

    // (1) find the number of characters the two strings have in common.
    // note that matching characters can only be half the length of the
    // longer string apart.
    int maxdist = (int) Math.floor(s2.length() / 2) ;
    int c = 0; // count of common characters
    int t = 0; // count of transpositions
    int prevpos = -1;
    for (int ix = 0; ix < s1.length(); ix++) {
      char ch = s1.charAt(ix);

      // now try to find it in s2
      for (int ix2 = Math.max(0, ix - maxdist);
           ix2 < Math.min(s2.length(), ix + maxdist);
           ix2++) {
        if (ch == s2.charAt(ix2) && !isCommonCharInS2.get(ix2)) {
          c++; // we found a common character
          isCommonCharInS2.set(ix2, true);
          if (prevpos != -1 && ix2 < prevpos)
            t++; // moved back before earlier
          prevpos = ix2;
          break;
        }
      }
    }

    // we don't divide t by 2 because as far as we can tell, the above
    // code counts transpositions directly.

    // System.out.println(""c: "" + c);
    // System.out.println(""t: "" + t);
    // System.out.println(""c/m: "" + (c / (double) s1.length()));
    // System.out.println(""c/n: "" + (c / (double) s2.length()));
    // System.out.println(""(c-t)/c: "" + ((c - t) / (double) c));

    // we might have to give up right here
    if (c == 0)
      return 0.0;

    // first compute the score
    double score = ((c / (double) s1.length()) +
            (c / (double) s2.length()) +
            ((c - t) / (double) c)) / 3.0;

    // (2) common prefix modification
    int p = 0; // length of prefix
    int last = Math.min(4, s1.length());
    for (; p < last && s1.charAt(p) == s2.charAt(p); p++)
      ;

    score = score + ((p * (1 - score)) / 10);

    // (3) longer string adjustment
    // I'm confused about this part. Winkler's original source code includes
    // it, and Yancey's 2005 paper describes it. However, Winkler's list of
    // test cases in his 2006 paper does not include this modification. So
    // is this part of Jaro-Winkler, or is it not? Hard to say.
    //
    //   if (s1.length() >= 5 && // both strings at least 5 characters long
    //       c - p >= 2 && // at least two common characters besides prefix
    //       c - p >= ((s1.length() - p) / 2)) // fairly rich in common chars
    //     {
    //     System.out.println(""ADJUSTED!"");
    //     score = score + ((1 - score) * ((c - (p + 1)) /
    //                                     ((double) ((s1.length() + s2.length())
    //                                                - (2 * (p - 1))))));
    // }

    // (4) similar characters adjustment
    // the same holds for this as for (3) above.

    return score;
  }"
"public static SearchExecutor newLdaptiveSearchExecutor(final String baseDn, final String filterQuery,
                                                           final List<String> params,
                                                           final String[] returnAttributes) {
        val executor = new SearchExecutor();
        executor.setBaseDn(baseDn);
        executor.setSearchFilter(newLdaptiveSearchFilter(filterQuery, params));
        executor.setReturnAttributes(returnAttributes);
        executor.setSearchScope(SearchScope.SUBTREE);
        return executor;
    }"
"public VariableResolver<String> createVariableResolver(AbstractBuild<?,?> build) {
        VariableResolver[] resolvers = new VariableResolver[getParameters().size()+1];
        int i=0;
        for (ParameterValue p : getParameters()) {
            if (p == null) continue;
            resolvers[i++] = p.createVariableResolver(build);
        }
            
        resolvers[i] = build.getBuildVariableResolver();

        return new VariableResolver.Union<String>(resolvers);
    }"
"protected Identifier getIdentifier(String name, boolean quoted,
			JdbcEnvironment jdbcEnvironment) {
		if (isCaseInsensitive(jdbcEnvironment)) {
			name = name.toLowerCase(Locale.ROOT);
		}
		return new Identifier(name, quoted);
	}"
"public void putBuildRow(BinaryRow row) throws IOException {
		long key = getBuildLongKey(row);
		final int hashCode = hashLong(key, 0);
		insertIntoTable(key, hashCode, row);
	}"
"@SuppressWarnings(""unchecked"")
    public static Map<String, int[][]> getPersonFreqMap() {
        Map<String, int[][]> map = new HashMap<>(0);
        try (InputStream inputStream = DicReader.getInputStream(""person/asian_name_freq.data"")) {
            ObjectInputStream objectInputStream = new ObjectInputStream(inputStream);
            map = (Map<String, int[][]>) objectInputStream.readObject();
        } catch (IOException e) {
            LOG.warn(""IO异常"", e);
        } catch (ClassNotFoundException e) {
            LOG.warn(""找不到类"", e);
        }
        return map;
    }"
"public float progress() { update_from_remote();
    float regularProgress = _work==0 ? 0f : Math.min(1,(float)_worked/_work);
    if (_max_runtime_msecs>0) return Math.min(1,Math.max(regularProgress, (float)msec()/_max_runtime_msecs));
    return regularProgress;
  }"
"@SuppressWarnings({""unchecked"", ""rawtypes""})
    public static <T extends Describable<T>,D extends Descriptor<T>>
    DescriptorExtensionList<T,D> createDescriptorList(Jenkins jenkins, Class<T> describableType) {
        if (describableType == (Class) Publisher.class) {
            return (DescriptorExtensionList) new Publisher.DescriptorExtensionListImpl(jenkins);
        }
        return new DescriptorExtensionList<>(jenkins, describableType);
    }"
"public SDVariable gatherNd(String name, SDVariable df, SDVariable indices) {
        SDVariable ret = f().gatherNd(df, indices);
        return updateVariableNameAndReference(ret, name);
    }"
"public static int partValue(int total, int partCount, boolean isPlusOneWhenHasRem) {
		int partValue = 0;
		if (total % partCount == 0) {
			partValue = total / partCount;
		} else {
			partValue = (int) Math.floor(total / partCount);
			if (isPlusOneWhenHasRem) {
				partValue += 1;
			}
		}
		return partValue;
	}"
"public static <T extends CharSequence> T validateChinese(T value, String errorMsg) throws ValidateException {
		if (false == isChinese(value)) {
			throw new ValidateException(errorMsg);
		}
		return value;
	}"
"public static <IN> StreamingFileSink.RowFormatBuilder<IN, String> forRowFormat(
			final Path basePath, final Encoder<IN> encoder) {
		return new StreamingFileSink.RowFormatBuilder<>(basePath, encoder, new DateTimeBucketAssigner<>());
	}"
"private synchronized ListenableFuture<?> updateUserMemory(String allocationTag, long delta)
    {
        if (delta >= 0) {
            enforceUserMemoryLimit(queryMemoryContext.getUserMemory(), delta, maxUserMemory);
            return memoryPool.reserve(queryId, allocationTag, delta);
        }
        memoryPool.free(queryId, allocationTag, -delta);
        return NOT_BLOCKED;
    }"
"public void setChannel(@Nonnull InputStream in, @Nonnull OutputStream out,
                           @CheckForNull OutputStream launchLog,
                           @CheckForNull Channel.Listener listener) throws IOException, InterruptedException {
        ChannelBuilder cb = new ChannelBuilder(nodeName,threadPoolForRemoting)
            .withMode(Channel.Mode.NEGOTIATE)
            .withHeaderStream(launchLog);

        for (ChannelConfigurator cc : ChannelConfigurator.all()) {
            cc.onChannelBuilding(cb,this);
        }

        Channel channel = cb.build(in,out);
        setChannel(channel,launchLog,listener);
    }"
"private static String format(String x) {
		int z = x.indexOf("".""); // 取小数点位置
		String lstr = """", rstr = """";
		if (z > -1) { // 看是否有小数，如果有，则分别取左边和右边
			lstr = x.substring(0, z);
			rstr = x.substring(z + 1);
		} else {
			// 否则就是全部
			lstr = x;
		}

		String lstrrev = StrUtil.reverse(lstr); // 对左边的字串取反
		String[] a = new String[5]; // 定义5个字串变量来存放解析出来的叁位一组的字串

		switch (lstrrev.length() % 3) {
		case 1:
			lstrrev += ""00"";
			break;
		case 2:
			lstrrev += ""0"";
			break;
		}
		String lm = """"; // 用来存放转换後的整数部分
		for (int i = 0; i < lstrrev.length() / 3; i++) {
			a[i] = StrUtil.reverse(lstrrev.substring(3 * i, 3 * i + 3)); // 截取第一个叁位
			if (!a[i].equals(""000"")) { // 用来避免这种情况：1000000 = one million
										// thousand only
				if (i != 0) {
					lm = transThree(a[i]) + "" "" + parseMore(String.valueOf(i)) + "" "" + lm; // 加:
																							// thousand、million、billion
				} else {
					lm = transThree(a[i]); // 防止i=0时， 在多加两个空格.
				}
			} else {
				lm += transThree(a[i]);
			}
		}

		String xs = """"; // 用来存放转换後小数部分
		if (z > -1) {
			xs = ""AND CENTS "" + transTwo(rstr) + "" ""; // 小数部分存在时转换小数
		}

		return lm.trim() + "" "" + xs + ""ONLY"";
	}"
"private DataSet<Edge<K, EV>> getPairwiseEdgeIntersection(DataSet<Edge<K, EV>> edges) {
		return this.getEdges()
				.coGroup(edges)
				.where(0, 1, 2)
				.equalTo(0, 1, 2)
				.with(new MatchingEdgeReducer<>())
					.name(""Intersect edges"");
	}"
"public static void main(String[] args) throws AnalysisException {
    // $example on:init_session$
    SparkSession spark = SparkSession
      .builder()
      .appName(""Java Spark SQL basic example"")
      .config(""spark.some.config.option"", ""some-value"")
      .getOrCreate();
    // $example off:init_session$

    runBasicDataFrameExample(spark);
    runDatasetCreationExample(spark);
    runInferSchemaExample(spark);
    runProgrammaticSchemaExample(spark);

    spark.stop();
  }"
"protected Label readLabel(int offset, Label[] labels) {
        // SPRING PATCH: leniently handle offset mismatch
        if (offset >= labels.length) {
            return new Label();
        }
        // END OF PATCH
        if (labels[offset] == null) {
            labels[offset] = new Label();
        }
        return labels[offset];
    }"
"private Map<Path, FileStatus> listEligibleFiles(FileSystem fileSystem, Path path) throws IOException {

		final FileStatus[] statuses;
		try {
			statuses = fileSystem.listStatus(path);
		} catch (IOException e) {
			// we may run into an IOException if files are moved while listing their status
			// delay the check for eligible files in this case
			return Collections.emptyMap();
		}

		if (statuses == null) {
			LOG.warn(""Path does not exist: {}"", path);
			return Collections.emptyMap();
		} else {
			Map<Path, FileStatus> files = new HashMap<>();
			// handle the new files
			for (FileStatus status : statuses) {
				if (!status.isDir()) {
					Path filePath = status.getPath();
					long modificationTime = status.getModificationTime();
					if (!shouldIgnore(filePath, modificationTime)) {
						files.put(filePath, status);
					}
				} else if (format.getNestedFileEnumeration() && format.acceptFile(status)){
					files.putAll(listEligibleFiles(fileSystem, status.getPath()));
				}
			}
			return files;
		}
	}"
"private void setIndicesAndTypes() {

        DeleteByQueryRequest innerRequest = request.request();
        innerRequest.indices(query.getIndexArr());
        String[] typeArr = query.getTypeArr();
        if (typeArr!=null){
            innerRequest.getSearchRequest().types(typeArr);
        }
//		String[] typeArr = query.getTypeArr();
//		if (typeArr != null) {
//            request.set(typeArr);
//		}
	}"
"public boolean filter(Term term) {

        if (!stop.isEmpty() && (stop.contains(term.getName()))) {
            return true;
        }

        if (!natureStop.isEmpty() && (natureStop.contains(term.natrue().natureStr))) {
            return true;
        }

        if (!regexList.isEmpty()) {
            for (Pattern stopwordPattern : regexList) {
                if (stopwordPattern.matcher(term.getName()).matches()) {
                    return true;
                }
            }
        }

        return false;
    }"
"public void setMaxFrame(final int maxFrame) {
    if (composition == null) {
      lazyCompositionTasks.add(new LazyCompositionTask() {
        @Override
        public void run(LottieComposition composition) {
          setMaxFrame(maxFrame);
        }
      });
      return;
    }
    animator.setMaxFrame(maxFrame + 0.99f);
  }"
"protected void stop() throws Exception {
		this.logger.debug(""Stopping application"");
		this.stopLock.lock();
		try {
			for (ConfigurableApplicationContext context : this.rootContexts) {
				context.close();
				this.rootContexts.remove(context);
			}
			cleanupCaches();
			if (this.forceReferenceCleanup) {
				forceReferenceCleanup();
			}
		}
		finally {
			this.stopLock.unlock();
		}
		System.gc();
		System.runFinalization();
	}"
"public static String toGetterName(JavacNode field) {
		return HandlerUtil.toGetterName(field.getAst(), getAccessorsForField(field), field.getName(), isBoolean(field));
	}"
"@Override
    public void setupSearchState(Pair<Gradient, Double> pair) {
        INDArray gradient = pair.getFirst().gradient(conf.variables());
        INDArray params = model.params().dup(); //Need dup here: params returns an array that isn't a copy (hence changes to this are problematic for line search methods)
        searchState.put(GRADIENT_KEY, gradient);
        searchState.put(SCORE_KEY, pair.getSecond());
        searchState.put(PARAMS_KEY, params);
    }"
"public Map<String, Collection<String>> headers() {
    Map<String, Collection<String>> headerMap = new TreeMap<>(String.CASE_INSENSITIVE_ORDER);
    this.headers.forEach((key, headerTemplate) -> {
      List<String> values = new ArrayList<>(headerTemplate.getValues());

      /* add the expanded collection, but only if it has values */
      if (!values.isEmpty()) {
        headerMap.put(key, Collections.unmodifiableList(values));
      }
    });
    return Collections.unmodifiableMap(headerMap);
  }"
"@PublicEvolving
	public <R> SingleOutputStreamOperator<R> process(ProcessFunction<T, R> processFunction) {

		TypeInformation<R> outType = TypeExtractor.getUnaryOperatorReturnType(
			processFunction,
			ProcessFunction.class,
			0,
			1,
			TypeExtractor.NO_INDEX,
			getType(),
			Utils.getCallLocationName(),
			true);

		return process(processFunction, outType);
	}"
"public AnnotationValueBuilder<T> values(@Nullable AnnotationValue<?>... annotations) {
        return member(AnnotationMetadata.VALUE_MEMBER, annotations);
    }"
"public TreeString intern(final String s) {
        if (s==null)    return null;
        return root.intern(s).node;
    }"
"public SDVariable eye(String name, SDVariable rows, SDVariable cols, SDVariable batchDimension) {
        SDVariable eye = new Eye(sd, rows, cols, batchDimension).outputVariable();
        return updateVariableNameAndReference(eye, name);
    }"
"public synchronized @CheckForNull HashedToken revokeToken(@Nonnull String tokenUuid) {
        for (Iterator<HashedToken> iterator = tokenList.iterator(); iterator.hasNext(); ) {
            HashedToken token = iterator.next();
            if (token.uuid.equals(tokenUuid)) {
                iterator.remove();
                
                return token;
            }
        }
        
        return null;
    }"
"@Override
    public int[] findJoinPositions(int probePosition, Page probe, int probeGeometryChannel, Optional<Integer> probePartitionChannel)
    {
        Block probeGeometryBlock = probe.getBlock(probeGeometryChannel);
        if (probeGeometryBlock.isNull(probePosition)) {
            return EMPTY_ADDRESSES;
        }

        int probePartition = probePartitionChannel.map(channel -> toIntExact(INTEGER.getLong(probe.getBlock(channel), probePosition))).orElse(-1);

        Slice slice = probeGeometryBlock.getSlice(probePosition, 0, probeGeometryBlock.getSliceLength(probePosition));
        OGCGeometry probeGeometry = deserialize(slice);
        verify(probeGeometry != null);
        if (probeGeometry.isEmpty()) {
            return EMPTY_ADDRESSES;
        }

        boolean probeIsPoint = probeGeometry instanceof OGCPoint;

        IntArrayList matchingPositions = new IntArrayList();

        Envelope envelope = getEnvelope(probeGeometry);
        rtree.query(envelope, item -> {
            GeometryWithPosition geometryWithPosition = (GeometryWithPosition) item;
            OGCGeometry buildGeometry = geometryWithPosition.getGeometry();
            if (partitions.isEmpty() || (probePartition == geometryWithPosition.getPartition() && (probeIsPoint || (buildGeometry instanceof OGCPoint) || testReferencePoint(envelope, buildGeometry, probePartition)))) {
                if (radiusChannel == -1) {
                    if (spatialRelationshipTest.apply(buildGeometry, probeGeometry, OptionalDouble.empty())) {
                        matchingPositions.add(geometryWithPosition.getPosition());
                    }
                }
                else {
                    if (spatialRelationshipTest.apply(geometryWithPosition.getGeometry(), probeGeometry, OptionalDouble.of(getRadius(geometryWithPosition.getPosition())))) {
                        matchingPositions.add(geometryWithPosition.getPosition());
                    }
                }
            }
        });

        return matchingPositions.toIntArray(null);
    }"
"protected final MethodSpec newSetter(TypeName varType, String varName, Visibility visibility) {
    String methodName = ""set"" + Character.toUpperCase(varName.charAt(0)) + varName.substring(1);
    String type;
    if (varType.isPrimitive()) {
      type = varType.equals(TypeName.INT) ? ""Int"" : ""Long"";
    } else {
      type = ""Object"";
    }
    MethodSpec.Builder setter = MethodSpec.methodBuilder(methodName)
        .addModifiers(context.publicFinalModifiers())
        .addParameter(varType, varName);
    if (visibility.isRelaxed) {
      setter.addStatement(""$T.UNSAFE.put$L(this, $N, $N)"",
          UNSAFE_ACCESS, type, offsetName(varName), varName);
    } else {
      setter.addStatement(""this.$N = $N"", varName, varName);
    }

    return setter.build();
  }"
"private static String transTwo(String s) {
		String value = """";
		// 判断位数
		if (s.length() > 2) {
			s = s.substring(0, 2);
		} else if (s.length() < 2) {
			s = ""0"" + s;
		}

		if (s.startsWith(""0"")) {// 07 - seven 是否小於10
			value = parseFirst(s);
		} else if (s.startsWith(""1"")) {// 17 seventeen 是否在10和20之间
			value = parseTeen(s);
		} else if (s.endsWith(""0"")) {// 是否在10与100之间的能被10整除的数
			value = parseTen(s);
		} else {
			value = parseTen(s) + "" "" + parseFirst(s);
		}
		return value;
	}"
"private void removeFromTable(Node node) {
    int last = data.size() - 1;
    table[node.index] = table[last];
    table[node.index].index = node.index;
    table[last] = null;
  }"
"private boolean isBareS3NBucketWithoutTrailingSlash(String s) {
    String s2 = s.toLowerCase();
    Matcher m = Pattern.compile(""s3n://[^/]*"").matcher(s2);
    return m.matches();
  }"
"public static <T> T get(Collection<T> collection, int index) {
		if (null == collection) {
			return null;
		}

		final int size = collection.size();
		if (index < 0) {
			index += size;
		}

		// 检查越界
		if (index >= size) {
			return null;
		}

		if (collection instanceof List) {
			final List<T> list = ((List<T>) collection);
			return list.get(index);
		} else {
			int i = 0;
			for (T t : collection) {
				if (i > index) {
					break;
				} else if (i == index) {
					return t;
				}
				i++;
			}
		}
		return null;
	}"
"public Pattern<T, F> until(IterativeCondition<F> untilCondition) {
		Preconditions.checkNotNull(untilCondition, ""The condition cannot be null"");

		if (this.untilCondition != null) {
			throw new MalformedPatternException(""Only one until condition can be applied."");
		}

		if (!quantifier.hasProperty(Quantifier.QuantifierProperty.LOOPING)) {
			throw new MalformedPatternException(""The until condition is only applicable to looping states."");
		}

		ClosureCleaner.clean(untilCondition, true);
		this.untilCondition = untilCondition;

		return this;
	}"
"@Override
    public Collection<Logo> getLogoUrls() {
        val list = new ArrayList<Logo>();
        if (this.uiInfo != null) {
            list.addAll(this.uiInfo.getLogos().stream().map(l -> new Logo(l.getURL(), l.getHeight(), l.getWidth())).collect(Collectors.toList()));
        }
        return list;
    }"
"public CouchDbMultifactorAuthenticationTrustRecord merge(final MultifactorAuthenticationTrustRecord other) {
        setId(other.getId());
        setPrincipal(other.getPrincipal());
        setDeviceFingerprint(other.getDeviceFingerprint());
        setRecordDate(other.getRecordDate());
        setRecordKey(other.getRecordKey());
        setName(other.getName());
        return this;
    }"
"@Deprecated
    public static ByteBuf unmodifiableBuffer(ByteBuf buffer) {
        ByteOrder endianness = buffer.order();
        if (endianness == BIG_ENDIAN) {
            return new ReadOnlyByteBuf(buffer);
        }

        return new ReadOnlyByteBuf(buffer.order(BIG_ENDIAN)).order(LITTLE_ENDIAN);
    }"
"public static Tree buildTree(TreebankNode node) throws Exception {
        if (node.getLeaf())
            return toTree(node);
        else {
            List<TreebankNode> preChildren = children(node);
            List<Tree> children = new ArrayList<>();
            Tree t = toTree(node);
            for (int i = 0; i < preChildren.size(); i++) {
                children.add(buildTree(preChildren.get(i)));
            }

            t.connect(children);
            return t;

        }



    }"
"public NettyServerBuilder permitKeepAliveTime(long keepAliveTime, TimeUnit timeUnit) {
    checkArgument(keepAliveTime >= 0, ""permit keepalive time must be non-negative"");
    permitKeepAliveTimeInNanos = timeUnit.toNanos(keepAliveTime);
    return this;
  }"
"static BaseLongColumnValueSelector makeColumnValueSelectorWithLongDefault(
      final ColumnSelectorFactory metricFactory,
      final ExprMacroTable macroTable,
      @Nullable final String fieldName,
      @Nullable final String fieldExpression,
      final long nullValue
  )
  {
    if ((fieldName == null) == (fieldExpression == null)) {
      throw new IllegalArgumentException(""Only one of fieldName and fieldExpression should be non-null"");
    }
    if (fieldName != null) {
      return metricFactory.makeColumnValueSelector(fieldName);
    } else {
      final Expr expr = Parser.parse(fieldExpression, macroTable);
      final ColumnValueSelector<ExprEval> baseSelector = ExpressionSelectors.makeExprEvalSelector(metricFactory, expr);
      class ExpressionLongColumnSelector implements LongColumnSelector
      {
        @Override
        public long getLong()
        {
          final ExprEval exprEval = baseSelector.getObject();
          return exprEval.isNumericNull() ? nullValue : exprEval.asLong();
        }

        @Override
        public void inspectRuntimeShape(RuntimeShapeInspector inspector)
        {
          inspector.visit(""baseSelector"", baseSelector);
        }

        @Override
        public boolean isNull()
        {
          final ExprEval exprEval = baseSelector.getObject();
          return exprEval == null || exprEval.isNumericNull();
        }
      }
      return new ExpressionLongColumnSelector();
    }
  }"
"public static ResourceManagerRuntimeServicesConfiguration fromConfiguration(Configuration configuration) throws ConfigurationException {

		final String strJobTimeout = configuration.getString(ResourceManagerOptions.JOB_TIMEOUT);
		final Time jobTimeout;

		try {
			jobTimeout = Time.milliseconds(Duration.apply(strJobTimeout).toMillis());
		} catch (NumberFormatException e) {
			throw new ConfigurationException(""Could not parse the resource manager's job timeout "" +
				""value "" + ResourceManagerOptions.JOB_TIMEOUT + '.', e);
		}

		final SlotManagerConfiguration slotManagerConfiguration = SlotManagerConfiguration.fromConfiguration(configuration);

		return new ResourceManagerRuntimeServicesConfiguration(jobTimeout, slotManagerConfiguration);
	}"
"public ClusteringModelPrediction predictClustering(RowData data) throws PredictException {
    ClusteringModelPrediction p = new ClusteringModelPrediction();
    if (useExtendedOutput && (m instanceof IClusteringModel)) {
      IClusteringModel cm = (IClusteringModel) m;
      // setup raw input
      double[] rawData = nanArray(m.nfeatures());
      rawData = fillRawData(data, rawData);
      // get cluster assignment & distances
      final int k = cm.getNumClusters();
      p.distances = new double[k];
      p.cluster = cm.distances(rawData, p.distances);
    } else {
      double[] preds = preamble(ModelCategory.Clustering, data);
      p.cluster = (int) preds[0];
    }

    return p;
  }"
"public DataSink<T> writeAsText(String filePath) {
		return output(new TextOutputFormat<T>(new Path(filePath)));
	}"
"public @Nonnull String getTimestampString() {
        long duration = System.currentTimeMillis()-timestamp.getTime();
        return Util.getPastTimeString(duration);
    }"
"public List<Field> resolveFields(QualifiedName name)
    {
        return allFields.stream()
                .filter(input -> input.canResolve(name))
                .collect(toImmutableList());
    }"
"public int showDialog(boolean showRoot, String panel) {
    	this.getJSplitPane().showDialog(showRoot, panel);
        this.setVisible(true);
    	return this.exitResult;
    }"
"private void bufferRows1() throws IOException {
		BinaryRow copy = key1.copy();
		buffer1.reset();
		do {
			buffer1.add(row1);
		} while (nextRow1() && keyComparator.compare(key1, copy) == 0);
		buffer1.complete();
	}"
"protected void handleUnmappedAttribute(final Map<String, List<Object>> attributesToRelease, final String attributeName, final Object attributeValue) {
        LOGGER.debug(""Found attribute [{}] that is not defined in pattern definitions"", attributeName);
        if (excludeUnmappedAttributes) {
            LOGGER.debug(""Excluding attribute [{}] given unmatched attributes are to be excluded"", attributeName);
        } else {
            LOGGER.debug(""Added unmatched attribute [{}] with value(s) [{}]"", attributeName, attributeValue);
            attributesToRelease.put(attributeName, CollectionUtils.toCollection(attributeValue, ArrayList.class));
        }
    }"
"private static String readLineStandard(ByteBuf undecodedChunk, Charset charset) {
        int readerIndex = undecodedChunk.readerIndex();
        try {
            ByteBuf line = buffer(64);

            while (undecodedChunk.isReadable()) {
                byte nextByte = undecodedChunk.readByte();
                if (nextByte == HttpConstants.CR) {
                    // check but do not changed readerIndex
                    nextByte = undecodedChunk.getByte(undecodedChunk.readerIndex());
                    if (nextByte == HttpConstants.LF) {
                        // force read
                        undecodedChunk.readByte();
                        return line.toString(charset);
                    } else {
                        // Write CR (not followed by LF)
                        line.writeByte(HttpConstants.CR);
                    }
                } else if (nextByte == HttpConstants.LF) {
                    return line.toString(charset);
                } else {
                    line.writeByte(nextByte);
                }
            }
        } catch (IndexOutOfBoundsException e) {
            undecodedChunk.readerIndex(readerIndex);
            throw new NotEnoughDataDecoderException(e);
        }
        undecodedChunk.readerIndex(readerIndex);
        throw new NotEnoughDataDecoderException();
    }"
"public static ByteBuf wrappedBuffer(ByteBuffer buffer) {
        if (!buffer.hasRemaining()) {
            return EMPTY_BUFFER;
        }
        if (!buffer.isDirect() && buffer.hasArray()) {
            return wrappedBuffer(
                    buffer.array(),
                    buffer.arrayOffset() + buffer.position(),
                    buffer.remaining()).order(buffer.order());
        } else if (PlatformDependent.hasUnsafe()) {
            if (buffer.isReadOnly()) {
                if (buffer.isDirect()) {
                    return new ReadOnlyUnsafeDirectByteBuf(ALLOC, buffer);
                } else {
                    return new ReadOnlyByteBufferBuf(ALLOC, buffer);
                }
            } else {
                return new UnpooledUnsafeDirectByteBuf(ALLOC, buffer, buffer.remaining());
            }
        } else {
            if (buffer.isReadOnly()) {
                return new ReadOnlyByteBufferBuf(ALLOC, buffer);
            }  else {
                return new UnpooledDirectByteBuf(ALLOC, buffer, buffer.remaining());
            }
        }
    }"
"public Applications getApplicationsFromMultipleRegions(String[] remoteRegions) {

        boolean includeRemoteRegion = null != remoteRegions && remoteRegions.length != 0;

        logger.debug(""Fetching applications registry with remote regions: {}, Regions argument {}"",
                includeRemoteRegion, remoteRegions);

        if (includeRemoteRegion) {
            GET_ALL_WITH_REMOTE_REGIONS_CACHE_MISS.increment();
        } else {
            GET_ALL_CACHE_MISS.increment();
        }
        Applications apps = new Applications();
        apps.setVersion(1L);
        for (Entry<String, Map<String, Lease<InstanceInfo>>> entry : registry.entrySet()) {
            Application app = null;

            if (entry.getValue() != null) {
                for (Entry<String, Lease<InstanceInfo>> stringLeaseEntry : entry.getValue().entrySet()) {
                    Lease<InstanceInfo> lease = stringLeaseEntry.getValue();
                    if (app == null) {
                        app = new Application(lease.getHolder().getAppName());
                    }
                    app.addInstance(decorateInstanceInfo(lease));
                }
            }
            if (app != null) {
                apps.addApplication(app);
            }
        }
        if (includeRemoteRegion) {
            for (String remoteRegion : remoteRegions) {
                RemoteRegionRegistry remoteRegistry = regionNameVSRemoteRegistry.get(remoteRegion);
                if (null != remoteRegistry) {
                    Applications remoteApps = remoteRegistry.getApplications();
                    for (Application application : remoteApps.getRegisteredApplications()) {
                        if (shouldFetchFromRemoteRegistry(application.getName(), remoteRegion)) {
                            logger.info(""Application {}  fetched from the remote region {}"",
                                    application.getName(), remoteRegion);

                            Application appInstanceTillNow = apps.getRegisteredApplications(application.getName());
                            if (appInstanceTillNow == null) {
                                appInstanceTillNow = new Application(application.getName());
                                apps.addApplication(appInstanceTillNow);
                            }
                            for (InstanceInfo instanceInfo : application.getInstances()) {
                                appInstanceTillNow.addInstance(instanceInfo);
                            }
                        } else {
                            logger.debug(""Application {} not fetched from the remote region {} as there exists a ""
                                            + ""whitelist and this app is not in the whitelist."",
                                    application.getName(), remoteRegion);
                        }
                    }
                } else {
                    logger.warn(""No remote registry available for the remote region {}"", remoteRegion);
                }
            }
        }
        apps.setAppsHashCode(apps.getReconcileHashCode());
        return apps;
    }"
"public void checkAndThrowException() throws Exception {
		Throwable t = exception.get();
		if (t != null) {
			if (t instanceof Exception) {
				throw (Exception) t;
			}
			else if (t instanceof Error) {
				throw (Error) t;
			}
			else {
				throw new Exception(t);
			}
		}
	}"
"public Collection<SQLSegment> extract(final SQLAST ast) {
        Collection<SQLSegment> result = new LinkedList<>();
        Preconditions.checkState(ast.getSQLStatementRule().isPresent());
        Map<ParserRuleContext, Integer> parameterMarkerIndexes = getParameterMarkerIndexes(ast.getParserRuleContext());
        for (SQLSegmentExtractor each : ast.getSQLStatementRule().get().getExtractors()) {
            if (each instanceof OptionalSQLSegmentExtractor) {
                Optional<? extends SQLSegment> sqlSegment = ((OptionalSQLSegmentExtractor) each).extract(ast.getParserRuleContext(), parameterMarkerIndexes);
                if (sqlSegment.isPresent()) {
                    result.add(sqlSegment.get());
                }
            } else if (each instanceof CollectionSQLSegmentExtractor) {
                result.addAll(((CollectionSQLSegmentExtractor) each).extract(ast.getParserRuleContext(), parameterMarkerIndexes));
            }
        }
        return result;
    }"
"@WebMethod(name = ""config.xml"")
    public void doConfigDotXml(StaplerRequest req, StaplerResponse rsp)
            throws IOException {
        if (req.getMethod().equals(""GET"")) {
            // read
            rsp.setContentType(""application/xml"");
            writeConfigDotXml(rsp.getOutputStream());
            return;
        }
        if (req.getMethod().equals(""POST"")) {
            // submission
            updateByXml((Source)new StreamSource(req.getReader()));
            return;
        }

        // huh?
        rsp.sendError(SC_BAD_REQUEST);
    }"
"public Boolean deletes(String tableName, Set<byte[]> rowKeys) {
        boolean flag = false;
        try {
            HTable table = (HTable) getConnection().getTable(TableName.valueOf(tableName));
            List<Delete> deletes = new ArrayList<>();
            for (byte[] rowKey : rowKeys) {
                Delete delete = new Delete(rowKey);
                deletes.add(delete);
            }
            if (!deletes.isEmpty()) {
                table.delete(deletes);
            }
            flag = true;
        } catch (Exception e) {
            logger.error(e.getMessage(), e);
            throw new RuntimeException(e);
        }
        return flag;
    }"
"public static void exportRocChartsToHtmlFile(ROCMultiClass roc, File file) throws Exception {
        String rocAsHtml = rocChartToHtml(roc);
        FileUtils.writeStringToFile(file, rocAsHtml, StandardCharsets.UTF_8);
    }"
"public static boolean verify(final Set<String> nameSet, final X509Certificate cert)  {
		if (null!=nameSet && !nameSet.isEmpty()) {
			return nameSet.stream().filter(name->verify(name, cert)).findAny().isPresent();
		}
		
		return false;
	}"
"protected static List<Vertex> combineByCustomDictionary(List<Vertex> vertexList)
    {
        return combineByCustomDictionary(vertexList, CustomDictionary.dat);
    }"
"public URLNormalizer removeTrailingHash() {
        if (url.endsWith(""#"") && StringUtils.countMatches(url, ""#"") == 1) {
            url = StringUtils.removeEnd(url, ""#"");
        }
        return this;
    }"
"@SuppressWarnings(""unchecked"")
	public <T> T toProxyBean(Class<T> interfaceClass) {
		return (T) Proxy.newProxyInstance(ClassLoaderUtil.getClassLoader(), new Class<?>[]{interfaceClass}, this);
	}"
"public static INDArray sinh(INDArray in, boolean copy) {
        return Nd4j.getExecutioner().exec(new Sinh(in, (copy ? in.ulike() : in)));
    }"
"public Long del(String... keys) {
		try (Jedis jedis = getJedis()) {
			return jedis.del(keys);
		}
	}"
"@Internal
    @SuppressWarnings({""WeakerAccess"", ""unused""})
    @UsedByGeneratedCode
    protected Object injectBean(BeanResolutionContext resolutionContext, BeanContext context, Object bean) {
        return bean;
    }"
"public static List<List<Term>> seg2sentence(String text)
    {
        List<List<Term>> sentenceList = SEGMENT.seg2sentence(text);
        for (List<Term> sentence : sentenceList)
        {
            ListIterator<Term> listIterator = sentence.listIterator();
            while (listIterator.hasNext())
            {
                if (!CoreStopWordDictionary.shouldInclude(listIterator.next()))
                {
                    listIterator.remove();
                }
            }
        }

        return sentenceList;
    }"
"public EnvVars getCharacteristicEnvVars() {
        EnvVars env = new EnvVars();
        env.put(""JENKINS_SERVER_COOKIE"",SERVER_COOKIE.get());
        env.put(""HUDSON_SERVER_COOKIE"",SERVER_COOKIE.get()); // Legacy compatibility
        env.put(""JOB_NAME"",getFullName());
        env.put(""JOB_BASE_NAME"", getName());
        return env;
    }"
"public void clear() throws IOException {
    Set<String> toClear = new LinkedHashSet<>();
    toClear.add(indexNameFormatter().formatType(SPAN));
    toClear.add(indexNameFormatter().formatType(DEPENDENCY));
    for (String index : toClear) clear(index);
  }"
"public static Forest[] gets(Collection<String> keys) {
        return gets(keys.toArray(new String[keys.size()]));
    }"
"protected long delayNanos(long currentTimeNanos) {
        ScheduledFutureTask<?> scheduledTask = peekScheduledTask();
        if (scheduledTask == null) {
            return SCHEDULE_PURGE_INTERVAL;
        }

        return scheduledTask.delayNanos(currentTimeNanos);
    }"
"private static Class<?> findTypeFromGenericInArguments(final InvocationOnMock invocation, final TypeVariable returnType) {
        final Type[] parameterTypes = invocation.getMethod().getGenericParameterTypes();
        for (int i = 0; i < parameterTypes.length; i++) {
            Type argType = parameterTypes[i];
            if (returnType.equals(argType)) {
                Object argument = invocation.getArgument(i);

                if (argument == null) {
                    return null;
                }

                return argument.getClass();
            }
            if (argType instanceof GenericArrayType) {
                argType = ((GenericArrayType) argType).getGenericComponentType();
                if (returnType.equals(argType)) {
                    return invocation.getArgument(i).getClass();
                }
            }
        }
        return null;
    }"
"@Deprecated
	public <R> SingleOutputStreamOperator<R> fold(R initialValue, FoldFunction<T, R> function) {
		if (function instanceof RichFunction) {
			throw new UnsupportedOperationException(""FoldFunction can not be a RichFunction. "" +
				""Please use fold(FoldFunction, WindowFunction) instead."");
		}

		TypeInformation<R> resultType = TypeExtractor.getFoldReturnTypes(function, input.getType(),
				Utils.getCallLocationName(), true);

		return fold(initialValue, function, resultType);
	}"
"@Override
	public FileBaseStatistics getStatistics(BaseStatistics cachedStats) throws IOException {
		
		final FileBaseStatistics cachedFileStats = cachedStats instanceof FileBaseStatistics ?
			(FileBaseStatistics) cachedStats : null;
				
		try {
			return getFileStats(cachedFileStats, getFilePaths(), new ArrayList<>(getFilePaths().length));
		} catch (IOException ioex) {
			if (LOG.isWarnEnabled()) {
				LOG.warn(""Could not determine statistics for paths '"" + Arrays.toString(getFilePaths()) + ""' due to an io error: ""
						+ ioex.getMessage());
			}
		}
		catch (Throwable t) {
			if (LOG.isErrorEnabled()) {
				LOG.error(""Unexpected problem while getting the file statistics for paths '"" + Arrays.toString(getFilePaths()) + ""': ""
						+ t.getMessage(), t);
			}
		}
		
		// no statistics available
		return null;
	}"
"private void checkConstraint(
		SqlValidatorTable validatorTable,
		SqlUpdate update,
		RelDataType targetRowType) {
		final ModifiableViewTable modifiableViewTable =
			validatorTable.unwrap(ModifiableViewTable.class);
		if (modifiableViewTable != null) {
			final Table table = modifiableViewTable.unwrap(Table.class);
			final RelDataType tableRowType = table.getRowType(typeFactory);

			final Map<Integer, RexNode> projectMap =
				RelOptUtil.getColumnConstraints(modifiableViewTable, targetRowType,
					typeFactory);
			final Map<String, Integer> nameToIndex =
				SqlValidatorUtil.mapNameToIndex(tableRowType.getFieldList());

			// Validate update values against the view constraint.
			final List<SqlNode> targets = update.getTargetColumnList().getList();
			final List<SqlNode> sources = update.getSourceExpressionList().getList();
			for (final Pair<SqlNode, SqlNode> column : Pair.zip(targets, sources)) {
				final String columnName = ((SqlIdentifier) column.left).getSimple();
				final Integer columnIndex = nameToIndex.get(columnName);
				if (projectMap.containsKey(columnIndex)) {
					final RexNode columnConstraint = projectMap.get(columnIndex);
					final ValidationError validationError =
						new ValidationError(column.right,
							RESOURCE.viewConstraintNotSatisfied(columnName,
								Util.last(validatorTable.getQualifiedName())));
					RelOptUtil.validateValueAgainstConstraint(column.right,
						columnConstraint, validationError);
				}
			}
		}
	}"
"@UiThread
  public static <T extends View> void run(@NonNull List<T> list,
      @NonNull Action<? super T> action) {
    for (int i = 0, count = list.size(); i < count; i++) {
      action.apply(list.get(i), i);
    }
  }"
"@VisibleForTesting
  static void propagateMetadataFromProps(Map<String, String> metaData, Props inputProps, String nodeType,
      String nodeName, Logger logger) {

    // Backward compatibility: Unless user specifies, this will be absent from flows and jobs
    // .. if so, do a no-op like before
    if (!inputProps.containsKey(AZKABAN_EVENT_REPORTING_PROPERTIES_TO_PROPAGATE)) {
      return;
    }

    if (null == metaData || null == inputProps || null == logger ||
        Strings.isNullOrEmpty(nodeType) || Strings.isNullOrEmpty(nodeName)) {
      throw new IllegalArgumentException(""Input params should not be null or empty."");
    }

    final String propsToPropagate = inputProps.getString(AZKABAN_EVENT_REPORTING_PROPERTIES_TO_PROPAGATE);
    if (Strings.isNullOrEmpty(propsToPropagate)) {
      // Nothing to propagate
      logger.info(String.format(""No properties to propagate to metadata for %s: %s"", nodeType, nodeName));
      return;
    } else {
      logger.info(String.format(""Propagating: %s to metadata for %s: %s"", propsToPropagate, nodeType, nodeName));
    }

    final List<String> propsToPropagateList = SPLIT_ON_COMMA.splitToList(propsToPropagate);
    for (String propKey : propsToPropagateList) {
      if (!inputProps.containsKey(propKey)) {
        logger.warn(String.format(""%s does not contains: %s property; ""
            + ""skipping propagation to metadata"", nodeName, propKey));
        continue;
      }
      metaData.put(propKey, inputProps.getString(propKey));
    }
  }"
"static public void bpropMiniBatch(Neurons[] neurons, int n) {
    neurons[neurons.length - 1].bpropOutputLayer(n);
    for (int i = neurons.length - 2; i > 0; --i)
      neurons[i].bprop(n);

    for (int mb=0;mb<n;++mb) {
      // all errors are reset to 0
      for (int i = 0; i<neurons.length ;++i) {
        Storage.DenseVector e = neurons[i]._e == null ? null : neurons[i]._e[mb];
        if (e==null) continue;
        Arrays.fill(e.raw(), 0);
      }
    }
  }"
"protected void processFromItem(FromItem fromItem, int level) {
        if (fromItem instanceof SubJoin) {
            SubJoin subJoin = (SubJoin) fromItem;
            if (subJoin.getJoinList() != null && subJoin.getJoinList().size() > 0) {
                for (Join join : subJoin.getJoinList()) {
                    if (join.getRightItem() != null) {
                        processFromItem(join.getRightItem(), level + 1);
                    }
                }
            }
            if (subJoin.getLeft() != null) {
                processFromItem(subJoin.getLeft(), level + 1);
            }
        } else if (fromItem instanceof SubSelect) {
            SubSelect subSelect = (SubSelect) fromItem;
            if (subSelect.getSelectBody() != null) {
                processSelectBody(subSelect.getSelectBody(), level + 1);
            }
        } else if (fromItem instanceof ValuesList) {

        } else if (fromItem instanceof LateralSubSelect) {
            LateralSubSelect lateralSubSelect = (LateralSubSelect) fromItem;
            if (lateralSubSelect.getSubSelect() != null) {
                SubSelect subSelect = lateralSubSelect.getSubSelect();
                if (subSelect.getSelectBody() != null) {
                    processSelectBody(subSelect.getSelectBody(), level + 1);
                }
            }
        }
        //Table时不用处理
    }"
"private void buildDawg(Keyset keyset, DawgBuilder dawgBuilder)
    {
        dawgBuilder.init();
        for (int i = 0; i < keyset.numKeys(); ++i)
        {
            dawgBuilder.insert(keyset.getKey(i), keyset.getValue(i));
        }
        dawgBuilder.finish();
    }"
"public static Map<String, DataSource> getDataSourceMap(final Map<String, DataSourceConfiguration> dataSourceConfigurationMap) {
        Map<String, DataSource> result = new LinkedHashMap<>(dataSourceConfigurationMap.size(), 1);
        for (Entry<String, DataSourceConfiguration> entry : dataSourceConfigurationMap.entrySet()) {
            result.put(entry.getKey(), entry.getValue().createDataSource());
        }
        return result;
    }"
"public static File copyFile(File src, File dest, StandardCopyOption... options) throws IORuntimeException {
		// check
		Assert.notNull(src, ""Source File is null !"");
		if (false == src.exists()) {
			throw new IORuntimeException(""File not exist: "" + src);
		}
		Assert.notNull(dest, ""Destination File or directiory is null !"");
		if (equals(src, dest)) {
			throw new IORuntimeException(""Files '{}' and '{}' are equal"", src, dest);
		}
		return copyFile(src.toPath(), dest.toPath(), options).toFile();
	}"
"public static <R> R findResource(
			String fileName,
			String fileExtension,
			String localeToken,
			Locale locale,
			Function<String, R> function) {
		return findResource(new ZapResourceBundleControl(), fileName, fileExtension, localeToken, locale, function);
	}"
"@Override
	public void collect(IT record) {
		try {
			this.numRecordsIn.inc();
			this.outputCollector.collect(this.mapper.map(record));
		} catch (Exception ex) {
			throw new ExceptionInChainedStubException(this.taskName, ex);
		}
	}"
"public static String socketAddressToUrlString(InetSocketAddress address) {
		if (address.isUnresolved()) {
			throw new IllegalArgumentException(""Address cannot be resolved: "" + address.getHostString());
		}
		return ipAddressAndPortToUrlString(address.getAddress(), address.getPort());
	}"
"public Object invokeWithoutCheckedException(T target, Object... args) {
    try {
      return invoke(target, args);
    } catch (InvocationTargetException e) {
      Throwable targetException = e.getTargetException();
      if (targetException instanceof RuntimeException) {
        throw (RuntimeException) targetException;
      }
      AssertionError error = new AssertionError(""Unexpected exception"");
      error.initCause(targetException);
      throw error;
    }
  }"
"public void addOnInstalled(AddOn addOn) {
        for (ExtensionHook hook : extensionHooks.values()) {
            for (AddOnInstallationStatusListener listener : hook.getAddOnInstallationStatusListeners()) {
                try {
                    listener.addOnInstalled(addOn);
                } catch (Exception e) {
                    logger.error(""An error occurred while notifying: "" + listener.getClass().getCanonicalName(), e);
                }
            }
        }
    }"
"public int[] executeBatch(String... sqls) throws SQLException {
		Connection conn = null;
		try {
			conn = this.getConnection();
			return SqlExecutor.executeBatch(conn, sqls);
		} catch (SQLException e) {
			throw e;
		} finally {
			this.closeConnection(conn);
		}
	}"
"public void setValueFor(Field target, Object value) {
        if(value == null && target.getType().isPrimitive()) {
            throw new ND4JIllegalStateException(""Unable to set primitive field "" + target + "" of type "" + target.getClass()
                    + "" using null value!"");
        }

        if(value != null) {
            value = ensureProperType(target, value);
        }

        if(isConfigProperties()){
            String propertyName = configFieldName();
            if(propertyName == null)
                propertyName = ""config"";
            Field f = null;
            Class<?> currClass = getClass();
            try{
                f = currClass.getDeclaredField(propertyName);
            } catch (NoSuchFieldException e){
                //OK, try superclass
            }
            while(f == null && currClass.getSuperclass() != null){
                currClass = currClass.getSuperclass();
                try{
                    f = currClass.getDeclaredField(propertyName);
                } catch (NoSuchFieldException e){
                    //OK, try superclass
                }
            }

            if(f == null){
                throw new IllegalStateException(""Could not find field \"""" + propertyName + ""\"" for class "" + getClass().getName());
            }

            try {
                f.setAccessible(true);
                Object o = f.get(this);
                if(o == null){
                    //Null config class - try to create one...
                    Class<?> c = f.getType();
                    try {
                        o = c.newInstance();
                    } catch (InstantiationException e){
                        throw new RuntimeException(""Error creating new instance of configuration object type "" + c.getName(), e);
                    }
                    f.set(this, o);
                }
                target.set(o, value);
            } catch (IllegalAccessException e){
                throw new RuntimeException(""Error setting configuration field \"""" + propertyName + ""\"" for config field \"""" + propertyName
                    + ""\"" on class "" + getClass().getName());
            }

        } else {
            try {
                target.set(this,value);
            } catch (IllegalAccessException e) {
                throw new RuntimeException(""Error setting property for function "" + getClass().getName(), e);
            }
        }
    }"
"public void timeCollectionsDefault(int reps) {
    for (int i=0; i<reps; ++i) {
      gson.fromJson(json, LIST_TYPE);
    }
  }"
"public JSONObject optJSONObject(String name) {
		Object object = opt(name);
		return object instanceof JSONObject ? (JSONObject) object : null;
	}"
"public Collection<String> getAllPaths() throws Exception {
		final String path = ""/"";

		while (true) {
			Stat stat = client.checkExists().forPath(path);

			if (stat == null) {
				return Collections.emptyList();
			} else {
				try {
					return client.getChildren().forPath(path);
				} catch (KeeperException.NoNodeException ignored) {
					// Concurrent deletion, retry
				}
			}
		}
	}"
"private void repartitionUnionState(
			Map<String, List<Tuple2<StreamStateHandle, OperatorStateHandle.StateMetaInfo>>> unionState,
			List<Map<StreamStateHandle, OperatorStateHandle>> mergeMapList) {

		for (Map<StreamStateHandle, OperatorStateHandle> mergeMap : mergeMapList) {
			for (Map.Entry<String, List<Tuple2<StreamStateHandle, OperatorStateHandle.StateMetaInfo>>> e :
					unionState.entrySet()) {

				for (Tuple2<StreamStateHandle, OperatorStateHandle.StateMetaInfo> handleWithMetaInfo : e.getValue()) {
					OperatorStateHandle operatorStateHandle = mergeMap.get(handleWithMetaInfo.f0);
					if (operatorStateHandle == null) {
						operatorStateHandle = new OperatorStreamStateHandle(
							new HashMap<>(unionState.size()),
							handleWithMetaInfo.f0);
						mergeMap.put(handleWithMetaInfo.f0, operatorStateHandle);
					}
					operatorStateHandle.getStateNameToPartitionOffsets().put(e.getKey(), handleWithMetaInfo.f1);
				}
			}
		}
	}"
"@Override
	@SuppressWarnings(""unchecked"")
	public Tuple12<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11> copy() {
		return new Tuple12<>(this.f0,
			this.f1,
			this.f2,
			this.f3,
			this.f4,
			this.f5,
			this.f6,
			this.f7,
			this.f8,
			this.f9,
			this.f10,
			this.f11);
	}"
"public BufferedWriter getWriter(boolean isAppend) throws IORuntimeException {
		try {
			return new BufferedWriter(new OutputStreamWriter(new FileOutputStream(FileUtil.touch(file), isAppend), charset));
		} catch (Exception e) {
			throw new IORuntimeException(e);
		}
	}"
"@Override
    public void displayMessage(Message message) {
        if (message == null) {
            getRequestPanel().clearView(true);
            getResponsePanel().clearView(false);
            return;
        }

        if (!(message instanceof HttpMessage)) {
            logger.warn(""Unable to display message: "" + message.getClass().getCanonicalName());
            return;
        }

        HttpMessage httpMessage = (HttpMessage) message;
        if (httpMessage.getRequestHeader().isEmpty()) {
            getRequestPanel().clearView(true);
        } else {
            getRequestPanel().setMessage(httpMessage);
        }

        if (httpMessage.getResponseHeader().isEmpty()) {
            getResponsePanel().clearView(false);
        } else {
            getResponsePanel().setMessage(httpMessage, true);
        }
    }"
"private static String readDelimiterStandard(ByteBuf undecodedChunk, String delimiter) {
        int readerIndex = undecodedChunk.readerIndex();
        try {
            StringBuilder sb = new StringBuilder(64);
            int delimiterPos = 0;
            int len = delimiter.length();
            while (undecodedChunk.isReadable() && delimiterPos < len) {
                byte nextByte = undecodedChunk.readByte();
                if (nextByte == delimiter.charAt(delimiterPos)) {
                    delimiterPos++;
                    sb.append((char) nextByte);
                } else {
                    // delimiter not found so break here !
                    undecodedChunk.readerIndex(readerIndex);
                    throw new NotEnoughDataDecoderException();
                }
            }
            // Now check if either opening delimiter or closing delimiter
            if (undecodedChunk.isReadable()) {
                byte nextByte = undecodedChunk.readByte();
                // first check for opening delimiter
                if (nextByte == HttpConstants.CR) {
                    nextByte = undecodedChunk.readByte();
                    if (nextByte == HttpConstants.LF) {
                        return sb.toString();
                    } else {
                        // error since CR must be followed by LF
                        // delimiter not found so break here !
                        undecodedChunk.readerIndex(readerIndex);
                        throw new NotEnoughDataDecoderException();
                    }
                } else if (nextByte == HttpConstants.LF) {
                    return sb.toString();
                } else if (nextByte == '-') {
                    sb.append('-');
                    // second check for closing delimiter
                    nextByte = undecodedChunk.readByte();
                    if (nextByte == '-') {
                        sb.append('-');
                        // now try to find if CRLF or LF there
                        if (undecodedChunk.isReadable()) {
                            nextByte = undecodedChunk.readByte();
                            if (nextByte == HttpConstants.CR) {
                                nextByte = undecodedChunk.readByte();
                                if (nextByte == HttpConstants.LF) {
                                    return sb.toString();
                                } else {
                                    // error CR without LF
                                    // delimiter not found so break here !
                                    undecodedChunk.readerIndex(readerIndex);
                                    throw new NotEnoughDataDecoderException();
                                }
                            } else if (nextByte == HttpConstants.LF) {
                                return sb.toString();
                            } else {
                                // No CRLF but ok however (Adobe Flash uploader)
                                // minus 1 since we read one char ahead but
                                // should not
                                undecodedChunk.readerIndex(undecodedChunk.readerIndex() - 1);
                                return sb.toString();
                            }
                        }
                        // FIXME what do we do here?
                        // either considering it is fine, either waiting for
                        // more data to come?
                        // lets try considering it is fine...
                        return sb.toString();
                    }
                    // only one '-' => not enough
                    // whatever now => error since incomplete
                }
            }
        } catch (IndexOutOfBoundsException e) {
            undecodedChunk.readerIndex(readerIndex);
            throw new NotEnoughDataDecoderException(e);
        }
        undecodedChunk.readerIndex(readerIndex);
        throw new NotEnoughDataDecoderException();
    }"
"public final JsonElement toJsonTree(T value) {
    try {
      JsonTreeWriter jsonWriter = new JsonTreeWriter();
      write(jsonWriter, value);
      return jsonWriter.get();
    } catch (IOException e) {
      throw new JsonIOException(e);
    }
  }"
"public static KerasTokenizer fromJson(String jsonFileName) throws IOException, InvalidKerasConfigurationException {
        String json = new String(Files.readAllBytes(Paths.get(jsonFileName)));
        Map<String, Object> tokenizerBaseConfig = parseJsonString(json);
        Map<String, Object> tokenizerConfig;
        if (tokenizerBaseConfig.containsKey(""config""))
            tokenizerConfig = (Map<String, Object>) tokenizerBaseConfig.get(""config"");
        else
            throw new InvalidKerasConfigurationException(""No configuration found for Keras tokenizer"");


        Integer numWords = (Integer) tokenizerConfig.get(""num_words"");
        String filters = (String) tokenizerConfig.get(""filters"");
        Boolean lower = (Boolean) tokenizerConfig.get(""lower"");
        String split = (String) tokenizerConfig.get(""split"");
        Boolean charLevel = (Boolean) tokenizerConfig.get(""char_level"");
        String oovToken = (String) tokenizerConfig.get(""oov_token"");
        Integer documentCount = (Integer) tokenizerConfig.get(""document_count"");

        @SuppressWarnings(""unchecked"")
        Map<String, Integer> wordCounts = (Map) parseJsonString((String) tokenizerConfig.get(""word_counts""));
        @SuppressWarnings(""unchecked"")
        Map<String, Integer> wordDocs = (Map) parseJsonString((String) tokenizerConfig.get(""word_docs""));
        @SuppressWarnings(""unchecked"")
        Map<String, Integer> wordIndex = (Map) parseJsonString((String) tokenizerConfig.get(""word_index""));
        @SuppressWarnings(""unchecked"")
        Map<Integer, String> indexWord = (Map) parseJsonString((String) tokenizerConfig.get(""index_word""));
        @SuppressWarnings(""unchecked"")
        Map<Integer, Integer> indexDocs = (Map) parseJsonString((String) tokenizerConfig.get(""index_docs""));

        KerasTokenizer tokenizer = new KerasTokenizer(numWords, filters, lower, split, charLevel, oovToken);
        tokenizer.setDocumentCount(documentCount);
        tokenizer.setWordCounts(wordCounts);
        tokenizer.setWordDocs(new HashMap<>(wordDocs));
        tokenizer.setWordIndex(wordIndex);
        tokenizer.setIndexWord(indexWord);
        tokenizer.setIndexDocs(indexDocs);

        return tokenizer;
    }"
"public static ImageTransformProcess fromYaml(String yaml) {
        try {
            return JsonMappers.getMapperYaml().readValue(yaml, ImageTransformProcess.class);
        } catch (IOException e) {
            //TODO better exceptions
            throw new RuntimeException(e);
        }
    }"
"public Map<String, String> getPropsWithPrefix(String confPrefix) {
		Properties props = getProps();
		Enumeration e = props.propertyNames();
		Map<String, String> configMap = new HashMap<>();
		String name = null;
		while (e.hasMoreElements()) {
			name = (String) e.nextElement();
			if (name.startsWith(confPrefix)) {
				String value = props.getProperty(name);
				name = name.substring(confPrefix.length());
				configMap.put(name, value);
			}
		}
		return configMap;
	}"
"private final void print( Object[] kvs ) {
    for( int i=0; i<len(kvs); i++ ) {
      Object K = key(kvs,i);
      if( K != null ) {
        String KS = (K == TOMBSTONE) ? ""XXX"" : K.toString();
        Object V = val(kvs,i);
        Object U = Prime.unbox(V);
        String p = (V==U) ? """" : ""prime_"";
        String US = (U == TOMBSTONE) ? ""tombstone"" : U.toString();
        System.out.println(""""+i+"" (""+KS+"",""+p+US+"")"");
      }
    }
    Object[] newkvs = chm(kvs)._newkvs; // New table, if any
    if( newkvs != null ) {
      System.out.println(""----"");
      print(newkvs);
    }
  }"
"public boolean dependsOn(AddOn addOn) {
		if (dependencies == null || dependencies.getAddOns().isEmpty()) {
			return false;
		}

		return dependsOn(dependencies.getAddOns(), addOn);
	}"
"public static DataAnalysis analyze(Schema schema, JavaRDD<List<Writable>> data) {
        return analyze(schema, data, DEFAULT_HISTOGRAM_BUCKETS);
    }"
"public void validateParam() throws Exception {
        Enumeration<AbstractParamPanel> en = tablePanel.elements();
        AbstractParamPanel panel = null;
        while (en.hasMoreElements()) {
            panel = en.nextElement();
            try {
                panel.validateParam(paramObject);
            } catch (Exception e) {
                showParamPanel(panel, panel.getName());
                throw e;
            }
        }
    }"
"public static ExpectedCondition<List<WebElement>> visibilityOfNestedElementsLocatedBy(
    final By parent,
    final By childLocator) {
    return new ExpectedCondition<List<WebElement>>() {

      @Override
      public List<WebElement> apply(WebDriver driver) {
        WebElement current = driver.findElement(parent);

        List<WebElement> allChildren = current.findElements(childLocator);
        // The original code only checked the first element. Fair enough.
        if (!allChildren.isEmpty() && allChildren.get(0).isDisplayed()) {
          return allChildren;
        }

        return null;
      }

      @Override
      public String toString() {
        return String.format(""visibility of elements located by %s -> %s"", parent, childLocator);
      }
    };
  }"
"public short getShort(String key) {
		addToDefaults(key, null);
		String value = getRequired(key);
		return Short.valueOf(value);
	}"
"private void sendAndReceiveImpl(HttpMessage message, HttpRequestConfig requestConfig) throws IOException {
        if (log.isDebugEnabled()) {
            log.debug(""Sending "" + message.getRequestHeader().getMethod() + "" "" + message.getRequestHeader().getURI());
        }
        message.setTimeSentMillis(System.currentTimeMillis());

        try {
            if (requestConfig.isNotifyListeners()) {
                notifyRequestListeners(message);
            }

            HttpMethodParams params = null;
            if (requestConfig.getSoTimeout() != HttpRequestConfig.NO_VALUE_SET) {
                params = new HttpMethodParams();
                params.setSoTimeout(requestConfig.getSoTimeout());
            }
            sendAuthenticated(message, false, params);

        } finally {
            message.setTimeElapsedMillis((int) (System.currentTimeMillis() - message.getTimeSentMillis()));

            if (log.isDebugEnabled()) {
                log.debug(
                        ""Received response after "" + message.getTimeElapsedMillis() + ""ms for ""
                                + message.getRequestHeader().getMethod() + "" "" + message.getRequestHeader().getURI());
            }

            if (requestConfig.isNotifyListeners()) {
                notifyResponseListeners(message);
            }
        }
    }"
"private void expandArray(int maxSize)
    {
        int curSize = getBaseArraySize();
        if (curSize > maxSize)
        {
            return;
        }
        if (maxSize >= LEAF_BIT)
        {
            throw new RuntimeException(""Double Array Trie size exceeds absolute threshold"");
        }
        for (int i = curSize; i <= maxSize; ++i)
        {
            this.base.append(0);
            this.check.append(0);
            addFreeLink(i);
        }
    }"
"public static double correlation(double[] residuals, double targetAttribute[]) {
        double[] predictedValues = new double[residuals.length];
        for (int i = 0; i < predictedValues.length; i++) {
            predictedValues[i] = targetAttribute[i] - residuals[i];
        }
        double ssErr = ssError(predictedValues, targetAttribute);
        double total = ssTotal(residuals, targetAttribute);
        return 1 - (ssErr / total);
    }"
"public static synchronized @CheckForNull PermissionGroup get(Class owner) {
        for (PermissionGroup g : PERMISSIONS) {
            if (g.owner == owner) {
                return g;
            }
        }
        return null;
    }"
"public static double randomDouble(double min, double max, int scale, RoundingMode roundingMode) {
		return NumberUtil.round(randomDouble(min, max), scale, roundingMode).doubleValue();
	}"
"@Override
    public void exec(List<Aggregate> batch) {
        if (batch.size() == 0)
            return;

        List<Batch<Aggregate>> batches = Batch.getBatches(batch);
        for (Batch<Aggregate> single : batches) {
            this.exec(single);
        }
    }"
"public <T extends Evaluation> T evaluate(RDD<DataSet> data, List<String> labelsList) {
        return evaluate(data.toJavaRDD(), labelsList);
    }"
"public static void writeWord2VecModel(Word2Vec vectors, File file) {
        try (FileOutputStream fos = new FileOutputStream(file);
             BufferedOutputStream stream = new BufferedOutputStream(fos)) {
            writeWord2VecModel(vectors, stream);
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    }"
"protected CountDownLatch startStreamingCalls(int callsPerChannel, final AtomicLong counter,
      final AtomicBoolean record, final AtomicBoolean done, final long counterDelta) {
    final CountDownLatch latch = new CountDownLatch(callsPerChannel * channels.length);
    for (final ManagedChannel channel : channels) {
      for (int i = 0; i < callsPerChannel; i++) {
        final ClientCall<ByteBuf, ByteBuf> streamingCall =
            channel.newCall(pingPongMethod, CALL_OPTIONS);
        final AtomicReference<StreamObserver<ByteBuf>> requestObserverRef =
            new AtomicReference<>();
        final AtomicBoolean ignoreMessages = new AtomicBoolean();
        StreamObserver<ByteBuf> requestObserver = ClientCalls.asyncBidiStreamingCall(
            streamingCall,
            new StreamObserver<ByteBuf>() {
              @Override
              public void onNext(ByteBuf value) {
                if (done.get()) {
                  if (!ignoreMessages.getAndSet(true)) {
                    requestObserverRef.get().onCompleted();
                  }
                  return;
                }
                requestObserverRef.get().onNext(request.slice());
                if (record.get()) {
                  counter.addAndGet(counterDelta);
                }
                // request is called automatically because the observer implicitly has auto
                // inbound flow control
              }

              @Override
              public void onError(Throwable t) {
                logger.log(Level.WARNING, ""call error"", t);
                latch.countDown();
              }

              @Override
              public void onCompleted() {
                latch.countDown();
              }
            });
        requestObserverRef.set(requestObserver);
        requestObserver.onNext(request.slice());
        requestObserver.onNext(request.slice());
      }
    }
    return latch;
  }"
"INDArray bucketData(INDArray query){
        INDArray mask = bucket(query);
        int nRes = mask.sum(0).getInt(0);
        INDArray res = Nd4j.create(new int[] {nRes, inDimension});
        int j = 0;
        for (int i = 0; i < nRes; i++){
            while (mask.getInt(j) == 0 && j < mask.length() - 1) {
                j += 1;
            }
            if (mask.getInt(j) == 1) res.putRow(i, indexData.getRow(j));
            j += 1;
        }
        return res;
    }"
"private String getVerboseConfig() {
    StringBuilder builder = new StringBuilder();
    GridHubConfiguration config = getRegistry().getHub().getConfiguration();

    builder.append(""<div id='verbose-config-container'>"");
    builder.append(""<a id='verbose-config-view-toggle' href='#'>View Verbose</a>"");

    builder.append(""<div id='verbose-config-content'>"");
    GridHubConfiguration tmp = new GridHubConfiguration();

    builder.append(""<br/><b>The final configuration comes from:</b><br/>"");
    builder.append(""<b>the default :</b><br/>"");
    builder.append(prettyHtmlPrint(tmp));

    if (config.getRawArgs() != null) {
      builder.append(""<b>updated with command line options:</b><br/>"");
      builder.append(String.join("" "", config.getRawArgs()));

      if (config.getConfigFile() != null) {
        builder.append(""<br/><b>and configuration loaded from "").append(config.getConfigFile()).append("":</b><br/>"");
        try {
          builder.append(String.join(""<br/>"", Files.readAllLines(new File(config.getConfigFile()).toPath())));
        } catch (IOException e) {
          builder.append(""<b>"").append(e.getMessage()).append(""</b>"");
        }
      }
    }
    builder.append(""</div>""); // End of Verbose Content
    builder.append(""</div>""); // End of Verbose Container
    return builder.toString();
  }"
"public static void writeWordVectors(@NonNull Glove vectors, @NonNull OutputStream stream) {
        try {
            writeWordVectors(vectors.lookupTable(), stream);
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    }"
"public void setTokenizerFactory(@NonNull TokenizerFactory tokenizerFactory) {
        this.tokenizerFactory = tokenizerFactory;

        if (sentenceIter != null) {
            SentenceTransformer transformer = new SentenceTransformer.Builder().iterator(sentenceIter)
                            .tokenizerFactory(this.tokenizerFactory).build();
            this.iterator = new AbstractSequenceIterator.Builder<>(transformer).build();
        }
    }"
"public static File createTempFile(String prefix, String suffix, File dir, boolean isReCreat) throws IORuntimeException {
		int exceptionsCount = 0;
		while (true) {
			try {
				File file = File.createTempFile(prefix, suffix, dir).getCanonicalFile();
				if (isReCreat) {
					file.delete();
					file.createNewFile();
				}
				return file;
			} catch (IOException ioex) { // fixes java.io.WinNTFileSystem.createFileExclusively access denied
				if (++exceptionsCount >= 50) {
					throw new IORuntimeException(ioex);
				}
			}
		}
	}"
"public static <T extends CharSequence> T validateEmail(T value, String errorMsg) throws ValidateException {
		if (false == isEmail(value)) {
			throw new ValidateException(errorMsg);
		}
		return value;
	}"
"TreeString split(final String prefix) {
        assert getLabel().startsWith(prefix);
        char[] suffix = new char[label.length - prefix.length()];
        System.arraycopy(label, prefix.length(), suffix, 0, suffix.length);

        TreeString middle = new TreeString(parent, prefix);
        label = suffix;
        parent = middle;

        return middle;
    }"
"private static boolean renameIndexFiles(
      final FileSystem outputFS,
      final Path indexZipFilePath,
      final Path finalIndexZipFilePath
  )
  {
    try {
      return RetryUtils.retry(
          () -> {
            final boolean needRename;

            if (outputFS.exists(finalIndexZipFilePath)) {
              // NativeS3FileSystem.rename won't overwrite, so we might need to delete the old index first
              final FileStatus zipFile = outputFS.getFileStatus(indexZipFilePath);
              final FileStatus finalIndexZipFile = outputFS.getFileStatus(finalIndexZipFilePath);

              if (zipFile.getModificationTime() >= finalIndexZipFile.getModificationTime()
                  || zipFile.getLen() != finalIndexZipFile.getLen()) {
                log.info(
                    ""File[%s / %s / %sB] existed, but wasn't the same as [%s / %s / %sB]"",
                    finalIndexZipFile.getPath(),
                    DateTimes.utc(finalIndexZipFile.getModificationTime()),
                    finalIndexZipFile.getLen(),
                    zipFile.getPath(),
                    DateTimes.utc(zipFile.getModificationTime()),
                    zipFile.getLen()
                );
                outputFS.delete(finalIndexZipFilePath, false);
                needRename = true;
              } else {
                log.info(
                    ""File[%s / %s / %sB] existed and will be kept"",
                    finalIndexZipFile.getPath(),
                    DateTimes.utc(finalIndexZipFile.getModificationTime()),
                    finalIndexZipFile.getLen()
                );
                needRename = false;
              }
            } else {
              needRename = true;
            }

            if (needRename) {
              log.info(""Attempting rename from [%s] to [%s]"", indexZipFilePath, finalIndexZipFilePath);
              return outputFS.rename(indexZipFilePath, finalIndexZipFilePath);
            } else {
              return true;
            }
          },
          FileUtils.IS_EXCEPTION,
          NUM_RETRIES
      );
    }
    catch (Exception e) {
      throw new RuntimeException(e);
    }
  }"
"int valueToFront(final byte value) {
        int index = 0;
        byte temp = mtf[0];
        if (value != temp) {
            mtf[0] = value;
            while (value != temp) {
                index++;
                final byte temp2 = temp;
                temp = mtf[index];
                mtf[index] = temp2;
            }
        }
        return index;
    }"
"public static void substituteDeprecatedConfigPrefix(
			Configuration config,
			String deprecatedPrefix,
			String designatedPrefix) {

		// set the designated key only if it is not set already
		final int prefixLen = deprecatedPrefix.length();

		Configuration replacement = new Configuration();

		for (String key : config.keySet()) {
			if (key.startsWith(deprecatedPrefix)) {
				String newKey = designatedPrefix + key.substring(prefixLen);
				if (!config.containsKey(newKey)) {
					replacement.setString(newKey, config.getString(key, null));
				}
			}
		}

		config.addAll(replacement);
	}"
"private synchronized Document asXmlDocument(String propertyName)
			throws IOException, IllegalArgumentException {
		Document doc;
		try {
			doc = DocumentBuilderFactory
					.newInstance()
					.newDocumentBuilder()
					.newDocument();
		} catch (ParserConfigurationException pe) {
			throw new IOException(pe);
		}

		Element conf = doc.createElement(""configuration"");
		doc.appendChild(conf);
		conf.appendChild(doc.createTextNode(""\n""));
		handleDeprecation(); //ensure properties is set and deprecation is handled

		if(!Strings.isNullOrEmpty(propertyName)) {
			if (!properties.containsKey(propertyName)) {
				// given property not found, illegal argument
				throw new IllegalArgumentException(""Property "" +
						propertyName + "" not found"");
			} else {
				// given property is found, write single property
				appendXMLProperty(doc, conf, propertyName);
				conf.appendChild(doc.createTextNode(""\n""));
			}
		} else {
			// append all elements
			for (Enumeration<Object> e = properties.keys(); e.hasMoreElements();) {
				appendXMLProperty(doc, conf, (String)e.nextElement());
				conf.appendChild(doc.createTextNode(""\n""));
			}
		}
		return doc;
	}"
"private void checkFile() throws IORuntimeException {
		if (false == file.exists()) {
			throw new IORuntimeException(""File not exist: "" + file);
		}
		if (false == file.isFile()) {
			throw new IORuntimeException(""Not a file:"" + file);
		}
	}"
"public static Font setFontStyle(Font font, short color, short fontSize, String fontName) {
		if(color > 0) {
			font.setColor(color);
		}
		if(fontSize > 0) {
			font.setFontHeightInPoints(fontSize);
		}
		if(StrUtil.isNotBlank(fontName)) {
			font.setFontName(fontName);
		}
		return font;
	}"
"private JComponent getTabComponent(JPanel panel) {
		JScrollPane scrollPane = panelToScrollPaneMap.get(panel);
		if (scrollPane != null) {
			return scrollPane;
		}
		return panel;
	}"
"public final int getInt32(final int pos) {
        final int position = origin + pos;

        if (pos + 3 >= limit || pos < 0) throw new IllegalArgumentException(""limit excceed: ""
                                                                            + (pos < 0 ? pos : (pos + 3)));

        byte[] buf = buffer;
        return (0xff & buf[position]) | ((0xff & buf[position + 1]) << 8) | ((0xff & buf[position + 2]) << 16)
               | ((buf[position + 3]) << 24);
    }"
"static public List<DisabledJob> fromDeprecatedObjectList(List<Object> objList) {
    if (objList == null) {
      return null;
    }
    return objList.stream().map(x -> {
        if (x == null) {
          return null;
        } else {
          return fromDeprecatedObject(x);
        }
    }).collect(Collectors.toList());
  }"
"public static CellStyle setColor(CellStyle cellStyle, short color, FillPatternType fillPattern) {
		cellStyle.setFillForegroundColor(color);
		cellStyle.setFillPattern(fillPattern);
		return cellStyle;
	}"
"private static int computeDimension(ResultPoint topLeft,
                                      ResultPoint topRight,
                                      ResultPoint bottomLeft,
                                      float moduleSize) throws NotFoundException {
    int tltrCentersDimension = MathUtils.round(ResultPoint.distance(topLeft, topRight) / moduleSize);
    int tlblCentersDimension = MathUtils.round(ResultPoint.distance(topLeft, bottomLeft) / moduleSize);
    int dimension = ((tltrCentersDimension + tlblCentersDimension) / 2) + 7;
    switch (dimension & 0x03) { // mod 4
      case 0:
        dimension++;
        break;
        // 1? do nothing
      case 2:
        dimension--;
        break;
      case 3:
        throw NotFoundException.getNotFoundInstance();
    }
    return dimension;
  }"
"public static SecretKey generateKey(String algorithm, KeySpec keySpec) {
		final SecretKeyFactory keyFactory = getSecretKeyFactory(algorithm);
		try {
			return keyFactory.generateSecret(keySpec);
		} catch (InvalidKeySpecException e) {
			throw new CryptoException(e);
		}
	}"
"public static boolean isNormalClass(Class<?> clazz) {
		return null != clazz //
				&& false == clazz.isInterface() //
				&& false == isAbstract(clazz) //
				&& false == clazz.isEnum() //
				&& false == clazz.isArray() //
				&& false == clazz.isAnnotation() //
				&& false == clazz.isSynthetic() //
				&& false == clazz.isPrimitive();//
	}"
"public static ParagraphVectors readParagraphVectors(InputStream stream) throws IOException {
        File tmpFile = DL4JFileUtils.createTempFile(""restore"", ""paravec"");
        try {
            FileUtils.copyInputStreamToFile(stream, tmpFile);
            return readParagraphVectors(tmpFile);
        } finally {
            tmpFile.delete();
        }
    }"
"public int[] getTopSentence(int size)
    {
        Collection<Integer> values = top.values();
        size = Math.min(size, values.size());
        int[] indexArray = new int[size];
        Iterator<Integer> it = values.iterator();
        for (int i = 0; i < size; ++i)
        {
            indexArray[i] = it.next();
        }
        return indexArray;
    }"
"public String format(INDArray arr, boolean summarize) {
        if(arr.isEmpty())
            return EMPTY_ARRAY_STR;
        this.scientificFormat = ""0."";
        int addPrecision = this.precision;
        while (addPrecision > 0) {
            this.scientificFormat += ""#"";
            addPrecision -= 1;
        }
        this.scientificFormat = this.scientificFormat + ""E0"";
        if (this.scientificFormat.length() + 2  > this.padding) this.padding = this.scientificFormat.length() + 2;
        this.maxToPrintWithoutSwitching = Math.pow(10,this.precision);
        this.minToPrintWithoutSwitching = 1.0/(this.maxToPrintWithoutSwitching);
        return format(arr, 0, summarize && arr.length() > maxPrintElements);
    }"
"public Authentication createAuthentication(HttpServletRequest request, ConsumerAuthentication authentication, OAuthAccessProviderToken authToken) {
    if (authToken != null) {
      Authentication userAuthentication = authToken.getUserAuthentication();
      if (userAuthentication instanceof AbstractAuthenticationToken) {
        //initialize the details with the consumer that is actually making the request on behalf of the user.
        ((AbstractAuthenticationToken) userAuthentication).setDetails(new OAuthAuthenticationDetails(request, authentication.getConsumerDetails()));
      }
      return userAuthentication;
    }

    return authentication;
  }"
"public Token scanIdentifier() {
        if ('`' == charAt(offset)) {
            int length = getLengthUntilTerminatedChar('`');
            return new Token(Literals.IDENTIFIER, input.substring(offset, offset + length), offset + length);
        }
        if ('""' == charAt(offset)) {
            int length = getLengthUntilTerminatedChar('""');
            return new Token(Literals.IDENTIFIER, input.substring(offset, offset + length), offset + length);
        }
        if ('[' == charAt(offset)) {
            int length = getLengthUntilTerminatedChar(']');
            return new Token(Literals.IDENTIFIER, input.substring(offset, offset + length), offset + length);
        }
        int length = 0;
        while (isIdentifierChar(charAt(offset + length))) {
            length++;
        }
        String literals = input.substring(offset, offset + length);
        if (isAmbiguousIdentifier(literals)) {
            return new Token(processAmbiguousIdentifier(offset + length, literals), literals, offset + length);
        }
        return new Token(dictionary.findTokenType(literals, Literals.IDENTIFIER), literals, offset + length);
    }"
"@Override
	public int compareTo(CharValue o) {
		final int other = o.value;
		return this.value < other ? -1 : this.value > other ? 1 : 0;
	}"
"private void beforeSessionEvent() throws NewSessionException {
    RemoteProxy p = session.getSlot().getProxy();
    if (p instanceof TestSessionListener) {
      try {
        ((TestSessionListener) p).beforeSession(session);
      } catch (Exception e) {
        log.severe(""Error running the beforeSessionListener : "" + e.getMessage());
        e.printStackTrace();
        throw new NewSessionException(""The listener threw an exception ( listener bug )"", e);
      }
    }
  }"
"public static <E> Iterator<E> toIterator(Enumeration<E> enumeration) {
        return new EnumerationIterator<E>(enumeration);
    }"
"public static String getTransformStage(Long pipelineId, Long processId) {
        return getProcess(pipelineId, processId) + ""/"" + ArbitrateConstants.NODE_TRANSFORMED;
    }"
"private void initialize() {

		contextManager = Model.getSingleton().getOptionsParam().getCertificateParam().getSSLContextManager();

		keyStoreListModel = new DefaultListModel<>();
		aliasTableModel = new AliasTableModel(contextManager);

		this.setLayout(new CardLayout());
		this.setName(Constant.messages.getString(""options.cert.title""));

		JPanel certificatePanel = getPanelCertificate();
		this.add(certificatePanel, certificatePanel.getName());

		driverConfig = createDriverConfiguration();
		updateDriverComboBox();
		driverConfig.addChangeListener(e -> updateDriverComboBox());

		Certificate cert =contextManager.getDefaultCertificate();
		if(cert!=null) {
			certificateTextField.setText(cert.toString());
		}
		
		if(contextManager.getKeyStoreCount() != 0) {
			overrideEnableClientCertificate = true;
		}

	}"
"public static boolean isHostInNetworkCard(String host) {
        try {
            InetAddress addr = InetAddress.getByName(host);
            return NetworkInterface.getByInetAddress(addr) != null;
        } catch (Exception e) {
            return false;
        }
    }"
"void link(Node<K, V> sentinel, Node<K, V> node) {
    node.setPreviousInVariableOrder(sentinel.getPreviousInVariableOrder());
    node.setNextInVariableOrder(sentinel);

    sentinel.getPreviousInVariableOrder().setNextInVariableOrder(node);
    sentinel.setPreviousInVariableOrder(node);
  }"
"public static void setupClasspath(
      final Path distributedClassPath,
      final Path intermediateClassPath,
      final Job job
  )
      throws IOException
  {
    String classpathProperty = System.getProperty(""druid.hadoop.internal.classpath"");
    if (classpathProperty == null) {
      classpathProperty = System.getProperty(""java.class.path"");
    }

    String[] jarFiles = classpathProperty.split(File.pathSeparator);

    final Configuration conf = job.getConfiguration();
    final FileSystem fs = distributedClassPath.getFileSystem(conf);

    if (fs instanceof LocalFileSystem) {
      return;
    }

    for (String jarFilePath : jarFiles) {

      final File jarFile = new File(jarFilePath);
      if (jarFile.getName().endsWith("".jar"")) {
        try {
          RetryUtils.retry(
              () -> {
                if (isSnapshot(jarFile)) {
                  addSnapshotJarToClassPath(jarFile, intermediateClassPath, fs, job);
                } else {
                  addJarToClassPath(jarFile, distributedClassPath, intermediateClassPath, fs, job);
                }
                return true;
              },
              shouldRetryPredicate(),
              NUM_RETRIES
          );
        }
        catch (Exception e) {
          throw new RuntimeException(e);
        }
      }
    }
  }"
"public static <K, V> List<Map<K, V>> toMapList(Map<K, ? extends Iterable<V>> listMap) {
		return MapUtil.toMapList(listMap);
	}"
"public String getEscapedCurrentHierPath() throws URIException {
        char[] path = getRawCurrentHierPath();
        return (path == null) ? null : new String(path);
    }"
"public static void info(Log log, String format, Object... arguments) {
		if (false == log(log, Level.INFO, null, format, arguments)) {
			log.info(format, arguments);
		}
	}"
"@Blocking
    public static String readText(BufferedReader reader) throws IOException {
        StringBuilder answer = new StringBuilder();
        if (reader == null) {
            return answer.toString();
        }
        // reading the content of the file within a char buffer
        // allow to keep the correct line endings
        char[] charBuffer = new char[BUFFER_MAX];
        int nbCharRead /* = 0*/;
        try {
            while ((nbCharRead = reader.read(charBuffer)) != -1) {
                // appends buffer
                answer.append(charBuffer, 0, nbCharRead);
            }
            Reader temp = reader;
            reader = null;
            temp.close();
        } finally {
            try {
                if (reader != null) {
                    reader.close();
                }
            } catch (IOException e) {
                if (LOG.isWarnEnabled()) {
                    LOG.warn(""Failed to close reader: "" + e.getMessage(), e);
                }
            }
        }
        return answer.toString();
    }"
"@SuppressWarnings(""unused"")
    @Internal
    void dump() {
        System.out.println(""declaredAnnotations = "" + declaredAnnotations);
        System.out.println(""declaredStereotypes = "" + declaredStereotypes);
        System.out.println(""allAnnotations = "" + allAnnotations);
        System.out.println(""allStereotypes = "" + allStereotypes);
        System.out.println(""annotationsByStereotype = "" + annotationsByStereotype);
    }"
"public void setTabLocked(AbstractPanel panel, boolean lock) {
        for (int i = 0; i < this.getTabCount(); i++) {
        	Component tabCom = this.getTabComponentAt(i);
        	if (tabCom != null && tabCom instanceof TabbedPanelTab && tabCom.isVisible()) {
        		TabbedPanelTab jp = (TabbedPanelTab) tabCom;
        		if (panel.equals(jp.getAbstractPanel())) {
            		jp.setLocked(!lock);
        		}
        	}
        }
	}"
"@Override
    public void validate(String name, String value) throws ParameterException {
        if(!value.equals(ArbiterCliGenerator.REGRESSION) || value.equals(ArbiterCliGenerator.CLASSIFICIATION)) {
            throw new ParameterException(""Problem type can only be "" + ArbiterCliGenerator.REGRESSION + "" or "" + ArbiterCliGenerator.CLASSIFICIATION);

        }
    }"
"@Override
  protected void serviceStop() {
    try {
      if (shuffleServer != null) {
        shuffleServer.close();
      }
      if (transportContext != null) {
        transportContext.close();
      }
      if (blockHandler != null) {
        blockHandler.close();
      }
      if (db != null) {
        db.close();
      }
    } catch (Exception e) {
      logger.error(""Exception when stopping service"", e);
    }
  }"
"public static double precision(long tpCount, long fpCount, double edgeCase) {
        //Edge case
        if (tpCount == 0 && fpCount == 0) {
            return edgeCase;
        }

        return tpCount / (double) (tpCount + fpCount);
    }"
"public void startRegistrationProcess() {
    // don't advertise that the remote (node) is bound to all IPv4 interfaces (default behavior)
    if (registrationRequest.getConfiguration().host.equals(""0.0.0.0"")) {
      // remove the value and call fixUpHost to determine the address of a public (non-loopback) IPv4 interface
      registrationRequest.getConfiguration().host = null;
      registrationRequest.getConfiguration().fixUpHost();
    }
    fixUpId();
    LOG.fine(""Using the json request : "" + new Json().toJson(registrationRequest));

    Boolean register = registrationRequest.getConfiguration().register;
    if (register == null) {
      register = false;
    }

    if (!register) {
      LOG.info(""No registration sent ( register = false )"");
    } else {
      final int
          registerCycleInterval =
          registrationRequest.getConfiguration().registerCycle != null ?
          registrationRequest.getConfiguration().registerCycle : 0;
      if (registerCycleInterval > 0) {
        new Thread(new Runnable() { // Thread safety reviewed

          @Override
          public void run() {
            boolean first = true;
            LOG.info(""Starting auto registration thread. Will try to register every ""
                     + registerCycleInterval + "" ms."");
            while (true) {
              try {
                boolean checkForPresence = true;
                if (first) {
                  first = false;
                  checkForPresence = false;
                }
                registerToHub(checkForPresence);
              } catch (GridException e) {
                LOG.info(""Couldn't register this node: "" + e.getMessage());
              }
              try {
                Thread.sleep(registerCycleInterval);
              } catch (InterruptedException e) {
                e.printStackTrace();
              }
              // While we wait for someone to rewrite server logging.
              LoggingManager.perSessionLogHandler().clearThreadTempLogs();
            }
          }
        }).start();
      } else {
        registerToHub(false);
      }
    }
    LoggingManager.perSessionLogHandler().clearThreadTempLogs();
  }"
"public final LogBuffer duplicate() {
        // XXX: Do momery copy avoid buffer modified.
        byte[] buf = Arrays.copyOfRange(buffer, origin, origin + limit);
        return new LogBuffer(buf, 0, limit);
    }"
"@VisibleForTesting
  final Metadata updateHeaders(
      Metadata originalHeaders, int previousAttemptCount) {
    Metadata newHeaders = new Metadata();
    newHeaders.merge(originalHeaders);
    if (previousAttemptCount > 0) {
      newHeaders.put(GRPC_PREVIOUS_RPC_ATTEMPTS, String.valueOf(previousAttemptCount));
    }
    return newHeaders;
  }"
"protected String getStringMethodParam(String methodName, String paramKey, String defaultValue) {
        if (CommonUtils.isEmpty(configContext)) {
            return defaultValue;
        }
        String o = (String) configContext.get(buildMethodKey(methodName, paramKey));
        if (o == null) {
            o = (String) configContext.get(paramKey);
            return o == null ? defaultValue : o;
        } else {
            return o;
        }
    }"
"public static RestartStrategyFactory createRestartStrategyFactory(Configuration configuration) throws Exception {
		String restartStrategyName = configuration.getString(ConfigConstants.RESTART_STRATEGY, null);

		if (restartStrategyName == null) {
			// support deprecated ConfigConstants values
			final int numberExecutionRetries = configuration.getInteger(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_ATTEMPTS,
				ConfigConstants.DEFAULT_EXECUTION_RETRIES);
			String pauseString = configuration.getString(AkkaOptions.WATCH_HEARTBEAT_PAUSE);
			String delayString = configuration.getString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY,
				pauseString);

			long delay;

			try {
				delay = Duration.apply(delayString).toMillis();
			} catch (NumberFormatException nfe) {
				if (delayString.equals(pauseString)) {
					throw new Exception(""Invalid config value for "" +
						AkkaOptions.WATCH_HEARTBEAT_PAUSE.key() + "": "" + pauseString +
						"". Value must be a valid duration (such as '10 s' or '1 min')"");
				} else {
					throw new Exception(""Invalid config value for "" +
						ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY + "": "" + delayString +
						"". Value must be a valid duration (such as '100 milli' or '10 s')"");
				}
			}

			if (numberExecutionRetries > 0 && delay >= 0) {
				return new FixedDelayRestartStrategy.FixedDelayRestartStrategyFactory(numberExecutionRetries, delay);
			} else {
				return new NoOrFixedIfCheckpointingEnabledRestartStrategyFactory();
			}
		}

		switch (restartStrategyName.toLowerCase()) {
			case ""none"":
			case ""off"":
			case ""disable"":
				return NoRestartStrategy.createFactory(configuration);
			case ""fixeddelay"":
			case ""fixed-delay"":
				return FixedDelayRestartStrategy.createFactory(configuration);
			case ""failurerate"":
			case ""failure-rate"":
				return FailureRateRestartStrategy.createFactory(configuration);
			default:
				try {
					Class<?> clazz = Class.forName(restartStrategyName);

					if (clazz != null) {
						Method method = clazz.getMethod(CREATE_METHOD, Configuration.class);

						if (method != null) {
							Object result = method.invoke(null, configuration);

							if (result != null) {
								return (RestartStrategyFactory) result;
							}
						}
					}
				} catch (ClassNotFoundException cnfe) {
					LOG.warn(""Could not find restart strategy class {}."", restartStrategyName);
				} catch (NoSuchMethodException nsme) {
					LOG.warn(""Class {} does not has static method {}."", restartStrategyName, CREATE_METHOD);
				} catch (InvocationTargetException ite) {
					LOG.warn(""Cannot call static method {} from class {}."", CREATE_METHOD, restartStrategyName);
				} catch (IllegalAccessException iae) {
					LOG.warn(""Illegal access while calling method {} from class {}."", CREATE_METHOD, restartStrategyName);
				}

				// fallback in case of an error
				return new NoOrFixedIfCheckpointingEnabledRestartStrategyFactory();
		}
	}"
"public static <E> Page<E> startPage(int pageNum, int pageSize, String orderBy) {
        Page<E> page = startPage(pageNum, pageSize);
        page.setOrderBy(orderBy);
        return page;
    }"
"public final void updateObjectInUse(T object, boolean inUse) {
    int origSize = inUseObjects.size();
    if (inUse) {
      inUseObjects.add(object);
      if (origSize == 0) {
        handleInUse();
      }
    } else {
      boolean removed = inUseObjects.remove(object);
      if (removed && origSize == 1) {
        handleNotInUse();
      }
    }
  }"
"void get_features(final State s,
                      final List<Integer> cluster4,
                      final List<Integer> cluster6,
                      final List<Integer> cluster,
                      List<Integer> features)
    {
        Context ctx = new Context();
        get_context(s, ctx);
        get_basic_features(ctx, s.ref.forms, s.ref.postags, s.deprels, features);
        get_distance_features(ctx, features);
        get_valency_features(ctx, s.nr_left_children, s.nr_right_children, features);
        get_cluster_features(ctx, cluster4, cluster6, cluster, features);
    }"
"private int fetch(Node parent, List<Node> siblings)
    {
        if (error_ < 0)
            return 0;

        int prev = 0;

        for (int i = parent.left; i < parent.right; i++)
        {
            if ((length != null ? length[i] : key.get(i).length()) < parent.depth)
                continue;

            String tmp = key.get(i);

            int cur = 0;
            if ((length != null ? length[i] : tmp.length()) != parent.depth)
                cur = (int) tmp.charAt(parent.depth) + 1;

            if (prev > cur)
            {
                error_ = -3;
                return 0;
            }

            if (cur != prev || siblings.size() == 0)
            {
                Node tmp_node = new Node();
                tmp_node.depth = parent.depth + 1;
                tmp_node.code = cur;
                tmp_node.left = i;
                if (siblings.size() != 0)
                    siblings.get(siblings.size() - 1).right = i;

                siblings.add(tmp_node);
            }

            prev = cur;
        }

        if (siblings.size() != 0)
            siblings.get(siblings.size() - 1).right = parent.right;

        return siblings.size();
    }"
"private <T> WatermarkGaugeExposingOutput<StreamRecord<T>> createOutputCollector(
			StreamTask<?, ?> containingTask,
			StreamConfig operatorConfig,
			Map<Integer, StreamConfig> chainedConfigs,
			ClassLoader userCodeClassloader,
			Map<StreamEdge, RecordWriterOutput<?>> streamOutputs,
			List<StreamOperator<?>> allOperators) {
		List<Tuple2<WatermarkGaugeExposingOutput<StreamRecord<T>>, StreamEdge>> allOutputs = new ArrayList<>(4);

		// create collectors for the network outputs
		for (StreamEdge outputEdge : operatorConfig.getNonChainedOutputs(userCodeClassloader)) {
			@SuppressWarnings(""unchecked"")
			RecordWriterOutput<T> output = (RecordWriterOutput<T>) streamOutputs.get(outputEdge);

			allOutputs.add(new Tuple2<>(output, outputEdge));
		}

		// Create collectors for the chained outputs
		for (StreamEdge outputEdge : operatorConfig.getChainedOutputs(userCodeClassloader)) {
			int outputId = outputEdge.getTargetId();
			StreamConfig chainedOpConfig = chainedConfigs.get(outputId);

			WatermarkGaugeExposingOutput<StreamRecord<T>> output = createChainedOperator(
				containingTask,
				chainedOpConfig,
				chainedConfigs,
				userCodeClassloader,
				streamOutputs,
				allOperators,
				outputEdge.getOutputTag());
			allOutputs.add(new Tuple2<>(output, outputEdge));
		}

		// if there are multiple outputs, or the outputs are directed, we need to
		// wrap them as one output

		List<OutputSelector<T>> selectors = operatorConfig.getOutputSelectors(userCodeClassloader);

		if (selectors == null || selectors.isEmpty()) {
			// simple path, no selector necessary
			if (allOutputs.size() == 1) {
				return allOutputs.get(0).f0;
			}
			else {
				// send to N outputs. Note that this includes the special case
				// of sending to zero outputs
				@SuppressWarnings({""unchecked"", ""rawtypes""})
				Output<StreamRecord<T>>[] asArray = new Output[allOutputs.size()];
				for (int i = 0; i < allOutputs.size(); i++) {
					asArray[i] = allOutputs.get(i).f0;
				}

				// This is the inverse of creating the normal ChainingOutput.
				// If the chaining output does not copy we need to copy in the broadcast output,
				// otherwise multi-chaining would not work correctly.
				if (containingTask.getExecutionConfig().isObjectReuseEnabled()) {
					return new CopyingBroadcastingOutputCollector<>(asArray, this);
				} else  {
					return new BroadcastingOutputCollector<>(asArray, this);
				}
			}
		}
		else {
			// selector present, more complex routing necessary

			// This is the inverse of creating the normal ChainingOutput.
			// If the chaining output does not copy we need to copy in the broadcast output,
			// otherwise multi-chaining would not work correctly.
			if (containingTask.getExecutionConfig().isObjectReuseEnabled()) {
				return new CopyingDirectedOutput<>(selectors, allOutputs);
			} else {
				return new DirectedOutput<>(selectors, allOutputs);
			}

		}
	}"
"@Override
  public void readIntegers(int total, WritableColumnVector c, int rowId) {
    int left = total;
    while (left > 0) {
      if (this.currentCount == 0) this.readNextGroup();
      int n = Math.min(left, this.currentCount);
      switch (mode) {
        case RLE:
          c.putInts(rowId, n, currentValue);
          break;
        case PACKED:
          c.putInts(rowId, n, currentBuffer, currentBufferIdx);
          currentBufferIdx += n;
          break;
      }
      rowId += n;
      left -= n;
      currentCount -= n;
    }
  }"
"private void loadAllAndReplaceExisting(Set<? extends K> keys) {
    int[] ignored = { 0 };
    Map<K, V> loaded = cacheLoader.get().loadAll(keys);
    for (Map.Entry<? extends K, ? extends V> entry : loaded.entrySet()) {
      putNoCopyOrAwait(entry.getKey(), entry.getValue(), /* publishToWriter */ false, ignored);
    }
  }"
"@GetMapping(path = ""/instances/{id}"", produces = MediaType.APPLICATION_JSON_VALUE)
    public Mono<ResponseEntity<Instance>> instance(@PathVariable String id) {
        LOGGER.debug(""Deliver registered instance with ID '{}'"", id);
        return registry.getInstance(InstanceId.of(id))
                       .filter(Instance::isRegistered)
                       .map(ResponseEntity::ok)
                       .defaultIfEmpty(ResponseEntity.notFound().build());
    }"
"public void cleanExpiredCallbacks() {
        long now = System.currentTimeMillis();
        
        // Cuncurrency could be possible for multiple instantiations
        synchronized(regCallbacks) {    
            Iterator<Map.Entry<String, RegisteredCallback>> it = regCallbacks.entrySet().iterator();
            Map.Entry<String, RegisteredCallback> entry;
            
            while (it.hasNext()) {
                entry = it.next();
                if (now - entry.getValue().getTimestamp() > CALLBACK_EXPIRE_TIME) {
                    it.remove();
                }
            }
        }
    }"
"public static INDArray reshapeTimeSeriesMaskToVector(INDArray timeSeriesMask) {
        if (timeSeriesMask.rank() != 2)
            throw new IllegalArgumentException(""Cannot reshape mask: rank is not 2"");

        if (timeSeriesMask.ordering() != 'f')
            timeSeriesMask = timeSeriesMask.dup('f');

        return timeSeriesMask.reshape('f', timeSeriesMask.length(), 1);
    }"
"private Observable<R> getFallbackOrThrowException(final AbstractCommand<R> _cmd, final HystrixEventType eventType, final FailureType failureType, final String message, final Exception originalException) {
        final HystrixRequestContext requestContext = HystrixRequestContext.getContextForCurrentThread();
        long latency = System.currentTimeMillis() - executionResult.getStartTimestamp();
        // record the executionResult
        // do this before executing fallback so it can be queried from within getFallback (see See https://github.com/Netflix/Hystrix/pull/144)
        executionResult = executionResult.addEvent((int) latency, eventType);

        if (isUnrecoverable(originalException)) {
            logger.error(""Unrecoverable Error for HystrixCommand so will throw HystrixRuntimeException and not apply fallback. "", originalException);

            /* executionHook for all errors */
            Exception e = wrapWithOnErrorHook(failureType, originalException);
            return Observable.error(new HystrixRuntimeException(failureType, this.getClass(), getLogMessagePrefix() + "" "" + message + "" and encountered unrecoverable error."", e, null));
        } else {
            if (isRecoverableError(originalException)) {
                logger.warn(""Recovered from java.lang.Error by serving Hystrix fallback"", originalException);
            }

            if (properties.fallbackEnabled().get()) {
                /* fallback behavior is permitted so attempt */

                final Action1<Notification<? super R>> setRequestContext = new Action1<Notification<? super R>>() {
                    @Override
                    public void call(Notification<? super R> rNotification) {
                        setRequestContextIfNeeded(requestContext);
                    }
                };

                final Action1<R> markFallbackEmit = new Action1<R>() {
                    @Override
                    public void call(R r) {
                        if (shouldOutputOnNextEvents()) {
                            executionResult = executionResult.addEvent(HystrixEventType.FALLBACK_EMIT);
                            eventNotifier.markEvent(HystrixEventType.FALLBACK_EMIT, commandKey);
                        }
                    }
                };

                final Action0 markFallbackCompleted = new Action0() {
                    @Override
                    public void call() {
                        long latency = System.currentTimeMillis() - executionResult.getStartTimestamp();
                        eventNotifier.markEvent(HystrixEventType.FALLBACK_SUCCESS, commandKey);
                        executionResult = executionResult.addEvent((int) latency, HystrixEventType.FALLBACK_SUCCESS);
                    }
                };

                final Func1<Throwable, Observable<R>> handleFallbackError = new Func1<Throwable, Observable<R>>() {
                    @Override
                    public Observable<R> call(Throwable t) {
                        /* executionHook for all errors */
                        Exception e = wrapWithOnErrorHook(failureType, originalException);
                        Exception fe = getExceptionFromThrowable(t);

                        long latency = System.currentTimeMillis() - executionResult.getStartTimestamp();
                        Exception toEmit;

                        if (fe instanceof UnsupportedOperationException) {
                            logger.debug(""No fallback for HystrixCommand. "", fe); // debug only since we're throwing the exception and someone higher will do something with it
                            eventNotifier.markEvent(HystrixEventType.FALLBACK_MISSING, commandKey);
                            executionResult = executionResult.addEvent((int) latency, HystrixEventType.FALLBACK_MISSING);

                            toEmit = new HystrixRuntimeException(failureType, _cmd.getClass(), getLogMessagePrefix() + "" "" + message + "" and no fallback available."", e, fe);
                        } else {
                            logger.debug(""HystrixCommand execution "" + failureType.name() + "" and fallback failed."", fe);
                            eventNotifier.markEvent(HystrixEventType.FALLBACK_FAILURE, commandKey);
                            executionResult = executionResult.addEvent((int) latency, HystrixEventType.FALLBACK_FAILURE);

                            toEmit = new HystrixRuntimeException(failureType, _cmd.getClass(), getLogMessagePrefix() + "" "" + message + "" and fallback failed."", e, fe);
                        }

                        // NOTE: we're suppressing fallback exception here
                        if (shouldNotBeWrapped(originalException)) {
                            return Observable.error(e);
                        }

                        return Observable.error(toEmit);
                    }
                };

                final TryableSemaphore fallbackSemaphore = getFallbackSemaphore();
                final AtomicBoolean semaphoreHasBeenReleased = new AtomicBoolean(false);
                final Action0 singleSemaphoreRelease = new Action0() {
                    @Override
                    public void call() {
                        if (semaphoreHasBeenReleased.compareAndSet(false, true)) {
                            fallbackSemaphore.release();
                        }
                    }
                };

                Observable<R> fallbackExecutionChain;

                // acquire a permit
                if (fallbackSemaphore.tryAcquire()) {
                    try {
                        if (isFallbackUserDefined()) {
                            executionHook.onFallbackStart(this);
                            fallbackExecutionChain = getFallbackObservable();
                        } else {
                            //same logic as above without the hook invocation
                            fallbackExecutionChain = getFallbackObservable();
                        }
                    } catch (Throwable ex) {
                        //If hook or user-fallback throws, then use that as the result of the fallback lookup
                        fallbackExecutionChain = Observable.error(ex);
                    }

                    return fallbackExecutionChain
                            .doOnEach(setRequestContext)
                            .lift(new FallbackHookApplication(_cmd))
                            .lift(new DeprecatedOnFallbackHookApplication(_cmd))
                            .doOnNext(markFallbackEmit)
                            .doOnCompleted(markFallbackCompleted)
                            .onErrorResumeNext(handleFallbackError)
                            .doOnTerminate(singleSemaphoreRelease)
                            .doOnUnsubscribe(singleSemaphoreRelease);
                } else {
                   return handleFallbackRejectionByEmittingError();
                }
            } else {
                return handleFallbackDisabledByEmittingError(originalException, failureType, message);
            }
        }
    }"
"public static void touch(File file) throws IOException {
		com.google.common.io.Files.touch(file);
	}"
"@SuppressWarnings(""unchecked"")
    private RequestCollapser<BatchReturnType, ResponseType, RequestArgumentType> getCollapserForUserRequest(HystrixCollapserBridge<BatchReturnType, ResponseType, RequestArgumentType> commandCollapser) {
        return (RequestCollapser<BatchReturnType, ResponseType, RequestArgumentType>) getRequestVariableForCommand(commandCollapser).get(concurrencyStrategy);
    }"
"@SuppressWarnings(""unchecked"")
	public <T extends Value> T getField(final int fieldNum, final Class<T> type) {
		// range check
		if (fieldNum < 0 || fieldNum >= this.numFields) {
			throw new IndexOutOfBoundsException(fieldNum + "" for range [0.."" + (this.numFields - 1) + ""]"");
		}
		
		// get offset and check for null
		final int offset = this.offsets[fieldNum];
		if (offset == NULL_INDICATOR_OFFSET) {
			return null;
		}		
		else if (offset == MODIFIED_INDICATOR_OFFSET) {
			// value that has been set is new or modified
			return (T) this.writeFields[fieldNum];
		}
		
		final int limit = offset + this.lengths[fieldNum];
		
		// get an instance, either from the instance cache or create a new one
		final Value oldField = this.readFields[fieldNum]; 
		final T field;
		if (oldField != null && oldField.getClass() == type) {
			field = (T) oldField;
		}
		else {
			field = InstantiationUtil.instantiate(type, Value.class);
			this.readFields[fieldNum] = field;
		}
		
		// deserialize
		deserialize(field, offset, limit, fieldNum);
		return field;
	}"
"public static ExecutorService getExecutor(final boolean isOccupyThreadForPerConnection, final TransactionType transactionType, final ChannelId channelId) {
        return (isOccupyThreadForPerConnection || TransactionType.XA == transactionType || TransactionType.BASE == transactionType)
            ? ChannelThreadExecutorGroup.getInstance().get(channelId) : UserExecutorGroup.getInstance().getExecutorService();
    }"
"public static void logMesosConfig(Logger log, MesosConfiguration config) {

		Map<String, String> env = System.getenv();
		Protos.FrameworkInfo.Builder info = config.frameworkInfo();

		log.info(""--------------------------------------------------------------------------------"");
		log.info("" Mesos Info:"");
		log.info(""    Master URL: {}"", config.masterUrl());

		log.info("" Framework Info:"");
		log.info(""    ID: {}"", info.hasId() ? info.getId().getValue() : ""(none)"");
		log.info(""    Name: {}"", info.hasName() ? info.getName() : ""(none)"");
		log.info(""    Failover Timeout (secs): {}"", info.getFailoverTimeout());
		log.info(""    Role: {}"", info.hasRole() ? info.getRole() : ""(none)"");
		log.info(""    Capabilities: {}"",
			info.getCapabilitiesList().size() > 0 ? info.getCapabilitiesList() : ""(none)"");
		log.info(""    Principal: {}"", info.hasPrincipal() ? info.getPrincipal() : ""(none)"");
		log.info(""    Host: {}"", info.hasHostname() ? info.getHostname() : ""(none)"");
		if (env.containsKey(""LIBPROCESS_IP"")) {
			log.info(""    LIBPROCESS_IP: {}"", env.get(""LIBPROCESS_IP""));
		}
		if (env.containsKey(""LIBPROCESS_PORT"")) {
			log.info(""    LIBPROCESS_PORT: {}"", env.get(""LIBPROCESS_PORT""));
		}
		log.info(""    Web UI: {}"", info.hasWebuiUrl() ? info.getWebuiUrl() : ""(none)"");

		log.info(""--------------------------------------------------------------------------------"");

	}"
"public static int getAvailablePort(String host, int port, int maxPort) {
        if (isAnyHost(host)
            || isLocalHost(host)
            || isHostInNetworkCard(host)) {
            if (port < MIN_PORT) {
                port = MIN_PORT;
            }
            for (int i = port; i <= maxPort; i++) {
                ServerSocket ss = null;
                try {
                    ss = new ServerSocket();
                    ss.bind(new InetSocketAddress(host, i));
                    if (LOGGER.isDebugEnabled()) {
                        LOGGER.debug(""ip:{} port:{} is available"", host, i);
                    }
                    return i;
                } catch (IOException e) {
                    // continue
                    if (LOGGER.isWarnEnabled()) {
                        LOGGER.warn(""Can't bind to address [{}:{}], "" +
                            ""Maybe 1) The port has been bound. "" +
                            ""2) The network card of this host is not exists or disable. "" +
                            ""3) The host is wrong."", host, i);
                    }
                    if (LOGGER.isInfoEnabled()) {
                        LOGGER.info(""Begin try next port(auto +1):{}"", i + 1);
                    }
                } finally {
                    IOUtils.closeQuietly(ss);
                }
            }
            throw new SofaRpcRuntimeException(""Can't bind to ANY port of "" + host + "", please check config"");
        } else {
            throw new SofaRpcRuntimeException(""The host "" + host
                + "" is not found in network cards, please check config"");
        }
    }"
"private ApiResponse buildResponseFromContext(Context c) {
		Map<String, String> fields = new HashMap<>();
		fields.put(""name"", c.getName());
		fields.put(""id"", Integer.toString(c.getIndex()));
		fields.put(""description"", c.getDescription());
		fields.put(""inScope"", Boolean.toString(c.isInScope()));
		fields.put(""excludeRegexs"", jsonEncodeList(c.getExcludeFromContextRegexs()));
		fields.put(""includeRegexs"", jsonEncodeList(c.getIncludeInContextRegexs()));
		
		AuthenticationMethod authenticationMethod = c.getAuthenticationMethod();
		if(authenticationMethod != null){
			Pattern pattern = authenticationMethod.getLoggedInIndicatorPattern();
			fields.put(""loggedInPattern"",  pattern == null ? """" : pattern.toString());
			pattern = authenticationMethod.getLoggedOutIndicatorPattern();
			fields.put(""loggedOutPattern"", pattern == null ? """" : pattern.toString());
			AuthenticationMethodType type = authenticationMethod.getType();
			fields.put(""authType"", type == null ? """" : type.getName());
		}
		
		AuthorizationDetectionMethod authorizationDetectionMethod = c.getAuthorizationDetectionMethod();
		if(authorizationDetectionMethod != null){
			fields.put(""authenticationDetectionMethodId"",String.valueOf(authorizationDetectionMethod.getMethodUniqueIdentifier()));
		}
		
		fields.put(""urlParameterParserClass"", c.getUrlParamParser().getClass().getCanonicalName());
		fields.put(""urlParameterParserConfig"", c.getUrlParamParser().getConfig());
		fields.put(""postParameterParserClass"", c.getPostParamParser().getClass().getCanonicalName());
		fields.put(""postParameterParserConfig"", c.getPostParamParser().getConfig());
		
		return new ApiResponseSet<String>(""context"", fields);
	}"
"public <OUT> DataStreamSource<OUT> fromCollection(Collection<OUT> data) {
		Preconditions.checkNotNull(data, ""Collection must not be null"");
		if (data.isEmpty()) {
			throw new IllegalArgumentException(""Collection must not be empty"");
		}

		OUT first = data.iterator().next();
		if (first == null) {
			throw new IllegalArgumentException(""Collection must not contain null elements"");
		}

		TypeInformation<OUT> typeInfo;
		try {
			typeInfo = TypeExtractor.getForObject(first);
		}
		catch (Exception e) {
			throw new RuntimeException(""Could not create TypeInformation for type "" + first.getClass()
					+ ""; please specify the TypeInformation manually via ""
					+ ""StreamExecutionEnvironment#fromElements(Collection, TypeInformation)"", e);
		}
		return fromCollection(data, typeInfo);
	}"
"public static INDArray pow(INDArray ndArray, INDArray power, boolean dup) {
        INDArray result = (dup ? ndArray.ulike() : ndArray);
        return exec(new PowPairwise(ndArray, power, result));
    }"
"private void doAppendLine(final String... fields) throws IOException {
		if (null != fields) {
			for (int i = 0; i < fields.length; i++) {
				appendField(fields[i]);
			}
			writer.write(config.lineDelimiter);
			newline = true;
		}
	}"
"@Override
	public void registerTableSink(String name) {
		Preconditions.checkNotNull(name);
		TableSink<?> tableSink = TableFactoryUtil.findAndCreateTableSink(this);
		tableEnv.registerTableSink(name, tableSink);
	}"
"boolean writeOneFrame() throws IOException {
    WebSocketWriter writer;
    ByteString pong;
    Object messageOrClose = null;
    int receivedCloseCode = -1;
    String receivedCloseReason = null;
    Streams streamsToClose = null;

    synchronized (RealWebSocket.this) {
      if (failed) {
        return false; // Failed web socket.
      }

      writer = this.writer;
      pong = pongQueue.poll();
      if (pong == null) {
        messageOrClose = messageAndCloseQueue.poll();
        if (messageOrClose instanceof Close) {
          receivedCloseCode = this.receivedCloseCode;
          receivedCloseReason = this.receivedCloseReason;
          if (receivedCloseCode != -1) {
            streamsToClose = this.streams;
            this.streams = null;
            this.executor.shutdown();
          } else {
            // When we request a graceful close also schedule a cancel of the websocket.
            cancelFuture = executor.schedule(new CancelRunnable(),
                ((Close) messageOrClose).cancelAfterCloseMillis, MILLISECONDS);
          }
        } else if (messageOrClose == null) {
          return false; // The queue is exhausted.
        }
      }
    }

    try {
      if (pong != null) {
        writer.writePong(pong);

      } else if (messageOrClose instanceof Message) {
        ByteString data = ((Message) messageOrClose).data;
        BufferedSink sink = Okio.buffer(writer.newMessageSink(
            ((Message) messageOrClose).formatOpcode, data.size()));
        sink.write(data);
        sink.close();
        synchronized (this) {
          queueSize -= data.size();
        }

      } else if (messageOrClose instanceof Close) {
        Close close = (Close) messageOrClose;
        writer.writeClose(close.code, close.reason);

        // We closed the writer: now both reader and writer are closed.
        if (streamsToClose != null) {
          listener.onClosed(this, receivedCloseCode, receivedCloseReason);
        }

      } else {
        throw new AssertionError();
      }

      return true;
    } finally {
      closeQuietly(streamsToClose);
    }
  }"
"public SDVariable norm1(String name, boolean keepDims, int... dimensions) {
        return sameDiff.norm1(name, this, keepDims, dimensions);
    }"
"public SDVariable normalTruncated(String name, double mean, double stddev, long... shape) {
        SDVariable ret = f().randomNormalTruncated(mean, stddev, shape);
        return updateVariableNameAndReference(ret, name);
    }"
"@Restricted(DoNotUse.class)
    public Categories doItemCategories(StaplerRequest req, StaplerResponse rsp, @QueryParameter String iconStyle) throws IOException, ServletException {
        getOwner().checkPermission(Item.CREATE);

        rsp.addHeader(""Cache-Control"", ""no-cache, no-store, must-revalidate"");
        rsp.addHeader(""Pragma"", ""no-cache"");
        rsp.addHeader(""Expires"", ""0"");
        Categories categories = new Categories();
        int order = 0;
        JellyContext ctx;

        if (StringUtils.isNotBlank(iconStyle)) {
            ctx = new JellyContext();
            ctx.setVariable(""resURL"", req.getContextPath() + Jenkins.RESOURCE_PATH);
        } else {
            ctx = null;
        }
        for (TopLevelItemDescriptor descriptor : DescriptorVisibilityFilter.apply(getOwner().getItemGroup(), Items.all(Jenkins.getAuthentication(), getOwner().getItemGroup()))) {
            ItemCategory ic = ItemCategory.getCategory(descriptor);
            Map<String, Serializable> metadata = new HashMap<>();

            // Information about Item.
            metadata.put(""class"", descriptor.getId());
            metadata.put(""order"", ++order);
            metadata.put(""displayName"", descriptor.getDisplayName());
            metadata.put(""description"", descriptor.getDescription());
            metadata.put(""iconFilePathPattern"", descriptor.getIconFilePathPattern());
            String iconClassName = descriptor.getIconClassName();
            if (StringUtils.isNotBlank(iconClassName)) {
                metadata.put(""iconClassName"", iconClassName);
                if (ctx != null) {
                    Icon icon = IconSet.icons
                            .getIconByClassSpec(StringUtils.join(new String[]{iconClassName, iconStyle}, "" ""));
                    if (icon != null) {
                        metadata.put(""iconQualifiedUrl"", icon.getQualifiedUrl(ctx));
                    }
                }
            }

            Category category = categories.getItem(ic.getId());
            if (category != null) {
                category.getItems().add(metadata);
            } else {
                List<Map<String, Serializable>> temp = new ArrayList<>();
                temp.add(metadata);
                category = new Category(ic.getId(), ic.getDisplayName(), ic.getDescription(), ic.getOrder(), ic.getMinToShow(), temp);
                categories.getItems().add(category);
            }
        }
        return categories;
    }"
"public void jarDir(File dirOrFile2Jar, File destJar)
		throws IOException {

		if (dirOrFile2Jar == null || destJar == null) {
			throw new IllegalArgumentException();
		}

		mDestJarName = destJar.getCanonicalPath();
		FileOutputStream fout = new FileOutputStream(destJar);
		JarOutputStream jout = new JarOutputStream(fout);
		//jout.setLevel(0);
		try {
			jarDir(dirOrFile2Jar, jout, null);
		} catch (IOException ioe) {
			throw ioe;
		} finally {
			jout.close();
			fout.close();
		}
	}"
"public byte[] getBytes(int rowId, int count) {
    byte[] res = new byte[count];
    for (int i = 0; i < count; i++) {
      res[i] = getByte(rowId + i);
    }
    return res;
  }"
"public static Document readXML(String pathOrContent) {
		if (StrUtil.startWith(pathOrContent, '<')) {
			return parseXml(pathOrContent);
		}
		return readXML(FileUtil.file(pathOrContent));
	}"
"public static HttpConnection create(String urlStr, Proxy proxy) {
		return create(URLUtil.toUrlForHttp(urlStr), proxy);
	}"
"private void parseBody() {
        if (currentStatus == MultiPartStatus.PREEPILOGUE || currentStatus == MultiPartStatus.EPILOGUE) {
            if (isLastChunk) {
                currentStatus = MultiPartStatus.EPILOGUE;
            }
            return;
        }
        parseBodyMultipart();
    }"
"public static Dialect getDialect(DataSource ds) {
		Dialect dialect = dialectPool.get(ds);
		if(null == dialect) {
			synchronized (lock) {
				dialect = dialectPool.get(ds);
				if(null == dialect) {
					dialect = newDialect(ds);
					dialectPool.put(ds, dialect);
				}
			}
		}
		return dialect;
	}"
"public HttpConnection setHttpsInfo(HostnameVerifier hostnameVerifier, SSLSocketFactory ssf) throws HttpException {
		final HttpURLConnection conn = this.conn;

		if (conn instanceof HttpsURLConnection) {
			// Https请求
			final HttpsURLConnection httpsConn = (HttpsURLConnection) conn;
			// 验证域
			httpsConn.setHostnameVerifier(null != hostnameVerifier ? hostnameVerifier : new TrustAnyHostnameVerifier());
			if (null == ssf) {
				try {
					if (StrUtil.equalsIgnoreCase(""dalvik"", System.getProperty(""java.vm.name""))) {
						// 兼容android低版本SSL连接
						ssf = new AndroidSupportSSLFactory();
					} else {
						ssf = SSLSocketFactoryBuilder.create().build();
					}
				} catch (KeyManagementException | NoSuchAlgorithmException e) {
					throw new HttpException(e);
				}
			}
			httpsConn.setSSLSocketFactory(ssf);
		}

		return this;
	}"
"@Override public void init(boolean expensive) {
    super.init(expensive); //drop constant and ignored columns
    _parms.validate(this, expensive);
    if (expensive && error_count() == 0) checkMemoryFootPrint();
  }"
"public void allocateSegments(int numberOfSegments) {
		while (getBlockCount() < numberOfSegments) {
			MemorySegment next = this.availableMemory.nextSegment();
			if (next != null) {
				this.partitionPages.add(next);
			} else {
				return;
			}
		}
	}"
"public static CharSequence escapeCsv(CharSequence value, boolean trimWhiteSpace) {
        int length = checkNotNull(value, ""value"").length();
        int start;
        int last;
        if (trimWhiteSpace) {
            start = indexOfFirstNonOwsChar(value, length);
            last = indexOfLastNonOwsChar(value, start, length);
        } else {
            start = 0;
            last = length - 1;
        }
        if (start > last) {
            return EMPTY_STRING;
        }

        int firstUnescapedSpecial = -1;
        boolean quoted = false;
        if (isDoubleQuote(value.charAt(start))) {
            quoted = isDoubleQuote(value.charAt(last)) && last > start;
            if (quoted) {
                start++;
                last--;
            } else {
                firstUnescapedSpecial = start;
            }
        }

        if (firstUnescapedSpecial < 0) {
            if (quoted) {
                for (int i = start; i <= last; i++) {
                    if (isDoubleQuote(value.charAt(i))) {
                        if (i == last || !isDoubleQuote(value.charAt(i + 1))) {
                            firstUnescapedSpecial = i;
                            break;
                        }
                        i++;
                    }
                }
            } else {
                for (int i = start; i <= last; i++) {
                    char c = value.charAt(i);
                    if (c == LINE_FEED || c == CARRIAGE_RETURN || c == COMMA) {
                        firstUnescapedSpecial = i;
                        break;
                    }
                    if (isDoubleQuote(c)) {
                        if (i == last || !isDoubleQuote(value.charAt(i + 1))) {
                            firstUnescapedSpecial = i;
                            break;
                        }
                        i++;
                    }
                }
            }

            if (firstUnescapedSpecial < 0) {
                // Special characters is not found or all of them already escaped.
                // In the most cases returns a same string. New string will be instantiated (via StringBuilder)
                // only if it really needed. It's important to prevent GC extra load.
                return quoted? value.subSequence(start - 1, last + 2) : value.subSequence(start, last + 1);
            }
        }

        StringBuilder result = new StringBuilder(last - start + 1 + CSV_NUMBER_ESCAPE_CHARACTERS);
        result.append(DOUBLE_QUOTE).append(value, start, firstUnescapedSpecial);
        for (int i = firstUnescapedSpecial; i <= last; i++) {
            char c = value.charAt(i);
            if (isDoubleQuote(c)) {
                result.append(DOUBLE_QUOTE);
                if (i < last && isDoubleQuote(value.charAt(i + 1))) {
                    i++;
                }
            }
            result.append(c);
        }
        return result.append(DOUBLE_QUOTE);
    }"
"@Override
    public void revertLabels(@NonNull INDArray[] labels, INDArray[] maskArrays) {
        for (int i = 0; i < labels.length; i++) {
            revertLabels(labels, maskArrays, i);
        }
    }"
"public ZipkinRule storeSpans(List<Span> spans) {
    try {
      storage.accept(spans).execute();
    } catch (IOException e) {
      throw Platform.get().uncheckedIOException(e);
    }
    return this;
  }"
"public static boolean areTypesCompatible(Class[] typeArguments, List<Class> classToCompare) {
        if (classToCompare.size() == 0) {
            // in this case the type doesn't specify type arguments, so this is the equivalent of using Object
            return true;
        } else {
            if (classToCompare.size() != typeArguments.length) {
                return false;
            } else {
                for (int i = 0; i < classToCompare.size(); i++) {
                    Class left = classToCompare.get(i);
                    Class right = typeArguments[i];
                    if (right == Object.class) {
                        continue;
                    }
                    if (left != right && !left.isAssignableFrom(right)) {
                        return false;
                    }
                }
            }
        }
        return true;
    }"
"private static InetAddress tryLocalHostBeforeReturning(
				InetAddress preliminaryResult, SocketAddress targetAddress, boolean logging) throws IOException {

		InetAddress localhostName = InetAddress.getLocalHost();

		if (preliminaryResult.equals(localhostName)) {
			// preliminary result is equal to the local host name
			return preliminaryResult;
		}
		else if (tryToConnect(localhostName, targetAddress, AddressDetectionState.SLOW_CONNECT.getTimeout(), logging)) {
			// success, we were able to use local host to connect
			LOG.debug(""Preferring {} (InetAddress.getLocalHost()) for local bind point over previous candidate {}"",
					localhostName, preliminaryResult);
			return localhostName;
		}
		else {
			// we have to make the preliminary result the final result
			return preliminaryResult;
		}
	}"
"public static void write(byte[] data, OutputStream output) throws IOException {
        ByteArrayInputStream input = null;
        try {
            input = new ByteArrayInputStream(data);
            copy(input, output);
            output.flush();
        } finally {
            IOUtils.closeQuietly(output);
        }
    }"
"public void setSentenceIterator(@NonNull SentenceIterator iterator) {
        //if (tokenizerFactory == null) throw new IllegalStateException(""Please call setTokenizerFactory() prior to setSentenceIter() call."");

        if (tokenizerFactory != null) {
            SentenceTransformer transformer = new SentenceTransformer.Builder().iterator(iterator)
                            .tokenizerFactory(tokenizerFactory)
                            .allowMultithreading(configuration == null || configuration.isAllowParallelTokenization())
                            .build();
            this.iterator = new AbstractSequenceIterator.Builder<>(transformer).build();
        } else
            log.error(""Please call setTokenizerFactory() prior to setSentenceIter() call."");
    }"
"static void setupWatch(final Map<String, ParseConfigFile> configFileMap) throws IOException {
    Preconditions.checkNotNull(configFileMap);
    Preconditions.checkArgument(configFileMap.size() > 0);

    final WatchService watchService;
    try {
      watchService = FileSystems.getDefault().newWatchService();
    } catch (IOException e) {
      log.warn("" Failed to create WatchService "" + e.getMessage());
      throw e;
    }

    // Map to store WatchKey to Dir mapping
    final Map<WatchKey, Path> keys = new HashMap<>();
    // A directory to config files multimap
    final Multimap<Path, String> dirToFilesMap = HashMultimap.create();

    // Iterate over each file.
    for (Map.Entry<String, ParseConfigFile> entry : configFileMap.entrySet()) {
      String fileName = entry.getKey();
      ParseConfigFile parser = entry.getValue();
      Preconditions.checkNotNull(fileName);
      Preconditions.checkNotNull(parser);

      final File file = new File(fileName);
      if (!file.exists()) {
        log.warn(""Failed to setup watch service, user provided file "" + fileName + "" does not ""
            + ""exist."");
        continue;
      }

      try {
        Path dir = Paths.get(fileName).getParent();
        if (!dirToFilesMap.containsKey(dir)) {
          // There is not entry for this directory, create a watchkey
          WatchKey watchKey = dir.register(watchService,
              new WatchEvent.Kind[]{StandardWatchEventKinds.ENTRY_MODIFY},
              SensitivityWatchEventModifier.HIGH);
          keys.put(watchKey, dir);
        }
        // Add the config file to dir map
        dirToFilesMap.put(dir, fileName);
      } catch (IOException e) {
        // Ignore the IOException
        log.warn(""IOException while setting up watch on conf "" + fileName + "". ""
            + e.getMessage());
      }
    }

    // Return if WatchService is not initialized
    if (keys.size() == 0) {
      log.warn(""Watchservice was not setup for any config file(s)."");
      try {
        watchService.close();
      } catch (IOException e) {
        log.warn(""IOException while closing watchService. "" + e.getMessage());
      }
      return;
    }

    Runnable runnable = () -> {
      // Watchservice is established, now listen for the events till eternity!
      for (;; ) {
        WatchKey watchKey;
        try {
          watchKey = watchService.take();
        } catch (InterruptedException ie) {
          log.warn(ie.getMessage());
          Thread.currentThread().interrupt();
          return;
        }

        // Get the directory for which watch service event triggered.
        Path dir = keys.get(watchKey);
        for (WatchEvent<?> event : watchKey.pollEvents()) {
          // Make sure the modification happened to user config file
          @SuppressWarnings(""unchecked"")
          final Path name = ((WatchEvent<Path>) event).context();
          final String filename = dir.resolve(name).toString();
          // Lookup the file in dirToFilesMap
          if (dirToFilesMap.containsEntry(dir, filename)) {
            // Match!
            // reparse the config file
            log.info(""Modification detected, reloading config file "" + filename);
            configFileMap.get(filename).parseConfigFile();
            break;
          }
        }
        watchKey.reset();
      }
    };

    final Thread thread = new Thread(runnable);
    log.info(""Starting configuration watching thread."");
    thread.start();
  }"
"protected FlinkKafkaConsumerBase<Row> getKafkaConsumer(
			String topic,
			Properties properties,
			DeserializationSchema<Row> deserializationSchema) {
		FlinkKafkaConsumerBase<Row> kafkaConsumer =
				createKafkaConsumer(topic, properties, deserializationSchema);
		switch (startupMode) {
			case EARLIEST:
				kafkaConsumer.setStartFromEarliest();
				break;
			case LATEST:
				kafkaConsumer.setStartFromLatest();
				break;
			case GROUP_OFFSETS:
				kafkaConsumer.setStartFromGroupOffsets();
				break;
			case SPECIFIC_OFFSETS:
				kafkaConsumer.setStartFromSpecificOffsets(specificStartupOffsets);
				break;
		}
		return kafkaConsumer;
	}"
"protected final void setResultIterator(MutableObjectIterator<E> iterator) {
		synchronized (this.iteratorLock) {
			// set the result iterator only, if no exception has occurred
			if (this.iteratorException == null) {
				this.iterator = iterator;
				this.iteratorLock.notifyAll();
			}
		}
	}"
"public long[] getShapeFromTensor(OnnxProto3.TensorProto tensorProto) {
        val ret = new long[Math.max(2,tensorProto.getDimsCount())];
        int dimCount = tensorProto.getDimsCount();
        if(dimCount >= 2)
            for(int i = 0; i < ret.length; i++) {
                ret[i] = (int) tensorProto.getDims(i);
            }
        else {
            ret[0] = 1;
            for(int i = 1; i < ret.length; i++) {
                ret[i] = (int) tensorProto.getDims(i - 1);
            }
        }


        return ret;
    }"
"public static Method getMethod(Class<?> clazz, String methodName, Class<?>... paramTypes) throws SecurityException {
		return getMethod(clazz, false, methodName, paramTypes);
	}"
"public Pattern<T, T> notFollowedBy(final String name) {
		if (quantifier.hasProperty(Quantifier.QuantifierProperty.OPTIONAL)) {
			throw new UnsupportedOperationException(
					""Specifying a pattern with an optional path to NOT condition is not supported yet. "" +
					""You can simulate such pattern with two independent patterns, one with and the other without "" +
					""the optional part."");
		}
		return new Pattern<>(name, this, ConsumingStrategy.NOT_FOLLOW, afterMatchSkipStrategy);
	}"
"private void initialize() {
		this.setLayout(new CardLayout());
		this.setName(getContextIndex() + "": "" + PANEL_NAME);
		this.setLayout(new GridBagLayout());
		this.setBorder(new EmptyBorder(2, 2, 2, 2));

		this.add(new JLabel(""<html><p>"" + Constant.messages.getString(""forceduser.panel.label.description"")
				+ ""</p></html>""), LayoutHelper.getGBC(0, 0, 1, 1.0D));

		// Forced User combo box
		this.add(getUsersComboBox(), LayoutHelper.getGBC(0, 2, 1, 1.0D, new Insets(5, 0, 0, 0)));

		// Padding
		this.add(new JLabel(), LayoutHelper.getGBC(0, 99, 1, 1.0D, 1.0D));
	}"
"private static boolean repStep(
			BufferedReader in,
			boolean readConsoleInput) throws IOException, InterruptedException {

		// wait until CLIENT_POLLING_INTERVAL is over or the user entered something.
		long startTime = System.currentTimeMillis();
		while ((System.currentTimeMillis() - startTime) < CLIENT_POLLING_INTERVAL_MS
			&& (!readConsoleInput || !in.ready())) {
			Thread.sleep(200L);
		}
		//------------- handle interactive command by user. ----------------------

		if (readConsoleInput && in.ready()) {
			String command = in.readLine();
			switch (command) {
				case ""quit"":
				case ""stop"":
					return false;

				case ""help"":
					System.err.println(YARN_SESSION_HELP);
					break;
				default:
					System.err.println(""Unknown command '"" + command + ""'. Showing help:"");
					System.err.println(YARN_SESSION_HELP);
					break;
			}
		}

		return true;
	}"
"public static java.lang.Double toDouble(Object arg) throws NoSuchMethodException {
        if (arg instanceof java.lang.Integer) return boxToDouble((double)unboxToInt(arg));
        if (arg instanceof java.lang.Float) return boxToDouble((double)unboxToFloat(arg));
        if (arg instanceof java.lang.Double) return (java.lang.Double)arg;
        if (arg instanceof java.lang.Long) return boxToDouble((double)unboxToLong(arg));
        if (arg instanceof java.lang.Character) return boxToDouble((double)unboxToChar(arg));
        if (arg instanceof java.lang.Byte) return boxToDouble((double)unboxToByte(arg));
        if (arg instanceof java.lang.Short) return boxToDouble((double)unboxToShort(arg));
        throw new NoSuchMethodException();
    }"
"protected Credential getServiceCredentialsFromRequest(final WebApplicationService service, final HttpServletRequest request) {
        val pgtUrl = request.getParameter(CasProtocolConstants.PARAMETER_PROXY_CALLBACK_URL);
        if (StringUtils.isNotBlank(pgtUrl)) {
            try {
                val registeredService = serviceValidateConfigurationContext.getServicesManager().findServiceBy(service);
                verifyRegisteredServiceProperties(registeredService, service);
                return new HttpBasedServiceCredential(new URL(pgtUrl), registeredService);
            } catch (final Exception e) {
                LOGGER.error(""Error constructing [{}]"", CasProtocolConstants.PARAMETER_PROXY_CALLBACK_URL, e);
            }
        }
        return null;
    }"
"private boolean isSessionNameUnique(final String name) {
		synchronized (this.sessions) {
			for (HttpSession session : sessions) {
				if (name.equals(session.getName())) {
					return false;
				}
			}
		}
		return true;
	}"
"public static <T> T mapToBean(Map<?, ?> map, Class<T> beanClass, CopyOptions copyOptions) {
		return fillBeanWithMap(map, ReflectUtil.newInstance(beanClass), copyOptions);
	}"
"protected List<String> preprocess(String document)
    {
        List<Term> termList = segment.seg(document);
        ListIterator<Term> listIterator = termList.listIterator();
        while (listIterator.hasNext())
        {
            Term term = listIterator.next();
            if (CoreStopWordDictionary.contains(term.word) ||
                term.nature.startsWith(""w"")
                )
            {
                listIterator.remove();
            }
        }
        List<String> wordList = new ArrayList<String>(termList.size());
        for (Term term : termList)
        {
            wordList.add(term.word);
        }
        return wordList;
    }"
"public static LogFactory set(LogFactory logFactory) {
		logFactory.getLog(GlobalLogFactory.class).debug(""Custom Use [{}] Logger."", logFactory.name);
		currentLogFactory = logFactory;
		return currentLogFactory;
	}"
"public static <C> ProgramTargetDescriptor of(C clusterId, JobID jobId, String webInterfaceUrl) {
		String clusterIdString;
		try {
			// check if cluster id has a toString method
			clusterId.getClass().getDeclaredMethod(""toString"");
			clusterIdString = clusterId.toString();
		} catch (NoSuchMethodException e) {
			clusterIdString = clusterId.getClass().getSimpleName();
		}
		return new ProgramTargetDescriptor(clusterIdString, jobId.toString(), webInterfaceUrl);
	}"
"public static <T extends CharSequence> T validateIpv6(T value, String errorMsg) throws ValidateException {
		if (false == isIpv6(value)) {
			throw new ValidateException(errorMsg);
		}
		return value;
	}"
"private void configureJobLevelMetrics(final JobRunner jobRunner) {
    this.logger.info(""Configuring Azkaban metrics tracking for jobrunner object"");
    if (MetricReportManager.isAvailable()) {
      final MetricReportManager metricManager = MetricReportManager.getInstance();

      // Adding NumRunningJobMetric listener
      jobRunner.addListener((NumRunningJobMetric) metricManager
          .getMetricFromName(NumRunningJobMetric.NUM_RUNNING_JOB_METRIC_NAME));

      // Adding NumFailedJobMetric listener
      jobRunner.addListener((NumFailedJobMetric) metricManager
          .getMetricFromName(NumFailedJobMetric.NUM_FAILED_JOB_METRIC_NAME));

    }

    jobRunner.addListener(JmxJobMBeanManager.getInstance());
  }"
"public boolean load(InputStream settingStream) throws IOException {
		super.clear();
		BufferedReader reader = null;
		try {
			reader = IoUtil.getReader(settingStream, charset);
			// 分组
			String group = null;
			LinkedHashSet<String> valueSet = null;

			while (true) {
				String line = reader.readLine();
				if (line == null) {
					break;
				}
				line = line.trim();
				// 跳过注释行和空行
				if (StrUtil.isBlank(line) || line.startsWith(COMMENT_FLAG_PRE)) {
					// 空行和注释忽略
					continue;
				} else if (line.startsWith(StrUtil.BACKSLASH + COMMENT_FLAG_PRE)) {
					// 对于值中出现开头为#的字符串，需要转义处理，在此做反转义
					line = line.substring(1);
				}

				// 记录分组名
				if (line.charAt(0) == GROUP_SURROUND[0] && line.charAt(line.length() - 1) == GROUP_SURROUND[1]) {
					// 开始新的分组取值，当出现重名分组时候，合并分组值
					group = line.substring(1, line.length() - 1).trim();
					valueSet = super.get(group);
					if (null == valueSet) {
						valueSet = new LinkedHashSet<String>();
					}
					super.put(group, valueSet);
					continue;
				}

				// 添加值
				if (null == valueSet) {
					// 当出现无分组值的时候，会导致valueSet为空，此时group为""""
					valueSet = new LinkedHashSet<String>();
					super.put(StrUtil.EMPTY, valueSet);
				}
				valueSet.add(line);
			}
		} finally {
			IoUtil.close(reader);
		}
		return true;
	}"
"public static <T extends CharSequence> T validateZipCode(T value, String errorMsg) throws ValidateException {
		if (false == isZipCode(value)) {
			throw new ValidateException(errorMsg);
		}
		return value;
	}"
"public static <K, V> Map<K, V> anyMap() {
        reportMatcher(new InstanceOf(Map.class, ""<any map>""));
        return new HashMap<K, V>(0);
    }"
"void get_cluster_features(final Context ctx,
                              final List<Integer> cluster4,
                              final List<Integer> cluster6,
                              final List<Integer> cluster,
                              List<Integer> features)
    {
        if (!use_cluster)
        {
            return;
        }

        PUSH(features, CLUSTER(cluster, ctx.S0));
        PUSH(features, CLUSTER4(cluster4, ctx.S0));
        PUSH(features, CLUSTER6(cluster6, ctx.S0));
        PUSH(features, CLUSTER(cluster, ctx.S1));
        PUSH(features, CLUSTER(cluster, ctx.S2));
        PUSH(features, CLUSTER(cluster, ctx.N0));
        PUSH(features, CLUSTER4(cluster4, ctx.N0));
        PUSH(features, CLUSTER6(cluster6, ctx.N0));
        PUSH(features, CLUSTER(cluster, ctx.N1));
        PUSH(features, CLUSTER(cluster, ctx.N2));
        PUSH(features, CLUSTER(cluster, ctx.S0L));
        PUSH(features, CLUSTER(cluster, ctx.S0R));
        PUSH(features, CLUSTER(cluster, ctx.S0L2));
        PUSH(features, CLUSTER(cluster, ctx.S0R2));
        PUSH(features, CLUSTER(cluster, ctx.S0LL));
        PUSH(features, CLUSTER(cluster, ctx.S0RR));
        PUSH(features, CLUSTER(cluster, ctx.S1L));
        PUSH(features, CLUSTER(cluster, ctx.S1R));
        PUSH(features, CLUSTER(cluster, ctx.S1L2));
        PUSH(features, CLUSTER(cluster, ctx.S1R2));
        PUSH(features, CLUSTER(cluster, ctx.S1LL));
        PUSH(features, CLUSTER(cluster, ctx.S1RR));
    }"
"public String getWarningReport() {
		Map<String, List<PropertyMigration>> content = getContent(
				LegacyProperties::getRenamed);
		if (content.isEmpty()) {
			return null;
		}
		StringBuilder report = new StringBuilder();
		report.append(String.format(""%nThe use of configuration keys that have been ""
				+ ""renamed was found in the environment:%n%n""));
		append(report, content);
		report.append(String.format(""%n""));
		report.append(""Each configuration key has been temporarily mapped to its ""
				+ ""replacement for your convenience. To silence this warning, please ""
				+ ""update your configuration to use the new keys."");
		report.append(String.format(""%n""));
		return report.toString();
	}"
"public long numParams() {
        int ret = 0;
        for (Map.Entry<String, INDArray> entry : params.entrySet()) {
            ret += entry.getValue().length();
        }
        return ret;
    }"
"protected void performRegistration(
        String discoveryService,
        RegistrationConfiguration registration,
        ServiceInstance instance,
        Publisher<HttpStatus> registrationObservable) {

        registrationObservable.subscribe(new Subscriber<HttpStatus>() {
            @Override
            public void onSubscribe(Subscription s) {
                s.request(1);
            }

            @Override
            public void onNext(HttpStatus httpStatus) {
                if (LOG.isInfoEnabled()) {
                    LOG.info(""Registered service [{}] with {}"", instance.getId(), discoveryService);
                }
            }

            @Override
            public void onError(Throwable t) {
                if (LOG.isErrorEnabled()) {
                    String message = getErrorMessage(discoveryService, t);
                    LOG.error(message, t);
                }
                if (registration.isFailFast() && instance instanceof EmbeddedServerInstance) {
                    ((EmbeddedServerInstance) instance).getEmbeddedServer().stop();
                }
            }

            @Override
            public void onComplete() {
            }
        });
    }"
"protected void createServiceWarningViewState(final Flow flow) {
        val stateWarning = createViewState(flow, CasWebflowConstants.STATE_ID_SHOW_WARNING_VIEW, CasWebflowConstants.VIEW_ID_CONFIRM);
        createTransitionForState(stateWarning, CasWebflowConstants.TRANSITION_ID_SUCCESS, ""finalizeWarning"");
        val finalizeWarn = createActionState(flow, ""finalizeWarning"", createEvaluateAction(""serviceWarningAction""));
        createTransitionForState(finalizeWarn, CasWebflowConstants.STATE_ID_REDIRECT, CasWebflowConstants.STATE_ID_REDIRECT);
    }"
"protected QLStepReturn<O> trainStep(O obs) {

        Integer action;
        INDArray input = getInput(obs);
        boolean isHistoryProcessor = getHistoryProcessor() != null;


        if (isHistoryProcessor)
            getHistoryProcessor().record(input);

        int skipFrame = isHistoryProcessor ? getHistoryProcessor().getConf().getSkipFrame() : 1;
        int historyLength = isHistoryProcessor ? getHistoryProcessor().getConf().getHistoryLength() : 1;
        int updateStart = getConfiguration().getUpdateStart()
                        + ((getConfiguration().getBatchSize() + historyLength) * skipFrame);

        Double maxQ = Double.NaN; //ignore if Nan for stats

        //if step of training, just repeat lastAction
        if (getStepCounter() % skipFrame != 0) {
            action = lastAction;
        } else {
            if (history == null) {
                if (isHistoryProcessor) {
                    getHistoryProcessor().add(input);
                    history = getHistoryProcessor().getHistory();
                } else
                    history = new INDArray[] {input};
            }
            //concat the history into a single INDArray input
            INDArray hstack = Transition.concat(Transition.dup(history));
            if (isHistoryProcessor) {
                hstack.muli(1.0 / getHistoryProcessor().getScale());
            }

            //if input is not 2d, you have to append that the batch is 1 length high
            if (hstack.shape().length > 2)
                hstack = hstack.reshape(Learning.makeShape(1, ArrayUtil.toInts(hstack.shape())));

            INDArray qs = getCurrentDQN().output(hstack);
            int maxAction = Learning.getMaxAction(qs);

            maxQ = qs.getDouble(maxAction);
            action = getEgPolicy().nextAction(hstack);
        }

        lastAction = action;

        StepReply<O> stepReply = getMdp().step(action);

        accuReward += stepReply.getReward() * configuration.getRewardFactor();

        //if it's not a skipped frame, you can do a step of training
        if (getStepCounter() % skipFrame == 0 || stepReply.isDone()) {

            INDArray ninput = getInput(stepReply.getObservation());
            if (isHistoryProcessor)
                getHistoryProcessor().add(ninput);

            INDArray[] nhistory = isHistoryProcessor ? getHistoryProcessor().getHistory() : new INDArray[] {ninput};

            Transition<Integer> trans = new Transition(history, action, accuReward, stepReply.isDone(), nhistory[0]);
            getExpReplay().store(trans);

            if (getStepCounter() > updateStart) {
                Pair<INDArray, INDArray> targets = setTarget(getExpReplay().getBatch());
                getCurrentDQN().fit(targets.getFirst(), targets.getSecond());
            }

            history = nhistory;
            accuReward = 0;
        }


        return new QLStepReturn<O>(maxQ, getCurrentDQN().getLatestScore(), stepReply);

    }"
"private boolean hasMessagesPending()
  {

    for (Map.Entry<MessageQueue, ConcurrentSkipListSet<MessageExt>> entry : messageQueueTreeSetMap.entrySet()) {
      if (!entry.getValue().isEmpty()) {
        return true;
      }
    }

    return false;
  }"
"@Nullable
  public InputRow transform(@Nullable final InputRow row)
  {
    if (row == null) {
      return null;
    }

    final InputRow transformedRow;

    if (transforms.isEmpty()) {
      transformedRow = row;
    } else {
      transformedRow = new TransformedInputRow(row, transforms);
    }

    if (valueMatcher != null) {
      rowSupplierForValueMatcher.set(transformedRow);
      if (!valueMatcher.matches()) {
        return null;
      }
    }

    return transformedRow;
  }"
"@Override
	public boolean triggerCheckpoint(CheckpointMetaData checkpointMetaData, CheckpointOptions checkpointOptions, boolean advanceToEndOfEventTime) throws Exception {
		if (!externallyInducedCheckpoints) {
			return super.triggerCheckpoint(checkpointMetaData, checkpointOptions, advanceToEndOfEventTime);
		}
		else {
			// we do not trigger checkpoints here, we simply state whether we can trigger them
			synchronized (getCheckpointLock()) {
				return isRunning();
			}
		}
	}"
"public static String getIfCacheNotNull(EntityColumn column, String contents) {
        StringBuilder sql = new StringBuilder();
        sql.append(""<if test=\"""").append(column.getProperty()).append(""_cache != null\"">"");
        sql.append(contents);
        sql.append(""</if>"");
        return sql.toString();
    }"
"@Deprecated
  public final OkHttpChannelBuilder negotiationType(io.grpc.okhttp.NegotiationType type) {
    Preconditions.checkNotNull(type, ""type"");
    switch (type) {
      case TLS:
        negotiationType = NegotiationType.TLS;
        break;
      case PLAINTEXT:
        negotiationType = NegotiationType.PLAINTEXT;
        break;
      default:
        throw new AssertionError(""Unknown negotiation type: "" + type);
    }
    return this;
  }"
"public static void copyProperties(Object source, Object target, String... ignoreProperties) {
		copyProperties(source, target, CopyOptions.create().setIgnoreProperties(ignoreProperties));
	}"
"public void setAnimationFromJson(String jsonString, @Nullable String cacheKey) {
    setAnimation(new JsonReader(new StringReader(jsonString)), cacheKey);
  }"
"protected static Optional<String> getEntityIdAsParameter(final Service service) {
        try {
            val builder = new URIBuilder(service.getId());
            val param = builder.getQueryParams()
                .stream()
                .filter(p -> p.getName().equals(SamlProtocolConstants.PARAMETER_ENTITY_ID))
                .findFirst();

            if (param.isPresent()) {
                LOGGER.debug(""Found entity Id in service id [{}]"", param.get().getValue());
                return Optional.of(param.get().getValue());
            }
            val request = WebUtils.getHttpServletRequestFromExternalWebflowContext();
            if (request != null && StringUtils.isNotBlank(request.getQueryString())) {
                val query = request.getQueryString().split(""&"");
                val paramRequest = Arrays.stream(query)
                    .map(p -> {
                        var params = Splitter.on(""="").splitToList(p);
                        return Pair.of(params.get(0), params.get(1));
                    })
                    .filter(p -> p.getKey().equals(SamlProtocolConstants.PARAMETER_ENTITY_ID))
                    .map(Pair::getValue)
                    .map(EncodingUtils::urlDecode)
                    .findFirst();
                LOGGER.debug(""Found entity id as part of request url [{}]"", paramRequest);
                return paramRequest;
            }
        } catch (final Exception e) {
            LOGGER.error(e.getMessage(), e);
        }
        return Optional.empty();
    }"
"public static int decodeBitWidth(int n)
    {
        if (n >= ONE.ordinal() && n <= TWENTY_FOUR.ordinal()) {
            return n + 1;
        }
        else if (n == TWENTY_SIX.ordinal()) {
            return 26;
        }
        else if (n == TWENTY_EIGHT.ordinal()) {
            return 28;
        }
        else if (n == THIRTY.ordinal()) {
            return 30;
        }
        else if (n == THIRTY_TWO.ordinal()) {
            return 32;
        }
        else if (n == FORTY.ordinal()) {
            return 40;
        }
        else if (n == FORTY_EIGHT.ordinal()) {
            return 48;
        }
        else if (n == FIFTY_SIX.ordinal()) {
            return 56;
        }
        else {
            return 64;
        }
    }"
"public void setStatusMapping(Map<String, Integer> statusMapping) {
		Assert.notNull(statusMapping, ""StatusMapping must not be null"");
		this.statusMapping = new HashMap<>(statusMapping);
	}"
"public Object unmarshal(HierarchicalStreamReader reader, Object root, DataHolder dataHolder, boolean nullOut) {
        // init() is too early to do this
        // defensive because some use of XStream happens before plugins are initialized.
        Jenkins h = Jenkins.getInstanceOrNull();
        if(h!=null && h.pluginManager!=null && h.pluginManager.uberClassLoader!=null) {
            setClassLoader(h.pluginManager.uberClassLoader);
        }

        Object o;
        if (root == null || !nullOut) {
            o = super.unmarshal(reader, root, dataHolder);
        } else {
            Set<String> topLevelFields = new HashSet<>();
            o = super.unmarshal(new ReaderWrapper(reader) {
                int depth;
                @Override
                public void moveUp() {
                    if (--depth == 0) {
                        topLevelFields.add(getNodeName());
                    }
                    super.moveUp();
                }
                @Override
                public void moveDown() {
                    try {
                        super.moveDown();
                    } finally {
                        depth++;
                    }
                }
            }, root, dataHolder);
            if (o == root && getConverterLookup().lookupConverterForType(o.getClass()) instanceof RobustReflectionConverter) {
                getReflectionProvider().visitSerializableFields(o, (String name, Class type, Class definedIn, Object value) -> {
                    if (topLevelFields.contains(name)) {
                        return;
                    }
                    Field f = Fields.find(definedIn, name);
                    Object v;
                    if (type.isPrimitive()) {
                        // oddly not in com.thoughtworks.xstream.core.util.Primitives
                        v = ReflectionUtils.getVmDefaultValueForPrimitiveType(type);
                        if (v.equals(value)) {
                            return;
                        }
                    } else {
                        if (value == null) {
                            return;
                        }
                        v = null;
                    }
                    LOGGER.log(Level.FINE, ""JENKINS-21017: nulling out {0} in {1}"", new Object[] {f, o});
                    Fields.write(f, o, v);
                });
            }
        }

        if (oldData.get()!=null) {
            oldData.remove();
            if (o instanceof Saveable) OldDataMonitor.report((Saveable)o, ""1.106"");
        }
        return o;
    }"
"@Override
	protected void computeOperatorSpecificDefaultEstimates(DataStatistics statistics) {
		this.estimatedNumRecords = getPredecessorNode().getEstimatedNumRecords();
		this.estimatedOutputSize = getPredecessorNode().getEstimatedOutputSize();
	}"
"private SimpleWindowState restoreWindowState() {
		SimpleWindowState laststate = null;
		final String statestr = preferences.get(prefnzPrefix+PREF_WINDOW_STATE, null);
		if (logger.isDebugEnabled()) logger.debug(""Restoring preference ""+PREF_WINDOW_STATE+""="" + statestr);
		if (statestr != null) {
			SimpleWindowState state = null;
			try {
				state = SimpleWindowState.valueOf(statestr);
			} catch (final IllegalArgumentException e) {	state = null; }
			if (state != null) {
				switch (state) {
				case ICONFIED: this.setExtendedState(Frame.ICONIFIED);	break;
				case NORMAL: this.setExtendedState(Frame.NORMAL); break;
				case MAXIMIZED: this.setExtendedState(Frame.MAXIMIZED_BOTH); break;
				default:
					logger.error(""Invalid window state (nothing will changed): "" + statestr);
				}
			}
			laststate = state;
		}
		return laststate;
	}"
"private void runInMainThread(Runnable runnable) {
        if (Looper.getMainLooper().getThread() != Thread.currentThread()) {
            mHandler.post(runnable);
        } else {
            runnable.run();
        }
    }"
"static <T> ConnectableObservable<T> wrap(
            ConnectableObservable<T> source, Collection<ReactiveInstrumenter> instrumentations) {
        return new RxInstrumentedConnectableObservable<>(source, instrumentations);
    }"
"Node<E> first() {
        restartFromHead:
        for (;;)
            for (Node<E> h = head, p = h, q;;) {
                if ((q = p.prev) != null &&
                    (q = (p = q).prev) != null)
                    // Check for head updates every other hop.
                    // If p == q, we are sure to follow head instead.
                    p = (h != (h = head)) ? h : q;
                else if (p == h
                         // It is possible that p is PREV_TERMINATOR,
                         // but if so, the CAS is guaranteed to fail.
                         || casHead(h, p))
                    return p;
                else
                    continue restartFromHead;
            }
    }"
"public void add(SingleCSVRecord record) {
        if (records == null)
            records = new ArrayList<>();
        records.add(record);
    }"
"public static HttpResponse executePost(final String url,
                                           final String basicAuthUsername,
                                           final String basicAuthPassword,
                                           final String entity) {
        return executePost(url, basicAuthUsername, basicAuthPassword, entity, new HashMap<>());
    }"
"public static String hexEncode(final byte[] data) {
        try {
            val result = Hex.encodeHex(data);
            return new String(result);
        } catch (final Exception e) {
            return null;
        }
    }"
"@Override
  public OperationHandle getSchemas(SessionHandle sessionHandle, String catalogName,
      String schemaName) throws HiveSQLException {
    return cliService.getSchemas(sessionHandle, catalogName, schemaName);
  }"
"protected void addMetric(String name, Metric metric) {
		if (metric == null) {
			LOG.warn(""Ignoring attempted registration of a metric due to being null for name {}."", name);
			return;
		}
		// add the metric only if the group is still open
		synchronized (this) {
			if (!closed) {
				// immediately put without a 'contains' check to optimize the common case (no collision)
				// collisions are resolved later
				Metric prior = metrics.put(name, metric);

				// check for collisions with other metric names
				if (prior == null) {
					// no other metric with this name yet

					if (groups.containsKey(name)) {
						// we warn here, rather than failing, because metrics are tools that should not fail the
						// program when used incorrectly
						LOG.warn(""Name collision: Adding a metric with the same name as a metric subgroup: '"" +
								name + ""'. Metric might not get properly reported. "" + Arrays.toString(scopeComponents));
					}

					registry.register(metric, name, this);
				}
				else {
					// we had a collision. put back the original value
					metrics.put(name, prior);

					// we warn here, rather than failing, because metrics are tools that should not fail the
					// program when used incorrectly
					LOG.warn(""Name collision: Group already contains a Metric with the name '"" +
							name + ""'. Metric will not be reported."" + Arrays.toString(scopeComponents));
				}
			}
		}
	}"
"public static void toFile(Template template, VelocityContext context, String destPath) {
		PrintWriter writer = null;
		try {
			writer = FileUtil.getPrintWriter(destPath, Velocity.getProperty(Velocity.INPUT_ENCODING).toString(), false);
			merge(template, context, writer);
		} catch (IORuntimeException e) {
			throw new UtilException(e, ""Write Velocity content to [{}] error!"", destPath);
		} finally {
			IoUtil.close(writer);
		}
	}"
"public MultiLayerConfiguration getMultiLayerConfiguration()
            throws InvalidKerasConfigurationException, UnsupportedKerasConfigurationException {
        if (!this.className.equals(config.getFieldClassNameSequential()))
            throw new InvalidKerasConfigurationException(
                    ""Keras model class name "" + this.className + "" incompatible with MultiLayerNetwork"");
        if (this.inputLayerNames.size() != 1)
            throw new InvalidKerasConfigurationException(
                    ""MultiLayerNetwork expects only 1 input (found "" + this.inputLayerNames.size() + "")"");
        if (this.outputLayerNames.size() != 1)
            throw new InvalidKerasConfigurationException(
                    ""MultiLayerNetwork expects only 1 output (found "" + this.outputLayerNames.size() + "")"");

        NeuralNetConfiguration.Builder modelBuilder = new NeuralNetConfiguration.Builder();

        if (optimizer != null) {
            modelBuilder.updater(optimizer);
        }

        NeuralNetConfiguration.ListBuilder listBuilder = modelBuilder.list();

        /* Add layers one at a time. */
        KerasLayer prevLayer = null;
        int layerIndex = 0;
        for (KerasLayer layer : this.layersOrdered) {
            if (layer.isLayer()) {
                int nbInbound = layer.getInboundLayerNames().size();
                if (nbInbound != 1)
                    throw new InvalidKerasConfigurationException(
                            ""Layers in MultiLayerConfiguration must have exactly one inbound layer (found ""
                                    + nbInbound + "" for layer "" + layer.getLayerName() + "")"");
                if (prevLayer != null) {
                    InputType[] inputTypes = new InputType[1];
                    InputPreProcessor preprocessor;
                    if (prevLayer.isInputPreProcessor()) {
                        inputTypes[0] = this.outputTypes.get(prevLayer.getInboundLayerNames().get(0));
                        preprocessor = prevLayer.getInputPreprocessor(inputTypes);
                    } else {
                        inputTypes[0] = this.outputTypes.get(prevLayer.getLayerName());
                        preprocessor = layer.getInputPreprocessor(inputTypes);
                    }
                    if (preprocessor != null)
                        listBuilder.inputPreProcessor(layerIndex, preprocessor);
                }
                listBuilder.layer(layerIndex++, layer.getLayer());
            } else if (layer.getVertex() != null)
                throw new InvalidKerasConfigurationException(""Cannot add vertex to MultiLayerConfiguration (class name ""
                        + layer.getClassName() + "", layer name "" + layer.getLayerName() + "")"");
            prevLayer = layer;
        }

        InputType inputType = this.layersOrdered.get(0).getOutputType();
        if (inputType != null)
            listBuilder.setInputType(inputType);

        /* Whether to use standard backprop (or BPTT) or truncated BPTT. */
        if (this.useTruncatedBPTT && this.truncatedBPTT > 0)
            listBuilder.backpropType(BackpropType.TruncatedBPTT).tBPTTForwardLength(truncatedBPTT)
                    .tBPTTBackwardLength(truncatedBPTT);
        else
            listBuilder.backpropType(BackpropType.Standard);
        return listBuilder.build();
    }"
"private void pollAndUpdateProgress(Stage stage, String name, WorkAllocations.Work work, Job parentJob, Job subJob) {
    pollAndUpdateProgress(stage, name, work, parentJob, subJob, false);
  }"
"private JSlider getSliderThreadsPerHost() {
        if (sliderThreadsPerHost == null) {
            sliderThreadsPerHost = new PositiveValuesSlider(Constant.MAX_THREADS_PER_SCAN);

            sliderThreadsPerHost.addChangeListener(new ChangeListener() {
                @Override
                public void stateChanged(ChangeEvent e) {
                    setLabelThreadsPerHostValue(getSliderThreadsPerHost().getValue());
                }
            });
        }
        return sliderThreadsPerHost;
    }"
"protected int countToken(String token, String target) {
        int tokenIndex = 0;
        int count = 0;
        while (tokenIndex != -1) {
            tokenIndex = target.indexOf(token, tokenIndex);
            if (tokenIndex > -1) {
                tokenIndex++;
                count++;
            }
        }
        return count;
    }"
"@Deprecated
    public static void removeHeader(HttpMessage message, String name) {
        message.headers().remove(name);
    }"
"public SslHandler newHandler(ByteBufAllocator alloc, Executor delegatedTaskExecutor) {
        return newHandler(alloc, startTls, delegatedTaskExecutor);
    }"
"private void setWhere(Where where) throws SqlParseException {
        if (where != null) {
            QueryBuilder whereQuery = QueryMaker.explan(where,this.select.isQuery);
            request.setQuery(whereQuery);
        }
    }"
"@PublicEvolving
	public <R> SingleOutputStreamOperator<R> reduce(
			ReduceFunction<T> reduceFunction,
			ProcessAllWindowFunction<T, R, W> function) {

		TypeInformation<R> resultType = getProcessAllWindowFunctionReturnType(function, input.getType());

		return reduce(reduceFunction, function, resultType);
	}"
"protected void configureProfiles(ConfigurableEnvironment environment, String[] args) {
		environment.getActiveProfiles(); // ensure they are initialized
		// But these ones should go first (last wins in a property key clash)
		Set<String> profiles = new LinkedHashSet<>(this.additionalProfiles);
		profiles.addAll(Arrays.asList(environment.getActiveProfiles()));
		environment.setActiveProfiles(StringUtils.toStringArray(profiles));
	}"
"public static OptimizeEngine newInstance(final EncryptRule encryptRule, final SQLStatement sqlStatement, final List<Object> parameters) {
        if (sqlStatement instanceof InsertStatement) {
            return new EncryptInsertOptimizeEngine(encryptRule, (InsertStatement) sqlStatement, parameters);
        }
        return new EncryptDefaultOptimizeEngine();
    }"
"@Override
    public void processMessage() {
        // this only picks up new training round
        //log.info(""sI_{} Starting CBOW dot..."", transport.getShardIndex());

        CbowRequestMessage cbrm = new CbowRequestMessage(rowsA, rowsB, w1, codes, negSamples, alpha, 119);
        if (negSamples > 0) {
            // unfortunately we have to get copy of negSamples here
            int negatives[] = Arrays.copyOfRange(rowsB, codes.length, rowsB.length);
            cbrm.setNegatives(negatives);
        }
        cbrm.setFrameId(-119L);
        cbrm.setTaskId(this.taskId);
        cbrm.setOriginatorId(this.getOriginatorId());


        // FIXME: get rid of THAT
        CbowTrainer cbt = (CbowTrainer) trainer;
        cbt.pickTraining(cbrm);


        // we calculate dot for all involved rows, and first of all we get mean word
        INDArray words = Nd4j.pullRows(storage.getArray(WordVectorStorage.SYN_0), 1, rowsA, 'c');
        INDArray mean = words.mean(0);

        int resultLength = codes.length + (negSamples > 0 ? (negSamples + 1) : 0);

        INDArray result = Nd4j.createUninitialized(resultLength, 1);
        int e = 0;
        for (; e < codes.length; e++) {
            double dot = Nd4j.getBlasWrapper().dot(mean, storage.getArray(WordVectorStorage.SYN_1).getRow(rowsB[e]));
            result.putScalar(e, dot);
        }

        // negSampling round
        for (; e < resultLength; e++) {
            double dot = Nd4j.getBlasWrapper().dot(mean,
                            storage.getArray(WordVectorStorage.SYN_1_NEGATIVE).getRow(rowsB[e]));
            result.putScalar(e, dot);
        }

        if (voidConfiguration.getExecutionMode() == ExecutionMode.AVERAGING) {
            DotAggregation dot = new DotAggregation(taskId, (short) 1, shardIndex, result);
            dot.setTargetId((short) -1);
            dot.setOriginatorId(getOriginatorId());
            transport.putMessage(dot);
        } else if (voidConfiguration.getExecutionMode() == ExecutionMode.SHARDED) {
            // send this message to everyone
            DotAggregation dot = new DotAggregation(taskId, (short) voidConfiguration.getNumberOfShards(), shardIndex,
                            result);
            dot.setTargetId((short) -1);
            dot.setOriginatorId(getOriginatorId());
            transport.sendMessage(dot);
        }
    }"
"public static Map<CacheMode, Long> cacheModeMapFor(long value) {
        if (value == 0) {
            return CACHE_MODE_ALL_ZEROS;
        }
        Map<CacheMode, Long> m = new HashMap<>();
        for (CacheMode cm : CacheMode.values()) {
            m.put(cm, value);
        }
        return m;
    }"
"@Nonnull
    public static synchronized ScheduledExecutorService get() {
        if (executorService == null) {
            // corePoolSize is set to 10, but will only be created if needed.
            // ScheduledThreadPoolExecutor ""acts as a fixed-sized pool using corePoolSize threads""
            // TODO consider also wrapping in ContextResettingExecutorService
             executorService = new ImpersonatingScheduledExecutorService(new ErrorLoggingScheduledThreadPoolExecutor(10, new NamingThreadFactory(new ClassLoaderSanityThreadFactory(new DaemonThreadFactory()), ""jenkins.util.Timer"")), ACL.SYSTEM);
        }
        return executorService;
    }"
"public boolean hasDataSourceConfiguration(final String shardingSchemaName) {
        return !Strings.isNullOrEmpty(regCenter.get(configNode.getDataSourcePath(shardingSchemaName)));
    }"
"public static String getDynamicTableName(Class<?> entityClass, String tableName) {
        if (IDynamicTableName.class.isAssignableFrom(entityClass)) {
            StringBuilder sql = new StringBuilder();
            sql.append(""<choose>"");
            sql.append(""<when test=\""@tk.mybatis.mapper.util.OGNL@isDynamicParameter(_parameter) and dynamicTableName != null and dynamicTableName != ''\"">"");
            sql.append(""${dynamicTableName}\n"");
            sql.append(""</when>"");
            //不支持指定列的时候查询全部列
            sql.append(""<otherwise>"");
            sql.append(tableName);
            sql.append(""</otherwise>"");
            sql.append(""</choose>"");
            return sql.toString();
        } else {
            return tableName;
        }
    }"
"@Deprecated
    public <T> Exception onFallbackError(HystrixCommand<T> commandInstance, Exception e) {
        // pass-thru by default
        return e;
    }"
"public static URI buildUri(final String host, final int port, final String path,
      final boolean isHttp, final Pair<String, String>... params) throws IOException {
    final URIBuilder builder = new URIBuilder();
    builder.setScheme(isHttp ? ""http"" : ""https"").setHost(host).setPort(port);

    if (null != path && path.length() > 0) {
      builder.setPath(path);
    }

    if (params != null) {
      for (final Pair<String, String> pair : params) {
        builder.setParameter(pair.getFirst(), pair.getSecond());
      }
    }

    try {
      return builder.build();
    } catch (final URISyntaxException e) {
      throw new IOException(e);
    }
  }"
"public static Object validateEqual(Object t1, Object t2, String errorMsg) throws ValidateException {
		if (false == equal(t1, t2)) {
			throw new ValidateException(errorMsg);
		}
		return t1;
	}"
"public XGBoostAutoBuffer putStr(String s ) {
        ab.put4(s.length());
        byte[] a = StringUtils.bytesOf(s);
        ab.putA1(a, a.length);
        return this;
    }"
"public static RythmTemplate wrap(org.rythmengine.template.ITemplate template) {
		return (null == template) ? null : new RythmTemplate(template);
	}"
"protected ByteBuf extractFrame(ChannelHandlerContext ctx, ByteBuf buffer, int index, int length) {
        return buffer.retainedSlice(index, length);
    }"
"static String responseToXml(String endpointName, ApiResponse response) throws ApiException {
		try {
			DocumentBuilderFactory docFactory = DocumentBuilderFactory.newInstance();
			DocumentBuilder docBuilder = docFactory.newDocumentBuilder();
	
			Document doc = docBuilder.newDocument();
			Element rootElement = doc.createElement(endpointName);
			doc.appendChild(rootElement);
			response.toXML(doc, rootElement);
			
			TransformerFactory transformerFactory = TransformerFactory.newInstance();
			Transformer transformer = transformerFactory.newTransformer();
			DOMSource source = new DOMSource(doc);
			
			StringWriter sw = new StringWriter();
			StreamResult result =  new StreamResult(sw);
			transformer.transform(source, result);
			
			return sw.toString();

		} catch (Exception e) {
			logger.error(""Failed to convert API response to XML: "" + e.getMessage(), e);
			throw new ApiException(ApiException.Type.INTERNAL_ERROR, e);
		}
	}"
"public TaskSchedulerBuilder customizers(
			Iterable<TaskSchedulerCustomizer> customizers) {
		Assert.notNull(customizers, ""Customizers must not be null"");
		return new TaskSchedulerBuilder(this.poolSize, this.awaitTermination,
				this.awaitTerminationPeriod, this.threadNamePrefix,
				append(null, customizers));
	}"
"public static void pickupFromResponse(RpcInvokeContext context, SofaResponse response, boolean init) {
        if (context == null && !init) {
            return;
        }
        Map<String, String> responseBaggage = response.getResponseProps();
        if (CommonUtils.isNotEmpty(responseBaggage)) {
            String prefix = RemotingConstants.RPC_RESPONSE_BAGGAGE + ""."";
            for (Map.Entry<String, String> entry : responseBaggage.entrySet()) {
                if (entry.getKey().startsWith(prefix)) {
                    if (context == null) {
                        context = RpcInvokeContext.getContext();
                    }
                    context.putResponseBaggage(entry.getKey().substring(prefix.length()),
                        entry.getValue());
                }
            }
        }
    }"
"public HttpResponse doPreviewDescription(@QueryParameter String text) throws IOException {
        StringWriter w = new StringWriter();
        translate(text, w);
        return HttpResponses.html(w.toString());
    }"
"public static String updateSetColumnsIgnoreVersion(Class<?> entityClass, String entityName, boolean notNull, boolean notEmpty) {
        StringBuilder sql = new StringBuilder();
        sql.append(""<set>"");
        //获取全部列
        Set<EntityColumn> columnSet = EntityHelper.getColumns(entityClass);
        // 逻辑删除列
        EntityColumn logicDeleteColumn = null;
        //当某个列有主键策略时，不需要考虑他的属性是否为空，因为如果为空，一定会根据主键策略给他生成一个值
        for (EntityColumn column : columnSet) {
            if (column.getEntityField().isAnnotationPresent(LogicDelete.class)) {
                if (logicDeleteColumn != null) {
                    throw new LogicDeleteException(entityClass.getCanonicalName() + "" 中包含多个带有 @LogicDelete 注解的字段，一个类中只能存在一个带有 @LogicDelete 注解的字段!"");
                }
                logicDeleteColumn = column;
            }
            if (!column.isId() && column.isUpdatable()) {
                if(column.getEntityField().isAnnotationPresent(Version.class)){
                    //ignore
                } else if (column == logicDeleteColumn) {
                    sql.append(logicDeleteColumnEqualsValue(column, false)).append("","");
                } else if (notNull) {
                    sql.append(SqlHelper.getIfNotNull(entityName, column, column.getColumnEqualsHolder(entityName) + "","", notEmpty));
                } else {
                    sql.append(column.getColumnEqualsHolder(entityName) + "","");
                }
            }
        }
        sql.append(""</set>"");
        return sql.toString();
    }"
"public HttpConnection setMethod(Method method) {
		// method
		try {
			this.conn.setRequestMethod(method.toString());
		} catch (ProtocolException e) {
			throw new HttpException(e);
		}

		// do input and output
		this.conn.setDoInput(true);
		if (Method.POST.equals(method) //
				|| Method.PUT.equals(method)//
				|| Method.PATCH.equals(method)//
				|| Method.DELETE.equals(method)) {
			this.conn.setDoOutput(true);
			this.conn.setUseCaches(false);
		}
		return this;
	}"
"@Override
  public Long unlink(final byte[]... keys) {
    checkIsInMultiOrPipeline();
    client.unlink(keys);
    return client.getIntegerReply();
  }"
"@Override
  public void recordTaskProcessDefinitionChange(String taskId, String processDefinitionId) {
    if (isHistoryLevelAtLeast(HistoryLevel.ACTIVITY)) {
      HistoricTaskInstanceEntity historicTaskInstance = getHistoricTaskInstanceEntityManager().findById(taskId);
      if (historicTaskInstance != null) {
        historicTaskInstance.setProcessDefinitionId(processDefinitionId);
      }
    }
  }"
"public static MetricRegistryConfiguration fromConfiguration(Configuration configuration) {
		ScopeFormats scopeFormats;
		try {
			scopeFormats = ScopeFormats.fromConfig(configuration);
		} catch (Exception e) {
			LOG.warn(""Failed to parse scope format, using default scope formats"", e);
			scopeFormats = ScopeFormats.fromConfig(new Configuration());
		}

		char delim;
		try {
			delim = configuration.getString(MetricOptions.SCOPE_DELIMITER).charAt(0);
		} catch (Exception e) {
			LOG.warn(""Failed to parse delimiter, using default delimiter."", e);
			delim = '.';
		}

		final long maximumFrameSize = AkkaRpcServiceUtils.extractMaximumFramesize(configuration);

		// padding to account for serialization overhead
		final long messageSizeLimitPadding = 256;

		return new MetricRegistryConfiguration(scopeFormats, delim, maximumFrameSize - messageSizeLimitPadding);
	}"
"@SneakyThrows
    protected boolean createUserResource(final Principal p, final Credential credential) {
        val user = new UserResource();
        this.mapper.map(user, p, credential);
        return scimService.create(""Users"", user) != null;
    }"
"public List<ProviderInfo> route(SofaRequest request, List<ProviderInfo> providerInfos) {
        for (Router router : routers) {
            providerInfos = router.route(request, providerInfos);
        }
        return providerInfos;
    }"
"public static final CounterFactory instance() {
        if(INSTANCE == null) throw new IllegalStateException(String.format(""%s not initialized"", CounterFactory.class.getSimpleName()));
        return INSTANCE;
    }"
"public static @CheckForNull <T extends Descriptor> T find(Collection<? extends T> list, String string) {
        T d = findByClassName(list, string);
        if (d != null) {
                return d;
        }
        return findById(list, string);
    }"
"public static EventLoopGroup getServerBossEventLoopGroup(ServerTransportConfig config) {
        String type = config.getProtocolType();
        EventLoopGroup bossGroup = serverBossGroups.get(type);
        if (bossGroup == null) {
            synchronized (NettyHelper.class) {
                bossGroup = serverBossGroups.get(config.getProtocolType());
                if (bossGroup == null) {
                    int bossThreads = config.getBossThreads();
                    bossThreads = bossThreads <= 0 ? Math.max(4, SystemInfo.getCpuCores() / 2) : bossThreads;
                    NamedThreadFactory threadName =
                            new NamedThreadFactory(""SEV-BOSS-"" + config.getPort(), config.isDaemon());
                    bossGroup = config.isUseEpoll() ?
                        new EpollEventLoopGroup(bossThreads, threadName) :
                        new NioEventLoopGroup(bossThreads, threadName);
                    serverBossGroups.put(type, bossGroup);
                    refCounter.putIfAbsent(bossGroup, new AtomicInteger(0));
                }
            }
        }
        refCounter.get(bossGroup).incrementAndGet();
        return bossGroup;
    }"
"@Override
    public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) {
        if (this.processPropertyPlaceHolders) {
            processPropertyPlaceHolders();
        }
        ClassPathMapperScanner scanner = new ClassPathMapperScanner(registry);
        scanner.setAddToConfig(this.addToConfig);
        scanner.setAnnotationClass(this.annotationClass);
        scanner.setMarkerInterface(this.markerInterface);
        scanner.setSqlSessionFactory(this.sqlSessionFactory);
        scanner.setSqlSessionTemplate(this.sqlSessionTemplate);
        scanner.setSqlSessionFactoryBeanName(this.sqlSessionFactoryBeanName);
        scanner.setSqlSessionTemplateBeanName(this.sqlSessionTemplateBeanName);
        scanner.setResourceLoader(this.applicationContext);
        scanner.setBeanNameGenerator(this.nameGenerator);
        scanner.registerFilters();
        //设置通用 Mapper
        scanner.setMapperHelper(this.mapperHelper);
        scanner.scan(StringUtils.tokenizeToStringArray(this.basePackage, ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS));
    }"
"@Benchmark
  @BenchmarkMode(Mode.SampleTime)
  @OutputTimeUnit(TimeUnit.NANOSECONDS)
  public Status codeDecode() {
    return Status.CODE_KEY.parseBytes(""15"".getBytes(Charset.forName(""US-ASCII"")));
  }"
"public double precision(Integer classLabel, double edgeCase) {
        double tpCount = truePositives.getCount(classLabel);
        double fpCount = falsePositives.getCount(classLabel);
        return EvaluationUtils.precision((long) tpCount, (long) fpCount, edgeCase);
    }"
"private static byte[] ntlmv2Hash(final String domain, final String user, final byte[] ntlmHash)
            throws AuthenticationException {
        if (UNICODE_LITTLE_UNMARKED == null) {
            throw new AuthenticationException(""Unicode not supported"");
        }
        final HMACMD5 hmacMD5 = new HMACMD5(ntlmHash);
        // Upper case username, mixed case target!!
        hmacMD5.update(user.toUpperCase(Locale.ROOT).getBytes(UNICODE_LITTLE_UNMARKED));
        if (domain != null) {
            hmacMD5.update(domain.getBytes(UNICODE_LITTLE_UNMARKED));
        }
        return hmacMD5.getOutput();
    }"
"@Override
	public void snapshotState(FunctionSnapshotContext context) throws Exception {
		Preconditions.checkState(this.checkpointedState != null,
			""The "" + getClass().getSimpleName() + "" has not been properly initialized."");

		if (LOG.isDebugEnabled()) {
			LOG.debug(""{} checkpointing: Messages: {}, checkpoint id: {}, timestamp: {}"",
				idsForCurrentCheckpoint, context.getCheckpointId(), context.getCheckpointTimestamp());
		}

		pendingCheckpoints.addLast(new Tuple2<>(context.getCheckpointId(), idsForCurrentCheckpoint));
		idsForCurrentCheckpoint = new HashSet<>(64);

		this.checkpointedState.clear();
		this.checkpointedState.add(SerializedCheckpointData.fromDeque(pendingCheckpoints, idSerializer));
	}"
"@Override
    public void configure(Object... vars) {
        if (vars[0] instanceof Number) {
            Number t = (Number) vars[0];
            threshold = FastMath.abs(t.floatValue());
            log.info(""Setting threshold to [{}]"", threshold);
        } else {
            throw new ND4JIllegalStateException(""Threshold value should be Number"");
        }
    }"
"public static String replace(String s, String target, String replacement)
  {
    // String.replace() is suboptimal in JDK8, but is fixed in JDK9+. When the minimal JDK version supported by Druid is
    // JDK9+, the implementation of this method should be replaced with simple delegation to String.replace(). However,
    // the method should still be prohibited to use in all other places except this method body, because it's easy to
    // suboptimally call String.replace(""a"", ""b""), String.replace(""a"", """"), String.replace(""a"", ""abc""), which have
    // better alternatives String.replace('a', 'b'), removeChar() and replaceChar() respectively.
    int pos = s.indexOf(target);
    if (pos < 0) {
      return s;
    }
    int sLength = s.length();
    int targetLength = target.length();
    // This is needed to work correctly with empty target string and mimic String.replace() behavior
    int searchSkip = Math.max(targetLength, 1);
    StringBuilder sb = new StringBuilder(sLength - targetLength + replacement.length());
    int prevPos = 0;
    do {
      sb.append(s, prevPos, pos);
      sb.append(replacement);
      prevPos = pos + targetLength;
      // Break from the loop if the target is empty
      if (pos == sLength) {
        break;
      }
      pos = s.indexOf(target, pos + searchSkip);
    } while (pos > 0);
    sb.append(s, prevPos, sLength);
    return sb.toString();
  }"
"public double getOutputSizeInBytes(Collection<Symbol> outputSymbols, TypeProvider types)
    {
        requireNonNull(outputSymbols, ""outputSymbols is null"");

        return outputSymbols.stream()
                .mapToDouble(symbol -> getOutputSizeForSymbol(getSymbolStatistics(symbol), types.get(symbol)))
                .sum();
    }"
"public CasServerProfile getProfile() {
        val profile = new CasServerProfile();
        profile.setRegisteredServiceTypesSupported(locateRegisteredServiceTypesSupported());
        profile.setRegisteredServiceTypes(locateRegisteredServiceTypesActive());
        profile.setMultifactorAuthenticationProviderTypesSupported(locateMultifactorAuthenticationProviderTypesSupported());
        profile.setMultifactorAuthenticationProviderTypes(locateMultifactorAuthenticationProviderTypesActive());
        profile.setDelegatedClientTypesSupported(locateDelegatedClientTypesSupported());
        profile.setDelegatedClientTypes(locateDelegatedClientTypes());
        profile.setAvailableAttributes(this.availableAttributes);
        return profile;
    }"
"public void addServer(InternalInstrumented<ServerStats> server) {
    ServerSocketMap prev = perServerSockets.put(id(server), new ServerSocketMap());
    assert prev == null;
    add(servers, server);
  }"
"private static String calcClassSign(String name) {
        try {
            Class<?> clazz = Class.forName(name);

            ByteArrayOutputStream result = new ByteArrayOutputStream();
            ObjectOutputStream outputStream = new ObjectOutputStream(result);
            outputStream.writeObject(clazz);
            outputStream.close();

            MessageDigest crypt = MessageDigest.getInstance(""SHA-1"");
            crypt.reset();
            crypt.update(result.toByteArray());

            return new BigInteger(1, crypt.digest()).toString(16);
        } catch (Exception e) {
            throw new IllegalStateException(""Can't calculate sign of "" + name, e);
        }
    }"
"public static <T> List<T> wrap(final T source) {
        val list = new ArrayList<T>();
        if (source != null) {
            if (source instanceof Collection) {
                val it = ((Collection) source).iterator();
                while (it.hasNext()) {
                    list.add((T) it.next());
                }
            } else if (source.getClass().isArray()) {
                if (source.getClass().isAssignableFrom(byte[].class)) {
                    list.add(source);
                } else {
                    val elements = Arrays.stream((Object[]) source).collect(Collectors.toList());
                    list.addAll((List) elements);
                }
            } else {
                list.add(source);
            }
        }
        return list;
    }"
"public  void markNodeOffline(@NonNull Node node) {
        synchronized (node) {
            node.status(NodeStatus.OFFLINE);

            for (val n : node.getDownstreamNodes())
                remapNode(n);
        }
    }"
"public void addCommands(Iterable<Command> commands) {
		Assert.notNull(commands, ""Commands must not be null"");
		for (Command command : commands) {
			addCommand(command);
		}
	}"
"@Override
    protected int idamin(long N, INDArray X, int incX) {
        return (int) cblas_idamin((int) N, (DoublePointer) X.data().addressPointer(), incX);
    }"
"protected int findMatchingVersionIndex(String dbVersion) {
        int index = 0;
        int matchingVersionIndex = -1;
        while (matchingVersionIndex < 0 && index < ACTIVITI_VERSIONS.size()) {
            if (ACTIVITI_VERSIONS.get(index).matches(dbVersion)) {
                matchingVersionIndex = index;
            } else {
                index++;
            }
        }
        return matchingVersionIndex;
    }"
"public static LocalContainerEntityManagerFactoryBean newHibernateEntityManagerFactoryBean(final JpaConfigDataHolder config,
                                                                                              final AbstractJpaProperties jpaProperties) {
        val bean = new LocalContainerEntityManagerFactoryBean();
        bean.setJpaVendorAdapter(config.getJpaVendorAdapter());

        if (StringUtils.isNotBlank(config.getPersistenceUnitName())) {
            bean.setPersistenceUnitName(config.getPersistenceUnitName());
        }
        bean.setPackagesToScan(config.getPackagesToScan().toArray(ArrayUtils.EMPTY_STRING_ARRAY));

        if (config.getDataSource() != null) {
            bean.setDataSource(config.getDataSource());
        }

        val properties = new Properties();
        properties.put(Environment.DIALECT, jpaProperties.getDialect());
        properties.put(Environment.HBM2DDL_AUTO, jpaProperties.getDdlAuto());
        properties.put(Environment.STATEMENT_BATCH_SIZE, jpaProperties.getBatchSize());
        if (StringUtils.isNotBlank(jpaProperties.getDefaultCatalog())) {
            properties.put(Environment.DEFAULT_CATALOG, jpaProperties.getDefaultCatalog());
        }
        if (StringUtils.isNotBlank(jpaProperties.getDefaultSchema())) {
            properties.put(Environment.DEFAULT_SCHEMA, jpaProperties.getDefaultSchema());
        }
        properties.put(Environment.ENABLE_LAZY_LOAD_NO_TRANS, Boolean.TRUE);
        properties.put(Environment.FORMAT_SQL, Boolean.TRUE);
        properties.put(""hibernate.connection.useUnicode"", Boolean.TRUE);
        properties.put(""hibernate.connection.characterEncoding"", StandardCharsets.UTF_8.name());
        properties.put(""hibernate.connection.charSet"", StandardCharsets.UTF_8.name());
        if (StringUtils.isNotBlank(jpaProperties.getPhysicalNamingStrategyClassName())) {
            properties.put(Environment.PHYSICAL_NAMING_STRATEGY, jpaProperties.getPhysicalNamingStrategyClassName());
        }
        properties.putAll(jpaProperties.getProperties());
        bean.setJpaProperties(properties);
        return bean;
    }"
"public static Marshaller createMarshaller(Class clazz, String encoding) {
		try {
			JAXBContext jaxbContext = getJaxbContext(clazz);

			Marshaller marshaller = jaxbContext.createMarshaller();

			marshaller.setProperty(Marshaller.JAXB_FORMATTED_OUTPUT, Boolean.TRUE);

			if (StringUtils.isNotBlank(encoding)) {
				marshaller.setProperty(Marshaller.JAXB_ENCODING, encoding);
			}

			return marshaller;
		} catch (JAXBException e) {
			throw ExceptionUtil.unchecked(e);
		}
	}"
"private boolean tryTerminate(boolean now, boolean enable) {
        Mutex lock = this.lock;
        for (long c;;) {
            if (((c = ctl) & STOP_BIT) != 0) {      // already terminating
                if ((short)(c >>> TC_SHIFT) == -parallelism) {
                    lock.lock();                    // don't need try/finally
                    termination.signalAll();        // signal when 0 workers
                    lock.unlock();
                }
                return true;
            }
            if (runState >= 0) {                    // not yet enabled
                if (!enable)
                    return false;
                lock.lock();
                runState |= SHUTDOWN;
                lock.unlock();
            }
            if (!now) {                             // check if idle & no tasks
                if ((int)(c >> AC_SHIFT) != -parallelism ||
                    hasQueuedSubmissions())
                    return false;
                // Check for unqueued inactive workers. One pass suffices.
                WorkQueue[] ws = workQueues; WorkQueue w;
                if (ws != null) {
                    for (int i = 1; i < ws.length; i += 2) {
                        if ((w = ws[i]) != null && w.eventCount >= 0)
                            return false;
                    }
                }
            }
            if (U.compareAndSwapLong(this, CTL, c, c | STOP_BIT)) {
                for (int pass = 0; pass < 3; ++pass) {
                    WorkQueue[] ws = workQueues;
                    if (ws != null) {
                        WorkQueue w;
                        int n = ws.length;
                        for (int i = 0; i < n; ++i) {
                            if ((w = ws[i]) != null) {
                                w.runState = -1;
                                if (pass > 0) {
                                    w.cancelAll();
                                    if (pass > 1)
                                        w.interruptOwner();
                                }
                            }
                        }
                        // Wake up workers parked on event queue
                        int i, e; long cc; Thread p;
                        while ((e = (int)(cc = ctl) & E_MASK) != 0 &&
                               (i = e & SMASK) < n &&
                               (w = ws[i]) != null) {
                            long nc = ((long)(w.nextWait & E_MASK) |
                                       ((cc + AC_UNIT) & AC_MASK) |
                                       (cc & (TC_MASK|STOP_BIT)));
                            if (w.eventCount == (e | INT_SIGN) &&
                                U.compareAndSwapLong(this, CTL, cc, nc)) {
                                w.eventCount = (e + E_SEQ) & E_MASK;
                                w.runState = -1;
                                if ((p = w.parker) != null)
                                    U.unpark(p);
                            }
                        }
                    }
                }
            }
        }
    }"
"static double inner_product(SparseVector vec1, SparseVector vec2)
    {
        Iterator<Map.Entry<Integer, Double>> it;
        SparseVector other;
        if (vec1.size() < vec2.size())
        {
            it = vec1.entrySet().iterator();
            other = vec2;
        }
        else
        {
            it = vec2.entrySet().iterator();
            other = vec1;
        }
        double prod = 0;
        while (it.hasNext())
        {
            Map.Entry<Integer, Double> entry = it.next();
            prod += entry.getValue() * other.get(entry.getKey());
        }
        return prod;
    }"
"private void writeObject (ObjectOutputStream out) throws IOException {
		out.defaultWriteObject();
		out.writeUTF(charset.name());
	}"
"private static String[] normalizeKeys(Object keys) {
		if (keys instanceof Tuple) {
			Tuple tupleKeys = (Tuple) keys;
			if (tupleKeys.getArity() == 0) {
				return new String[0];
			}
			if (tupleKeys.getField(0) instanceof Integer) {
				String[] stringKeys = new String[tupleKeys.getArity()];
				for (int x = 0; x < stringKeys.length; x++) {
					stringKeys[x] = ""f0.f"" + (Integer) tupleKeys.getField(x);
				}
				return stringKeys;
			}
			if (tupleKeys.getField(0) instanceof String) {
				return tupleToStringArray(tupleKeys);
			}
			throw new RuntimeException(""Key argument contains field that is neither an int nor a String: "" + tupleKeys);
		}
		if (keys instanceof int[]) {
			int[] intKeys = (int[]) keys;
			String[] stringKeys = new String[intKeys.length];
			for (int x = 0; x < stringKeys.length; x++) {
				stringKeys[x] = ""f0.f"" + intKeys[x];
			}"
"protected AbstractMetadataResolver buildMetadataResolverFrom(final SamlRegisteredService service,
                                                                 final SamlMetadataDocument metadataDocument) {
        try {
            val desc = StringUtils.defaultString(service.getDescription(), service.getName());
            val metadataResource = ResourceUtils.buildInputStreamResourceFrom(metadataDocument.getDecodedValue(), desc);
            val metadataResolver = new InMemoryResourceMetadataResolver(metadataResource, configBean);

            val metadataFilterList = new ArrayList<MetadataFilter>();
            if (StringUtils.isNotBlank(metadataDocument.getSignature())) {
                val signatureResource = ResourceUtils.buildInputStreamResourceFrom(metadataDocument.getSignature(), desc);
                buildSignatureValidationFilterIfNeeded(service, metadataFilterList, signatureResource);
            }
            configureAndInitializeSingleMetadataResolver(metadataResolver, service, metadataFilterList);
            return metadataResolver;
        } catch (final Exception e) {
            LOGGER.error(e.getMessage(), e);
        }
        return null;
    }"
"static int calculateBCHCode(int value, int poly) {
    if (poly == 0) {
      throw new IllegalArgumentException(""0 polynomial"");
    }
    // If poly is ""1 1111 0010 0101"" (version info poly), msbSetInPoly is 13. We'll subtract 1
    // from 13 to make it 12.
    int msbSetInPoly = findMSBSet(poly);
    value <<= msbSetInPoly - 1;
    // Do the division business using exclusive-or operations.
    while (findMSBSet(value) >= msbSetInPoly) {
      value ^= poly << (findMSBSet(value) - msbSetInPoly);
    }
    // Now the ""value"" is the remainder (i.e. the BCH code)
    return value;
  }"
"@Deprecated
  public void handleResolvedAddressGroups(
      List<EquivalentAddressGroup> servers,
      @NameResolver.ResolutionResultAttr Attributes attributes) {
    handleResolvedAddresses(
        ResolvedAddresses.newBuilder().setAddresses(servers).setAttributes(attributes).build());
  }"
"@Override
	public int compareTo(Costs o) {
		// check the network cost. if we have actual costs on both, use them, otherwise use the heuristic costs.
		if (this.networkCost != UNKNOWN && o.networkCost != UNKNOWN) {
			if (this.networkCost != o.networkCost) {
				return this.networkCost < o.networkCost ? -1 : 1;
			}
		} else if (this.heuristicNetworkCost < o.heuristicNetworkCost) {
			return -1;
		} else if (this.heuristicNetworkCost > o.heuristicNetworkCost) {
			return 1;
		}
		
		// next, check the disk cost. again, if we have actual costs on both, use them, otherwise use the heuristic costs.
		if (this.diskCost != UNKNOWN && o.diskCost != UNKNOWN) {
			if (this.diskCost != o.diskCost) {
				return this.diskCost < o.diskCost ? -1 : 1;
			}
		} else if (this.heuristicDiskCost < o.heuristicDiskCost) {
			return -1;
		} else if (this.heuristicDiskCost > o.heuristicDiskCost) {
			return 1;
		}
		
		// next, check the CPU cost. again, if we have actual costs on both, use them, otherwise use the heuristic costs.
		if (this.cpuCost != UNKNOWN && o.cpuCost != UNKNOWN) {
			return this.cpuCost < o.cpuCost ? -1 : this.cpuCost > o.cpuCost ? 1 : 0;
		} else if (this.heuristicCpuCost < o.heuristicCpuCost) {
			return -1;
		} else if (this.heuristicCpuCost > o.heuristicCpuCost) {
			return 1;
		} else {
			return 0;
		}
	}"
"public boolean areCompatible(Keys<?> other) throws IncompatibleKeysException {

		TypeInformation<?>[] thisKeyFieldTypes = this.getKeyFieldTypes();
		TypeInformation<?>[] otherKeyFieldTypes = other.getKeyFieldTypes();

		if (thisKeyFieldTypes.length != otherKeyFieldTypes.length) {
			throw new IncompatibleKeysException(IncompatibleKeysException.SIZE_MISMATCH_MESSAGE);
		} else {
			for (int i = 0; i < thisKeyFieldTypes.length; i++) {
				if (!thisKeyFieldTypes[i].equals(otherKeyFieldTypes[i])) {
					throw new IncompatibleKeysException(thisKeyFieldTypes[i], otherKeyFieldTypes[i] );
				}
			}
		}
		return true;
	}"
"public static String normalize(String url, boolean isEncodeBody) {
		if (StrUtil.isBlank(url)) {
			return url;
		}
		final int sepIndex = url.indexOf(""://"");
		String pre;
		String body;
		if (sepIndex > 0) {
			pre = StrUtil.subPre(url, sepIndex + 3);
			body = StrUtil.subSuf(url, sepIndex + 3);
		} else {
			pre = ""http://"";
			body = url;
		}

		final int paramsSepIndex = StrUtil.indexOf(body, '?');
		String params = null;
		if (paramsSepIndex > 0) {
			params = StrUtil.subSuf(body, paramsSepIndex);
			body = StrUtil.subPre(body, paramsSepIndex);
		}

		// 去除开头的\或者/
		body = body.replaceAll(""^[\\/]+"", StrUtil.EMPTY);
		// 替换多个\或/为单个/
		body = body.replace(""\\"", ""/"").replaceAll(""//+"", ""/"");
		if (isEncodeBody) {
			body = encode(body);
		}
		return pre + body + StrUtil.nullToEmpty(params);
	}"
"private void setDefaultList() {
        // Remember, these are regexs, so escape properly \\ vs \
        // Also, http://regexpal.com/ for quick testing.
        // The file formats are common types, not inclusive of all types. Remember, more == slower;
        // complex == slower. Don't overload with every obscure image/audio/video format in existence.
    	
    	/* At some point in the future, this could be read from some a config file and
    	 * parsed.  Thus, we just make it as arrays of strings and assume there
    	 * is some level of parsing at some point.  Since it is rarely accessed (like
    	 * once per boot, it need not be optimized).  */
    	final String defaultListArray[][] = {
			{
	    		""^.*\\.(?:gif|jpe?g|png|ico|icns|bmp)$"",
	    	    ""Extension - Image (ends with .extension)"",
	            ""false""
	  	    }, {
				""^.*\\.(?:mp[34]|mpe?g|m4[ap]|aac|avi|mov|wmv|og[gav])$"",
				""Extension - Audio/Video (ends with .extension)"",
				""false""
			}, {
				""^.*\\.(?:pdf|docx?|xlsx?|pptx?)$"",
				""Extension - PDF & Office (ends with .extension)"",
				""false""
			}, {
				""^.*\\.(?:css|js)$"",
				""Extension - Stylesheet, JavaScript (ends with .extension)"",
				""false""
			}, {
				""^.*\\.(?:sw[fa]|flv)$"",
				""Extension - Flash & related (ends with .extension)"",
				""false""
			}, {
				""^[^\\?]*\\.(?:gif|jpe?g|png|ico|icns|bmp)\\?.*$"",
				""ExtParam - Image (extension plus ?params=values)"",
				""false""
			}, {
				""^[^\\?]*\\.(?:mp[34]|mpe?g|m4[ap]|aac|avi|mov|wmv|og[gav])\\?.*$"",
				""ExtParam - Audio/Video (extension plus ?params=values)"",
				""false""
			}, {
				""^[^\\?]*\\.(?:pdf|docx?|xlsx?|pptx?)\\?.*$"",
				""ExtParam - PDF & Office (extension plus ?params=values)"",
				""false""
			}, {
				""^[^\\?]*\\.(?:css|js)\\?.*$"",
				""ExtParam - Stylesheet, JavaScript (extension plus ?params=values)"",
				""false""
			}, {
				""^[^\\?]*\\.(?:sw[fa]|flv)\\?.*$"",
				""ExtParam - Flash & related (extension plus ?params=values)"",
				""false""
			}, {
				""^[^\\?]*/(?:WebResource|ScriptResource)\\.axd\\?d=.*$"",
				""ExtParam - .NET adx resources (SR/WR.adx?d=)"",
				""false""
			}, {
				""^https?://api\\.bing\\.com/qsml\\.aspx?query=.*$"",
				""Site - Bing API queries"",
				""false""
			}, {
				""^https?://(?:safebrowsing-cache|sb-ssl|sb|safebrowsing).*\\.(?:google|googleapis)\\.com/.*$"",
				""Site - Google malware detector updates"",
				""false""
			}, {
				""^https?://(?:[^/])*\\.?lastpass\\.com"",
				""Site - Lastpass manager"",
				""false""
			}, {
				""^https?://(?:.*addons|aus[0-9])\\.mozilla\\.(?:org|net|com)/.*$"",
				""Site - Firefox browser updates"",
				""false""
			}, {
				""^https?://(?:[^/])*\\.?(?:getfoxyproxy\\.org|getfirebug\\.com|noscript\\.net)"",
				""Site - Firefox extensions phoning home"",
				""false""
			}, {
				// some of this from http://serverfault.com/questions/332003/what-urls-must-be-in-ies-trusted-sites-list-to-allow-windows-update
				""^https?://(?:.*update\\.microsoft|.*\\.windowsupdate)\\.com/.*$"",
				""Site - Microsoft Windows updates"",
				""false""
			}, {
				""^https?://clients2\\.google\\.com/service/update2/crx.*$"",
				""Site - Google Chrome extension updates"",
				""false""
			}, {
				""^https?://detectportal\\.firefox\\.com.*$"",
				""Site - Firefox captive portal detection"",
				""false""
			}, {
				""^https?://www\\.google-analytics\\.com.*$"",
				""Site - Google Analytics"",
				""false""
			}, {
				""^https?://ciscobinary\\.openh264\\.org.*$"",
				""Site - Firefox h264 codec download"", // https://support.mozilla.org/t5/Firefox/Where-is-a-check-that-http-ciscobinary-openh264-org-openh264-is/m-p/1316497#M1005892
				""false""
			}, {
				""^https?://fonts.*$"",
				""Site - Fonts CDNs such as fonts.gstatic.com, etc"",
				""false""
			}, {
				""^https?://.*\\.cdn\\.mozilla\\.(?:com|org|net)/.*$"",
				""Site - Mozilla CDN (requests such as getpocket)"",
				""false""
			}, {
				""^https?://.*\\.telemetry\\.mozilla\\.(?:com|org|net)/.*$"",
				""Site - Firefox browser telemetry"",
				""false""
			}, {
				""^https?://.*\\.adblockplus\\.org.*$"",
				""Site - Adblockplus updates and notifications"",
				""false""
			}, {
				""^https?://.*\\.services\\.mozilla\\.com.*$"",
				""Site - Firefox services"",
				""false""
			}, {
				""^https?://.*\\.gvt1\\.com.*$"",
				""Site - Google updates"",
				""false""
			}
    	};
    	
    	for (String row[] : defaultListArray) {
    		boolean b = row[2].equalsIgnoreCase(""true"") ? true : false;
        	defaultList.add( new GlobalExcludeURLParamToken( row[0], row[1], b));
    	}
    }"
"public void setSize(double width, double height) {
        this.setMinSize(StackPane.USE_PREF_SIZE, StackPane.USE_PREF_SIZE);
        this.setPrefSize(width, height);
        this.setMaxSize(StackPane.USE_PREF_SIZE, StackPane.USE_PREF_SIZE);
    }"
"@Restricted(NoExternalUse.class)
    public List<User> getImpactedUserList() {
        return User.getAll().stream()
                .filter(user -> {
                    ApiTokenProperty apiTokenProperty = user.getProperty(ApiTokenProperty.class);
                    return (apiTokenProperty != null && apiTokenProperty.hasLegacyToken());
                })
                .collect(Collectors.toList());
    }"
"public void storeLocal(final OutputStream out) throws IOException {
    final Properties p = new Properties();
    for (final String key : this._current.keySet()) {
      p.setProperty(key, get(key));
    }
    p.store(out, null);
  }"
"public static PreparedStatement prepareStatementForBatch(Connection conn, String sql, Iterable<Object[]> paramsBatch) throws SQLException {
		Assert.notBlank(sql, ""Sql String must be not blank!"");

		sql = sql.trim();
		SqlLog.INSTASNCE.log(sql, paramsBatch);
		PreparedStatement ps = conn.prepareStatement(sql);
		for (Object[] params : paramsBatch) {
			StatementUtil.fillParams(ps, params);
			ps.addBatch();
		}
		return ps;
	}"
"@PublicEvolving
	public AllWindowedStream<T, W> sideOutputLateData(OutputTag<T> outputTag) {
		Preconditions.checkNotNull(outputTag, ""Side output tag must not be null."");
		this.lateDataOutputTag = input.getExecutionEnvironment().clean(outputTag);
		return this;
	}"
"public EqualityPartition generateEqualitiesPartitionedBy(Predicate<Symbol> symbolScope)
    {
        ImmutableSet.Builder<Expression> scopeEqualities = ImmutableSet.builder();
        ImmutableSet.Builder<Expression> scopeComplementEqualities = ImmutableSet.builder();
        ImmutableSet.Builder<Expression> scopeStraddlingEqualities = ImmutableSet.builder();

        for (Collection<Expression> equalitySet : equalitySets.asMap().values()) {
            Set<Expression> scopeExpressions = new LinkedHashSet<>();
            Set<Expression> scopeComplementExpressions = new LinkedHashSet<>();
            Set<Expression> scopeStraddlingExpressions = new LinkedHashSet<>();

            // Try to push each non-derived expression into one side of the scope
            for (Expression expression : filter(equalitySet, not(derivedExpressions::contains))) {
                Expression scopeRewritten = rewriteExpression(expression, symbolScope, false);
                if (scopeRewritten != null) {
                    scopeExpressions.add(scopeRewritten);
                }
                Expression scopeComplementRewritten = rewriteExpression(expression, not(symbolScope), false);
                if (scopeComplementRewritten != null) {
                    scopeComplementExpressions.add(scopeComplementRewritten);
                }
                if (scopeRewritten == null && scopeComplementRewritten == null) {
                    scopeStraddlingExpressions.add(expression);
                }
            }
            // Compile the equality expressions on each side of the scope
            Expression matchingCanonical = getCanonical(scopeExpressions);
            if (scopeExpressions.size() >= 2) {
                for (Expression expression : filter(scopeExpressions, not(equalTo(matchingCanonical)))) {
                    scopeEqualities.add(new ComparisonExpression(ComparisonExpression.Operator.EQUAL, matchingCanonical, expression));
                }
            }
            Expression complementCanonical = getCanonical(scopeComplementExpressions);
            if (scopeComplementExpressions.size() >= 2) {
                for (Expression expression : filter(scopeComplementExpressions, not(equalTo(complementCanonical)))) {
                    scopeComplementEqualities.add(new ComparisonExpression(ComparisonExpression.Operator.EQUAL, complementCanonical, expression));
                }
            }

            // Compile the scope straddling equality expressions
            List<Expression> connectingExpressions = new ArrayList<>();
            connectingExpressions.add(matchingCanonical);
            connectingExpressions.add(complementCanonical);
            connectingExpressions.addAll(scopeStraddlingExpressions);
            connectingExpressions = ImmutableList.copyOf(filter(connectingExpressions, Predicates.notNull()));
            Expression connectingCanonical = getCanonical(connectingExpressions);
            if (connectingCanonical != null) {
                for (Expression expression : filter(connectingExpressions, not(equalTo(connectingCanonical)))) {
                    scopeStraddlingEqualities.add(new ComparisonExpression(ComparisonExpression.Operator.EQUAL, connectingCanonical, expression));
                }
            }
        }

        return new EqualityPartition(scopeEqualities.build(), scopeComplementEqualities.build(), scopeStraddlingEqualities.build());
    }"
"public static <C> Iterable<C> findServices(Class<C> target) throws IOException {
		return findServices(target, Thread.currentThread().getContextClassLoader());
	}"
"public static FeatureVector toFeatures(Block map)
    {
        Map<Integer, Double> features = new HashMap<>();

        if (map != null) {
            for (int position = 0; position < map.getPositionCount(); position += 2) {
                features.put((int) BIGINT.getLong(map, position), DOUBLE.getDouble(map, position + 1));
            }
        }
        return new FeatureVector(features);
    }"
"public char charValue() throws OtpErlangRangeException {
        final long l = longValue();
        final char i = (char) l;

        if (i != l) {
            throw new OtpErlangRangeException(""Value too large for char: ""
                    + val);
        }

        return i;
    }"
"public static void move(File src, File dest, boolean isOverride) throws IORuntimeException {
		// check
		if (false == src.exists()) {
			throw new IORuntimeException(""File not found: "" + src);
		}

		// 来源为文件夹，目标为文件
		if (src.isDirectory() && dest.isFile()) {
			throw new IORuntimeException(StrUtil.format(""Can not move directory [{}] to file [{}]"", src, dest));
		}

		if (isOverride && dest.isFile()) {// 只有目标为文件的情况下覆盖之
			dest.delete();
		}

		// 来源为文件，目标为文件夹
		if (src.isFile() && dest.isDirectory()) {
			dest = new File(dest, src.getName());
		}

		if (false == src.renameTo(dest)) {
			// 在文件系统不同的情况下，renameTo会失败，此时使用copy，然后删除原文件
			try {
				copy(src, dest, isOverride);
			} catch (Exception e) {
				throw new IORuntimeException(StrUtil.format(""Move [{}] to [{}] failed!"", src, dest), e);
			}
			// 复制后删除源
			del(src);
		}
	}"
"protected FlinkKafkaConsumerBase<T> setStartFromTimestamp(long startupOffsetsTimestamp) {
		checkArgument(startupOffsetsTimestamp >= 0, ""The provided value for the startup offsets timestamp is invalid."");

		long currentTimestamp = System.currentTimeMillis();
		checkArgument(startupOffsetsTimestamp <= currentTimestamp,
			""Startup time[%s] must be before current time[%s]."", startupOffsetsTimestamp, currentTimestamp);

		this.startupMode = StartupMode.TIMESTAMP;
		this.startupOffsetsTimestamp = startupOffsetsTimestamp;
		this.specificStartupOffsets = null;
		return this;
	}"
"@GET
  @Path(""/loadStatus"")
  @Produces(MediaType.APPLICATION_JSON)
  @Consumes(MediaType.APPLICATION_JSON)
  @ResourceFilters(BasicSecurityResourceFilter.class)
  public Response getLoadStatus(
      @Context HttpServletRequest req
  )
  {
    return handler.getLoadStatus();
  }"
"public static <T> TimestampedValue<T> from(StreamRecord<T> streamRecord) {
		if (streamRecord.hasTimestamp()) {
			return new TimestampedValue<>(streamRecord.getValue(), streamRecord.getTimestamp());
		} else {
			return new TimestampedValue<>(streamRecord.getValue());
		}
	}"
"private String getHttpPath(String httpPath) {
    if(httpPath == null || httpPath.equals("""")) {
      httpPath = ""/*"";
    }
    else {
      if(!httpPath.startsWith(""/"")) {
        httpPath = ""/"" + httpPath;
      }
      if(httpPath.endsWith(""/"")) {
        httpPath = httpPath + ""*"";
      }
      if(!httpPath.endsWith(""/*"")) {
        httpPath = httpPath + ""/*"";
      }
    }
    return httpPath;
  }"
"public void revertFeatures(@NonNull INDArray[] features, INDArray[] maskArrays) {
        for (int i = 0; i < features.length; i++) {
            INDArray mask = (maskArrays == null ? null : maskArrays[i]);
            revertFeatures(features[i], mask, i);
        }
    }"
"protected Map<String, Object> getModelAttributes(final Map<String, Object> model) {
        return (Map<String, Object>) model.get(CasProtocolConstants.VALIDATION_CAS_MODEL_ATTRIBUTE_NAME_ATTRIBUTES);
    }"
"private static BigDecimal currentTokenAsJavaDecimal(JsonParser parser, int precision, int scale)
            throws IOException
    {
        BigDecimal result;
        switch (parser.getCurrentToken()) {
            case VALUE_NULL:
                return null;
            case VALUE_STRING:
            case FIELD_NAME:
                result = new BigDecimal(parser.getText());
                result = result.setScale(scale, HALF_UP);
                break;
            case VALUE_NUMBER_FLOAT:
            case VALUE_NUMBER_INT:
                result = parser.getDecimalValue();
                result = result.setScale(scale, HALF_UP);
                break;
            case VALUE_TRUE:
                result = BigDecimal.ONE.setScale(scale, HALF_UP);
                break;
            case VALUE_FALSE:
                result = BigDecimal.ZERO.setScale(scale, HALF_UP);
                break;
            default:
                throw new JsonCastException(format(""Unexpected token when cast to DECIMAL(%s,%s): %s"", precision, scale, parser.getText()));
        }

        if (result.precision() > precision) {
            // TODO: Should we use NUMERIC_VALUE_OUT_OF_RANGE instead?
            throw new PrestoException(INVALID_CAST_ARGUMENT, format(""Cannot cast input json to DECIMAL(%s,%s)"", precision, scale));
        }
        return result;
    }"
"@Override
	public List<V> subList(final int fromIndex, final int toIndex) {
		return this.list.subList(fromIndex, toIndex);
	}"
"public String serializeDataActionList(List<DataAction> list) {
        ObjectMapper om = getObjectMapper();
        try {
            return om.writeValueAsString(new ListWrappers.DataActionList(list));
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    }"
"private void initialize() {
        this.setText(Constant.messages.getString(""sites.resend.popup""));

        this.addActionListener(new java.awt.event.ActionListener() { 

        	@Override
        	public void actionPerformed(java.awt.event.ActionEvent evt) {    

                if (treeSite != null) {
        		    SiteNode node = (SiteNode) treeSite.getLastSelectedPathComponent();

            	    ManualRequestEditorDialog dialog = extension.getResendDialog();
            	    HistoryReference ref = node.getHistoryReference();
            	    HttpMessage msg = null;
            	    try {
                        msg = ref.getHttpMessage().cloneRequest();
                        dialog.setMessage(msg);
                        dialog.setVisible(true);
                    } catch (HttpMalformedHeaderException | DatabaseException e) {
                        logger.error(e.getMessage(), e);
                    }
                }
        	}
        });

			
	}"
"public String[] sequencesToTexts(Integer[][] sequences) {
        Integer oovTokenIndex  = wordIndex.get(outOfVocabularyToken);
        ArrayList<String> texts = new ArrayList<>();
        for (Integer[] sequence: sequences) {
            ArrayList<String> wordVector = new ArrayList<>();
            for (Integer index: sequence) {
                if (indexWord.containsKey(index)) {
                    String word = indexWord.get(index);
                    if (numWords != null && index >= numWords) {
                        if (oovTokenIndex != null) {
                            wordVector.add(indexWord.get(oovTokenIndex));
                        } else {
                            wordVector.add(word);
                        }
                    }
                } else if (oovTokenIndex != null) {
                    wordVector.add(indexWord.get(oovTokenIndex));
                }
            }
            StringBuilder builder = new StringBuilder();
            for (String word: wordVector) {
                builder.append(word + split);
            }
            String text = builder.toString();
            texts.add(text);
        }
        return texts.toArray(new String[texts.size()]);
    }"
"public static String extractMultiAndDelPre(Pattern pattern, Holder<CharSequence> contentHolder, String template) {
		if (null == contentHolder || null == pattern || null == template) {
			return null;
		}

		HashSet<String> varNums = findAll(PatternPool.GROUP_VAR, template, 1, new HashSet<String>());

		final CharSequence content = contentHolder.get();
		Matcher matcher = pattern.matcher(content);
		if (matcher.find()) {
			for (String var : varNums) {
				int group = Integer.parseInt(var);
				template = template.replace(""$"" + var, matcher.group(group));
			}
			contentHolder.set(StrUtil.sub(content, matcher.end(), content.length()));
			return template;
		}
		return null;
	}"
"public static HttpResponse toHttpResponse(final int streamId,
                                              final Http2Headers http2Headers,
                                              final boolean validateHttpHeaders) throws Http2Exception {
        final HttpResponseStatus status = parseStatus(http2Headers.status());
        // HTTP/2 does not define a way to carry the version or reason phrase that is included in an
        // HTTP/1.1 status line.
        final HttpResponse msg = new DefaultHttpResponse(HttpVersion.HTTP_1_1, status, validateHttpHeaders);
        try {
            addHttp2ToHttpHeaders(streamId, http2Headers, msg.headers(), msg.protocolVersion(), false, true);
        } catch (final Http2Exception e) {
            throw e;
        } catch (final Throwable t) {
            throw streamError(streamId, PROTOCOL_ERROR, t, ""HTTP/2 to HTTP/1.x headers conversion error"");
        }
        return msg;
    }"
"public Principal getAuthenticationPrincipal(final String ticketGrantingTicketId) {
        try {
            val ticketGrantingTicket = this.centralAuthenticationService.getTicket(ticketGrantingTicketId, TicketGrantingTicket.class);
            return ticketGrantingTicket.getAuthentication().getPrincipal();
        } catch (final InvalidTicketException e) {
            LOGGER.warn(""Ticket-granting ticket [{}] cannot be found in the ticket registry."", e.getMessage());
            LOGGER.debug(e.getMessage(), e);
        }
        LOGGER.warn(""In the absence of valid ticket-granting ticket, the authentication principal cannot be determined. Returning [{}]"", NullPrincipal.class.getSimpleName());
        return NullPrincipal.getInstance();
    }"
"private static Result<?> decodeVariableHeader(ByteBuf buffer, MqttFixedHeader mqttFixedHeader) {
        switch (mqttFixedHeader.messageType()) {
            case CONNECT:
                return decodeConnectionVariableHeader(buffer);

            case CONNACK:
                return decodeConnAckVariableHeader(buffer);

            case SUBSCRIBE:
            case UNSUBSCRIBE:
            case SUBACK:
            case UNSUBACK:
            case PUBACK:
            case PUBREC:
            case PUBCOMP:
            case PUBREL:
                return decodeMessageIdVariableHeader(buffer);

            case PUBLISH:
                return decodePublishVariableHeader(buffer, mqttFixedHeader);

            case PINGREQ:
            case PINGRESP:
            case DISCONNECT:
                // Empty variable header
                return new Result<Object>(null, 0);
        }
        return new Result<Object>(null, 0); //should never reach here
    }"
"private static AbstractWebApplicationService determineWebApplicationFormat(final HttpServletRequest request,
                                                                               final AbstractWebApplicationService webApplicationService) {
        val format = request != null ? request.getParameter(CasProtocolConstants.PARAMETER_FORMAT) : null;
        try {
            if (StringUtils.isNotBlank(format)) {
                val formatType = ValidationResponseType.valueOf(format.toUpperCase());
                webApplicationService.setFormat(formatType);
            }
        } catch (final Exception e) {
            LOGGER.error(""Format specified in the request [{}] is not recognized"", format);
        }
        return webApplicationService;
    }"
"public static ReadOnlyHttp2Headers serverHeaders(boolean validateHeaders,
                                                     AsciiString status,
                                                     AsciiString... otherHeaders) {
        return new ReadOnlyHttp2Headers(validateHeaders,
                                        new AsciiString[] { PseudoHeaderName.STATUS.value(), status },
                                        otherHeaders);
    }"
"@Deprecated
    protected void set(long index, long length, Pointer from) {
        set(index, length, from, 1);
    }"
"public PythonStreamExecutionEnvironment create_local_execution_environment(Configuration config) {
		return new PythonStreamExecutionEnvironment(new LocalStreamEnvironment(config), new Path(localTmpPath), scriptName);
	}"
"public static void mergeNodes(TreeNode master, TreeNode slave) {
        DefaultMutableTreeNode masterNode = (DefaultMutableTreeNode) master;
        DefaultMutableTreeNode slaveNode = (DefaultMutableTreeNode) slave;

        int masterCnt = masterNode.getChildCount();

        // loop thru the slaves
        while (slaveNode.getChildCount() > 0) {
            DefaultMutableTreeNode slaveNodeChild = (DefaultMutableTreeNode) slaveNode.getFirstChild();

            // loop thru the master children
            for (int m = 0; m < masterCnt; m++) {
                DefaultMutableTreeNode masterAtM = (DefaultMutableTreeNode) masterNode.getChildAt(m);

                if (doCustomMerge(slaveNodeChild, masterAtM)) {
                    slaveNodeChild = null;
                    break;
                }

                // see if the names are the same
                if (MergeHelpUtilities.compareNames(masterAtM, slaveNodeChild) == 0) {
                    if (MergeHelpUtilities.haveEqualID(masterAtM, slaveNodeChild)) {
                        // ID and name the same merge the slave node in
                        MergeHelpUtilities.mergeNodes(DEFAULT_MERGE_TYPE, masterAtM, slaveNodeChild);
                        // Need to remove the slaveNodeChild from the list
                        slaveNodeChild.removeFromParent();
                        slaveNodeChild = null;
                        break;
                    }
                    // Names are the same but the ID are not
                    // Mark the nodes and add the slaveChild
                    MergeHelpUtilities.markNodes(masterAtM, slaveNodeChild);
                    masterNode.add(slaveNodeChild);
                    MergeHelpUtilities.mergeNodeChildren(DEFAULT_MERGE_TYPE, slaveNodeChild);
                    slaveNodeChild = null;
                    break;
                }
            }
            if (slaveNodeChild != null) {
                masterNode.add(slaveNodeChild);
                MergeHelpUtilities.mergeNodeChildren(DEFAULT_MERGE_TYPE, slaveNodeChild);
            }
        }
        // There are no more children.
        // Remove slaveNode from it's parent
        slaveNode.removeFromParent();
        slaveNode = null;
    }"
"public static void setLearningRate(ComputationGraph net, ISchedule newLrSchedule) {
        setLearningRate(net, Double.NaN, newLrSchedule);
    }"
"static public X509Certificate readCertificate(String filename)
            throws Exception {
        InputStream inStream = null;
        X509Certificate cert = null;
        try {
            inStream = Config.getInstance().getInputStreamFromFile(filename);
            if (inStream != null) {
                CertificateFactory cf = CertificateFactory.getInstance(""X.509"");
                cert = (X509Certificate) cf.generateCertificate(inStream);
            } else {
                logger.info(""Certificate "" + Encode.forJava(filename) + "" not found."");
            }
        } catch (Exception e) {
            logger.error(""Exception: "", e);
        } finally {
            if (inStream != null) {
                try {
                    inStream.close();
                } catch (IOException ioe) {
                    logger.error(""Exception: "", ioe);
                }
            }
        }
        return cert;
    }"
"public static <T> Publisher<T> fromCompletableFuture(Supplier<CompletableFuture<T>> futureSupplier) {
        return new CompletableFuturePublisher<>(futureSupplier);
    }"
"public SDVariable unsortedSegmentSqrtN(SDVariable data, SDVariable segmentIds, int numSegments) {
        return unsortedSegmentSqrtN(null, data, segmentIds, numSegments);
    }"
"@CanIgnoreReturnValue
  public <V> V call(Callable<V> c) throws Exception {
    Context previous = attach();
    try {
      return c.call();
    } finally {
      detach(previous);
    }
  }"
"@Override
  public ExecutionEntity createProcessInstanceExecution(ProcessDefinition processDefinition, String businessKey, String tenantId, String initiatorVariableName) {
    ExecutionEntity processInstanceExecution = executionDataManager.create();
    
    if (isExecutionRelatedEntityCountEnabledGlobally()) {
      ((CountingExecutionEntity) processInstanceExecution).setCountEnabled(true);
    }
    
    processInstanceExecution.setProcessDefinitionId(processDefinition.getId());
    processInstanceExecution.setProcessDefinitionKey(processDefinition.getKey());
    processInstanceExecution.setProcessDefinitionName(processDefinition.getName());
    processInstanceExecution.setProcessDefinitionVersion(processDefinition.getVersion());
    processInstanceExecution.setBusinessKey(businessKey);
    processInstanceExecution.setScope(true); // process instance is always a scope for all child executions

    // Inherit tenant id (if any)
    if (tenantId != null) {
      processInstanceExecution.setTenantId(tenantId);
    }

    String authenticatedUserId = Authentication.getAuthenticatedUserId();

    processInstanceExecution.setStartTime(Context.getProcessEngineConfiguration().getClock().getCurrentTime());
    processInstanceExecution.setStartUserId(authenticatedUserId);

    // Store in database
    insert(processInstanceExecution, false);

    if (initiatorVariableName != null) {
      processInstanceExecution.setVariable(initiatorVariableName, authenticatedUserId);
    }

    // Need to be after insert, cause we need the id
    processInstanceExecution.setProcessInstanceId(processInstanceExecution.getId());
    processInstanceExecution.setRootProcessInstanceId(processInstanceExecution.getId());
    if (authenticatedUserId != null) {
      getIdentityLinkEntityManager().addIdentityLink(processInstanceExecution, authenticatedUserId, null, IdentityLinkType.STARTER);
    }
    
    // Fire events
    if (getEventDispatcher().isEnabled()) {
      getEventDispatcher().dispatchEvent(ActivitiEventBuilder.createEntityEvent(ActivitiEventType.ENTITY_CREATED, processInstanceExecution));
    }

    return processInstanceExecution;
  }"
"public boolean add(int e)
  {

    // range check
    if (e < ConciseSetUtils.MIN_ALLOWED_SET_BIT || e > ConciseSetUtils.MAX_ALLOWED_INTEGER) {
      throw new IndexOutOfBoundsException(String.valueOf(e));
    }

    // the element can be simply appended
    if (e > last) {
      append(e);
      return true;
    }

    if (e == last) {
      return false;
    }

    // check if the element can be put in a literal word
    int blockIndex = maxLiteralLengthDivision(e);
    int bitPosition = maxLiteralLengthModulus(e);
    for (int i = 0; i <= lastWordIndex && blockIndex >= 0; i++) {
      int w = words[i];
      if (isLiteral(w)) {
        // check if the current literal word is the ""right"" one
        if (blockIndex == 0) {
          // bit already set
          if ((w & (1 << bitPosition)) != 0) {
            return false;
          }

          // By adding the bit we potentially create a sequence:
          // -- If the literal is made up of all zeros, it definitely
          //    cannot be part of a sequence (otherwise it would not have
          //    been created). Thus, we can create a 1-bit literal word
          // -- If there are MAX_LITERAL_LENGTH - 2 set bits, by adding
          //    the new one we potentially allow for a 1's sequence
          //    together with the successive word
          // -- If there are MAX_LITERAL_LENGTH - 1 set bits, by adding
          //    the new one we potentially allow for a 1's sequence
          //    together with the successive and/or the preceding words
          if (!simulateWAH) {
            int bitCount = getLiteralBitCount(w);
            if (bitCount >= ConciseSetUtils.MAX_LITERAL_LENGTH - 2) {
              break;
            }
          } else {
            if (containsOnlyOneBit(~w) || w == ConciseSetUtils.ALL_ONES_LITERAL) {
              break;
            }
          }

          // set the bit
          words[i] |= 1 << bitPosition;
          if (size >= 0) {
            size++;
          }
          return true;
        }

        blockIndex--;
      } else {
        if (simulateWAH) {
          if (isOneSequence(w) && blockIndex <= getSequenceCount(w)) {
            return false;
          }
        } else {
          // if we are at the beginning of a sequence, and it is
          // a set bit, the bit already exists
          if (blockIndex == 0
              && (getLiteral(w) & (1 << bitPosition)) != 0) {
            return false;
          }

          // if we are in the middle of a sequence of 1's, the bit already exist
          if (blockIndex > 0
              && blockIndex <= getSequenceCount(w)
              && isOneSequence(w)) {
            return false;
          }
        }

        // next word
        blockIndex -= getSequenceCount(w) + 1;
      }
    }

    // the bit is in the middle of a sequence or it may cause a literal to
    // become a sequence, thus the ""easiest"" way to add it is by ORing
    return replaceWith(performOperation(convert(e), Operator.OR));
  }"
"private static ThreadPoolExecutor build(ExecutorBuilder builder) {
		final int corePoolSize = builder.corePoolSize;
		final int maxPoolSize = builder.maxPoolSize;
		final long keepAliveTime = builder.keepAliveTime;
		final BlockingQueue<Runnable> workQueue;
		if (null != builder.workQueue) {
			workQueue = builder.workQueue;
		} else {
			// corePoolSize为0则要使用SynchronousQueue避免无限阻塞
			workQueue = (corePoolSize <= 0) ? new SynchronousQueue<Runnable>() : new LinkedBlockingQueue<Runnable>();
		}
		final ThreadFactory threadFactory = (null != builder.threadFactory) ? builder.threadFactory : Executors.defaultThreadFactory();
		RejectedExecutionHandler handler = ObjectUtil.defaultIfNull(builder.handler, new ThreadPoolExecutor.AbortPolicy());

		final ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(//
				corePoolSize, //
				maxPoolSize, //
				keepAliveTime, TimeUnit.NANOSECONDS, //
				workQueue, //
				threadFactory, //
				handler//
		);
		if (null != builder.allowCoreThreadTimeOut) {
			threadPoolExecutor.allowCoreThreadTimeOut(builder.allowCoreThreadTimeOut);
		}
		return threadPoolExecutor;
	}"
"static boolean moreIsBetter(StoppingMetric criterion) {
    return (criterion == StoppingMetric.AUC || criterion == StoppingMetric.lift_top_group || criterion == StoppingMetric.custom_increasing); // || criterion == StoppingMetric.r2);
  }"
"@EnsuresNonNull(""fn"")
  private Function getCompiledScript()
  {
    // JavaScript configuration should be checked when it's actually used because someone might still want Druid
    // nodes to be able to deserialize JavaScript-based objects even though JavaScript is disabled.
    Preconditions.checkState(config.isEnabled(), ""JavaScript is disabled"");

    Function syncedFn = fn;
    if (syncedFn == null) {
      synchronized (config) {
        syncedFn = fn;
        if (syncedFn == null) {
          syncedFn = compile(function);
          fn = syncedFn;
        }
      }
    }
    return syncedFn;
  }"
"public void endObject() throws IOException {
    int p = peeked;
    if (p == PEEKED_NONE) {
      p = doPeek();
    }
    if (p == PEEKED_END_OBJECT) {
      stackSize--;
      pathNames[stackSize] = null; // Free the last path name so that it can be garbage collected!
      pathIndices[stackSize - 1]++;
      peeked = PEEKED_NONE;
    } else {
      throw new IllegalStateException(""Expected END_OBJECT but was "" + peek() + locationString());
    }
  }"
"private void ajaxScheduleCronFlow(final HttpServletRequest req,
      final HashMap<String, Object> ret, final User user) throws ServletException {
    final String projectName = getParam(req, ""projectName"");
    final String flowName = getParam(req, ""flow"");

    final Project project = this.projectManager.getProject(projectName);

    if (project == null) {
      ret.put(PARAM_MESSAGE, ""Project "" + projectName + "" does not exist"");
      ret.put(PARAM_STATUS, STATUS_ERROR);
      return;
    }
    final int projectId = project.getId();

    if (!hasPermission(project, user, Type.SCHEDULE)) {
      ret.put(PARAM_STATUS, STATUS_ERROR);
      ret.put(PARAM_MESSAGE, ""Permission denied. Cannot execute "" + flowName);
      return;
    }

    final Flow flow = project.getFlow(flowName);
    if (flow == null) {
      ret.put(PARAM_STATUS, STATUS_ERROR);
      ret.put(PARAM_MESSAGE, ""Flow "" + flowName + "" cannot be found in project ""
          + projectName);
      return;
    }

    if (flow.isLocked()) {
      ret.put(PARAM_STATUS, STATUS_ERROR);
      ret.put(PARAM_MESSAGE, ""Flow "" + flowName + "" in project "" + projectName + "" is locked."");
      return;
    }

    final boolean hasFlowTrigger;
    try {
      hasFlowTrigger = this.projectManager.hasFlowTrigger(project, flow);
    } catch (final Exception ex) {
      logger.error(ex);
      ret.put(PARAM_STATUS, STATUS_ERROR);
      ret.put(PARAM_MESSAGE, String.format(""Error looking for flow trigger of flow: %s.%s "",
          projectName, flowName));
      return;
    }

    if (hasFlowTrigger) {
      ret.put(PARAM_STATUS, STATUS_ERROR);
      ret.put(PARAM_MESSAGE, String.format(""<font color=\""red\""> Error: Flow %s.%s is already ""
              + ""associated with flow trigger, so schedule has to be defined in flow trigger config </font>"",
          projectName, flowName));
      return;
    }

    final DateTimeZone timezone = DateTimeZone.getDefault();
    final DateTime firstSchedTime = getPresentTimeByTimezone(timezone);

    String cronExpression = null;
    try {
      if (hasParam(req, ""cronExpression"")) {
        // everything in Azkaban functions is at the minute granularity, so we add 0 here
        // to let the expression to be complete.
        cronExpression = getParam(req, ""cronExpression"");
        if (azkaban.utils.Utils.isCronExpressionValid(cronExpression, timezone) == false) {
          ret.put(PARAM_ERROR,
              ""This expression <"" + cronExpression + ""> can not be parsed to quartz cron."");
          return;
        }
      }
      if (cronExpression == null) {
        throw new Exception(""Cron expression must exist."");
      }
    } catch (final Exception e) {
      ret.put(PARAM_ERROR, e.getMessage());
    }

    final long endSchedTime = getLongParam(req, ""endSchedTime"",
        Constants.DEFAULT_SCHEDULE_END_EPOCH_TIME);
    try {
      // Todo kunkun-tang: Need to verify if passed end time is valid.
    } catch (final Exception e) {
      ret.put(PARAM_ERROR, ""Invalid date and time: "" + endSchedTime);
      return;
    }

    ExecutionOptions flowOptions = null;
    try {
      flowOptions = HttpRequestUtils.parseFlowOptions(req);
      HttpRequestUtils.filterAdminOnlyFlowParams(this.userManager, flowOptions, user);
    } catch (final Exception e) {
      ret.put(PARAM_ERROR, e.getMessage());
    }

    // Because either cronExpression or recurrence exists, we build schedule in the below way.
    final Schedule schedule = this.scheduleManager
        .cronScheduleFlow(-1, projectId, projectName, flowName,
            ""ready"", firstSchedTime.getMillis(), endSchedTime, firstSchedTime.getZone(),
            DateTime.now().getMillis(), firstSchedTime.getMillis(),
            firstSchedTime.getMillis(), user.getUserId(), flowOptions,
            cronExpression);

    logger.info(""User '"" + user.getUserId() + ""' has scheduled "" + ""[""
        + projectName + flowName + "" ("" + projectId + "")"" + ""]."");
    this.projectManager.postProjectEvent(project, EventType.SCHEDULE,
        user.getUserId(), ""Schedule "" + schedule.toString()
            + "" has been added."");

    ret.put(PARAM_STATUS, STATUS_SUCCESS);
    ret.put(PARAM_SCHEDULE_ID, schedule.getScheduleId());
    ret.put(PARAM_MESSAGE, projectName + ""."" + flowName + "" scheduled."");
  }"
"public Layer getOutputLayer(int outputLayerIdx) {
        if (outputLayerIdx >= numOutputArrays)
            throw new IllegalArgumentException(""Invalid index: cannot get output layer "" + outputLayerIdx
                    + "", total number of network outputs = "" + numOutputArrays);
        return getLayer(configuration.getNetworkOutputs().get(outputLayerIdx));
    }"
"protected LogoutHttpMessage getLogoutHttpMessageToSend(final SingleLogoutRequest request, final SingleLogoutMessage logoutMessage) {
        return new LogoutHttpMessage(request.getLogoutUrl(), logoutMessage.getPayload(), this.asynchronous);
    }"
"public static FormValidation error(Throwable e, String message) {
        return _error(Kind.ERROR, e, message);
    }"
"@Override
	public void open(Configuration parameters) throws Exception {
		try {
			client = new Socket(hostIp, port);
			outputStream = client.getOutputStream();
			streamWriter = new DataOutputViewStreamWrapper(outputStream);
		}
		catch (IOException e) {
			throw new IOException(""Cannot connect to the client to send back the stream"", e);
		}
	}"
"private static void resolveServerConfig(ServerConfig serverConfig) {
        // 绑定到指定网卡 或全部网卡
        String boundHost = serverConfig.getBoundHost();
        if (boundHost == null) {
            String host = serverConfig.getHost();
            if (StringUtils.isBlank(host)) {
                host = SystemInfo.getLocalHost();
                serverConfig.setHost(host);
                // windows绑定到0.0.0.0的某个端口以后，其它进程还能绑定到该端口
                boundHost = SystemInfo.isWindows() ? host : NetUtils.ANYHOST;
            } else {
                boundHost = host;
            }
            serverConfig.setBoundHost(boundHost);
        }

        // 绑定的端口
        if (serverConfig.isAdaptivePort()) {
            int oriPort = serverConfig.getPort();
            int port = NetUtils.getAvailablePort(boundHost, oriPort,
                RpcConfigs.getIntValue(RpcOptions.SERVER_PORT_END));
            if (port != oriPort) {
                if (LOGGER.isInfoEnabled()) {
                    LOGGER.info(""Changed port from {} to {} because the config port is disabled"", oriPort, port);
                }
                serverConfig.setPort(port);
            }
        }
    }"
"@Override
    public void eval(INDArray labels, INDArray predictions, INDArray mask, final List<? extends Serializable> recordMetaData) {

        Triple<INDArray,INDArray, INDArray> p = BaseEvaluation.reshapeAndExtractNotMasked(labels, predictions, mask, axis);
        if(p == null){
            //All values masked out; no-op
            return;
        }

        INDArray labels2d = p.getFirst();
        INDArray predictions2d = p.getSecond();
        INDArray maskArray = p.getThird();
        Preconditions.checkState(maskArray == null, ""Per-output masking for ROCMultiClass is not supported"");


        if(labels2d.dataType() != predictions2d.dataType())
            labels2d = labels2d.castTo(predictions2d.dataType());

        // FIXME: int cast
        int n = (int) labels2d.size(1);
        if (underlying == null) {
            underlying = new ROC[n];
            for (int i = 0; i < n; i++) {
                underlying[i] = new ROC(thresholdSteps, rocRemoveRedundantPts);
            }
        }

        if (underlying.length != labels2d.size(1)) {
            throw new IllegalArgumentException(
                            ""Cannot evaluate data: number of label classes does not match previous call. "" + ""Got ""
                                            + labels2d.size(1) + "" labels (from array shape ""
                                            + Arrays.toString(labels2d.shape()) + "")""
                                            + "" vs. expected number of label classes = "" + underlying.length);
        }

        for (int i = 0; i < n; i++) {
            INDArray prob = predictions2d.getColumn(i, true); //Probability of class i
            INDArray label = labels2d.getColumn(i, true);
            //Workaround for: https://github.com/deeplearning4j/deeplearning4j/issues/7305
            if(prob.rank() == 0)
                prob = prob.reshape(1,1);
            if(label.rank() == 0)
                label = label.reshape(1,1);
            underlying[i].eval(label, prob);
        }
    }"
"public int sendBuffer1(SingleElementPushBackIterator<IN1> input) throws IOException {
		if (serializer1 == null) {
			IN1 value = input.next();
			serializer1 = getSerializer(value);
			input.pushBack(value);
		}
		return sendBuffer(input, serializer1);
	}"
"public static List<String> getTables(DataSource ds, TableType... types) {
		return getTables(ds, null, null, types);
	}"
"public static CharSequence getCharsetAsSequence(HttpMessage message) {
        CharSequence contentTypeValue = message.headers().get(HttpHeaderNames.CONTENT_TYPE);
        if (contentTypeValue != null) {
            return getCharsetAsSequence(contentTypeValue);
        } else {
            return null;
        }
    }"
"public void write8LE(final long n) {
        write((byte) (n & 0xff));
        write((byte) (n >> 8 & 0xff));
        write((byte) (n >> 16 & 0xff));
        write((byte) (n >> 24 & 0xff));
        write((byte) (n >> 32 & 0xff));
        write((byte) (n >> 40 & 0xff));
        write((byte) (n >> 48 & 0xff));
        write((byte) (n >> 56 & 0xff));
    }"
"public INDArray hash(INDArray data) {
        if (data.shape()[1] != inDimension){
            throw new ND4JIllegalStateException(
                    String.format(""Invalid shape: Requested INDArray shape %s, this table expects dimension %d"",
                            Arrays.toString(data.shape()), inDimension));
        }
        INDArray projected = data.mmul(randomProjection);
        INDArray res = Nd4j.getExecutioner().exec(new Sign(projected));
        return res;
    }"
"public void setComponentEnabled(boolean enabled) {
        super.setEnabled(enabled);

        table.setEnabled(enabled);
        if (scrollPane.getVerticalScrollBar() != null) {
            scrollPane.getVerticalScrollBar().setEnabled(enabled);
        }
        if (scrollPane.getHorizontalScrollBar() != null) {
            scrollPane.getHorizontalScrollBar().setEnabled(enabled);
        }
    }"
"public void setZones(Map<String, List<URL>> zones) {
        if (zones != null) {
            this.otherZones = zones.entrySet()
                .stream()
                .flatMap((Function<Map.Entry<String, List<URL>>, Stream<ServiceInstance>>) entry ->
                    entry.getValue()
                        .stream()
                        .map(uriMapper())
                        .map(uri ->
                            ServiceInstance.builder(getServiceID(), uri)
                                .zone(entry.getKey())
                                .build()
                        ))
                .collect(Collectors.toList());
        }
    }"
"public static String formatHttpDate(Date date) {
		if (null == date) {
			return null;
		}
		return DatePattern.HTTP_DATETIME_FORMAT.format(date);
	}"
"public static Date addDays(@NotNull final Date date, final int amount) {
		return DateUtils.addDays(date, amount);
	}"
"public void notifyAddOnInstalled(final AddOn addOn) {
        if (EventQueue.isDispatchThread()) {
            if (latestInfo != null && latestInfo.getAddOn(addOn.getId()) != null) {
                uninstalledAddOnsModel.removeAddOn(addOn);
            }
            installedAddOnsModel.addOrRefreshAddOn(addOn);
        } else {
            EventQueue.invokeLater(new Runnable() {

                @Override
                public void run() {
                    notifyAddOnInstalled(addOn);
                }
            });
        }
    }"
"public static String createHtmlAnalysisString(DataAnalysis analysis) throws Exception {
        Configuration cfg = new Configuration(new Version(2, 3, 23));

        // Where do we load the templates from:
        cfg.setClassForTemplateLoading(HtmlAnalysis.class, ""/templates/"");

        // Some other recommended settings:
        cfg.setIncompatibleImprovements(new Version(2, 3, 23));
        cfg.setDefaultEncoding(""UTF-8"");
        cfg.setLocale(Locale.US);
        cfg.setTemplateExceptionHandler(TemplateExceptionHandler.RETHROW_HANDLER);


        Map<String, Object> input = new HashMap<>();

        ObjectMapper ret = new ObjectMapper();
        ret.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);
        ret.configure(SerializationFeature.FAIL_ON_EMPTY_BEANS, false);
        ret.configure(MapperFeature.SORT_PROPERTIES_ALPHABETICALLY, true);
        ret.enable(SerializationFeature.INDENT_OUTPUT);

        List<ColumnAnalysis> caList = analysis.getColumnAnalysis();
        Schema schema = analysis.getSchema();

        SequenceDataAnalysis sda = null;
        boolean hasSLA = false;
        if(analysis instanceof SequenceDataAnalysis) {
            sda = (SequenceDataAnalysis) analysis;
            hasSLA = sda.getSequenceLengthAnalysis() != null;
        }


        int n = caList.size();
        if(hasSLA){
            n++;
        }
        String[][] table = new String[n][3];

        List<DivObject> divs = new ArrayList<>();
        List<String> histogramDivNames = new ArrayList<>();

        //Render sequence length analysis, if required:
        if(hasSLA){
            SequenceLengthAnalysis seqLength = sda.getSequenceLengthAnalysis();
            String name = ""Sequence Lengths"";

            table[0][0] = name;
            table[0][1] = ""(Seq Length)"";
            table[0][2] = seqLength.toString().replaceAll("","", "", ""); //Hacky work-around to improve display in HTML table
            table[0][2] = table[0][2].replaceAll("" -> "", "" : "");    //Quantiles rendering

            double[] buckets = seqLength.getHistogramBuckets();
            long[] counts = seqLength.getHistogramBucketCounts();


            if(buckets != null){
                RenderableComponentHistogram.Builder histBuilder = new RenderableComponentHistogram.Builder();
                for (int j = 0; j < counts.length; j++) {
                    histBuilder.addBin(buckets[j], buckets[j + 1], counts[j]);
                }
                histBuilder.margins(60, 60, 90, 20);

                RenderableComponentHistogram hist = histBuilder.title(name).build();

                String divName = ""histdiv_"" + name.replaceAll(""\\W"", """");
                divs.add(new DivObject(divName, ret.writeValueAsString(hist)));
                histogramDivNames.add(divName);
            }
        }

        for (int i = 0; i < caList.size(); i++) {
            ColumnAnalysis ca = caList.get(i);
            String name = schema.getName(i); //namesList.get(i);
            ColumnType type = schema.getType(i);

            int idx = i + (sda != null && sda.getSequenceLengthAnalysis() != null ? 1 : 0);
            table[idx][0] = name;
            table[idx][1] = type.toString();
            table[idx][2] = ca.toString().replaceAll("","", "", ""); //Hacky work-around to improve display in HTML table
            table[idx][2] = table[idx][2].replaceAll("" -> "", "" : "");    //Quantiles rendering
            double[] buckets;
            long[] counts;

            switch (type) {
                case String:
                    StringAnalysis sa = (StringAnalysis) ca;
                    buckets = sa.getHistogramBuckets();
                    counts = sa.getHistogramBucketCounts();
                    break;
                case Integer:
                    IntegerAnalysis ia = (IntegerAnalysis) ca;
                    buckets = ia.getHistogramBuckets();
                    counts = ia.getHistogramBucketCounts();
                    break;
                case Long:
                    LongAnalysis la = (LongAnalysis) ca;
                    buckets = la.getHistogramBuckets();
                    counts = la.getHistogramBucketCounts();
                    break;
                case Double:
                    DoubleAnalysis da = (DoubleAnalysis) ca;
                    buckets = da.getHistogramBuckets();
                    counts = da.getHistogramBucketCounts();
                    break;
                case NDArray:
                    NDArrayAnalysis na = (NDArrayAnalysis) ca;
                    buckets = na.getHistogramBuckets();
                    counts = na.getHistogramBucketCounts();
                    break;
                case Categorical:
                case Time:
                case Bytes:
                    buckets = null;
                    counts = null;
                    break;
                default:
                    throw new RuntimeException(""Invalid/unknown column type: "" + type);
            }

            if (buckets != null) {
                RenderableComponentHistogram.Builder histBuilder = new RenderableComponentHistogram.Builder();

                for (int j = 0; j < counts.length; j++) {
                    histBuilder.addBin(buckets[j], buckets[j + 1], counts[j]);
                }

                histBuilder.margins(60, 60, 90, 20);

                RenderableComponentHistogram hist = histBuilder.title(name).build();

                String divName = ""histdiv_"" + name.replaceAll(""\\W"", """");
                divs.add(new DivObject(divName, ret.writeValueAsString(hist)));
                histogramDivNames.add(divName);
            }
        }

        //Create the summary table
        RenderableComponentTable rct = new RenderableComponentTable.Builder().table(table)
                        .header(""Column Name"", ""Column Type"", ""Column Analysis"").backgroundColor(""#FFFFFF"")
                        .headerColor(""#CCCCCC"").colWidthsPercent(20, 10, 70).border(1).padLeftPx(4).padRightPx(4)
                        .build();

        divs.add(new DivObject(""tablesource"", ret.writeValueAsString(rct)));

        input.put(""divs"", divs);
        input.put(""histogramIDs"", histogramDivNames);

        //Current date/time, UTC
        DateTimeFormatter formatter = DateTimeFormat.forPattern(""YYYY-MM-dd HH:mm:ss zzz"").withZone(DateTimeZone.UTC);
        long currTime = System.currentTimeMillis();
        String dateTime = formatter.print(currTime);
        input.put(""datetime"", dateTime);

        Template template = cfg.getTemplate(""analysis.ftl"");

        //Process template to String
        Writer stringWriter = new StringWriter();
        template.process(input, stringWriter);

        return stringWriter.toString();
    }"
"public static RoleDescriptorResolver getRoleDescriptorResolver(final MetadataResolver metadata,
                                                                   final boolean requireValidMetadata) throws Exception {
        val roleDescriptorResolver = new PredicateRoleDescriptorResolver(metadata);
        roleDescriptorResolver.setSatisfyAnyPredicates(true);
        roleDescriptorResolver.setUseDefaultPredicateRegistry(true);
        roleDescriptorResolver.setRequireValidMetadata(requireValidMetadata);
        roleDescriptorResolver.initialize();
        return roleDescriptorResolver;
    }"
"public static String buildFilterID(String application_name, FilterType filter_type, String filter_name) {
        return application_name + "":"" + filter_name + "":"" + filter_type.toString();
    }"
"public List<SDVariable> dotProductAttention(String name, SDVariable queries, SDVariable keys, SDVariable values, SDVariable mask, boolean scaled, boolean withWeights){
        List<SDVariable> result = f().dotProductAttention(queries, keys, values, mask, scaled, withWeights);
        if(withWeights){
            return Collections.singletonList(updateVariableNameAndReference(result.get(0), name));
        }else{
            return Arrays.asList(
                    updateVariableNameAndReference(result.get(0), name),
                    updateVariableNameAndReference(result.get(1), name+"":weights"")
            );
        }
    }"
"public SingleOutputStreamOperator<T> sum(String field) {
		return aggregate(new SumAggregator<>(field, input.getType(), input.getExecutionConfig()));
	}"
"public Object answer(InvocationOnMock invocation) throws Throwable {
        Object ret = delegate.answer(invocation);
        if (ret != null) {
            return ret;
        }

        Class<?> returnType = invocation.getMethod().getReturnType();
        return returnValueFor(returnType);
    }"
"public void update(int[] goldIndex, int[] predictIndex)
    {
        for (int i = 0; i < goldIndex.length; ++i)
        {
            if (goldIndex[i] == predictIndex[i])
                continue;
            else // 预测与答案不一致
            {
                parameter[goldIndex[i]]++; // 奖励正确的特征函数（将它的权值加一）
                if (predictIndex[i] >= 0 && predictIndex[i] < parameter.length)
                    parameter[predictIndex[i]]--; // 惩罚招致错误的特征函数（将它的权值减一）
                else
                {
                    throw new IllegalArgumentException(""更新参数时传入了非法的下标"");
                }
            }
        }
    }"
"public void retireWindow(W window) {
		W removed = this.mapping.remove(window);
		if (removed == null) {
			throw new IllegalStateException(""Window "" + window + "" is not in in-flight window set."");
		}
	}"
"public FilePath createTextTempFile(final String prefix, final String suffix, final String contents) throws IOException, InterruptedException {
        return createTextTempFile(prefix,suffix,contents,true);
    }"
"public static Vertex newE()
    {
        return new Vertex(Predefine.TAG_END, "" "", new CoreDictionary.Attribute(Nature.end, Predefine.MAX_FREQUENCY / 10), CoreDictionary.getWordID(Predefine.TAG_END));
    }"
"public static double[] xVals(double[] vector) {


        if (vector == null)
            return null;
        double[] x = new double[vector.length / 2];
        int count = 0;
        for (int i = 0; i < vector.length; i++) {
            if (i % 2 != 0)
                x[count++] = vector[i];
        }
        return x;
    }"
"public static double compuScoreFreq(Term from, Term term) {
        return from.termNatures().allFreq + term.termNatures().allFreq;
    }"
"public static MultiValueMap asMultiValueMap(final Map innerMap) {
        return org.springframework.util.CollectionUtils.toMultiValueMap(innerMap);
    }"
"private void writeObject(ObjectOutputStream out) throws IOException {
		// serialize the parent fields and the final fields
		out.defaultWriteObject();

		// the job conf knows how to serialize itself
		jobConf.write(out);

		// write the input split
		hadoopInputSplit.write(out);
	}"
"@GetMapping(value = ""/v1/tickets/{id:.+}"")
    public ResponseEntity<String> getTicketStatus(@PathVariable(""id"") final String id) {
        try {
            val ticket = this.centralAuthenticationService.getTicket(id);
            return new ResponseEntity<>(ticket.getId(), HttpStatus.OK);
        } catch (final InvalidTicketException e) {
            return new ResponseEntity<>(""Ticket could not be found"", HttpStatus.NOT_FOUND);
        } catch (final Exception e) {
            LOGGER.error(e.getMessage(), e);
            return new ResponseEntity<>(e.getMessage(), HttpStatus.INTERNAL_SERVER_ERROR);
        }
    }"
"public Result addCcToken(ClientRequest request) {
        Result<Jwt> result = tokenManager.getJwt(request);
        if(result.isFailure()) { return Failure.of(result.getError()); }
        request.getRequestHeaders().put(Headers.AUTHORIZATION, ""Bearer "" + result.getResult().getJwt());
        return result;
    }"
"public void beginObject() throws IOException {
    int p = peeked;
    if (p == PEEKED_NONE) {
      p = doPeek();
    }
    if (p == PEEKED_BEGIN_OBJECT) {
      push(JsonScope.EMPTY_OBJECT);
      peeked = PEEKED_NONE;
    } else {
      throw new IllegalStateException(""Expected BEGIN_OBJECT but was "" + peek() + locationString());
    }
  }"
"public HystrixMetricsPublisherCollapser getMetricsPublisherForCollapser(HystrixCollapserKey collapserKey, HystrixCollapserMetrics metrics, HystrixCollapserProperties properties) {
        return new HystrixMetricsPublisherCollapserDefault(collapserKey, metrics, properties);
    }"
"public final static void addCookie(HttpServletResponse response, String name, String value, int maxAgeInSeconds, String path, String domain) {
		Cookie cookie = new Cookie(name, value);
		if (domain != null) {
			cookie.setDomain(domain);
		}
		cookie.setMaxAge(maxAgeInSeconds);
		cookie.setPath(path);
		addCookie(response, cookie);
	}"
"public WordVectorModel train(String trainFileName, String modelFileName)
    {
        Config settings = new Config();
        settings.setInputFile(trainFileName);
        settings.setLayer1Size(layerSize);
        settings.setUseContinuousBagOfWords(type == NeuralNetworkType.CBOW);
        settings.setUseHierarchicalSoftmax(useHierarchicalSoftmax);
        settings.setNegative(negativeSamples);
        settings.setNumThreads(numThreads);
        settings.setAlpha(initialLearningRate == null ? type.getDefaultInitialLearningRate() : initialLearningRate);
        settings.setSample(downSampleRate);
        settings.setWindow(windowSize);
        settings.setIter(iterations);
        settings.setMinCount(minFrequency);
        settings.setOutputFile(modelFileName);
        Word2VecTraining model = new Word2VecTraining(settings);
        final long timeStart = System.currentTimeMillis();
//        if (callback == null)
//        {
//            callback = new TrainingCallback()
//            {
//                public void corpusLoading(float percent)
//                {
//                    System.out.printf(""\r加载训练语料：%.2f%%"", percent);
//                }
//
//                public void corpusLoaded(int vocWords, int trainWords, int totalWords)
//                {
//                    System.out.println();
//                    System.out.printf(""词表大小：%d\n"", vocWords);
//                    System.out.printf(""训练词数：%d\n"", trainWords);
//                    System.out.printf(""语料词数：%d\n"", totalWords);
//                }
//
//                public void training(float alpha, float progress)
//                {
//                    System.out.printf(""\r学习率：%.6f  进度：%.2f%%"", alpha, progress);
//                    long timeNow = System.currentTimeMillis();
//                    long costTime = timeNow - timeStart + 1;
//                    progress /= 100;
//                    String etd = Utility.humanTime((long) (costTime / progress * (1.f - progress)));
//                    if (etd.length() > 0) System.out.printf(""  剩余时间：%s"", etd);
//                    System.out.flush();
//                }
//            };
//        }
        settings.setCallback(callback);

        try
        {
            model.trainModel();
            System.out.println();
            System.out.printf(""训练结束，一共耗时：%s\n"", Utility.humanTime(System.currentTimeMillis() - timeStart));
            return new WordVectorModel(modelFileName);
        }
        catch (IOException e)
        {
            logger.warning(""训练过程中发生IO异常\n"" + TextUtility.exceptionToString(e));
        }

        return null;
    }"
"private static int[] createIncrIntArray(int numKeys) {
		int[] keyFields = new int[numKeys];
		for (int i = 0; i < numKeys; i++) {
			keyFields[i] = i;
		}
		return keyFields;
	}"
"public int read_nil() throws OtpErlangDecodeException {
        int arity = 0;
        final int tag = read1skip_version();

        switch (tag) {
        case OtpExternal.nilTag:
            arity = 0;
            break;

        default:
            throw new OtpErlangDecodeException(""Not valid nil tag: "" + tag);
        }

        return arity;
    }"
"@Override
    protected Object run() throws Exception {
        LOGGER.debug(""execute command: {}"", getCommandKey().name());
        return process(new Action() {
            @Override
            Object execute() {
                return getCommandAction().execute(getExecutionType());
            }
        });
    }"
"public static Channel newJVM(String displayName, TaskListener listener, JVMBuilder vmb, FilePath workDir, ClasspathBuilder classpath) throws IOException {
        ServerSocket serverSocket = new ServerSocket();
        serverSocket.bind(new InetSocketAddress(""localhost"",0));
        serverSocket.setSoTimeout((int)TimeUnit.SECONDS.toMillis(10));

        // use -cp + FQCN instead of -jar since remoting.jar can be rebundled (like in the case of the swarm plugin.)
        vmb.classpath().addJarOf(Channel.class);
        vmb.mainClass(Launcher.class);

        if(classpath!=null)
            vmb.args().add(""-cp"").add(classpath);
        vmb.args().add(""-connectTo"",""localhost:""+serverSocket.getLocalPort());

        listener.getLogger().println(""Starting ""+displayName);
        Proc p = vmb.launch(new LocalLauncher(listener)).stdout(listener).pwd(workDir).start();

        Socket s = serverSocket.accept();
        serverSocket.close();

        return forProcess(""Channel to ""+displayName, Computer.threadPoolForRemoting,
                new BufferedInputStream(SocketChannelStream.in(s)),
                new BufferedOutputStream(SocketChannelStream.out(s)),null,p);
    }"
"public void addAdditionalTomcatConnectors(Connector... connectors) {
		Assert.notNull(connectors, ""Connectors must not be null"");
		this.additionalTomcatConnectors.addAll(Arrays.asList(connectors));
	}"
"public synchronized static Server getServer(ServerConfig serverConfig) {
        try {
            Server server = SERVER_MAP.get(Integer.toString(serverConfig.getPort()));
            if (server == null) {
                // 算下网卡和端口
                resolveServerConfig(serverConfig);

                ExtensionClass<Server> ext = ExtensionLoaderFactory.getExtensionLoader(Server.class)
                    .getExtensionClass(serverConfig.getProtocol());
                if (ext == null) {
                    throw ExceptionUtils.buildRuntime(""server.protocol"", serverConfig.getProtocol(),
                        ""Unsupported protocol of server!"");
                }
                server = ext.getExtInstance();
                server.init(serverConfig);
                SERVER_MAP.put(serverConfig.getPort() + """", server);
            }
            return server;
        } catch (SofaRpcRuntimeException e) {
            throw e;
        } catch (Throwable e) {
            throw new SofaRpcRuntimeException(e.getMessage(), e);
        }
    }"
"public List<PipeKey> put(final DbBatch data, Long nid) throws PipeException {
        List<PipeKey> keys = new ArrayList<PipeKey>();
        if (isLocal(nid)) {
            keys.add(rowDataMemoryPipe.put(data));
        } else {
            Future<PipeKey> future = null;
            Pipeline pipeline = configClientService.findPipeline(data.getRowBatch().getIdentity().getPipelineId());
            if (data.getFileBatch() != null && !CollectionUtils.isEmpty(data.getFileBatch().getFiles())) {
                future = executorService.submit(new Callable<PipeKey>() {

                    public PipeKey call() throws Exception {
                        try {
                            MDC.put(OtterConstants.splitPipelineLogFileKey,
                                    String.valueOf(data.getFileBatch().getIdentity().getPipelineId()));
                            return attachmentHttpPipe.put(data.getFileBatch());
                        } finally {
                            MDC.remove(OtterConstants.splitPipelineLogFileKey);
                        }
                    }
                });
            }
            try {
                PipeChooseMode pipeChooseMode = pipeline.getParameters().getPipeChooseType();
                if (pipeChooseMode.isAutomatic()) {
                    if (calculateSize(data) <= sizeThresold) {
                        keys.add(rowDataRpcPipe.put(data));
                    } else {
                        keys.add(rowDataHttpPipe.put(data));
                    }
                } else if (pipeChooseMode.isRpc()) {
                    keys.add(rowDataRpcPipe.put(data));
                } else if (pipeChooseMode.isHttp()) {
                    keys.add(rowDataHttpPipe.put(data));
                } else {
                    throw new PipeException(""pipeChooseMode is error!"" + pipeChooseMode);
                }

                // 等待一下附件处理
                if (future != null) {
                    keys.add(future.get());
                }
            } catch (Exception e) {
                throw new PipeException(e);
            }
        }

        return keys;
    }"
"public static RefCountedBufferingFileStream openNew(
			final FunctionWithException<File, RefCountedFile, IOException> tmpFileProvider) throws IOException {

		return new RefCountedBufferingFileStream(
				tmpFileProvider.apply(null),
				BUFFER_SIZE);
	}"
"@Override
    public double getStdDev() {
        // two-pass algorithm for variance, avoids numeric overflow

        if (values.length <= 1) {
            return 0;
        }

        final double mean = getMean();
        double sum = 0;

        for (long value : values) {
            final double diff = value - mean;
            sum += diff * diff;
        }

        final double variance = sum / (values.length - 1);
        return Math.sqrt(variance);
    }"
"public static int bytesHighFirstToInt(byte[] bytes, int start)
    {
        int num = bytes[start + 3] & 0xFF;
        num |= ((bytes[start + 2] << 8) & 0xFF00);
        num |= ((bytes[start + 1] << 16) & 0xFF0000);
        num |= ((bytes[start] << 24) & 0xFF000000);
        return num;
    }"
"public static <T> Operator<T> createUnionCascade(Operator<T>... operators) {
		return createUnionCascade(null, operators);
	}"
"@ShellMethod(key = ""generate-ddl"", value = ""Generate database DDL scripts"")
    public void generate(
        @ShellOption(value = {""file""},
            help = ""DDL file to contain to generated script"",
            defaultValue = ""/etc/cas/config/cas-db-schema.sql"") final String file,
        @ShellOption(value = {""dialect""},
            help = ""Database dialect class"",
            defaultValue = ""HSQL"") final String dialect,
        @ShellOption(value = {""url""},
            help = ""JDBC database connection URL"",
            defaultValue = ""jdbc:hsqldb:mem:cas"") final String jdbcUrl,
        @ShellOption(value = {""delimiter""},
            help = ""Delimiter to use for separation of statements when generating SQL"",
            defaultValue = "";"") final String delimiter,
        @ShellOption(value = {""pretty""},
            help = ""Format DDL scripts and pretty-print the output"",
            defaultValue = ""true"") final boolean pretty,
        @ShellOption(value = {""dropSchema""},
            help = ""Generate DROP SQL statements in the DDL"",
            defaultValue = ""true"") final boolean dropSchema,
        @ShellOption(value = {""createSchema""},
            help = ""Generate DROP SQL statements in the DDL"",
            defaultValue = ""true"") final boolean createSchema,
        @ShellOption(value = {""haltOnError""},
            help = ""Halt if an error occurs during the generation process"",
            defaultValue = ""true"") final boolean haltOnError) {

        val dialectName = DIALECTS_MAP.getOrDefault(dialect.trim().toUpperCase(), dialect);
        LOGGER.info(""Using database dialect class [{}]"", dialectName);
        if (!dialectName.contains(""."")) {
            LOGGER.warn(""Dialect name must be a fully qualified class name. Supported dialects by default are [{}] ""
                + ""or you may specify the dialect class directly"", DIALECTS_MAP.keySet());
            return;
        }

        val svcRegistry = new StandardServiceRegistryBuilder();

        val settings = new HashMap<String, String>();
        settings.put(AvailableSettings.DIALECT, dialect);
        settings.put(AvailableSettings.URL, jdbcUrl);
        settings.put(AvailableSettings.HBM2DDL_AUTO, ""none"");
        settings.put(AvailableSettings.SHOW_SQL, ""true"");
        svcRegistry.applySettings(settings);

        LOGGER.info(""Collecting entity metadata sources..."");
        val metadata = new MetadataSources(svcRegistry.build());
        REFLECTIONS.getTypesAnnotatedWith(MappedSuperclass.class).forEach(metadata::addAnnotatedClass);
        REFLECTIONS.getTypesAnnotatedWith(Entity.class).forEach(metadata::addAnnotatedClass);
        val metadataSources = metadata.buildMetadata();

        val export = new SchemaExport();
        export.setDelimiter(delimiter);
        export.setOutputFile(file);
        export.setFormat(pretty);
        export.setHaltOnError(haltOnError);
        export.setManageNamespaces(true);

        final SchemaExport.Action action;
        if (createSchema && dropSchema) {
            action = SchemaExport.Action.BOTH;
        } else if (createSchema) {
            action = SchemaExport.Action.CREATE;
        } else if (dropSchema) {
            action = SchemaExport.Action.DROP;
        } else {
            action = SchemaExport.Action.NONE;
        }
        LOGGER.info(""Exporting Database DDL to [{}] using dialect [{}] with export type set to [{}]"", file, dialect, action);
        export.execute(EnumSet.of(TargetType.SCRIPT, TargetType.STDOUT), SchemaExport.Action.BOTH, metadataSources);
        LOGGER.info(""Database DDL is exported to [{}]"", file);
    }"
"public double calculateAUCPR() {
        if (auprc != null) {
            return auprc;
        }

        if (exampleCount == 0) {
            return Double.NaN;
        }

        auprc = getPrecisionRecallCurve().calculateAUPRC();
        return auprc;
    }"
"public static Tuple<String, String> split(String strColumn, String pattern, String valueName) {
        String name = ""split_"" + random();
        if (valueName == null) {
            return new Tuple(name, ""def "" + name + "" = doc['"" + strColumn + ""'].value.split('"" + pattern + ""')"" );
        } else {
            return new Tuple(name, strColumn + ""; def "" + name + "" = "" + valueName + "".split('"" + pattern + ""')"");
        }

    }"
"private void createConnection() throws IOException {
		client = new Socket(hostName, port);
		client.setKeepAlive(true);
		client.setTcpNoDelay(true);

		outputStream = client.getOutputStream();
	}"
"public static String defaultDeviceForThread() {
        Integer deviceForThread = Nd4j.getAffinityManager().getDeviceForThread(Thread.currentThread());
        String deviceName = null;
        //gpu
        if(Nd4j.getBackend().getClass().getName().contains(""JCublasBackend"")) {
            deviceName = ""/device:gpu:"" + deviceForThread;
        }
        else {
            deviceName = ""/device:cpu:"" + deviceForThread;
        }


        return deviceName;
    }"
"@SuppressWarnings(""unchecked"")
	private void emitWindowContents(W window, ACC contents) throws Exception {
		timestampedCollector.setAbsoluteTimestamp(window.maxTimestamp());
		processContext.window = window;
		userFunction.process(triggerContext.key, window, processContext, contents, timestampedCollector);
	}"
"private static int parseInt(String value, int beginIndex, int endIndex) throws NumberFormatException {
        if (beginIndex < 0 || endIndex > value.length() || beginIndex > endIndex) {
            throw new NumberFormatException(value);
        }
        // use same logic as in Integer.parseInt() but less generic we're not supporting negative values
        int i = beginIndex;
        int result = 0;
        int digit;
        if (i < endIndex) {
            digit = Character.digit(value.charAt(i++), 10);
            if (digit < 0) {
                throw new NumberFormatException(""Invalid number: "" + value.substring(beginIndex, endIndex));
            }
            result = -digit;
        }
        while (i < endIndex) {
            digit = Character.digit(value.charAt(i++), 10);
            if (digit < 0) {
                throw new NumberFormatException(""Invalid number: "" + value.substring(beginIndex, endIndex));
            }
            result *= 10;
            result -= digit;
        }
        return -result;
    }"
"public static int[] get3DOutputSize(INDArray inputData, int[] kernel, int[] strides, int[] padding,
                                        ConvolutionMode convolutionMode, int[] dilation, boolean isNCDHW) {

        // NCDHW vs. NDHWC
        int inD = (int) (isNCDHW ? inputData.size(2) : inputData.size(1));
        int inH = (int) (isNCDHW ? inputData.size(3) : inputData.size(2));
        int inW = (int) (isNCDHW ? inputData.size(4) : inputData.size(3));

        int[] eKernel = effectiveKernelSize(kernel, dilation);
        boolean atrous = (eKernel == kernel);

        // FIXME: int cast
        val inShape = new int[]{inD, inH, inW};
        validateShapes(ArrayUtil.toInts(inputData.shape()), eKernel, strides, padding, convolutionMode, dilation, inShape, atrous);

        if (convolutionMode == ConvolutionMode.Same) {
            int outD = (int) Math.ceil(inD / ((double) strides[0]));
            int outH = (int) Math.ceil(inH / ((double) strides[1]));
            int outW = (int) Math.ceil(inW / ((double) strides[2]));

            return new int[]{outD, outH, outW};
        }

        int outD = (inD - eKernel[0] + 2 * padding[0]) / strides[0] + 1;
        int outH = (inH - eKernel[1] + 2 * padding[1]) / strides[1] + 1;
        int outW = (inW - eKernel[2] + 2 * padding[2]) / strides[2] + 1;

        return new int[]{outD, outH, outW};
    }"
"public AggregatorFactory getMergingFactory(AggregatorFactory other) throws AggregatorFactoryNotMergeableException
  {
    final AggregatorFactory combiningFactory = this.getCombiningFactory();
    if (other.getName().equals(this.getName()) && combiningFactory.equals(other.getCombiningFactory())) {
      return combiningFactory;
    } else {
      throw new AggregatorFactoryNotMergeableException(this, other);
    }
  }"
"public static Jwt decode(String token) {
		int firstPeriod = token.indexOf('.');
		int lastPeriod = token.lastIndexOf('.');

		if (firstPeriod <= 0 || lastPeriod <= firstPeriod) {
			throw new IllegalArgumentException(""JWT must have 3 tokens"");
		}
		CharBuffer buffer = CharBuffer.wrap(token, 0, firstPeriod);
		// TODO: Use a Reader which supports CharBuffer
		JwtHeader header = JwtHeaderHelper.create(buffer.toString());

		buffer.limit(lastPeriod).position(firstPeriod + 1);
		byte[] claims = b64UrlDecode(buffer);
		boolean emptyCrypto = lastPeriod == token.length() - 1;

		byte[] crypto;

		if (emptyCrypto) {
			if (!""none"".equals(header.parameters.alg)) {
				throw new IllegalArgumentException(
						""Signed or encrypted token must have non-empty crypto segment"");
			}
			crypto = new byte[0];
		}
		else {
			buffer.limit(token.length()).position(lastPeriod + 1);
			crypto = b64UrlDecode(buffer);
		}
		return new JwtImpl(header, claims, crypto);
	}"
"protected BigDecimal calculateScoreBasedOnEventsCount(final Authentication authentication,
                                                          final Collection<? extends CasEvent> events,
                                                          final long count) {
        if (count == events.size()) {
            LOGGER.debug(""Principal [{}] is assigned to the lowest risk score with attempted count of [{}]"", authentication.getPrincipal(), count);
            return LOWEST_RISK_SCORE;
        }
        return getFinalAveragedScore(count, events.size());
    }"
"protected String getIdForNewProcessDefinition(ProcessDefinitionEntity processDefinition) {
        String nextId = idGenerator.getNextId();

        String result = processDefinition.getKey() + "":"" + processDefinition.getVersion() + "":"" + nextId; // ACT-505
        // ACT-115: maximum id length is 64 characters
        if (result.length() > 64) {
            result = nextId;
        }

        return result;
    }"
"public static Predicate<Credential> newCredentialSelectionPredicate(final String selectionCriteria) {
        try {
            if (StringUtils.isBlank(selectionCriteria)) {
                return credential -> true;
            }

            if (selectionCriteria.endsWith("".groovy"")) {
                val loader = new DefaultResourceLoader();
                val resource = loader.getResource(selectionCriteria);
                val script = IOUtils.toString(resource.getInputStream(), StandardCharsets.UTF_8);

                val clz = AccessController.doPrivileged((PrivilegedAction<Class<Predicate>>) () -> {
                    val classLoader = new GroovyClassLoader(Beans.class.getClassLoader(),
                        new CompilerConfiguration(), true);
                    return classLoader.parseClass(script);
                });
                return clz.getDeclaredConstructor().newInstance();

            }

            val predicateClazz = ClassUtils.getClass(selectionCriteria);
            return (Predicate<org.apereo.cas.authentication.Credential>) predicateClazz.getDeclaredConstructor().newInstance();
        } catch (final Exception e) {
            val predicate = Pattern.compile(selectionCriteria).asPredicate();
            return credential -> predicate.test(credential.getId());
        }
    }"
"public static Configuration loadConfiguration(Configuration dynamicProperties, Logger log) {
		Configuration configuration =
			GlobalConfiguration.loadConfigurationWithDynamicProperties(dynamicProperties);

		// read the environment variables
		final Map<String, String> envs = System.getenv();
		final String tmpDirs = envs.get(MesosConfigKeys.ENV_FLINK_TMP_DIR);

		BootstrapTools.updateTmpDirectoriesInConfiguration(configuration, tmpDirs);

		return configuration;
	}"
"public static void putIfAbsent(String key, String path) {

        if (!DIC.containsKey(key)) {
            DIC.put(key, KV.with(path, (Forest) null));
        }
    }"
"public ServerWebExchangeLimiterBuilder partitionByParameter(String name) {
		return partitionResolver(
				exchange -> exchange.getRequest().getQueryParams().getFirst(name));
	}"
"protected TypeMirror interfaceGenericTypeFor(TypeElement element, String interfaceName) {
        List<? extends TypeMirror> typeMirrors = interfaceGenericTypesFor(element, interfaceName);
        return typeMirrors.isEmpty() ? null : typeMirrors.get(0);
    }"
"@Deprecated
    public static void setHeader(HttpMessage message, String name, Iterable<?> values) {
        message.headers().set(name, values);
    }"
"private static byte[] aes(byte[] input, byte[] key, int mode) {
		try {
			SecretKey secretKey = new SecretKeySpec(key, AES_ALG);
			Cipher cipher = Cipher.getInstance(AES_ALG);
			cipher.init(mode, secretKey);
			return cipher.doFinal(input);
		} catch (GeneralSecurityException e) {
			throw ExceptionUtil.unchecked(e);
		}
	}"
"public List<Map<String, INDArray>> output(DataSetIterator iterator, String... outputs){
        return output(new MultiDataSetIteratorAdapter(iterator), outputs);
    }"
"@Deprecated
	public <L, R> SingleOutputStreamOperator<Either<L, R>> select(
			final PatternTimeoutFunction<T, L> patternTimeoutFunction,
			final PatternSelectFunction<T, R> patternSelectFunction) {

		final TypeInformation<R> mainTypeInfo = TypeExtractor.getUnaryOperatorReturnType(
			patternSelectFunction,
			PatternSelectFunction.class,
			0,
			1,
			TypeExtractor.NO_INDEX,
			builder.getInputType(),
			null,
			false);

		final TypeInformation<L> timeoutTypeInfo = TypeExtractor.getUnaryOperatorReturnType(
			patternTimeoutFunction,
			PatternTimeoutFunction.class,
			0,
			1,
			TypeExtractor.NO_INDEX,
			builder.getInputType(),
			null,
			false);

		final TypeInformation<Either<L, R>> outTypeInfo = new EitherTypeInfo<>(timeoutTypeInfo, mainTypeInfo);

		final OutputTag<L> outputTag = new OutputTag<>(UUID.randomUUID().toString(), timeoutTypeInfo);

		final PatternProcessFunction<T, R> processFunction =
			fromSelect(builder.clean(patternSelectFunction))
				.withTimeoutHandler(outputTag, builder.clean(patternTimeoutFunction))
				.build();

		final SingleOutputStreamOperator<R> mainStream = process(processFunction, mainTypeInfo);
		final DataStream<L> timedOutStream = mainStream.getSideOutput(outputTag);

		return mainStream
			.connect(timedOutStream)
			.map(new CoMapTimeout<>())
			.returns(outTypeInfo);
	}"
"public Map<String, ConfigurationMetadataProperty> find(final boolean strict, final Pattern propertyPattern) {
        val results = new HashMap<String, ConfigurationMetadataProperty>();

        val repository = new CasConfigurationMetadataRepository();
        val props = repository.getRepository().getAllProperties();

        props.forEach((k, v) -> {
            val matched = StreamSupport.stream(RelaxedPropertyNames.forCamelCase(k).spliterator(), false)
                .map(Object::toString)
                .anyMatch(name -> strict
                    ? RegexUtils.matches(propertyPattern, name)
                    : RegexUtils.find(propertyPattern, name));
            if (matched) {
                results.put(k, v);
            }
        });

        return results;
    }"
"@SuppressWarnings(""unchecked"")
	public static <T> Constructor<T>[] getConstructors(Class<T> beanClass) throws SecurityException {
		Assert.notNull(beanClass);
		Constructor<?>[] constructors = CONSTRUCTORS_CACHE.get(beanClass);
		if (null != constructors) {
			return (Constructor<T>[]) constructors;
		}

		constructors = getConstructorsDirectly(beanClass);
		return (Constructor<T>[]) CONSTRUCTORS_CACHE.put(beanClass, constructors);
	}"
"public static CronSchedule monthlyOnDayAndHourAndMinute(int dayOfMonth, int hour, int minute) {
        String expression = String.format(""0 %d %d %d * ?"", minute, hour, dayOfMonth);
        return of(expression);
    }"
"public static void initialize(String[] args, boolean forceReferenceCleanup,
			RestartInitializer initializer) {
		initialize(args, forceReferenceCleanup, initializer, true);
	}"
"public static int getTermFrequency(String term)
    {
        Attribute attribute = get(term);
        if (attribute == null) return 0;
        return attribute.totalFrequency;
    }"
"@SuppressWarnings(""unchecked"")
    public static <T> T readObject(InputStream is) {
        try {
            ObjectInputStream ois = new ObjectInputStream(is);
            T ret = (T) ois.readObject();
            ois.close();
            return ret;
        } catch (Exception e) {
            throw new RuntimeException(e);
        }

    }"
"public <T> T toBeanIgnoreCase(Class<T> clazz) {
		return BeanUtil.mapToBeanIgnoreCase(this, clazz, false);
	}"
"public Collection<Token> tokenize(String text)
    {

        Collection<Token> tokens = new ArrayList<Token>();

        Collection<Emit> collectedEmits = parseText(text);
        // 下面是最长分词的关键
        IntervalTree intervalTree = new IntervalTree((List<Intervalable>) (List<?>) collectedEmits);
        intervalTree.removeOverlaps((List<Intervalable>) (List<?>) collectedEmits);
        // 移除结束

        int lastCollectedPosition = -1;
        for (Emit emit : collectedEmits)
        {
            if (emit.getStart() - lastCollectedPosition > 1)
            {
                tokens.add(createFragment(emit, text, lastCollectedPosition));
            }
            tokens.add(createMatch(emit, text));
            lastCollectedPosition = emit.getEnd();
        }
        if (text.length() - lastCollectedPosition > 1)
        {
            tokens.add(createFragment(null, text, lastCollectedPosition));
        }

        return tokens;
    }"
"public static JavaRDD<LabeledPoint> fromBinary(JavaRDD<Tuple2<String, PortableDataStream>> binaryFiles,
                    final RecordReader reader) {
        return fromBinary(JavaPairRDD.fromJavaRDD(binaryFiles), reader);
    }"
"public static <T> T invoke(String classNameWithMethodName, boolean isSingleton, Object... args) {
		if (StrUtil.isBlank(classNameWithMethodName)) {
			throw new UtilException(""Blank classNameDotMethodName!"");
		}

		int splitIndex = classNameWithMethodName.lastIndexOf('#');
		if (splitIndex <= 0) {
			splitIndex = classNameWithMethodName.lastIndexOf('.');
		}
		if (splitIndex <= 0) {
			throw new UtilException(""Invalid classNameWithMethodName [{}]!"", classNameWithMethodName);
		}

		final String className = classNameWithMethodName.substring(0, splitIndex);
		final String methodName = classNameWithMethodName.substring(splitIndex + 1);

		return invoke(className, methodName, isSingleton, args);
	}"
"private static <T, F> FieldAugment<T, F> tryCreateReflectionAugment(Class<T> type, Class<? super F> fieldType, String name, F defaultValue) {
		Field f = findField(type, fieldType, name);
		if (f != null && typeIsAssignmentCompatible(f.getType(), fieldType)) return new ReflectionFieldAugment<T, F>(f, fieldType, defaultValue);
		return null;
	}"
"boolean isDisplayNameUnique(String displayName, String currentJobName) {
        Collection<TopLevelItem> itemCollection = items.values();

        // if there are a lot of projects, we'll have to store their
        // display names in a HashSet or something for a quick check
        for(TopLevelItem item : itemCollection) {
            if(item.getName().equals(currentJobName)) {
                // we won't compare the candidate displayName against the current
                // item. This is to prevent an validation warning if the user
                // sets the displayName to what the existing display name is
                continue;
            }
            else if(displayName.equals(item.getDisplayName())) {
                return false;
            }
        }

        return true;
    }"
"public static Collection<Integer> appendRange(int start, int stop, int step, Collection<Integer> values) {
		if (start < stop) {
			step = Math.abs(step);
		} else if (start > stop) {
			step = -Math.abs(step);
		} else {// start == end
			values.add(start);
			return values;
		}

		for (int i = start; (step > 0) ? i <= stop : i >= stop; i += step) {
			values.add(i);
		}
		return values;
	}"
"public void unjarDir(File jarFile, File destDir) throws IOException {
		BufferedOutputStream dest = null;
		FileInputStream fis = new FileInputStream(jarFile);
		unjar(fis, destDir);
	}"
"public CsvData read(File file, Charset charset) throws IORuntimeException {
		return read(Objects.requireNonNull(file.toPath(), ""file must not be null""), charset);
	}"
"public void skipAll(final TokenType... tokenTypes) {
        Set<TokenType> tokenTypeSet = Sets.newHashSet(tokenTypes);
        while (tokenTypeSet.contains(lexer.getCurrentToken().getType())) {
            lexer.nextToken();
        }
    }"
"@Override public void onAck() {
    if( _val != null ) {        // Set transient fields after deserializing
      assert !_xkey.home() && _val._key == null;
      _val._key = _xkey;
    }
    // Now update the local store, caching the result.

    // We only started down the TGK path because we missed locally, so we only
    // expect to find a NULL in the local store.  If somebody else installed
    // another value (e.g. a racing TGK, or racing local Put) this value must
    // be more recent than our NULL - but is UNORDERED relative to the Value
    // returned from the Home.  We'll take the local Value to preserve ordering
    // and rely on invalidates from Home to force refreshes as needed.

    // Hence we can do a blind putIfMatch here over a null or empty Value
    // If it fails, what is there is also the TGK result.
    Value old = H2O.STORE.get(_xkey);
    if( old != null && !old.isEmpty() ) old=null;
    Value res = H2O.putIfMatch(_xkey,_val,old);
    if( res != old ) _val = res;
    TGKS.remove(_xkey); // Clear from dup cache
  }"
"private void clearExceptionalCompletion() {
        int h = System.identityHashCode(this);
        final ReentrantLock lock = exceptionTableLock;
        lock.lock();
        try {
            ExceptionNode[] t = exceptionTable;
            int i = h & (t.length - 1);
            ExceptionNode e = t[i];
            ExceptionNode pred = null;
            while (e != null) {
                ExceptionNode next = e.next;
                if (e.get() == this) {
                    if (pred == null)
                        t[i] = next;
                    else
                        pred.next = next;
                    break;
                }
                pred = e;
                e = next;
            }
            expungeStaleExceptions();
            status = 0;
        } finally {
            lock.unlock();
        }
    }"
"public final ChannelFuture spliceTo(final FileDescriptor ch, final int offset, final int len) {
        return spliceTo(ch, offset, len, newPromise());
    }"
"public Expression longToIntForHashCode(Expression ref1, Expression ref2, ASTNode source) {
		int pS = source.sourceStart, pE = source.sourceEnd;
		/* (int)(ref >>> 32 ^ ref) */
		IntLiteral int32 = makeIntLiteral(""32"".toCharArray(), source);
		BinaryExpression higherBits = new BinaryExpression(ref1, int32, OperatorIds.UNSIGNED_RIGHT_SHIFT);
		setGeneratedBy(higherBits, source);
		BinaryExpression xorParts = new BinaryExpression(ref2, higherBits, OperatorIds.XOR);
		setGeneratedBy(xorParts, source);
		TypeReference intRef = TypeReference.baseTypeReference(TypeIds.T_int, 0);
		intRef.sourceStart = pS; intRef.sourceEnd = pE;
		setGeneratedBy(intRef, source);
		CastExpression expr = makeCastExpression(xorParts, intRef, source);
		expr.sourceStart = pS; expr.sourceEnd = pE;
		return expr;
	}"
"@Deprecated
    public static Date getDateHeader(HttpMessage message, CharSequence name) throws ParseException {
        String value = message.headers().get(name);
        if (value == null) {
            throw new ParseException(""header not found: "" + name, 0);
        }
        Date date = DateFormatter.parseHttpDate(value);
        if (date == null) {
            throw new ParseException(""header can't be parsed into a Date: "" + value, 0);
        }
        return date;
    }"
"private void setExcludeFromProxyUrls() {
		List<String> fullList = new ArrayList<>();
		fullList.addAll(this.excludeFromProxyRegexs);
		fullList.addAll(getGlobalExcludeURLRegexs());

		Control.getSingleton().setExcludeFromProxyUrls(fullList);
	}"
"public final void setBackgroundImage(URL imageUrl) {
        if (imageUrl != null) {
            try {
                img = ImageIO.read(imageUrl);
                
            } catch (IOException ioe) {
                // do nothing
            }
        }        
    }"
"public int find(String what, int start) {
        try {
            ByteBuffer src = ByteBuffer.wrap(this.bytes, 0, this.length);
            ByteBuffer tgt = encode(what);
            byte b = tgt.get();
            src.position(start);

            while (src.hasRemaining()) {
                if (b == src.get()) { // matching first byte
                    src.mark(); // save position in loop
                    tgt.mark(); // save position in target
                    boolean found = true;
                    int pos = src.position() - 1;
                    while (tgt.hasRemaining()) {
                        if (!src.hasRemaining()) { // src expired first
                            tgt.reset();
                            src.reset();
                            found = false;
                            break;
                        }
                        if (!(tgt.get() == src.get())) {
                            tgt.reset();
                            src.reset();
                            found = false;
                            break; // no match
                        }
                    }
                    if (found)
                        return pos;
                }
            }
            return -1; // not found
        } catch (CharacterCodingException e) {
            // can't get here
            e.printStackTrace();
            return -1;
        }
    }"
"public void setPathScore(Term from, Map<String, Double> relationMap) {
        // 维特比进行最优路径的构建
        double score = MathUtil.compuScore(from, this, relationMap);
        if (this.from == null || this.score == 0 || this.score >= score) {
            this.setFromAndScore(from, score);
        }
    }"
"public static boolean isFieldDeprecated(JavacNode field) {
		if (!(field.get() instanceof JCVariableDecl)) return false;
		JCVariableDecl fieldNode = (JCVariableDecl) field.get();
		if ((fieldNode.mods.flags & Flags.DEPRECATED) != 0) {
			return true;
		}
		for (JavacNode child : field.down()) {
			if (annotationTypeMatches(Deprecated.class, child)) {
				return true;
			}
		}
		return false;
	}"
"protected void updatePeerEurekaNodes(List<String> newPeerUrls) {
        if (newPeerUrls.isEmpty()) {
            logger.warn(""The replica size seems to be empty. Check the route 53 DNS Registry"");
            return;
        }

        Set<String> toShutdown = new HashSet<>(peerEurekaNodeUrls);
        toShutdown.removeAll(newPeerUrls);
        Set<String> toAdd = new HashSet<>(newPeerUrls);
        toAdd.removeAll(peerEurekaNodeUrls);

        if (toShutdown.isEmpty() && toAdd.isEmpty()) { // No change
            return;
        }

        // Remove peers no long available
        List<PeerEurekaNode> newNodeList = new ArrayList<>(peerEurekaNodes);

        if (!toShutdown.isEmpty()) {
            logger.info(""Removing no longer available peer nodes {}"", toShutdown);
            int i = 0;
            while (i < newNodeList.size()) {
                PeerEurekaNode eurekaNode = newNodeList.get(i);
                if (toShutdown.contains(eurekaNode.getServiceUrl())) {
                    newNodeList.remove(i);
                    eurekaNode.shutDown();
                } else {
                    i++;
                }
            }
        }

        // Add new peers
        if (!toAdd.isEmpty()) {
            logger.info(""Adding new peer nodes {}"", toAdd);
            for (String peerUrl : toAdd) {
                newNodeList.add(createPeerEurekaNode(peerUrl));
            }
        }

        this.peerEurekaNodes = newNodeList;
        this.peerEurekaNodeUrls = new HashSet<>(newPeerUrls);
    }"
"protected char[] getPasswordFromCredentialProviders(String name)
      throws IOException {
    char[] pass = null;
    try {
      List<CredentialProvider> providers =
          CredentialProviderFactory.getProviders(this);

      if (providers != null) {
        for (CredentialProvider provider : providers) {
          try {
            CredentialEntry entry = provider.getCredentialEntry(name);
            if (entry != null) {
              pass = entry.getCredential();
              break;
            }
          }
          catch (IOException ioe) {
            throw new IOException(""Can't get key "" + name + "" from key provider"" +
            		""of type: "" + provider.getClass().getName() + ""."", ioe);
          }
        }
      }
    }
    catch (IOException ioe) {
      throw new IOException(""Configuration problem with provider path."", ioe);
    }

    return pass;
  }"
"public <T> T get(K key, Class<T> type) throws ConvertException{
		return get(key, type, false);
	}"
"public SDVariable log(String name, SDVariable in, double base) {
        validateNumerical(""log"", in);
        SDVariable ret = f().log(in, base);
        return updateVariableNameAndReference(ret, name);
    }"
"@SuppressWarnings(""deprecation"")
	@Override
	public JobGraph getJobGraph(@Nullable JobID jobID) {
		// temporarily forbid checkpointing for iterative jobs
		if (isIterative() && checkpointConfig.isCheckpointingEnabled() && !checkpointConfig.isForceCheckpointing()) {
			throw new UnsupportedOperationException(
				""Checkpointing is currently not supported by default for iterative jobs, as we cannot guarantee exactly once semantics. ""
					+ ""State checkpoints happen normally, but records in-transit during the snapshot will be lost upon failure. ""
					+ ""\nThe user can force enable state checkpoints with the reduced guarantees by calling: env.enableCheckpointing(interval,true)"");
		}

		return StreamingJobGraphGenerator.createJobGraph(this, jobID);
	}"
"private static void write2frame(GenericRecord gr, String[] columnNames, Schema.Field[] inSchema, byte[] columnTypes, ParseWriter dout) {
    assert inSchema.length == columnTypes.length : ""AVRO field flatenized schema has to match to parser setup"";
    BufferedString bs = new BufferedString();
    for (int cIdx = 0; cIdx < columnNames.length; cIdx++) {
      int inputFieldIdx = inSchema[cIdx].pos();
      Schema.Type inputType = toPrimitiveType(inSchema[cIdx].schema());
      byte targetType = columnTypes[cIdx]; // FIXME: support target conversions
      Object value = gr.get(inputFieldIdx);
      if (value == null) {
        dout.addInvalidCol(cIdx);
      } else {
        switch (inputType) {
          case BOOLEAN:
            dout.addNumCol(cIdx, ((Boolean) value) ? 1 : 0);
            break;
          case INT:
            dout.addNumCol(cIdx, ((Integer) value), 0);
            break;
          case LONG:
            dout.addNumCol(cIdx, ((Long) value), 0);
            break;
          case FLOAT:
            dout.addNumCol(cIdx, (Float) value);
            break;
          case DOUBLE:
            dout.addNumCol(cIdx, (Double) value);
            break;
          case ENUM:
            // Note: this code expects ordering of categoricals provided by Avro remain same
            // as in H2O!!!
            GenericData.EnumSymbol es = (GenericData.EnumSymbol) value;
            dout.addNumCol(cIdx, es.getSchema().getEnumOrdinal(es.toString()));
            break;
          case BYTES:
            dout.addStrCol(cIdx, bs.set(((ByteBuffer) value).array()));
            break;
          case STRING:
            dout.addStrCol(cIdx, bs.set(((Utf8) value).getBytes()));
            break;
          case NULL:
            dout.addInvalidCol(cIdx);
            break;
        }
      }
    }
  }"
"public Pair<Double, INDArray> hBeta(INDArray d, double beta) {
        INDArray P = exp(d.neg().muli(beta));
        double sumP = P.sumNumber().doubleValue();
        double logSumP = FastMath.log(sumP);
        Double H = logSumP + ((beta * (d.mul(P).sumNumber().doubleValue())) / sumP);
        P.divi(sumP);
        return new Pair<>(H, P);
    }"
"public static <E extends Enum<E>> E getOptionalEnumParam(JSONObject params, String paramName,
			Class<E> enumType) throws ApiException {
		String enumValS = params.optString(paramName, null);
		E enumVal = null;
		if (enumValS != null && !enumValS.isEmpty()) {
			try {
				enumVal = Enum.valueOf(enumType, enumValS);
			} catch (Exception ex) {
				throw new ApiException(ApiException.Type.ILLEGAL_PARAMETER, paramName + "": ""
						+ ex.getLocalizedMessage());
			}
		}
		return enumVal;
	}"
"private static boolean isFirstTime() {
        Path acceptedLicenseFile = Paths.get(Constant.getInstance().ACCEPTED_LICENSE);
        return Files.notExists(acceptedLicenseFile);
    }"
"public static INDArray normalizeZeroMeanAndUnitVariance(INDArray toNormalize) {
        INDArray columnMeans = toNormalize.mean(0);
        INDArray columnStds = toNormalize.std(0);

        toNormalize.subiRowVector(columnMeans);
        //padding for non zero
        columnStds.addi(Nd4j.EPS_THRESHOLD);
        toNormalize.diviRowVector(columnStds);
        return toNormalize;
    }"
"public static void putServiceIntoFlowScope(final RequestContext context, final Service service) {
        context.getFlowScope().put(PARAMETER_SERVICE, service);
    }"
"public static @Nonnull <U> U lookupSingleton(Class<U> type) {
        ExtensionList<U> all = lookup(type);
        if (all.size() != 1) {
            throw new IllegalStateException(""Expected 1 instance of "" + type.getName() + "" but got "" + all.size());
        }
        return all.get(0);
    }"
"public static void putPublicWorkstationToFlowIfRequestParameterPresent(final RequestContext context) {
        if (StringUtils.isNotBlank(context.getExternalContext().getRequestParameterMap().get(PUBLIC_WORKSTATION_ATTRIBUTE))) {
            context.getFlowScope().put(PUBLIC_WORKSTATION_ATTRIBUTE, Boolean.TRUE);
        }
    }"
"@Nullable
    @ThriftField(value = 1, requiredness = OPTIONAL)
    public Map<String, PrestoThriftDomain> getDomains()
    {
        return domains;
    }"
"public void register(final SelectableChannel ch, final int interestOps, final NioTask<?> task) {
        if (ch == null) {
            throw new NullPointerException(""ch"");
        }
        if (interestOps == 0) {
            throw new IllegalArgumentException(""interestOps must be non-zero."");
        }
        if ((interestOps & ~ch.validOps()) != 0) {
            throw new IllegalArgumentException(
                    ""invalid interestOps: "" + interestOps + ""(validOps: "" + ch.validOps() + ')');
        }
        if (task == null) {
            throw new NullPointerException(""task"");
        }

        if (isShutdown()) {
            throw new IllegalStateException(""event loop shut down"");
        }

        if (inEventLoop()) {
            register0(ch, interestOps, task);
        } else {
            try {
                // Offload to the EventLoop as otherwise java.nio.channels.spi.AbstractSelectableChannel.register
                // may block for a long time while trying to obtain an internal lock that may be hold while selecting.
                submit(new Runnable() {
                    @Override
                    public void run() {
                        register0(ch, interestOps, task);
                    }
                }).sync();
            } catch (InterruptedException ignore) {
                // Even if interrupted we did schedule it so just mark the Thread as interrupted.
                Thread.currentThread().interrupt();
            }
        }
    }"
"public static TumblingProcessingTimeWindows of(Time size, Time offset) {
		return new TumblingProcessingTimeWindows(size.toMilliseconds(), offset.toMilliseconds());
	}"
"@Override
	public void close() throws Exception {
		// flag this as not running any more
		isRunning = false;

		// clean up in locked scope, so there is no concurrent change to the stream and client
		synchronized (lock) {
			// we notify first (this statement cannot fail). The notified thread will not continue
			// anyways before it can re-acquire the lock
			lock.notifyAll();

			try {
				if (outputStream != null) {
					outputStream.close();
				}
			}
			finally {
				if (client != null) {
					client.close();
				}
			}
		}
	}"
"@Override
    public long getAllocatedHostObjects() {
        AtomicLong counter = new AtomicLong(0);
        for (Long threadId : zeroAllocations.keySet()) {
            counter.addAndGet(zeroAllocations.get(threadId).size());
        }
        return counter.get();
    }"
"@Autowired
    @RefreshScope
    @Bean
    public IgniteConfiguration igniteConfiguration(@Qualifier(""ticketCatalog"") final TicketCatalog ticketCatalog) {
        val ignite = casProperties.getTicket().getRegistry().getIgnite();

        val config = new IgniteConfiguration();
        val spi = new TcpDiscoverySpi();

        if (!StringUtils.isEmpty(ignite.getLocalAddress())) {
            spi.setLocalAddress(ignite.getLocalAddress());
        }
        if (ignite.getLocalPort() != -1) {
            spi.setLocalPort(ignite.getLocalPort());
        }
        spi.setJoinTimeout(Beans.newDuration(ignite.getJoinTimeout()).toMillis());
        spi.setAckTimeout(Beans.newDuration(ignite.getAckTimeout()).toMillis());
        spi.setNetworkTimeout(Beans.newDuration(ignite.getNetworkTimeout()).toMillis());
        spi.setSocketTimeout(Beans.newDuration(ignite.getSocketTimeout()).toMillis());
        spi.setThreadPriority(ignite.getThreadPriority());
        spi.setForceServerMode(ignite.isForceServerMode());

        val finder = new TcpDiscoveryVmIpFinder();
        finder.setAddresses(ignite.getIgniteAddress());
        spi.setIpFinder(finder);
        config.setDiscoverySpi(spi);
        val cacheConfigurations = buildIgniteTicketCaches(ignite, ticketCatalog);
        config.setCacheConfiguration(cacheConfigurations.toArray(CacheConfiguration[]::new));
        config.setClientMode(ignite.isClientMode());

        val factory = buildSecureTransportForIgniteConfiguration();
        if (factory != null) {
            config.setSslContextFactory(factory);
        }

        val dataStorageConfiguration = new DataStorageConfiguration();
        val dataRegionConfiguration = new DataRegionConfiguration();
        dataRegionConfiguration.setName(""DefaultRegion"");
        dataRegionConfiguration.setMaxSize(ignite.getDefaultRegionMaxSize());
        dataRegionConfiguration.setPersistenceEnabled(ignite.isDefaultPersistenceEnabled());
        dataStorageConfiguration.setDefaultDataRegionConfiguration(dataRegionConfiguration);

        dataStorageConfiguration.setSystemRegionMaxSize(ignite.getDefaultRegionMaxSize());
        config.setDataStorageConfiguration(dataStorageConfiguration);

        if (LOGGER.isDebugEnabled()) {
            LOGGER.debug(""igniteConfiguration.cacheConfiguration=[{}]"", (Object[]) config.getCacheConfiguration());
            LOGGER.debug(""igniteConfiguration.getDiscoverySpi=[{}]"", config.getDiscoverySpi());
            LOGGER.debug(""igniteConfiguration.getSslContextFactory=[{}]"", config.getSslContextFactory());
        }

        return config;
    }"
"public double getDouble(String key, double defaultValue) {
		Object o = getRawValue(key);
		if (o == null) {
			return defaultValue;
		}

		return convertToDouble(o, defaultValue);
	}"
"protected Response handleRequest() {
		ResponseBuilder builder = null;
		/* ensure we aren't allowing more connections than we want */
		int numberConnections = getCurrentConnections().get();
		int maxNumberConnectionsAllowed = getMaxNumberConcurrentConnectionsAllowed(); // may change at runtime, so look this up for each request
		if (numberConnections >= maxNumberConnectionsAllowed) {
			builder = Response.status(Status.SERVICE_UNAVAILABLE).entity(""MaxConcurrentConnections reached: "" + maxNumberConnectionsAllowed);
		} else {
			/* initialize response */
			builder = Response.status(Status.OK);
			builder.header(HttpHeaders.CONTENT_TYPE, ""text/event-stream;charset=UTF-8"");
			builder.header(HttpHeaders.CACHE_CONTROL, ""no-cache, no-store, max-age=0, must-revalidate"");
			builder.header(""Pragma"", ""no-cache"");
			getCurrentConnections().incrementAndGet();
			builder.entity(new HystrixStream(sampleStream, pausePollerThreadDelayInMs, getCurrentConnections()));
		}
		return builder.build();

	}"
"@Override
  public UnsafeRow getKeyRow(int rowId) {
    assert(rowId >= 0);
    assert(rowId < numRows);
    if (keyRowId != rowId) { // if keyRowId == rowId, desired keyRow is already cached
      long offset = getKeyOffsetForFixedLengthRecords(rowId);
      keyRow.pointTo(base, offset, klen);
      // set keyRowId so we can check if desired row is cached
      keyRowId = rowId;
    }
    return keyRow;
  }"
"@Override
  public String getHomeDirectory() {
    try {
      FileSystem fs = FileSystem.get(CONF);
      return fs.getHomeDirectory().toString();
    }
    catch (Exception e) {
      return null;
    }
  }"
"@Deprecated
    public static SslContext newServerContext(
            SslProvider provider,
            File certChainFile, File keyFile, String keyPassword,
            Iterable<String> ciphers, Iterable<String> nextProtocols,
            long sessionCacheSize, long sessionTimeout) throws SSLException {
        return newServerContext(provider, certChainFile, keyFile, keyPassword,
                                ciphers, IdentityCipherSuiteFilter.INSTANCE,
                                toApplicationProtocolConfig(nextProtocols), sessionCacheSize, sessionTimeout);
    }"
"private SingularData getSingularData(EclipseNode node, ASTNode source) {
		for (EclipseNode child : node.down()) {
			if (!annotationTypeMatches(Singular.class, child)) continue;
			
			char[] pluralName = node.getKind() == Kind.FIELD ? removePrefixFromField(node) : ((AbstractVariableDeclaration) node.get()).name;
			AnnotationValues<Singular> ann = createAnnotation(Singular.class, child);
			String explicitSingular = ann.getInstance().value();
			if (explicitSingular.isEmpty()) {
				if (Boolean.FALSE.equals(node.getAst().readConfiguration(ConfigurationKeys.SINGULAR_AUTO))) {
					node.addError(""The singular must be specified explicitly (e.g. @Singular(\""task\"")) because auto singularization is disabled."");
					explicitSingular = new String(pluralName);
				} else {
					explicitSingular = autoSingularize(new String(pluralName));
					if (explicitSingular == null) {
						node.addError(""Can't singularize this name; please specify the singular explicitly (i.e. @Singular(\""sheep\""))"");
						explicitSingular = new String(pluralName);
					}
				}
			}
			char[] singularName = explicitSingular.toCharArray();
			
			TypeReference type = ((AbstractVariableDeclaration) node.get()).type;
			TypeReference[] typeArgs = null;
			String typeName;
			if (type instanceof ParameterizedSingleTypeReference) {
				typeArgs = ((ParameterizedSingleTypeReference) type).typeArguments;
				typeName = new String(((ParameterizedSingleTypeReference) type).token);
			} else if (type instanceof ParameterizedQualifiedTypeReference) {
				TypeReference[][] tr = ((ParameterizedQualifiedTypeReference) type).typeArguments;
				if (tr != null) typeArgs = tr[tr.length - 1];
				char[][] tokens = ((ParameterizedQualifiedTypeReference) type).tokens;
				StringBuilder sb = new StringBuilder();
				for (int i = 0; i < tokens.length; i++) {
					if (i > 0) sb.append(""."");
					sb.append(tokens[i]);
				}
				typeName = sb.toString();
			} else {
				typeName = type.toString();
			}
			
			String targetFqn = EclipseSingularsRecipes.get().toQualified(typeName);
			EclipseSingularizer singularizer = EclipseSingularsRecipes.get().getSingularizer(targetFqn);
			if (singularizer == null) {
				node.addError(""Lombok does not know how to create the singular-form builder methods for type '"" + typeName + ""'; they won't be generated."");
				return null;
			}
			
			return new SingularData(child, singularName, pluralName, typeArgs == null ? Collections.<TypeReference>emptyList() : Arrays.asList(typeArgs), targetFqn, singularizer, source);
		}
		
		return null;
	}"
"public Class forceLoadSystemClass(String classname) throws ClassNotFoundException {
        log(""force system loading "" + classname, Project.MSG_DEBUG);

        Class theClass = findLoadedClass(classname);

        if (theClass == null) {
            theClass = findBaseClass(classname);
        }
        return theClass;
    }"
"@Override
    protected byte[] load(ConfidentialKey key) throws IOException {
        try {
            File f = getFileFor(key);
            if (!f.exists())    return null;

            Cipher sym = Secret.getCipher(""AES"");
            sym.init(Cipher.DECRYPT_MODE, masterKey);
            try (InputStream fis=Files.newInputStream(f.toPath());
                 CipherInputStream cis = new CipherInputStream(fis, sym)) {
                byte[] bytes = IOUtils.toByteArray(cis);
                return verifyMagic(bytes);
            }
        } catch (GeneralSecurityException e) {
            throw new IOException(""Failed to load the key: ""+key.getId(),e);
        } catch (InvalidPathException e) {
            throw new IOException(e);
        } catch (IOException x) {
            if (x.getCause() instanceof BadPaddingException) {
                return null; // broken somehow
            } else {
                throw x;
            }
        }
    }"
"public void add(String string) {
    elements.add(string == null ? JsonNull.INSTANCE : new JsonPrimitive(string));
  }"
"public InputType getOutputType(InputType... inputType) throws InvalidKerasConfigurationException {
        if (inputType.length > 1)
            throw new InvalidKerasConfigurationException(
                    ""Keras PReLU layer accepts only one input (received "" + inputType.length + "")"");
        InputType inType = inputType[0];

        // Dynamically infer input shape of PReLU layer from input type
        PReLULayer shapedLayer = (PReLULayer) this.layer;
        shapedLayer.setInputShape(inType.getShape());
        this.layer = shapedLayer;

        return this.getPReLULayer().getOutputType(-1, inputType[0]);
    }"
"protected synchronized Map<String,INDArray> ffToLayerActivationsInWS(boolean train, int layerIndex, int[] excludeIdxs,
                                                            FwdPassType fwdPassType, boolean storeLastForTBPTT,
                                                            INDArray[] input, INDArray[] fMask, INDArray[] lMask, boolean clearInputs) {
        if(layerIndex != -1 && (layerIndex < 0 || layerIndex >= topologicalOrder.length)){
            throw new IllegalArgumentException(""Invalid input index - index must be >= 0 and < "" + topologicalOrder.length
                    + "", got index "" + layerIndex);
        }
        setInputs(input);
        setLayerMaskArrays(fMask, lMask);

        LayerWorkspaceMgr workspaceMgr;
        WorkspaceMode wsm = (train ? configuration.getTrainingWorkspaceMode() : configuration.getInferenceWorkspaceMode());
        if(wsm == WorkspaceMode.NONE){
            //Verify that no workspace is open externally
            WorkspaceUtils.assertNoWorkspacesOpen(""Expected no workspace active in ffToLayerActivationsDetached"", true);

            workspaceMgr = LayerWorkspaceMgr.noWorkspaces();
        } else {
            WorkspaceUtils.assertOpenAndActive(WS_ALL_LAYERS_ACT, ""ffToLayerActivationsInWs method requires workspace WS_ALL_LAYERS_ACT to be open"");

            workspaceMgr = LayerWorkspaceMgr.builder()
                    .with(ArrayType.ACTIVATIONS, WS_ALL_LAYERS_ACT, WS_ALL_LAYERS_ACT_CONFIG)
                    .with(ArrayType.INPUT, WS_ALL_LAYERS_ACT, WS_ALL_LAYERS_ACT_CONFIG)
                    .with(ArrayType.FF_WORKING_MEM, WS_LAYER_WORKING_MEM, WS_LAYER_WORKING_MEM_CONFIG)
                    .with(ArrayType.RNN_FF_LOOP_WORKING_MEM, WS_RNN_LOOP_WORKING_MEM, WS_RNN_LOOP_WORKING_MEM_CONFIG)
                    .build();

            if(input[0].isAttached()){
                //Don't leverage out of async DataMultiSetIterator workspaces
                workspaceMgr.setNoLeverageOverride(input[0].data().getParentWorkspace().getId());
            }

            if(configuration.getCacheMode() != CacheMode.NONE){
                //For now: store cache mode activations in activations workspace
                workspaceMgr.setWorkspace(ArrayType.FF_CACHE, WS_ALL_LAYERS_ACT, WS_ALL_LAYERS_ACT_CONFIG);
            }
        }
        workspaceMgr.setHelperWorkspacePointers(helperWorkspaces);

        Map<String, INDArray> activations = new HashMap<>();
        //Do forward pass according to the topological ordering of the network
        int stopIndex;
        if (layerIndex > 0) {
            stopIndex = ArrayUtils.indexOf(topologicalOrder, layerIndex);
        } else {
            stopIndex = topologicalOrder.length -1;
        }
        for (int i = 0; i <= stopIndex; i++) {
            GraphVertex current = vertices[topologicalOrder[i]];
            String vName = current.getVertexName();
            int vIdx = current.getVertexIndex();

            if(excludeIdxs != null && ArrayUtils.contains(excludeIdxs, vIdx)){
                continue;
            }

            try(MemoryWorkspace wsFFWorking = workspaceMgr.notifyScopeEntered(ArrayType.FF_WORKING_MEM)){
                VertexIndices[] inputsTo = current.getOutputVertices();

                INDArray out;
                if(current.isInputVertex()){
                    out = inputs[vIdx];
                } else {

                    if(fwdPassType == FwdPassType.STANDARD){
                        out = current.doForward(train, workspaceMgr);
                    } else if(fwdPassType == FwdPassType.RNN_ACTIVATE_WITH_STORED_STATE) {
                        if (current.hasLayer()) {
                            Layer l = current.getLayer();
                            if (l instanceof RecurrentLayer) {
                                out = ((RecurrentLayer) l).rnnActivateUsingStoredState(current.getInputs()[0], train,
                                        storeLastForTBPTT, workspaceMgr);
                            } else if(l instanceof org.deeplearning4j.nn.layers.wrapper.BaseWrapperLayer && ((org.deeplearning4j.nn.layers.wrapper.BaseWrapperLayer)l).getUnderlying() instanceof RecurrentLayer) {
                                RecurrentLayer rl = (RecurrentLayer) ((org.deeplearning4j.nn.layers.wrapper.BaseWrapperLayer)l).getUnderlying();
                                out = rl.rnnActivateUsingStoredState(current.getInputs()[0], train,storeLastForTBPTT, workspaceMgr);
                            } else if (l instanceof MultiLayerNetwork) {
                                List<INDArray> temp = ((MultiLayerNetwork) l).rnnActivateUsingStoredState(
                                        current.getInputs()[0], train, storeLastForTBPTT);
                                out = temp.get(temp.size() - 1);
                            } else {
                                //non-recurrent layer
                                out = current.doForward(train, workspaceMgr);
                            }
                        } else {
                            out = current.doForward(train, workspaceMgr);
                        }
                    } else {
                        throw new IllegalStateException(""FwdPassType not supported for this method: "" + fwdPassType);
                    }

                    validateArrayWorkspaces(workspaceMgr, out, ArrayType.ACTIVATIONS, vName, false, ""Feed forward (inference)"");
                }
                activations.put(current.getVertexName(), out);

                if(inputsTo != null) {
                    //Can be null for output layers
                    for (VertexIndices v : inputsTo) {
                        //Note that we don't have to do anything special here: the activations are always detached in
                        // this method
                        int inputToIndex = v.getVertexIndex();
                        int vIdxEdge = v.getVertexEdgeNumber();
                        vertices[inputToIndex].setInput(vIdxEdge, out, workspaceMgr);
                    }
                }

                if(clearInputs) {
                    current.clear();
                }
            }
        }
        return activations;
    }"
"@Override
  public void cancelFlow(final ExecutableFlow exFlow, final String userId)
      throws ExecutorManagerException {
    synchronized (exFlow) {
      if (this.runningExecutions.get().containsKey(exFlow.getExecutionId())) {
        final Pair<ExecutionReference, ExecutableFlow> pair =
            this.runningExecutions.get().get(exFlow.getExecutionId());
        this.apiGateway.callWithReferenceByUser(pair.getFirst(), ConnectorParams.CANCEL_ACTION,
            userId);
      } else if (this.queuedFlows.hasExecution(exFlow.getExecutionId())) {
        this.queuedFlows.dequeue(exFlow.getExecutionId());
        this.executionFinalizer
            .finalizeFlow(exFlow, ""Cancelled before dispatching to executor"", null);
      } else {
        throw new ExecutorManagerException(""Execution ""
            + exFlow.getExecutionId() + "" of flow "" + exFlow.getFlowId()
            + "" isn't running."");
      }
    }
  }"
"protected List<HistoryReference> getSelectedHistoryReferences(HttpMessageContainer httpMessageContainer) {
        if (httpMessageContainer instanceof SelectableHistoryReferencesContainer) {
            return ((SelectableHistoryReferencesContainer) httpMessageContainer).getSelectedHistoryReferences();
        } else if (httpMessageContainer instanceof SingleHistoryReferenceContainer) {
            SingleHistoryReferenceContainer singleContainer = (SingleHistoryReferenceContainer) httpMessageContainer;
            if (!singleContainer.isEmpty()) {
                List<HistoryReference> selectedHistoryReferences = new ArrayList<>(1);
                selectedHistoryReferences.add(singleContainer.getHistoryReference());
                return selectedHistoryReferences;
            }
        }

        return Collections.emptyList();
    }"
"public static List<ApiImplementor> getAllImplementors() {
		List<ApiImplementor> imps = new ArrayList<>();
		
		ApiImplementor api;

		imps.add(new AlertAPI(null));

		api = new AntiCsrfAPI(null);
		api.addApiOptions(new AntiCsrfParam());
		imps.add(api);
		
		imps.add(new PassiveScanAPI(null));
		imps.add(new SearchAPI(null));

		api = new AutoUpdateAPI(null);
		api.addApiOptions(new OptionsParamCheckForUpdates());
		imps.add(api);

		api = new SpiderAPI(null);
		api.addApiOptions(new SpiderParam());
		imps.add(api);

		api = new CoreAPI(new ConnectionParam());
		imps.add(api);

		imps.add(new ParamsAPI(null));
		
		api = new ActiveScanAPI(null);
		api.addApiOptions(new ScannerParam());
		imps.add(api);

        imps.add(new ContextAPI());
		
		imps.add(new HttpSessionsAPI(null));
		
		imps.add(new BreakAPI(null));
		
		imps.add(new AuthenticationAPI(null));
		
		imps.add(new AuthorizationAPI());

		imps.add(new SessionManagementAPI(null));
		
		imps.add(new UsersAPI(null));
		
		imps.add(new ForcedUserAPI(null));

		imps.add(new ScriptAPI(null));

		api = new StatsAPI(null);
		api.addApiOptions(new StatsParam());
		imps.add(api);

		return imps;
	}"
"public static String concat(String baseName, String... appendName) {
		if (appendName.length == 0) {
			return baseName;
		}

		StringBuilder concatName = new StringBuilder();
		if (MoreStringUtil.endWith(baseName, Platforms.FILE_PATH_SEPARATOR_CHAR)) {
			concatName.append(baseName).append(appendName[0]);
		} else {
			concatName.append(baseName).append(Platforms.FILE_PATH_SEPARATOR_CHAR).append(appendName[0]);
		}

		if (appendName.length > 1) {
			for (int i = 1; i < appendName.length; i++) {
				concatName.append(Platforms.FILE_PATH_SEPARATOR_CHAR).append(appendName[i]);
			}
		}

		return concatName.toString();
	}"
"public static boolean regionMatches(final CharSequence cs, final boolean ignoreCase, final int csStart,
                                        final CharSequence string, final int start, final int length) {
        if (cs == null || string == null) {
            return false;
        }

        if (cs instanceof String && string instanceof String) {
            return ((String) cs).regionMatches(ignoreCase, csStart, (String) string, start, length);
        }

        if (cs instanceof AsciiString) {
            return ((AsciiString) cs).regionMatches(ignoreCase, csStart, string, start, length);
        }

        return regionMatchesCharSequences(cs, csStart, string, start, length,
                                            ignoreCase ? GeneralCaseInsensitiveCharEqualityComparator.INSTANCE :
                                                    DefaultCharEqualityComparator.INSTANCE);
    }"
"public void setTypes(Class<K> keyType, Class<V> valueType) {
    delegate.setTypes(keyType, valueType);
  }"
"public byte[] encrypt(String message, Charset charset) throws CryptoException {
		return crypt(StrUtil.bytes(message, charset));
	}"
"public void addParseFilter(ParseFilter filter) {
		log.debug(""Loading parse filter: "" + filter.getClass().getSimpleName());
		parseFilters.add(filter);
	}"
"public static DateTime parseTime(String timeString) {
		timeString = normalize(timeString);
		return parse(timeString, DatePattern.NORM_TIME_FORMAT);
	}"
"public Postcard withFloat(@Nullable String key, float value) {
        mBundle.putFloat(key, value);
        return this;
    }"
"@Override
    public double getValue(double quantile) {
        if (quantile < 0.0 || quantile > 1.0 || Double.isNaN( quantile )) {
            throw new IllegalArgumentException(quantile + "" is not in [0..1]"");
        }

        if (values.length == 0) {
            return 0.0;
        }

        final double pos = quantile * (values.length + 1);
        final int index = (int) pos;

        if (index < 1) {
            return values[0];
        }

        if (index >= values.length) {
            return values[values.length - 1];
        }

        final double lower = values[index - 1];
        final double upper = values[index];
        return lower + (pos - floor(pos)) * (upper - lower);
    }"
"private String createZfsFileSystem(final TaskListener listener, String rootUsername, String rootPassword) throws IOException, InterruptedException, ZFSException {
        // capture the UID that Hudson runs under
        // so that we can allow this user to do everything on this new partition
        final int uid = LIBC.geteuid();
        final int gid = LIBC.getegid();
        passwd pwd = LIBC.getpwuid(uid);
        if(pwd==null)
            throw new IOException(""Failed to obtain the current user information for ""+uid);
        final String userName = pwd.pw_name;

        final File home = Jenkins.getInstance().getRootDir();

        // this is the actual creation of the file system.
        // return true indicating a success
        return SU.execute(listener, rootUsername, rootPassword, new Create(listener, home, uid, gid, userName));
    }"
"public void deleteTempDir(File file) {
    if (!shouldReap()) {
      return;
    }

    // If the tempfile can be removed, delete it. If not, it wasn't created by us.
    if (temporaryFiles.remove(file)) {
      FileHandler.delete(file);
    }
  }"
"public <K> UnsortedGrouping<T> groupBy(KeySelector<T, K> keyExtractor) {
		TypeInformation<K> keyType = TypeExtractor.getKeySelectorTypes(keyExtractor, getType());
		return new UnsortedGrouping<>(this, new Keys.SelectorFunctionKeys<>(clean(keyExtractor), getType(), keyType));
	}"
"public static String getMainStem(Long channelId, Long pipelineId) {
        return MessageFormat.format(ArbitrateConstants.NODE_PIPELINE_FORMAT,
            String.valueOf(channelId),
            String.valueOf(pipelineId))
               + ""/"" + ArbitrateConstants.NODE_MAINSTEM;
    }"
"public static String signSamlResponse(final String samlResponse, final PrivateKey privateKey, final PublicKey publicKey) {
        val doc = constructDocumentFromXml(samlResponse);

        if (doc != null) {
            val signedElement = signSamlElement(doc.getRootElement(),
                privateKey, publicKey);
            doc.setRootElement((org.jdom.Element) signedElement.detach());
            return new XMLOutputter().outputString(doc);
        }
        throw new IllegalArgumentException(""Error signing SAML Response: Null document"");
    }"
"public static Calendar truncate(Calendar calendar, DateField dateField) {
		return DateModifier.modify(calendar, dateField.getValue(), ModifyType.TRUNCATE);
	}"
"@Override
	protected void configure(ServletRegistration.Dynamic registration) {
		super.configure(registration);
		String[] urlMapping = StringUtils.toStringArray(this.urlMappings);
		if (urlMapping.length == 0 && this.alwaysMapUrl) {
			urlMapping = DEFAULT_MAPPINGS;
		}
		if (!ObjectUtils.isEmpty(urlMapping)) {
			registration.addMapping(urlMapping);
		}
		registration.setLoadOnStartup(this.loadOnStartup);
		if (this.multipartConfig != null) {
			registration.setMultipartConfig(this.multipartConfig);
		}
	}"
"@SuppressWarnings(""unchecked"")
	@Override
	public Object handle(ProceedingJoinPoint proceedingJoinPoint, io.github.resilience4j.retry.Retry retry, String methodName) throws Throwable {
		Object returnValue = proceedingJoinPoint.proceed();
		if (Flux.class.isAssignableFrom(returnValue.getClass())) {
			Flux<?> fluxReturnValue = (Flux<?>) returnValue;
			return fluxReturnValue.transform(RetryOperator.of(retry));
		} else if (Mono.class.isAssignableFrom(returnValue.getClass())) {
			Mono<?> monoReturnValue = (Mono<?>) returnValue;
			return monoReturnValue.transform(RetryOperator.of(retry));
		} else {
			logger.error(""Unsupported type for Reactor retry {}"", returnValue.getClass().getTypeName());
			throw new IllegalArgumentException(""Not Supported type for the retry in Reactor :"" + returnValue.getClass().getName());

		}
	}"
"@Override
	public void collect(IT record) {
		numRecordsIn.inc();
		try {
			if (base == null) {
				base = serializer.copy(record);
			} else {
				base = objectReuseEnabled ? reducer.reduce(base, record) : serializer.copy(reducer.reduce(base, record));
			}
		} catch (Exception e) {
			throw new ExceptionInChainedStubException(taskName, e);
		}
	}"
"public static @CheckForNull <T> T lookup(Class<T> type) {
        Jenkins j = Jenkins.getInstanceOrNull();
        return j != null ? j.lookup.get(type) : null;
    }"
"public boolean hasAbsentKeysOrValues() {
		for (Entry<String, KeyValue<K, V>> entry : underlyingMap.entrySet()) {
			if (keyOrValueIsAbsent(entry)) {
				return true;
			}
		}
		return false;
	}"
"@Override
    public void reset() {
        // just replace accumulator, gc will do the rest
        accumulator = new ThreadLocal<>();

        // resetting this counter too
        workersCounter.set(0);

        // reset indexes too
        index = new ThreadLocal<>();

        // throw away message queues
        for (int i = 0; i < parties; i++) {
            messages.get(i).clear();
        }
    }"
"public List<Invocation> find(List<?> mocks) {
        List<Invocation> unused = new LinkedList<Invocation>();
        for (Object mock : mocks) {
            List<Stubbing> fromSingleMock = MockUtil.getInvocationContainer(mock).getStubbingsDescending();
            for(Stubbing s : fromSingleMock) {
                if (!s.wasUsed()) {
                     unused.add(s.getInvocation());
                }
            }
        }
        return unused;
    }"
"protected void collectAttributeWithFilteredValues(final Map<String, List<Object>> attributesToRelease, final String attributeName,
                                                      final List<Object> filteredValues) {
        attributesToRelease.put(attributeName, filteredValues);
    }"
"private void kdf(ECPoint c1, byte[] encData) {
		final Digest digest = this.digest;
		int digestSize = digest.getDigestSize();
		byte[] buf = new byte[Math.max(4, digestSize)];
		int off = 0;

		Memoable memo = null;
		Memoable copy = null;

		if (digest instanceof Memoable) {
			addFieldElement(c1.getAffineXCoord());
			addFieldElement(c1.getAffineYCoord());
			memo = (Memoable) digest;
			copy = memo.copy();
		}

		int ct = 0;

		while (off < encData.length) {
			if (memo != null) {
				memo.reset(copy);
			} else {
				addFieldElement(c1.getAffineXCoord());
				addFieldElement(c1.getAffineYCoord());
			}

			Pack.intToBigEndian(++ct, buf, 0);
			digest.update(buf, 0, 4);
			digest.doFinal(buf, 0);

			int xorLen = Math.min(digestSize, encData.length - off);
			xor(encData, buf, off, xorLen);
			off += xorLen;
		}
	}"
"protected void createGatewayRequestCheckDecisionState(final Flow flow) {
        createDecisionState(flow, CasWebflowConstants.STATE_ID_GATEWAY_REQUEST_CHECK,
            ""requestParameters.gateway != '' and requestParameters.gateway != null and flowScope.service != null"",
            CasWebflowConstants.STATE_ID_GATEWAY_SERVICES_MGMT_CHECK,
            CasWebflowConstants.STATE_ID_SERVICE_AUTHZ_CHECK);
    }"
"public void setDefaultZone(List<URL> defaultZone) {
        this.defaultZone = defaultZone
            .stream()
            .map(uriMapper())
            .map(uri -> ServiceInstance.builder(getServiceID(), uri).build())
            .collect(Collectors.toList());
    }"
"public static InstanceFields declaredFieldsOf(Object instance) {
        List<InstanceField> instanceFields = new ArrayList<InstanceField>();
        instanceFields.addAll(instanceFieldsIn(instance, instance.getClass().getDeclaredFields()));
        return new InstanceFields(instance, instanceFields);
    }"
"protected final void clearReadPending() {
        if (isRegistered()) {
            EventLoop eventLoop = eventLoop();
            if (eventLoop.inEventLoop()) {
                readPending = false;
            } else {
                eventLoop.execute(clearReadPendingRunnable);
            }
        } else {
            // Best effort if we are not registered yet clear readPending. This happens during channel initialization.
            readPending = false;
        }
    }"
"public char next(char c) throws JSONException {
		char n = this.next();
		if (n != c) {
			throw this.syntaxError(""Expected '"" + c + ""' and instead saw '"" + n + ""'"");
		}
		return n;
	}"
"private void resetNextProxy(HttpUrl url, Proxy proxy) {
    if (proxy != null) {
      // If the user specifies a proxy, try that and only that.
      proxies = Collections.singletonList(proxy);
    } else {
      // Try each of the ProxySelector choices until one connection succeeds.
      List<Proxy> proxiesOrNull = address.proxySelector().select(url.uri());
      proxies = proxiesOrNull != null && !proxiesOrNull.isEmpty()
          ? Util.immutableList(proxiesOrNull)
          : Util.immutableList(Proxy.NO_PROXY);
    }
    nextProxyIndex = 0;
  }"
"public void setSelectedInternalItem(User user) {
		User internalUser = null;
		int index = getIndexOf(user);
		if (index != -1) {
			internalUser = getElementAt(index);
		} else if (getSize() > 0) {
			internalUser = getElementAt(0);
		}

		setSelectedItemImpl(internalUser);
	}"
"private int getColor(Point p1, Point p2) {
    float d = distance(p1, p2);
    float dx = (p2.getX() - p1.getX()) / d;
    float dy = (p2.getY() - p1.getY()) / d;
    int error = 0;

    float px = p1.getX();
    float py = p1.getY();

    boolean colorModel = image.get(p1.getX(), p1.getY());

    int iMax = (int) Math.ceil(d);
    for (int i = 0; i < iMax; i++) {
      px += dx;
      py += dy;
      if (image.get(MathUtils.round(px), MathUtils.round(py)) != colorModel) {
        error++;
      }
    }

    float errRatio = error / d;

    if (errRatio > 0.1f && errRatio < 0.9f) {
      return 0;
    }

    return (errRatio <= 0.1f) == colorModel ? 1 : -1;
  }"
"private JButton getHelpButton() {
        if (btnHelp == null) {
            btnHelp = new JButton();
            btnHelp.setBorder(null);
            btnHelp.setIcon(new ImageIcon(AbstractParamContainerPanel.class.getResource(""/resource/icon/16/201.png""))); // help icon
            btnHelp.addActionListener(getShowHelpAction());
            btnHelp.setToolTipText(Constant.messages.getString(""menu.help""));
        }
        
        return btnHelp;
    }"
"public static int extractYearMonth(TimeUnitRange range, int v) {
		switch (range) {
			case YEAR: return v / 12;
			case MONTH: return v % 12;
			case QUARTER: return (v % 12 + 2) / 3;
			default: throw new UnsupportedOperationException(""Unsupported TimeUnitRange: "" + range);
		}
	}"
"public static boolean isAtLeastMajorMinor(String version, int majorVersion, int minorVersion) {
        SemanticVersion semanticVersion = new SemanticVersion(version);
        return isAtLeastMajorMinorImpl(semanticVersion, majorVersion, minorVersion);
    }"
"public void addFeedbackEdge(StreamTransformation<F> transform) {

		if (transform.getParallelism() != this.getParallelism()) {
			throw new UnsupportedOperationException(
					""Parallelism of the feedback stream must match the parallelism of the original"" +
							"" stream. Parallelism of original stream: "" + this.getParallelism() +
							""; parallelism of feedback stream: "" + transform.getParallelism());
		}

		feedbackEdges.add(transform);
	}"
"@Override
	public void releaseMemory(int toRelease) throws IOException {
		checkArgument(toRelease > 0);

		for (ResultSubpartition subpartition : subpartitions) {
			toRelease -= subpartition.releaseMemory();

			// Only release as much memory as needed
			if (toRelease <= 0) {
				break;
			}
		}
	}"
"public static ByteBuf copiedBuffer(char[] array, Charset charset) {
        if (array == null) {
            throw new NullPointerException(""array"");
        }
        return copiedBuffer(array, 0, array.length, charset);
    }"
"public Sentence makeSentence(String[] words, String[] posTags, boolean rootFirst, boolean lowerCased)
    {
        ArrayList<Integer> tokens = new ArrayList<Integer>();
        ArrayList<Integer> tags = new ArrayList<Integer>();
        ArrayList<Integer> bc4 = new ArrayList<Integer>();
        ArrayList<Integer> bc6 = new ArrayList<Integer>();
        ArrayList<Integer> bcf = new ArrayList<Integer>();

        int i = 0;
        for (String word : words)
        {
            if (word.length() == 0)
                continue;
            String lowerCaseWord = word.toLowerCase();
            if (lowerCased)
                word = lowerCaseWord;

            int[] clusterIDs = clusterId(word);
            bcf.add(clusterIDs[0]);
            bc4.add(clusterIDs[1]);
            bc6.add(clusterIDs[2]);

            String pos = posTags[i];

            int wi = -1;
            if (wordId.containsKey(word))
                wi = wordId.get(word);

            int pi = -1;
            if (wordId.containsKey(pos))
                pi = wordId.get(pos);

            tokens.add(wi);
            tags.add(pi);

            i++;
        }

        if (!rootFirst)
        {
            tokens.add(0);
            tags.add(0);
            bcf.add(0);
            bc6.add(0);
            bc4.add(0);
        }

        return new Sentence(tokens, tags, bc4, bc6, bcf);
    }"
"public static void createFileBatchesSpark(JavaRDD<String> filePaths, final String rootOutputDir, final int batchSize, JavaSparkContext sc) {
        createFileBatchesSpark(filePaths, rootOutputDir, batchSize, sc.hadoopConfiguration());
    }"
"public AbstractProject<?,?> getRootProject() {
        if (this instanceof TopLevelItem) {
            return this;
        } else {
            ItemGroup p = this.getParent();
            if (p instanceof AbstractProject)
                return ((AbstractProject) p).getRootProject();
            return this;
        }
    }"
"private Transition getShowAnimation(DialogTransition transitionType) {
        Transition animation = null;
        if (contentHolder != null) {
            switch (transitionType) {
                case LEFT:
                    contentHolder.setScaleX(1);
                    contentHolder.setScaleY(1);
                    contentHolder.setTranslateX(-offsetX);
                    animation = new LeftTransition();
                    break;
                case RIGHT:
                    contentHolder.setScaleX(1);
                    contentHolder.setScaleY(1);
                    contentHolder.setTranslateX(offsetX);
                    animation = new RightTransition();
                    break;
                case TOP:
                    contentHolder.setScaleX(1);
                    contentHolder.setScaleY(1);
                    contentHolder.setTranslateY(-offsetY);
                    animation = new TopTransition();
                    break;
                case BOTTOM:
                    contentHolder.setScaleX(1);
                    contentHolder.setScaleY(1);
                    contentHolder.setTranslateY(offsetY);
                    animation = new BottomTransition();
                    break;
                case CENTER:
                    contentHolder.setScaleX(0);
                    contentHolder.setScaleY(0);
                    animation = new CenterTransition();
                    break;
                default:
                    animation = null;
                    contentHolder.setScaleX(1);
                    contentHolder.setScaleY(1);
                    contentHolder.setTranslateX(0);
                    contentHolder.setTranslateY(0);
                    break;
            }
        }
        if (animation != null) {
            animation.setOnFinished(finish ->
                Event.fireEvent(JFXDialog.this, new JFXDialogEvent(JFXDialogEvent.OPENED)));
        }
        return animation;
    }"
"private javax.swing.JPanel getPanelCommand() {
		if (panelCommand == null) {
			panelCommand = new javax.swing.JPanel();
			panelCommand.setLayout(new java.awt.GridBagLayout());
			panelCommand.setName(Constant.messages.getString(""httpsessions.panel.title""));

			// Add the two components: toolbar and work pane
			GridBagConstraints toolbarGridBag = new GridBagConstraints();
			GridBagConstraints workPaneGridBag = new GridBagConstraints();

			toolbarGridBag.gridx = 0;
			toolbarGridBag.gridy = 0;
			toolbarGridBag.weightx = 1.0d;
			toolbarGridBag.insets = new java.awt.Insets(2, 2, 2, 2);
			toolbarGridBag.anchor = java.awt.GridBagConstraints.NORTHWEST;
			toolbarGridBag.fill = java.awt.GridBagConstraints.HORIZONTAL;

			workPaneGridBag.gridx = 0;
			workPaneGridBag.gridy = 1;
			workPaneGridBag.weightx = 1.0;
			workPaneGridBag.weighty = 1.0;
			workPaneGridBag.insets = new java.awt.Insets(0, 0, 0, 0);
			workPaneGridBag.anchor = java.awt.GridBagConstraints.NORTHWEST;
			workPaneGridBag.fill = java.awt.GridBagConstraints.BOTH;

			panelCommand.add(this.getPanelToolbar(), toolbarGridBag);
			panelCommand.add(getWorkPane(), workPaneGridBag);
		}
		return panelCommand;
	}"
"public Word07Writer addText(ParagraphAlignment align, Font font, String... texts) {
		final XWPFParagraph p = this.doc.createParagraph();
		if (null != align) {
			p.setAlignment(align);
		}
		if (ArrayUtil.isNotEmpty(texts)) {
			XWPFRun run;
			for (String text : texts) {
				run = p.createRun();
				run.setText(text);
				if (null != font) {
					run.setFontFamily(font.getFamily());
					run.setFontSize(font.getSize());
					run.setBold(font.isBold());
					run.setItalic(font.isItalic());
				}
			}
		}
		return this;
	}"
"public final Result solve(GradientSolver gslvr, double [] beta, GradientInfo ginfo, ProgressMonitor pm) {
    if(_hist == null)
      _hist = new History(_historySz, beta.length);
    int iter = 0;
    double rel_improvement = 1;
    final double [] pk = new double[beta.length];
    double minStep = 1e-16;
    LineSearchSolver lineSearch = new MoreThuente(gslvr,beta,ginfo);
    while(!ArrayUtils.hasNaNsOrInfs(beta) && (ArrayUtils.linfnorm(ginfo._gradient,false) > _gradEps  && rel_improvement > _objEps) && iter != _maxIter) {
      ++iter;
      _hist.getSearchDirection(ginfo._gradient,pk);
      if(!lineSearch.evaluate(pk))
        break;
      lineSearch.setInitialStep(Math.max(minStep, lineSearch.step()));
      GradientInfo newGinfo = lineSearch.ginfo();
      _hist.update(pk, newGinfo._gradient, ginfo._gradient);
      rel_improvement = (ginfo._objVal - newGinfo._objVal)/ginfo._objVal;
      ginfo = newGinfo;
      if(!pm.progress(lineSearch.getX(), ginfo))break;
    }
    return new Result((ArrayUtils.linfnorm(ginfo._gradient,false) <= _gradEps  || rel_improvement <= _objEps),iter,lineSearch.getX(), lineSearch.ginfo(),rel_improvement);
  }"
"private void writes() {
    int index = random.nextInt();
    for (;;) {
      Integer key = ints[index++ & MASK];
      cache.put(key, Boolean.TRUE);
      calls.increment();
    }
  }"
"@Override
    public double getMean() {
        if (values.length == 0) {
            return 0;
        }

        double sum = 0;
        for (int i = 0; i < values.length; i++) {
            sum += values[i] * normWeights[i];
        }
        return sum;
    }"
"public static String deleteFromTable(Class<?> entityClass, String defaultTableName) {
        StringBuilder sql = new StringBuilder();
        sql.append(""DELETE FROM "");
        sql.append(getDynamicTableName(entityClass, defaultTableName));
        sql.append("" "");
        return sql.toString();
    }"
"@PublicEvolving
	public float getFloat(ConfigOption<Float> configOption) {
		Object o = getValueOrDefaultFromOption(configOption);
		return convertToFloat(o, configOption.defaultValue());
	}"
"public static <T> List<T> nullToEmptyList(Collection<T> newValue) {
    if (newValue == null) {
      return new ArrayList<>();
    }
    return new ArrayList<>(newValue);
  }"
"@VisibleForTesting
  static Level getLogLevel(Throwable t) {
    if (t instanceof IOException
        && t.getMessage() != null
        && QUIET_ERRORS.contains(t.getMessage())) {
      return Level.FINE;
    }
    return Level.INFO;
  }"
"public boolean isRefinedPartitioningOver(
            Partitioning right,
            Metadata metadata,
            Session session)
    {
        if (!handle.equals(right.handle) && !metadata.isRefinedPartitioningOver(session, handle, right.handle)) {
            return false;
        }

        return arguments.equals(right.arguments);
    }"
"private static void generateAllCombinations(
      List<Filter> result,
      List<Filter> andList,
      List<Filter> nonAndList
  )
  {
    List<Filter> children = ((AndFilter) andList.get(0)).getFilters();
    if (result.isEmpty()) {
      for (Filter child : children) {
        List<Filter> a = Lists.newArrayList(nonAndList);
        a.add(child);
        result.add(new OrFilter(a));
      }
    } else {
      List<Filter> work = new ArrayList<>(result);
      result.clear();
      for (Filter child : children) {
        for (Filter or : work) {
          List<Filter> a = Lists.newArrayList((((OrFilter) or).getFilters()));
          a.add(child);
          result.add(new OrFilter(a));
        }
      }
    }
    if (andList.size() > 1) {
      generateAllCombinations(result, andList.subList(1, andList.size()), nonAndList);
    }
  }"
"public String[] getStrings(String key, String group) {
		return getStrings(key, group, DEFAULT_DELIMITER);
	}"
"public T next() {
		if(MapUtil.isEmpty(this.weightMap)) {
			return null;
		}
		final double randomWeight = this.weightMap.lastKey() * random.nextDouble();
		final SortedMap<Double, T> tailMap = this.weightMap.tailMap(randomWeight, false);
		return this.weightMap.get(tailMap.firstKey());
	}"
"public static void isAssignable(Class<?> superType, Class<?> subType) throws IllegalArgumentException {
		isAssignable(superType, subType, ""{} is not assignable to {})"", subType, superType);
	}"
"public int resetErrorStateAndParse(byte[] bytes, int startPos, int limit, byte[] delim, T reuse) {
		resetParserState();
		return parseField(bytes, startPos, limit, delim, reuse);
	}"
"@View(name = ""by_uid_otp"", map = ""function(doc) { if(doc.token && doc.userId) { emit([doc.userId, doc.token], doc) } }"")
    public CouchDbGoogleAuthenticatorToken findOneByUidForOtp(final String uid, final Integer otp) {
        val view = createQuery(""by_uid_otp"").key(ComplexKey.of(uid, otp)).limit(1);
        return db.queryView(view, CouchDbGoogleAuthenticatorToken.class).stream().findFirst().orElse(null);
    }"
"public Val exec(AstRoot ast, AstFunction scope) {
    sanity_check_refs(null);

    // Execute
    Env env = new Env(this);
    env._scope = scope;
    Val val = ast.exec(env);    // Execute
    assert env.sp() == 0;         // Stack balanced at end
    sanity_check_refs(val);
    return val;                 // Can return a frame, which may point to session-shared Vecs
  }"
"public void doProgressText(StaplerRequest req, StaplerResponse rsp) throws IOException {
        rsp.setContentType(""text/plain"");
        rsp.setStatus(HttpServletResponse.SC_OK);

        if(!source.exists()) {
            // file doesn't exist yet
            rsp.addHeader(""X-Text-Size"",""0"");
            rsp.addHeader(""X-More-Data"",""true"");
            return;
        }

        long start = 0;
        String s = req.getParameter(""start"");
        if(s!=null)
            start = Long.parseLong(s);

        if(source.length() < start )
            start = 0;  // text rolled over

        CharSpool spool = new CharSpool();
        long r = writeLogTo(start,spool);

        rsp.addHeader(""X-Text-Size"",String.valueOf(r));
        if(!completed)
            rsp.addHeader(""X-More-Data"",""true"");

        // when sending big text, try compression. don't bother if it's small
        Writer w;
        if(r-start>4096)
            w = rsp.getCompressedWriter(req);
        else
            w = rsp.getWriter();
        spool.writeTo(new LineEndNormalizingWriter(w));
        w.close();

    }"
"@CheckReturnValue
  public <NewReqT, NewRespT> Builder<NewReqT, NewRespT> toBuilder(
      Marshaller<NewReqT> requestMarshaller, Marshaller<NewRespT> responseMarshaller) {
    return MethodDescriptor.<NewReqT, NewRespT>newBuilder()
        .setRequestMarshaller(requestMarshaller)
        .setResponseMarshaller(responseMarshaller)
        .setType(type)
        .setFullMethodName(fullMethodName)
        .setIdempotent(idempotent)
        .setSafe(safe)
        .setSampledToLocalTracing(sampledToLocalTracing)
        .setSchemaDescriptor(schemaDescriptor);
  }"
"public void shutdown() {
        RequestBatch<BatchReturnType, ResponseType, RequestArgumentType> currentBatch = batch.getAndSet(null);
        if (currentBatch != null) {
            currentBatch.shutdown();
        }

        if (timerListenerReference.get() != null) {
            // if the timer was started we'll clear it so it stops ticking
            timerListenerReference.get().clear();
        }
    }"
"@Override
	public void processElement1(StreamRecord<T1> record) throws Exception {
		processElement(record, leftBuffer, rightBuffer, lowerBound, upperBound, true);
	}"
"private OptimizedPlan compile(Plan program, OptimizerPostPass postPasser) throws CompilerException {
		if (program == null || postPasser == null) {
			throw new NullPointerException();
		}
		
		if (LOG.isDebugEnabled()) {
			LOG.debug(""Beginning compilation of program '"" + program.getJobName() + '\'');
		}

		final ExecutionMode defaultDataExchangeMode = program.getExecutionConfig().getExecutionMode();

		final int defaultParallelism = program.getDefaultParallelism() > 0 ?
			program.getDefaultParallelism() : this.defaultParallelism;

		// log the default settings
		LOG.debug(""Using a default parallelism of {}"",  defaultParallelism);
		LOG.debug(""Using default data exchange mode {}"", defaultDataExchangeMode);

		// the first step in the compilation is to create the optimizer plan representation
		// this step does the following:
		// 1) It creates an optimizer plan node for each operator
		// 2) It connects them via channels
		// 3) It looks for hints about local strategies and channel types and
		// sets the types and strategies accordingly
		// 4) It makes estimates about the data volume of the data sources and
		// propagates those estimates through the plan

		GraphCreatingVisitor graphCreator = new GraphCreatingVisitor(defaultParallelism, defaultDataExchangeMode);
		program.accept(graphCreator);

		// if we have a plan with multiple data sinks, add logical optimizer nodes that have two data-sinks as children
		// each until we have only a single root node. This allows to transparently deal with the nodes with
		// multiple outputs
		OptimizerNode rootNode;
		if (graphCreator.getSinks().size() == 1) {
			rootNode = graphCreator.getSinks().get(0);
		}
		else if (graphCreator.getSinks().size() > 1) {
			Iterator<DataSinkNode> iter = graphCreator.getSinks().iterator();
			rootNode = iter.next();

			while (iter.hasNext()) {
				rootNode = new SinkJoiner(rootNode, iter.next());
			}
		}
		else {
			throw new CompilerException(""Bug: The optimizer plan representation has no sinks."");
		}

		// now that we have all nodes created and recorded which ones consume memory, tell the nodes their minimal
		// guaranteed memory, for further cost estimations. We assume an equal distribution of memory among consumer tasks
		rootNode.accept(new IdAndEstimatesVisitor(this.statistics));

		// We need to enforce that union nodes always forward their output to their successor.
		// Any partitioning must be either pushed before or done after the union, but not on the union's output.
		UnionParallelismAndForwardEnforcer unionEnforcer = new UnionParallelismAndForwardEnforcer();
		rootNode.accept(unionEnforcer);

		// We are dealing with operator DAGs, rather than operator trees.
		// That requires us to deviate at some points from the classical DB optimizer algorithms.
		// This step builds auxiliary structures to help track branches and joins in the DAG
		BranchesVisitor branchingVisitor = new BranchesVisitor();
		rootNode.accept(branchingVisitor);

		// Propagate the interesting properties top-down through the graph
		InterestingPropertyVisitor propsVisitor = new InterestingPropertyVisitor(this.costEstimator);
		rootNode.accept(propsVisitor);
		
		// perform a sanity check: the root may not have any unclosed branches
		if (rootNode.getOpenBranches() != null && rootNode.getOpenBranches().size() > 0) {
			throw new CompilerException(""Bug: Logic for branching plans (non-tree plans) has an error, and does not "" +
					""track the re-joining of branches correctly."");
		}

		// the final step is now to generate the actual plan alternatives
		List<PlanNode> bestPlan = rootNode.getAlternativePlans(this.costEstimator);

		if (bestPlan.size() != 1) {
			throw new CompilerException(""Error in compiler: more than one best plan was created!"");
		}

		// check if the best plan's root is a data sink (single sink plan)
		// if so, directly take it. if it is a sink joiner node, get its contained sinks
		PlanNode bestPlanRoot = bestPlan.get(0);
		List<SinkPlanNode> bestPlanSinks = new ArrayList<SinkPlanNode>(4);

		if (bestPlanRoot instanceof SinkPlanNode) {
			bestPlanSinks.add((SinkPlanNode) bestPlanRoot);
		} else if (bestPlanRoot instanceof SinkJoinerPlanNode) {
			((SinkJoinerPlanNode) bestPlanRoot).getDataSinks(bestPlanSinks);
		}

		// finalize the plan
		OptimizedPlan plan = new PlanFinalizer().createFinalPlan(bestPlanSinks, program.getJobName(), program);
		
		plan.accept(new BinaryUnionReplacer());

		plan.accept(new RangePartitionRewriter(plan));

		// post pass the plan. this is the phase where the serialization and comparator code is set
		postPasser.postPass(plan);
		
		return plan;
	}"
"public static void makesureDirExists(Path dirPath) throws IOException {
		Validate.notNull(dirPath);
		Files.createDirectories(dirPath);
	}"
"@SuppressWarnings(""unchecked cast"")
    public static <F, T> PropertyPattern<F, T> upcast(PropertyPattern<F, ? extends T> propertyPattern)
    {
        return (PropertyPattern<F, T>) propertyPattern;
    }"
"private static int findMatchingLength(ByteBuf in, int minIndex, int inIndex, int maxIndex) {
        int matched = 0;

        while (inIndex <= maxIndex - 4 &&
                in.getInt(inIndex) == in.getInt(minIndex + matched)) {
            inIndex += 4;
            matched += 4;
        }

        while (inIndex < maxIndex && in.getByte(minIndex + matched) == in.getByte(inIndex)) {
            ++inIndex;
            ++matched;
        }

        return matched;
    }"
"public void startPipeline(NodeTask nodeTask) {
        Long pipelineId = nodeTask.getPipeline().getId();
        releasePipeline(pipelineId);
        Map<StageType, GlobalTask> tasks = controllers.get(pipelineId);
        // 处理具体的任务命令
        List<StageType> stage = nodeTask.getStage();
        List<TaskEvent> event = nodeTask.getEvent();
        for (int i = 0; i < stage.size(); i++) {
            StageType stageType = stage.get(i);
            TaskEvent taskEvent = event.get(i);
            if (taskEvent.isCreate()) {
                startTask(nodeTask.getPipeline(), tasks, stageType);
            } else {
                stopTask(tasks, stageType);
            }
        }
    }"
"public void addLossVariable(@NonNull String variableName){
        Preconditions.checkState(hasVariable(variableName), ""No variable with name \""%s\"" exists"", variableName);
        SDVariable v = getVariable(variableName);
        Preconditions.checkState(v.dataType().isFPType(), ""Only floating point type variables can be marked as losses to be minimized."" +
                "" SDVariable \""%s\"" has datatype %s"", variableName, v.dataType());
        Preconditions.checkState(v.getVariableType() == VariableType.ARRAY, ""Only ARRAY type SDVariables can be marked as losses to be minimized."" +
                "" SDVariable \""%s\"" has variable type %s"", variableName, v.getVariableType());
        if(!lossVariables.contains(variableName)){
            lossVariables.add(variableName);
        }
    }"
"public void removeJob(JobID jobId) throws Exception {
		LOG.debug(""Remove job {} from job leader id monitoring."", jobId);

		JobLeaderIdListener listener = jobLeaderIdListeners.remove(jobId);

		if (listener != null) {
			listener.stop();
		}
	}"
"public static void readLines(Reader reader, LineHandler lineHandler) throws IORuntimeException {
		Assert.notNull(reader);
		Assert.notNull(lineHandler);

		// 从返回的内容中读取所需内容
		final BufferedReader bReader = getReader(reader);
		String line = null;
		try {
			while ((line = bReader.readLine()) != null) {
				lineHandler.handle(line);
			}
		} catch (IOException e) {
			throw new IORuntimeException(e);
		}
	}"
"@GuardedBy(""evictionLock"")
  void reorderProbation(Node<K, V> node) {
    if (!accessOrderProbationDeque().contains(node)) {
      // Ignore stale accesses for an entry that is no longer present
      return;
    } else if (node.getPolicyWeight() > mainProtectedMaximum()) {
      return;
    }

    // If the protected space exceeds its maximum, the LRU items are demoted to the probation space.
    // This is deferred to the adaption phase at the end of the maintenance cycle.
    setMainProtectedWeightedSize(mainProtectedWeightedSize() + node.getPolicyWeight());
    accessOrderProbationDeque().remove(node);
    accessOrderProtectedDeque().add(node);
    node.makeMainProtected();
  }"
"public CompletableFuture<Void> shutdownServer() {
		CompletableFuture<Void> shutdownFuture = new CompletableFuture<>();
		if (serverShutdownFuture.compareAndSet(null, shutdownFuture)) {
			log.info(""Shutting down {} @ {}"", serverName, serverAddress);

			final CompletableFuture<Void> groupShutdownFuture = new CompletableFuture<>();
			if (bootstrap != null) {
				EventLoopGroup group = bootstrap.group();
				if (group != null && !group.isShutdown()) {
					group.shutdownGracefully(0L, 0L, TimeUnit.MILLISECONDS)
							.addListener(finished -> {
								if (finished.isSuccess()) {
									groupShutdownFuture.complete(null);
								} else {
									groupShutdownFuture.completeExceptionally(finished.cause());
								}
							});
				} else {
					groupShutdownFuture.complete(null);
				}
			} else {
				groupShutdownFuture.complete(null);
			}

			final CompletableFuture<Void> handlerShutdownFuture = new CompletableFuture<>();
			if (handler == null) {
				handlerShutdownFuture.complete(null);
			} else {
				handler.shutdown().whenComplete((result, throwable) -> {
					if (throwable != null) {
						handlerShutdownFuture.completeExceptionally(throwable);
					} else {
						handlerShutdownFuture.complete(null);
					}
				});
			}

			final CompletableFuture<Void> queryExecShutdownFuture = CompletableFuture.runAsync(() -> {
				if (queryExecutor != null) {
					ExecutorUtils.gracefulShutdown(10L, TimeUnit.MINUTES, queryExecutor);
				}
			});

			CompletableFuture.allOf(
					queryExecShutdownFuture, groupShutdownFuture, handlerShutdownFuture
			).whenComplete((result, throwable) -> {
				if (throwable != null) {
					shutdownFuture.completeExceptionally(throwable);
				} else {
					shutdownFuture.complete(null);
				}
			});
		}
		return serverShutdownFuture.get();
	}"
"public static PrecisionTime parsePrecisionDateTimeLiteral(String s,
															  DateFormat dateFormat, TimeZone tz, int maxPrecision) {
		final ParsePosition pp = new ParsePosition(0);
		final Calendar cal = parseDateFormat(s, dateFormat, tz, pp);
		if (cal == null) {
			return null; // Invalid date/time format
		}

		// Note: the Java SimpleDateFormat 'S' treats any number after
		// the decimal as milliseconds. That means 12:00:00.9 has 9
		// milliseconds and 12:00:00.9999 has 9999 milliseconds.
		int p = 0;
		String secFraction = """";
		if (pp.getIndex() < s.length()) {
			// Check to see if rest is decimal portion
			if (s.charAt(pp.getIndex()) != '.') {
				return null;
			}

			// Skip decimal sign
			pp.setIndex(pp.getIndex() + 1);

			// Parse decimal portion
			if (pp.getIndex() < s.length()) {
				secFraction = s.substring(pp.getIndex());
				if (!secFraction.matches(""\\d+"")) {
					return null;
				}
				NumberFormat nf = NumberFormat.getIntegerInstance(Locale.ROOT);
				Number num = nf.parse(s, pp);
				if ((num == null) || (pp.getIndex() != s.length())) {
					// Invalid decimal portion
					return null;
				}

				// Determine precision - only support prec 3 or lower
				// (milliseconds) Higher precisions are quietly rounded away
				p = secFraction.length();
				if (maxPrecision >= 0) {
					// If there is a maximum precision, ignore subsequent digits
					p = Math.min(maxPrecision, p);
					secFraction = secFraction.substring(0, p);
				}

				// Calculate milliseconds
				String millis = secFraction;
				if (millis.length() > 3) {
					millis = secFraction.substring(0, 3);
				}
				while (millis.length() < 3) {
					millis = millis + ""0"";
				}

				int ms = Integer.valueOf(millis);
				cal.add(Calendar.MILLISECOND, ms);
			}
		}

		assert pp.getIndex() == s.length();
		return new PrecisionTime(cal, secFraction, p);
	}"
"private static BitMatrix extractPureBits(BitMatrix image) throws NotFoundException {

    int[] leftTopBlack = image.getTopLeftOnBit();
    int[] rightBottomBlack = image.getBottomRightOnBit();
    if (leftTopBlack == null || rightBottomBlack == null) {
      throw NotFoundException.getNotFoundInstance();
    }

    float moduleSize = moduleSize(leftTopBlack, image);

    int top = leftTopBlack[1];
    int bottom = rightBottomBlack[1];
    int left = leftTopBlack[0];
    int right = rightBottomBlack[0];

    // Sanity check!
    if (left >= right || top >= bottom) {
      throw NotFoundException.getNotFoundInstance();
    }

    if (bottom - top != right - left) {
      // Special case, where bottom-right module wasn't black so we found something else in the last row
      // Assume it's a square, so use height as the width
      right = left + (bottom - top);
      if (right >= image.getWidth()) {
        // Abort if that would not make sense -- off image
        throw NotFoundException.getNotFoundInstance();
      }
    }

    int matrixWidth = Math.round((right - left + 1) / moduleSize);
    int matrixHeight = Math.round((bottom - top + 1) / moduleSize);
    if (matrixWidth <= 0 || matrixHeight <= 0) {
      throw NotFoundException.getNotFoundInstance();
    }
    if (matrixHeight != matrixWidth) {
      // Only possibly decode square regions
      throw NotFoundException.getNotFoundInstance();
    }

    // Push in the ""border"" by half the module width so that we start
    // sampling in the middle of the module. Just in case the image is a
    // little off, this will help recover.
    int nudge = (int) (moduleSize / 2.0f);
    top += nudge;
    left += nudge;

    // But careful that this does not sample off the edge
    // ""right"" is the farthest-right valid pixel location -- right+1 is not necessarily
    // This is positive by how much the inner x loop below would be too large
    int nudgedTooFarRight = left + (int) ((matrixWidth - 1) * moduleSize) - right;
    if (nudgedTooFarRight > 0) {
      if (nudgedTooFarRight > nudge) {
        // Neither way fits; abort
        throw NotFoundException.getNotFoundInstance();
      }
      left -= nudgedTooFarRight;
    }
    // See logic above
    int nudgedTooFarDown = top + (int) ((matrixHeight - 1) * moduleSize) - bottom;
    if (nudgedTooFarDown > 0) {
      if (nudgedTooFarDown > nudge) {
        // Neither way fits; abort
        throw NotFoundException.getNotFoundInstance();
      }
      top -= nudgedTooFarDown;
    }

    // Now just read off the bits
    BitMatrix bits = new BitMatrix(matrixWidth, matrixHeight);
    for (int y = 0; y < matrixHeight; y++) {
      int iOffset = top + (int) (y * moduleSize);
      for (int x = 0; x < matrixWidth; x++) {
        if (image.get(left + (int) (x * moduleSize), iOffset)) {
          bits.set(x, y);
        }
      }
    }
    return bits;
  }"
"public static StreamExecutionEnvironment createRemoteEnvironment(
			String host, int port, String... jarFiles) {
		return new RemoteStreamEnvironment(host, port, jarFiles);
	}"
"public static Tag uri(HttpServletRequest request, HttpServletResponse response) {
		if (request != null) {
			String pattern = getMatchingPattern(request);
			if (pattern != null) {
				return Tag.of(""uri"", pattern);
			}
			if (response != null) {
				HttpStatus status = extractStatus(response);
				if (status != null) {
					if (status.is3xxRedirection()) {
						return URI_REDIRECTION;
					}
					if (status == HttpStatus.NOT_FOUND) {
						return URI_NOT_FOUND;
					}
				}
			}
			String pathInfo = getPathInfo(request);
			if (pathInfo.isEmpty()) {
				return URI_ROOT;
			}
		}
		return URI_UNKNOWN;
	}"
"private static void onHeadersRead(ChannelHandlerContext ctx, Http2HeadersFrame headers)
            throws Exception {
        if (headers.isEndStream()) {
            ByteBuf content = ctx.alloc().buffer();
            content.writeBytes(RESPONSE_BYTES.duplicate());
            ByteBufUtil.writeAscii(content, "" - via HTTP/2"");
            sendResponse(ctx, content);
        }
    }"
"public static BigDecimal round(BigDecimal number, int scale, RoundingMode roundingMode) {
		if (null == number) {
			number = BigDecimal.ZERO;
		}
		if (scale < 0) {
			scale = 0;
		}
		if (null == roundingMode) {
			roundingMode = RoundingMode.HALF_UP;
		}

		return number.setScale(scale, roundingMode);
	}"
"public int compareTo(LogPosition o) {
        final int val = fileName.compareTo(o.fileName);

        if (val == 0) {
            return (int) (position - o.position);
        }
        return val;
    }"
"@Nullable
	public InetSocketAddress getServerAddress() {
		synchronized (lock) {
			Preconditions.checkState(state != State.CREATED, ""The RestServerEndpoint has not been started yet."");
			Channel server = this.serverChannel;

			if (server != null) {
				try {
					return ((InetSocketAddress) server.localAddress());
				} catch (Exception e) {
					log.error(""Cannot access local server address"", e);
				}
			}

			return null;
		}
	}"
"public static String camelhumpToUnderline(String str) {
        final int size;
        final char[] chars;
        final StringBuilder sb = new StringBuilder(
                (size = (chars = str.toCharArray()).length) * 3 / 2 + 1);
        char c;
        for (int i = 0; i < size; i++) {
            c = chars[i];
            if (isUppercaseAlpha(c)) {
                sb.append('_').append(toLowerAscii(c));
            } else {
                sb.append(c);
            }
        }
        return sb.charAt(0) == '_' ? sb.substring(1) : sb.toString();
    }"
"public static ValueMatcher makeValueMatcherGeneric(DimensionSelector selector, Predicate<String> predicate)
  {
    int cardinality = selector.getValueCardinality();
    if (cardinality >= 0 && selector.nameLookupPossibleInAdvance()) {
      return makeDictionaryEncodedValueMatcherGeneric(selector, predicate);
    } else {
      return makeNonDictionaryEncodedValueMatcherGeneric(selector, predicate);
    }
  }"
"public Assertion newAssertion(final AuthenticationStatement authnStatement, final String issuer,
                                  final ZonedDateTime issuedAt, final String id) {
        val assertion = newSamlObject(Assertion.class);

        assertion.setID(id);
        assertion.setIssueInstant(DateTimeUtils.dateTimeOf(issuedAt));
        assertion.setIssuer(issuer);
        assertion.getAuthenticationStatements().add(authnStatement);
        return assertion;
    }"
"@Override
	public HttpConnection getConnectionWithTimeout(
			HostConfiguration hostConfiguration, long timeout) {

		if (httpConnection == null) {
			httpConnection = new ZapHttpConnection(hostConfiguration);
			httpConnection.setHttpConnectionManager(this);
			httpConnection.getParams().setDefaults(this.getParams());
		}
		
		return super.getConnectionWithTimeout(hostConfiguration, timeout);
	}"
"public static String getClassName(String path) {
        for (Pattern pattern : patterns) {
            Matcher m = pattern.matcher(path);
            if (m.find()) {
                return m.group(1).replaceAll(""[/\\\\]"", ""."");
            }
        }
        return null;
    }"
"public AnnotationMetadata buildDeclared(T element) {
        final AnnotationMetadata existing = MUTATED_ANNOTATION_METADATA.get(element);
        if (existing != null) {
            return existing;
        } else {

            DefaultAnnotationMetadata annotationMetadata = new DefaultAnnotationMetadata();

            try {
                AnnotationMetadata metadata = buildInternal(null, element, annotationMetadata, true, true);
                if (metadata.isEmpty()) {
                    return AnnotationMetadata.EMPTY_METADATA;
                }
                return metadata;
            } catch (RuntimeException e) {
                if (""org.eclipse.jdt.internal.compiler.problem.AbortCompilation"".equals(e.getClass().getName())) {
                    // workaround for a bug in the Eclipse APT implementation. See bug 541466 on their Bugzilla.
                    return AnnotationMetadata.EMPTY_METADATA;
                } else {
                    throw e;
                }
            }
        }
    }"
"@Override
    public int syncUp() {
        // Copy entire entry from neighboring DS node
        int count = 0;

        for (int i = 0; ((i < serverConfig.getRegistrySyncRetries()) && (count == 0)); i++) {
            if (i > 0) {
                try {
                    Thread.sleep(serverConfig.getRegistrySyncRetryWaitMs());
                } catch (InterruptedException e) {
                    logger.warn(""Interrupted during registry transfer.."");
                    break;
                }
            }
            Applications apps = eurekaClient.getApplications();
            for (Application app : apps.getRegisteredApplications()) {
                for (InstanceInfo instance : app.getInstances()) {
                    try {
                        if (isRegisterable(instance)) {
                            register(instance, instance.getLeaseInfo().getDurationInSecs(), true);
                            count++;
                        }
                    } catch (Throwable t) {
                        logger.error(""During DS init copy"", t);
                    }
                }
            }
        }
        return count;
    }"
"public void addArgsFor(String[] variables, DifferentialFunction function) {
        if (function.getOwnName() == null)
            throw new ND4JIllegalStateException(""Instance id can not be null. Function not initialized properly"");

        //double check if function contains placeholder args
        for (val varName : variables) {
            if (isPlaceHolder(varName)) {
                placeHolderFunctions.add(function.getOwnName());
            }
        }

        //Add function if it doesn't exist
        //TODO could ""not existing"" be a bug sometimes?
        if(!ops.containsKey(function.getOwnName())){
            ops.put(function.getOwnName(), SameDiffOp.builder().name(function.getOwnName()).op(function).build());
        }

        //Update variable 'inputs to op' accounting for repeated inputs (like y = x+x)
        ops.get(function.getOwnName()).setInputsToOp(Arrays.asList(variables));     //Duplicate variables OK/required here

        for (String variableName : variables) {
            List<String> funcs = this.variables.get(variableName).getInputsForOp();
            if (funcs == null) {
                funcs = new ArrayList<>();
                this.variables.get(variableName).setInputsForOp(funcs);
            }
            if(!funcs.contains(function.getOwnName()))  //Avoid duplicates for function names.
                funcs.add(function.getOwnName());
        }
    }"
"private StructuralNode getStartNode(URI startURI, boolean recurse) throws ApiException {
		StructuralNode startNode = null;
		try {
			if (recurse) {
				startNode = SessionStructure.find(Model.getSingleton().getSession().getSessionId(), startURI, """", """");
			}
			if (startNode == null) {
				startNode = SessionStructure.find(Model.getSingleton().getSession().getSessionId(), startURI, ""GET"", """");
			}
		} catch (Exception e) {
			throw new ApiException(ApiException.Type.INTERNAL_ERROR, e);
		}
		return startNode;
	}"
"public static <T> List<List<T>> partition(List<T> list, int size) {
		return Lists.partition(list, size);
	}"
"public Map<String, OriginTrackedValue> load(boolean expandLists) throws IOException {
		try (CharacterReader reader = new CharacterReader(this.resource)) {
			Map<String, OriginTrackedValue> result = new LinkedHashMap<>();
			StringBuilder buffer = new StringBuilder();
			while (reader.read()) {
				String key = loadKey(buffer, reader).trim();
				if (expandLists && key.endsWith(""[]"")) {
					key = key.substring(0, key.length() - 2);
					int index = 0;
					do {
						OriginTrackedValue value = loadValue(buffer, reader, true);
						put(result, key + ""["" + (index++) + ""]"", value);
						if (!reader.isEndOfLine()) {
							reader.read();
						}
					}
					while (!reader.isEndOfLine());
				}
				else {
					OriginTrackedValue value = loadValue(buffer, reader, false);
					put(result, key, value);
				}
			}
			return result;
		}
	}"
"public ParseSetup readSetup(FileVec f, String[] columnNames, byte[] columnTypes) {
    try {
      Reader orcFileReader = getReader(f);
      StructObjectInspector insp = (StructObjectInspector) orcFileReader.getObjectInspector();
      OrcParser.OrcParseSetup stp = OrcParser.deriveParseSetup(orcFileReader, insp);

      // change back the columnNames and columnTypes if they are specified already
      if (!(columnNames == null) && (stp.getAllColNames().length == columnNames.length)) { // copy column name
        stp.setColumnNames(columnNames);
        stp.setAllColNames(columnNames);
      }

      if (columnTypes != null) { // copy enum type only

        byte[] old_columnTypes = stp.getColumnTypes();
        String[] old_columnTypeNames = stp.getColumnTypesString();
        for (int index = 0; index < columnTypes.length; index++) {
          if(columnTypes[index] != old_columnTypes[index]){
            if(supported_type_conversions[old_columnTypes[index]][columnTypes[index]] == 1){
              old_columnTypes[index] = columnTypes[index];
            } else {
              stp.addErrs(new ParseWriter.UnsupportedTypeOverride(f._key.toString(),Vec.TYPE_STR[old_columnTypes[index]], Vec.TYPE_STR[columnTypes[index]],columnNames[index]));
            }
          }
          if (columnTypes[index] == Vec.T_CAT || columnTypes[index] == Vec.T_BAD || columnTypes[index] == Vec.T_TIME)  // only copy the enum types
            old_columnTypes[index] = columnTypes[index];
        }
        stp.setColumnTypes(old_columnTypes);
        stp.setColumnTypeStrings(old_columnTypeNames);
      }

      List<StripeInformation> stripesInfo = orcFileReader.getStripes();
      if(stripesInfo.size() == 0) { // empty file
        f.setChunkSize(stp._chunk_size = (int)f.length());
        return stp;
      }
      f.setNChunks(stripesInfo.size());
      stp._chunk_size = f._chunkSize;
      assert f.nChunks() == stripesInfo.size(); // ORC parser needs one-to one mapping between chunk and strip (just ids, offsets do not matter)
      return stp;
    } catch(IOException ioe) {
      throw new RuntimeException(ioe);
    }
  }"
"public RestTemplateBuilder uriTemplateHandler(UriTemplateHandler uriTemplateHandler) {
		Assert.notNull(uriTemplateHandler, ""UriTemplateHandler must not be null"");
		return new RestTemplateBuilder(this.detectRequestFactory, this.rootUri,
				this.messageConverters, this.requestFactorySupplier, uriTemplateHandler,
				this.errorHandler, this.basicAuthentication, this.restTemplateCustomizers,
				this.requestFactoryCustomizer, this.interceptors);
	}"
"@Internal
	public <R> SingleOutputStreamOperator<R> process(
			CoProcessFunction<IN1, IN2, R> coProcessFunction,
			TypeInformation<R> outputType) {

		TwoInputStreamOperator<IN1, IN2, R> operator;

		if ((inputStream1 instanceof KeyedStream) && (inputStream2 instanceof KeyedStream)) {
			operator = new KeyedCoProcessOperator<>(inputStream1.clean(coProcessFunction));
		} else {
			operator = new CoProcessOperator<>(inputStream1.clean(coProcessFunction));
		}

		return transform(""Co-Process"", outputType, operator);
	}"
"public URLNormalizer removeWWW() {
        String host = toURL().getHost();
        String newHost = StringUtils.removeStartIgnoreCase(host, ""www."");
        url = StringUtils.replaceOnce(url, host, newHost);
        return this;
    }"
"final Serializable fetchValue(String columnName, int columnIndex, int type, final int meta, boolean isBinary) {
        int len = 0;

        if (type == LogEvent.MYSQL_TYPE_STRING) {
            if (meta >= 256) {
                int byte0 = meta >> 8;
                int byte1 = meta & 0xff;
                if ((byte0 & 0x30) != 0x30) {
                    /* a long CHAR() field: see #37426 */
                    len = byte1 | (((byte0 & 0x30) ^ 0x30) << 4);
                    type = byte0 | 0x30;
                } else {
                    switch (byte0) {
                        case LogEvent.MYSQL_TYPE_SET:
                        case LogEvent.MYSQL_TYPE_ENUM:
                        case LogEvent.MYSQL_TYPE_STRING:
                            type = byte0;
                            len = byte1;
                            break;
                        default:
                            throw new IllegalArgumentException(String.format(""!! Don't know how to handle column type=%d meta=%d (%04X)"",
                                type,
                                meta,
                                meta));
                    }
                }
            } else {
                len = meta;
            }
        }

        switch (type) {
            case LogEvent.MYSQL_TYPE_LONG: {
                // XXX: How to check signed / unsigned?
                // value = unsigned ? Long.valueOf(buffer.getUint32()) :
                // Integer.valueOf(buffer.getInt32());
                value = Integer.valueOf(buffer.getInt32());
                javaType = Types.INTEGER;
                length = 4;
                break;
            }
            case LogEvent.MYSQL_TYPE_TINY: {
                // XXX: How to check signed / unsigned?
                // value = Integer.valueOf(unsigned ? buffer.getUint8() :
                // buffer.getInt8());
                value = Integer.valueOf(buffer.getInt8());
                javaType = Types.TINYINT; // java.sql.Types.INTEGER;
                length = 1;
                break;
            }
            case LogEvent.MYSQL_TYPE_SHORT: {
                // XXX: How to check signed / unsigned?
                // value = Integer.valueOf(unsigned ? buffer.getUint16() :
                // buffer.getInt16());
                value = Integer.valueOf((short) buffer.getInt16());
                javaType = Types.SMALLINT; // java.sql.Types.INTEGER;
                length = 2;
                break;
            }
            case LogEvent.MYSQL_TYPE_INT24: {
                // XXX: How to check signed / unsigned?
                // value = Integer.valueOf(unsigned ? buffer.getUint24() :
                // buffer.getInt24());
                value = Integer.valueOf(buffer.getInt24());
                javaType = Types.INTEGER;
                length = 3;
                break;
            }
            case LogEvent.MYSQL_TYPE_LONGLONG: {
                // XXX: How to check signed / unsigned?
                // value = unsigned ? buffer.getUlong64()) :
                // Long.valueOf(buffer.getLong64());
                value = Long.valueOf(buffer.getLong64());
                javaType = Types.BIGINT; // Types.INTEGER;
                length = 8;
                break;
            }
            case LogEvent.MYSQL_TYPE_DECIMAL: {
                /*
                 * log_event.h : This enumeration value is only used internally
                 * and cannot exist in a binlog.
                 */
                logger.warn(""MYSQL_TYPE_DECIMAL : This enumeration value is ""
                            + ""only used internally and cannot exist in a binlog!"");
                javaType = Types.DECIMAL;
                value = null; /* unknown format */
                length = 0;
                break;
            }
            case LogEvent.MYSQL_TYPE_NEWDECIMAL: {
                final int precision = meta >> 8;
                final int decimals = meta & 0xff;
                value = buffer.getDecimal(precision, decimals);
                javaType = Types.DECIMAL;
                length = precision;
                break;
            }
            case LogEvent.MYSQL_TYPE_FLOAT: {
                value = Float.valueOf(buffer.getFloat32());
                javaType = Types.REAL; // Types.FLOAT;
                length = 4;
                break;
            }
            case LogEvent.MYSQL_TYPE_DOUBLE: {
                value = Double.valueOf(buffer.getDouble64());
                javaType = Types.DOUBLE;
                length = 8;
                break;
            }
            case LogEvent.MYSQL_TYPE_BIT: {
                /* Meta-data: bit_len, bytes_in_rec, 2 bytes */
                final int nbits = ((meta >> 8) * 8) + (meta & 0xff);
                len = (nbits + 7) / 8;
                if (nbits > 1) {
                    // byte[] bits = new byte[len];
                    // buffer.fillBytes(bits, 0, len);
                    // 转化为unsign long
                    switch (len) {
                        case 1:
                            value = buffer.getUint8();
                            break;
                        case 2:
                            value = buffer.getBeUint16();
                            break;
                        case 3:
                            value = buffer.getBeUint24();
                            break;
                        case 4:
                            value = buffer.getBeUint32();
                            break;
                        case 5:
                            value = buffer.getBeUlong40();
                            break;
                        case 6:
                            value = buffer.getBeUlong48();
                            break;
                        case 7:
                            value = buffer.getBeUlong56();
                            break;
                        case 8:
                            value = buffer.getBeUlong64();
                            break;
                        default:
                            throw new IllegalArgumentException(""!! Unknown Bit len = "" + len);
                    }
                } else {
                    final int bit = buffer.getInt8();
                    // value = (bit != 0) ? Boolean.TRUE : Boolean.FALSE;
                    value = bit;
                }
                javaType = Types.BIT;
                length = nbits;
                break;
            }
            case LogEvent.MYSQL_TYPE_TIMESTAMP: {
                // MYSQL DataTypes: TIMESTAMP
                // range is '1970-01-01 00:00:01' UTC to '2038-01-19 03:14:07'
                // UTC
                // A TIMESTAMP cannot represent the value '1970-01-01 00:00:00'
                // because that is equivalent to 0 seconds from the epoch and
                // the value 0 is reserved for representing '0000-00-00
                // 00:00:00', the “zero” TIMESTAMP value.
                final long i32 = buffer.getUint32();
                if (i32 == 0) {
                    value = ""0000-00-00 00:00:00"";
                } else {
                    String v = new Timestamp(i32 * 1000).toString();
                    value = v.substring(0, v.length() - 2);
                }
                javaType = Types.TIMESTAMP;
                length = 4;
                break;
            }
            case LogEvent.MYSQL_TYPE_TIMESTAMP2: {
                final long tv_sec = buffer.getBeUint32(); // big-endian
                int tv_usec = 0;
                switch (meta) {
                    case 0:
                        tv_usec = 0;
                        break;
                    case 1:
                    case 2:
                        tv_usec = buffer.getInt8() * 10000;
                        break;
                    case 3:
                    case 4:
                        tv_usec = buffer.getBeInt16() * 100;
                        break;
                    case 5:
                    case 6:
                        tv_usec = buffer.getBeInt24();
                        break;
                    default:
                        tv_usec = 0;
                        break;
                }

                String second = null;
                if (tv_sec == 0) {
                    second = ""0000-00-00 00:00:00"";
                } else {
                    Timestamp time = new Timestamp(tv_sec * 1000);
                    second = time.toString();
                    second = second.substring(0, second.length() - 2);// 去掉毫秒精度.0
                }

                if (meta >= 1) {
                    String microSecond = usecondsToStr(tv_usec, meta);
                    microSecond = microSecond.substring(0, meta);
                    value = second + '.' + microSecond;
                } else {
                    value = second;
                }

                javaType = Types.TIMESTAMP;
                length = 4 + (meta + 1) / 2;
                break;
            }
            case LogEvent.MYSQL_TYPE_DATETIME: {
                // MYSQL DataTypes: DATETIME
                // range is '0000-01-01 00:00:00' to '9999-12-31 23:59:59'
                final long i64 = buffer.getLong64(); /* YYYYMMDDhhmmss */
                if (i64 == 0) {
                    value = ""0000-00-00 00:00:00"";
                } else {
                    final int d = (int) (i64 / 1000000);
                    final int t = (int) (i64 % 1000000);
                    // if (cal == null) cal = Calendar.getInstance();
                    // cal.clear();
                    /* month is 0-based, 0 for january. */
                    // cal.set(d / 10000, (d % 10000) / 100 - 1, d % 100, t /
                    // 10000, (t % 10000) / 100, t % 100);
                    // value = new Timestamp(cal.getTimeInMillis());
                    // value = String.format(""%04d-%02d-%02d %02d:%02d:%02d"",
                    // d / 10000,
                    // (d % 10000) / 100,
                    // d % 100,
                    // t / 10000,
                    // (t % 10000) / 100,
                    // t % 100);

                    StringBuilder builder = new StringBuilder();
                    appendNumber4(builder, d / 10000);
                    builder.append('-');
                    appendNumber2(builder, (d % 10000) / 100);
                    builder.append('-');
                    appendNumber2(builder, d % 100);
                    builder.append(' ');
                    appendNumber2(builder, t / 10000);
                    builder.append(':');
                    appendNumber2(builder, (t % 10000) / 100);
                    builder.append(':');
                    appendNumber2(builder, t % 100);
                    value = builder.toString();
                }
                javaType = Types.TIMESTAMP;
                length = 8;
                break;
            }
            case LogEvent.MYSQL_TYPE_DATETIME2: {
                /*
                 * DATETIME and DATE low-level memory and disk representation
                 * routines 1 bit sign (used when on disk) 17 bits year*13+month
                 * (year 0-9999, month 0-12) 5 bits day (0-31) 5 bits hour
                 * (0-23) 6 bits minute (0-59) 6 bits second (0-59) 24 bits
                 * microseconds (0-999999) Total: 64 bits = 8 bytes
                 * SYYYYYYY.YYYYYYYY
                 * .YYdddddh.hhhhmmmm.mmssssss.ffffffff.ffffffff.ffffffff
                 */
                long intpart = buffer.getBeUlong40() - DATETIMEF_INT_OFS; // big-endian
                int frac = 0;
                switch (meta) {
                    case 0:
                        frac = 0;
                        break;
                    case 1:
                    case 2:
                        frac = buffer.getInt8() * 10000;
                        break;
                    case 3:
                    case 4:
                        frac = buffer.getBeInt16() * 100;
                        break;
                    case 5:
                    case 6:
                        frac = buffer.getBeInt24();
                        break;
                    default:
                        frac = 0;
                        break;
                }

                String second = null;
                if (intpart == 0) {
                    second = ""0000-00-00 00:00:00"";
                } else {
                    // 构造TimeStamp只处理到秒
                    long ymd = intpart >> 17;
                    long ym = ymd >> 5;
                    long hms = intpart % (1 << 17);

                    // if (cal == null) cal = Calendar.getInstance();
                    // cal.clear();
                    // cal.set((int) (ym / 13), (int) (ym % 13) - 1, (int) (ymd
                    // % (1 << 5)), (int) (hms >> 12),
                    // (int) ((hms >> 6) % (1 << 6)), (int) (hms % (1 << 6)));
                    // value = new Timestamp(cal.getTimeInMillis());
                    // second = String.format(""%04d-%02d-%02d %02d:%02d:%02d"",
                    // (int) (ym / 13),
                    // (int) (ym % 13),
                    // (int) (ymd % (1 << 5)),
                    // (int) (hms >> 12),
                    // (int) ((hms >> 6) % (1 << 6)),
                    // (int) (hms % (1 << 6)));

                    StringBuilder builder = new StringBuilder(26);
                    appendNumber4(builder, (int) (ym / 13));
                    builder.append('-');
                    appendNumber2(builder, (int) (ym % 13));
                    builder.append('-');
                    appendNumber2(builder, (int) (ymd % (1 << 5)));
                    builder.append(' ');
                    appendNumber2(builder, (int) (hms >> 12));
                    builder.append(':');
                    appendNumber2(builder, (int) ((hms >> 6) % (1 << 6)));
                    builder.append(':');
                    appendNumber2(builder, (int) (hms % (1 << 6)));
                    second = builder.toString();
                }

                if (meta >= 1) {
                    String microSecond = usecondsToStr(frac, meta);
                    microSecond = microSecond.substring(0, meta);
                    value = second + '.' + microSecond;
                } else {
                    value = second;
                }

                javaType = Types.TIMESTAMP;
                length = 5 + (meta + 1) / 2;
                break;
            }
            case LogEvent.MYSQL_TYPE_TIME: {
                // MYSQL DataTypes: TIME
                // The range is '-838:59:59' to '838:59:59'
                // final int i32 = buffer.getUint24();
                final int i32 = buffer.getInt24();
                final int u32 = Math.abs(i32);
                if (i32 == 0) {
                    value = ""00:00:00"";
                } else {
                    // if (cal == null) cal = Calendar.getInstance();
                    // cal.clear();
                    // cal.set(70, 0, 1, i32 / 10000, (i32 % 10000) / 100, i32 %
                    // 100);
                    // value = new Time(cal.getTimeInMillis());
                    // value = String.format(""%s%02d:%02d:%02d"",
                    // (i32 >= 0) ? """" : ""-"",
                    // u32 / 10000,
                    // (u32 % 10000) / 100,
                    // u32 % 100);

                    StringBuilder builder = new StringBuilder(17);
                    if (i32 < 0) {
                        builder.append('-');
                    }

                    int d = u32 / 10000;
                    if (d > 100) {
                        builder.append(String.valueOf(d));
                    } else {
                        appendNumber2(builder, d);
                    }
                    builder.append(':');
                    appendNumber2(builder, (u32 % 10000) / 100);
                    builder.append(':');
                    appendNumber2(builder, u32 % 100);
                    value = builder.toString();
                }
                javaType = Types.TIME;
                length = 3;
                break;
            }
            case LogEvent.MYSQL_TYPE_TIME2: {
                /*
                 * TIME low-level memory and disk representation routines
                 * In-memory format: 1 bit sign (Used for sign, when on disk) 1
                 * bit unused (Reserved for wider hour range, e.g. for
                 * intervals) 10 bit hour (0-836) 6 bit minute (0-59) 6 bit
                 * second (0-59) 24 bits microseconds (0-999999) Total: 48 bits
                 * = 6 bytes
                 * Suhhhhhh.hhhhmmmm.mmssssss.ffffffff.ffffffff.ffffffff
                 */
                long intpart = 0;
                int frac = 0;
                long ltime = 0;
                switch (meta) {
                    case 0:
                        intpart = buffer.getBeUint24() - TIMEF_INT_OFS; // big-endian
                        ltime = intpart << 24;
                        break;
                    case 1:
                    case 2:
                        intpart = buffer.getBeUint24() - TIMEF_INT_OFS;
                        frac = buffer.getUint8();
                        if (intpart < 0 && frac > 0) {
                            /*
                             * Negative values are stored with reverse
                             * fractional part order, for binary sort
                             * compatibility. Disk value intpart frac Time value
                             * Memory value 800000.00 0 0 00:00:00.00
                             * 0000000000.000000 7FFFFF.FF -1 255 -00:00:00.01
                             * FFFFFFFFFF.FFD8F0 7FFFFF.9D -1 99 -00:00:00.99
                             * FFFFFFFFFF.F0E4D0 7FFFFF.00 -1 0 -00:00:01.00
                             * FFFFFFFFFF.000000 7FFFFE.FF -1 255 -00:00:01.01
                             * FFFFFFFFFE.FFD8F0 7FFFFE.F6 -2 246 -00:00:01.10
                             * FFFFFFFFFE.FE7960 Formula to convert fractional
                             * part from disk format (now stored in ""frac""
                             * variable) to absolute value: ""0x100 - frac"". To
                             * reconstruct in-memory value, we shift to the next
                             * integer value and then substruct fractional part.
                             */
                            intpart++; /* Shift to the next integer value */
                            frac -= 0x100; /* -(0x100 - frac) */
                            // fraclong = frac * 10000;
                        }
                        frac = frac * 10000;
                        ltime = intpart << 24;
                        break;
                    case 3:
                    case 4:
                        intpart = buffer.getBeUint24() - TIMEF_INT_OFS;
                        frac = buffer.getBeUint16();
                        if (intpart < 0 && frac > 0) {
                            /*
                             * Fix reverse fractional part order:
                             * ""0x10000 - frac"". See comments for FSP=1 and
                             * FSP=2 above.
                             */
                            intpart++; /* Shift to the next integer value */
                            frac -= 0x10000; /* -(0x10000-frac) */
                            // fraclong = frac * 100;
                        }
                        frac = frac * 100;
                        ltime = intpart << 24;
                        break;
                    case 5:
                    case 6:
                        intpart = buffer.getBeUlong48() - TIMEF_OFS;
                        ltime = intpart;
                        frac = (int) (intpart % (1L << 24));
                        break;
                    default:
                        intpart = buffer.getBeUint24() - TIMEF_INT_OFS;
                        ltime = intpart << 24;
                        break;
                }

                String second = null;
                if (intpart == 0) {
                    second = ""00:00:00"";
                } else {
                    // 目前只记录秒，不处理us frac
                    // if (cal == null) cal = Calendar.getInstance();
                    // cal.clear();
                    // cal.set(70, 0, 1, (int) ((intpart >> 12) % (1 << 10)),
                    // (int) ((intpart >> 6) % (1 << 6)),
                    // (int) (intpart % (1 << 6)));
                    // value = new Time(cal.getTimeInMillis());
                    long ultime = Math.abs(ltime);
                    intpart = ultime >> 24;
                    // second = String.format(""%s%02d:%02d:%02d"",
                    // ltime >= 0 ? """" : ""-"",
                    // (int) ((intpart >> 12) % (1 << 10)),
                    // (int) ((intpart >> 6) % (1 << 6)),
                    // (int) (intpart % (1 << 6)));

                    StringBuilder builder = new StringBuilder(12);
                    if (ltime < 0) {
                        builder.append('-');
                    }

                    int d = (int) ((intpart >> 12) % (1 << 10));
                    if (d > 100) {
                        builder.append(String.valueOf(d));
                    } else {
                        appendNumber2(builder, d);
                    }
                    builder.append(':');
                    appendNumber2(builder, (int) ((intpart >> 6) % (1 << 6)));
                    builder.append(':');
                    appendNumber2(builder, (int) (intpart % (1 << 6)));
                    second = builder.toString();
                }

                if (meta >= 1) {
                    String microSecond = usecondsToStr(Math.abs(frac), meta);
                    microSecond = microSecond.substring(0, meta);
                    value = second + '.' + microSecond;
                } else {
                    value = second;
                }

                javaType = Types.TIME;
                length = 3 + (meta + 1) / 2;
                break;
            }
            case LogEvent.MYSQL_TYPE_NEWDATE: {
                /*
                 * log_event.h : This enumeration value is only used internally
                 * and cannot exist in a binlog.
                 */
                logger.warn(""MYSQL_TYPE_NEWDATE : This enumeration value is ""
                            + ""only used internally and cannot exist in a binlog!"");
                javaType = Types.DATE;
                value = null; /* unknown format */
                length = 0;
                break;
            }
            case LogEvent.MYSQL_TYPE_DATE: {
                // MYSQL DataTypes:
                // range: 0000-00-00 ~ 9999-12-31
                final int i32 = buffer.getUint24();
                if (i32 == 0) {
                    value = ""0000-00-00"";
                } else {
                    // if (cal == null) cal = Calendar.getInstance();
                    // cal.clear();
                    /* month is 0-based, 0 for january. */
                    // cal.set((i32 / (16 * 32)), (i32 / 32 % 16) - 1, (i32 %
                    // 32));
                    // value = new java.sql.Date(cal.getTimeInMillis());
                    // value = String.format(""%04d-%02d-%02d"", i32 / (16 * 32),
                    // i32 / 32 % 16, i32 % 32);

                    StringBuilder builder = new StringBuilder(12);
                    appendNumber4(builder, i32 / (16 * 32));
                    builder.append('-');
                    appendNumber2(builder, i32 / 32 % 16);
                    builder.append('-');
                    appendNumber2(builder, i32 % 32);
                    value = builder.toString();
                }
                javaType = Types.DATE;
                length = 3;
                break;
            }
            case LogEvent.MYSQL_TYPE_YEAR: {
                // MYSQL DataTypes: YEAR[(2|4)]
                // In four-digit format, values display as 1901 to 2155, and
                // 0000.
                // In two-digit format, values display as 70 to 69, representing
                // years from 1970 to 2069.

                final int i32 = buffer.getUint8();
                // If connection property 'YearIsDateType' has
                // set, value is java.sql.Date.
                /*
                 * if (cal == null) cal = Calendar.getInstance(); cal.clear();
                 * cal.set(Calendar.YEAR, i32 + 1900); value = new
                 * java.sql.Date(cal.getTimeInMillis());
                 */
                // The else, value is java.lang.Short.
                if (i32 == 0) {
                    value = ""0000"";
                } else {
                    value = String.valueOf((short) (i32 + 1900));
                }
                // It might seem more correct to create a java.sql.Types.DATE
                // value
                // for this date, but it is much simpler to pass the value as an
                // integer. The MySQL JDBC specification states that one can
                // pass a java int between 1901 and 2055. Creating a DATE value
                // causes truncation errors with certain SQL_MODES
                // (e.g.""STRICT_TRANS_TABLES"").
                javaType = Types.VARCHAR; // Types.INTEGER;
                length = 1;
                break;
            }
            case LogEvent.MYSQL_TYPE_ENUM: {
                final int int32;
                /*
                 * log_event.h : This enumeration value is only used internally
                 * and cannot exist in a binlog.
                 */
                switch (len) {
                    case 1:
                        int32 = buffer.getUint8();
                        break;
                    case 2:
                        int32 = buffer.getUint16();
                        break;
                    default:
                        throw new IllegalArgumentException(""!! Unknown ENUM packlen = "" + len);
                }
                // logger.warn(""MYSQL_TYPE_ENUM : This enumeration value is ""
                // + ""only used internally and cannot exist in a binlog!"");
                value = Integer.valueOf(int32);
                javaType = Types.INTEGER;
                length = len;
                break;
            }
            case LogEvent.MYSQL_TYPE_SET: {
                final int nbits = (meta & 0xFF) * 8;
                len = (nbits + 7) / 8;
                if (nbits > 1) {
                    // byte[] bits = new byte[len];
                    // buffer.fillBytes(bits, 0, len);
                    // 转化为unsign long
                    switch (len) {
                        case 1:
                            value = buffer.getUint8();
                            break;
                        case 2:
                            value = buffer.getUint16();
                            break;
                        case 3:
                            value = buffer.getUint24();
                            break;
                        case 4:
                            value = buffer.getUint32();
                            break;
                        case 5:
                            value = buffer.getUlong40();
                            break;
                        case 6:
                            value = buffer.getUlong48();
                            break;
                        case 7:
                            value = buffer.getUlong56();
                            break;
                        case 8:
                            value = buffer.getUlong64();
                            break;
                        default:
                            throw new IllegalArgumentException(""!! Unknown Set len = "" + len);
                    }
                } else {
                    final int bit = buffer.getInt8();
                    // value = (bit != 0) ? Boolean.TRUE : Boolean.FALSE;
                    value = bit;
                }

                javaType = Types.BIT;
                length = len;
                break;
            }
            case LogEvent.MYSQL_TYPE_TINY_BLOB: {
                /*
                 * log_event.h : This enumeration value is only used internally
                 * and cannot exist in a binlog.
                 */
                logger.warn(""MYSQL_TYPE_TINY_BLOB : This enumeration value is ""
                            + ""only used internally and cannot exist in a binlog!"");
            }
            case LogEvent.MYSQL_TYPE_MEDIUM_BLOB: {
                /*
                 * log_event.h : This enumeration value is only used internally
                 * and cannot exist in a binlog.
                 */
                logger.warn(""MYSQL_TYPE_MEDIUM_BLOB : This enumeration value is ""
                            + ""only used internally and cannot exist in a binlog!"");
            }
            case LogEvent.MYSQL_TYPE_LONG_BLOB: {
                /*
                 * log_event.h : This enumeration value is only used internally
                 * and cannot exist in a binlog.
                 */
                logger.warn(""MYSQL_TYPE_LONG_BLOB : This enumeration value is ""
                            + ""only used internally and cannot exist in a binlog!"");
            }
            case LogEvent.MYSQL_TYPE_BLOB: {
                /*
                 * BLOB or TEXT datatype
                 */
                switch (meta) {
                    case 1: {
                        /* TINYBLOB/TINYTEXT */
                        final int len8 = buffer.getUint8();
                        byte[] binary = new byte[len8];
                        buffer.fillBytes(binary, 0, len8);
                        value = binary;
                        javaType = Types.VARBINARY;
                        length = len8;
                        break;
                    }
                    case 2: {
                        /* BLOB/TEXT */
                        final int len16 = buffer.getUint16();
                        byte[] binary = new byte[len16];
                        buffer.fillBytes(binary, 0, len16);
                        value = binary;
                        javaType = Types.LONGVARBINARY;
                        length = len16;
                        break;
                    }
                    case 3: {
                        /* MEDIUMBLOB/MEDIUMTEXT */
                        final int len24 = buffer.getUint24();
                        byte[] binary = new byte[len24];
                        buffer.fillBytes(binary, 0, len24);
                        value = binary;
                        javaType = Types.LONGVARBINARY;
                        length = len24;
                        break;
                    }
                    case 4: {
                        /* LONGBLOB/LONGTEXT */
                        final int len32 = (int) buffer.getUint32();
                        byte[] binary = new byte[len32];
                        buffer.fillBytes(binary, 0, len32);
                        value = binary;
                        javaType = Types.LONGVARBINARY;
                        length = len32;
                        break;
                    }
                    default:
                        throw new IllegalArgumentException(""!! Unknown BLOB packlen = "" + meta);
                }
                break;
            }
            case LogEvent.MYSQL_TYPE_VARCHAR:
            case LogEvent.MYSQL_TYPE_VAR_STRING: {
                /*
                 * Except for the data length calculation, MYSQL_TYPE_VARCHAR,
                 * MYSQL_TYPE_VAR_STRING and MYSQL_TYPE_STRING are handled the
                 * same way.
                 */
                len = meta;
                if (len < 256) {
                    len = buffer.getUint8();
                } else {
                    len = buffer.getUint16();
                }

                if (isBinary) {
                    // fixed issue #66 ,binary类型在binlog中为var_string
                    /* fill binary */
                    byte[] binary = new byte[len];
                    buffer.fillBytes(binary, 0, len);

                    javaType = Types.VARBINARY;
                    value = binary;
                } else {
                    value = buffer.getFullString(len, charsetName);
                    javaType = Types.VARCHAR;
                }

                length = len;
                break;
            }
            case LogEvent.MYSQL_TYPE_STRING: {
                if (len < 256) {
                    len = buffer.getUint8();
                } else {
                    len = buffer.getUint16();
                }

                if (isBinary) {
                    /* fill binary */
                    byte[] binary = new byte[len];
                    buffer.fillBytes(binary, 0, len);

                    javaType = Types.BINARY;
                    value = binary;
                } else {
                    value = buffer.getFullString(len, charsetName);
                    javaType = Types.CHAR; // Types.VARCHAR;
                }
                length = len;
                break;
            }
            case LogEvent.MYSQL_TYPE_JSON: {
                switch (meta) {
                    case 1: {
                        len = buffer.getUint8();
                        break;
                    }
                    case 2: {
                        len = buffer.getUint16();
                        break;
                    }
                    case 3: {
                        len = buffer.getUint24();
                        break;
                    }
                    case 4: {
                        len = (int) buffer.getUint32();
                        break;
                    }
                    default:
                        throw new IllegalArgumentException(""!! Unknown JSON packlen = "" + meta);
                }

                if (partialBits.get(1)) {
                    // print_json_diff
                    int position = buffer.position();
                    StringBuilder builder = JsonDiffConversion.print_json_diff(buffer,
                        len,
                        columnName,
                        columnIndex,
                        charsetName);
                    value = builder.toString();
                    buffer.position(position + len);
                } else {
                    if (0 == len) {
                        // fixed issue #1 by lava, json column of zero length
                        // has no
                        // value, value parsing should be skipped
                        value = """";
                    } else {
                        int position = buffer.position();
                        Json_Value jsonValue = JsonConversion.parse_value(buffer.getUint8(),
                            buffer,
                            len - 1,
                            charsetName);
                        StringBuilder builder = new StringBuilder();
                        jsonValue.toJsonString(builder, charsetName);
                        value = builder.toString();
                        buffer.position(position + len);
                    }
                }
                javaType = Types.VARCHAR;
                length = len;
                break;
            }
            case LogEvent.MYSQL_TYPE_GEOMETRY: {
                /*
                 * MYSQL_TYPE_GEOMETRY: copy from BLOB or TEXT
                 */
                switch (meta) {
                    case 1:
                        len = buffer.getUint8();
                        break;
                    case 2:
                        len = buffer.getUint16();
                        break;
                    case 3:
                        len = buffer.getUint24();
                        break;
                    case 4:
                        len = (int) buffer.getUint32();
                        break;
                    default:
                        throw new IllegalArgumentException(""!! Unknown MYSQL_TYPE_GEOMETRY packlen = "" + meta);
                }
                /* fill binary */
                byte[] binary = new byte[len];
                buffer.fillBytes(binary, 0, len);

                /* Warning unsupport cloumn type */
                // logger.warn(String.format(""!! Unsupport column type MYSQL_TYPE_GEOMETRY: meta=%d (%04X), len = %d"",
                // meta,
                // meta,
                // len));
                javaType = Types.BINARY;
                value = binary;
                length = len;
                break;
            }
            default:
                logger.error(String.format(""!! Don't know how to handle column type=%d meta=%d (%04X)"",
                    type,
                    meta,
                    meta));
                javaType = Types.OTHER;
                value = null;
                length = 0;
        }

        return value;
    }"
"public static SQLParser newInstance(final DatabaseType dbType, final EncryptRule encryptRule, final ShardingTableMetaData shardingTableMetaData, final String sql) {
        if (DatabaseType.MySQL == dbType || DatabaseType.H2 == dbType) {
            return new AntlrParsingEngine(dbType, sql, encryptRule, shardingTableMetaData);
        }
        throw new SQLParsingUnsupportedException(String.format(""Can not support %s"", dbType)); 
    }"
"public static AlternateTypeRule newRule(Type original, Type alternate, int order) {
    TypeResolver resolver = new TypeResolver();
    return new AlternateTypeRule(resolver.resolve(original), resolver.resolve(alternate), order);
  }"
"public static Set<LabelAtom> parse(String labels) {
        final Set<LabelAtom> r = new TreeSet<>();
        labels = fixNull(labels);
        if(labels.length()>0) {
            final QuotedStringTokenizer tokenizer = new QuotedStringTokenizer(labels);
            while (tokenizer.hasMoreTokens())
                r.add(Jenkins.getInstance().getLabelAtom(tokenizer.nextToken()));
            }
        return r;
    }"
"public ByteBuilder appendSpecial(long value, int length, boolean preserveNegative){
		testAddition(length);
		{
			byte[] b = new byte[length];
	        for (int i = 0; i < length; i++) {
	            int offset = (b.length - 1 - i) * 8;
	            b[i] = (byte) ((value >>> offset) & 0xFF);
	            if (preserveNegative && i == 0){
	            	if (value < 0){ //original value is negative
	            		b[i] |= 0x80; // 1000 0000 - or'ed into the value to make it negative
	            	} else { //original value is positive
	            		b[i] &= 0x7F; // 0111 0000 - and'ed into the value to clear the negative bit
	            	}
	            }
	        }
	        
	        copyIntoArray(b);
		}
		
		return this;
	}"
"public static boolean arrayEquals(
      Object leftBase, long leftOffset, Object rightBase, long rightOffset, final long length) {
    int i = 0;

    // check if stars align and we can get both offsets to be aligned
    if ((leftOffset % 8) == (rightOffset % 8)) {
      while ((leftOffset + i) % 8 != 0 && i < length) {
        if (Platform.getByte(leftBase, leftOffset + i) !=
            Platform.getByte(rightBase, rightOffset + i)) {
              return false;
        }
        i += 1;
      }
    }
    // for architectures that support unaligned accesses, chew it up 8 bytes at a time
    if (unaligned || (((leftOffset + i) % 8 == 0) && ((rightOffset + i) % 8 == 0))) {
      while (i <= length - 8) {
        if (Platform.getLong(leftBase, leftOffset + i) !=
            Platform.getLong(rightBase, rightOffset + i)) {
              return false;
        }
        i += 8;
      }
    }
    // this will finish off the unaligned comparisons, or do the entire aligned
    // comparison whichever is needed.
    while (i < length) {
      if (Platform.getByte(leftBase, leftOffset + i) !=
          Platform.getByte(rightBase, rightOffset + i)) {
            return false;
      }
      i += 1;
    }
    return true;
  }"
"protected boolean isAPI(TurbineRunData rundata) {
        String requestUrl = rundata.getRequest().getRequestURI();
        return StringUtils.containsIgnoreCase(requestUrl, ""/api/"");
    }"
"public static SentenceIterator createWithPath(String path) throws Exception {
        return new UimaSentenceIterator(path,
                        new UimaResource(AnalysisEngineFactory.createEngine(AnalysisEngineFactory
                                        .createEngineDescription(TokenizerAnnotator.getDescription(),
                                                        SentenceAnnotator.getDescription()))));
    }"
"public void checkSubTree(TreePath tp, boolean check) {
        CheckedNode cn = nodesCheckingState.get(tp);
        cn.isSelected = check;
        DefaultMutableTreeNode node = (DefaultMutableTreeNode) tp.getLastPathComponent();
        for (int i = 0 ; i < node.getChildCount() ; i++) {              
            checkSubTree(tp.pathByAddingChild(node.getChildAt(i)), check);
        }
        cn.allChildrenSelected = check;
        if (check) {
            checkedPaths.add(tp);
        } else {
            checkedPaths.remove(tp);
        }
        updatePredecessorsAllChildrenSelectedState(tp);
    }"
"public ApiListingBuilder availableTags(Set<Tag> availableTags) {
    this.tagLookup.putAll(nullToEmptySet(availableTags).stream().collect(toMap(Tag::getName, identity())));
    return this;
  }"
"public static ExpectedCondition<WebElement> elementToBeClickable(final By locator) {
    return new ExpectedCondition<WebElement>() {
      @Override
      public WebElement apply(WebDriver driver) {
        WebElement element = visibilityOfElementLocated(locator).apply(driver);
        try {
          if (element != null && element.isEnabled()) {
            return element;
          }
          return null;
        } catch (StaleElementReferenceException e) {
          return null;
        }
      }

      @Override
      public String toString() {
        return ""element to be clickable: "" + locator;
      }
    };
  }"
"public static int sortKeyPrefixArray(
      LongArray array,
      long startIndex,
      long numRecords,
      int startByteIndex,
      int endByteIndex,
      boolean desc,
      boolean signed) {
    assert startByteIndex >= 0 : ""startByteIndex ("" + startByteIndex + "") should >= 0"";
    assert endByteIndex <= 7 : ""endByteIndex ("" + endByteIndex + "") should <= 7"";
    assert endByteIndex > startByteIndex;
    assert numRecords * 4 <= array.size();
    long inIndex = startIndex;
    long outIndex = startIndex + numRecords * 2L;
    if (numRecords > 0) {
      long[][] counts = getKeyPrefixArrayCounts(
        array, startIndex, numRecords, startByteIndex, endByteIndex);
      for (int i = startByteIndex; i <= endByteIndex; i++) {
        if (counts[i] != null) {
          sortKeyPrefixArrayAtByte(
            array, numRecords, counts[i], i, inIndex, outIndex,
            desc, signed && i == endByteIndex);
          long tmp = inIndex;
          inIndex = outIndex;
          outIndex = tmp;
        }
      }
    }
    return Ints.checkedCast(inIndex);
  }"
"public static ColumnIO lookupColumnByName(GroupColumnIO groupColumnIO, String columnName)
    {
        ColumnIO columnIO = groupColumnIO.getChild(columnName);

        if (columnIO != null) {
            return columnIO;
        }

        for (int i = 0; i < groupColumnIO.getChildrenCount(); i++) {
            if (groupColumnIO.getChild(i).getName().equalsIgnoreCase(columnName)) {
                return groupColumnIO.getChild(i);
            }
        }

        return null;
    }"
"@Deprecated
    public static void writeFullModel(@NonNull Word2Vec vec, @NonNull String path) {
        /*
            Basically we need to save:
                    1. WeightLookupTable, especially syn0 and syn1 matrices
                    2. VocabCache, including only WordCounts
                    3. Settings from Word2Vect model: workers, layers, etc.
         */

        PrintWriter printWriter = null;
        try {
            printWriter = new PrintWriter(new OutputStreamWriter(new FileOutputStream(path), ""UTF-8""));
        } catch (Exception e) {
            throw new RuntimeException(e);
        }

        WeightLookupTable<VocabWord> lookupTable = vec.getLookupTable();
        VocabCache<VocabWord> vocabCache = vec.getVocab(); // ((InMemoryLookupTable) lookupTable).getVocab(); //vec.getVocab();


        if (!(lookupTable instanceof InMemoryLookupTable))
            throw new IllegalStateException(""At this moment only InMemoryLookupTable is supported."");

        VectorsConfiguration conf = vec.getConfiguration();
        conf.setVocabSize(vocabCache.numWords());


        printWriter.println(conf.toJson());
        //log.info(""Word2Vec conf. JSON: "" + conf.toJson());
        /*
            We have the following map:
            Line 0 - VectorsConfiguration JSON string
            Line 1 - expTable
            Line 2 - table
        
            All following lines are vocab/weight lookup table saved line by line as VocabularyWord JSON representation
         */

        // actually we don't need expTable, since it produces exact results on subsequent runs untill you dont modify expTable size :)
        // saving ExpTable just for ""special case in future""
        StringBuilder builder = new StringBuilder();
        for (int x = 0; x < ((InMemoryLookupTable) lookupTable).getExpTable().length; x++) {
            builder.append(((InMemoryLookupTable) lookupTable).getExpTable()[x]).append("" "");
        }
        printWriter.println(builder.toString().trim());

        // saving table, available only if negative sampling is used
        if (conf.getNegative() > 0 && ((InMemoryLookupTable) lookupTable).getTable() != null) {
            builder = new StringBuilder();
            for (int x = 0; x < ((InMemoryLookupTable) lookupTable).getTable().columns(); x++) {
                builder.append(((InMemoryLookupTable) lookupTable).getTable().getDouble(x)).append("" "");
            }
            printWriter.println(builder.toString().trim());
        } else
            printWriter.println("""");


        List<VocabWord> words = new ArrayList<>(vocabCache.vocabWords());
        for (SequenceElement word : words) {
            VocabularyWord vw = new VocabularyWord(word.getLabel());
            vw.setCount(vocabCache.wordFrequency(word.getLabel()));

            vw.setHuffmanNode(VocabularyHolder.buildNode(word.getCodes(), word.getPoints(), word.getCodeLength(),
                    word.getIndex()));


            // writing down syn0
            INDArray syn0 = ((InMemoryLookupTable) lookupTable).getSyn0().getRow(vocabCache.indexOf(word.getLabel()));
            double[] dsyn0 = new double[syn0.columns()];
            for (int x = 0; x < conf.getLayersSize(); x++) {
                dsyn0[x] = syn0.getDouble(x);
            }
            vw.setSyn0(dsyn0);

            // writing down syn1
            INDArray syn1 = ((InMemoryLookupTable) lookupTable).getSyn1().getRow(vocabCache.indexOf(word.getLabel()));
            double[] dsyn1 = new double[syn1.columns()];
            for (int x = 0; x < syn1.columns(); x++) {
                dsyn1[x] = syn1.getDouble(x);
            }
            vw.setSyn1(dsyn1);

            // writing down syn1Neg, if negative sampling is used
            if (conf.getNegative() > 0 && ((InMemoryLookupTable) lookupTable).getSyn1Neg() != null) {
                INDArray syn1Neg = ((InMemoryLookupTable) lookupTable).getSyn1Neg()
                        .getRow(vocabCache.indexOf(word.getLabel()));
                double[] dsyn1Neg = new double[syn1Neg.columns()];
                for (int x = 0; x < syn1Neg.columns(); x++) {
                    dsyn1Neg[x] = syn1Neg.getDouble(x);
                }
                vw.setSyn1Neg(dsyn1Neg);
            }


            // in case of UseAdaGrad == true - we should save gradients for each word in vocab
            if (conf.isUseAdaGrad() && ((InMemoryLookupTable) lookupTable).isUseAdaGrad()) {
                INDArray gradient = word.getHistoricalGradient();
                if (gradient == null)
                    gradient = Nd4j.zeros(word.getCodes().size());
                double ada[] = new double[gradient.columns()];
                for (int x = 0; x < gradient.columns(); x++) {
                    ada[x] = gradient.getDouble(x);
                }
                vw.setHistoricalGradient(ada);
            }

            printWriter.println(vw.toJson());
        }

        // at this moment we have whole vocab serialized
        printWriter.flush();
        printWriter.close();
    }"
"protected List<ExtensionComponent<T>> load() {
        LOGGER.fine(() -> String.format(""Loading ExtensionList '%s'"", extensionType.getName()));
        if (LOGGER.isLoggable(Level.FINER)) {
            LOGGER.log(Level.FINER, String.format(""Loading ExtensionList '%s' from"", extensionType.getName()), new Throwable(""Only present for stacktrace information""));
        }

        return jenkins.getPluginManager().getPluginStrategy().findComponents(extensionType, hudson);
    }"
"public void storeLocal(final File file) throws IOException {
    final BufferedOutputStream out =
        new BufferedOutputStream(new FileOutputStream(file));
    try {
      storeLocal(out);
    } finally {
      out.close();
    }
  }"
"private JScrollPane getJScrollPane() {
        if (jScrollPane == null) {
            jScrollPane = new JScrollPane();
            jScrollPane.setViewportView(getTreeParam());
            jScrollPane.setBorder(javax.swing.BorderFactory.createEmptyBorder(0, 0, 0, 0));
        }
        
        return jScrollPane;
    }"
"public boolean contains(int o)
  {
    if (isEmpty() || o > last || o < 0) {
      return false;
    }

    // check if the element is within a literal word
    int block = maxLiteralLengthDivision(o);
    int bit = maxLiteralLengthModulus(o);
    for (int i = 0; i <= lastWordIndex; i++) {
      final int w = words[i];
      final int t = w & 0xC0000000; // the first two bits...
      switch (t) {
        case 0x80000000:  // LITERAL
        case 0xC0000000:  // LITERAL
          // check if the current literal word is the ""right"" one
          if (block == 0) {
            return (w & (1 << bit)) != 0;
          }
          block--;
          break;
        case 0x00000000:  // ZERO SEQUENCE
          if (!simulateWAH) {
            if (block == 0 && ((w >> 25) - 1) == bit) {
              return true;
            }
          }
          block -= getSequenceCount(w) + 1;
          if (block < 0) {
            return false;
          }
          break;
        case 0x40000000:  // ONE SEQUENCE
          if (!simulateWAH) {
            if (block == 0 && (0x0000001F & (w >> 25) - 1) == bit) {
              return false;
            }
          }
          block -= getSequenceCount(w) + 1;
          if (block < 0) {
            return true;
          }
          break;
      }
    }

    // no more words
    return false;
  }"
"private void check_Min_Value(long l, int cIdx, int rowNumber, ParseWriter dout) {
    if (l <= Long.MIN_VALUE) {
      String warning = ""Orc Parser: Long.MIN_VALUE: "" + l + "" is found in column ""+cIdx+"" row ""+rowNumber +
          "" of stripe ""+_cidx +"".  This value is used for sentinel and will not be parsed correctly."";
      dout.addError(new ParseWriter.ParseErr(warning, _cidx, rowNumber, -2L));
    }
  }"
"private void xor(byte[] data, byte[] kdfOut, int dOff, int dRemaining) {
		for (int i = 0; i != dRemaining; i++) {
			data[dOff + i] ^= kdfOut[i];
		}
	}"
"public static boolean hasText(@Nullable CharSequence str) {
        if (isEmpty(str)) {
            return false;
        }

        int strLen = str.length();
        for (int i = 0; i < strLen; i++) {
            if (!Character.isWhitespace(str.charAt(i))) {
                return true;
            }
        }
        return false;
    }"
"private static void safelyTruncateFile(
			final FileSystem fileSystem,
			final Path path,
			final HadoopFsRecoverable recoverable) throws IOException {

		ensureTruncateInitialized();

		waitUntilLeaseIsRevoked(fileSystem, path);

		// truncate back and append
		boolean truncated;
		try {
			truncated = truncate(fileSystem, path, recoverable.offset());
		} catch (Exception e) {
			throw new IOException(""Problem while truncating file: "" + path, e);
		}

		if (!truncated) {
			// Truncate did not complete immediately, we must wait for
			// the operation to complete and release the lease.
			waitUntilLeaseIsRevoked(fileSystem, path);
		}
	}"
"public static CookieGenerationContext buildCookieGenerationContext(final TicketGrantingCookieProperties cookie) {
        val rememberMeMaxAge = (int) Beans.newDuration(cookie.getRememberMeMaxAge()).getSeconds();
        val builder = buildCookieGenerationContextBuilder(cookie);
        return builder.rememberMeMaxAge(rememberMeMaxAge).build();
    }"
"public <U extends T> List<U> getAll(Class<U> type) {
        List<U> r = new ArrayList<>();
        for (T t : data)
            if(type.isInstance(t))
                r.add(type.cast(t));
        return r;
    }"
"public static <T> File writeUtf8Lines(Collection<T> list, String path) throws IORuntimeException {
		return writeLines(list, path, CharsetUtil.CHARSET_UTF_8);
	}"
"public void handleMethod(EclipseNode annotation, AbstractMethodDeclaration method, List<DeclaredException> exceptions) {
		if (method.isAbstract()) {
			annotation.addError(""@SneakyThrows can only be used on concrete methods."");
			return;
		}
		
		if (method.statements == null || method.statements.length == 0) {
			boolean hasConstructorCall = false;
			if (method instanceof ConstructorDeclaration) {
				ExplicitConstructorCall constructorCall = ((ConstructorDeclaration) method).constructorCall;
				hasConstructorCall = constructorCall != null && !constructorCall.isImplicitSuper() && !constructorCall.isImplicitThis();
			}
			
			if (hasConstructorCall) {
				annotation.addWarning(""Calls to sibling / super constructors are always excluded from @SneakyThrows; @SneakyThrows has been ignored because there is no other code in this constructor."");
			} else {
				annotation.addWarning(""This method or constructor is empty; @SneakyThrows has been ignored."");
			}
			
			return;
		}
		
		Statement[] contents = method.statements;
		
		for (DeclaredException exception : exceptions) {
			contents = new Statement[] { buildTryCatchBlock(contents, exception, exception.node, method) };
		}
		
		method.statements = contents;
		annotation.up().rebuild();
	}"
"@Deprecated
	@SuppressWarnings(""unchecked"")
	public void addInput(List<Operator<IN>> inputs) {
		this.input = Operator.createUnionCascade(this.input, inputs.toArray(new Operator[inputs.size()]));
	}"
"protected static List<Intervalable> findOverlappingRanges(IntervalNode node, Intervalable interval)
    {
        if (node != null)
        {
            return node.findOverlaps(interval);
        }
        return Collections.emptyList();
    }"
"@Override
	public void accept(Visitor<OptimizerNode> visitor) {
		if (visitor.preVisit(this)) {
			if (this.input1 == null || this.input2 == null) {
				throw new CompilerException();
			}
			
			getFirstPredecessorNode().accept(visitor);
			getSecondPredecessorNode().accept(visitor);
			
			for (DagConnection connection : getBroadcastConnections()) {
				connection.getSource().accept(visitor);
			}
			
			visitor.postVisit(this);
		}
	}"
"public boolean add(E e)
    {
        if (queue.size() < maxSize)
        { // 未达到最大容量，直接添加
            queue.add(e);
            return true;
        }
        else
        { // 队列已满
            E peek = queue.peek();
            if (queue.comparator().compare(e, peek) > 0)
            { // 将新元素与当前堆顶元素比较，保留较小的元素
                queue.poll();
                queue.add(e);
                return true;
            }
        }
        return false;
    }"
"public static String unescape(String htmlStr) {
		if (StrUtil.isBlank(htmlStr)) {
			return htmlStr;
		}
		return htmlStr.replace(StrUtil.HTML_APOS, ""'"")//
				.replace(""&#039;"", ""'"")//
				.replace(""&#39;"", ""'"")//
				.replace(StrUtil.HTML_LT, ""<"")//
				.replace(StrUtil.HTML_GT, "">"")//
				.replace(StrUtil.HTML_QUOTE, ""\"""")//
				.replace(StrUtil.HTML_AMP, ""&"")//
				.replace(StrUtil.HTML_NBSP, "" ""//
		);
	}"
"public String toHexString() {
		byte[] bytes = this.data.array();
		char[] hex = new char[this.data.remaining() * 2];
		for (int i = this.data.position(); i < this.data.remaining(); i++) {
			int b = bytes[i] & 0xFF;
			hex[i * 2] = HEX_CHARS[b >>> 4];
			hex[i * 2 + 1] = HEX_CHARS[b & 0x0F];
		}
		return new String(hex);
	}"
"public static CallableStatement prepareCall(Connection conn, String sql, Object... params) throws SQLException {
		Assert.notBlank(sql, ""Sql String must be not blank!"");

		sql = sql.trim();
		SqlLog.INSTASNCE.log(sql, params);
		final CallableStatement call = conn.prepareCall(sql);
		fillParams(call, params);
		return call;
	}"
"public void write(final Point point) {
        this.influxDb.write(influxDbProperties.getDatabase(), influxDbProperties.getRetentionPolicy(), point);
    }"
"@Scheduled(fixedRateString = ""${hystrix.stream.queue.sendRate:${hystrix.stream.queue.send-rate:500}}"")
	public void sendMetrics() {
		ArrayList<String> metrics = new ArrayList<>();
		this.jsonMetrics.drainTo(metrics);

		if (!metrics.isEmpty()) {
			if (log.isTraceEnabled()) {
				log.trace(""sending stream metrics size: "" + metrics.size());
			}
			for (String json : metrics) {
				// TODO: batch all metrics to one message
				try {
					// TODO: remove the explicit content type when s-c-stream can handle
					// that for us
					this.outboundChannel.send(MessageBuilder.withPayload(json)
							.setHeader(MessageHeaders.CONTENT_TYPE,
									this.properties.getContentType())
							.build());
				}
				catch (Exception ex) {
					if (log.isTraceEnabled()) {
						log.trace(""failed sending stream metrics: "" + ex.getMessage());
					}
				}
			}
		}
	}"
"public static void handleException(final Exception cause) {
        if (null == cause) {
            return;
        }
        if (isIgnoredException(cause) || null != cause.getCause() && isIgnoredException(cause.getCause())) {
            log.debug(""Ignored exception for: {}"", cause.getMessage());
        } else if (cause instanceof InterruptedException) {
            Thread.currentThread().interrupt();
        } else {
            throw new RegistryCenterException(cause);
        }
    }"
"private void doLoad() throws IOException {
    final String libName = getName();
    try {
      System.loadLibrary(libName);
    } catch (UnsatisfiedLinkError e) {
      try {
        extractAndLoad(getPlatformLibraryPath(), getSimpleLibraryPath());
      } catch (IOException ioe) {
        logger.warn(""Failed to load library from both native path and jar!"");
        throw ioe;
      }
    }
  }"
"@PublicEvolving
	public void setInteger(ConfigOption<Integer> key, int value) {
		setValueInternal(key.key(), value);
	}"
"private void setupLookAndFeel() {
        if (lookAndFeelSet) {
            return;
        }
        lookAndFeelSet = true;

        if (setLookAndFeel(System.getProperty(""swing.defaultlaf""))) {
            return;
        }

        OptionsParam options = Model.getSingleton().getOptionsParam();

        if (setLookAndFeel(getLookAndFeelClassname(options.getViewParam().getLookAndFeel()))) {
            return;
        }

        if (Constant.isMacOsX()) {
            OsXGui.setup();
        } else if (setLookAndFeel(getLookAndFeelClassname(""Nimbus""))) {
            return;
        }

        setLookAndFeel(UIManager.getSystemLookAndFeelClassName());
    }"
"static String firstNonEmpty(String... candidates) {
    for (String s : candidates) {
      if (!isEmpty(s)) {
        return s;
      }
    }
    return null;
  }"
"public static List<String> getKeywordList(String document, int size)
    {
        TextRankKeyword textRankKeyword = new TextRankKeyword();

        return textRankKeyword.getKeywords(document, size);
    }"
"public static void runFlinkZkQuorumPeer(String zkConfigFile, int peerId) throws Exception {

		Properties zkProps = new Properties();

		try (InputStream inStream = new FileInputStream(new File(zkConfigFile))) {
			zkProps.load(inStream);
		}

		LOG.info(""Configuration: "" + zkProps);

		// Set defaults for required properties
		setRequiredProperties(zkProps);

		// Write peer id to myid file
		writeMyIdToDataDir(zkProps, peerId);

		// The myid file needs to be written before creating the instance. Otherwise, this
		// will fail.
		QuorumPeerConfig conf = new QuorumPeerConfig();
		conf.parseProperties(zkProps);

		if (conf.isDistributed()) {
			// Run quorum peer
			LOG.info(""Running distributed ZooKeeper quorum peer (total peers: {})."",
					conf.getServers().size());

			QuorumPeerMain qp = new QuorumPeerMain();
			qp.runFromConfig(conf);
		}
		else {
			// Run standalone
			LOG.info(""Running standalone ZooKeeper quorum peer."");

			ZooKeeperServerMain zk = new ZooKeeperServerMain();
			ServerConfig sc = new ServerConfig();
			sc.readFrom(conf);
			zk.runFromConfig(sc);
		}
	}"
"public static Consumer<Subscription> subscriberLoop(final FragmentHandler fragmentHandler, final int limit,
                    final AtomicBoolean running, final IdleStrategy idleStrategy, final AtomicBoolean launched) {
        return (subscription) -> {
            try {
                while (running.get()) {
                    idleStrategy.idle(subscription.poll(fragmentHandler, limit));
                    launched.set(true);
                }
            } catch (final Exception ex) {
                LangUtil.rethrowUnchecked(ex);
            }
        };
    }"
"@SuppressWarnings(""unused"")
    @Internal
    @UsedByGeneratedCode
    protected final AbstractBeanDefinition<T> addExecutableMethod(ExecutableMethod<T, ?> executableMethod) {
        MethodKey key = new MethodKey(executableMethod.getMethodName(), executableMethod.getArgumentTypes());
        executableMethodMap.put(key, executableMethod);
        return this;
    }"
"public S setMethods(List<MethodConfig> methods) {
        if (this.methods == null) {
            this.methods = new ConcurrentHashMap<String, MethodConfig>();
        }
        if (methods != null) {
            for (MethodConfig methodConfig : methods) {
                this.methods.put(methodConfig.getName(), methodConfig);
            }
        }
        return castThis();
    }"
"@SuppressWarnings(""unchecked"")
    @PostConstruct
    void init(BeanContext beanContext, ThreadFactory threadFactory) {
        try {
            BeanDefinition<ExecutorService> beanDefinition = beanContext.getBeanDefinition(ExecutorService.class, Qualifiers.byName(TaskExecutors.SCHEDULED));
            Collection<BeanCreatedEventListener> schedulerCreateListeners =
                    beanContext.getBeansOfType(BeanCreatedEventListener.class, Qualifiers.byTypeArguments(ScheduledExecutorService.class));

            Schedulers.addExecutorServiceDecorator(Environment.MICRONAUT, (scheduler, scheduledExecutorService) -> {
                for (BeanCreatedEventListener schedulerCreateListener : schedulerCreateListeners) {
                    Object newBean = schedulerCreateListener.onCreated(new BeanCreatedEvent(beanContext, beanDefinition, BeanIdentifier.of(""reactor-"" + scheduler.getClass().getSimpleName()), scheduledExecutorService));
                    if (!(newBean instanceof ScheduledExecutorService)) {
                        throw new BeanContextException(""Bean creation listener ["" + schedulerCreateListener + ""] should return ScheduledExecutorService, but returned "" + newBean);
                    }
                    scheduledExecutorService = (ScheduledExecutorService) newBean;
                }
                return scheduledExecutorService;
            });
        } catch (Exception e) {
            if (LOG.isErrorEnabled()) {
                LOG.error(""Could not instrument Reactor for Tracing: "" + e.getMessage(), e);
            }
        }
    }"
"public Entity wrap(Entity entity){
		if(null == entity) {
			return null;
		}
		
		final Entity wrapedEntity = new Entity();
		
		//wrap table name
		wrapedEntity.setTableName(wrap(entity.getTableName()));
		
		//wrap fields
		for (Entry<String, Object> entry : entity.entrySet()) {
			wrapedEntity.set(wrap(entry.getKey()), entry.getValue());
		}
		
		return wrapedEntity;
	}"
"public void loadContext(Context ctx) {
		validateContextNotNull(ctx);

		for (ContextDataFactory cdf : this.contextDataFactories) {
			cdf.loadContextData(getSession(), ctx);
		}
	}"
"public ChannelFuture connect(String inetHost, int inetPort) {
        return connect(InetSocketAddress.createUnresolved(inetHost, inetPort));
    }"
"private static Result<Jwt> renewCCTokenSync(final Jwt jwt) {
        // Already expired, try to renew getCCTokenSynchronously but let requests use the old token.
        logger.trace(""In renew window and token is already expired."");
        //the token can be renew when it's not on renewing or current time is lager than retrying interval
        if (!jwt.isRenewing() || System.currentTimeMillis() > jwt.getExpiredRetryTimeout()) {
            jwt.setRenewing(true);
            jwt.setEarlyRetryTimeout(System.currentTimeMillis() + Jwt.getExpiredRefreshRetryDelay());
            Result<Jwt> result = getCCTokenRemotely(jwt);
            //set renewing flag to false no mater fail or success
            jwt.setRenewing(false);
            return result;
        } else {
            if(logger.isTraceEnabled()) logger.trace(""Circuit breaker is tripped and not timeout yet!"");
            // token is renewing
            return Failure.of(new Status(STATUS_CLIENT_CREDENTIALS_TOKEN_NOT_AVAILABLE));
        }
    }"
"@Override
	public void open(FileInputSplit fileSplit) throws IOException {

		this.currentSplit = fileSplit;
		this.splitStart = fileSplit.getStart();
		this.splitLength = fileSplit.getLength();

		if (LOG.isDebugEnabled()) {
			LOG.debug(""Opening input split "" + fileSplit.getPath() + "" ["" + this.splitStart + "","" + this.splitLength + ""]"");
		}

		
		// open the split in an asynchronous thread
		final InputSplitOpenThread isot = new InputSplitOpenThread(fileSplit, this.openTimeout);
		isot.start();
		
		try {
			this.stream = isot.waitForCompletion();
			this.stream = decorateInputStream(this.stream, fileSplit);
		}
		catch (Throwable t) {
			throw new IOException(""Error opening the Input Split "" + fileSplit.getPath() + 
					"" ["" + splitStart + "","" + splitLength + ""]: "" + t.getMessage(), t);
		}
		
		// get FSDataInputStream
		if (this.splitStart != 0) {
			this.stream.seek(this.splitStart);
		}
	}"
"public static String getGarbageCollectorStatsAsString(List<GarbageCollectorMXBean> gcMXBeans) {
		StringBuilder bld = new StringBuilder(""Garbage collector stats: "");
		
		for (GarbageCollectorMXBean bean : gcMXBeans) {
			bld.append('[').append(bean.getName()).append("", GC TIME (ms): "").append(bean.getCollectionTime());
			bld.append("", GC COUNT: "").append(bean.getCollectionCount()).append(']');
			
			bld.append("", "");
		}
		
		if (!gcMXBeans.isEmpty()) {
			bld.setLength(bld.length() - 2);
		}
		
		return bld.toString();
	}"
"public List<Writable> joinExamples(List<Writable> leftExample, List<Writable> rightExample) {

        List<Writable> out = new ArrayList<>();
        if (leftExample == null) {
            if (rightExample == null)
                throw new IllegalArgumentException(
                                ""Cannot join examples: Both examples are null (max 1 allowed to be null)"");

            //Insert a set of null writables...
            //Complication here: the **key values** should still exist (we have to extract them from second value)
            int nLeft = leftSchema.numColumns();
            List<String> leftNames = leftSchema.getColumnNames();
            int keysSoFar = 0;
            for (int i = 0; i < nLeft; i++) {
                String name = leftNames.get(i);
                if (ArrayUtils.contains(joinColumnsLeft, name)) {
                    //This would normally be where the left key came from...
                    //So let's get the key value from the *right* example
                    String rightKeyName = joinColumnsRight[keysSoFar];
                    int idxOfRightKey = rightSchema.getIndexOfColumn(rightKeyName);
                    out.add(rightExample.get(idxOfRightKey));
                } else {
                    //Not a key column, so just add a NullWritable
                    out.add(NullWritable.INSTANCE);
                }
            }
        } else {
            out.addAll(leftExample);
        }

        List<String> rightNames = rightSchema.getColumnNames();
        if (rightExample == null) {
            //Insert a set of null writables...
            int nRight = rightSchema.numColumns();
            for (int i = 0; i < nRight; i++) {
                String name = rightNames.get(i);
                if (ArrayUtils.contains(joinColumnsRight, name))
                    continue; //Skip the key column value
                out.add(NullWritable.INSTANCE);
            }
        } else {
            //Add all values from right, except for key columns...
            for (int i = 0; i < rightExample.size(); i++) {
                String name = rightNames.get(i);
                if (ArrayUtils.contains(joinColumnsRight, name))
                    continue; //Skip the key column value
                out.add(rightExample.get(i));
            }
        }

        return out;
    }"
"@Skip
    @Override
    public void bind(ChannelHandlerContext ctx, SocketAddress localAddress,
                     ChannelPromise promise) throws Exception {
        ctx.bind(localAddress, promise);
    }"
"public void validate(String origin) {
        List<String> problems = new ArrayList<>();
        if(source == null) {
            if(path == null) {
                problems.add(""You must specify either path or source"");
            } else if(method == null) {
                problems.add(""You must specify method along with path: "" + path);
            }
        } else {
            if(path != null) {
                problems.add(""Conflicting source: "" + source + "" and path: "" + path);
            }
            if(method != null) {
                problems.add(""Conflicting source: "" + source + "" and method: "" + method);
            }
        }
        if(method != null && !Util.METHODS.contains(method.toUpperCase())) {
            problems.add(""Invalid HTTP method: "" + method);
        }
        if(!problems.isEmpty()) {
            throw new RuntimeException(""Bad paths element in "" + origin + "" [ "" + String.join("" | "", problems) + "" ]"");
        }
    }"
"private static void convertData2Row(MappingConfig.HbaseMapping hbaseMapping, HRow hRow, Map<String, Object> data) {
        Map<String, MappingConfig.ColumnItem> columnItems = hbaseMapping.getColumnItems();
        int i = 0;
        for (Map.Entry<String, Object> entry : data.entrySet()) {
            if (hbaseMapping.getExcludeColumns() != null && hbaseMapping.getExcludeColumns().contains(entry.getKey())) {
                continue;
            }
            if (entry.getValue() != null) {
                MappingConfig.ColumnItem columnItem = columnItems.get(entry.getKey());

                byte[] bytes = typeConvert(columnItem, hbaseMapping, entry.getValue());

                if (columnItem == null) {
                    String familyName = hbaseMapping.getFamily();
                    String qualifier = entry.getKey();
                    if (hbaseMapping.isUppercaseQualifier()) {
                        qualifier = qualifier.toUpperCase();
                    }

                    if (hbaseMapping.getRowKey() == null && i == 0) {
                        hRow.setRowKey(bytes);
                    } else {
                        hRow.addCell(familyName, qualifier, bytes);
                    }
                } else {
                    if (columnItem.isRowKey()) {
                        if (columnItem.getRowKeyLen() != null && entry.getValue() != null) {
                            if (entry.getValue() instanceof Number) {
                                String v = String.format(""%0"" + columnItem.getRowKeyLen() + ""d"",
                                    ((Number) entry.getValue()).longValue());
                                bytes = Bytes.toBytes(v);
                            } else {
                                try {
                                    String v = String.format(""%0"" + columnItem.getRowKeyLen() + ""d"",
                                        Integer.parseInt((String) entry.getValue()));
                                    bytes = Bytes.toBytes(v);
                                } catch (Exception e) {
                                    logger.error(e.getMessage(), e);
                                }
                            }
                        }
                        hRow.setRowKey(bytes);
                    } else {
                        hRow.addCell(columnItem.getFamily(), columnItem.getQualifier(), bytes);
                    }
                }
            }
            i++;
        }
    }"
"public static <T> List<T> getFieldValues(Iterable<?> collection, final String fieldName, final Class<T> elementType) {
		List<Object> fieldValues = getFieldValues(collection, fieldName);
		return Convert.toList(elementType, fieldValues);
	}"
"@Override
	public void read(DataInputView in) throws IOException {
		final boolean isNotNull = in.readBoolean();
		if (isNotNull) {
			final String scheme = StringUtils.readNullableString(in);
			final String userInfo = StringUtils.readNullableString(in);
			final String host = StringUtils.readNullableString(in);
			final int port = in.readInt();
			final String path = StringUtils.readNullableString(in);
			final String query = StringUtils.readNullableString(in);
			final String fragment = StringUtils.readNullableString(in);

			try {
				uri = new URI(scheme, userInfo, host, port, path, query, fragment);
			} catch (URISyntaxException e) {
				throw new IOException(""Error reconstructing URI"", e);
			}
		}
	}"
"void removeEntry(NodeId nodeId) throws Exception {
		this.entryCache.remove(nodeId);
		this.entries.remove(nodeId);
	}"
"public Builder clear() {
      traceId = null;
      parentId = null;
      id = null;
      kind = null;
      name = null;
      timestamp = 0L;
      duration = 0L;
      localEndpoint = null;
      remoteEndpoint = null;
      if (annotations != null) annotations.clear();
      if (tags != null) tags.clear();
      flags = 0;
      return this;
    }"
"public static boolean equal(Object obj1, Object obj2) {
//		return (obj1 != null) ? (obj1.equals(obj2)) : (obj2 == null);
		return (obj1 == obj2) || (obj1 != null && obj1.equals(obj2));
	}"
"public static TaskManagerServices fromConfiguration(
			TaskManagerServicesConfiguration taskManagerServicesConfiguration,
			TaskManagerMetricGroup taskManagerMetricGroup,
			ResourceID resourceID,
			Executor taskIOExecutor,
			long freeHeapMemoryWithDefrag,
			long maxJvmHeapMemory) throws Exception {

		// pre-start checks
		checkTempDirs(taskManagerServicesConfiguration.getTmpDirPaths());

		final TaskEventDispatcher taskEventDispatcher = new TaskEventDispatcher();

		final NetworkEnvironment network = new NetworkEnvironment(
			taskManagerServicesConfiguration.getNetworkConfig(), taskEventDispatcher, taskManagerMetricGroup);
		network.start();

		final KvStateService kvStateService = KvStateService.fromConfiguration(taskManagerServicesConfiguration);
		kvStateService.start();

		final TaskManagerLocation taskManagerLocation = new TaskManagerLocation(
			resourceID,
			taskManagerServicesConfiguration.getTaskManagerAddress(),
			network.getConnectionManager().getDataPort());

		// this call has to happen strictly after the network stack has been initialized
		final MemoryManager memoryManager = createMemoryManager(taskManagerServicesConfiguration, freeHeapMemoryWithDefrag, maxJvmHeapMemory);

		// start the I/O manager, it will create some temp directories.
		final IOManager ioManager = new IOManagerAsync(taskManagerServicesConfiguration.getTmpDirPaths());

		final BroadcastVariableManager broadcastVariableManager = new BroadcastVariableManager();

		final List<ResourceProfile> resourceProfiles = new ArrayList<>(taskManagerServicesConfiguration.getNumberOfSlots());

		for (int i = 0; i < taskManagerServicesConfiguration.getNumberOfSlots(); i++) {
			resourceProfiles.add(ResourceProfile.ANY);
		}

		final TimerService<AllocationID> timerService = new TimerService<>(
			new ScheduledThreadPoolExecutor(1),
			taskManagerServicesConfiguration.getTimerServiceShutdownTimeout());

		final TaskSlotTable taskSlotTable = new TaskSlotTable(resourceProfiles, timerService);

		final JobManagerTable jobManagerTable = new JobManagerTable();

		final JobLeaderService jobLeaderService = new JobLeaderService(taskManagerLocation, taskManagerServicesConfiguration.getRetryingRegistrationConfiguration());

		final String[] stateRootDirectoryStrings = taskManagerServicesConfiguration.getLocalRecoveryStateRootDirectories();

		final File[] stateRootDirectoryFiles = new File[stateRootDirectoryStrings.length];

		for (int i = 0; i < stateRootDirectoryStrings.length; ++i) {
			stateRootDirectoryFiles[i] = new File(stateRootDirectoryStrings[i], LOCAL_STATE_SUB_DIRECTORY_ROOT);
		}

		final TaskExecutorLocalStateStoresManager taskStateManager = new TaskExecutorLocalStateStoresManager(
			taskManagerServicesConfiguration.isLocalRecoveryEnabled(),
			stateRootDirectoryFiles,
			taskIOExecutor);

		return new TaskManagerServices(
			taskManagerLocation,
			memoryManager,
			ioManager,
			network,
			kvStateService,
			broadcastVariableManager,
			taskSlotTable,
			jobManagerTable,
			jobLeaderService,
			taskStateManager,
			taskEventDispatcher);
	}"
"public static RedissonClient create(Config config) {
        Redisson redisson = new Redisson(config);
        if (config.isReferenceEnabled()) {
            redisson.enableRedissonReferenceSupport();
        }
        return redisson;
    }"
"public static BDDStubber willThrow(Class<? extends Throwable> toBeThrown, Class<? extends Throwable>... throwableTypes) {
        return new BDDStubberImpl(Mockito.doThrow(toBeThrown, throwableTypes));
    }"
"protected int transition(int current, char c)
    {
        int b = current;
        int p;

        p = b + c + 1;
        if (b == check[p])
            b = base[p];
        else
            return -1;

        p = b;
        return p;
    }"
"public void execute(@Param(""userId"") Long userId, @Param(""pageIndex"") int pageIndex,
                        @Param(""searchKey"") String searchKey, Context context, Navigator nav) throws Exception {
        User user = userService.findUserById(userId);

        context.put(""user"", user);
        context.put(""pageIndex"", pageIndex);
        context.put(""searchKey"", searchKey);
    }"
"public static InitStrategy get(ClassLoader cl) throws IOException {
        Iterator<InitStrategy> it = ServiceLoader.load(InitStrategy.class, cl).iterator();
        if (!it.hasNext()) {
            return new InitStrategy(); // default
        }
        InitStrategy s = it.next();
        LOGGER.log(Level.FINE, ""Using {0} as InitStrategy"", s);
        return s;
    }"
"private void updateInitialReceiveWindowSize(int newInitialWindowSize) {
        int deltaWindowSize = newInitialWindowSize - initialReceiveWindowSize;
        initialReceiveWindowSize = newInitialWindowSize;
        spdySession.updateAllReceiveWindowSizes(deltaWindowSize);
    }"
"public AggregationBuilder makeFieldAgg(MethodField field, AggregationBuilder parent) throws SqlParseException {
        //question 加到groupMap里是为了什么
        groupMap.put(field.getAlias(), new KVValue(""FIELD"", parent));

        ValuesSourceAggregationBuilder builder;
        field.setAlias(fixAlias(field.getAlias()));
        switch (field.getName().toUpperCase()) {
            case ""SUM"":
                builder = AggregationBuilders.sum(field.getAlias());
                return addFieldToAgg(field, builder);
            case ""MAX"":
                builder = AggregationBuilders.max(field.getAlias());
                return addFieldToAgg(field, builder);
            case ""MIN"":
                builder = AggregationBuilders.min(field.getAlias());
                return addFieldToAgg(field, builder);
            case ""AVG"":
                builder = AggregationBuilders.avg(field.getAlias());
                return addFieldToAgg(field, builder);
            case ""STATS"":
                builder = AggregationBuilders.stats(field.getAlias());
                return addFieldToAgg(field, builder);
            case ""EXTENDED_STATS"":
                builder = AggregationBuilders.extendedStats(field.getAlias());
                return addFieldToAgg(field, builder);
            case ""PERCENTILES"":
                builder = AggregationBuilders.percentiles(field.getAlias());
                addSpecificPercentiles((PercentilesAggregationBuilder) builder, field.getParams());
                return addFieldToAgg(field, builder);
            case ""TOPHITS"":
                return makeTopHitsAgg(field);
            case ""SCRIPTED_METRIC"":
                return scriptedMetric(field);
            case ""COUNT"":
                groupMap.put(field.getAlias(), new KVValue(""COUNT"", parent));
                return addFieldToAgg(field, makeCountAgg(field));
            default:
                throw new SqlParseException(""the agg function not to define !"");
        }
    }"
"private AbstractHelperDialect getDialect(MappedStatement ms) {
        //改为对dataSource做缓存
        DataSource dataSource = ms.getConfiguration().getEnvironment().getDataSource();
        String url = getUrl(dataSource);
        if (urlDialectMap.containsKey(url)) {
            return urlDialectMap.get(url);
        }
        try {
            lock.lock();
            if (urlDialectMap.containsKey(url)) {
                return urlDialectMap.get(url);
            }
            if (StringUtil.isEmpty(url)) {
                throw new PageException(""无法自动获取jdbcUrl，请在分页插件中配置dialect参数!"");
            }
            String dialectStr = fromJdbcUrl(url);
            if (dialectStr == null) {
                throw new PageException(""无法自动获取数据库类型，请通过 helperDialect 参数指定!"");
            }
            AbstractHelperDialect dialect = initDialect(dialectStr, properties);
            urlDialectMap.put(url, dialect);
            return dialect;
        } finally {
            lock.unlock();
        }
    }"
"public List<EventColumn> getUpdatedColumns() {
        List<EventColumn> columns = new ArrayList<EventColumn>();
        for (EventColumn column : this.columns) {
            if (column.isUpdate()) {
                columns.add(column);
            }
        }

        return columns;
    }"
"@Override
    public Message getWithoutAck(ClientIdentity clientIdentity, int batchSize) throws CanalServerException {
        return getWithoutAck(clientIdentity, batchSize, null, null);
    }"
"public long between(DateUnit unit) {
		long diff = end.getTime() - begin.getTime();
		return diff / unit.getMillis();
	}"
"private String doKerberosAuth(HttpServletRequest request)
      throws HttpAuthenticationException {
    // Try authenticating with the http/_HOST principal
    if (httpUGI != null) {
      try {
        return httpUGI.doAs(new HttpKerberosServerAction(request, httpUGI));
      } catch (Exception e) {
        LOG.info(""Failed to authenticate with http/_HOST kerberos principal, "" +
            ""trying with hive/_HOST kerberos principal"");
      }
    }
    // Now try with hive/_HOST principal
    try {
      return serviceUGI.doAs(new HttpKerberosServerAction(request, serviceUGI));
    } catch (Exception e) {
      LOG.error(""Failed to authenticate with hive/_HOST kerberos principal"");
      throw new HttpAuthenticationException(e);
    }

  }"
"private void parseValue() {
		// 当值无时，视为空判定
		if (null == this.value) {
			this.operator = OPERATOR_IS;
			this.value = VALUE_NULL;
			return;
		}

		// 对数组和集合值按照 IN 处理
		if (this.value instanceof Collection || ArrayUtil.isArray(this.value)) {
			this.operator = OPERATOR_IN;
			return;
		}

		// 其他类型值，跳过
		if (false == (this.value instanceof String)) {
			return;
		}

		String valueStr = ((String) value);
		if (StrUtil.isBlank(valueStr)) {
			// 空字段不做处理
			return;
		}

		valueStr = valueStr.trim();

		// 处理null
		if (StrUtil.endWithIgnoreCase(valueStr, ""null"")) {
			if (StrUtil.equalsIgnoreCase(""= null"", valueStr) || StrUtil.equalsIgnoreCase(""is null"", valueStr)) {
				// 处理""= null""和""is null""转换为""IS NULL""
				this.operator = OPERATOR_IS;
				this.value = VALUE_NULL;
				this.isPlaceHolder = false;
				return;
			} else if (StrUtil.equalsIgnoreCase(""!= null"", valueStr) || StrUtil.equalsIgnoreCase(""is not null"", valueStr)) {
				// 处理""!= null""和""is not null""转换为""IS NOT NULL""
				this.operator = OPERATOR_IS_NOT;
				this.value = VALUE_NULL;
				this.isPlaceHolder = false;
				return;
			}
		}

		List<String> strs = StrUtil.split(valueStr, StrUtil.C_SPACE, 2);
		if (strs.size() < 2) {
			return;
		}

		// 处理常用符号和IN
		final String firstPart = strs.get(0).trim().toUpperCase();
		if (OPERATORS.contains(firstPart)) {
			this.operator = firstPart;
			this.value = strs.get(1).trim();
			return;
		}

		// 处理LIKE
		if (OPERATOR_LIKE.equals(firstPart)) {
			this.operator = OPERATOR_LIKE;
			this.value = unwrapQuote(strs.get(1));
			return;
		}

		// 处理BETWEEN x AND y
		if (OPERATOR_BETWEEN.equals(firstPart)) {
			final List<String> betweenValueStrs = StrSpliter.splitTrimIgnoreCase(strs.get(1), LogicalOperator.AND.toString(), 2, true);
			if (betweenValueStrs.size() < 2) {
				// 必须满足a AND b格式，不满足被当作普通值
				return;
			}

			this.operator = OPERATOR_BETWEEN;
			this.value = unwrapQuote(betweenValueStrs.get(0));
			this.secondValue = unwrapQuote(betweenValueStrs.get(1));
			return;
		}
	}"
"public static void saveSequenceFileSequences(String path, JavaRDD<List<List<Writable>>> rdd) {
        saveSequenceFileSequences(path, rdd, null);
    }"
"public static JMXConnector connect(int port) throws IOException {
		String url = ""service:jmx:rmi:///jndi/rmi://127.0.0.1:"" + port + ""/jmxrmi"";
		JMXServiceURL serviceUrl = new JMXServiceURL(url);
		return JMXConnectorFactory.connect(serviceUrl, null);
	}"
"static void tcp_ack( final AutoBuffer ab ) throws IOException {
    // Get the RPC we're waiting on
    int task = ab.getTask();
    RPC rpc = ab._h2o.taskGet(task);
    // Race with canceling a large RPC fetch: Task is already dead.  Do not
    // bother reading from the TCP socket, just bail out & close socket.
    if( rpc == null || rpc._done) {
      ab.drainClose();
    } else {
      assert rpc._tasknum == task;
      assert !rpc._done;
      // Here we have the result, and we're on the correct Node but wrong
      // Thread.  If we just return, the TCP reader thread will close the
      // remote, the remote will UDP ACK the RPC back, and back on the current
      // Node but in the correct Thread, we'd wake up and realize we received a
      // large result.
      try {
        rpc.response(ab);
      } catch( AutoBuffer.AutoBufferException e ) {
        // If TCP fails, we will have done a short-read crushing the original
        // _dt object, and be unable to resend.  This is fatal right now.
        // Really: an unimplemented feature; fix is to notice that a partial
        // TCP read means that the server (1) got our remote_exec request, (2)
        // has computed an answer and was trying to send it to us, (3) failed
        // sending via TCP hence the server knows it failed and will send again
        // without any further work from us.  We need to disable all the resend
        // & retry logic, and wait for the server to re-send our result.
        // Meanwhile the _dt object is crushed with half-read crap, and cannot
        // be trusted except in the base fields.
        throw Log.throwErr(e._ioe);
      }
    }
    // ACKACK the remote, telling him ""we got the answer""
    new AutoBuffer(ab._h2o, H2O.ACK_ACK_PRIORITY).putTask(UDP.udp.ackack.ordinal(),task).close();
  }"
"private void checkAndLoadDependentExtensions() {
        boolean changed = false;
        for (Entry<String, AddOnClassLoader> entry : new HashMap<>(addOnLoaders).entrySet()) {
            AddOn runningAddOn = aoc.getAddOn(entry.getKey());
            if (runningAddOn.getInstallationStatus() == AddOn.InstallationStatus.UNINSTALLATION_FAILED) {
                continue;
            }
            for (String extClassName : runningAddOn.getExtensionsWithDeps()) {
                if (!runningAddOn.isExtensionLoaded(extClassName)) {
                    AddOn.AddOnRunRequirements reqs = runningAddOn.calculateExtensionRunRequirements(
                            extClassName,
                            aoc.getInstalledAddOns());
                    ExtensionRunRequirements extReqs = reqs.getExtensionRequirements().get(0);
                    if (extReqs.isRunnable()) {
                        List<AddOnClassLoader> dependencies = new ArrayList<>(extReqs.getDependencies().size());
                        for (AddOn addOnDep : extReqs.getDependencies()) {
                            dependencies.add(addOnLoaders.get(addOnDep.getId()));
                        }
                        AddOnClassLoader extAddOnClassLoader = new AddOnClassLoader(
                                entry.getValue(),
                                dependencies,
                                runningAddOn.getExtensionAddOnClassnames(extClassName));
                        Extension ext = loadAddOnExtension(runningAddOn, extReqs.getClassname(), extAddOnClassLoader);
                        AddOnInstaller.installAddOnExtension(runningAddOn, ext);
                        runnableAddOns.get(runningAddOn).add(extReqs.getClassname());
                        changed = true;
                    }
                }
            }
        }

        if (changed) {
            saveAddOnsRunState(runnableAddOns);
        }
    }"
"public boolean getBoolean(int index) throws JSONException {
		Object object = get(index);
		Boolean result = JSON.toBoolean(object);
		if (result == null) {
			throw JSON.typeMismatch(index, object, ""boolean"");
		}
		return result;
	}"
"@Deprecated
    public static boolean uninstall(AddOn addOn, AddOnUninstallationProgressCallback callback) {
        return uninstall(addOn, callback, null);
    }"
"@Override
    public boolean configure(StaplerRequest req, JSONObject json) throws FormException {
        req.bindJSON(this, json);
        return true;
    }"
"JSONStringer close(Scope empty, Scope nonempty, String closeBracket)
			throws JSONException {
		Scope context = peek();
		if (context != nonempty && context != empty) {
			throw new JSONException(""Nesting problem"");
		}

		this.stack.remove(this.stack.size() - 1);
		if (context == nonempty) {
			newline();
		}
		this.out.append(closeBracket);
		return this;
	}"
"void checkWriteSuspend(ChannelHandlerContext ctx, long delay, long queueSize) {
        if (queueSize > maxWriteSize || delay > maxWriteDelay) {
            setUserDefinedWritability(ctx, false);
        }
    }"
"public boolean setCancellerHandle(ScheduledFuture<?> cancellerHandle) {
		synchronized (lock) {
			if (this.cancellerHandle == null) {
				if (!discarded) {
					this.cancellerHandle = cancellerHandle;
					return true;
				} else {
					return false;
				}
			}
			else {
				throw new IllegalStateException(""A canceller handle was already set"");
			}
		}
	}"
"public static void skip(DataInputStream in) throws IOException {
        byte[] preamble = new byte[PREAMBLE.length];
        in.readFully(preamble);
        if (!Arrays.equals(preamble,PREAMBLE))
            return;    // not a valid preamble

        DataInputStream decoded = new DataInputStream(new UnbufferedBase64InputStream(in));
        int macSz = - decoded.readInt();
        if (macSz > 0) { // new format
            IOUtils.skip(decoded, macSz);
            int sz = decoded.readInt();
            IOUtils.skip(decoded, sz);
        } else { // old format
            int sz = -macSz;
            IOUtils.skip(decoded, sz);
        }

        byte[] postamble = new byte[POSTAMBLE.length];
        in.readFully(postamble);
    }"
"@SuppressWarnings(""ReferenceEquality"")
  private void updateBalancingState() {
    List<Subchannel> activeList = filterNonFailingSubchannels(getSubchannels());
    if (activeList.isEmpty()) {
      // No READY subchannels, determine aggregate state and error status
      boolean isConnecting = false;
      Status aggStatus = EMPTY_OK;
      for (Subchannel subchannel : getSubchannels()) {
        ConnectivityStateInfo stateInfo = getSubchannelStateInfoRef(subchannel).value;
        // This subchannel IDLE is not because of channel IDLE_TIMEOUT,
        // in which case LB is already shutdown.
        // RRLB will request connection immediately on subchannel IDLE.
        if (stateInfo.getState() == CONNECTING || stateInfo.getState() == IDLE) {
          isConnecting = true;
        }
        if (aggStatus == EMPTY_OK || !aggStatus.isOk()) {
          aggStatus = stateInfo.getStatus();
        }
      }
      updateBalancingState(isConnecting ? CONNECTING : TRANSIENT_FAILURE,
          // If all subchannels are TRANSIENT_FAILURE, return the Status associated with
          // an arbitrary subchannel, otherwise return OK.
          new EmptyPicker(aggStatus));
    } else {
      // initialize the Picker to a random start index to ensure that a high frequency of Picker
      // churn does not skew subchannel selection.
      int startIndex = random.nextInt(activeList.size());
      updateBalancingState(READY, new ReadyPicker(activeList, startIndex, stickinessState));
    }
  }"
"private List<DataSegment> generateAndPushSegments(
      final TaskToolbox toolbox,
      final ParallelIndexTaskClient taskClient,
      final FirehoseFactory firehoseFactory,
      final File firehoseTempDir
  ) throws IOException, InterruptedException
  {
    final DataSchema dataSchema = ingestionSchema.getDataSchema();
    final GranularitySpec granularitySpec = dataSchema.getGranularitySpec();
    final FireDepartment fireDepartmentForMetrics =
        new FireDepartment(dataSchema, new RealtimeIOConfig(null, null, null), null);
    final FireDepartmentMetrics fireDepartmentMetrics = fireDepartmentForMetrics.getMetrics();

    if (toolbox.getMonitorScheduler() != null) {
      toolbox.getMonitorScheduler().addMonitor(
          new RealtimeMetricsMonitor(
              Collections.singletonList(fireDepartmentForMetrics),
              Collections.singletonMap(DruidMetrics.TASK_ID, new String[]{getId()})
          )
      );
    }

    // Initialize maxRowsPerSegment and maxTotalRows lazily
    final ParallelIndexTuningConfig tuningConfig = ingestionSchema.getTuningConfig();
    @Nullable final Integer maxRowsPerSegment = IndexTask.getValidMaxRowsPerSegment(tuningConfig);
    @Nullable final Long maxTotalRows = IndexTask.getValidMaxTotalRows(tuningConfig);
    final long pushTimeout = tuningConfig.getPushTimeout();
    final boolean explicitIntervals = granularitySpec.bucketIntervals().isPresent();
    final SegmentAllocator segmentAllocator = createSegmentAllocator(toolbox, taskClient, ingestionSchema);

    try (
        final Appenderator appenderator = newAppenderator(fireDepartmentMetrics, toolbox, dataSchema, tuningConfig);
        final BatchAppenderatorDriver driver = newDriver(appenderator, toolbox, segmentAllocator);
        final Firehose firehose = firehoseFactory.connect(dataSchema.getParser(), firehoseTempDir)
    ) {
      driver.startJob();

      final List<DataSegment> pushedSegments = new ArrayList<>();

      while (firehose.hasMore()) {
        try {
          final InputRow inputRow = firehose.nextRow();

          if (inputRow == null) {
            fireDepartmentMetrics.incrementThrownAway();
            continue;
          }

          if (!Intervals.ETERNITY.contains(inputRow.getTimestamp())) {
            final String errorMsg = StringUtils.format(
                ""Encountered row with timestamp that cannot be represented as a long: [%s]"",
                inputRow
            );
            throw new ParseException(errorMsg);
          }

          if (explicitIntervals) {
            final Optional<Interval> optInterval = granularitySpec.bucketInterval(inputRow.getTimestamp());
            if (!optInterval.isPresent()) {
              fireDepartmentMetrics.incrementThrownAway();
              continue;
            }
          }

          // Segments are created as needed, using a single sequence name. They may be allocated from the overlord
          // (in append mode) or may be created on our own authority (in overwrite mode).
          final String sequenceName = getId();
          final AppenderatorDriverAddResult addResult = driver.add(inputRow, sequenceName);

          if (addResult.isOk()) {
            if (addResult.isPushRequired(maxRowsPerSegment, maxTotalRows)) {
              // There can be some segments waiting for being published even though any rows won't be added to them.
              // If those segments are not published here, the available space in appenderator will be kept to be small
              // which makes the size of segments smaller.
              final SegmentsAndMetadata pushed = driver.pushAllAndClear(pushTimeout);
              pushedSegments.addAll(pushed.getSegments());
              log.info(""Pushed segments[%s]"", pushed.getSegments());
            }
          } else {
            throw new ISE(""Failed to add a row with timestamp[%s]"", inputRow.getTimestamp());
          }

          fireDepartmentMetrics.incrementProcessed();
        }
        catch (ParseException e) {
          if (tuningConfig.isReportParseExceptions()) {
            throw e;
          } else {
            fireDepartmentMetrics.incrementUnparseable();
          }
        }
      }

      final SegmentsAndMetadata pushed = driver.pushAllAndClear(pushTimeout);
      pushedSegments.addAll(pushed.getSegments());
      log.info(""Pushed segments[%s]"", pushed.getSegments());

      return pushedSegments;
    }
    catch (TimeoutException | ExecutionException e) {
      throw new RuntimeException(e);
    }
  }"
"void free(long handle, ByteBuffer nioBuffer) {
        int memoryMapIdx = memoryMapIdx(handle);
        int bitmapIdx = bitmapIdx(handle);

        if (bitmapIdx != 0) { // free a subpage
            PoolSubpage<T> subpage = subpages[subpageIdx(memoryMapIdx)];
            assert subpage != null && subpage.doNotDestroy;

            // Obtain the head of the PoolSubPage pool that is owned by the PoolArena and synchronize on it.
            // This is need as we may add it back and so alter the linked-list structure.
            PoolSubpage<T> head = arena.findSubpagePoolHead(subpage.elemSize);
            synchronized (head) {
                if (subpage.free(head, bitmapIdx & 0x3FFFFFFF)) {
                    return;
                }
            }
        }
        freeBytes += runLength(memoryMapIdx);
        setValue(memoryMapIdx, depth(memoryMapIdx));
        updateParentsFree(memoryMapIdx);

        if (nioBuffer != null && cachedNioBuffers != null &&
                cachedNioBuffers.size() < PooledByteBufAllocator.DEFAULT_MAX_CACHED_BYTEBUFFERS_PER_CHUNK) {
            cachedNioBuffers.offer(nioBuffer);
        }
    }"
"public List<String> formatTypeAndRange(@Nullable String type, long beginMillis, long endMillis) {
    GregorianCalendar current = midnightUTC(beginMillis);
    GregorianCalendar end = midnightUTC(endMillis);
    if (current.equals(end)) {
      return Collections.singletonList(formatTypeAndTimestamp(type, current.getTimeInMillis()));
    }

    String prefix = prefix(type);
    List<String> indices = new ArrayList<>();
    while (current.compareTo(end) <= 0) {
      if (current.get(Calendar.MONTH) == 0 && current.get(Calendar.DAY_OF_MONTH) == 1) {
        // attempt to compress a year
        current.set(Calendar.DAY_OF_YEAR, current.getActualMaximum(Calendar.DAY_OF_YEAR));
        if (current.compareTo(end) <= 0) {
          indices.add(format(""%s-%s%c*"", prefix, current.get(Calendar.YEAR), dateSeparator()));
          current.add(Calendar.DAY_OF_MONTH, 1); // rollover to next year
          continue;
        } else {
          current.set(Calendar.DAY_OF_YEAR, 1); // rollback to first of the year
        }
      } else if (current.get(Calendar.DAY_OF_MONTH) == 1) {
        // attempt to compress a month
        current.set(Calendar.DAY_OF_MONTH, current.getActualMaximum(Calendar.DAY_OF_MONTH));
        if (current.compareTo(end) <= 0) {
          indices.add(formatIndexPattern(""%s-%s%c%02d%c*"", current, prefix));
          current.add(Calendar.DAY_OF_MONTH, 1); // rollover to next month
          continue;
        }
        current.set(Calendar.DAY_OF_MONTH, 9); // try to compress days 0-9
        if (current.compareTo(end) <= 0) {
          indices.add(formatIndexPattern(""%s-%s%c%02d%c0*"", current, prefix));
          current.add(Calendar.DAY_OF_MONTH, 1); // rollover to day 10
          continue;
        }
        current.set(Calendar.DAY_OF_MONTH, 1); // set back to day 1
      } else if (current.get(Calendar.DAY_OF_MONTH) == 10) {
        current.set(Calendar.DAY_OF_MONTH, 19); // try to compress days 10-19
        if (current.compareTo(end) <= 0) {
          indices.add(formatIndexPattern(""%s-%s%c%02d%c1*"", current, prefix));
          current.add(Calendar.DAY_OF_MONTH, 1); // rollover to day 20
          continue;
        }
        current.set(Calendar.DAY_OF_MONTH, 10); // set back to day 10
      } else if (current.get(Calendar.DAY_OF_MONTH) == 20) {
        current.set(Calendar.DAY_OF_MONTH, 29); // try to compress days 20-29
        if (current.compareTo(end) <= 0) {
          indices.add(formatIndexPattern(""%s-%s%c%02d%c2*"", current, prefix));
          current.add(Calendar.DAY_OF_MONTH, 1); // rollover to day 30
          continue;
        }
        current.set(Calendar.DAY_OF_MONTH, 20); // set back to day 20
      }
      indices.add(formatTypeAndTimestamp(type, current.getTimeInMillis()));
      current.add(Calendar.DAY_OF_MONTH, 1);
    }
    return indices;
  }"
"protected void checkParameters() {
        // 检查注入的ref是否接口实现类
        Class proxyClass = providerConfig.getProxyClass();
        String key = providerConfig.buildKey();
        T ref = providerConfig.getRef();
        if (!proxyClass.isInstance(ref)) {
            throw ExceptionUtils.buildRuntime(""provider.ref"",
                ref == null ? ""null"" : ref.getClass().getName(),
                ""This is not an instance of "" + providerConfig.getInterfaceId()
                    + "" in provider config with key "" + key + "" !"");
        }
        // server 不能为空
        if (CommonUtils.isEmpty(providerConfig.getServer())) {
            throw ExceptionUtils.buildRuntime(""server"", ""NULL"", ""Value of \""server\"" is not specified in provider"" +
                "" config with key "" + key + "" !"");
        }
        checkMethods(proxyClass);
    }"
"public String updateSetColumnsByDiffer(Class<?> entityClass) {
        StringBuilder sql = new StringBuilder();
        sql.append(""<set>"");
        //获取全部列
        Set<EntityColumn> columnSet = EntityHelper.getColumns(entityClass);
        //对乐观锁的支持
        EntityColumn versionColumn = null;
        //当某个列有主键策略时，不需要考虑他的属性是否为空，因为如果为空，一定会根据主键策略给他生成一个值
        for (EntityColumn column : columnSet) {
            if (column.getEntityField().isAnnotationPresent(Version.class)) {
                if (versionColumn != null) {
                    throw new VersionException(entityClass.getCanonicalName() + "" 中包含多个带有 @Version 注解的字段，一个类中只能存在一个带有 @Version 注解的字段!"");
                }
                versionColumn = column;
            }
            if (!column.isId() && column.isUpdatable()) {
                if (column == versionColumn) {
                    Version version = versionColumn.getEntityField().getAnnotation(Version.class);
                    String versionClass = version.nextVersion().getCanonicalName();
                    //version = ${@tk.mybatis.mapper.version@nextVersionClass(""versionClass"", version)}
                    sql.append(column.getColumn())
                        .append("" = ${@tk.mybatis.mapper.version.VersionUtil@nextVersion("")
                        .append(""@"").append(versionClass).append(""@class, "")
                        .append(column.getProperty()).append("")},"");
                } else {
                    //if old.xx != newer.xx
                    sql.append(getIfNotEqual(column, column.getColumnEqualsHolder(NEWER) + "",""));
                }
            }
        }
        sql.append(""</set>"");
        return sql.toString();
    }"
"protected T sendAndReturn(final HttpUriRequest request) throws IOException {
    try (CloseableHttpClient client = HttpClients.createDefault()) {
      return this.parseResponse(client.execute(request));
    }
  }"
"public static void addDeprecation(String key, String newKey,
	                                  String customMessage) {
		addDeprecation(key, new String[] {newKey}, customMessage);
	}"
"public static long lowerHexToUnsignedLong(String lowerHex) {
    int length = lowerHex.length();
    if (length < 1 || length > 32) throw isntLowerHexLong(lowerHex);

    // trim off any high bits
    int beginIndex = length > 16 ? length - 16 : 0;

    return lowerHexToUnsignedLong(lowerHex, beginIndex);
  }"
"protected void configureTwitterClient(final Collection<BaseClient> properties) {
        val twitter = pac4jProperties.getTwitter();
        if (StringUtils.isNotBlank(twitter.getId()) && StringUtils.isNotBlank(twitter.getSecret())) {
            val client = new TwitterClient(twitter.getId(), twitter.getSecret(), twitter.isIncludeEmail());
            configureClient(client, twitter);

            LOGGER.debug(""Created client [{}] with identifier [{}]"", client.getName(), client.getKey());
            properties.add(client);
        }
    }"
"public String getColumnHolder(String entityName, String suffix) {
        return getColumnHolder(entityName, null, null);
    }"
"public static <T> SinkFunction.Context<T> forTimestamp(long timestamp) {
		return new SinkFunction.Context<T>() {
			@Override
			public long currentProcessingTime() {
				throw new RuntimeException(""Not implemented"");
			}

			@Override
			public long currentWatermark() {
				throw new RuntimeException(""Not implemented"");
			}

			@Override
			public Long timestamp() {
				return timestamp;
			}
		};
	}"
"@Override AutoBuffer call( AutoBuffer ab ) {
    long[] a = snapshot();
    if( ab._h2o == H2O.SELF ) {
      synchronized(TimeLine.class) {
        for( int i=0; i<CLOUD._memary.length; i++ )
          if( CLOUD._memary[i]==H2O.SELF )
            SNAPSHOT[i] = a;
        TimeLine.class.notify();
      }
    } else // Send timeline to remote
      new AutoBuffer(ab._h2o,udp.timeline._prior).putUdp(UDP.udp.timeline).putA8(a).close();
    return null;
  }"
"public Canal findCanal(String destination) {
        FindCanalEvent event = new FindCanalEvent();
        event.setDestination(destination);
        try {
            Object obj = delegate.callManager(event);
            if (obj != null && obj instanceof Canal) {
                return (Canal) obj;
            } else {
                throw new CanalException(""No Such Canal by ["" + destination + ""]"");
            }
        } catch (Exception e) {
            throw new CanalException(""call_manager_error"", e);
        }
    }"
"public Map<Long, ThroughputInfo> listTimelineThroughput(TimelineThroughputCondition condition) {
        Assert.assertNotNull(condition);
        Map<Long, ThroughputInfo> throughputInfos = new LinkedHashMap<Long, ThroughputInfo>();
        List<ThroughputStatDO> throughputStatDOs = throughputDao.listTimelineThroughputStat(condition);
        int size = throughputStatDOs.size();
        int k = size - 1;
        for (Long i = condition.getStart().getTime(); i <= condition.getEnd().getTime(); i += 60 * 1000) {
            ThroughputInfo throughputInfo = new ThroughputInfo();
            List<ThroughputStat> throughputStat = new ArrayList<ThroughputStat>();
            // 取出每个时间点i以内的数据，k是一个游标，每次遍历时前面已经取过了的数据就不用再遍历了
            for (int j = k; j >= 0; --j) {
                if ((i - throughputStatDOs.get(j).getEndTime().getTime() <= 60 * 1000)
                    && (i - throughputStatDOs.get(j).getEndTime().getTime() >= 0)) {
                    throughputStat.add(throughputStatDOToModel(throughputStatDOs.get(j)));
                    k = j - 1;
                }// 如果不满足if条件，则后面的数据也不用再遍历
                else {
                    break;
                }
            }
            if (throughputStat.size() > 0) {
                throughputInfo.setItems(throughputStat);
                throughputInfo.setSeconds(1 * 60L);
                throughputInfos.put(i, throughputInfo);
            }

        }
        return throughputInfos;
    }"
"public short shortValue() throws OtpErlangRangeException {
        final long l = longValue();
        final short i = (short) l;

        if (i != l) {
            throw new OtpErlangRangeException(""Value too large for short: ""
                    + val);
        }

        return i;
    }"
"private Writer doWrite(Writer writer, int indentFactor, int indent) throws IOException {
		writer.write(CharUtil.BRACKET_START);
		final int newindent = indent + indentFactor;
		final boolean isIgnoreNullValue = this.config.isIgnoreNullValue();
		boolean isFirst = true;
		for (Object obj : this.rawList) {
			if(ObjectUtil.isNull(obj) && isIgnoreNullValue) {
				continue;
			}
			if (isFirst) {
				isFirst = false;
			}else {
				writer.write(CharUtil.COMMA);
			}
			
			if (indentFactor > 0) {
				writer.write(CharUtil.LF);
			}
			InternalJSONUtil.indent(writer, newindent);
			InternalJSONUtil.writeValue(writer, obj, indentFactor, newindent, this.config);
		}
		
		if (indentFactor > 0) {
			writer.write(CharUtil.LF);
		}
		InternalJSONUtil.indent(writer, indent);
		writer.write(CharUtil.BRACKET_END);
		return writer;
	}"
"public static void verifyAndThrow(final Set<String> nameSet, final X509Certificate cert) throws CertificateException{
		if (!verify(nameSet, cert)) {
			throw new CertificateException(""No name matching "" + nameSet + "" found"");
		}
	}"
"public static File appendString(String content, File file, String charset) throws IORuntimeException {
		return FileWriter.create(file, CharsetUtil.charset(charset)).append(content);
	}"
"public static Set<Symbol> extractUnique(RowExpression expression)
    {
        return ImmutableSet.copyOf(extractAll(expression).stream().map(variable -> new Symbol(variable.getName())).collect(toSet()));
    }"
"public void addBodyFileUpload(String name, File file, String contentType, boolean isText)
            throws ErrorDataEncoderException {
        addBodyFileUpload(name, file.getName(), file, contentType, isText);
    }"
"public void greet(String name) {
    logger.info(""Will try to greet "" + name + "" ..."");
    HelloRequest request = HelloRequest.newBuilder().setName(name).build();
    HelloReply response;
    try {
      response = blockingStub.sayHello(request);
    } catch (StatusRuntimeException e) {
      logger.log(Level.WARNING, ""RPC failed: {0}"", e.getStatus());
      return;
    }
    logger.info(""Greeting: "" + response.getMessage());
  }"
"public SDVariable lt(String name, SDVariable other){
        return sameDiff.lt(name, this, other);
    }"
"private List<String> yield(List<String> labels) {
        labels.add(label);
        for (Tree t : children()) {
            labels.addAll(t.yield());
        }
        return labels;
    }"
"@Nullable
	public static SSLContext createRestClientSSLContext(Configuration config) throws Exception {
		final RestSSLContextConfigMode configMode;
		if (isRestSSLAuthenticationEnabled(config)) {
			configMode = RestSSLContextConfigMode.MUTUAL;
		} else {
			configMode = RestSSLContextConfigMode.CLIENT;
		}

		return createRestSSLContext(config, configMode);
	}"
"private static void sortAtByte(
      LongArray array, long numRecords, long[] counts, int byteIdx, long inIndex, long outIndex,
      boolean desc, boolean signed) {
    assert counts.length == 256;
    long[] offsets = transformCountsToOffsets(
      counts, numRecords, array.getBaseOffset() + outIndex * 8L, 8, desc, signed);
    Object baseObject = array.getBaseObject();
    long baseOffset = array.getBaseOffset() + inIndex * 8L;
    long maxOffset = baseOffset + numRecords * 8L;
    for (long offset = baseOffset; offset < maxOffset; offset += 8) {
      long value = Platform.getLong(baseObject, offset);
      int bucket = (int)((value >>> (byteIdx * 8)) & 0xff);
      Platform.putLong(baseObject, offsets[bucket], value);
      offsets[bucket] += 8;
    }
  }"
"public static @CheckForNull <T extends Item> T findNearest(Class<T> type, String name, ItemGroup context) {
        List<String> names = new ArrayList<>();
        for (T item: Jenkins.getInstance().allItems(type)) {
            names.add(item.getRelativeNameFrom(context));
        }
        String nearest = EditDistance.findNearest(name, names);
        return Jenkins.getInstance().getItem(nearest, context, type);
    }"
"private static boolean patchShadedLibraryId(byte[] bytes, String originalName, String name) {
        // Our native libs always have the name as part of their id so we can search for it and replace it
        // to make the ID unique if shading is used.
        byte[] nameBytes = originalName.getBytes(CharsetUtil.UTF_8);
        int idIdx = -1;

        // Be aware this is a really raw way of patching a dylib but it does all we need without implementing
        // a full mach-o parser and writer. Basically we just replace the the original bytes with some
        // random bytes as part of the ID regeneration. The important thing here is that we need to use the same
        // length to not corrupt the mach-o header.
        outerLoop: for (int i = 0; i < bytes.length && bytes.length - i >= nameBytes.length; i++) {
            int idx = i;
            for (int j = 0; j < nameBytes.length;) {
                if (bytes[idx++] != nameBytes[j++]) {
                    // Did not match the name, increase the index and try again.
                    break;
                } else if (j == nameBytes.length) {
                    // We found the index within the id.
                    idIdx = i;
                    break outerLoop;
                }
            }
        }

        if (idIdx == -1) {
            logger.debug(""Was not able to find the ID of the shaded native library {}, can't adjust it."", name);
            return false;
        } else {
            // We found our ID... now monkey-patch it!
            for (int i = 0; i < nameBytes.length; i++) {
                // We should only use bytes as replacement that are in our UNIQUE_ID_BYTES array.
                bytes[idIdx + i] = UNIQUE_ID_BYTES[PlatformDependent.threadLocalRandom()
                                                                    .nextInt(UNIQUE_ID_BYTES.length)];
            }

            if (logger.isDebugEnabled()) {
                logger.debug(
                        ""Found the ID of the shaded native library {}. Replacing ID part {} with {}"",
                        name, originalName, new String(bytes, idIdx, nameBytes.length, CharsetUtil.UTF_8));
            }
            return true;
        }
    }"
"private void startProcessSelect() {
        executor.submit(new Runnable() {

            public void run() {
                MDC.put(OtterConstants.splitPipelineLogFileKey, String.valueOf(pipelineId));
                String currentName = Thread.currentThread().getName();
                Thread.currentThread().setName(createTaskName(pipelineId, ""ProcessSelect""));
                try {
                    processSelect();
                } finally {
                    Thread.currentThread().setName(currentName);
                    MDC.remove(OtterConstants.splitPipelineLogFileKey);
                }
            }
        });

    }"
"@SuppressWarnings(""deprecation"") // in this case we really want to use PeriodicWork.logger since it reports the impl class
    public final void doRun() {
        try {
            if(thread!=null && thread.isAlive()) {
                logger.log(this.getSlowLoggingLevel(), ""{0} thread is still running. Execution aborted."", name);
                return;
            }
            thread = new Thread(new Runnable() {
                public void run() {
                    logger.log(getNormalLoggingLevel(), ""Started {0}"", name);
                    long startTime = System.currentTimeMillis();
                    long stopTime;

                    StreamTaskListener l = createListener();
                    try {
                        l.getLogger().printf(""Started at %tc%n"", new Date(startTime));
                        ACL.impersonate(ACL.SYSTEM);

                        execute(l);
                    } catch (IOException e) {
                        Functions.printStackTrace(e, l.fatalError(e.getMessage()));
                    } catch (InterruptedException e) {
                        Functions.printStackTrace(e, l.fatalError(""aborted""));
                    } finally {
                        stopTime = System.currentTimeMillis();
                        try {
                            l.getLogger().printf(""Finished at %tc. %dms%n"", new Date(stopTime), stopTime - startTime);
                        } finally {
                            l.closeQuietly();
                        }
                    }

                    logger.log(getNormalLoggingLevel(), ""Finished {0}. {1,number} ms"",
                            new Object[]{name, stopTime - startTime});
                }
            },name+"" thread"");
            thread.start();
        } catch (Throwable t) {
            LogRecord lr = new LogRecord(this.getErrorLoggingLevel(), ""{0} thread failed with error"");
            lr.setThrown(t);
            lr.setParameters(new Object[]{name});
            logger.log(lr);
        }
    }"
"public String createPersistentSequential(String path, Object data) throws ZkInterruptedException,
                                                                      IllegalArgumentException, ZkException,
                                                                      RuntimeException {
        return create(path, data, CreateMode.PERSISTENT_SEQUENTIAL);
    }"
"public static byte getFlatOpType(Op.Type type) {
        switch (type) {
            case SCALAR:
                return OpType.SCALAR;
            case SCALAR_BOOL:
                return OpType.SCALAR_BOOL;
            case BROADCAST:
                return OpType.BROADCAST;
            case BROADCAST_BOOL:
                return OpType.BROADCAST_BOOL;
            case TRANSFORM_BOOL:
                return OpType.TRANSFORM_BOOL;
            case TRANSFORM_FLOAT:
                return OpType.TRANSFORM_FLOAT;
            case TRANSFORM_SAME:
                return OpType.TRANSFORM_SAME;
            case TRANSFORM_ANY:
                return OpType.TRANSFORM_ANY;
            case TRANSFORM_STRICT:
                return OpType.TRANSFORM_STRICT;
            case SPECIAL:
                return OpType.TRANSFORM_STRICT;
            case VARIANCE:
            case REDUCE_FLOAT:
                return OpType.REDUCE_FLOAT;
            case REDUCE_BOOL:
                return OpType.REDUCE_BOOL;
            case REDUCE_SAME:
                return OpType.REDUCE_SAME;
            case REDUCE_LONG:
                return OpType.REDUCE_LONG;
            case REDUCE3:
                return OpType.REDUCE_3;
            case INDEXREDUCE:
                return OpType.INDEX_REDUCE;
            case RANDOM:
                return OpType.RANDOM;
            case MERGE:
            case CONDITIONAL:
            case LOOP:
            case RETURN:
            case ENTER:
            case EXIT:
            case NEXT_ITERATION:
            case LOOP_COND:
            case IF:
                return OpType.LOGIC;
            case CUSTOM:
                return OpType.CUSTOM;
            case PAIRWISE:
                return OpType.PAIRWISE;
            case PAIRWISE_BOOL:
                return OpType.PAIRWISE_BOOL;
            case SUMMARYSTATS:
                return OpType.SUMMARYSTATS;
            default:
                throw new UnsupportedOperationException(""Unknown op type passed in: "" + type);
        }
    }"
"public static CalendarInterval fromDayTimeString(String s) throws IllegalArgumentException {
    CalendarInterval result = null;
    if (s == null) {
      throw new IllegalArgumentException(""Interval day-time string was null"");
    }
    s = s.trim();
    Matcher m = dayTimePattern.matcher(s);
    if (!m.matches()) {
      throw new IllegalArgumentException(
        ""Interval string does not match day-time format of 'd h:m:s.n': "" + s);
    } else {
      try {
        int sign = m.group(1) != null && m.group(1).equals(""-"") ? -1 : 1;
        long days = toLongWithRange(""day"", m.group(2), 0, Integer.MAX_VALUE);
        long hours = toLongWithRange(""hour"", m.group(3), 0, 23);
        long minutes = toLongWithRange(""minute"", m.group(4), 0, 59);
        long seconds = toLongWithRange(""second"", m.group(5), 0, 59);
        // Hive allow nanosecond precision interval
        long nanos = toLongWithRange(""nanosecond"", m.group(7), 0L, 999999999L);
        result = new CalendarInterval(0, sign * (
          days * MICROS_PER_DAY + hours * MICROS_PER_HOUR + minutes * MICROS_PER_MINUTE +
          seconds * MICROS_PER_SECOND + nanos / 1000L));
      } catch (Exception e) {
        throw new IllegalArgumentException(
          ""Error parsing interval day-time string: "" + e.getMessage(), e);
      }
    }
    return result;
  }"
"@Nullable
  public static String getHealthCheckedServiceName(@Nullable Map<String, ?> serviceConfig) {
    String healthCheckKey = ""healthCheckConfig"";
    String serviceNameKey = ""serviceName"";
    if (serviceConfig == null || !serviceConfig.containsKey(healthCheckKey)) {
      return null;
    }

    /* schema as follows
    {
      ""healthCheckConfig"": {
        // Service name to use in the health-checking request.
        ""serviceName"": string
      }
    }
    */
    Map<String, ?> healthCheck = getObject(serviceConfig, healthCheckKey);
    if (!healthCheck.containsKey(serviceNameKey)) {
      return null;
    }
    return getString(healthCheck, ""serviceName"");
  }"
"protected String extractHeaderToken(HttpServletRequest request) {
		Enumeration<String> headers = request.getHeaders(""Authorization"");
		while (headers.hasMoreElements()) { // typically there is only one (most servers enforce that)
			String value = headers.nextElement();
			if ((value.toLowerCase().startsWith(OAuth2AccessToken.BEARER_TYPE.toLowerCase()))) {
				String authHeaderValue = value.substring(OAuth2AccessToken.BEARER_TYPE.length()).trim();
				// Add this here for the auth details later. Would be better to change the signature of this method.
				request.setAttribute(OAuth2AuthenticationDetails.ACCESS_TOKEN_TYPE,
						value.substring(0, OAuth2AccessToken.BEARER_TYPE.length()).trim());
				int commaIndex = authHeaderValue.indexOf(',');
				if (commaIndex > 0) {
					authHeaderValue = authHeaderValue.substring(0, commaIndex);
				}
				return authHeaderValue;
			}
		}

		return null;
	}"
"protected URL getResourceURL(File file, String resourceName) {
        try {
            JarFile jarFile = (JarFile) jarFiles.get(file);
            if (jarFile == null && file.isDirectory()) {
                File resource = new File(file, resourceName);

                if (resource.exists()) {
                    try {
                        return FILE_UTILS.getFileURL(resource);
                    } catch (MalformedURLException ex) {
                        return null;
                    }
                }
            } else {
                if (jarFile == null) {
                    if (file.exists()) {
                        jarFile = new JarFile(file);
                        jarFiles.put(file, jarFile);
                    } else {
                        return null;
                    }
                    // potential race-condition
                    jarFile = (JarFile) jarFiles.get(file);
                }
                JarEntry entry = jarFile.getJarEntry(resourceName);
                if (entry != null) {
                    try {
                        return new URL(""jar:"" + FILE_UTILS.getFileURL(file) + ""!/"" + entry);
                    } catch (MalformedURLException ex) {
                        return null;
                    }
                }
            }
        } catch (Exception e) {
            String msg = ""Unable to obtain resource from "" + file + "": "";
            log(msg + e, Project.MSG_WARN);
            System.err.println(msg);
            e.printStackTrace();
        }
        return null;
    }"
"public boolean isSet(_Fields field) {
    if (field == null) {
      throw new IllegalArgumentException();
    }

    switch (field) {
    case OBJECT_TYPE_PTR:
      return isSetObjectTypePtr();
    }
    throw new IllegalStateException();
  }"
"public static Long getValidMaxTotalRows(IndexTuningConfig tuningConfig)
  {
    @Nullable final Integer numShards = tuningConfig.numShards;
    @Nullable final Long maxTotalRows = tuningConfig.maxTotalRows;
    if (numShards == null || numShards == -1) {
      return maxTotalRows == null ? IndexTuningConfig.DEFAULT_MAX_TOTAL_ROWS : maxTotalRows;
    } else {
      return null;
    }
  }"
"@SuppressWarnings(""unchecked"")
	public void restoreTimersForKeyGroup(InternalTimersSnapshot<?, ?> restoredSnapshot, int keyGroupIdx) {
		this.restoredTimersSnapshot = (InternalTimersSnapshot<K, N>) restoredSnapshot;

		TypeSerializer<K> restoredKeySerializer = restoredTimersSnapshot.getKeySerializerSnapshot().restoreSerializer();
		if (this.keyDeserializer != null && !this.keyDeserializer.equals(restoredKeySerializer)) {
			throw new IllegalArgumentException(""Tried to restore timers for the same service with different key serializers."");
		}
		this.keyDeserializer = restoredKeySerializer;

		TypeSerializer<N> restoredNamespaceSerializer = restoredTimersSnapshot.getNamespaceSerializerSnapshot().restoreSerializer();
		if (this.namespaceDeserializer != null && !this.namespaceDeserializer.equals(restoredNamespaceSerializer)) {
			throw new IllegalArgumentException(""Tried to restore timers for the same service with different namespace serializers."");
		}
		this.namespaceDeserializer = restoredNamespaceSerializer;

		checkArgument(localKeyGroupRange.contains(keyGroupIdx),
			""Key Group "" + keyGroupIdx + "" does not belong to the local range."");

		// restore the event time timers
		eventTimeTimersQueue.addAll(restoredTimersSnapshot.getEventTimeTimers());

		// restore the processing time timers
		processingTimeTimersQueue.addAll(restoredTimersSnapshot.getProcessingTimeTimers());
	}"
"public static SlotProfile preferredLocality(ResourceProfile resourceProfile, Collection<TaskManagerLocation> preferredLocations) {
		return new SlotProfile(resourceProfile, preferredLocations, Collections.emptyList());
	}"
"public Set<String> generateIdsToUse(long nextFreeTransactionalId) {
		Set<String> transactionalIds = new HashSet<>();
		for (int i = 0; i < poolSize; i++) {
			long transactionalId = nextFreeTransactionalId + subtaskIndex * poolSize + i;
			transactionalIds.add(generateTransactionalId(transactionalId));
		}
		return transactionalIds;
	}"
"public boolean learn(String segmentedTaggedSentence)
    {
        Sentence sentence = Sentence.create(segmentedTaggedSentence);
        return learn(sentence);
    }"
"public void getFieldsIntoCheckingNull(int[] positions, Value[] targets) {
		for (int i = 0; i < positions.length; i++) {
			if (!getFieldInto(positions[i], targets[i])) {
				throw new NullKeyFieldException(i);
			}
		}
	}"
"public static boolean endsWithIgnoreCase(String str, String suffix) {
        if (str == null || suffix == null) {
            return false;
        }
        if (str.endsWith(suffix)) {
            return true;
        }
        if (str.length() < suffix.length()) {
            return false;
        }

        String lcStr = str.substring(str.length() - suffix.length()).toLowerCase();
        String lcSuffix = suffix.toLowerCase();
        return lcStr.equals(lcSuffix);
    }"
"private static void readToList(InputStream input, String encoding, List<String> blackPrefixList) {
        InputStreamReader reader = null;
        BufferedReader bufferedReader = null;
        try {
            reader = new InputStreamReader(input, encoding);
            bufferedReader = new BufferedReader(reader);
            String lineText;
            while ((lineText = bufferedReader.readLine()) != null) {
                String pkg = lineText.trim();
                if (pkg.length() > 0) {
                    blackPrefixList.add(pkg);
                }
            }
        } catch (IOException e) {
            if (LOGGER.isWarnEnabled()) {
                LOGGER.warn(e.getMessage(), e);
            }
        } finally {
            closeQuietly(bufferedReader);
            closeQuietly(reader);
        }
    }"
"public static void checkArgument(boolean condition,
			@Nullable String errorMessageTemplate,
			@Nullable Object... errorMessageArgs) {

		if (!condition) {
			throw new IllegalArgumentException(format(errorMessageTemplate, errorMessageArgs));
		}
	}"
"public static Long getLong(final LdapEntry entry, final String attribute, final Long nullValue) {
        val v = getString(entry, attribute, nullValue.toString());
        if (NumberUtils.isCreatable(v)) {
            return Long.valueOf(v);
        }
        return nullValue;
    }"
"public ParameterTool applyTo(ParameterTool parameterTool) throws RequiredParametersException {
		List<String> missingArguments = new LinkedList<>();

		HashMap<String, String> newParameters = new HashMap<>(parameterTool.toMap());

		for (Option o : data.values()) {
			if (newParameters.containsKey(o.getName())) {
				if (Objects.equals(newParameters.get(o.getName()), ParameterTool.NO_VALUE_KEY)) {
					// the parameter has been passed, but no value, check if there is a default value
					checkAndApplyDefaultValue(o, newParameters);
				} else {
					// a value has been passed in the parameterTool, now check if it adheres to all constraints
					checkAmbiguousValues(o, newParameters);
					checkIsCastableToDefinedType(o, newParameters);
					checkChoices(o, newParameters);
				}
			} else {
				// check if there is a default name or a value passed for a possibly defined alternative name.
				if (hasNoDefaultValueAndNoValuePassedOnAlternativeName(o, newParameters)) {
					missingArguments.add(o.getName());
				}
			}
		}
		if (!missingArguments.isEmpty()) {
			throw new RequiredParametersException(this.missingArgumentsText(missingArguments), missingArguments);
		}

		return ParameterTool.fromMap(newParameters);
	}"
"private static String multiPointCoordinatesFromWkt(String wkt) {
        wkt = removeBrackets(wkt,1);
        boolean isSecondVersionMultiPoint = wkt.contains(""("");
        String coordinates = """";
        if(isSecondVersionMultiPoint){
            //(10 40), (40 30), (20 20)-> 10 40, 40 30, 20 20
            wkt = wkt.replaceAll(""\\(|\\)"" ,"""");
        }
        coordinates = getJsonArrayFromListOfPoints(wkt);
        return coordinates;
    }"
"public boolean hasParticipant(User user) {
        for( R build = getLastBuild(); build!=null; build=build.getPreviousBuild())
            if(build.hasParticipant(user))
                return true;
        return false;
    }"
"public LogoutRequest newLogoutRequest(final String id, final DateTime issueInstant,
                                          final String destination, final Issuer issuer,
                                          final String sessionIndex, final NameID nameId) {
        val request = newSamlObject(LogoutRequest.class);
        request.setID(id);
        request.setVersion(SAMLVersion.VERSION_20);
        request.setIssueInstant(issueInstant);
        request.setIssuer(issuer);
        request.setDestination(destination);

        if (StringUtils.isNotBlank(sessionIndex)) {
            val sessionIdx = newSamlObject(SessionIndex.class);
            sessionIdx.setSessionIndex(sessionIndex);
            request.getSessionIndexes().add(sessionIdx);
        }

        if (nameId != null) {
            request.setNameID(nameId);
        }
        return request;
    }"
"protected void updateTicketGrantingTicketState() {
        val ticketGrantingTicket = getTicketGrantingTicket();
        if (ticketGrantingTicket != null && !ticketGrantingTicket.isExpired()) {
            val state = TicketState.class.cast(ticketGrantingTicket);
            state.update();
        }
    }"
"@Override
  public Long hlen(final byte[] key) {
    checkIsInMultiOrPipeline();
    client.hlen(key);
    return client.getIntegerReply();
  }"
"final void launchIntent(Intent intent) {
    try {
      rawLaunchIntent(intent);
    } catch (ActivityNotFoundException ignored) {
      AlertDialog.Builder builder = new AlertDialog.Builder(activity);
      builder.setTitle(R.string.app_name);
      builder.setMessage(R.string.msg_intent_failed);
      builder.setPositiveButton(R.string.button_ok, null);
      builder.show();
    }
  }"
"protected Map<CharSequence, List<V>> wrapValues(Map<CharSequence, List<V>> values) {
        return Collections.unmodifiableMap(values);
    }"
"public static InstrumentedExecutorService newSingleThreadExecutor(MetricRegistry registry, String name) {
        return new InstrumentedExecutorService(Executors.newSingleThreadExecutor(), registry, name);
    }"
"public static DataSource createDataSource(final byte[] yamlBytes) throws SQLException, IOException {
        YamlOrchestrationMasterSlaveRuleConfiguration config = unmarshal(yamlBytes);
        return createDataSource(config.getDataSources(), config.getMasterSlaveRule(), config.getProps(), config.getOrchestration());
    }"
"public TransitionableState getTransitionableState(final Flow flow, final String stateId) {
        if (containsFlowState(flow, stateId)) {
            return (TransitionableState) flow.getTransitionableState(stateId);
        }
        return null;
    }"
"public String executeCommandOnServlet(String command) {
    try {
      return getCommandResponseAsString(command);
    } catch (IOException e) {
      if (e instanceof ConnectException) {
        throw new SeleniumException(e.getMessage(), e);
      }
      e.printStackTrace();
      throw new UnsupportedOperationException(""Catch body broken: IOException from "" + command +
          "" -> "" + e, e);
    }
  }"
"public void add(final Condition condition) {
        if (andConditions.isEmpty()) {
            andConditions.add(new AndCondition());
        }
        andConditions.get(0).getConditions().add(condition);
    }"
"public static void recoverOriginWeight(ProviderInfo providerInfo, int originWeight) {
        providerInfo.setStatus(ProviderStatus.AVAILABLE);
        providerInfo.setWeight(originWeight);
    }"
"public ShardingStrategy getTableShardingStrategy(final TableRule tableRule) {
        return null == tableRule.getTableShardingStrategy() ? defaultTableShardingStrategy : tableRule.getTableShardingStrategy();
    }"
"public HystrixMetricsPublisherThreadPool getMetricsPublisherForThreadPool(HystrixThreadPoolKey threadPoolKey, HystrixThreadPoolMetrics metrics, HystrixThreadPoolProperties properties) {
        return new HystrixMetricsPublisherThreadPoolDefault(threadPoolKey, metrics, properties);
    }"
"public static BaseRowKeySelector getBaseRowSelector(int[] keyFields, BaseRowTypeInfo rowType) {
		if (keyFields.length > 0) {
			InternalType[] inputFieldTypes = rowType.getInternalTypes();
			String[] inputFieldNames = rowType.getFieldNames();
			InternalType[] keyFieldTypes = new InternalType[keyFields.length];
			String[] keyFieldNames = new String[keyFields.length];
			for (int i = 0; i < keyFields.length; ++i) {
				keyFieldTypes[i] = inputFieldTypes[keyFields[i]];
				keyFieldNames[i] = inputFieldNames[keyFields[i]];
			}
			RowType returnType = new RowType(keyFieldTypes, keyFieldNames);
			RowType inputType = new RowType(inputFieldTypes, rowType.getFieldNames());
			GeneratedProjection generatedProjection = ProjectionCodeGenerator.generateProjection(
				CodeGeneratorContext.apply(new TableConfig()),
				""KeyProjection"",
				inputType,
				returnType, keyFields);
			BaseRowTypeInfo keyRowType = returnType.toTypeInfo();
			// check if type implements proper equals/hashCode
			TypeCheckUtils.validateEqualsHashCode(""grouping"", keyRowType);
			return new BinaryRowKeySelector(keyRowType, generatedProjection);
		} else {
			return NullBinaryRowKeySelector.INSTANCE;
		}
	}"
"protected AppenderatorDriverAddResult append(
      final InputRow row,
      final String sequenceName,
      @Nullable final Supplier<Committer> committerSupplier,
      final boolean skipSegmentLineageCheck,
      final boolean allowIncrementalPersists
  ) throws IOException
  {
    Preconditions.checkNotNull(row, ""row"");
    Preconditions.checkNotNull(sequenceName, ""sequenceName"");

    final SegmentIdWithShardSpec identifier = getSegment(row, sequenceName, skipSegmentLineageCheck);

    if (identifier != null) {
      try {
        final Appenderator.AppenderatorAddResult result = appenderator.add(
            identifier,
            row,
            committerSupplier == null ? null : wrapCommitterSupplier(committerSupplier),
            allowIncrementalPersists
        );
        return AppenderatorDriverAddResult.ok(
            identifier,
            result.getNumRowsInSegment(),
            appenderator.getTotalRowCount(),
            result.isPersistRequired(),
            result.getParseException()
        );
      }
      catch (SegmentNotWritableException e) {
        throw new ISE(e, ""WTF?! Segment[%s] not writable when it should have been."", identifier);
      }
    } else {
      return AppenderatorDriverAddResult.fail();
    }
  }"
"@PUT
    @Path(""{asgName}/status"")
    public Response statusUpdate(@PathParam(""asgName"") String asgName,
                                 @QueryParam(""value"") String newStatus,
                                 @HeaderParam(PeerEurekaNode.HEADER_REPLICATION) String isReplication) {
        if (awsAsgUtil == null) {
            return Response.status(400).build();
        }

        try {
            logger.info(""Trying to update ASG Status for ASG {} to {}"", asgName, newStatus);
            ASGStatus asgStatus = ASGStatus.valueOf(newStatus.toUpperCase());
            awsAsgUtil.setStatus(asgName, (!ASGStatus.DISABLED.equals(asgStatus)));
            registry.statusUpdate(asgName, asgStatus, Boolean.valueOf(isReplication));
            logger.debug(""Updated ASG Status for ASG {} to {}"", asgName, asgStatus);

        } catch (Throwable e) {
            logger.error(""Cannot update the status {} for the ASG {}"", newStatus, asgName, e);
            return Response.serverError().build();
        }
        return Response.ok().build();
    }"
"protected void createWarnDecisionState(final Flow flow) {
        createDecisionState(flow, CasWebflowConstants.STATE_ID_WARN,
            ""flowScope.warnCookieValue"",
            CasWebflowConstants.STATE_ID_SHOW_WARNING_VIEW,
            CasWebflowConstants.STATE_ID_REDIRECT);
    }"
"public String getDisplayName() {
        val items = getDisplayNames();
        if (items.isEmpty()) {
            return this.registeredService.getName();
        }
        return StringUtils.collectionToDelimitedString(items, ""."");
    }"
"public static void main(String[] args) throws Exception {
    boolean usage = false;
    int serverPort = 0;
    int driverPort = 0;
    for (String arg : args) {
      if (!arg.startsWith(""--"")) {
        System.err.println(""All arguments must start with '--': "" + arg);
        usage = true;
        break;
      }
      String[] parts = arg.substring(2).split(""="", 2);
      String key = parts[0];
      if (""help"".equals(key)) {
        usage = true;
        break;
      }
      if (parts.length != 2) {
        System.err.println(""All arguments must be of the form --arg=value"");
        usage = true;
        break;
      }
      String value = parts[1];
      if (""server_port"".equals(key)) {
        serverPort = Integer.valueOf(value);
      } else if (""driver_port"".equals(key)) {
        driverPort = Integer.valueOf(value);
      } else {
        System.err.println(""Unknown argument: "" + key);
        usage = true;
        break;
      }
    }
    if (usage || driverPort == 0) {
      System.err.println(
          ""Usage: [ARGS...]""
              + ""\n""
              + ""\n  --driver_port=<port>""
              + ""\n    Port to expose grpc.testing.WorkerService, used by driver to initiate work.""
              + ""\n  --server_port=<port>""
              + ""\n    Port to start load servers on. Defaults to any available port"");
      System.exit(1);
    }
    LoadWorker loadWorker = new LoadWorker(driverPort, serverPort);
    loadWorker.start();
    loadWorker.driverServer.awaitTermination();
    log.log(Level.INFO, ""DriverServer has terminated."");

    // Allow enough time for quitWorker to deliver OK status to the driver.
    Thread.sleep(3000);
  }"
"@Nonnull
    public Descriptor getDescriptorOrDie(Class<? extends Describable> type) {
        Descriptor d = getDescriptor(type);
        if (d==null)
            throw new AssertionError(type+"" is missing its descriptor"");
        return d;
    }"
"public ServiceInstance choose(String serviceId, Object hint) {
		Server server = getServer(getLoadBalancer(serviceId), hint);
		if (server == null) {
			return null;
		}
		return new RibbonServer(serviceId, server, isSecure(server, serviceId),
				serverIntrospector(serviceId).getMetadata(server));
	}"
"public INDArray compress(INDArray array, String algorithm) {
        algorithm = algorithm.toUpperCase();
        if (!codecs.containsKey(algorithm))
            throw new RuntimeException(""Non-existent compression algorithm requested: ["" + algorithm + ""]"");

        return codecs.get(algorithm).compress(array);
    }"
"public static Method getPublicMethodNamed(Class c, String methodName) {
        for( Method m : c.getMethods() )
            if(m.getName().equals(methodName))
                return m;
        return null;
    }"
"public ExcelWriter addHeaderAlias(String name, String alias) {
		Map<String, String> headerAlias = this.headerAlias;
		if (null == headerAlias) {
			headerAlias = new LinkedHashMap<>();
		}
		this.headerAlias = headerAlias;
		headerAlias.put(name, alias);
		return this;
	}"
"public static HandlerLibrary load(Messager messager, Trees trees) {
		HandlerLibrary library = new HandlerLibrary(messager);
		
		try {
			loadAnnotationHandlers(library, trees);
			loadVisitorHandlers(library, trees);
		} catch (IOException e) {
			System.err.println(""Lombok isn't running due to misconfigured SPI files: "" + e);
		}
		
		library.calculatePriorities();
		
		return library;
	}"
"protected char[] normalize(char[] path) throws URIException {

        if (path == null) { 
            return null;
        }

        String normalized = new String(path);

        // If the buffer begins with ""./"" or ""../"", the ""."" or "".."" is removed.
        if (normalized.startsWith(""./"")) {
            normalized = normalized.substring(1);
        } else if (normalized.startsWith(""../"")) {
            normalized = normalized.substring(2);
        } else if (normalized.startsWith("".."")) {
            normalized = normalized.substring(2);
        }

        // All occurrences of ""/./"" in the buffer are replaced with ""/""
        int index = -1;
        while ((index = normalized.indexOf(""/./"")) != -1) {
            normalized = normalized.substring(0, index) + normalized.substring(index + 2);
        }

        // If the buffer ends with ""/."", the ""."" is removed.
        if (normalized.endsWith(""/."")) {
            normalized = normalized.substring(0, normalized.length() - 1);
        }

        int startIndex = 0;

        // All occurrences of ""/<segment>/../"" in the buffer, where ""..""
        // and <segment> are complete path segments, are iteratively replaced
        // with ""/"" in order from left to right until no matching pattern remains.
        // If the buffer ends with ""/<segment>/.."", that is also replaced
        // with ""/"".  Note that <segment> may be empty.
        while ((index = normalized.indexOf(""/../"", startIndex)) != -1) {
            int slashIndex = normalized.lastIndexOf('/', index - 1);
            if (slashIndex >= 0) {
                normalized = normalized.substring(0, slashIndex) + normalized.substring(index + 3);
            } else {
                startIndex = index + 3;   
            }
        }
        if (normalized.endsWith(""/.."")) {
            int slashIndex = normalized.lastIndexOf('/', normalized.length() - 4);
            if (slashIndex >= 0) {
                normalized = normalized.substring(0, slashIndex + 1);
            }
        }

        // All prefixes of ""<segment>/../"" in the buffer, where ""..""
        // and <segment> are complete path segments, are iteratively replaced
        // with ""/"" in order from left to right until no matching pattern remains.
        // If the buffer ends with ""<segment>/.."", that is also replaced
        // with ""/"".  Note that <segment> may be empty.
        while ((index = normalized.indexOf(""/../"")) != -1) {
            int slashIndex = normalized.lastIndexOf('/', index - 1);
            if (slashIndex >= 0) {
                break;
            } else {
                normalized = normalized.substring(index + 3);
            }
        }
        if (normalized.endsWith(""/.."")) {
            int slashIndex = normalized.lastIndexOf('/', normalized.length() - 4);
            if (slashIndex < 0) {
                normalized = ""/"";
            }
        }

        return normalized.toCharArray();
    }"
"@Nonnull
    public static String rawEncode(@Nonnull String s) {
        boolean escaped = false;
        StringBuilder out = null;
        CharsetEncoder enc = null;
        CharBuffer buf = null;
        char c;
        for (int i = 0, m = s.length(); i < m; i++) {
            c = s.charAt(i);
            if (c > 122 || uriMap[c]) {
                if (!escaped) {
                    out = new StringBuilder(i + (m - i) * 3);
                    out.append(s.substring(0, i));
                    enc = StandardCharsets.UTF_8.newEncoder();
                    buf = CharBuffer.allocate(1);
                    escaped = true;
                }
                // 1 char -> UTF8
                buf.put(0,c);
                buf.rewind();
                try {
                    ByteBuffer bytes = enc.encode(buf);
                    while (bytes.hasRemaining()) {
                        byte b = bytes.get();
                        out.append('%');
                        out.append(toDigit((b >> 4) & 0xF));
                        out.append(toDigit(b & 0xF));
                    }
                } catch (CharacterCodingException ex) { }
            } else if (escaped) {
                out.append(c);
            }
        }
        return escaped ? out.toString() : s;
    }"
"public @CheckForNull Authentication authenticate(Queue.Item item) {
        if (Util.isOverridden(QueueItemAuthenticator.class, getClass(), ""authenticate"", Queue.Task.class)) {
            return authenticate(item.task);
        } else {
            throw new AbstractMethodError(""you must override at least one of the QueueItemAuthenticator.authenticate methods"");
        }
    }"
"public static Optional<ModelAndView> hasDelegationRequestFailed(final HttpServletRequest request, final int status) {
        val params = request.getParameterMap();
        if (Stream.of(""error"", ""error_code"", ""error_description"", ""error_message"").anyMatch(params::containsKey)) {
            val model = new HashMap<String, Object>();
            if (params.containsKey(""error_code"")) {
                model.put(""code"", StringEscapeUtils.escapeHtml4(request.getParameter(""error_code"")));
            } else {
                model.put(""code"", status);
            }
            model.put(""error"", StringEscapeUtils.escapeHtml4(request.getParameter(""error"")));
            model.put(""reason"", StringEscapeUtils.escapeHtml4(request.getParameter(""error_reason"")));
            if (params.containsKey(""error_description"")) {
                model.put(""description"", StringEscapeUtils.escapeHtml4(request.getParameter(""error_description"")));
            } else if (params.containsKey(""error_message"")) {
                model.put(""description"", StringEscapeUtils.escapeHtml4(request.getParameter(""error_message"")));
            }
            model.put(CasProtocolConstants.PARAMETER_SERVICE, request.getAttribute(CasProtocolConstants.PARAMETER_SERVICE));
            model.put(""client"", StringEscapeUtils.escapeHtml4(request.getParameter(""client_name"")));
            LOGGER.debug(""Delegation request has failed. Details are [{}]"", model);
            return Optional.of(new ModelAndView(""casPac4jStopWebflow"", model));
        }
        return Optional.empty();
    }"
"void linkLast(final E e) {
    final E l = last;
    last = e;

    if (l == null) {
      first = e;
    } else {
      setNext(l, e);
      setPrevious(e, l);
    }
  }"
"protected boolean doRequiredAttributesAllowPrincipalAccess(final Map<String, Object> principalAttributes, final Map<String, Set<String>> requiredAttributes) {
        LOGGER.debug(""These required attributes [{}] are examined against [{}] before service can proceed."", requiredAttributes, principalAttributes);
        if (requiredAttributes.isEmpty()) {
            return true;
        }
        return requiredAttributesFoundInMap(principalAttributes, requiredAttributes);
    }"
"public <T extends Trigger> T getTrigger(Class<T> clazz) {
        for (Trigger p : triggers()) {
            if(clazz.isInstance(p))
                return clazz.cast(p);
        }
        return null;
    }"
"public RestTemplateBuilder interceptors(
			ClientHttpRequestInterceptor... interceptors) {
		Assert.notNull(interceptors, ""interceptors must not be null"");
		return interceptors(Arrays.asList(interceptors));
	}"
"public void setAgentProtocols(Set<String> protocols) {
        Set<String> disabled = new TreeSet<>();
        Set<String> enabled = new TreeSet<>();
        for (AgentProtocol p : AgentProtocol.all()) {
            String name = p.getName();
            if (name != null && !p.isRequired()) {
                // we want to record the protocols where the admin has made a conscious decision
                // thus, if a protocol is opt-in, we record the admin enabling it
                // if a protocol is opt-out, we record the admin disabling it
                // We should not transition rapidly from opt-in -> opt-out -> opt-in
                // the scenario we want to have work is:
                // 1. We introduce a new protocol, it starts off as opt-in. Some admins decide to test and opt-in
                // 2. We decide that the protocol is ready for general use. It gets marked as opt-out. Any admins
                //    that took part in early testing now have their config switched to not mention the new protocol
                //    at all when they save their config as the protocol is now opt-out. Any admins that want to
                //    disable it can do so and will have their preference recorded.
                // 3. We decide that the protocol needs to be retired. It gets switched back to opt-in. At this point
                //    the initial opt-in admins, assuming they visited an upgrade to a master with step 2, will
                //    have the protocol disabled for them. This is what we want. If they didn't upgrade to a master
                //    with step 2, well there is not much we can do to differentiate them from somebody who is upgrading
                //    from a previous step 3 master and had needed to keep the protocol turned on.
                //
                // What we should never do is flip-flop: opt-in -> opt-out -> opt-in -> opt-out as that will basically
                // clear any preference that an admin has set, but this should be ok as we only ever will be
                // adding new protocols and retiring old ones.
                if (p.isOptIn()) {
                    if (protocols.contains(name)) {
                        enabled.add(name);
                    }
                } else {
                    if (!protocols.contains(name)) {
                        disabled.add(name);
                    }
                }
            }
        }
        disabledAgentProtocols = disabled.isEmpty() ? null : new ArrayList<>(disabled);
        enabledAgentProtocols = enabled.isEmpty() ? null : new ArrayList<>(enabled);
        agentProtocols = null;
    }"
"static URI updateToSecureConnectionIfNeeded(URI uri, ServiceInstance ribbonServer) {
		String scheme = uri.getScheme();

		if (StringUtils.isEmpty(scheme)) {
			scheme = ""http"";
		}

		if (!StringUtils.isEmpty(uri.toString())
				&& unsecureSchemeMapping.containsKey(scheme) && ribbonServer.isSecure()) {
			return upgradeConnection(uri, unsecureSchemeMapping.get(scheme));
		}
		return uri;
	}"
"public static <T> Entity parse(T bean, boolean isToUnderlineCase, boolean ignoreNullValue) {
		return create(null).parseBean(bean, isToUnderlineCase, ignoreNullValue);
	}"
"protected Event newEvent(final String id, final Throwable error) {
        return newEvent(id, new LocalAttributeMap(CasWebflowConstants.TRANSITION_ID_ERROR, error));
    }"
"public static String decode(String value, Charset charset) {
    try {
      /* there is nothing special between uri and url decoding */
      return URLDecoder.decode(value, charset.name());
    } catch (UnsupportedEncodingException uee) {
      /* since the encoding is not supported, return the original value */
      return value;
    }
  }"
"private static String addLineFeedForNonASCII(String s) {
        if(!s.startsWith(""#!"")) {
            if (s.indexOf('\n')!=0) {
                return ""\n"" + s;
            }
        }

        return s;
    }"
"private boolean validateKeyTypeIsHashable(TypeInformation<?> type) {
		try {
			return (type instanceof PojoTypeInfo)
					? !type.getTypeClass().getMethod(""hashCode"").getDeclaringClass().equals(Object.class)
					: !(type instanceof PrimitiveArrayTypeInfo || type instanceof BasicArrayTypeInfo || type instanceof ObjectArrayTypeInfo);
		} catch (NoSuchMethodException ignored) {
			// this should never happen as we are just searching for the hashCode() method.
		}
		return false;
	}"
"private JPanel getPanelSession() {
		if (panelSession == null) {

			panelSession = new JPanel();
			panelSession.setLayout(new GridBagLayout());
			panelSession.setName(""ExcludeFromScope"");

			java.awt.GridBagConstraints gridBagConstraints2 = new GridBagConstraints();
	        java.awt.GridBagConstraints gridBagConstraints1 = new GridBagConstraints();

	        javax.swing.JLabel jLabel = new JLabel();

	        jLabel.setText(Constant.messages.getString(""context.label.exclude""));
	        gridBagConstraints1.gridx = 0;
	        gridBagConstraints1.gridy = 0;
	        gridBagConstraints1.gridheight = 1;
	        gridBagConstraints1.insets = new java.awt.Insets(10,0,5,0);
	        gridBagConstraints1.anchor = java.awt.GridBagConstraints.NORTHWEST;
	        gridBagConstraints1.fill = java.awt.GridBagConstraints.HORIZONTAL;
	        gridBagConstraints1.weightx = 0.0D;

	        gridBagConstraints2.gridx = 0;
	        gridBagConstraints2.gridy = 1;
	        gridBagConstraints2.weightx = 1.0;
	        gridBagConstraints2.weighty = 1.0;
	        gridBagConstraints2.fill = java.awt.GridBagConstraints.BOTH;
	        gridBagConstraints2.ipadx = 0;
	        gridBagConstraints2.insets = new java.awt.Insets(0,0,0,0);
	        gridBagConstraints2.anchor = java.awt.GridBagConstraints.NORTHWEST;
	        panelSession.add(jLabel, gridBagConstraints1);
	        panelSession.add(regexesPanel, gridBagConstraints2);
		}
		return panelSession;
	}"
"static void doRss(StaplerRequest req, StaplerResponse rsp, List<LogRecord> logs) throws IOException, ServletException {
        // filter log records based on the log level
        String level = req.getParameter(""level"");
        if(level!=null) {
            Level threshold = Level.parse(level);
            List<LogRecord> filtered = new ArrayList<>();
            for (LogRecord r : logs) {
                if(r.getLevel().intValue() >= threshold.intValue())
                    filtered.add(r);
            }
            logs = filtered;
        }

        RSS.forwardToRss(""Hudson log"","""", logs, new FeedAdapter<LogRecord>() {
            public String getEntryTitle(LogRecord entry) {
                return entry.getMessage();
            }

            public String getEntryUrl(LogRecord entry) {
                return ""log"";   // TODO: one URL for one log entry?
            }

            public String getEntryID(LogRecord entry) {
                return String.valueOf(entry.getSequenceNumber());
            }

            public String getEntryDescription(LogRecord entry) {
                return Functions.printLogRecord(entry);
            }

            public Calendar getEntryTimestamp(LogRecord entry) {
                GregorianCalendar cal = new GregorianCalendar();
                cal.setTimeInMillis(entry.getMillis());
                return cal;
            }

            public String getEntryAuthor(LogRecord entry) {
                return JenkinsLocationConfiguration.get().getAdminAddress();
            }
        },req,rsp);
    }"
"public static ValueMatcher makeValueMatcher(
      final ColumnSelectorFactory columnSelectorFactory,
      final String columnName,
      final DruidPredicateFactory predicateFactory
  )
  {
    final ColumnCapabilities capabilities = columnSelectorFactory.getColumnCapabilities(columnName);

    // This should be folded into the ValueMatcherColumnSelectorStrategy once that can handle LONG typed columns.
    if (capabilities != null && capabilities.getType() == ValueType.LONG) {
      return getLongPredicateMatcher(
          columnSelectorFactory.makeColumnValueSelector(columnName),
          predicateFactory.makeLongPredicate()
      );
    }

    final ColumnSelectorPlus<ValueMatcherColumnSelectorStrategy> selector =
        DimensionHandlerUtils.createColumnSelectorPlus(
            ValueMatcherColumnSelectorStrategyFactory.instance(),
            DefaultDimensionSpec.of(columnName),
            columnSelectorFactory
        );

    return selector.getColumnSelectorStrategy().makeValueMatcher(selector.getSelector(), predicateFactory);
  }"
"@Override
	public CompletableFuture<Void> onStop() {
		log.info(""Stopping TaskExecutor {}."", getAddress());

		Throwable throwable = null;

		if (resourceManagerConnection != null) {
			resourceManagerConnection.close();
		}

		for (JobManagerConnection jobManagerConnection : jobManagerConnections.values()) {
			try {
				disassociateFromJobManager(jobManagerConnection, new FlinkException(""The TaskExecutor is shutting down.""));
			} catch (Throwable t) {
				throwable = ExceptionUtils.firstOrSuppressed(t, throwable);
			}
		}

		jobManagerHeartbeatManager.stop();

		resourceManagerHeartbeatManager.stop();

		try {
			stopTaskExecutorServices();
		} catch (Exception e) {
			throwable = ExceptionUtils.firstOrSuppressed(e, throwable);
		}

		if (throwable != null) {
			return FutureUtils.completedExceptionally(new FlinkException(""Error while shutting the TaskExecutor down."", throwable));
		} else {
			log.info(""Stopped TaskExecutor {}."", getAddress());
			return CompletableFuture.completedFuture(null);
		}
	}"
"public void execute(@Param(""nodeId"") Long nodeId, @Param(""pageIndex"") int pageIndex,
                        @Param(""searchKey"") String searchKey, Context context, Navigator nav) throws Exception {
        Node node = nodeService.findById(nodeId);
        if (node.getStatus().isStart()) {
            nav.redirectTo(WebConstant.ERROR_FORBIDDEN_Link);
            return;
        }

        List<AutoKeeperCluster> zkClusters = autoKeeperClusterService.listAutoKeeperClusters();
        context.put(""zkClusters"", zkClusters);
        context.put(""node"", node);
        context.put(""pageIndex"", pageIndex);
        context.put(""searchKey"", searchKey);
    }"
"private boolean reconcileAndLogDifference(Applications delta, String reconcileHashCode) throws Throwable {
        logger.warn(""The Reconcile hashcodes do not match, client : {}, server : {}. Getting the full registry"",
                reconcileHashCode, delta.getAppsHashCode());

        long currentGeneration = fetchRegistryGeneration.get();

        Applications apps = this.fetchRemoteRegistry(false);
        if (apps == null) {
            logger.error(""The application is null for some reason. Not storing this information"");
            return false;
        }

        if (fetchRegistryGeneration.compareAndSet(currentGeneration, currentGeneration + 1)) {
            applications.set(apps);
            applicationsDelta.set(apps);
            logger.warn(""The Reconcile hashcodes after complete sync up, client : {}, server : {}."",
                    getApplications().getReconcileHashCode(),
                    delta.getAppsHashCode());
            return true;
        }else {
            logger.warn(""Not setting the applications map as another thread has advanced the update generation"");
            return true;  // still return true
        }
    }"
"private AstNumList parseNumList() {
    ArrayList<Double> bases = new ArrayList<>();
    ArrayList<Double> strides = new ArrayList<>();
    ArrayList<Long> counts = new ArrayList<>();

    while (skipWS() != ']') {
      double base = number();
      double count = 1;
      double stride = 1;
      if (skipWS() == ':') {
        eatChar(':');
        skipWS();
        count = number();
        if (count < 1 || ((long) count) != count)
          throw new IllegalASTException(""Count must be a positive integer, got "" + count);
      }
      if (skipWS() == ':') {
        eatChar(':');
        skipWS();
        stride = number();
        if (stride < 0 || Double.isNaN(stride))
          throw new IllegalASTException(""Stride must be positive, got "" + stride);
      }
      if (count == 1 && stride != 1)
        throw new IllegalASTException(""If count is 1, then stride must be one (and ignored)"");
      bases.add(base);
      counts.add((long) count);
      strides.add(stride);
      // Optional comma separating span
      if (skipWS() == ',') eatChar(',');
    }

    return new AstNumList(bases, strides, counts);
  }"
"public static long getIdleTimeMillis() {
    long latestEndTimeMillis = -1;

    // If there are any running rapids queries, consider that not idle.
    if (activeRapidsExecs.get() > 0) {
      updateNotIdle();
    }
    else {
      // If there are any running jobs, consider that not idle.
      // Remember the latest job ending time as well.
      Job[] jobs = Job.jobs();
      for (int i = jobs.length - 1; i >= 0; i--) {
        Job j = jobs[i];
        if (j.isRunning()) {
          updateNotIdle();
          break;
        }

        if (j.end_time() > latestEndTimeMillis) {
          latestEndTimeMillis = j.end_time();
        }
      }
    }

    long latestTimeMillis = Math.max(latestEndTimeMillis, lastTimeSomethingHappenedMillis);

    // Calculate milliseconds and clamp at zero.
    long now = System.currentTimeMillis();
    long deltaMillis = now - latestTimeMillis;
    if (deltaMillis < 0) {
      deltaMillis = 0;
    }
    return deltaMillis;
  }"
"protected boolean shouldSkipInterruptForRegisteredService(final RegisteredService registeredService) {
        if (registeredService != null) {
            LOGGER.debug(""Checking interrupt rules for service [{}]"", registeredService.getName());
            if (RegisteredServiceProperties.SKIP_INTERRUPT_NOTIFICATIONS.isAssignedTo(registeredService)) {
                LOGGER.debug(""Service [{}] is set to skip interrupt notifications"", registeredService.getName());
                return true;
            }
            LOGGER.debug(""Service [{}] is set to not skip interrupt notifications"", registeredService.getName());
        } else {
            LOGGER.debug(""No service was found in the request context. Proceeding as usual..."");
        }
        return false;
    }"
"public void write_compressed(final OtpErlangObject o, final int level) {
        @SuppressWarnings(""resource"")
        final OtpOutputStream oos = new OtpOutputStream(o);
        /*
         * similar to erts_term_to_binary() in external.c: We don't want to
         * compress if compression actually increases the size. Since
         * compression uses 5 extra bytes (COMPRESSED tag + size), don't
         * compress if the original term is smaller.
         */
        if (oos.size() < 5) {
            // fast path for small terms
            try {
                oos.writeToAndFlush(this);
                // if the term is written as a compressed term, the output
                // stream is closed, so we do this here, too
                close();
            } catch (final IOException e) {
                throw new java.lang.IllegalArgumentException(
                        ""Intermediate stream failed for Erlang object "" + o);
            }
        } else {
            final int startCount = super.count;
            // we need destCount bytes for an uncompressed term
            // -> if compression uses more, use the uncompressed term!
            final int destCount = startCount + oos.size();
            fixedSize = destCount;
            final Deflater def = new Deflater(level);
            final java.util.zip.DeflaterOutputStream dos = new java.util.zip.DeflaterOutputStream(
                    this, def);
            try {
                write1(OtpExternal.compressedTag);
                write4BE(oos.size());
                oos.writeTo(dos);
                dos.close(); // note: closes this, too!
            } catch (final IllegalArgumentException e) {
                /*
                 * Discard further un-compressed data (if not called, there may
                 * be memory leaks).
                 *
                 * After calling java.util.zip.Deflater.end(), the deflater
                 * should not be used anymore, not even the close() method of
                 * dos. Calling dos.close() before def.end() is prevented since
                 * an unfinished DeflaterOutputStream will try to deflate its
                 * unprocessed data to the (fixed) byte array which is prevented
                 * by ensureCapacity() and would also unnecessarily process
                 * further data that is discarded anyway.
                 *
                 * Since we are re-using the byte array of this object below, we
                 * must not call close() in e.g. a finally block either (with or
                 * without a call to def.end()).
                 */
                def.end();
                // could not make the value smaller than originally
                // -> reset to starting count, write uncompressed
                super.count = startCount;
                try {
                    oos.writeTo(this);
                    // if the term is written as a compressed term, the output
                    // stream is closed, so we do this here, too
                    close();
                } catch (final IOException e2) {
                    throw new java.lang.IllegalArgumentException(
                            ""Intermediate stream failed for Erlang object "" + o);
                }
            } catch (final IOException e) {
                throw new java.lang.IllegalArgumentException(
                        ""Intermediate stream failed for Erlang object "" + o);
            } finally {
                fixedSize = Integer.MAX_VALUE;
            }
        }
    }"
"@Override
  public synchronized void handleEvent(final Event event) {
    if (event.getType() == EventType.JOB_FINISHED && Status.FAILED
        .equals(event.getData().getStatus())) {
      this.value = this.value + 1;
    }
  }"
"public void addParentNode(final String childNodeName, final String parentNodeName) {
    checkIsBuilt();

    final Node child = this.nameToNodeMap.get(childNodeName);
    if (child == null) {
      throw new DagException(String.format(""Unknown child node (%s). Did you create the node?"",
          childNodeName));
    }

    final Node parent = this.nameToNodeMap.get(parentNodeName);
    if (parent == null) {
      throw new DagException(
          String.format(""Unknown parent node (%s). Did you create the node?"", parentNodeName));
    }

    child.addParent(parent);
  }"
"private void handleScriptException(ScriptWrapper script, Writer writer, Exception exception) {
		Exception cause = exception;
		if (cause instanceof ScriptException && cause.getCause() instanceof Exception) {
			// Dereference one level
			cause = (Exception) cause.getCause();
		}
		try {
			writer.append(cause.toString());
		} catch (IOException ignore) {
			logger.error(cause.getMessage(), cause);
		}
		this.setError(script, cause);
		this.setEnabled(script, false);
	}"
"public static Sheet getOrCreateSheet(Workbook book, String sheetName) {
		if (null == book) {
			return null;
		}
		sheetName = StrUtil.isBlank(sheetName) ? ""sheet1"" : sheetName;
		Sheet sheet = book.getSheet(sheetName);
		if (null == sheet) {
			sheet = book.createSheet(sheetName);
		}
		return sheet;
	}"
"@Override
  public void encodeUtf8(CharSequence in, ByteBuffer out) {
    if (out.hasArray()) {
      int start = out.arrayOffset();
      int end = encodeUtf8Array(in, out.array(), start + out.position(),
          out.remaining());
      out.position(end - start);
    } else {
      encodeUtf8Buffer(in, out);
    }
  }"
"public static Optional<Class> resolveSuperGenericTypeArgument(Class type) {
        try {
            Type genericSuperclass = type.getGenericSuperclass();
            if (genericSuperclass instanceof ParameterizedType) {
                return resolveSingleTypeArgument(genericSuperclass);
            }
            return Optional.empty();
        } catch (NoClassDefFoundError e) {
            return Optional.empty();
        }
    }"
"public static String getMetricsTableName(String schema, String table)
    {
        return schema.equals(""default"") ? table + ""_idx_metrics""
                : schema + '.' + table + ""_idx_metrics"";
    }"
"@Override
    protected void readResponse(HttpState state, HttpConnection conn)
    throws IOException, HttpException {
        LOG.trace(""enter HttpMethodBase.readResponse(HttpState, HttpConnection)"");
        
        boolean isUpgrade = false;
        
		while (getStatusLine() == null) {
            readStatusLine(state, conn);
            processStatusLine(state, conn);
            readResponseHeaders(state, conn);
            processResponseHeaders(state, conn);
            
            int status = this.statusLine.getStatusCode();
            if (status == 101) {
            	LOG.debug(""Retrieved HTTP status code '101 Switching Protocols'. Keep connection open!"");

            	// This means the requester has asked the server to switch protocols
            	// and the server is acknowledging that it will do so
            	// e.g.: upgrade to websocket
            	
				if (conn instanceof ZapHttpConnection) {
	            	isUpgrade = true;
	            	// avoid connection release of HttpClient library 
	            	conn.setHttpConnectionManager(null);
	            }
            } else if ((status >= 100) && (status < 200)) {
                if (LOG.isInfoEnabled()) {
                    LOG.info(""Discarding unexpected response: "" + this.statusLine.toString()); 
                }
                this.statusLine = null;
            }
        }

    	// get socket and input stream out of HttpClient
		if (conn instanceof ZapHttpConnection) {
			ZapHttpConnection zapConn = (ZapHttpConnection) conn;
	    	upgradedSocket = zapConn.getSocket();
			inputStream = zapConn.getResponseInputStream();
		}
		
		if (!isUpgrade) {
			// read & process rest of response
			// only if connection should not be kept
	        readResponseBody(state, conn);        
	        processResponseBody(state, conn);
		}
    }"
"private Supplier<DruidLongPredicate> getLongPredicateSupplier()
  {
    return new Supplier<DruidLongPredicate>()
    {
      private final Object initLock = new Object();
      private DruidLongPredicate predicate;


      private void initLongValues()
      {
        if (predicate != null) {
          return;
        }

        synchronized (initLock) {
          if (predicate != null) {
            return;
          }

          LongArrayList longs = new LongArrayList(values.size());
          for (String value : values) {
            final Long longValue = DimensionHandlerUtils.getExactLongFromDecimalString(value);
            if (longValue != null) {
              longs.add(longValue);
            }
          }

          if (longs.size() > NUMERIC_HASHING_THRESHOLD) {
            final LongOpenHashSet longHashSet = new LongOpenHashSet(longs);

            predicate = input -> longHashSet.contains(input);
          } else {
            final long[] longArray = longs.toLongArray();
            Arrays.sort(longArray);

            predicate = input -> Arrays.binarySearch(longArray, input) >= 0;
          }
        }
      }

      @Override
      public DruidLongPredicate get()
      {
        initLongValues();
        return predicate;
      }
    };
  }"
"public List<Pair<Integer, Integer>> commonPrefixSearch(byte[] key,
                                                           int offset,
                                                           int maxResults)
    {
        ArrayList<Pair<Integer, Integer>> result = new ArrayList<Pair<Integer, Integer>>();
        int unit = _array[0];
        int nodePos = 0;
        // nodePos ^= unit.offset();
        nodePos ^= ((unit >>> 10) << ((unit & (1 << 9)) >>> 6));
        for (int i = offset; i < key.length; ++i)
        {
            byte b = key[i];
            nodePos ^= (b & 0xff);
            unit = _array[nodePos];
            // if (unit.label() != b) {
            if ((unit & ((1 << 31) | 0xFF)) != (b & 0xff))
            {
                return result;
            }

            // nodePos ^= unit.offset();
            nodePos ^= ((unit >>> 10) << ((unit & (1 << 9)) >>> 6));

            // if (unit.has_leaf()) {
            if (((unit >>> 8) & 1) == 1)
            {
                if (result.size() < maxResults)
                {
                    // result.add(new Pair<i, _array[nodePos].value());
                    result.add(new Pair<Integer, Integer>(i + 1, _array[nodePos] & ((1 << 31) - 1)));
                }
            }
        }
        return result;
    }"
"private static String cleanODataPath(String path, HandleParametersOption handleParameters) {
		String cleanedPath = path;
		
		if (HandleParametersOption.USE_ALL.equals(handleParameters) ) {
			cleanedPath = path;
		} else {

			// check for single ID (unnamed)
			Matcher matcher = patternResourceIdentifierUnquoted.matcher(path);
			if (matcher.find()) {
				String resourceName =  matcher.group(1); 
				String resourceID   =  matcher.group(2);
			
				String subString = resourceName + ""("" + resourceID + "")"";
				int begin = path.indexOf(subString);
				int end   = begin + subString.length();
				
				String beforeSubstring = path.substring(0,begin);
				String afterSubstring  = path.substring(end);
				
	
				if (HandleParametersOption.IGNORE_COMPLETELY.equals(handleParameters) ||
				    HandleParametersOption.IGNORE_VALUE.equals(handleParameters)	     ) {
					
					StringBuilder sb = new StringBuilder(beforeSubstring);
					sb.append(resourceName).append(""()"").append(afterSubstring);
					cleanedPath = sb.toString();
				} 
							
			} else {
				
				matcher = patternResourceMultipleIdentifier.matcher(path);
				if (matcher.find()) {
					// We've found a composite identifier. i.e: /Resource(field1=a,field2=3)
					
					String multipleIdentifierSection =   matcher.group(1); 
					
					int begin = path.indexOf(multipleIdentifierSection);
					int end   = begin + multipleIdentifierSection.length();
	
					String beforeSubstring = path.substring(0,begin);
					String afterSubstring  = path.substring(end);

					if (HandleParametersOption.IGNORE_COMPLETELY.equals(handleParameters) ) {
							cleanedPath = beforeSubstring + afterSubstring;
					} else {
						StringBuilder sb = new StringBuilder(beforeSubstring);
						
						matcher = patternResourceMultipleIdentifierDetail.matcher(multipleIdentifierSection);
						int i = 1;
						while (matcher.find()) {
							
							if (i >  1) {
								sb.append(',');
							}
							String paramName       = matcher.group(1);
							sb.append(paramName);
							i++;
						}
					
						sb.append(afterSubstring);
						cleanedPath = sb.toString();
					}
							
				} 
			}		
		}
		
		return cleanedPath;
	}"
"public boolean isValidSubset(FieldSet set) {
		if (set.size() > size()) {
			return false;
		}
		for (Integer i : set) {
			if (!contains(i)) {
				return false;
			}
		}
		return true;
	}"
"public static String convertUnderscoreNameToClassName(String name) {
        StringBuffer result = new StringBuffer();
        boolean nextIsUpper = false;

        if (name != null) {
            int len = name.length();

            if (len > 0) {
                String s = String.valueOf(name.charAt(0));

                result.append(s.toUpperCase());

                for (int i = 1; i < len; i++) {
                    s = String.valueOf(name.charAt(i));

                    if (""_"".equals(s)) {
                        nextIsUpper = true;
                    } else {
                        if (nextIsUpper) {
                            result.append(s.toUpperCase());
                            nextIsUpper = false;
                        } else {
                            result.append(s.toLowerCase());
                        }
                    }
                }
            }
        }

        return result.toString();
    }"
"static boolean isO2JCached(String key, String protocol, String value) {
        Map<String, String> p2j = o2j.get(key);
        if (p2j == null) {
            return false;
        } else {
            return value.equals(p2j.get(protocol));
        }
    }"
"public static Builder forCondition(String condition, Object... details) {
		return new ConditionMessage().andCondition(condition, details);
	}"
"protected <T> TypedResult<T> handleMissingResult() {
		// check if the monitoring thread is still there
		// we need to wait until we know what is going on
		if (monitoringThread.isAlive()) {
			return TypedResult.empty();
		}
		// the job finished with an exception
		else if (executionException != null) {
			throw executionException;
		}
		// we assume that a bounded job finished
		else {
			return TypedResult.endOfStream();
		}
	}"
"public static void parseJsonToSingleRowBlock(
            JsonParser parser,
            SingleRowBlockWriter singleRowBlockWriter,
            BlockBuilderAppender[] fieldAppenders,
            Optional<Map<String, Integer>> fieldNameToIndex)
            throws IOException
    {
        if (parser.getCurrentToken() == START_ARRAY) {
            for (int i = 0; i < fieldAppenders.length; i++) {
                parser.nextToken();
                fieldAppenders[i].append(parser, singleRowBlockWriter);
            }
            if (parser.nextToken() != JsonToken.END_ARRAY) {
                throw new JsonCastException(format(""Expected json array ending, but got %s"", parser.getText()));
            }
        }
        else {
            verify(parser.getCurrentToken() == START_OBJECT);
            if (!fieldNameToIndex.isPresent()) {
                throw new JsonCastException(""Cannot cast a JSON object to anonymous row type. Input must be a JSON array."");
            }
            boolean[] fieldWritten = new boolean[fieldAppenders.length];
            int numFieldsWritten = 0;

            while (parser.nextToken() != JsonToken.END_OBJECT) {
                if (parser.currentToken() != FIELD_NAME) {
                    throw new JsonCastException(format(""Expected a json field name, but got %s"", parser.getText()));
                }
                String fieldName = parser.getText().toLowerCase(Locale.ENGLISH);
                Integer fieldIndex = fieldNameToIndex.get().get(fieldName);
                parser.nextToken();
                if (fieldIndex != null) {
                    if (fieldWritten[fieldIndex]) {
                        throw new JsonCastException(""Duplicate field: "" + fieldName);
                    }
                    fieldWritten[fieldIndex] = true;
                    numFieldsWritten++;
                    fieldAppenders[fieldIndex].append(parser, singleRowBlockWriter.getFieldBlockBuilder(fieldIndex));
                }
                else {
                    parser.skipChildren();
                }
            }

            if (numFieldsWritten != fieldAppenders.length) {
                for (int i = 0; i < fieldWritten.length; i++) {
                    if (!fieldWritten[i]) {
                        singleRowBlockWriter.getFieldBlockBuilder(i).appendNull();
                    }
                }
            }
        }
    }"
"public static void write(HttpServletResponse response, InputStream in) {
		write(response, in, IoUtil.DEFAULT_BUFFER_SIZE);
	}"
"public void startScanNode(SiteNode node) {
		Target target = new Target(node);
		target.setRecurse(true);
		this.startScan(target, null, null);
	}"
"public URLNormalizer removeTrailingQuestionMark() {
        if (url.endsWith(""?"") && StringUtils.countMatches(url, ""?"") == 1) {
            url = StringUtils.removeEnd(url, ""?"");
        }
        return this;
    }"
"public INDArray outputFromFeaturized(INDArray input) {
        if (isGraph) {
            if (unFrozenSubsetGraph.getNumOutputArrays() > 1) {
                throw new IllegalArgumentException(
                                ""Graph has more than one output. Expecting an input array with outputFromFeaturized method call"");
            }
            return unFrozenSubsetGraph.output(input)[0];
        } else {
            return unFrozenSubsetMLN.output(input);
        }
    }"
"public boolean updateState(TaskExecutionState state) {
		assertRunningInJobMasterMainThread();
		final Execution attempt = currentExecutions.get(state.getID());

		if (attempt != null) {
			try {
				Map<String, Accumulator<?, ?>> accumulators;

				switch (state.getExecutionState()) {
					case RUNNING:
						return attempt.switchToRunning();

					case FINISHED:
						// this deserialization is exception-free
						accumulators = deserializeAccumulators(state);
						attempt.markFinished(accumulators, state.getIOMetrics());
						return true;

					case CANCELED:
						// this deserialization is exception-free
						accumulators = deserializeAccumulators(state);
						attempt.completeCancelling(accumulators, state.getIOMetrics());
						return true;

					case FAILED:
						// this deserialization is exception-free
						accumulators = deserializeAccumulators(state);
						attempt.markFailed(state.getError(userClassLoader), accumulators, state.getIOMetrics());
						return true;

					default:
						// we mark as failed and return false, which triggers the TaskManager
						// to remove the task
						attempt.fail(new Exception(""TaskManager sent illegal state update: "" + state.getExecutionState()));
						return false;
				}
			}
			catch (Throwable t) {
				ExceptionUtils.rethrowIfFatalErrorOrOOM(t);

				// failures during updates leave the ExecutionGraph inconsistent
				failGlobal(t);
				return false;
			}
		}
		else {
			return false;
		}
	}"
"public static Pair<INDArray, INDArray> convertWritablesSequence(List<List<List<Writable>>> list,
                                                                    RecordDetails details) {


        INDArray arr;

        if (list.get(0).size() == 0) {
            throw new ZeroLengthSequenceException(""Zero length sequence encountered"");
        }

        List<Writable> firstStep = list.get(0).get(0);

        int size = 0;
        //Need to account for NDArrayWritables etc in list:
        for (Writable w : firstStep) {
            if (w instanceof NDArrayWritable) {
                size += ((NDArrayWritable) w).get().size(1);
            } else {
                size++;
            }
        }


        arr = Nd4j.create(new int[] {details.getMinValues(), size, details.getMaxTSLength()}, 'f');

        boolean needMaskArray = false;
        for (List<List<Writable>> c : list) {
            if (c.size() < details.getMaxTSLength()) {
                needMaskArray = true;
                break;
            }
        }


        INDArray maskArray;
        if (needMaskArray) {
            maskArray = Nd4j.ones(details.getMinValues(), details.getMaxTSLength());
        } else {
            maskArray = null;
        }



        for (int i = 0; i < details.getMinValues(); i++) {
            List<List<Writable>> sequence = list.get(i);
            int t = 0;
            int k;
            for (List<Writable> timeStep : sequence) {
                k =  t++;

                //Convert entire reader contents, without modification
                Iterator<Writable> iter = timeStep.iterator();
                int j = 0;
                while (iter.hasNext()) {
                    Writable w = iter.next();

                    if (w instanceof NDArrayWritable) {
                        INDArray row = ((NDArrayWritable) w).get();

                        arr.put(new INDArrayIndex[] {NDArrayIndex.point(i),
                                NDArrayIndex.interval(j, j + row.length()), NDArrayIndex.point(k)}, row);
                        j += row.length();
                    } else {
                        arr.putScalar(i, j, k, w.toDouble());
                        j++;
                    }
                }



            }

            //For any remaining time steps: set mask array to 0 (just padding)
            if (needMaskArray) {
                //Masking array entries at end (for align start)
                int lastStep =  sequence.size();
                for (int t2 = lastStep; t2 < details.getMaxTSLength(); t2++) {
                    maskArray.putScalar(i, t2, 0.0);
                }

            }
        }

        return new Pair<>(arr, maskArray);
    }"
"public SDVariable logNormal(String name, double mean, double stddev, long... shape) {
        SDVariable ret = f().randomLogNormal(mean, stddev, shape);
        return updateVariableNameAndReference(ret, name);
    }"
"public static boolean isAbsolutePath(String path) {
		if (StrUtil.isEmpty(path)) {
			return false;
		}

		if (StrUtil.C_SLASH == path.charAt(0) || path.matches(""^[a-zA-Z]:[/\\\\].*"")) {
			// 给定的路径已经是绝对路径了
			return true;
		}
		return false;
	}"
"public void handleHttp2Request(int streamId, SofaRequest request, ChannelHandlerContext ctx,
                                   Http2ConnectionEncoder encoder) {
        Http2ServerTask task = new Http2ServerTask(this, request, ctx, streamId, encoder);

        processingCount.incrementAndGet();
        try {
            task.run();
        } catch (RejectedExecutionException e) {
            processingCount.decrementAndGet();
            throw e;
        }
    }"
"private Frame closeFrame(Key key, String[] names, String[][] domains, Futures fs) {
    if( _output_types == null ) return null;
    final int noutputs = _output_types.length;
    Vec[] vecs = new Vec[noutputs];
    if( _appendables==null || _appendables.length == 0)  // Zero rows?
      for( int i = 0; i < noutputs; i++ )
        vecs[i] = _fr.anyVec().makeZero();
    else {
      int rowLayout = _appendables[0].compute_rowLayout();
      for( int i = 0; i < noutputs; i++ ) {
        _appendables[i].setDomain(domains==null ? null : domains[i]);
        vecs[i] = _appendables[i].close(rowLayout,fs);
      }
    }
    return new Frame(key,names,vecs);
  }"
"public static StageScheduler newSourcePartitionedSchedulerAsStageScheduler(
            SqlStageExecution stage,
            PlanNodeId partitionedNode,
            SplitSource splitSource,
            SplitPlacementPolicy splitPlacementPolicy,
            int splitBatchSize)
    {
        SourcePartitionedScheduler sourcePartitionedScheduler = new SourcePartitionedScheduler(stage, partitionedNode, splitSource, splitPlacementPolicy, splitBatchSize, false);
        sourcePartitionedScheduler.startLifespan(Lifespan.taskWide(), NOT_PARTITIONED);

        return new StageScheduler() {
            @Override
            public ScheduleResult schedule()
            {
                ScheduleResult scheduleResult = sourcePartitionedScheduler.schedule();
                sourcePartitionedScheduler.drainCompletelyScheduledLifespans();
                return scheduleResult;
            }

            @Override
            public void close()
            {
                sourcePartitionedScheduler.close();
            }
        };
    }"
"protected String getUserAuthorizationRedirectURL(ProtectedResourceDetails details, OAuthConsumerToken requestToken, String callbackURL) {
		try {
			String baseURL = details.getUserAuthorizationURL();
			StringBuilder builder = new StringBuilder(baseURL);
			char appendChar = baseURL.indexOf('?') < 0 ? '?' : '&';
			builder.append(appendChar).append(""oauth_token="");
			builder.append(URLEncoder.encode(requestToken.getValue(), ""UTF-8""));
			if (!details.isUse10a()) {
				builder.append('&').append(""oauth_callback="");
				builder.append(URLEncoder.encode(callbackURL, ""UTF-8""));
			}
			return builder.toString();
		}
		catch (UnsupportedEncodingException e) {
			throw new IllegalStateException(e);
		}
	}"
"@Deprecated
	public SplitStream<T> split(OutputSelector<T> outputSelector) {
		return new SplitStream<>(this, clean(outputSelector));
	}"
"public static StreamShardHandle convertToStreamShardHandle(StreamShardMetadata streamShardMetadata) {
		Shard shard = new Shard();
		shard.withShardId(streamShardMetadata.getShardId());
		shard.withParentShardId(streamShardMetadata.getParentShardId());
		shard.withAdjacentParentShardId(streamShardMetadata.getAdjacentParentShardId());

		HashKeyRange hashKeyRange = new HashKeyRange();
		hashKeyRange.withStartingHashKey(streamShardMetadata.getStartingHashKey());
		hashKeyRange.withEndingHashKey(streamShardMetadata.getEndingHashKey());
		shard.withHashKeyRange(hashKeyRange);

		SequenceNumberRange sequenceNumberRange = new SequenceNumberRange();
		sequenceNumberRange.withStartingSequenceNumber(streamShardMetadata.getStartingSequenceNumber());
		sequenceNumberRange.withEndingSequenceNumber(streamShardMetadata.getEndingSequenceNumber());
		shard.withSequenceNumberRange(sequenceNumberRange);

		return new StreamShardHandle(streamShardMetadata.getStreamName(), shard);
	}"
"@SuppressWarnings(""unchecked"")
	public static <T> boolean containsAny(T[] array, T... values) {
		for (T value : values) {
			if(contains(array, value)) {
				return true;
			}
		}
		return false;
	}"
"private JPanel getJTabbed() {
		if (jPanel == null) {
			/*
			jPanel = new JPanel();
			jPanel.setPreferredSize(new java.awt.Dimension(800,600));

			jPanel.setLayout(new GridBagLayout());
			*/

			// jPanel is the outside one
			jPanel = new JPanel();
			jPanel.setPreferredSize(new java.awt.Dimension(800,600));
			jPanel.setLayout(new GridBagLayout());

			jTabbed = new JTabbedPane();
			jTabbed.setPreferredSize(new java.awt.Dimension(800,500));

			final JPanel jPanel1 = new JPanel();
			jPanel1.setLayout(new GridBagLayout());

			final JPanel jPanel2 = new JPanel();
			//jPanel2.setPreferredSize(new java.awt.Dimension(800,500));
			jPanel2.setLayout(new GridBagLayout());

			final JPanel jPanel3 = new JPanel();

			//jPanel3.setPreferredSize(new java.awt.Dimension(800,500));
			jPanel3.setLayout(new GridBagLayout());

			final JPanel jPanel4 = new JPanel();
			jPanel4.setLayout(new GridBagLayout());

			final JPanel jPanel5 = new JPanel();
			jPanel5.setLayout(new GridBagLayout());

			// 3 tabs - Encode, Decode, Hash??
			addField(jPanel1, 1, getBase64EncodeField(), Constant.messages.getString(""enc2.label.b64Enc""));
			addField(jPanel1, 2, getUrlEncodeField(), Constant.messages.getString(""enc2.label.urlEnc""));
			addField(jPanel1, 3, getAsciiHexEncodeField(), Constant.messages.getString(""enc2.label.asciiEnc""));
			addField(jPanel1, 4, getHTMLEncodeField(), Constant.messages.getString(""enc2.label.HTMLEnc""));
			addField(jPanel1, 5, getJavaScriptEncodeField(), Constant.messages.getString(""enc2.label.JavaScriptEnc""));

			addField(jPanel2, 1, getBase64DecodeField(), Constant.messages.getString(""enc2.label.b64Dec""));
			addField(jPanel2, 2, getUrlDecodeField(), Constant.messages.getString(""enc2.label.urlDec""));
			addField(jPanel2, 3, getAsciiHexDecodeField(), Constant.messages.getString(""enc2.label.asciiDec""));
			addField(jPanel2, 4, getHTMLDecodeField(), Constant.messages.getString(""enc2.label.HTMLDec""));
			addField(jPanel2, 5, getJavaScriptDecodeField(), Constant.messages.getString(""enc2.label.JavaScriptDec""));
			
			
			addField(jPanel3, 1, getSha1HashField(), Constant.messages.getString(""enc2.label.sha1Hash""));
			addField(jPanel3, 2, getMd5HashField(), Constant.messages.getString(""enc2.label.md5Hash""));

			addField(jPanel4, 1, getIllegalUTF82ByteField(), Constant.messages.getString(""enc2.label.illegalUTF8.2byte""));
			addField(jPanel4, 2, getIllegalUTF83ByteField(), Constant.messages.getString(""enc2.label.illegalUTF8.3byte""));
			addField(jPanel4, 3, getIllegalUTF84ByteField(), Constant.messages.getString(""enc2.label.illegalUTF8.4byte""));

            addField(jPanel5, 1, getEscapedTextField(), Constant.messages.getString(""enc2.label.unicode.escapedText""));
            addField(jPanel5, 2, getUnescapedTextField(), Constant.messages.getString(""enc2.label.unicode.unescapedText""));



			jTabbed.addTab(Constant.messages.getString(""enc2.tab.encode""), jPanel1);
			jTabbed.addTab(Constant.messages.getString(""enc2.tab.decode""), jPanel2);
			jTabbed.addTab(Constant.messages.getString(""enc2.tab.hash""), jPanel3);
			jTabbed.addTab(Constant.messages.getString(""enc2.tab.illegalUTF8""), jPanel4);
            jTabbed.addTab(Constant.messages.getString(""enc2.tab.unicode""), jPanel5);


			final java.awt.GridBagConstraints gbc1 = new GridBagConstraints();
			gbc1.gridx = 0;
			gbc1.gridy = 1;
			gbc1.insets = new java.awt.Insets(1,1,1,1);
			gbc1.anchor = java.awt.GridBagConstraints.NORTHWEST;
			gbc1.fill = java.awt.GridBagConstraints.BOTH;
			gbc1.weightx = 1.0D;
			gbc1.weighty = 0.25D;

			final java.awt.GridBagConstraints gbc2 = new GridBagConstraints();
			gbc2.gridx = 0;
			gbc2.gridy = 2;
			gbc2.insets = new java.awt.Insets(1,1,1,1);
			gbc2.anchor = java.awt.GridBagConstraints.NORTHWEST;
			gbc2.fill = java.awt.GridBagConstraints.BOTH;
			gbc2.weightx = 1.0D;
			gbc2.weighty = 1.0D;

			final JScrollPane jsp = new JScrollPane();
			jsp.setViewportView(getInputField());
			jsp.setHorizontalScrollBarPolicy(ScrollPaneConstants.HORIZONTAL_SCROLLBAR_NEVER);
			jsp.setBorder(
					BorderFactory.createTitledBorder(
							null, Constant.messages.getString(""enc2.label.text""),
							TitledBorder.DEFAULT_JUSTIFICATION,
							javax.swing.border.TitledBorder.DEFAULT_POSITION,
							FontUtils.getFont(FontUtils.Size.standard),
							java.awt.Color.black));

			//addField(jPanel, 1, getInputField(), ""Text to be encoded/decoded/hashed"");
			//addField(jPanel, 2, jTabbed, ""Text to be encoded/decoded/hashed"");

			jPanel.add(jsp, gbc1);
			jPanel.add(jTabbed, gbc2);

			jPanel2.requestFocus();

		}
		return jPanel;
	}"
"private static Map<String, Pair<String, String>> autoGenerateMapping(List<ColumnMetadata> columns, Optional<Map<String, Set<String>>> groups)
    {
        Map<String, Pair<String, String>> mapping = new HashMap<>();
        for (ColumnMetadata column : columns) {
            Optional<String> family = getColumnLocalityGroup(column.getName(), groups);
            mapping.put(column.getName(), Pair.of(family.orElse(column.getName()), column.getName()));
        }
        return mapping;
    }"
"protected ByteBuffer __vector_as_bytebuffer(int vector_offset, int elem_size) {
    int o = __offset(vector_offset);
    if (o == 0) return null;
    ByteBuffer bb = this.bb.duplicate().order(ByteOrder.LITTLE_ENDIAN);
    int vectorstart = __vector(o);
    bb.position(vectorstart);
    bb.limit(vectorstart + __vector_len(o) * elem_size);
    return bb;
  }"
"protected Set<Event> resolveMultifactorAuthenticationProvider(final Optional<RequestContext> context,
                                                                  final RegisteredService service,
                                                                  final Principal principal) {
        val globalPrincipalAttributeValueRegex = casProperties.getAuthn().getMfa().getGlobalPrincipalAttributeValueRegex();
        val providerMap = MultifactorAuthenticationUtils.getAvailableMultifactorAuthenticationProviders(ApplicationContextProvider.getApplicationContext());
        val providers = providerMap.values();
        if (providers.size() == 1 && StringUtils.isNotBlank(globalPrincipalAttributeValueRegex)) {
            return resolveSingleMultifactorProvider(context, service, principal, providers);
        }

        return resolveMultifactorProviderViaPredicate(context, service, principal, providers);
    }"
"protected InputStream getDefaultDiagram(String diagramImageFileName) {
        String imageFileName = diagramImageFileName != null ?
                diagramImageFileName :
                getDefaultDiagramImageFileName();
        InputStream imageStream = getClass().getResourceAsStream(imageFileName);
        if (imageStream == null) {
            throw new ActivitiImageException(""Error occurred while getting default diagram image from file: "" + imageFileName);
        }
        return imageStream;
    }"
"public static HttpHandler getNext(HttpServerExchange httpServerExchange, HttpHandler next) throws Exception {
		if (next != null) {
			return next;
		}
		return getNext(httpServerExchange);
	}"
"public Docket tags(Tag first, Tag... remaining) {
    tags.add(first);
    tags.addAll(Arrays.stream(remaining).collect(toSet()));
    return this;
  }"
"public static void scale(ImageInputStream srcStream, ImageOutputStream destStream, int width, int height, Color fixedColor) throws IORuntimeException {
		scale(read(srcStream), destStream, width, height, fixedColor);
	}"
"public void unschedule(final Project project) throws SchedulerException {
    for (final Flow flow : project.getFlows()) {
      if (!flow.isEmbeddedFlow()) {
        try {
          if (this.scheduler
              .unscheduleJob(FlowTriggerQuartzJob.JOB_NAME, generateGroupName(flow))) {
            logger.info(""Flow {}.{} unregistered from scheduler"", project.getName(), flow.getId());
          }
        } catch (final SchedulerException e) {
          logger.error(""Fail to unregister flow from scheduler {}.{}"", project.getName(),
              flow.getId(), e);
          throw e;
        }
      }
    }
  }"
"protected Object interceptSync(MethodInvocationContext context, ReturnType returnTypeObject, Class returnType) {
        final ValueWrapper wrapper = new ValueWrapper();
        CacheOperation cacheOperation = new CacheOperation(context, returnType);

        AnnotationValue<Cacheable> cacheConfig = cacheOperation.cacheable;
        if (cacheConfig != null) {
            CacheKeyGenerator defaultKeyGenerator = cacheOperation.defaultKeyGenerator;
            CacheKeyGenerator keyGenerator = resolveKeyGenerator(defaultKeyGenerator, cacheConfig);
            Object[] parameterValues = resolveParams(context, cacheConfig.get(MEMBER_PARAMETERS, String[].class, StringUtils.EMPTY_STRING_ARRAY));
            Object key = keyGenerator.generateKey(context, parameterValues);
            Argument returnArgument = returnTypeObject.asArgument();
            if (cacheConfig.getRequiredValue(MEMBER_ATOMIC, Boolean.class)) {
                SyncCache syncCache = cacheManager.getCache(cacheOperation.cacheableCacheName);

                try {
                    wrapper.value = syncCache.get(key, returnArgument, () -> {
                        try {
                            doProceed(context, wrapper);
                            return wrapper.value;
                        } catch (RuntimeException e) {
                            throw new ValueSupplierException(key, e);
                        }
                    });
                } catch (ValueSupplierException e) {
                    throw e.getCause();
                } catch (RuntimeException e) {
                    errorHandler.handleLoadError(syncCache, key, e);
                    throw e;
                }
            } else {
                String[] cacheNames = resolveCacheNames(cacheOperation.defaultConfig, cacheConfig);
                boolean cacheHit = false;
                for (String cacheName : cacheNames) {
                    SyncCache syncCache = cacheManager.getCache(cacheName);
                    try {
                        Optional optional = syncCache.get(key, returnArgument);
                        if (optional.isPresent()) {
                            if (LOG.isDebugEnabled()) {
                                LOG.debug(""Value found in cache ["" + cacheName + ""] for invocation: "" + context);
                            }
                            cacheHit = true;
                            wrapper.value = optional.get();
                            break;
                        }
                    } catch (RuntimeException e) {
                        if (errorHandler.handleLoadError(syncCache, key, e)) {
                            throw e;
                        }
                    }
                }
                if (!cacheHit) {
                    if (LOG.isDebugEnabled()) {
                        LOG.debug(""Value not found in cache for invocation: "" + context);
                    }
                    doProceed(context, wrapper);
                    syncPut(cacheNames, key, wrapper.value);
                }
            }
        } else {
            if (!cacheOperation.hasWriteOperations()) {
                return context.proceed();
            } else {
                doProceed(context, wrapper);
            }
        }

        List<AnnotationValue<CachePut>> cachePuts = cacheOperation.putOperations;
        if (cachePuts != null) {

            for (AnnotationValue<CachePut> cachePut : cachePuts) {
                boolean async = cachePut.get(MEMBER_ASYNC, Boolean.class, false);
                if (async) {
                    ioExecutor.submit(() ->
                            processCachePut(context, wrapper, cachePut, cacheOperation)
                    );
                } else {
                    processCachePut(context, wrapper, cachePut, cacheOperation);
                }
            }
        }

        List<AnnotationValue<CacheInvalidate>> cacheInvalidates = cacheOperation.invalidateOperations;
        if (cacheInvalidates != null) {
            for (AnnotationValue<CacheInvalidate> cacheInvalidate : cacheInvalidates) {
                boolean async = cacheInvalidate.get(MEMBER_ASYNC, Boolean.class, false);
                if (async) {
                    ioExecutor.submit(() -> {
                                try {
                                    processCacheEvict(context, cacheInvalidate, cacheOperation, async);
                                } catch (Exception e) {
                                    throw new CacheSystemException(""Cache invalidate operation failed: "" + e.getMessage(), e);
                                }
                            }
                    );
                } else {
                    processCacheEvict(context, cacheInvalidate, cacheOperation, async);
                }
            }
        }

        return wrapper.optional ? Optional.ofNullable(wrapper.value) : wrapper.value;
    }"
"private URLPatternHolder convertStringToPattern(String line) {
        URLPatternHolder holder = new URLPatternHolder();
        Pattern compiledPattern;
        Perl5Compiler compiler = new Perl5Compiler();
        String perl5RegExp = line;
        try {
            compiledPattern = compiler.compile(perl5RegExp, Perl5Compiler.READ_ONLY_MASK);
            holder.setCompiledPattern(compiledPattern);
        } catch (MalformedPatternException mpe) {
            throw new IllegalArgumentException(""Malformed regular expression: "" + perl5RegExp);
        }

        if (logger.isDebugEnabled()) {
            logger.debug(""Added regular expression: "" + compiledPattern.getPattern().toString());
        }
        return holder;
    }"
"List<ProviderInfo> mergeProviderInfo(List<String> userDatas, List<String> configDatas) {
        // 是否自己缓存运算后的结果？？ TODO
        List<ProviderInfo> providers = SofaRegistryHelper.parseProviderInfos(userDatas);
        // 交叉比较
        if (CommonUtils.isNotEmpty(providers) && CommonUtils.isNotEmpty(configDatas)) {
            List<ProviderInfo> override = SofaRegistryHelper.parseProviderInfos(configDatas);
            Iterator<ProviderInfo> iterator = providers.iterator();
            while (iterator.hasNext()) {
                ProviderInfo origin = iterator.next();
                for (ProviderInfo over : override) {
                    if (PROTOCOL_TYPE_OVERRIDE.equals(over.getProtocolType()) &&
                        StringUtils.equals(origin.getHost(), over.getHost()) && origin.getPort() == over.getPort()) {
                        // host 和 port 相同 认为是一个地址
                        if (over.getWeight() != origin.getWeight()) {
                            origin.setWeight(over.getWeight());
                        }
                        if (CommonUtils.isTrue(over.getAttr(ProviderInfoAttrs.ATTR_DISABLED))) {
                            if (LOGGER.isInfoEnabled()) {
                                LOGGER.info(""Provider is disabled by override. {}"", origin.toUrl());
                            }
                            iterator.remove(); // 禁用 删掉
                        }
                    }
                }
            }
        }
        return providers;
    }"
"synchronized public void initCloud() {
		if (groups == null || groups.length == 0) {
			throw new DbRuntimeException(""Please give replication set groups!"");
		}

		if (setting == null) {
			// 若未指定配置文件，则使用默认配置文件
			setting = new Setting(MONGO_CONFIG_PATH, true);
		}

		final List<ServerAddress> addrList = new ArrayList<ServerAddress>();
		for (String group : groups) {
			addrList.add(createServerAddress(group));
		}

		final MongoCredential credentail = createCredentail(StrUtil.EMPTY);
		try {
			if (null == credentail) {
				mongo = new MongoClient(addrList, buildMongoClientOptions(StrUtil.EMPTY));
			} else {
				mongo = new MongoClient(addrList, credentail, buildMongoClientOptions(StrUtil.EMPTY));
			}
		} catch (Exception e) {
			log.error(e, ""Init MongoDB connection error!"");
			return;
		}

		log.info(""Init MongoDB cloud Set pool with connection to {}"", addrList);
	}"
"static void installResourceBundle(AddOnClassLoader addOnClassLoader, AddOn addOn) {
        AddOn.BundleData bundleData = addOn.getBundleData();
        if (bundleData.isEmpty()) {
            return;
        }

        try {
            ResourceBundle resourceBundle = ResourceBundle.getBundle(
                    bundleData.getBaseName(),
                    Constant.getLocale(),
                    addOnClassLoader,
                    new ZapResourceBundleControl());
            addOn.setResourceBundle(resourceBundle);
            String bundlePrefix = bundleData.getPrefix();
            if (!bundlePrefix.isEmpty()) {
                Constant.messages.addMessageBundle(bundlePrefix, resourceBundle);
            }
        } catch (MissingResourceException e) {
            logger.error(""Declared bundle not found in "" + addOn.getId() + "" add-on:"", e);
        }
    }"
"public static boolean isInSSSP(final Edge<Long, Double> edgeToBeRemoved, DataSet<Edge<Long, Double>> edgesInSSSP) throws Exception {

		return edgesInSSSP.filter(new FilterFunction<Edge<Long, Double>>() {
			@Override
			public boolean filter(Edge<Long, Double> edge) throws Exception {
				return edge.equals(edgeToBeRemoved);
			}
		}).count() > 0;
	}"
"protected File initRecoveryDb(String dbName) {
    Preconditions.checkNotNull(_recoveryPath,
      ""recovery path should not be null if NM recovery is enabled"");

    File recoveryFile = new File(_recoveryPath.toUri().getPath(), dbName);
    if (recoveryFile.exists()) {
      return recoveryFile;
    }

    // db doesn't exist in recovery path go check local dirs for it
    String[] localDirs = _conf.getTrimmedStrings(""yarn.nodemanager.local-dirs"");
    for (String dir : localDirs) {
      File f = new File(new Path(dir).toUri().getPath(), dbName);
      if (f.exists()) {
        // If the recovery path is set then either NM recovery is enabled or another recovery
        // DB has been initialized. If NM recovery is enabled and had set the recovery path
        // make sure to move all DBs to the recovery path from the old NM local dirs.
        // If another DB was initialized first just make sure all the DBs are in the same
        // location.
        Path newLoc = new Path(_recoveryPath, dbName);
        Path copyFrom = new Path(f.toURI());
        if (!newLoc.equals(copyFrom)) {
          logger.info(""Moving "" + copyFrom + "" to: "" + newLoc);
          try {
            // The move here needs to handle moving non-empty directories across NFS mounts
            FileSystem fs = FileSystem.getLocal(_conf);
            fs.rename(copyFrom, newLoc);
          } catch (Exception e) {
            // Fail to move recovery file to new path, just continue on with new DB location
            logger.error(""Failed to move recovery file {} to the path {}"",
              dbName, _recoveryPath.toString(), e);
          }
        }
        return new File(newLoc.toUri().getPath());
      }
    }

    return new File(_recoveryPath.toUri().getPath(), dbName);
  }"
"public static void main(final String[] args) {
        new SpringApplicationBuilder(CasEurekaServerWebApplication.class)
            .banner(new CasEurekaServerBanner())
            .logStartupInfo(true)
            .bannerMode(Banner.Mode.CONSOLE)
            .web(WebApplicationType.SERVLET)
            .run(args);
    }"
"public void transferBackToVocabCache(VocabCache cache, boolean emptyHolder) {
        if (!(cache instanceof InMemoryLookupCache))
            throw new IllegalStateException(""Sorry, only InMemoryLookupCache use implemented."");

        // make sure that huffman codes are updated before transfer
        List<VocabularyWord> words = words(); //updateHuffmanCodes();

        for (VocabularyWord word : words) {
            if (word.getWord().isEmpty())
                continue;
            VocabWord vocabWord = new VocabWord(1, word.getWord());

            // if we're transferring full model, it CAN contain HistoricalGradient for AdaptiveGradient feature
            if (word.getHistoricalGradient() != null) {
                INDArray gradient = Nd4j.create(word.getHistoricalGradient());
                vocabWord.setHistoricalGradient(gradient);
            }

            // put VocabWord into both Tokens and Vocabs maps
            ((InMemoryLookupCache) cache).getVocabs().put(word.getWord(), vocabWord);
            ((InMemoryLookupCache) cache).getTokens().put(word.getWord(), vocabWord);


            // update Huffman tree information
            if (word.getHuffmanNode() != null) {
                vocabWord.setIndex(word.getHuffmanNode().getIdx());
                vocabWord.setCodeLength(word.getHuffmanNode().getLength());
                vocabWord.setPoints(arrayToList(word.getHuffmanNode().getPoint(), word.getHuffmanNode().getLength()));
                vocabWord.setCodes(arrayToList(word.getHuffmanNode().getCode(), word.getHuffmanNode().getLength()));

                // put word into index
                cache.addWordToIndex(word.getHuffmanNode().getIdx(), word.getWord());
            }

            //update vocabWord counter. substract 1, since its the base value for any token
            // >1 hack is required since VocabCache impl imples 1 as base word count, not 0
            if (word.getCount() > 1)
                cache.incrementWordCount(word.getWord(), word.getCount() - 1);
        }

        // at this moment its pretty safe to nullify all vocabs.
        if (emptyHolder) {
            idxMap.clear();
            vocabulary.clear();
        }
    }"
"public void start() throws Exception {
		try {
			leaderElectionService.start(this);
		} catch (Exception e) {
			log.error(""Could not start the JobManager because the leader election service did not start."", e);
			throw new Exception(""Could not start the leader election service."", e);
		}
	}"
"public static void resetBaseDirectoryLocation(){
        String property = System.getProperty(DL4JSystemProperties.DL4J_RESOURCES_DIR_PROPERTY);
        if(property != null){
            baseDirectory = new File(property);
        } else {
            baseDirectory = new File(System.getProperty(""user.home""), "".deeplearning4j"");
        }

        if(!baseDirectory.exists()){
            baseDirectory.mkdirs();
        }
    }"
"public List<Filter> deserializeFilterList(String str) {
        return load(str, ListWrappers.FilterList.class).getList();
    }"
"public void start() throws IOException {
    server.start();
    logger.info(""Server started, listening on "" + port);
    Runtime.getRuntime().addShutdownHook(new Thread() {
      @Override
      public void run() {
        // Use stderr here since the logger may has been reset by its JVM shutdown hook.
        System.err.println(""*** shutting down gRPC server since JVM is shutting down"");
        RouteGuideServer.this.stop();
        System.err.println(""*** server shut down"");
      }
    });
  }"
"public static SequenceBatchCSVRecord fromDataSet(MultiDataSet dataSet) {
        SequenceBatchCSVRecord batchCSVRecord = new SequenceBatchCSVRecord();
        for (int i = 0; i < dataSet.numFeatureArrays(); i++) {
            batchCSVRecord.add(Arrays.asList(BatchCSVRecord.fromDataSet(new DataSet(dataSet.getFeatures(i),dataSet.getLabels(i)))));
        }

        return batchCSVRecord;
    }"
"@RequirePOST
    public JSONArray doPrevalidateConfig(StaplerRequest req) throws IOException {
        Jenkins.getInstance().checkPermission(Jenkins.ADMINISTER);

        JSONArray response = new JSONArray();

        for (Map.Entry<String,VersionNumber> p : parseRequestedPlugins(req.getInputStream()).entrySet()) {
            PluginWrapper pw = getPlugin(p.getKey());
            JSONObject j = new JSONObject()
                    .accumulate(""name"", p.getKey())
                    .accumulate(""version"", p.getValue().toString());
            if (pw == null) { // install new
                response.add(j.accumulate(""mode"", ""missing""));
            } else if (pw.isOlderThan(p.getValue())) { // upgrade
                response.add(j.accumulate(""mode"", ""old""));
            } // else already good
        }

        return response;
    }"
"@Deprecated
  public RequestTemplate bodyTemplate(String bodyTemplate) {
    this.body(Request.Body.bodyTemplate(bodyTemplate, Util.UTF_8));
    return this;
  }"
"public static long between(Date beginDate, Date endDate, DateUnit unit, boolean isAbs) {
		return new DateBetween(beginDate, endDate, isAbs).between(unit);
	}"
"static ByteBuf doEncode(ByteBufAllocator byteBufAllocator, MqttMessage message) {

        switch (message.fixedHeader().messageType()) {
            case CONNECT:
                return encodeConnectMessage(byteBufAllocator, (MqttConnectMessage) message);

            case CONNACK:
                return encodeConnAckMessage(byteBufAllocator, (MqttConnAckMessage) message);

            case PUBLISH:
                return encodePublishMessage(byteBufAllocator, (MqttPublishMessage) message);

            case SUBSCRIBE:
                return encodeSubscribeMessage(byteBufAllocator, (MqttSubscribeMessage) message);

            case UNSUBSCRIBE:
                return encodeUnsubscribeMessage(byteBufAllocator, (MqttUnsubscribeMessage) message);

            case SUBACK:
                return encodeSubAckMessage(byteBufAllocator, (MqttSubAckMessage) message);

            case UNSUBACK:
            case PUBACK:
            case PUBREC:
            case PUBREL:
            case PUBCOMP:
                return encodeMessageWithOnlySingleByteFixedHeaderAndMessageId(byteBufAllocator, message);

            case PINGREQ:
            case PINGRESP:
            case DISCONNECT:
                return encodeMessageWithOnlySingleByteFixedHeader(byteBufAllocator, message);

            default:
                throw new IllegalArgumentException(
                        ""Unknown message type: "" + message.fixedHeader().messageType().value());
        }
    }"
"public static ComputationGraph importKerasModelAndWeights(String modelHdf5Filename, int[] inputShape,
                                                              boolean enforceTrainingConfig)
            throws IOException, UnsupportedKerasConfigurationException, InvalidKerasConfigurationException {
        KerasModel kerasModel = new KerasModel().modelBuilder.modelHdf5Filename(modelHdf5Filename)
                .enforceTrainingConfig(enforceTrainingConfig).inputShape(inputShape).buildModel();
        return kerasModel.getComputationGraph();
    }"
"public static <T> byte[] write(Buffer.Writer<T> writer, T value) {
    Buffer b = Buffer.allocate(writer.sizeInBytes(value));
    try {
      writer.write(value, b);
    } catch (RuntimeException e) {
      byte[] bytes = b.toByteArray();
      int lengthWritten = bytes.length;
      for (int i = 0; i < bytes.length; i++) {
        if (bytes[i] == 0) {
          lengthWritten = i;
          break;
        }
      }

      final byte[] bytesWritten;
      if (lengthWritten == bytes.length) {
        bytesWritten = bytes;
      } else {
        bytesWritten = new byte[lengthWritten];
        System.arraycopy(bytes, 0, bytesWritten, 0, lengthWritten);
      }

      String written = new String(bytesWritten, UTF_8);
      // Don't use value directly in the message, as its toString might be implemented using this
      // method. If that's the case, we'd stack overflow. Instead, emit what we've written so far.
      String message =
        format(
          ""Bug found using %s to write %s as json. Wrote %s/%s bytes: %s"",
          writer.getClass().getSimpleName(),
          value.getClass().getSimpleName(),
          lengthWritten,
          bytes.length,
          written);
      throw Platform.get().assertionError(message, e);
    }
    return b.toByteArray();
  }"
"@Override
    public void setArray(INDArray arr) {
        if (this.arr.get() == null)
            this.arr.set(arr);
    }"
"public static URL register(String serviceId, int port) {
        try {
            registry = SingletonServiceFactory.getBean(Registry.class);
            if (registry == null)
                throw new RuntimeException(""Could not find registry instance in service map"");
            // in kubernetes pod, the hostIP is passed in as STATUS_HOST_IP environment
            // variable. If this is null
            // then get the current server IP as it is not running in Kubernetes.
            String ipAddress = System.getenv(STATUS_HOST_IP);
            logger.info(""Registry IP from STATUS_HOST_IP is "" + ipAddress);
            if (ipAddress == null) {
                InetAddress inetAddress = Util.getInetAddress();
                ipAddress = inetAddress.getHostAddress();
                logger.info(""Could not find IP from STATUS_HOST_IP, use the InetAddress "" + ipAddress);
            }

            ServerConfig serverConfig = getServerConfig();
            Map parameters = new HashMap<>();
            if (serverConfig.getEnvironment() != null)
                parameters.put(ENV_PROPERTY_KEY, serverConfig.getEnvironment());
            URL serviceUrl = new URLImpl(""light"", ipAddress, port, serviceId, parameters);
            if (logger.isInfoEnabled()) logger.info(""register service: "" + serviceUrl.toFullStr());
            registry.register(serviceUrl);
            return serviceUrl;
            // handle the registration exception separately to eliminate confusion
        } catch (Exception e) {
            System.out.println(""Failed to register service, the server stopped."");
            e.printStackTrace();
            if (logger.isInfoEnabled())
                logger.info(""Failed to register service, the server stopped."", e);
            throw new RuntimeException(e.getMessage());
        }

    }"
"private void rotateLeft(Node<K, V> root) {
    Node<K, V> left = root.left;
    Node<K, V> pivot = root.right;
    Node<K, V> pivotLeft = pivot.left;
    Node<K, V> pivotRight = pivot.right;

    // move the pivot's left child to the root's right
    root.right = pivotLeft;
    if (pivotLeft != null) {
      pivotLeft.parent = root;
    }

    replaceInParent(root, pivot);

    // move the root to the pivot's left
    pivot.left = root;
    root.parent = pivot;

    // fix heights
    root.height = Math.max(left != null ? left.height : 0,
        pivotLeft != null ? pivotLeft.height : 0) + 1;
    pivot.height = Math.max(root.height,
        pivotRight != null ? pivotRight.height : 0) + 1;
  }"
"@Override
   public CallableStatement prepareCall(String sql) throws SQLException
   {
      return ProxyFactory.getProxyCallableStatement(this, trackStatement(delegate.prepareCall(sql)));
   }"
"public void normalize() {
        for (T key : keySet()) {
            setCount(key, getCount(key) / totalCount.get());
        }

        rebuildTotals();
    }"
"public static boolean del(Path path) throws IORuntimeException {
		if (Files.notExists(path)) {
			return true;
		}

		try {
			if (Files.isDirectory(path)) {
				Files.walkFileTree(path, new SimpleFileVisitor<Path>() {

					@Override
					public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException {
						Files.delete(file);
						return FileVisitResult.CONTINUE;
					}

					@Override
					public FileVisitResult postVisitDirectory(Path dir, IOException e) throws IOException {
						if (e == null) {
							Files.delete(dir);
							return FileVisitResult.CONTINUE;
						} else {
							throw e;
						}
					}
				});
			} else {
				Files.delete(path);
			}
		} catch (IOException e) {
			throw new IORuntimeException(e);
		}
		return true;
	}"
"@Override
    public ChannelFuture block(
            InetAddress multicastAddress, NetworkInterface networkInterface,
            InetAddress sourceToBlock, ChannelPromise promise) {
        checkJavaVersion();

        if (multicastAddress == null) {
            throw new NullPointerException(""multicastAddress"");
        }
        if (sourceToBlock == null) {
            throw new NullPointerException(""sourceToBlock"");
        }

        if (networkInterface == null) {
            throw new NullPointerException(""networkInterface"");
        }
        synchronized (this) {
            if (memberships != null) {
                List<MembershipKey> keys = memberships.get(multicastAddress);
                for (MembershipKey key: keys) {
                    if (networkInterface.equals(key.networkInterface())) {
                        try {
                            key.block(sourceToBlock);
                        } catch (IOException e) {
                            promise.setFailure(e);
                        }
                    }
                }
            }
        }
        promise.setSuccess();
        return promise;
    }"
"protected int[] score_decide(Chunk chks[], int nnids[]) {
    int [] res = nnids.clone();
    for( int row=0; row<nnids.length; row++ ) { // Over all rows
      int nid = nnids[row];          // Get Node to decide from
      if( isDecidedRow(nid)) {               // already done
        res[row] -= _leaf;
        continue;
      }
      // Score row against current decisions & assign new split
      boolean oob = isOOBRow(nid);
      if( oob ) nid = oob2Nid(nid); // sampled away - we track the position in the tree
      DTree.DecidedNode dn = _tree.decided(nid);
      if( dn._split == null ) { // Might have a leftover non-split
        if( DTree.isRootNode(dn) ) { res[row] = nid - _leaf; continue; }
        nid = dn._pid;             // Use the parent split decision then
        int xnid = oob ? nid2Oob(nid) : nid;
        nnids[row] = xnid;
        res[row] = xnid - _leaf;
        dn = _tree.decided(nid); // Parent steers us
      }
      assert !isDecidedRow(nid);
      nid = dn.getChildNodeID(chks,row); // Move down the tree 1 level
      if( !isDecidedRow(nid) ) {
        if( oob ) nid = nid2Oob(nid); // Re-apply OOB encoding
        nnids[row] = nid;
      }
      res[row] = nid-_leaf;
    }
    return res;
  }"
"public static <T> T isInstanceOf(Class<?> type, T obj, String errorMsgTemplate, Object... params) throws IllegalArgumentException {
		notNull(type, ""Type to check against must not be null"");
		if (false == type.isInstance(obj)) {
			throw new IllegalArgumentException(StrUtil.format(errorMsgTemplate, params));
		}
		return obj;
	}"
"public synchronized OtpErlangRef createRef() {
        final OtpErlangRef r = new OtpErlangRef(node, refId, creation);

        // increment ref ids (3 ints: 18 + 32 + 32 bits)
        refId[0]++;
        if (refId[0] > 0x3ffff) {
            refId[0] = 0;

            refId[1]++;
            if (refId[1] == 0) {
                refId[2]++;
            }
        }

        return r;
    }"
"private static void mergeContinueNumIntoOne(List<Vertex> linkedArray)
    {
        if (linkedArray.size() < 2)
            return;

        ListIterator<Vertex> listIterator = linkedArray.listIterator();
        Vertex next = listIterator.next();
        Vertex current = next;
        while (listIterator.hasNext())
        {
            next = listIterator.next();
//            System.out.println(""current:"" + current + "" next:"" + next);
            if ((TextUtility.isAllNum(current.realWord) || TextUtility.isAllChineseNum(current.realWord)) && (TextUtility.isAllNum(next.realWord) || TextUtility.isAllChineseNum(next.realWord)))
            {
                /////////// 这部分从逻辑上等同于current.realWord = current.realWord + next.realWord;
                // 但是current指针被几个路径共享，需要备份，不然修改了一处就修改了全局
                current = Vertex.newNumberInstance(current.realWord + next.realWord);
                listIterator.previous();
                listIterator.previous();
                listIterator.set(current);
                listIterator.next();
                listIterator.next();
                /////////// end 这部分
//                System.out.println(""before:"" + linkedArray);
                listIterator.remove();
//                System.out.println(""after:"" + linkedArray);
            }
            else
            {
                current = next;
            }
        }

//        logger.trace(""数字识别后："" + Graph.parseResult(linkedArray));
    }"
"public void doLogout( StaplerRequest req, StaplerResponse rsp ) throws IOException, ServletException {
        String user = getAuthentication().getName();
        securityRealm.doLogout(req, rsp);
        SecurityListener.fireLoggedOut(user);
    }"
"@Override
	public AuthorizationRequest checkForPreApproval(AuthorizationRequest authorizationRequest,
			Authentication userAuthentication) {

		boolean approved = false;
		// If we are allowed to check existing approvals this will short circuit the decision
		if (useApprovalStore) {
			authorizationRequest = super.checkForPreApproval(authorizationRequest, userAuthentication);
			approved = authorizationRequest.isApproved();
		}
		else {
			if (clientDetailsService != null) {
				Collection<String> requestedScopes = authorizationRequest.getScope();
				try {
					ClientDetails client = clientDetailsService
							.loadClientByClientId(authorizationRequest.getClientId());
					for (String scope : requestedScopes) {
						if (client.isAutoApprove(scope)) {
							approved = true;
							break;
						}
					}
				}
				catch (ClientRegistrationException e) {
				}
			}
		}
		authorizationRequest.setApproved(approved);

		return authorizationRequest;

	}"
"public Option defaultValue(String defaultValue) throws RequiredParametersException {
		if (this.choices.isEmpty()) {
			return this.setDefaultValue(defaultValue);
		} else {
			if (this.choices.contains(defaultValue)) {
				return this.setDefaultValue(defaultValue);
			} else {
				throw new RequiredParametersException(""Default value "" + defaultValue +
						"" is not in the list of valid values for option "" + this.longName);
			}
		}
	}"
"@Benchmark
  public int unionAndIter(BitmapsForUnion state)
  {
    ImmutableBitmap intersection = factory.union(Arrays.asList(state.bitmaps));
    return iter(intersection);
  }"
"protected boolean isFirehoseDrainableByClosing(FirehoseFactory firehoseFactory)
  {
    return firehoseFactory instanceof EventReceiverFirehoseFactory
           || (firehoseFactory instanceof TimedShutoffFirehoseFactory
               && isFirehoseDrainableByClosing(((TimedShutoffFirehoseFactory) firehoseFactory).getDelegateFactory()))
           || (firehoseFactory instanceof ClippedFirehoseFactory
               && isFirehoseDrainableByClosing(((ClippedFirehoseFactory) firehoseFactory).getDelegate()));
  }"
"public static <TERM> Map<TERM, Double> tfIdf(Map<TERM, Double> tf, Map<TERM, Double> idf,
                                                 Normalization normalization)
    {
        Map<TERM, Double> tfIdf = new HashMap<TERM, Double>();
        for (TERM term : tf.keySet())
        {
            Double TF = tf.get(term);
            if (TF == null) TF = 1.;
            Double IDF = idf.get(term);
            if (IDF == null) IDF = 1.;
            tfIdf.put(term, TF * IDF);
        }
        if (normalization == Normalization.COSINE)
        {
            double n = 0.0;
            for (double x : tfIdf.values())
            {
                n += x * x;
            }
            n = Math.sqrt(n);

            for (TERM term : tfIdf.keySet())
            {
                tfIdf.put(term, tfIdf.get(term) / n);
            }
        }
        return tfIdf;
    }"
"public static boolean validateClassLoadable(ClassNotFoundException cnfe, ClassLoader cl) {
		try {
			String className = cnfe.getMessage();
			Class.forName(className, false, cl);
			return true;
		}
		catch (ClassNotFoundException e) {
			return false;
		}
		catch (Exception e) {
			return false;
		}
	}"
"protected void callDecode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out) {
        try {
            while (in.isReadable()) {
                int outSize = out.size();

                if (outSize > 0) {
                    fireChannelRead(ctx, out, outSize);
                    out.clear();

                    // Check if this handler was removed before continuing with decoding.
                    // If it was removed, it is not safe to continue to operate on the buffer.
                    //
                    // See:
                    // - https://github.com/netty/netty/issues/4635
                    if (ctx.isRemoved()) {
                        break;
                    }
                    outSize = 0;
                }

                int oldInputLength = in.readableBytes();
                decodeRemovalReentryProtection(ctx, in, out);

                // Check if this handler was removed before continuing the loop.
                // If it was removed, it is not safe to continue to operate on the buffer.
                //
                // See https://github.com/netty/netty/issues/1664
                if (ctx.isRemoved()) {
                    break;
                }

                if (outSize == out.size()) {
                    if (oldInputLength == in.readableBytes()) {
                        break;
                    } else {
                        continue;
                    }
                }

                if (oldInputLength == in.readableBytes()) {
                    throw new DecoderException(
                            StringUtil.simpleClassName(getClass()) +
                                    "".decode() did not read anything but decoded a message."");
                }

                if (isSingleDecode()) {
                    break;
                }
            }
        } catch (DecoderException e) {
            throw e;
        } catch (Exception cause) {
            throw new DecoderException(cause);
        }
    }"
"private <IN> void executeDataSink(GenericDataSinkBase<?> sink, int superStep) throws Exception {
		Operator<?> inputOp = sink.getInput();
		if (inputOp == null) {
			throw new InvalidProgramException(""The data sink "" + sink.getName() + "" has no input."");
		}
		
		@SuppressWarnings(""unchecked"")
		List<IN> input = (List<IN>) execute(inputOp);
		
		@SuppressWarnings(""unchecked"")
		GenericDataSinkBase<IN> typedSink = (GenericDataSinkBase<IN>) sink;

		// build the runtime context and compute broadcast variables, if necessary
		TaskInfo taskInfo = new TaskInfo(typedSink.getName(), 1, 0, 1, 0);
		RuntimeUDFContext ctx;

		MetricGroup metrics = new UnregisteredMetricsGroup();
			
		if (RichOutputFormat.class.isAssignableFrom(typedSink.getUserCodeWrapper().getUserCodeClass())) {
			ctx = superStep == 0 ? new RuntimeUDFContext(taskInfo, userCodeClassLoader, executionConfig, cachedFiles, accumulators, metrics) :
					new IterationRuntimeUDFContext(taskInfo, userCodeClassLoader, executionConfig, cachedFiles, accumulators, metrics);
		} else {
			ctx = null;
		}

		typedSink.executeOnCollections(input, ctx, executionConfig);
	}"
"public synchronized void stop() throws Exception {
		if (this.serverChannel != null) {
			this.serverChannel.close().awaitUninterruptibly();
			this.serverChannel = null;
		}
		if (bootstrap != null) {
			if (bootstrap.group() != null) {
				bootstrap.group().shutdownGracefully();
			}
			bootstrap = null;
		}
	}"
"public static OffHeapColumnVector[] allocateColumns(int capacity, StructField[] fields) {
    OffHeapColumnVector[] vectors = new OffHeapColumnVector[fields.length];
    for (int i = 0; i < fields.length; i++) {
      vectors[i] = new OffHeapColumnVector(capacity, fields[i].dataType());
    }
    return vectors;
  }"
"public static String replaceFirst(final String text, final String regex, final String replacement) {
        if (text == null || regex == null|| replacement == null ) {
            return text;
        }
        return text.replaceFirst(regex, replacement);
    }"
"public static String getClassName(Object obj, boolean isSimple) {
		if (null == obj) {
			return null;
		}
		final Class<?> clazz = obj.getClass();
		return getClassName(clazz, isSimple);
	}"
"@Override
	public Class<?> getColumnClass(int columnIndex) {
		switch (columnIndex) {
		case 0:
			return Boolean.class;
		case 1:
			return String.class;
		case 2:
			return String.class;
		case 3:
			return Integer.class;
		}
		return null;
	}"
"public SDVariable maxPooling2d(SDVariable input, Pooling2DConfig pooling2DConfig) {
        MaxPooling2D maxPooling2D = MaxPooling2D.builder()
                .input(input)
                .sameDiff(sameDiff())
                .config(pooling2DConfig)
                .build();

        return maxPooling2D.outputVariable();
    }"
"public AdamicAdar<K, VV, EV> setMinimumRatio(float ratio) {
		Preconditions.checkArgument(ratio >= 0, ""Minimum ratio must be non-negative"");

		this.minimumRatio = ratio;

		return this;
	}"
"public static <KT, KB, VVT, VVB, EV> BipartiteGraph<KT, KB, VVT, VVB, EV> fromDataSet(
			DataSet<Vertex<KT, VVT>> topVertices,
			DataSet<Vertex<KB, VVB>> bottomVertices,
			DataSet<BipartiteEdge<KT, KB, EV>> edges,
			ExecutionEnvironment context) {
		return new BipartiteGraph<>(topVertices, bottomVertices, edges, context);
	}"
"public static ScoreKeeper[] scoreKeepers(ScoringInfo[] scoring_history) {
    ScoreKeeper[] sk = new ScoreKeeper[scoring_history.length];
    for (int i=0;i<sk.length;++i) {
      sk[i] = scoring_history[i].cross_validation ? scoring_history[i].scored_xval
              : scoring_history[i].validation ? scoring_history[i].scored_valid
              : scoring_history[i].scored_train;
    }
    return sk;
  }"
"public List<SDVariable> multiHeadDotProductAttention(String name, SDVariable queries, SDVariable keys, SDVariable values, SDVariable Wq, SDVariable Wk, SDVariable Wv, SDVariable Wo, SDVariable mask, boolean scaled, boolean withWeights){
        List<SDVariable> result = f().multiHeadDotProductAttention(queries, keys, values, Wq, Wk, Wv, Wo, mask, scaled, withWeights);
        if(withWeights){
            return Collections.singletonList(updateVariableNameAndReference(result.get(0), name));
        }else{
            return Arrays.asList(
                    updateVariableNameAndReference(result.get(0), name),
                    updateVariableNameAndReference(result.get(1), name+"":weights"")
            );
        }
    }"
"protected Collection<L> buildWithField(Class<L> nodeType, N statement, FieldAccess fa) {
		List<L> list = new ArrayList<L>();
		buildWithField0(nodeType, statement, fa, list);
		return list;
	}"
"private JPanel getPanelParam() {
        if (panelParam == null) {
            panelParam = new JPanel();
            panelParam.setLayout(new CardLayout());
            panelParam.setPreferredSize(new java.awt.Dimension(300, 300));
            panelParam.setBorder(javax.swing.BorderFactory.createEmptyBorder(0, 0, 0, 0));
        }
        
        return panelParam;
    }"
"private static boolean isJarFile(File file) {
		if (false == FileUtil.isFile(file)) {
			return false;
		}
		return file.getPath().toLowerCase().endsWith("".jar"");
	}"
"public static List<String[]> arrangementSelect(String[] datas, int m) {
		return new Arrangement(datas).select(m);
	}"
"public static Predicate<String> regex(final String pathRegex) {
    return new Predicate<String>() {
      @Override
      public boolean test(String input) {
        return input.matches(pathRegex);
      }
    };
  }"
"@SneakyThrows
    public static <T, R> Function<T, R> doAndHandle(final CheckedFunction<T, R> function, final CheckedFunction<Throwable, R> errorHandler) {
        return t -> {
            try {
                return function.apply(t);
            } catch (final Throwable e) {
                LOGGER.warn(e.getMessage(), e);
                try {
                    return errorHandler.apply(e);
                } catch (final Throwable ex) {
                    throw new IllegalArgumentException(ex.getMessage());
                }
            }
        };
    }"
"@Override
    public Set<BeanDefinitionHolder> doScan(String... basePackages) {
        Set<BeanDefinitionHolder> beanDefinitions = super.doScan(basePackages);

        if (beanDefinitions.isEmpty()) {
            logger.warn(""No MyBatis mapper was found in '"" + Arrays.toString(basePackages) + ""' package. Please check your configuration."");
        } else {
            processBeanDefinitions(beanDefinitions);
        }

        return beanDefinitions;
    }"
"public static FastDateFormat getDateInstance(final int style, final TimeZone timeZone, final Locale locale) {
		return cache.getDateInstance(style, timeZone, locale);
	}"
"public Object navigation(Context context, NavigationCallback callback) {
        return ARouter.getInstance().navigation(context, this, -1, callback);
    }"
"private int writeKnownLengthUncompressed(InputStream message, int messageLength)
      throws IOException {
    if (maxOutboundMessageSize >= 0 && messageLength > maxOutboundMessageSize) {
      throw Status.RESOURCE_EXHAUSTED
          .withDescription(
              String.format(""message too large %d > %d"", messageLength , maxOutboundMessageSize))
          .asRuntimeException();
    }
    ByteBuffer header = ByteBuffer.wrap(headerScratch);
    header.put(UNCOMPRESSED);
    header.putInt(messageLength);
    // Allocate the initial buffer chunk based on frame header + payload length.
    // Note that the allocator may allocate a buffer larger or smaller than this length
    if (buffer == null) {
      buffer = bufferAllocator.allocate(header.position() + messageLength);
    }
    writeRaw(headerScratch, 0, header.position());
    return writeToOutputStream(message, outputStreamAdapter);
  }"
"public static long getLongHash(@NonNull String string) {
        long h = HSTART;
        final long hmult = HMULT;
        final long[] ht = byteTable;
        final int len = string.length();
        for (int i = 0; i < len; i++) {
            char ch = string.charAt(i);
            h = (h * hmult) ^ ht[ch & 0xff];
            h = (h * hmult) ^ ht[(ch >>> 8) & 0xff];
        }
        return h;
    }"
"public static <T> void register(final Class<T> service) {
        for (T each : ServiceLoader.load(service)) {
            registerServiceClass(service, each);
        }
    }"
"@Override
  public GraphiteEvent druidEventToGraphite(ServiceMetricEvent serviceMetricEvent)
  {
    if (!this.isInWhiteList(serviceMetricEvent)) {
      return null;
    }
    final ImmutableList.Builder<String> metricPathBuilder = new ImmutableList.Builder<>();
    metricPathBuilder.add(this.getNamespacePrefix());
    if (!this.isIgnoreServiceName()) {
      metricPathBuilder.add(GraphiteEmitter.sanitize(serviceMetricEvent.getService()));
    }
    if (!this.isIgnoreHostname()) {
      metricPathBuilder.add(GraphiteEmitter.sanitize(serviceMetricEvent.getHost()));
    }
    List<String> dimValues = getOrderedDimValues(serviceMetricEvent);
    if (dimValues != null) {
      metricPathBuilder.addAll(dimValues);
    }
    metricPathBuilder.add(GraphiteEmitter.sanitize(serviceMetricEvent.getMetric(), this.replaceSlashWithDot()));

    return new GraphiteEvent(
        Joiner.on(""."").join(metricPathBuilder.build()),
        String.valueOf(serviceMetricEvent.getValue()),
        TimeUnit.MILLISECONDS.toSeconds(serviceMetricEvent.getCreatedTime().getMillis())
    );
  }"
"@Override
  public TsiPeer extractPeer() throws GeneralSecurityException {
    Preconditions.checkState(!isInProgress(), ""Handshake is not complete."");
    List<TsiPeer.Property<?>> peerProperties = new ArrayList<>();
    peerProperties.add(
        new TsiPeer.StringProperty(
            TSI_SERVICE_ACCOUNT_PEER_PROPERTY,
            handshaker.getResult().getPeerIdentity().getServiceAccount()));
    return new TsiPeer(peerProperties);
  }"
"public void acknowledgePages(long sequenceId)
    {
        checkArgument(sequenceId >= 0, ""Invalid sequence id"");

        List<SerializedPageReference> removedPages = new ArrayList<>();
        synchronized (this) {
            if (destroyed.get()) {
                return;
            }

            // if pages have already been acknowledged, just ignore this
            long oldCurrentSequenceId = currentSequenceId.get();
            if (sequenceId < oldCurrentSequenceId) {
                return;
            }

            int pagesToRemove = toIntExact(sequenceId - oldCurrentSequenceId);
            checkArgument(pagesToRemove <= pages.size(), ""Invalid sequence id"");

            long bytesRemoved = 0;
            for (int i = 0; i < pagesToRemove; i++) {
                SerializedPageReference removedPage = pages.removeFirst();
                removedPages.add(removedPage);
                bytesRemoved += removedPage.getRetainedSizeInBytes();
            }

            // update current sequence id
            verify(currentSequenceId.compareAndSet(oldCurrentSequenceId, oldCurrentSequenceId + pagesToRemove));

            // update memory tracking
            verify(bufferedBytes.addAndGet(-bytesRemoved) >= 0);
        }

        // dereference outside of synchronized to avoid making a callback while holding a lock
        removedPages.forEach(SerializedPageReference::dereferencePage);
    }"
"public void setExcludeFromContextRegexs(List<String> excludeRegexs) {
		validateRegexs(excludeRegexs);
		// Check if theyve been changed
		if (excludeFromRegexs.size() == excludeRegexs.size()) {
			boolean changed = false;
			for (int i = 0; i < excludeFromRegexs.size(); i++) {
				if (!excludeFromRegexs.get(i).equals(excludeRegexs.get(i))) {
					changed = true;
					break;
				}
			}
			if (!changed) {
				// No point reapplying the same regexs
				return;
			}
		}

		excludeFromRegexs.clear();
		excludeFromPatterns.clear();
		for (String url : excludeRegexs) {
			url = url.trim();
			if (url.length() > 0) {
				Pattern p = Pattern.compile(url, Pattern.CASE_INSENSITIVE);
				excludeFromPatterns.add(p);
				excludeFromRegexs.add(url);
			}
		}
	}"
"java.util.regex.Pattern getPattern(
            @Nonnull AnnotationValue<?> annotationMetadata,
            boolean isOptional) {
        final Optional<String> regexp = annotationMetadata.get(""regexp"", String.class);
        final String pattern;

        if (isOptional) {
            pattern = regexp.orElse("".*"");
        } else {
            pattern = regexp
                    .orElseThrow(() -> new ValidationException(""No pattern specified""));
        }

        final Pattern.Flag[] flags = annotationMetadata.get(""flags"", Pattern.Flag[].class).orElse(ZERO_FLAGS);
        if (isOptional && pattern.equals("".*"") && flags.length == 0) {
            return null;
        }

        int computedFlag = 0;
        for (Pattern.Flag flag : flags) {
            computedFlag = computedFlag | flag.getValue();
        }

        final PatternKey key = new PatternKey(pattern, computedFlag);
        java.util.regex.Pattern regex = COMPUTED_PATTERNS.get(key);
        if (regex == null) {
            try {
                if (computedFlag != 0) {
                    regex = java.util.regex.Pattern.compile(pattern, computedFlag);
                } else {
                    regex = java.util.regex.Pattern.compile(pattern);
                }
            } catch (PatternSyntaxException e) {
                throw new IllegalArgumentException(""Invalid regular expression"", e);
            }
            COMPUTED_PATTERNS.put(key, regex);
        }
        return regex;
    }"
"public static <T> T[] sub(T[] array, int start, int end) {
		int length = length(array);
		if (start < 0) {
			start += length;
		}
		if (end < 0) {
			end += length;
		}
		if (start == length) {
			return newArray(array.getClass().getComponentType(), 0);
		}
		if (start > end) {
			int tmp = start;
			start = end;
			end = tmp;
		}
		if (end > length) {
			if (start >= length) {
				return newArray(array.getClass().getComponentType(), 0);
			}
			end = length;
		}
		return Arrays.copyOfRange(array, start, end);
	}"
"public void doGeneric(String method, HttpServletRequest request, HttpServletResponse response) {
    try {
      ServletUtils.startTransaction(request.getHeader(""User-Agent""));

      // Note that getServletPath does an un-escape so that the %24 of job id's are turned into $ characters.
      String uri = request.getServletPath();

      Properties headers = new Properties();
      Enumeration<String> en = request.getHeaderNames();
      while (en.hasMoreElements()) {
        String key = en.nextElement();
        String value = request.getHeader(key);
        headers.put(key, value);
      }

      final String contentType = request.getContentType();
      Properties parms = new Properties();
      String postBody = null;
      if (System.getProperty(H2O.OptArgs.SYSTEM_PROP_PREFIX + ""debug.cors"") != null) {
        response.setHeader(""Access-Control-Allow-Origin"", ""*"");
        response.setHeader(""Access-Control-Allow-Headers"", ""Content-Type"");
      }

      if (contentType != null && contentType.startsWith(MIME_JSON)) {
        StringBuffer jb = new StringBuffer();
        String line = null;
        try {
          BufferedReader reader = request.getReader();
          while ((line = reader.readLine()) != null)
            jb.append(line);
        } catch (Exception e) {
          throw new H2OIllegalArgumentException(""Exception reading POST body JSON for URL: "" + uri);
        }
        postBody = jb.toString();
      } else {
        // application/x-www-form-urlencoded
        Map<String, String[]> parameterMap;
        parameterMap = request.getParameterMap();
        for (Map.Entry<String, String[]> entry : parameterMap.entrySet()) {
          String key = entry.getKey();
          String[] values = entry.getValue();

          if (values.length == 1) {
            parms.put(key, values[0]);
          } else if (values.length > 1) {
            StringBuilder sb = new StringBuilder();
            sb.append(""["");
            boolean first = true;
            for (String value : values) {
              if (!first) sb.append("","");
              sb.append(""\"""").append(value).append(""\"""");
              first = false;
            }
            sb.append(""]"");
            parms.put(key, sb.toString());
          }
        }
      }

      // Make serve() call.
      NanoResponse resp = serve(uri, method, headers, parms, postBody);

      // Un-marshal Nano response back to Jetty.
      String choppedNanoStatus = resp.status.substring(0, 3);
      assert (choppedNanoStatus.length() == 3);
      int sc = Integer.parseInt(choppedNanoStatus);
      ServletUtils.setResponseStatus(response, sc);

      response.setContentType(resp.mimeType);

      Properties header = resp.header;
      Enumeration<Object> en2 = header.keys();
      while (en2.hasMoreElements()) {
        String key = (String) en2.nextElement();
        String value = header.getProperty(key);
        response.setHeader(key, value);
      }

      resp.writeTo(response.getOutputStream());

    } catch (IOException e) {
      e.printStackTrace();
      ServletUtils.setResponseStatus(response, 500);
      Log.err(e);
      // Trying to send an error message or stack trace will produce another IOException...
    } finally {
      ServletUtils.logRequest(method, request, response);
      // Handle shutdown if it was requested.
      if (H2O.getShutdownRequested()) {
        (new Thread() {
          public void run() {
            boolean [] confirmations = new boolean[H2O.CLOUD.size()];
            if (H2O.SELF.index() >= 0) {
              confirmations[H2O.SELF.index()] = true;
            }
            for(H2ONode n:H2O.CLOUD._memary) {
              if(n != H2O.SELF)
                new RPC<>(n, new UDPRebooted.ShutdownTsk(H2O.SELF,n.index(), 1000, confirmations, 0)).call();
            }
            try { Thread.sleep(2000); }
            catch (Exception ignore) {}
            int failedToShutdown = 0;
            // shutdown failed
            for(boolean b:confirmations)
              if(!b) failedToShutdown++;
            Log.info(""Orderly shutdown: "" + (failedToShutdown > 0? failedToShutdown + "" nodes failed to shut down! "":"""") + "" Shutting down now."");
            H2O.closeAll();
            H2O.exit(failedToShutdown);
          }
        }).start();
      }
      ServletUtils.endTransaction();
    }
  }"
"public static double iou(DetectedObject o1, DetectedObject o2) {
        double x1min  = o1.getCenterX() - o1.getWidth() / 2;
        double x1max  = o1.getCenterX() + o1.getWidth() / 2;
        double y1min  = o1.getCenterY() - o1.getHeight() / 2;
        double y1max  = o1.getCenterY() + o1.getHeight() / 2;

        double x2min  = o2.getCenterX() - o2.getWidth() / 2;
        double x2max  = o2.getCenterX() + o2.getWidth() / 2;
        double y2min  = o2.getCenterY() - o2.getHeight() / 2;
        double y2max  = o2.getCenterY() + o2.getHeight() / 2;

        double ow = overlap(x1min, x1max, x2min, x2max);
        double oh = overlap(y1min, y1max, y2min, y2max);

        double intersection = ow * oh;
        double union = o1.getWidth() * o1.getHeight() + o2.getWidth() * o2.getHeight() - intersection;
        return intersection / union;
    }"
"public static List<Integer> arrayToList(int[] array, int codeLen) {
        List<Integer> result = new ArrayList<>();
        for (int x = 0; x < codeLen; x++) {
            result.add(array[x]);
        }
        return result;
    }"
"public static void exportCSVLocal(File outputFile, String delimiter, JavaRDD<List<Writable>> data, int rngSeed)
                    throws Exception {
        exportCSVLocal(outputFile, delimiter, null, data, rngSeed);
    }"
"public void stop() {
        bossGroup.shutdownGracefully().syncUninterruptibly();
        workerGroup.shutdownGracefully().syncUninterruptibly();

        pipelineFactory.stop();
        log.info(""SocketIO server stopped"");
    }"
"public static INDArray pca_factor(INDArray A, double variance, boolean normalize) {
        if (normalize) {
            // Normalize to mean 0 for each feature ( each column has 0 mean )
            INDArray mean = A.mean(0);
            A.subiRowVector(mean);
        }

        long m = A.rows();
        long n = A.columns();

        // The prepare SVD results, we'll decomp A to UxSxV'
        INDArray s = Nd4j.create(A.dataType(), m < n ? m : n);
        INDArray VT = Nd4j.create(A.dataType(), new long[]{n, n}, 'f');

        // Note - we don't care about U 
        Nd4j.getBlasWrapper().lapack().gesvd(A, s, null, VT);

        // Now convert the eigs of X into the eigs of the covariance matrix
        for (int i = 0; i < s.length(); i++) {
            s.putScalar(i, Math.sqrt(s.getDouble(i)) / (m - 1));
        }

        // Now find how many features we need to preserve the required variance
        // Which is the same percentage as a cumulative sum of the eigenvalues' percentages
        double totalEigSum = s.sumNumber().doubleValue() * variance;
        int k = -1; // we will reduce to k dimensions
        double runningTotal = 0;
        for (int i = 0; i < s.length(); i++) {
            runningTotal += s.getDouble(i);
            if (runningTotal >= totalEigSum) { // OK I know it's a float, but what else can we do ?
                k = i + 1; // we will keep this many features to preserve the reqd. variance
                break;
            }
        }
        if (k == -1) { // if we need everything
            throw new RuntimeException(""No reduction possible for reqd. variance - use smaller variance"");
        }
        // So now let's rip out the appropriate number of left singular vectors from
        // the V output (note we pulls rows since VT is a transpose of V)
        INDArray V = VT.transpose();
        INDArray factor = Nd4j.createUninitialized(A.dataType(), new long[]{n, k}, 'f');
        for (int i = 0; i < k; i++) {
            factor.putColumn(i, V.getColumn(i));
        }

        return factor;
    }"
"protected char[] getPasswordFromConfig(String name) {
    char[] pass = null;
    if (getBoolean(CredentialProvider.CLEAR_TEXT_FALLBACK, true)) {
      String passStr = get(name);
      if (passStr != null) {
        pass = passStr.toCharArray();
      }
    }
    return pass;
  }"
"public static String identifyDriver(DataSource ds) {
		if(ds instanceof DataSourceWrapper) {
			final String driver = ((DataSourceWrapper)ds).getDriver();
			if(StrUtil.isNotBlank(driver)) {
				return driver;
			}
		}
		
		Connection conn = null;
		String driver = null;
		try {
			try {
				conn = ds.getConnection();
			} catch (SQLException e) {
				throw new DbRuntimeException(""Get Connection error !"", e);
			} catch (NullPointerException e) {
				throw new DbRuntimeException(""Unexpected NullPointException, maybe [jdbcUrl] or [url] is empty!"", e);
			}
			driver = identifyDriver(conn);
		} finally {
			DbUtil.close(conn);
		}

		return driver;
	}"
"private static void visitSelectTable(SchemaItem schemaItem, SQLTableSource sqlTableSource,
                                         List<TableItem> tableItems, TableItem tableItemTmp) {
        if (sqlTableSource instanceof SQLExprTableSource) {
            SQLExprTableSource sqlExprTableSource = (SQLExprTableSource) sqlTableSource;
            TableItem tableItem;
            if (tableItemTmp != null) {
                tableItem = tableItemTmp;
            } else {
                tableItem = new TableItem(schemaItem);
            }
            tableItem.setSchema(sqlExprTableSource.getSchema());
            tableItem.setTableName(sqlExprTableSource.getTableName());
            if (tableItem.getAlias() == null) {
                tableItem.setAlias(sqlExprTableSource.getAlias());
            }
            if (tableItems.isEmpty()) {
                // 第一张表为主表
                tableItem.setMain(true);
            }
            tableItems.add(tableItem);
        } else if (sqlTableSource instanceof SQLJoinTableSource) {
            SQLJoinTableSource sqlJoinTableSource = (SQLJoinTableSource) sqlTableSource;
            SQLTableSource leftTableSource = sqlJoinTableSource.getLeft();
            visitSelectTable(schemaItem, leftTableSource, tableItems, null);
            SQLTableSource rightTableSource = sqlJoinTableSource.getRight();
            TableItem rightTableItem = new TableItem(schemaItem);
            // 解析on条件字段
            visitOnCondition(sqlJoinTableSource.getCondition(), rightTableItem);
            visitSelectTable(schemaItem, rightTableSource, tableItems, rightTableItem);

        } else if (sqlTableSource instanceof SQLSubqueryTableSource) {
            SQLSubqueryTableSource subQueryTableSource = (SQLSubqueryTableSource) sqlTableSource;
            MySqlSelectQueryBlock sqlSelectQuery = (MySqlSelectQueryBlock) subQueryTableSource.getSelect().getQuery();
            TableItem tableItem;
            if (tableItemTmp != null) {
                tableItem = tableItemTmp;
            } else {
                tableItem = new TableItem(schemaItem);
            }
            tableItem.setAlias(subQueryTableSource.getAlias());
            tableItem.setSubQuerySql(SQLUtils.toMySqlString(sqlSelectQuery));
            tableItem.setSubQuery(true);
            tableItem.setSubQueryFields(collectSelectQueryFields(sqlSelectQuery));
            visitSelectTable(schemaItem, sqlSelectQuery.getFrom(), tableItems, tableItem);
        }
    }"
"public void readLines(LineHandler lineHandler) throws IORuntimeException{
		BufferedReader reader = null;
		try {
			reader = FileUtil.getReader(file, charset);
			IoUtil.readLines(reader, lineHandler);
		} finally {
			IoUtil.close(reader);
		}
	}"
"@CheckReturnValue
    private boolean loadMasterKillSwitchFile(@Nonnull File f) {
        try {
            if (!f.exists())    return true;
            return Boolean.parseBoolean(FileUtils.readFileToString(f).trim());
        } catch (IOException e) {
            LOGGER.log(WARNING, ""Failed to read ""+f, e);
            return false;
        }
    }"
"public static Cluster getCluster(ConsumerBootstrap consumerBootstrap) {
        try {
            ConsumerConfig consumerConfig = consumerBootstrap.getConsumerConfig();
            ExtensionClass<Cluster> ext = ExtensionLoaderFactory.getExtensionLoader(Cluster.class)
                .getExtensionClass(consumerConfig.getCluster());
            if (ext == null) {
                throw ExceptionUtils.buildRuntime(""consumer.cluster"",
                    consumerConfig.getCluster(), ""Unsupported cluster of client!"");
            }
            return ext.getExtInstance(new Class[] { ConsumerBootstrap.class },
                new Object[] { consumerBootstrap });
        } catch (SofaRpcRuntimeException e) {
            throw e;
        } catch (Throwable e) {
            throw new SofaRpcRuntimeException(e.getMessage(), e);
        }
    }"
"public TouchActions scroll(int xOffset, int yOffset) {
    if (touchScreen != null) {
      action.addAction(new ScrollAction(touchScreen, xOffset, yOffset));
    }
    return this;
  }"
"public void substring(StringValue target, int start, int end) {
		target.setValue(this, start, end - start);
	}"
"public static KeyStore readKeyStore(String type, InputStream in, char[] password) {
		KeyStore keyStore = null;
		try {
			keyStore = KeyStore.getInstance(type);
			keyStore.load(in, password);
		} catch (Exception e) {
			throw new CryptoException(e);
		}
		return keyStore;
	}"
"static String[] translateCommandline(String toProcess) {
        if (toProcess == null || toProcess.length() == 0) {
            //no command? no string
            return new String[0];
        }
        // parse with a simple finite state machine

        final int normal = 0;
        final int inQuote = 1;
        final int inDoubleQuote = 2;
        int state = normal;
        final StringTokenizer tok = new StringTokenizer(toProcess, ""\""\' "", true);
        final ArrayList<String> result = new ArrayList<String>();
        final StringBuilder current = new StringBuilder();
        boolean lastTokenHasBeenQuoted = false;

        while (tok.hasMoreTokens()) {
            String nextTok = tok.nextToken();
            switch (state) {
                case inQuote:
                    if (""\'"".equals(nextTok)) {
                        lastTokenHasBeenQuoted = true;
                        state = normal;
                    } else {
                        current.append(nextTok);
                    }
                    break;
                case inDoubleQuote:
                    if (""\"""".equals(nextTok)) {
                        lastTokenHasBeenQuoted = true;
                        state = normal;
                    } else {
                        current.append(nextTok);
                    }
                    break;
                default:
                    if (""\'"".equals(nextTok)) {
                        state = inQuote;
                    } else if (""\"""".equals(nextTok)) {
                        state = inDoubleQuote;
                    } else if ("" "".equals(nextTok)) {
                        if (lastTokenHasBeenQuoted || current.length() != 0) {
                            result.add(current.toString());
                            current.setLength(0);
                        }
                    } else {
                        current.append(nextTok);
                    }
                    lastTokenHasBeenQuoted = false;
                    break;
            }
        }
        if (lastTokenHasBeenQuoted || current.length() != 0) {
            result.add(current.toString());
        }
        if (state == inQuote || state == inDoubleQuote) {
            throw new ParseException(""unbalanced quotes in "" + toProcess);
        }
        return result.toArray(new String[0]);
    }"
"private static String encode(String text, char[][] array) {
		int len;
		if ((text == null) || ((len = text.length()) == 0)) {
			return StrUtil.EMPTY;
		}
		StringBuilder buffer = new StringBuilder(len + (len >> 2));
		char c;
		for (int i = 0; i < len; i++) {
			c = text.charAt(i);
			if (c < 64) {
				buffer.append(array[c]);
			} else {
				buffer.append(c);
			}
		}
		return buffer.toString();
	}"
"public final void addStrings(Collection<String> strCollection)
    {
        if (sourceNode != null)
        {
            String previousString = """";

            //Add all the Strings in strCollection to the MDAG.
            for (String currentString : strCollection)
            {
                int mpsIndex = calculateMinimizationProcessingStartIndex(previousString, currentString);

                //If the _transition path of the previousString needs to be examined for minimization or
                //equivalence class representation after a certain point, call replaceOrRegister to do so.
                if (mpsIndex != -1)
                {

                    String transitionSubstring = previousString.substring(0, mpsIndex);
                    String minimizationProcessingSubString = previousString.substring(mpsIndex);
                    replaceOrRegister(sourceNode.transition(transitionSubstring), minimizationProcessingSubString);
                }
                /////

                addStringInternal(currentString);
                previousString = currentString;
            }
            /////

            //Since we delay the minimization of the previously-added String
            //until after we read the next one, we need to have a seperate
            //statement to minimize the absolute last String.
            replaceOrRegister(sourceNode, previousString);
        }
        else
        {
            unSimplify();
            addStrings(strCollection);
        }
    }"
"public Builder merge(Span source) {
      if (traceId == null) traceId = source.traceId;
      if (id == null) id = source.id;
      if (parentId == null) parentId = source.parentId;
      if (kind == null) kind = source.kind;
      if (name == null) name = source.name;
      if (timestamp == 0L) timestamp = source.timestamp;
      if (duration == 0L) duration = source.duration;
      if (localEndpoint == null) {
        localEndpoint = source.localEndpoint;
      } else if (source.localEndpoint != null) {
        localEndpoint = localEndpoint.toBuilder().merge(source.localEndpoint).build();
      }
      if (remoteEndpoint == null) {
        remoteEndpoint = source.remoteEndpoint;
      } else if (source.remoteEndpoint != null) {
        remoteEndpoint = remoteEndpoint.toBuilder().merge(source.remoteEndpoint).build();
      }
      if (!source.annotations.isEmpty()) {
        if (annotations == null) {
          annotations = new ArrayList<>(source.annotations.size());
        }
        annotations.addAll(source.annotations);
      }
      if (!source.tags.isEmpty()) {
        if (tags == null) tags = new TreeMap<>();
        tags.putAll(source.tags);
      }
      flags = flags | source.flags;
      return this;
    }"
"@GetMapping(path = SamlIdPConstants.ENDPOINT_SAML2_SLO_PROFILE_REDIRECT)
    protected void handleSaml2ProfileSLOPostRequest(final HttpServletResponse response,
                                                    final HttpServletRequest request) throws Exception {
        val decoder = getSamlProfileHandlerConfigurationContext().getSamlMessageDecoders().getInstance(HttpMethod.GET);
        handleSloProfileRequest(response, request, decoder);
    }"
"@Override
    public String getEscapedValue(String value, boolean toQuote) {
        // Escape special characters
        StringBuilder buf = new StringBuilder(value.length());
        int idx = 0;
        int ch;

        while (idx < value.length()) {
            ch = value.charAt(idx++);
            if (ch == 0) {
                buf.append(""\\0"");

            } else if (ch == 92) { // backslash
                buf.append(""\\\\"");

            } else if (ch == 124) { // vertical bar
                // 124 = ""|"" = AbstractSerializationStream.RPC_SEPARATOR_CHAR
                buf.append(""\\!"");

            } else if ((ch >= 0xD800) && (ch < 0xFFFF)) {
                buf.append(String.format(""\\u%04x"", ch));

            } else {
                buf.append((char) ch);
            }
        }

        return buf.toString();
    }"
"static <T> ConvertibleValues<T> of(Environment environment, Map<? extends CharSequence, T> values) {
        if (values == null) {
            return ConvertibleValuesMap.empty();
        } else {
            return new EnvironmentConvertibleValuesMap<>(values, environment);
        }
    }"
"public Path[] getFilePaths() {

		if (supportsMultiPaths()) {
			if (this.filePaths == null) {
				return new Path[0];
			}
			return this.filePaths;
		} else {
			if (this.filePath == null) {
				return new Path[0];
			}
			return new Path[] {filePath};
		}
	}"
"public Project getProject(final int id) {
    Project fetchedProject = this.projectsById.get(id);
    if (fetchedProject == null) {
      try {
        fetchedProject = this.projectLoader.fetchProjectById(id);
      } catch (final ProjectManagerException e) {
        logger.error(""Could not load project from store."", e);
      }
    }
    return fetchedProject;
  }"
"public final void parseSingleTableWithoutAlias(final SQLStatement sqlStatement) {
        int beginPosition = lexerEngine.getCurrentToken().getEndPosition() - lexerEngine.getCurrentToken().getLiterals().length();
        String literals = lexerEngine.getCurrentToken().getLiterals();
        int skippedSchemaNameLength = 0;
        lexerEngine.nextToken();
        if (lexerEngine.skipIfEqual(Symbol.DOT)) {
            skippedSchemaNameLength = literals.length() + Symbol.DOT.getLiterals().length();
            literals = lexerEngine.getCurrentToken().getLiterals();
            lexerEngine.nextToken();
        }
        sqlStatement.addSQLToken(new TableToken(beginPosition, literals, QuoteCharacter.getQuoteCharacter(literals), skippedSchemaNameLength));
        sqlStatement.getTables().add(new Table(SQLUtil.getExactlyValue(literals), null));
    }"
"public static synchronized DecoderWrapper resolveDecoder(String name, String eurekaAccept) {
        EurekaAccept accept = EurekaAccept.fromString(eurekaAccept);
        switch (accept) {
            case compact:
                return getDecoder(JacksonJsonMini.class);
            case full:
            default:
                return getDecoder(name);
        }
    }"
"@Deprecated
    @RestrictedSince(""1.651.2 / 2.TODO"")
    @Restricted(NoExternalUse.class)
    public static boolean isAbsoluteUri(@Nonnull String uri) {
        int idx = uri.indexOf(':');
        if (idx<0)  return false;   // no ':'. can't be absolute

        // #, ?, and / must not be before ':'
        return idx<_indexOf(uri, '#') && idx<_indexOf(uri,'?') && idx<_indexOf(uri,'/');
    }"
"public SslContextBuilder ciphers(Iterable<String> ciphers, CipherSuiteFilter cipherFilter) {
        checkNotNull(cipherFilter, ""cipherFilter"");
        this.ciphers = ciphers;
        this.cipherFilter = cipherFilter;
        return this;
    }"
"private synchronized void _release(@Nonnull FilePath p) {
        Entry old = inUse.get(p.getRemote());
        if (old==null)
            throw new AssertionError(""Releasing unallocated workspace ""+p);
        if (LOGGER.isLoggable(Level.FINE)) {
            LOGGER.log(Level.FINE, ""releasing "" + p + "" with lock count "" + old.lockCount, new Throwable(""from "" + this));
        }
        old.lockCount--;
        if (old.lockCount==0)
            inUse.remove(p.getRemote());
        notifyAll();
    }"
"@Override public final int size(){
      if( _size != 0 ) return _size; // Cached size

      assert _nodeType == 0:""unexpected node type: "" + _nodeType;
      if(_split._equal != 0)
        _nodeType |= _split._equal == 1 ? 4 : (_split._equal == 2 ? 8 : 12);

      // int res = 7;  // 1B node type + flags, 2B colId, 4B float split val
      // 1B node type + flags, 2B colId, 4B split val/small group or (2B offset + 4B size) + large group
      int res = _split._equal == 3 ? 9 + _split._bs.numBytes() : 7;

      // NA handling correction
      res++; //1 byte for NA split dir
      if (_split._nasplit == DHistogram.NASplitDir.NAvsREST)
        res -= _split._equal == 3 ? 6 + _split._bs.numBytes() : 4; //don't need certain stuff

      Node left = _tree.node(_nids[0]);
      int lsz = left.size();
      res += lsz;
      if( left instanceof LeafNode ) _nodeType |= (byte)48;
      else {
        int slen = lsz < 256 ? 0 : (lsz < 65535 ? 1 : (lsz<(1<<24) ? 2 : 3));
        _nodeType |= slen; // Set the size-skip bits
        res += (slen+1); //
      }

      Node right = _tree.node(_nids[1]);
      if( right instanceof LeafNode ) _nodeType |= (byte)(48 << 2);
      res += right.size();
      assert (_nodeType&0x33) != 51;
      assert res != 0;
      return (_size = res);
    }"
"public Solution getSolution(String id) {
        for( Solution s : Solution.all() )
            if(s.id.equals(id))
                return s;
        return null;
    }"
"private static AbstractInvokable loadAndInstantiateInvokable(
		ClassLoader classLoader,
		String className,
		Environment environment) throws Throwable {

		final Class<? extends AbstractInvokable> invokableClass;
		try {
			invokableClass = Class.forName(className, true, classLoader)
				.asSubclass(AbstractInvokable.class);
		} catch (Throwable t) {
			throw new Exception(""Could not load the task's invokable class."", t);
		}

		Constructor<? extends AbstractInvokable> statelessCtor;

		try {
			statelessCtor = invokableClass.getConstructor(Environment.class);
		} catch (NoSuchMethodException ee) {
			throw new FlinkException(""Task misses proper constructor"", ee);
		}

		// instantiate the class
		try {
			//noinspection ConstantConditions  --> cannot happen
			return statelessCtor.newInstance(environment);
		} catch (InvocationTargetException e) {
			// directly forward exceptions from the eager initialization
			throw e.getTargetException();
		} catch (Exception e) {
			throw new FlinkException(""Could not instantiate the task's invokable class."", e);
		}
	}"
"@Override
  public TwoDimTableV3 fillFromImpl(TwoDimTable t) {
    name = t.getTableHeader();
    description = t.getTableDescription();
    final int rows = t.getRowDim();
    rowcount = rows;
    boolean have_row_header_cols = t.getColHeaderForRowHeaders() != null;
    for (int r=0; r<rows; ++r) {
      if (!have_row_header_cols) break;
      have_row_header_cols &= t.getRowHeaders()[r] != null;
    }
    if (have_row_header_cols) {
      final int cols = t.getColDim()+1;
      columns = new ColumnSpecsBase[cols];
      columns[0] = new ColumnSpecsBase();
      columns[0].name = pythonify(t.getColHeaderForRowHeaders());
      columns[0].type = ""string"";
      columns[0].format = ""%s"";
      columns[0].description = t.getColHeaderForRowHeaders();
      for (int c = 1; c < cols; ++c) {
        columns[c] = new ColumnSpecsBase();
        columns[c].name = pythonify(t.getColHeaders()[c - 1]);
        columns[c].type = t.getColTypes()[c - 1];
        columns[c].format = t.getColFormats()[c - 1];
        columns[c].description = t.getColHeaders()[c - 1];
      }
      data = new IcedWrapper[cols][rows];
      data[0] = new IcedWrapper[t.getRowDim()];
      for (int r = 0; r < t.getRowDim(); ++r) {
        data[0][r] = new IcedWrapper(t.getRowHeaders()[r]);
      }
      IcedWrapper[][] cellValues = t.getCellValues();
      for (int c = 1; c < cols; ++c) {
        data[c] = new IcedWrapper[rows];
        for (int r = 0; r < rows; ++r) {
          data[c][r] = cellValues[r][c - 1];
        }
      }
    } else {
      final int cols = t.getColDim();
      columns = new ColumnSpecsBase[cols];
      for (int c = 0; c < cols; ++c) {
        columns[c] = new ColumnSpecsBase();
        columns[c].name = pythonify(t.getColHeaders()[c]);
        columns[c].type = t.getColTypes()[c];
        columns[c].format = t.getColFormats()[c];
        columns[c].description = t.getColHeaders()[c];
      }
      data = new IcedWrapper[cols][rows];
      IcedWrapper[][] cellValues = t.getCellValues();
      for (int c = 0; c < cols; ++c) {
        data[c] = new IcedWrapper[rows];
        for (int r = 0; r < rows; ++r) {
          data[c][r] = cellValues[r][c];
        }
      }
    }
    return this;
  }"
"@Override
  public List<Pair<ExecutableFlow, Optional<Executor>>> getActiveFlowsWithExecutor()
      throws IOException {
    final List<Pair<ExecutableFlow, Optional<Executor>>> flows =
        new ArrayList<>();
    getActiveFlowsWithExecutorHelper(flows, this.queuedFlows.getAllEntries());
    getActiveFlowsWithExecutorHelper(flows, this.runningExecutions.get().values());
    return flows;
  }"
"public static ProviderInfo convertProviderToProviderInfo(ProviderConfig config, ServerConfig server) {
        ProviderInfo providerInfo = new ProviderInfo()
            .setPort(server.getPort())
            .setWeight(config.getWeight())
            .setSerializationType(config.getSerialization())
            .setProtocolType(server.getProtocol())
            .setPath(server.getContextPath());
        String host = server.getHost();
        if (NetUtils.isLocalHost(host) || NetUtils.isAnyHost(host)) {
            host = SystemInfo.getLocalHost();
        }
        providerInfo.setHost(host);
        return providerInfo;
    }"
"private static String getXForwardedHeader(StaplerRequest req, String header, String defaultValue) {
        String value = req.getHeader(header);
        if (value != null) {
            int index = value.indexOf(',');
            return index == -1 ? value.trim() : value.substring(0,index).trim();
        }
        return defaultValue;
    }"
"static boolean checkStandardUPCEANChecksum(CharSequence s) throws FormatException {
    int length = s.length();
    if (length == 0) {
      return false;
    }
    int check = Character.digit(s.charAt(length - 1), 10);
    return getStandardUPCEANChecksum(s.subSequence(0, length - 1)) == check;
  }"
"private void recoverAndCommitInternal(TransactionHolder<TXN> transactionHolder) {
		try {
			logWarningIfTimeoutAlmostReached(transactionHolder);
			recoverAndCommit(transactionHolder.handle);
		} catch (final Exception e) {
			final long elapsedTime = clock.millis() - transactionHolder.transactionStartTime;
			if (ignoreFailuresAfterTransactionTimeout && elapsedTime > transactionTimeout) {
				LOG.error(""Error while committing transaction {}. "" +
						""Transaction has been open for longer than the transaction timeout ({})."" +
						""Commit will not be attempted again. Data loss might have occurred."",
					transactionHolder.handle, transactionTimeout, e);
			} else {
				throw e;
			}
		}
	}"
"private static List<String> buildCommand(
      AbstractCommandBuilder builder,
      Map<String, String> env,
      boolean printLaunchCommand) throws IOException, IllegalArgumentException {
    List<String> cmd = builder.buildCommand(env);
    if (printLaunchCommand) {
      System.err.println(""Spark Command: "" + join("" "", cmd));
      System.err.println(""========================================"");
    }
    return cmd;
  }"
"public static long between(Date beginDate, Date endDate, DateUnit unit) {
		return between(beginDate, endDate, unit, true);
	}"
"long expireAfterCreate(@Nullable K key, @Nullable V value, Expiry<K, V> expiry, long now) {
    if (expiresVariable() && (key != null) && (value != null)) {
      long duration = expiry.expireAfterCreate(key, value, now);
      return isAsync ? (now + duration) : (now + Math.min(duration, MAXIMUM_EXPIRY));
    }
    return 0L;
  }"
"public Entity queryOne(String sql, Object... params) throws SQLException {
		return query(sql, new EntityHandler(), params);
	}"
"public static DataRowsFacade normalize(DataRowsFacade dataFrame, double min, double max) {
        return normalize(dataFrame, min, max, Collections.<String>emptyList());
    }"
"@SuppressWarnings(""unchecked, rawtype"")
	private GroupByStateNameResults groupByStateMode(List<List<OperatorStateHandle>> previousParallelSubtaskStates) {

		//Reorganize: group by (State Name -> StreamStateHandle + StateMetaInfo)
		EnumMap<OperatorStateHandle.Mode,
				Map<String, List<Tuple2<StreamStateHandle, OperatorStateHandle.StateMetaInfo>>>> nameToStateByMode =
				new EnumMap<>(OperatorStateHandle.Mode.class);

		for (OperatorStateHandle.Mode mode : OperatorStateHandle.Mode.values()) {

			nameToStateByMode.put(
					mode,
					new HashMap<>());
		}

		for (List<OperatorStateHandle> previousParallelSubtaskState : previousParallelSubtaskStates) {
			for (OperatorStateHandle operatorStateHandle : previousParallelSubtaskState) {

				if (operatorStateHandle == null) {
					continue;
				}

				final Set<Map.Entry<String, OperatorStateHandle.StateMetaInfo>> partitionOffsetEntries =
					operatorStateHandle.getStateNameToPartitionOffsets().entrySet();

				for (Map.Entry<String, OperatorStateHandle.StateMetaInfo> e : partitionOffsetEntries) {
					OperatorStateHandle.StateMetaInfo metaInfo = e.getValue();

					Map<String, List<Tuple2<StreamStateHandle, OperatorStateHandle.StateMetaInfo>>> nameToState =
						nameToStateByMode.get(metaInfo.getDistributionMode());

					List<Tuple2<StreamStateHandle, OperatorStateHandle.StateMetaInfo>> stateLocations =
						nameToState.computeIfAbsent(
							e.getKey(),
							k -> new ArrayList<>(previousParallelSubtaskStates.size() * partitionOffsetEntries.size()));

					stateLocations.add(Tuple2.of(operatorStateHandle.getDelegateStateHandle(), e.getValue()));
				}
			}
		}

		return new GroupByStateNameResults(nameToStateByMode);
	}"
"public static BinaryString blankString(int length) {
		byte[] spaces = new byte[length];
		Arrays.fill(spaces, (byte) ' ');
		return fromBytes(spaces);
	}"
"public void put(String key, V value)
    {
        if (key.length() == 0) return;  // 安全起见
        BaseNode branch = this;
        char[] chars = key.toCharArray();
        for (int i = 0; i < chars.length - 1; ++i)
        {
            // 除了最后一个字外，都是继续
            branch.addChild(new Node(chars[i], Status.NOT_WORD_1, null));
            branch = branch.getChild(chars[i]);
        }
        // 最后一个字加入时属性为end
        if (branch.addChild(new Node<V>(chars[chars.length - 1], Status.WORD_END_3, value)))
        {
            ++size; // 维护size
        }
    }"
"public static String timestampToString(long ts, int precision, TimeZone tz) {
		int p = (precision <= 3 && precision >= 0) ? precision : 3;
		String format = DEFAULT_DATETIME_FORMATS[p];
		return dateFormat(ts, format, tz);
	}"
"public void saveParam() throws Exception {
        Enumeration<AbstractParamPanel> en = tablePanel.elements();
        AbstractParamPanel panel = null;
        while (en.hasMoreElements()) {
            panel = en.nextElement();
            panel.saveParam(paramObject);
        }
    }"
"public static Pair<ComputationGraph, Normalizer> restoreComputationGraphAndNormalizer(
            @NonNull InputStream is, boolean loadUpdater) throws IOException {
        checkInputStream(is);

        File tmpFile = null;
        try {
            tmpFile = tempFileFromStream(is);
            return restoreComputationGraphAndNormalizer(tmpFile, loadUpdater);
        } finally {
            if (tmpFile != null) {
                tmpFile.delete();
            }
        }
    }"
"public static String convertUPCEtoUPCA(String upce) {
    char[] upceChars = new char[6];
    upce.getChars(1, 7, upceChars, 0);
    StringBuilder result = new StringBuilder(12);
    result.append(upce.charAt(0));
    char lastChar = upceChars[5];
    switch (lastChar) {
      case '0':
      case '1':
      case '2':
        result.append(upceChars, 0, 2);
        result.append(lastChar);
        result.append(""0000"");
        result.append(upceChars, 2, 3);
        break;
      case '3':
        result.append(upceChars, 0, 3);
        result.append(""00000"");
        result.append(upceChars, 3, 2);
        break;
      case '4':
        result.append(upceChars, 0, 4);
        result.append(""00000"");
        result.append(upceChars[4]);
        break;
      default:
        result.append(upceChars, 0, 5);
        result.append(""0000"");
        result.append(lastChar);
        break;
    }
    // Only append check digit in conversion if supplied
    if (upce.length() >= 8) {
      result.append(upce.charAt(7));
    }
    return result.toString();
  }"
"public final double[] eval(String[] context, double[] outsums)
    {
        assert context != null;
        int[] scontexts = new int[context.length];
        for (int i = 0; i < context.length; i++)
        {
            Integer ci = pmap.get(context[i]);
            scontexts[i] = ci == null ? -1 : ci;
        }
        prior.logPrior(outsums);
        return eval(scontexts, outsums, evalParams);
    }"
"public FormValidation verifySignature(JSONObject o) throws IOException {
        try {
            FormValidation warning = null;

            JSONObject signature = o.getJSONObject(""signature"");
            if (signature.isNullObject()) {
                return FormValidation.error(""No signature block found in ""+name);
            }
            o.remove(""signature"");

            List<X509Certificate> certs = new ArrayList<>();
            {// load and verify certificates
                CertificateFactory cf = CertificateFactory.getInstance(""X509"");
                for (Object cert : signature.getJSONArray(""certificates"")) {
                    try {
                        X509Certificate c = (X509Certificate) cf.generateCertificate(new ByteArrayInputStream(Base64.getDecoder().decode(cert.toString().getBytes(StandardCharsets.UTF_8))));
                        try {
                            c.checkValidity();
                        } catch (CertificateExpiredException e) { // even if the certificate isn't valid yet, we'll proceed it anyway
                            warning = FormValidation.warning(e, String.format(""Certificate %s has expired in %s"", cert.toString(), name));
                        } catch (CertificateNotYetValidException e) {
                            warning = FormValidation.warning(e, String.format(""Certificate %s is not yet valid in %s"", cert.toString(), name));
                        }
                        LOGGER.log(Level.FINE, ""Add certificate found in json doc: \r\n\tsubjectDN: {0}\r\n\tissuer: {1}"", new Object[]{c.getSubjectDN(), c.getIssuerDN()});
                        certs.add(c);
                    } catch (IllegalArgumentException ex) {
                        throw new IOException(""Could not decode certificate"", ex);
                    }
                }

                CertificateUtil.validatePath(certs, loadTrustAnchors(cf));
            }

            if (certs.isEmpty()) {
                return FormValidation.error(""No certificate found in %s. Cannot verify the signature"", name);
            }

            // check the better digest first
            FormValidation resultSha512 = null;
            try {
                MessageDigest digest = MessageDigest.getInstance(""SHA-512"");
                Signature sig = Signature.getInstance(""SHA512withRSA"");
                sig.initVerify(certs.get(0));
                resultSha512 = checkSpecificSignature(o, signature, digest, ""correct_digest512"", sig, ""correct_signature512"", ""SHA-512"");
                switch (resultSha512.kind) {
                    case ERROR:
                        return resultSha512;
                    case WARNING:
                        LOGGER.log(Level.INFO, ""JSON data source '"" + name + ""' does not provide a SHA-512 content checksum or signature. Looking for SHA-1."");
                        break;
                    case OK:
                        // fall through
                }
            } catch (NoSuchAlgorithmException nsa) {
                LOGGER.log(Level.WARNING, ""Failed to verify potential SHA-512 digest/signature, falling back to SHA-1"", nsa);
            }

            // if we get here, SHA-512 passed, wasn't provided, or the JRE is terrible.

            MessageDigest digest = MessageDigest.getInstance(""SHA1"");
            Signature sig = Signature.getInstance(""SHA1withRSA"");
            sig.initVerify(certs.get(0));
            FormValidation resultSha1 = checkSpecificSignature(o, signature, digest, ""correct_digest"", sig, ""correct_signature"", ""SHA-1"");

            switch (resultSha1.kind) {
                case ERROR:
                    return resultSha1;
                case WARNING:
                    if (resultSha512.kind == FormValidation.Kind.WARNING) {
                        // neither signature provided
                        return FormValidation.error(""No correct_signature or correct_signature512 entry found in '"" + name + ""'."");
                    }
                case OK:
                    // fall through
            }

            if (warning!=null)  return warning;
            return FormValidation.ok();
        } catch (GeneralSecurityException e) {
            return FormValidation.error(e, ""Signature verification failed in ""+name);
        }
    }"
"public static boolean isRuleWord(String word) {
        char c = 0;
        for (int i = 0; i < word.length(); i++) {
            c = word.charAt(i);

            if (c != '·') {
                if (c < 256 || filter.contains(c) || (c = WordAlert.CharCover(word.charAt(i))) > 0) {
                    return true;
                }
            }
        }
        return false;
    }"
"public static byte[] bufferToArray(ByteBuffer buffer) {
    if (buffer.hasArray() && buffer.arrayOffset() == 0 &&
        buffer.array().length == buffer.remaining()) {
      return buffer.array();
    } else {
      byte[] bytes = new byte[buffer.remaining()];
      buffer.get(bytes);
      return bytes;
    }
  }"
"public final int getBeInt32(final int pos) {
        final int position = origin + pos;

        if (pos + 3 >= limit || pos < 0) throw new IllegalArgumentException(""limit excceed: ""
                                                                            + (pos < 0 ? pos : (pos + 3)));

        byte[] buf = buffer;
        return (0xff & buf[position + 3]) | ((0xff & buf[position + 2]) << 8) | ((0xff & buf[position + 1]) << 16)
               | ((buf[position]) << 24);
    }"
"public void append(final byte[] b, final int off, final int len) {
        if (b == null) {
            return;
        }
        if ((off < 0) || (off > b.length) || (len < 0) ||
                ((off + len) < 0) || ((off + len) > b.length)) {
            throw new IndexOutOfBoundsException(""off: ""+off+"" len: ""+len+"" b.length: ""+b.length);
        }
        if (len == 0) {
            return;
        }
        final int newlen = this.len + len;
        if (newlen > this.array.length) {
            expand(newlen);
        }
        System.arraycopy(b, off, this.array, this.len, len);
        this.len = newlen;
    }"
"public static INDArray im2col(INDArray img, int kh, int kw, int sy, int sx, int ph, int pw, int pval,
                                  boolean isSameMode) {
        INDArray output = null;

        if (isSameMode) {
            int oH = (int) Math.ceil(img.size(2) * 1.f / sy);
            int oW = (int) Math.ceil(img.size(3) * 1.f / sx);

            output = Nd4j.createUninitialized(img.dataType(), new long[]{img.size(0), img.size(1), kh, kw, oH, oW}, 'c');
        } else {
            // FIXME: int cast
            int oH = ((int) img.size(2) - (kh + (kh - 1) * (1 - 1)) + 2 * ph) / sy + 1;
            int oW = ((int) img.size(3) - (kw + (kw - 1) * (1 - 1)) + 2 * pw) / sx + 1;

            output = Nd4j.createUninitialized(img.dataType(), new long[]{img.size(0), img.size(1), kh, kw, oH, oW}, 'c');
        }

        Im2col im2col = Im2col.builder()
                .inputArrays(new INDArray[]{img})
                .outputs(new INDArray[]{output})
                .conv2DConfig(Conv2DConfig.builder()
                        .pW(pw)
                        .pH(ph)
                        .sH(sy)
                        .sW(sx)
                        .kW(kw)
                        .kH(kh)
                        .dW(1)
                        .dH(1)
                        .isSameMode(isSameMode)
                        .build()).build();

        Nd4j.getExecutioner().execAndReturn(im2col);
        return im2col.outputArguments()[0];
    }"
"public String toFString(int digits) {
        if (b.compareTo(BigInteger.ONE) != 0) {
            MathContext mc = new MathContext(digits, RoundingMode.DOWN);
            BigDecimal f = (new BigDecimal(a)).divide(new BigDecimal(b), mc);
            return (f.toString());
        } else {
            return a.toString();
        }
    }"
"public String serialize(Object o) {
        ObjectMapper om = getObjectMapper();
        try {
            return om.writeValueAsString(o);
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    }"
"protected List<HttpMessage> getSelectedMessages(HttpMessageContainer httpMessageContainer) {
        if (httpMessageContainer instanceof SelectableHttpMessagesContainer) {
            return ((SelectableHttpMessagesContainer) httpMessageContainer).getSelectedMessages();
        } else if (httpMessageContainer instanceof SingleHttpMessageContainer) {
            SingleHttpMessageContainer singleMessageContainer = (SingleHttpMessageContainer) httpMessageContainer;
            if (!singleMessageContainer.isEmpty()) {
                List<HttpMessage> selectedHttpMessages = new ArrayList<>(1);
                selectedHttpMessages.add((((SingleHttpMessageContainer) httpMessageContainer).getMessage()));
                return selectedHttpMessages;
            }
        }

        return Collections.emptyList();
    }"
"public static <KeyType> int requiredBufferCapacity(
      KeySerde<KeyType> keySerde,
      AggregatorFactory[] aggregatorFactories
  )
  {
    int recordSize = keySerde.keySize();
    for (AggregatorFactory aggregatorFactory : aggregatorFactories) {
      recordSize += aggregatorFactory.getMaxIntermediateSizeWithNulls();
    }
    return recordSize * 3;
  }"
"private void resetLoggedInOutIndicators() {
		getLoggedInIndicaterRegexField().setToolTipText(null);
		getLoggedInIndicaterRegexField().setEnabled(true);
		getLoggedOutIndicaterRegexField().setToolTipText(null);
		getLoggedOutIndicaterRegexField().setEnabled(true);
	}"
"public static boolean pathEquals(String path1, String path2) {
        return cleanPath(path1).equals(cleanPath(path2));
    }"
"private List<FileData> doFileExtract(RowBatch rowBatch) {
        List<FileData> fileDatas = new ArrayList<FileData>();
        // 处理数据
        Pipeline pipeline = getPipeline(rowBatch.getIdentity().getPipelineId());
        List<EventData> eventDatas = rowBatch.getDatas();
        for (EventData eventData : eventDatas) {
            if (eventData.getEventType().isDdl()) {
                continue;
            }

            List<DataMediaPair> dataMediaPairs = ConfigHelper.findDataMediaPairByMediaId(pipeline,
                                                                                         eventData.getTableId());
            if (dataMediaPairs == null) {
                throw new ExtractException(""ERROR ## the dataMediaId = "" + eventData.getTableId()
                                           + "" dataMediaPair is null,please check"");
            }

            for (DataMediaPair dataMediaPair : dataMediaPairs) {
                if (dataMediaPair.getResolverData() == null
                    || dataMediaPair.getResolverData().getExtensionDataType() == null
                    || (dataMediaPair.getResolverData().getExtensionDataType().isClazz() && StringUtils.isBlank(dataMediaPair.getResolverData().getClazzPath()))
                    || (dataMediaPair.getResolverData().getExtensionDataType().isSource() && StringUtils.isBlank(dataMediaPair.getResolverData().getSourceText()))) {
                    continue;
                }

                FileResolver fileResolver = null;

                if (dataMediaPair.getResolverData() != null) {
                    fileResolver = extensionFactory.getExtension(FileResolver.class, dataMediaPair.getResolverData());
                } else {
                    continue;
                }

                if (fileResolver == null) {
                    throw new ExtractException(""ERROR ## the dataMediaId = "" + eventData.getTableId()
                                               + "" the fileResolver className  = ""
                                               + dataMediaPair.getResolverData().getClazzPath()
                                               + "" is null ,please check the class"");
                }

                if (fileResolver instanceof RemoteDirectoryFetcherAware) {
                    RemoteDirectoryFetcherAware remoteDirectoryFetcherAware = (RemoteDirectoryFetcherAware) fileResolver;
                    remoteDirectoryFetcherAware.setRemoteDirectoryFetcher(arandaRemoteDirectoryFetcher);
                }

                List<FileData> singleRowFileDatas = getSingleRowFileInfos(dataMediaPair.getId(), fileResolver,
                                                                          eventData);
                // 做一下去重处理
                for (FileData data : singleRowFileDatas) {
                    if (!fileDatas.contains(data)) {
                        fileDatas.add(data);
                    }
                }
            }
        }

        // 判断是否需要进行图片重复同步检查
        if (pipeline.getParameters().getFileDetect()) {
            doFileDetectCollector(pipeline, fileDatas);
        }
        return fileDatas;
    }"
"final boolean clear(String hostname) {
        Entries entries = resolveCache.remove(hostname);
        return entries != null && entries.clearAndCancel();
    }"
"public static ExtractionResult fromPredicate(
            Metadata metadata,
            Session session,
            Expression predicate,
            TypeProvider types)
    {
        return new Visitor(metadata, session, types).process(predicate, false);
    }"
"public static List<NT> viterbiCompute(List<EnumItem<NT>> roleTagList)
    {
        return Viterbi.computeEnum(roleTagList, OrganizationDictionary.transformMatrixDictionary);
    }"
"@SuppressWarnings(""unused"") // called through reflection by RequestServer
  public JobsV3 list(int version, JobsV3 s) {
    Job[] jobs = Job.jobs();
    // Jobs j = new Jobs();
    // j._jobs = Job.jobs();
    // PojoUtils.copyProperties(s, j, PojoUtils.FieldNaming.ORIGIN_HAS_UNDERSCORES);
    s.jobs = new JobV3[jobs.length];

    int i = 0;
    for (Job j : jobs) {
      try { s.jobs[i] = (JobV3) SchemaServer.schema(version, j).fillFromImpl(j); }
      // no special schema for this job subclass, so fall back to JobV3
      catch (H2ONotFoundArgumentException e) { s.jobs[i] = new JobV3().fillFromImpl(j); }
      i++; // Java does the increment before the function call which throws?!
    }
    return s;
  }"
"@Restricted(NoExternalUse.class)
    public static void skip(@Nonnull Iterator<?> iterator, int count) {
        if (count < 0) {
            throw new IllegalArgumentException();
        }
        while (iterator.hasNext() && count-- > 0) {
            iterator.next();
        }
    }"
"public static OpPredicate opNameMatches(final String regex){
        return new OpPredicate() {
            @Override
            public boolean matches(SameDiff sameDiff, DifferentialFunction function) {
                return function.getOwnName().matches(regex);
            }
        };
    }"
"public static int computeDefaultMaxParallelism(int operatorParallelism) {

		checkParallelismPreconditions(operatorParallelism);

		return Math.min(
				Math.max(
						MathUtils.roundUpToPowerOfTwo(operatorParallelism + (operatorParallelism / 2)),
						DEFAULT_LOWER_BOUND_MAX_PARALLELISM),
				UPPER_BOUND_MAX_PARALLELISM);
	}"
"public BinaryString hash(MessageDigest md) {
		String str = EncodingUtils.hex(md.digest(getBytes()));
		return fromString(str);
	}"
"@Override
    public INDArray create(List<INDArray> list, int[] shape) {
        if (order == FORTRAN)
            return new JCublasNDArray(list, shape, ArrayUtil.calcStridesFortran(shape));
        else
            return new JCublasNDArray(list, shape);
    }"
"protected void setupQueue() throws IOException {
		if (queueName != null) {
			channel.queueDeclare(queueName, false, false, false, null);
		}
	}"
"public static void writeStringToFile(String path, String toWrite, JavaSparkContext sc) throws IOException {
        writeStringToFile(path, toWrite, sc.sc());
    }"
"@Override
    public void setDType(DataType dtype) {
        assert dtype == DataType.DOUBLE || dtype == DataType.FLOAT
                        || dtype == DataType.INT : ""Invalid opType passed, must be float or double"";
        // this.dtype = dtype;
    }"
"public static ExpectedCondition<Boolean> urlContains(final String fraction) {
    return new ExpectedCondition<Boolean>() {
      private String currentUrl = """";

      @Override
      public Boolean apply(WebDriver driver) {
        currentUrl = driver.getCurrentUrl();
        return currentUrl != null && currentUrl.contains(fraction);
      }

      @Override
      public String toString() {
        return String.format(""url to contain \""%s\"". Current url: \""%s\"""", fraction, currentUrl);
      }
    };
  }"
"public boolean endsWith(String word)
    {
        word = reverse(word);
        return trie.commonPrefixSearchWithValue(word).size() > 0;
    }"
"public static Method getSetter(String fieldName, Class<?> clazz, Class<?> fieldType) {
    String setterName = ""set"" + Character.toTitleCase(fieldName.charAt(0)) + fieldName.substring(1, fieldName.length());
    try {
      // Using getMethods(), getMethod(...) expects exact parameter type
      // matching and ignores inheritance-tree.
      Method[] methods = clazz.getMethods();
      for (Method method : methods) {
        if (method.getName().equals(setterName)) {
          Class<?>[] paramTypes = method.getParameterTypes();
          if (paramTypes != null && paramTypes.length == 1 && paramTypes[0].isAssignableFrom(fieldType)) {
            return method;
          }
        }
      }
      return null;
    } catch (SecurityException e) {
      throw new ActivitiException(""Not allowed to access method "" + setterName + "" on class "" + clazz.getCanonicalName());
    }
  }"
"private static int findNodesToRelocate(final int[] array, final int maximumLength) {
        int currentNode = array.length - 2;
        for (int currentDepth = 1; currentDepth < maximumLength - 1 && currentNode > 1; currentDepth++) {
            currentNode =  first(array, currentNode - 1, 0);
        }
        return currentNode;
    }"
"public Bindable<T> withAnnotations(Annotation... annotations) {
		return new Bindable<>(this.type, this.boxedType, this.value,
				(annotations != null) ? annotations : NO_ANNOTATIONS);
	}"
"private String getStackTrace(Throwable ex) {
        StringWriter out = new StringWriter();
        ex.printStackTrace(new PrintWriter(out));
        return out.getBuffer().toString();
    }"
"private void useClientCertificateCheckBoxActionPerformed(java.awt.event.ActionEvent evt) {//GEN-FIRST:event_useClientCertificateCheckBoxActionPerformed
		// The enable unsafe SSL renegotiation checkbox is independent of using a client certificate (although commonly related)
		// enableUnsafeSSLRenegotiationCheckBox.setEnabled(useClientCertificateCheckBox.isSelected());

		//keyStore tab
		certificatejTabbedPane.setEnabled(useClientCertificateCheckBox.isSelected() );

		keyStoreScrollPane.setEnabled(useClientCertificateCheckBox.isSelected());
		keyStoreList.setEnabled(useClientCertificateCheckBox.isSelected());

		aliasScrollPane.setEnabled(useClientCertificateCheckBox.isSelected());
		aliasTable.setEnabled(useClientCertificateCheckBox.isSelected());

		deleteButton.setEnabled(useClientCertificateCheckBox.isSelected() );
		setActiveButton.setEnabled(useClientCertificateCheckBox.isSelected() );
		showAliasButton.setEnabled(useClientCertificateCheckBox.isSelected() );

		//pkcs12 tab
		fileTextField.setEnabled(useClientCertificateCheckBox.isSelected() );
		browseButton.setEnabled(useClientCertificateCheckBox.isSelected() );
		pkcs12PasswordField.setEnabled(useClientCertificateCheckBox.isSelected() );
		addPkcs12Button.setEnabled(useClientCertificateCheckBox.isSelected() );

		//pkcs11 tab
		driverComboBox.setEnabled(useClientCertificateCheckBox.isSelected() );
		driverButton.setEnabled(useClientCertificateCheckBox.isSelected() );
		pkcs11PasswordField.setEnabled(useClientCertificateCheckBox.isSelected() );
		addPkcs11Button.setEnabled(useClientCertificateCheckBox.isSelected() );
		usePkcs11ExperimentalSliSupportCheckBox.setEnabled(useClientCertificateCheckBox.isSelected());
		usePkcs11ExperimentalSliSupportCheckBox.setSelected(Model.getSingleton().getOptionsParam().getExperimentalFeaturesParam().isExerimentalSliSupportEnabled());

		//actual certificate fields
		certificateTextField.setEnabled(useClientCertificateCheckBox.isSelected() );
		showActiveCertificateButton.setEnabled(useClientCertificateCheckBox.isSelected() );

	}"
"private static List<Interval> findInitialSearchInterval(
      VersionedIntervalTimeline<String, DataSegment> timeline,
      Period skipOffset,
      @Nullable List<Interval> skipIntervals
  )
  {
    Preconditions.checkArgument(timeline != null && !timeline.isEmpty(), ""timeline should not be null or empty"");
    Preconditions.checkNotNull(skipOffset, ""skipOffset"");

    final TimelineObjectHolder<String, DataSegment> first = Preconditions.checkNotNull(timeline.first(), ""first"");
    final TimelineObjectHolder<String, DataSegment> last = Preconditions.checkNotNull(timeline.last(), ""last"");
    final List<Interval> fullSkipIntervals = sortAndAddSkipIntervalFromLatest(
        last.getInterval().getEnd(),
        skipOffset,
        skipIntervals
    );

    final Interval totalInterval = new Interval(first.getInterval().getStart(), last.getInterval().getEnd());
    final List<Interval> filteredInterval = filterSkipIntervals(totalInterval, fullSkipIntervals);
    final List<Interval> searchIntervals = new ArrayList<>();

    for (Interval lookupInterval : filteredInterval) {
      final List<TimelineObjectHolder<String, DataSegment>> holders = timeline.lookup(
          new Interval(lookupInterval.getStart(), lookupInterval.getEnd())
      );

      final List<DataSegment> segments = holders
          .stream()
          .flatMap(holder -> StreamSupport.stream(holder.getObject().spliterator(), false))
          .map(PartitionChunk::getObject)
          .filter(segment -> lookupInterval.contains(segment.getInterval()))
          .sorted((s1, s2) -> Comparators.intervalsByStartThenEnd().compare(s1.getInterval(), s2.getInterval()))
          .collect(Collectors.toList());

      if (!segments.isEmpty()) {
        searchIntervals.add(
            new Interval(
                segments.get(0).getInterval().getStart(),
                segments.get(segments.size() - 1).getInterval().getEnd()
            )
        );
      }
    }

    return searchIntervals;
  }"
"@Override
    public void closeAllClientTransports(DestroyHook destroyHook) {
        // 清空所有列表,不让再调了
        Map<ProviderInfo, ClientTransport> all = clearProviders();
        if (destroyHook != null) {
            try {
                destroyHook.preDestroy();
            } catch (Exception e) {
                if (LOGGER.isWarnEnabled(consumerConfig.getAppName())) {
                    LOGGER.warnWithApp(consumerConfig.getAppName(), e.getMessage(), e);
                }
            }
        }
        // 多线程销毁已经建立的连接
        int providerSize = all.size();
        if (providerSize > 0) {
            int timeout = consumerConfig.getDisconnectTimeout();
            int threads = Math.min(10, providerSize); // 最大10个
            final CountDownLatch latch = new CountDownLatch(providerSize);
            ThreadPoolExecutor closePool = new ThreadPoolExecutor(threads, threads,
                0L, TimeUnit.MILLISECONDS,
                new LinkedBlockingQueue<Runnable>(providerSize),
                new NamedThreadFactory(""CLI-DISCONN-"" + consumerConfig.getInterfaceId(), true));
            for (Map.Entry<ProviderInfo, ClientTransport> entry : all.entrySet()) {
                final ProviderInfo providerInfo = entry.getKey();
                final ClientTransport transport = entry.getValue();
                closePool.execute(new Runnable() {
                    @Override
                    public void run() {
                        try {
                            ClientTransportFactory.releaseTransport(transport, 0);
                        } catch (Exception e) {
                            if (LOGGER.isWarnEnabled(consumerConfig.getAppName())) {
                                LOGGER.warnWithApp(consumerConfig.getAppName(),
                                    ""catch exception but ignore it when close alive client : {}"", providerInfo);
                            }
                        } finally {
                            latch.countDown();
                        }
                    }
                });
            }
            try {
                int totalTimeout = ((providerSize % threads == 0) ? (providerSize / threads) : ((providerSize /
                    threads) + 1)) * timeout + 500;
                latch.await(totalTimeout, TimeUnit.MILLISECONDS); // 一直等到
            } catch (InterruptedException e) {
                LOGGER.errorWithApp(consumerConfig.getAppName(), ""Exception when close transport"", e);
            } finally {
                closePool.shutdown();
            }
        }
    }"
"@Override
	public Thread newThread(Runnable runnable) {
		Thread t = new Thread(group, runnable, namePrefix + threadNumber.getAndIncrement());
		t.setDaemon(true);

		t.setPriority(threadPriority);

		// optional handler for uncaught exceptions
		if (exceptionHandler != null) {
			t.setUncaughtExceptionHandler(exceptionHandler);
		}

		return t;
	}"
"public void setCrumbSalt(String salt) {
        if (Util.fixEmptyAndTrim(salt) == null) {
            crumbSalt = ""hudson.crumb"";
        } else {
            crumbSalt = salt;
        }
    }"
"private void tryDisposeAllOperators() throws Exception {
		for (StreamOperator<?> operator : operatorChain.getAllOperators()) {
			if (operator != null) {
				operator.dispose();
			}
		}
	}"
"private final void updateHead() {
        // Either head already points to an active node, or we keep
        // trying to cas it to the first node until it does.
        Node<E> h, p, q;
        restartFromHead:
        while ((h = head).item == null && (p = h.prev) != null) {
            for (;;) {
                if ((q = p.prev) == null ||
                    (q = (p = q).prev) == null) {
                    // It is possible that p is PREV_TERMINATOR,
                    // but if so, the CAS is guaranteed to fail.
                    if (casHead(h, p))
                        return;
                    else
                        continue restartFromHead;
                }
                else if (h != head)
                    continue restartFromHead;
                else
                    p = q;
            }
        }
    }"
"void exit2(final OtpErlangPid from, final OtpErlangPid to,
            final OtpErlangObject reason) {
        try {
            super.sendExit2(from, to, reason);
        } catch (final Exception e) {
        }
    }"
"@Restricted(NoExternalUse.class)
    public static void deleteRecursive(@Nonnull Path dir, @Nonnull PathRemover.PathChecker pathChecker) throws IOException {
        newPathRemover(pathChecker).forceRemoveRecursive(dir);
    }"
"public static int delimiterOffset(String input, int pos, int limit, char delimiter) {
    for (int i = pos; i < limit; i++) {
      if (input.charAt(i) == delimiter) return i;
    }
    return limit;
  }"
"public synchronized static Lifecycle get() {
        if(INSTANCE==null) {
            Lifecycle instance;
            String p = SystemProperties.getString(""hudson.lifecycle"");
            if(p!=null) {
                try {
                    ClassLoader cl = Jenkins.getInstance().getPluginManager().uberClassLoader;
                    instance = (Lifecycle)cl.loadClass(p).newInstance();
                } catch (InstantiationException e) {
                    InstantiationError x = new InstantiationError(e.getMessage());
                    x.initCause(e);
                    throw x;
                } catch (IllegalAccessException e) {
                    IllegalAccessError x = new IllegalAccessError(e.getMessage());
                    x.initCause(e);
                    throw x;
                } catch (ClassNotFoundException e) {
                    NoClassDefFoundError x = new NoClassDefFoundError(e.getMessage());
                    x.initCause(e);
                    throw x;
                }
            } else {
                if(Functions.isWindows()) {
                    instance = new Lifecycle() {
                        @Override
                        public void verifyRestartable() throws RestartNotSupportedException {
                            throw new RestartNotSupportedException(
                                    ""Default Windows lifecycle does not support restart."");
                        }
                    };
                } else if (System.getenv(""SMF_FMRI"")!=null && System.getenv(""SMF_RESTARTER"")!=null) {
                    // when we are run by Solaris SMF, these environment variables are set.
                    instance = new SolarisSMFLifecycle();
                } else {
                    // if run on Unix, we can do restart
                    try {
                        instance = new UnixLifecycle();
                    } catch (final IOException e) {
                        LOGGER.log(Level.WARNING, ""Failed to install embedded lifecycle implementation"",e);
                        instance = new Lifecycle() {
                            @Override
                            public void verifyRestartable() throws RestartNotSupportedException {
                                throw new RestartNotSupportedException(
                                        ""Failed to install embedded lifecycle implementation, so cannot restart: "" + e, e);
                            }
                        };
                    }
                }
            }
            assert instance != null;
            INSTANCE = instance;
        }

        return INSTANCE;
    }"
"@Override
    public List<Statement> getStatements() {
        List<Statement> result = new LinkedList<>();
        for (ShardingExecuteGroup<StatementExecuteUnit> each : getExecuteGroups()) {
            result.addAll(Lists.transform(each.getInputs(), new Function<StatementExecuteUnit, Statement>() {
                
                @Override
                public Statement apply(final StatementExecuteUnit input) {
                    return input.getStatement();
                }
            }));
        }
        return result;
    }"
"public static void putMethodCache(String serviceName, Method method) {
        ConcurrentHashMap<String, Method> cache = NOT_OVERLOAD_METHOD_CACHE.get(serviceName);
        if (cache == null) {
            cache = new ConcurrentHashMap<String, Method>();
            ConcurrentHashMap<String, Method> old = NOT_OVERLOAD_METHOD_CACHE.putIfAbsent(serviceName, cache);
            if (old != null) {
                cache = old;
            }
        }
        cache.putIfAbsent(method.getName(), method);
    }"
"public static boolean isThisMe(String url) {
        InstanceInfo myInfo = ApplicationInfoManager.getInstance().getInfo();
        String hostName = hostFromUrl(url);
        return hostName != null && hostName.equals(myInfo.getHostName());
    }"
"@Override
  public long transferTo(final WritableByteChannel target, final long position) throws IOException {
    Preconditions.checkArgument(position == totalBytesTransferred, ""Invalid position."");
    // Bytes written for header in this call.
    long writtenHeader = 0;
    if (header.readableBytes() > 0) {
      writtenHeader = copyByteBuf(header, target);
      totalBytesTransferred += writtenHeader;
      if (header.readableBytes() > 0) {
        return writtenHeader;
      }
    }

    // Bytes written for body in this call.
    long writtenBody = 0;
    if (body instanceof FileRegion) {
      writtenBody = ((FileRegion) body).transferTo(target, totalBytesTransferred - headerLength);
    } else if (body instanceof ByteBuf) {
      writtenBody = copyByteBuf((ByteBuf) body, target);
    }
    totalBytesTransferred += writtenBody;

    return writtenHeader + writtenBody;
  }"
"public static <T> ConjunctFuture<Collection<T>> combineAll(Collection<? extends CompletableFuture<? extends T>> futures) {
		checkNotNull(futures, ""futures"");

		return new ResultConjunctFuture<>(futures);
	}"
"boolean contains(AccessOrder<?> e) {
    return (e.getPreviousInAccessOrder() != null)
        || (e.getNextInAccessOrder() != null)
        || (e == first);
  }"
"protected JScrollPane createTabScrollable(String tabLabel, JPanel tabPanel) {
		return new JScrollPane(tabPanel, JScrollPane.VERTICAL_SCROLLBAR_AS_NEEDED, JScrollPane.HORIZONTAL_SCROLLBAR_AS_NEEDED);
	}"
"public void sendAndReceive(HttpMessage msg, boolean isFollowRedirect) throws IOException {

		log.debug(""sendAndReceive "" + msg.getRequestHeader().getMethod() + "" ""
				+ msg.getRequestHeader().getURI() + "" start"");
		msg.setTimeSentMillis(System.currentTimeMillis());

		try {
			notifyRequestListeners(msg);
			if (!isFollowRedirect
					|| !(msg.getRequestHeader().getMethod().equalsIgnoreCase(HttpRequestHeader.POST) || msg
							.getRequestHeader().getMethod().equalsIgnoreCase(HttpRequestHeader.PUT))) {
				// ZAP: Reauthentication when sending a message from the perspective of a User
				sendAuthenticated(msg, isFollowRedirect);
				return;
			}

			// ZAP: Reauthentication when sending a message from the perspective of a User
			sendAuthenticated(msg, false);

			HttpMessage temp = msg.cloneAll();
			temp.setRequestingUser(getUser(msg));
			// POST/PUT method cannot be redirected by library. Need to follow by code

			// loop 1 time only because httpclient can handle redirect itself after first GET.
			for (int i = 0; i < 1
					&& (HttpStatusCode.isRedirection(temp.getResponseHeader().getStatusCode()) && temp
							.getResponseHeader().getStatusCode() != HttpStatusCode.NOT_MODIFIED); i++) {
				String location = temp.getResponseHeader().getHeader(HttpHeader.LOCATION);
				URI baseUri = temp.getRequestHeader().getURI();
				URI newLocation = new URI(baseUri, location, false);
				temp.getRequestHeader().setURI(newLocation);

				temp.getRequestHeader().setMethod(HttpRequestHeader.GET);
				temp.getRequestHeader().setHeader(HttpHeader.CONTENT_LENGTH, null);
				// ZAP: Reauthentication when sending a message from the perspective of a User
				sendAuthenticated(temp, true);
			}

			msg.setResponseHeader(temp.getResponseHeader());
			msg.setResponseBody(temp.getResponseBody());

		} finally {
			msg.setTimeElapsedMillis((int) (System.currentTimeMillis() - msg.getTimeSentMillis()));
			log.debug(""sendAndReceive "" + msg.getRequestHeader().getMethod() + "" ""
					+ msg.getRequestHeader().getURI() + "" took "" + msg.getTimeElapsedMillis());

			notifyResponseListeners(msg);
		}
	}"
"private DataMatrixDO modelToDo(DataMatrix matrix) {
        DataMatrixDO matrixDo = new DataMatrixDO();
        try {
            matrixDo.setId(matrix.getId());
            matrixDo.setGroupKey(matrix.getGroupKey());
            matrixDo.setDescription(matrix.getDescription());
            matrixDo.setMaster(matrix.getMaster());
            matrixDo.setSlave(matrix.getSlave());
            matrixDo.setGmtCreate(matrix.getGmtCreate());
            matrixDo.setGmtModified(matrix.getGmtModified());
        } catch (Exception e) {
            logger.error(""ERROR ## change the matrix Model to Do has an exception"");
            throw new ManagerException(e);
        }
        return matrixDo;
    }"
"@edu.umd.cs.findbugs.annotations.SuppressFBWarnings(""DM_GC"")
    @RequirePOST
    public void doGc(StaplerResponse rsp) throws IOException {
        checkPermission(Jenkins.ADMINISTER);
        System.gc();
        rsp.setStatus(HttpServletResponse.SC_OK);
        rsp.setContentType(""text/plain"");
        rsp.getWriter().println(""GCed"");
    }"
"@Override
	public void connectToResourceManager(@Nonnull ResourceManagerGateway resourceManagerGateway) {
		this.resourceManagerGateway = checkNotNull(resourceManagerGateway);

		// work on all slots waiting for this connection
		for (PendingRequest pendingRequest : waitingForResourceManager.values()) {
			requestSlotFromResourceManager(resourceManagerGateway, pendingRequest);
		}

		// all sent off
		waitingForResourceManager.clear();
	}"
"@Override
	public void combine(Aggregator<T, NumericColumnSummary<T>> otherSameType) {
		NumericSummaryAggregator<T> other = (NumericSummaryAggregator<T>) otherSameType;

		nullCount += other.nullCount;
		nanCount += other.nanCount;
		infinityCount += other.infinityCount;

		if (nonMissingCount == 0) {
			nonMissingCount = other.nonMissingCount;

			min = other.min;
			max = other.max;

			sum = other.sum;
			mean = other.mean;
			m2 = other.m2;
		}
		else if (other.nonMissingCount != 0) {
			long combinedCount = nonMissingCount + other.nonMissingCount;

			min.combine(other.min);
			max.combine(other.max);

			sum.combine(other.sum);

			double deltaMean = other.mean.value() - mean.value();
			mean = mean.add(deltaMean * other.nonMissingCount / combinedCount);
			m2 = m2.add(other.m2).add(deltaMean * deltaMean * nonMissingCount * other.nonMissingCount / combinedCount);

			nonMissingCount = combinedCount;
		}
	}"
"@Override
	protected final void acknowledgeIDs(long checkpointId, Set<UId> uniqueIds) {
		LOG.debug(""Acknowledging ids for checkpoint {}"", checkpointId);
		Iterator<Tuple2<Long, List<SessionId>>> iterator = sessionIdsPerSnapshot.iterator();
		while (iterator.hasNext()) {
			final Tuple2<Long, List<SessionId>> next = iterator.next();
			long id = next.f0;
			if (id <= checkpointId) {
				acknowledgeSessionIDs(next.f1);
				// remove ids for this session
				iterator.remove();
			}
		}
	}"
"private int getStreamId(HttpHeaders httpHeaders) throws Exception {
        return httpHeaders.getInt(HttpConversionUtil.ExtensionHeaderNames.STREAM_ID.text(),
                                  connection().local().incrementAndGetNextStreamId());
    }"
"public static <T> T getFirst(Iterable<T> iterable) {
		if (null != iterable) {
			return getFirst(iterable.iterator());
		}
		return null;
	}"
"private void initTermin() {
        String path = StagePathUtils.getTerminRoot(getPipelineId());
        List<String> termins = zookeeper.getChildren(path);
        initTermin(termins);
    }"
"private boolean patternMatchesAttributeValue(final Object value) {
        val matcher = value.toString();
        LOGGER.trace(""Compiling a pattern matcher for [{}]"", matcher);
        return this.compiledPattern.matcher(matcher).matches();
    }"
"public Optional<String> parseSelectItemAlias() {
        if (lexerEngine.skipIfEqual(DefaultKeyword.AS)) {
            return parseWithAs(null, false, null);
        }
        if (lexerEngine.equalAny(getDefaultAvailableKeywordsForSelectItemAlias()) || lexerEngine.equalAny(getCustomizedAvailableKeywordsForSelectItemAlias())) {
            return parseAlias(null, false, null);
        }
        return Optional.absent();
    }"
"public static <TERM> Map<TERM, Double> idfFromTfs(Iterable<Map<TERM, Double>> tfs, boolean smooth, boolean addOne)
    {
        return idf(new KeySetIterable<TERM, Double>(tfs), smooth, addOne);
    }"
"private final void decodeFields(LogBuffer buffer, final int len) {
        final int limit = buffer.limit();

        buffer.limit(len + buffer.position());
        for (int i = 0; i < columnCnt; i++) {
            ColumnInfo info = columnInfo[i];

            switch (info.type) {
                case MYSQL_TYPE_TINY_BLOB:
                case MYSQL_TYPE_BLOB:
                case MYSQL_TYPE_MEDIUM_BLOB:
                case MYSQL_TYPE_LONG_BLOB:
                case MYSQL_TYPE_DOUBLE:
                case MYSQL_TYPE_FLOAT:
                case MYSQL_TYPE_GEOMETRY:
                case MYSQL_TYPE_JSON:
                    /*
                     * These types store a single byte.
                     */
                    info.meta = buffer.getUint8();
                    break;
                case MYSQL_TYPE_SET:
                case MYSQL_TYPE_ENUM:
                    /*
                     * log_event.h : MYSQL_TYPE_SET & MYSQL_TYPE_ENUM : This
                     * enumeration value is only used internally and cannot
                     * exist in a binlog.
                     */
                    logger.warn(""This enumeration value is only used internally ""
                                + ""and cannot exist in a binlog: type="" + info.type);
                    break;
                case MYSQL_TYPE_STRING: {
                    /*
                     * log_event.h : The first byte is always
                     * MYSQL_TYPE_VAR_STRING (i.e., 253). The second byte is the
                     * field size, i.e., the number of bytes in the
                     * representation of size of the string: 3 or 4.
                     */
                    int x = (buffer.getUint8() << 8); // real_type
                    x += buffer.getUint8(); // pack or field length
                    info.meta = x;
                    break;
                }
                case MYSQL_TYPE_BIT:
                    info.meta = buffer.getUint16();
                    break;
                case MYSQL_TYPE_VARCHAR:
                    /*
                     * These types store two bytes.
                     */
                    info.meta = buffer.getUint16();
                    break;
                case MYSQL_TYPE_NEWDECIMAL: {
                    int x = buffer.getUint8() << 8; // precision
                    x += buffer.getUint8(); // decimals
                    info.meta = x;
                    break;
                }
                case MYSQL_TYPE_TIME2:
                case MYSQL_TYPE_DATETIME2:
                case MYSQL_TYPE_TIMESTAMP2: {
                    info.meta = buffer.getUint8();
                    break;
                }
                default:
                    info.meta = 0;
                    break;
            }
        }
        buffer.limit(limit);
    }"
"public RequestTemplate body(Request.Body body) {
    this.body = body;

    header(CONTENT_LENGTH);
    if (body.length() > 0) {
      header(CONTENT_LENGTH, String.valueOf(body.length()));
    }

    return this;
  }"
"public static <T> Bindable<T> of(Class<T> type) {
		Assert.notNull(type, ""Type must not be null"");
		return of(ResolvableType.forClass(type));
	}"
"protected @Nonnull <T> Collection<T> getBeansOfType(@Nullable BeanResolutionContext resolutionContext, @Nonnull Class<T> beanType) {
        return getBeansOfTypeInternal(resolutionContext, beanType, null);
    }"
"public byte[] readStringNulByBytes() {
        byte[] result = new byte[byteBuf.bytesBefore((byte) 0)];
        byteBuf.readBytes(result);
        byteBuf.skipBytes(1);
        return result;
    }"
"private static void encodeInteger(ByteBuf out, int mask, int n, int i) {
        encodeInteger(out, mask, n, (long) i);
    }"
"private static Object invokeNullaryFactoryMethod(final String fqcn, final String methodName) {
        try {
            final Class<?> type = Class.forName(fqcn);
            final Method method = type.getMethod(methodName);

            return method.invoke(null);
            // any exception is really unexpected since the type name has
            // already been verified
        } catch (final Exception e) {
            throw new InstantiationException(
                    String.format(""Could not create %s#%s(): %s"", fqcn, methodName, e), e);
        }
    }"
"public boolean isIncluded(String url) {
		if (url == null) {
			return false;
		}
		if (url.indexOf(""?"") > 0) {
			// Strip off any parameters
			url = url.substring(0, url.indexOf(""?""));
		}
		for (Pattern p : this.includeInPatterns) {
			if (p.matcher(url).matches()) {
				return true;
			}
		}
		return false;
	}"
"protected void emitRecordWithTimestamp(
			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception {

		if (record != null) {
			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {
				// fast path logic, in case there are no watermarks generated in the fetcher

				// emit the record, using the checkpoint lock to guarantee
				// atomicity of record emission and offset state update
				synchronized (checkpointLock) {
					sourceContext.collectWithTimestamp(record, timestamp);
					partitionState.setOffset(offset);
				}
			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {
				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, timestamp);
			} else {
				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, timestamp);
			}
		} else {
			// if the record is null, simply just update the offset state for partition
			synchronized (checkpointLock) {
				partitionState.setOffset(offset);
			}
		}
	}"
"public InternalRunner create(Class<?> klass, Supplier<MockitoTestListener> listenerSupplier) throws InvocationTargetException {
        try {
            String runnerClassName = ""org.mockito.internal.runners.DefaultInternalRunner"";
            //Warning: I'm using String literal on purpose!
            //When JUnit is not on classpath, we want the code to throw exception here so that we can catch it
            //If we statically link the class, we will get Error when class is loaded
            return new RunnerProvider().newInstance(runnerClassName, klass, listenerSupplier);
        } catch (InvocationTargetException e) {
            if (!hasTestMethods(klass)) {
                throw new MockitoException(
                    ""\n"" +
                    ""\n"" +
                    ""No tests found in "" + klass.getSimpleName() + ""\n"" +
                    ""Is the method annotated with @Test?\n"" +
                    ""Is the method public?\n""
                    , e);
            }
            throw e;
        } catch (Throwable t) {
            throw new MockitoException(
                    ""\n"" +
                    ""\n"" +
                    ""MockitoRunner can only be used with JUnit 4.5 or higher.\n"" +
                    ""You can upgrade your JUnit version or write your own Runner (please consider contributing your runner to the Mockito community).\n"" +
                    ""Bear in mind that you can still enjoy all features of the framework without using runners (they are completely optional).\n"" +
                    ""If you get this error despite using JUnit 4.5 or higher then please report this error to the mockito mailing list.\n""
                    , t);
        }
    }"
"public int determinePort() {
		if (CollectionUtils.isEmpty(this.parsedAddresses)) {
			return getPort();
		}
		Address address = this.parsedAddresses.get(0);
		return address.port;
	}"
"public <S extends F> Pattern<T, S> subtype(final Class<S> subtypeClass) {
		Preconditions.checkNotNull(subtypeClass, ""The class cannot be null."");

		if (condition == null) {
			this.condition = new SubtypeCondition<F>(subtypeClass);
		} else {
			this.condition = new RichAndCondition<>(condition, new SubtypeCondition<F>(subtypeClass));
		}

		@SuppressWarnings(""unchecked"")
		Pattern<T, S> result = (Pattern<T, S>) this;

		return result;
	}"
"public static boolean isLongValue(final String value) {
        try {
            Long.parseLong(value);
            return true;
        } catch (final NumberFormatException ex) {
            return false;
        }
    }"
"public Iterator<E> iterator() {
        final Iterator<? extends E> itr = core.iterator();
        return new Iterator<E>() {
            private E last;
            public boolean hasNext() {
                return itr.hasNext();
            }

            public E next() {
                return last=itr.next();
            }

            public void remove() {
                CopyOnWriteList.this.remove(last);
            }
        };
    }"
"public Optional<ShardingEncryptor> getShardingEncryptor(final String logicTableName, final String columnName) {
        for (ShardingEncryptorStrategy each : shardingEncryptorStrategies.values()) {
            Optional<ShardingEncryptor> result = each.getShardingEncryptor(logicTableName, columnName);
            if (result.isPresent()) {
                return result;
            }
        }
        return Optional.absent();
    }"
"protected void prepareCasResponseAttributesForViewModel(final Map<String, Object> model) {
        val service = authenticationRequestServiceSelectionStrategies.resolveService(getServiceFrom(model));
        val registeredService = this.servicesManager.findServiceBy(service);

        val principalAttributes = getCasPrincipalAttributes(model, registeredService);
        val attributes = new HashMap<String, Object>(principalAttributes);

        LOGGER.trace(""Processed principal attributes from the output model to be [{}]"", principalAttributes.keySet());
        val protocolAttributes = getCasProtocolAuthenticationAttributes(model, registeredService);
        attributes.putAll(protocolAttributes);

        LOGGER.debug(""Final collection of attributes for the response are [{}]."", attributes.keySet());
        putCasResponseAttributesIntoModel(model, attributes, registeredService, this.attributesRenderer);
    }"
"protected Authentication getAuthenticationSatisfiedByPolicy(final Authentication authentication, final ServiceContext context) throws AbstractTicketException {
        val policy = this.serviceContextAuthenticationPolicyFactory.createPolicy(context);
        try {
            if (policy.isSatisfiedBy(authentication)) {
                return authentication;
            }
        } catch (final Exception e) {
            LOGGER.error(e.getMessage(), e);
        }
        throw new UnsatisfiedAuthenticationPolicyException(policy);
    }"
"public synchronized void add(ConfusionMatrix<T> other) {
        for (T actual : other.matrix.keySet()) {
            Multiset<T> counts = other.matrix.get(actual);
            for (T predicted : counts.elementSet()) {
                int count = counts.count(predicted);
                this.add(actual, predicted, count);
            }
        }
    }"
"protected boolean isPackableWith(Object value, int choose) {
        if (value == null) {
            return false;
        }

        if (choose == CHOOSE_EXTENSION) {
            if (value.equals(getDefaultFileExtension())) {
                return true;
            }
        } else if (choose == CHOOSE_NAME) {
            if (value.equals(getName())) {
                return true;
            }
        }

        return false;
    }"
"private void modifiers(int modifiers) throws IOException {
    if ((modifiers & Modifier.PUBLIC) != 0) {
      out.write(""public "");
    }
    if ((modifiers & Modifier.PRIVATE) != 0) {
      out.write(""private "");
    }
    if ((modifiers & Modifier.PROTECTED) != 0) {
      out.write(""protected "");
    }
    if ((modifiers & Modifier.STATIC) != 0) {
      out.write(""static "");
    }
    if ((modifiers & Modifier.FINAL) != 0) {
      out.write(""final "");
    }
    if ((modifiers & Modifier.ABSTRACT) != 0) {
      out.write(""abstract "");
    }
    if ((modifiers & Modifier.SYNCHRONIZED) != 0) {
      out.write(""synchronized "");
    }
    if ((modifiers & Modifier.TRANSIENT) != 0) {
      out.write(""transient "");
    }
    if ((modifiers & Modifier.VOLATILE) != 0) {
      out.write(""volatile "");
    }
  }"
"public void setProviderName(final String pName) {
        if (StringUtils.isNotBlank(pName)) {
            LOGGER.debug(""Configured Jasypt provider"");
            this.jasyptInstance.setProviderName(pName);
        }
    }"
"public void addJar(Path jar) {
		if (jar == null) {
			throw new IllegalArgumentException();
		}

		if (!userJars.contains(jar)) {
			userJars.add(jar);
		}
	}"
"@Exported
    public Set<LabelAtom> getAssignedLabels() {
        Set<LabelAtom> r = Label.parse(getLabelString());
        r.add(getSelfLabel());
        r.addAll(getDynamicLabels());
        return Collections.unmodifiableSet(r);
    }"
"public static <T> List<T> loadDeclaredClasses(
            AddOnClassLoader addOnClassLoader,
            List<String> classnames,
            Class<T> clazz,
            String type) {
        validateNotNull(addOnClassLoader, ""addOnClassLoader"");
        validateNotNull(classnames, ""classnames"");
        validateNotNull(clazz, ""clazz"");
        validateNotNull(type, ""type"");

        if (classnames.isEmpty()) {
            return Collections.emptyList();
        }

        ArrayList<T> instances = new ArrayList<>(classnames.size());
        for (String classname : classnames) {
            T instance = loadAndInstantiateClassImpl(addOnClassLoader, classname, clazz, type);
            if (instance != null) {
                instances.add(instance);
            }
        }
        instances.trimToSize();
        return Collections.unmodifiableList(instances);
    }"
"public static ComputationGraphConfiguration fromJson(String json) {
        //As per MultiLayerConfiguration.fromJson()
        ObjectMapper mapper = NeuralNetConfiguration.mapper();
        ComputationGraphConfiguration conf;
        try {
            conf = mapper.readValue(json, ComputationGraphConfiguration.class);
        } catch (Exception e) {
            //Check if this exception came from legacy deserializer...
            String msg = e.getMessage();
            if(msg != null && msg.contains(""legacy"")){
                throw new RuntimeException(""Error deserializing ComputationGraphConfiguration - configuration may have a custom "" +
                        ""layer, vertex or preprocessor, in pre version 1.0.0-alpha JSON format. These layers can be "" +
                        ""deserialized by first registering them with NeuralNetConfiguration.registerLegacyCustomClassesForJSON(Class...)"", e);
            }
            throw new RuntimeException(e);
        }

        //To maintain backward compatibility after activation function refactoring (configs generated with v0.7.1 or earlier)
        // Previously: enumeration used for activation functions. Now: use classes
        int layerCount = 0;
        Map<String, GraphVertex> vertexMap = conf.getVertices();
        JsonNode vertices = null;
        for (Map.Entry<String, GraphVertex> entry : vertexMap.entrySet()) {
            if (!(entry.getValue() instanceof LayerVertex)) {
                continue;
            }

            LayerVertex lv = (LayerVertex) entry.getValue();
            if (lv.getLayerConf() != null && lv.getLayerConf().getLayer() != null) {
                Layer layer = lv.getLayerConf().getLayer();

                if (layer instanceof BaseLayer && ((BaseLayer) layer).getActivationFn() == null) {
                    String layerName = layer.getLayerName();

                    try {
                        if (vertices == null) {
                            JsonNode jsonNode = mapper.readTree(json);
                            vertices = jsonNode.get(""vertices"");
                        }

                        JsonNode vertexNode = vertices.get(layerName);
                        JsonNode layerVertexNode = vertexNode.get(""LayerVertex"");
                        if (layerVertexNode == null || !layerVertexNode.has(""layerConf"")
                                        || !layerVertexNode.get(""layerConf"").has(""layer"")) {
                            continue;
                        }
                        JsonNode layerWrapperNode = layerVertexNode.get(""layerConf"").get(""layer"");

                        if (layerWrapperNode == null || layerWrapperNode.size() != 1) {
                            continue;
                        }

                        JsonNode layerNode = layerWrapperNode.elements().next();
                        JsonNode activationFunction = layerNode.get(""activationFunction""); //Should only have 1 element: ""dense"", ""output"", etc

                        if (activationFunction != null) {
                            IActivation ia = Activation.fromString(activationFunction.asText()).getActivationFunction();
                            ((BaseLayer) layer).setActivationFn(ia);
                        }

                    } catch (IOException e) {
                        log.warn(""Layer with null ActivationFn field or pre-0.7.2 activation function detected: could not parse JSON"",
                                        e);
                    }
                }

                handleLegacyWeightInitFromJson(json, layer, mapper, vertices);
            }
        }

        return conf;
    }"
"private void writeArrayHeader(ByteBufAllocator allocator, ArrayHeaderRedisMessage msg, List<Object> out) {
        writeArrayHeader(allocator, msg.isNull(), msg.length(), out);
    }"
"@GetMapping(""/count/{type}/{key}/{task}"")
    public Map<String, Object> count(@PathVariable String type, @PathVariable String key, @PathVariable String task) {
        OuterAdapter adapter = loader.getExtension(type, key);
        return adapter.count(task);
    }"
"public static String removeAllHtmlAttr(String content, String... tagNames) {
		String regex = null;
		for (String tagName : tagNames) {
			regex = StrUtil.format(""(?i)<{}[^>]*?>"", tagName);
			content = content.replaceAll(regex, StrUtil.format(""<{}>"", tagName));
		}
		return content;
	}"
"protected SimpleSlot getNewSlotForSharingGroup(ExecutionVertex vertex,
													Iterable<TaskManagerLocation> requestedLocations,
													SlotSharingGroupAssignment groupAssignment,
													CoLocationConstraint constraint,
													boolean localOnly)
	{
		// we need potentially to loop multiple times, because there may be false positives
		// in the set-with-available-instances
		while (true) {
			Pair<Instance, Locality> instanceLocalityPair = findInstance(requestedLocations, localOnly);
			
			if (instanceLocalityPair == null) {
				// nothing is available
				return null;
			}

			final Instance instanceToUse = instanceLocalityPair.getLeft();
			final Locality locality = instanceLocalityPair.getRight();

			try {
				JobVertexID groupID = vertex.getJobvertexId();
				
				// allocate a shared slot from the instance
				SharedSlot sharedSlot = instanceToUse.allocateSharedSlot(groupAssignment);

				// if the instance has further available slots, re-add it to the set of available resources.
				if (instanceToUse.hasResourcesAvailable()) {
					this.instancesWithAvailableResources.put(instanceToUse.getTaskManagerID(), instanceToUse);
				}

				if (sharedSlot != null) {
					// add the shared slot to the assignment group and allocate a sub-slot
					SimpleSlot slot = constraint == null ?
							groupAssignment.addSharedSlotAndAllocateSubSlot(sharedSlot, locality, groupID) :
							groupAssignment.addSharedSlotAndAllocateSubSlot(sharedSlot, locality, constraint);

					if (slot != null) {
						return slot;
					}
					else {
						// could not add and allocate the sub-slot, so release shared slot
						sharedSlot.releaseSlot(new FlinkException(""Could not allocate sub-slot.""));
					}
				}
			}
			catch (InstanceDiedException e) {
				// the instance died it has not yet been propagated to this scheduler
				// remove the instance from the set of available instances
				removeInstance(instanceToUse);
			}

			// if we failed to get a slot, fall through the loop
		}
	}"
"protected void configureEnvironment(ConfigurableEnvironment environment,
			String[] args) {
		if (this.addConversionService) {
			ConversionService conversionService = ApplicationConversionService
					.getSharedInstance();
			environment.setConversionService(
					(ConfigurableConversionService) conversionService);
		}
		configurePropertySources(environment, args);
		configureProfiles(environment, args);
	}"
"private FormValidation checkSpecificSignature(JSONObject json, JSONObject signatureJson, MessageDigest digest, String digestEntry, Signature signature, String signatureEntry, String digestName) throws IOException {
        // this is for computing a digest to check sanity
        DigestOutputStream dos = new DigestOutputStream(new NullOutputStream(), digest);
        SignatureOutputStream sos = new SignatureOutputStream(signature);

        String providedDigest = signatureJson.optString(digestEntry, null);
        if (providedDigest == null) {
            return FormValidation.warning(""No '"" + digestEntry + ""' found"");
        }

        String providedSignature = signatureJson.optString(signatureEntry, null);
        if (providedSignature == null) {
            return FormValidation.warning(""No '"" + signatureEntry + ""' found"");
        }

        // until JENKINS-11110 fix, UC used to serve invalid digest (and therefore unverifiable signature)
        // that only covers the earlier portion of the file. This was caused by the lack of close() call
        // in the canonical writing, which apparently leave some bytes somewhere that's not flushed to
        // the digest output stream. This affects Jenkins [1.424,1,431].
        // Jenkins 1.432 shipped with the ""fix"" (1eb0c64abb3794edce29cbb1de50c93fa03a8229) that made it
        // compute the correct digest, but it breaks all the existing UC json metadata out there. We then
        // quickly discovered ourselves in the catch-22 situation. If we generate UC with the correct signature,
        // it'll cut off [1.424,1.431] from the UC. But if we don't, we'll cut off [1.432,*).
        //
        // In 1.433, we revisited 1eb0c64abb3794edce29cbb1de50c93fa03a8229 so that the original ""digest""/""signature""
        // pair continues to be generated in a buggy form, while ""correct_digest""/""correct_signature"" are generated
        // correctly.
        //
        // Jenkins should ignore ""digest""/""signature"" pair. Accepting it creates a vulnerability that allows
        // the attacker to inject a fragment at the end of the json.
        json.writeCanonical(new OutputStreamWriter(new TeeOutputStream(dos,sos), Charsets.UTF_8)).close();

        // did the digest match? this is not a part of the signature validation, but if we have a bug in the c14n
        // (which is more likely than someone tampering with update center), we can tell

        if (!digestMatches(digest.digest(), providedDigest)) {
            String msg = digestName + "" digest mismatch: expected="" + providedDigest + "" in '"" + name + ""'"";
            if (LOGGER.isLoggable(Level.SEVERE)) {
                LOGGER.severe(msg);
                LOGGER.severe(json.toString(2));
            }
            return FormValidation.error(msg);
        }

        if (!verifySignature(signature, providedSignature)) {
            return FormValidation.error(digestName + "" based signature in the update center doesn't match with the certificate in '""+name + ""'"");
        }

        return FormValidation.ok();
    }"
"public static <K, V> Map<K, V> filter(Map<K, V> map, Filter<Entry<K, V>> filter) {
		if(null == map || null == filter) {
			return map;
		}
		
		final Map<K, V> map2 = ObjectUtil.clone(map);
		if (isEmpty(map2)) {
			return map2;
		}

		map2.clear();
		for (Entry<K, V> entry : map.entrySet()) {
			if (filter.accept(entry)) {
				map2.put(entry.getKey(), entry.getValue());
			}
		}
		return map2;
	}"
"public void setContent(Region content) {
        if (content != null) {
            this.content = content;
            this.content.setPickOnBounds(false);
            contentHolder.getChildren().setAll(content);
        }
    }"
"public HashSet<String> getStringsStartingWith(String prefixStr)
    {
        HashSet<String> strHashSet = new HashSet<String>();

        if (sourceNode != null)      //if the MDAG hasn't been simplified
        {
            MDAGNode originNode = sourceNode.transition(prefixStr);  //attempt to _transition down the path denoted by prefixStr

            if (originNode != null) //if there a _transition path corresponding to prefixString (one or more stored Strings begin with prefixString)
            {
                if (originNode.isAcceptNode()) strHashSet.add(prefixStr);
                getStrings(strHashSet, SearchCondition.PREFIX_SEARCH_CONDITION, prefixStr, prefixStr, originNode.getOutgoingTransitions());   //retrieve all Strings that extend the _transition path denoted by prefixStr
            }
        }
        else
        {
            SimpleMDAGNode originNode = SimpleMDAGNode.traverseMDAG(mdagDataArray, simplifiedSourceNode, prefixStr);      //attempt to _transition down the path denoted by prefixStr

            if (originNode != null)      //if there a _transition path corresponding to prefixString (one or more stored Strings begin with prefixStr)
            {
                if (originNode.isAcceptNode()) strHashSet.add(prefixStr);
                getStrings(strHashSet, SearchCondition.PREFIX_SEARCH_CONDITION, prefixStr, prefixStr, originNode);        //retrieve all Strings that extend the _transition path denoted by prefixString
            }
        }

        return strHashSet;
    }"
"@PublicEvolving
	@Deprecated
	public <ACC> QueryableStateStream<KEY, ACC> asQueryableState(
			String queryableStateName,
			FoldingStateDescriptor<T, ACC> stateDescriptor) {

		transform(""Queryable state: "" + queryableStateName,
				getType(),
				new QueryableAppendingStateOperator<>(queryableStateName, stateDescriptor));

		stateDescriptor.initializeSerializerUnlessSet(getExecutionConfig());

		return new QueryableStateStream<>(
				queryableStateName,
				stateDescriptor,
				getKeyType().createSerializer(getExecutionConfig()));
	}"
"@SuppressWarnings(""rawtypes"")
    protected List cacheLoadOrStore(List<Object> loadedObjects) {
        if (loadedObjects.isEmpty()) {
            return loadedObjects;
        }
        if (!(loadedObjects.get(0) instanceof Entity)) {
            return loadedObjects;
        }

        List<Entity> filteredObjects = new ArrayList<Entity>(loadedObjects.size());
        for (Object loadedObject : loadedObjects) {
            Entity cachedEntity = cacheLoadOrStore((Entity) loadedObject);
            filteredObjects.add(cachedEntity);
        }
        return filteredObjects;
    }"
"public static ExpectedCondition<Boolean> elementSelectionStateToBe(final WebElement element,
                                                                     final boolean selected) {
    return new ExpectedCondition<Boolean>() {
      @Override
      public Boolean apply(WebDriver driver) {
        return element.isSelected() == selected;
      }

      @Override
      public String toString() {
        return String.format(""element (%s) to %sbe selected"", element, (selected ? """" : ""not ""));
      }
    };
  }"
"public SDVariable fill(SDVariable shape, org.nd4j.linalg.api.buffer.DataType dataType, double value) {
        return fill(null, shape, dataType, value);
    }"
"RPC.RPCCall record_task( RPC.RPCCall rpc ) {
    // Task removal (and roll-up) suffers from classic race-condition, which we
    // fix by a classic Dekker's algo; a task# is always in either the _work
    // HashMap, or rolled-up in the _removed_task_ids counter, or both (for
    // short intervals during the handoff).  We can never has a cycle where
    // it's in neither or else a late UDP may attempt to ""resurrect"" the
    // already completed task.  Hence we must always check the ""removed ids""
    // AFTER we insert in the HashMap (we can check before also, but that's a
    // simple optimization and not sufficient for correctness).
    final RPC.RPCCall x = _work.putIfAbsent(rpc._tsknum,rpc);
    if( x != null ) return x;   // Return pre-existing work
    // If this RPC task# is very old, we just return a Golden Completed task.
    // The task is not just completed, but also we have already received
    // verification that the client got the answer.  So this is just a really
    // old attempt to restart a long-completed task.
    if( rpc._tsknum > _removed_task_ids.get() ) return null; // Task is new
    _work.remove(rpc._tsknum); // Bogus insert, need to remove it
    return _removed_task;      // And return a generic Golden Completed object
  }"
"public static void slimNode(RPNode node) {
        if(node.getRight() != null && node.getLeft() != null) {
            node.getIndices().clear();
        }

    }"
"private void checkAndEnableSaveButton() {
		boolean enabled = true;
		enabled &= txt_PubCert.getDocument().getLength() > MIN_CERT_LENGTH;
		bt_save.setEnabled(enabled);
	}"
"public static long decodeTimestamp(long seconds, long serializedNanos, long baseTimestampInSeconds)
    {
        long millis = (seconds + baseTimestampInSeconds) * MILLIS_PER_SECOND;
        long nanos = parseNanos(serializedNanos);
        if (nanos > 999999999 || nanos < 0) {
            throw new IllegalArgumentException(""nanos field of an encoded timestamp in ORC must be between 0 and 999999999 inclusive, got "" + nanos);
        }

        // the rounding error exists because java always rounds up when dividing integers
        // -42001/1000 = -42; and -42001 % 1000 = -1 (+ 1000)
        // to get the correct value we need
        // (-42 - 1)*1000 + 999 = -42001
        // (42)*1000 + 1 = 42001
        if (millis < 0 && nanos != 0) {
            millis -= 1000;
        }
        // Truncate nanos to millis and add to mills
        return millis + (nanos / 1_000_000);
    }"
"public SDVariable leakyRelu(String name, SDVariable x, double alpha) {
        validateFloatingPoint(""leaky ReLU"", x);
        SDVariable result = f().leakyRelu(x, alpha);
        return updateVariableNameAndReference(result, name);
    }"
"@SuppressWarnings({""ConstantConditions"",""deprecation""})
    @SuppressFBWarnings(""RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE"")
    public void addAction(@Nonnull Action a) {
        if(a==null) {
            throw new IllegalArgumentException(""Action must be non-null"");
        }
        getActions().add(a);
    }"
"public static LinkedHashSet<String> yearAndQuarter(Date startDate, Date endDate) {
		if (startDate == null || endDate == null) {
			return new LinkedHashSet<String>(0);
		}
		return yearAndQuarter(startDate.getTime(), endDate.getTime());
	}"
"public static Calendar ceiling(Calendar calendar, DateField dateField) {
		return DateModifier.modify(calendar, dateField.getValue(), ModifyType.CEILING);
	}"
"protected void runAsyncWithoutFencing(Runnable runnable) {
		if (rpcServer instanceof FencedMainThreadExecutable) {
			((FencedMainThreadExecutable) rpcServer).runAsyncWithoutFencing(runnable);
		} else {
			throw new RuntimeException(""FencedRpcEndpoint has not been started with a FencedMainThreadExecutable RpcServer."");
		}
	}"
"@Override
    public void emitResponse(T response) {
        if (!isTerminated()) {
            subject.onNext(response);
            valueSet.set(true);
        } else {
            throw new IllegalStateException(""Response has already terminated so response can not be set : "" + response);
        }
    }"
"public static void main(String[] args) throws Exception {

		// Checking input parameters
		final ParameterTool params = ParameterTool.fromArgs(args);

		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
		env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);

		DataStream<Integer> trainingData = env.addSource(new FiniteTrainingDataSource());
		DataStream<Integer> newData = env.addSource(new FiniteNewDataSource());

		// build new model on every second of new data
		DataStream<Double[]> model = trainingData
				.assignTimestampsAndWatermarks(new LinearTimestamp())
				.timeWindowAll(Time.of(5000, TimeUnit.MILLISECONDS))
				.apply(new PartialModelBuilder());

		// use partial model for newData
		DataStream<Integer> prediction = newData.connect(model).map(new Predictor());

		// emit result
		if (params.has(""output"")) {
			prediction.writeAsText(params.get(""output""));
		} else {
			System.out.println(""Printing result to stdout. Use --output to specify output path."");
			prediction.print();
		}

		// execute program
		env.execute(""Streaming Incremental Learning"");
	}"
"public void store(String path, Class<?> clazz) {
		this.store(FileUtil.getAbsolutePath(path, clazz));
	}"
"protected Element[] getElements(Element base, String childTag) {
		NodeList nodeList = base.getElementsByTagName(childTag);
		if (nodeList.getLength() == 0) {
			return null;
		}
		Element[] elements = new Element[nodeList.getLength()];
		for (int i=0; i<nodeList.getLength(); i++) {
		    elements[i] = (Element) nodeList.item(i);
		}
		return elements;
	}"
"public CheckpointStatsSnapshot createSnapshot() {
		CheckpointStatsSnapshot snapshot = latestSnapshot;

		// Only create a new snapshot if dirty and no update in progress,
		// because we don't want to block the coordinator.
		if (dirty && statsReadWriteLock.tryLock()) {
			try {
				// Create a new snapshot
				snapshot = new CheckpointStatsSnapshot(
					counts.createSnapshot(),
					summary.createSnapshot(),
					history.createSnapshot(),
					latestRestoredCheckpoint);

				latestSnapshot = snapshot;

				dirty = false;
			} finally {
				statsReadWriteLock.unlock();
			}
		}

		return snapshot;
	}"
"static CommandLine parseCommandLine(String[] args) {
        return CommandLine.build()
            .addOption(DATA_OPTION, ""For passing the data"")
            .addOption(DEBUG_OPTIONS, ""For outputting debug information"")
            .parse(args);
    }"
"@Override
    public void partialUpdate(INDArray arr, INDArray result, long idx, int... dimensions) {
        result.tensorAlongDimension((int) idx, dimensions).addi(arr);
    }"
"public void setHealthCheckRegistry(Object healthCheckRegistry)
   {
      checkIfSealed();

      if (healthCheckRegistry != null) {
         healthCheckRegistry = getObjectOrPerformJndiLookup(healthCheckRegistry);

         if (!(healthCheckRegistry instanceof HealthCheckRegistry)) {
            throw new IllegalArgumentException(""Class must be an instance of com.codahale.metrics.health.HealthCheckRegistry"");
         }
      }

      this.healthCheckRegistry = healthCheckRegistry;
   }"
"private static boolean nonEmptyIntersection(String[] a, String[] b) {
    if (a == null || b == null || a.length == 0 || b.length == 0) {
      return false;
    }
    for (String toFind : a) {
      if (contains(b, toFind)) {
        return true;
      }
    }
    return false;
  }"
"public void shutdown() {
		// -------------------- BEGIN CRITICAL SECTION -------------------
		synchronized (lock) {
			if (!isShutDown) {
				// mark as shutdown and release memory
				isShutDown = true;
				numNonAllocatedPages = 0;

				// go over all allocated segments and release them
				for (Set<MemorySegment> segments : allocatedSegments.values()) {
					for (MemorySegment seg : segments) {
						seg.free();
					}
				}

				memoryPool.clear();
			}
		}
		// -------------------- END CRITICAL SECTION -------------------
	}"
"public static Object getByPath(JSON json, String expression) {
		return (null == json || StrUtil.isBlank(expression)) ? null : json.getByPath(expression);
	}"
"private void onCompleteHandler(StreamElementQueueEntry<?> streamElementQueueEntry) throws InterruptedException {
		lock.lockInterruptibly();

		try {
			if (!queue.isEmpty() && queue.peek().isDone()) {
				LOG.debug(""Signal ordered stream element queue has completed head element."");
				headIsCompleted.signalAll();
			}
		} finally {
			lock.unlock();
		}
	}"
"public static <K, V> Map<K, V> nullToEmptyMap(Map<K, V> newValue) {
    if (newValue == null) {
      return new HashMap<>();
    }
    return newValue;
  }"
"private String getAuthHeader(HttpServletRequest request, String authType)
      throws HttpAuthenticationException {
    String authHeader = request.getHeader(HttpAuthUtils.AUTHORIZATION);
    // Each http request must have an Authorization header
    if (authHeader == null || authHeader.isEmpty()) {
      throw new HttpAuthenticationException(""Authorization header received "" +
          ""from the client is empty."");
    }

    String authHeaderBase64String;
    int beginIndex;
    if (isKerberosAuthMode(authType)) {
      beginIndex = (HttpAuthUtils.NEGOTIATE + "" "").length();
    }
    else {
      beginIndex = (HttpAuthUtils.BASIC + "" "").length();
    }
    authHeaderBase64String = authHeader.substring(beginIndex);
    // Authorization header must have a payload
    if (authHeaderBase64String == null || authHeaderBase64String.isEmpty()) {
      throw new HttpAuthenticationException(""Authorization header received "" +
          ""from the client does not contain any data."");
    }
    return authHeaderBase64String;
  }"
"public byte[] encrypt(String data, String charset, KeyType keyType) {
		return encrypt(StrUtil.bytes(data, charset), keyType);
	}"
"private ConciseSet performOperation(ConciseSet other, Operator operator)
  {
    // non-empty arguments
    if (this.isEmpty() || other.isEmpty()) {
      return operator.combineEmptySets(this, other);
    }

    // if the two operands are disjoint, the operation is faster
    ConciseSet res = operator.combineDisjointSets(this, other);
    if (res != null) {
      return res;
    }

    // Allocate a sufficient number of words to contain all possible results.
    // NOTE: since lastWordIndex is the index of the last used word in ""words"",
    // we require ""+2"" to have the actual maximum required space.
    // In any case, we do not allocate more than the maximum space required
    // for the uncompressed representation.
    // Another ""+1"" is required to allows for the addition of the last word
    // before compacting.
    res = empty();
    res.words = new int[1 + Math.min(
        this.lastWordIndex + other.lastWordIndex + 2,
        maxLiteralLengthDivision(Math.max(this.last, other.last)) << (simulateWAH ? 1 : 0)
    )];

    // scan ""this"" and ""other""
    WordIterator thisItr = new WordIterator();
    WordIterator otherItr = other.new WordIterator();
    while (true) {
      if (!thisItr.isLiteral) {
        if (!otherItr.isLiteral) {
          int minCount = Math.min(thisItr.count, otherItr.count);
          res.appendFill(minCount, operator.combineLiterals(thisItr.word, otherItr.word));
          //noinspection NonShortCircuitBooleanExpression
          if (!thisItr.prepareNext(minCount) | /* NOT || */ !otherItr.prepareNext(minCount)) {
            break;
          }
        } else {
          res.appendLiteral(operator.combineLiterals(thisItr.toLiteral(), otherItr.word));
          thisItr.word--;
          //noinspection NonShortCircuitBooleanExpression
          if (!thisItr.prepareNext(1) | /* do NOT use ""||"" */ !otherItr.prepareNext()) {
            break;
          }
        }
      } else if (!otherItr.isLiteral) {
        res.appendLiteral(operator.combineLiterals(thisItr.word, otherItr.toLiteral()));
        otherItr.word--;
        //noinspection NonShortCircuitBooleanExpression
        if (!thisItr.prepareNext() | /* do NOT use  ""||"" */ !otherItr.prepareNext(1)) {
          break;
        }
      } else {
        res.appendLiteral(operator.combineLiterals(thisItr.word, otherItr.word));
        //noinspection NonShortCircuitBooleanExpression
        if (!thisItr.prepareNext() | /* do NOT use  ""||"" */ !otherItr.prepareNext()) {
          break;
        }
      }
    }

    // invalidate the size
    res.size = -1;
    boolean invalidLast = true;

    // if one bit string is greater than the other one, we add the remaining
    // bits depending on the given operation.
    switch (operator) {
      case AND:
        break;
      case OR:
        res.last = Math.max(this.last, other.last);
        invalidLast = thisItr.flush(res);
        invalidLast |= otherItr.flush(res);
        break;
      case XOR:
        if (this.last != other.last) {
          res.last = Math.max(this.last, other.last);
          invalidLast = false;
        }
        invalidLast |= thisItr.flush(res);
        invalidLast |= otherItr.flush(res);
        break;
      case ANDNOT:
        if (this.last > other.last) {
          res.last = this.last;
          invalidLast = false;
        }
        invalidLast |= thisItr.flush(res);
        break;
    }

    // remove trailing zeros
    res.trimZeros();
    if (res.isEmpty()) {
      return res;
    }

    // compute the greatest element
    if (invalidLast) {
      res.updateLast();
    }

    // compact the memory
    res.compact();

    return res;
  }"
"public static int parseInt(String num, int defaultInt) {
        if (num == null) {
            return defaultInt;
        } else {
            try {
                return Integer.parseInt(num);
            } catch (Exception e) {
                return defaultInt;
            }
        }
    }"
"protected void ensureSequenceFlowIdSet(SequenceFlow sequenceFlow) {
    // We really must have ids for sequence flow to be able to generate
    // stuff
    if (sequenceFlow.getId() == null) {
      sequenceFlow.setId(""sequenceFlow-"" + UUID.randomUUID().toString());
    }
  }"
"@Override
    public Collection<String> wordsNearestSum(Collection<String> positive, Collection<String> negative, int top) {
        INDArray words = Nd4j.create(lookupTable.layerSize());
        //    Set<String> union = SetUtils.union(new HashSet<>(positive), new HashSet<>(negative));
        for (String s : positive)
            words.addi(lookupTable.vector(s));


        for (String s : negative)
            words.addi(lookupTable.vector(s).mul(-1));

        return wordsNearestSum(words, top);
    }"
"void deleteWithChildren() {
    if (leaderboard != null) leaderboard.deleteWithChildren();

    if (gridKeys != null)
      for (Key<Grid> gridKey : gridKeys) gridKey.remove();

    // If the Frame was made here (e.g. buildspec contained a path, then it will be deleted
    if (buildSpec.input_spec.training_frame == null && origTrainingFrame != null) {
      origTrainingFrame.delete();
    }
    if (buildSpec.input_spec.validation_frame == null && validationFrame != null) {
      validationFrame.delete();
    }
    if (buildSpec.input_spec.leaderboard_frame == null && leaderboardFrame != null) {
      leaderboardFrame.delete();
    }
    delete();
  }"
"public ComputationGraph fitMultiDataSet(JavaRDD<MultiDataSet> rdd) {
        if (Nd4j.getExecutioner() instanceof GridExecutioner)
            ((GridExecutioner) Nd4j.getExecutioner()).flushQueue();

        trainingMaster.executeTrainingMDS(this, rdd);
        network.incrementEpochCount();
        return network;
    }"
"@EventListener
    public void handleCasRegisteredServiceLoadedEvent(final CasRegisteredServiceLoadedEvent event) {
        LOGGER.trace(""Received event [{}]"", event);
        this.publisher.publish(event.getRegisteredService(), event);
    }"
"public int uIntValue() throws OtpErlangRangeException {
        final long l = longValue();
        final int i = (int) l;

        if (i != l) {
            throw new OtpErlangRangeException(""Value too large for int: "" + val);
        } else if (i < 0) {
            throw new OtpErlangRangeException(""Value not positive: "" + val);
        }

        return i;
    }"
"public boolean isIgnored() {
        NodeMonitor m = ComputerSet.getMonitors().get(this);
        return m==null || m.isIgnored();
    }"
"private void init2() {
        Map<String, int[][]> personFreqMap = MyStaticValue.getPersonFreqMap();
        Set<Entry<String, int[][]>> entrySet = personFreqMap.entrySet();
        PersonNatureAttr pna = null;
        for (Entry<String, int[][]> entry : entrySet) {
            pna = pnMap.get(entry.getKey());
            if (pna == null) {
                pna = new PersonNatureAttr();
                pna.setlocFreq(entry.getValue());
                pnMap.put(entry.getKey(), pna);
            } else {
                pna.setlocFreq(entry.getValue());
            }

        }
    }"
"final void helpQuiescePool(WorkQueue w) {
        for (boolean active = true;;) {
            ForkJoinTask<?> localTask; // exhaust local queue
            while ((localTask = w.nextLocalTask()) != null)
                localTask.doExec();
            WorkQueue q = findNonEmptyStealQueue(w);
            if (q != null) {
                ForkJoinTask<?> t; int b;
                if (!active) {      // re-establish active count
                    long c;
                    active = true;
                    do {} while (!U.compareAndSwapLong
                                 (this, CTL, c = ctl, c + AC_UNIT));
                }
                if ((b = q.base) - q.top < 0 && (t = q.pollAt(b)) != null)
                    w.runSubtask(t);
            }
            else {
                long c;
                if (active) {       // decrement active count without queuing
                    active = false;
                    do {} while (!U.compareAndSwapLong
                                 (this, CTL, c = ctl, c -= AC_UNIT));
                }
                else
                    c = ctl;        // re-increment on exit
                if ((int)(c >> AC_SHIFT) + parallelism == 0) {
                    do {} while (!U.compareAndSwapLong
                                 (this, CTL, c = ctl, c + AC_UNIT));
                    break;
                }
            }
        }
    }"
"public static <E, T extends Collection<E>> T handleRsToBeanList(ResultSet rs, T collection, Class<E> elementBeanType) throws SQLException {
		final ResultSetMetaData meta = rs.getMetaData();
		final int columnCount = meta.getColumnCount();

		while (rs.next()) {
			collection.add(handleRow(columnCount, meta, rs, elementBeanType));
		}

		return collection;
	}"
"public static CauseOfBlockage fromMessage(@Nonnull final Localizable l) {
        l.getKey(); // null check
        return new CauseOfBlockage() {
            @Override
            public String getShortDescription() {
                return l.toString();
            }
        };
    }"
"@Override
	public void runFetchLoop() throws Exception {
		// the map from broker to the thread that is connected to that broker
		final Map<Node, SimpleConsumerThread<T>> brokerToThread = new HashMap<>();

		// this holds possible the exceptions from the concurrent broker connection threads
		final ExceptionProxy errorHandler = new ExceptionProxy(Thread.currentThread());

		// the offset handler handles the communication with ZooKeeper, to commit externally visible offsets
		final ZookeeperOffsetHandler zookeeperOffsetHandler = new ZookeeperOffsetHandler(kafkaConfig);
		this.zookeeperOffsetHandler = zookeeperOffsetHandler;

		PeriodicOffsetCommitter periodicCommitter = null;
		try {

			// offsets in the state may still be placeholder sentinel values if we are starting fresh, or the
			// checkpoint / savepoint state we were restored with had not completely been replaced with actual offset
			// values yet; replace those with actual offsets, according to what the sentinel value represent.
			for (KafkaTopicPartitionState<TopicAndPartition> partition : subscribedPartitionStates()) {
				if (partition.getOffset() == KafkaTopicPartitionStateSentinel.EARLIEST_OFFSET) {
					// this will be replaced by an actual offset in SimpleConsumerThread
					partition.setOffset(OffsetRequest.EarliestTime());
				} else if (partition.getOffset() == KafkaTopicPartitionStateSentinel.LATEST_OFFSET) {
					// this will be replaced by an actual offset in SimpleConsumerThread
					partition.setOffset(OffsetRequest.LatestTime());
				} else if (partition.getOffset() == KafkaTopicPartitionStateSentinel.GROUP_OFFSET) {
					Long committedOffset = zookeeperOffsetHandler.getCommittedOffset(partition.getKafkaTopicPartition());
					if (committedOffset != null) {
						// the committed offset in ZK represents the next record to process,
						// so we subtract it by 1 to correctly represent internal state
						partition.setOffset(committedOffset - 1);
					} else {
						// if we can't find an offset for a partition in ZK when using GROUP_OFFSETS,
						// we default to ""auto.offset.reset"" like the Kafka high-level consumer
						LOG.warn(""No group offset can be found for partition {} in Zookeeper;"" +
							"" resetting starting offset to 'auto.offset.reset'"", partition);

						partition.setOffset(invalidOffsetBehavior);
					}
				} else {
					// the partition already has a specific start offset and is ready to be consumed
				}
			}

			// start the periodic offset committer thread, if necessary
			if (autoCommitInterval > 0) {
				LOG.info(""Starting periodic offset committer, with commit interval of {}ms"", autoCommitInterval);

				periodicCommitter = new PeriodicOffsetCommitter(
						zookeeperOffsetHandler,
						subscribedPartitionStates(),
						errorHandler,
						autoCommitInterval);
				periodicCommitter.setName(""Periodic Kafka partition offset committer"");
				periodicCommitter.setDaemon(true);
				periodicCommitter.start();
			}

			// Main loop polling elements from the unassignedPartitions queue to the threads
			while (running) {
				// re-throw any exception from the concurrent fetcher threads
				errorHandler.checkAndThrowException();

				// wait for max 5 seconds trying to get partitions to assign
				// if threads shut down, this poll returns earlier, because the threads inject the
				// special marker into the queue
				List<KafkaTopicPartitionState<TopicAndPartition>> partitionsToAssign =
						unassignedPartitionsQueue.getBatchBlocking(5000);
				// note: if there are more markers, remove them all
				partitionsToAssign.removeIf(MARKER::equals);

				if (!partitionsToAssign.isEmpty()) {
					LOG.info(""Assigning {} partitions to broker threads"", partitionsToAssign.size());
					Map<Node, List<KafkaTopicPartitionState<TopicAndPartition>>> partitionsWithLeaders =
							findLeaderForPartitions(partitionsToAssign, kafkaConfig);

					// assign the partitions to the leaders (maybe start the threads)
					for (Map.Entry<Node, List<KafkaTopicPartitionState<TopicAndPartition>>> partitionsWithLeader :
							partitionsWithLeaders.entrySet()) {
						final Node leader = partitionsWithLeader.getKey();
						final List<KafkaTopicPartitionState<TopicAndPartition>> partitions = partitionsWithLeader.getValue();
						SimpleConsumerThread<T> brokerThread = brokerToThread.get(leader);

						if (!running) {
							break;
						}

						if (brokerThread == null || !brokerThread.getNewPartitionsQueue().isOpen()) {
							// start new thread
							brokerThread = createAndStartSimpleConsumerThread(partitions, leader, errorHandler);
							brokerToThread.put(leader, brokerThread);
						}
						else {
							// put elements into queue of thread
							ClosableBlockingQueue<KafkaTopicPartitionState<TopicAndPartition>> newPartitionsQueue =
									brokerThread.getNewPartitionsQueue();

							for (KafkaTopicPartitionState<TopicAndPartition> fp : partitions) {
								if (!newPartitionsQueue.addIfOpen(fp)) {
									// we were unable to add the partition to the broker's queue
									// the broker has closed in the meantime (the thread will shut down)
									// create a new thread for connecting to this broker
									List<KafkaTopicPartitionState<TopicAndPartition>> seedPartitions = new ArrayList<>();
									seedPartitions.add(fp);
									brokerThread = createAndStartSimpleConsumerThread(seedPartitions, leader, errorHandler);
									brokerToThread.put(leader, brokerThread);
									newPartitionsQueue = brokerThread.getNewPartitionsQueue(); // update queue for the subsequent partitions
								}
							}
						}
					}
				}
				else {
					// there were no partitions to assign. Check if any broker threads shut down.
					// we get into this section of the code, if either the poll timed out, or the
					// blocking poll was woken up by the marker element
					Iterator<SimpleConsumerThread<T>> bttIterator = brokerToThread.values().iterator();
					while (bttIterator.hasNext()) {
						SimpleConsumerThread<T> thread = bttIterator.next();
						if (!thread.getNewPartitionsQueue().isOpen()) {
							LOG.info(""Removing stopped consumer thread {}"", thread.getName());
							bttIterator.remove();
						}
					}
				}

				if (brokerToThread.size() == 0 && unassignedPartitionsQueue.isEmpty()) {
					if (unassignedPartitionsQueue.close()) {
						LOG.info(""All consumer threads are finished, there are no more unassigned partitions. Stopping fetcher"");
						break;
					}
					// we end up here if somebody added something to the queue in the meantime --> continue to poll queue again
				}
			}
		}
		catch (InterruptedException e) {
			// this may be thrown because an exception on one of the concurrent fetcher threads
			// woke this thread up. make sure we throw the root exception instead in that case
			errorHandler.checkAndThrowException();

			// no other root exception, throw the interrupted exception
			throw e;
		}
		finally {
			this.running = false;
			this.zookeeperOffsetHandler = null;

			// if we run a periodic committer thread, shut that down
			if (periodicCommitter != null) {
				periodicCommitter.shutdown();
			}

			// clear the interruption flag
			// this allows the joining on consumer threads (on best effort) to happen in
			// case the initial interrupt already
			Thread.interrupted();

			// make sure that in any case (completion, abort, error), all spawned threads are stopped
			try {
				int runningThreads;
				do {
					// check whether threads are alive and cancel them
					runningThreads = 0;
					Iterator<SimpleConsumerThread<T>> threads = brokerToThread.values().iterator();
					while (threads.hasNext()) {
						SimpleConsumerThread<?> t = threads.next();
						if (t.isAlive()) {
							t.cancel();
							runningThreads++;
						} else {
							threads.remove();
						}
					}

					// wait for the threads to finish, before issuing a cancel call again
					if (runningThreads > 0) {
						for (SimpleConsumerThread<?> t : brokerToThread.values()) {
							t.join(500 / runningThreads + 1);
						}
					}
				}
				while (runningThreads > 0);
			}
			catch (InterruptedException ignored) {
				// waiting for the thread shutdown apparently got interrupted
				// restore interrupted state and continue
				Thread.currentThread().interrupt();
			}
			catch (Throwable t) {
				// we catch all here to preserve the original exception
				LOG.error(""Exception while shutting down consumer threads"", t);
			}

			try {
				zookeeperOffsetHandler.close();
			}
			catch (Throwable t) {
				// we catch all here to preserve the original exception
				LOG.error(""Exception while shutting down ZookeeperOffsetHandler"", t);
			}
		}
	}"
"public static Color randomColor(Random random) {
		if (null == random) {
			random = RandomUtil.getRandom();
		}
		return new Color(random.nextInt(255), random.nextInt(255), random.nextInt(255));
	}"
"Driver provideHiveDriver() {
    HiveConf hiveConf = provideHiveConf();
    SessionState.start(hiveConf);

    return new Driver(hiveConf);
  }"
"public static long getLong(Properties config, String key, long defaultValue, Logger logger) {
		try {
			return getLong(config, key, defaultValue);
		} catch (IllegalArgumentException iae) {
			logger.warn(iae.getMessage());
			return defaultValue;
		}
	}"
"public void collectClient(RpcClientLookoutModel rpcClientMetricsModel) {

        try {
            Id methodConsumerId = createMethodConsumerId(rpcClientMetricsModel);
            MixinMetric methodConsumerMetric = Lookout.registry().mixinMetric(methodConsumerId);

            recordCounterAndTimer(methodConsumerMetric, rpcClientMetricsModel);

            recordSize(methodConsumerMetric, rpcClientMetricsModel);

        } catch (Throwable t) {
            LOGGER.error(LogCodes.getLog(LogCodes.ERROR_METRIC_REPORT_ERROR), t);
        }
    }"
"private static boolean parse(XMLTokener x, JSONObject context, String name) throws JSONException {
    char c;
    int i;
    String n;
    JSONObject o = null;
    String s;
    Object t;

    // Test for and skip past these forms:
    // <!-- ... -->
    // <! ... >
    // <![ ... ]]>
    // <? ... ?>
    // Report errors for these forms:
    // <>
    // <=
    // <<

    t = x.nextToken();

    // <!

    if (t == BANG) {
      c = x.next();
      if (c == '-') {
        if (x.next() == '-') {
          x.skipPast(""-->"");
          return false;
        }
        x.back();
      } else if (c == '[') {
        t = x.nextToken();
        if (t.equals(""CDATA"")) {
          if (x.next() == '[') {
            s = x.nextCDATA();
            if (s.length() > 0) {
              context.accumulate(""content"", s);
            }
            return false;
          }
        }
        throw x.syntaxError(""Expected 'CDATA['"");
      }
      i = 1;
      do {
        t = x.nextMeta();
        if (t == null) {
          throw x.syntaxError(""Missing '>' after '<!'."");
        } else if (t == LT) {
          i += 1;
        } else if (t == GT) {
          i -= 1;
        }
      } while (i > 0);
      return false;
    } else if (t == QUEST) {

      // <?

      x.skipPast(""?>"");
      return false;
    } else if (t == SLASH) {

      // Close tag </

      t = x.nextToken();
      if (name == null) {
        throw x.syntaxError(""Mismatched close tag"" + t);
      }
      if (!t.equals(name)) {
        throw x.syntaxError(""Mismatched "" + name + "" and "" + t);
      }
      if (x.nextToken() != GT) {
        throw x.syntaxError(""Misshaped close tag"");
      }
      return true;

    } else if (t instanceof Character) {
      throw x.syntaxError(""Misshaped tag"");

      // Open tag <

    } else {
      n = (String) t;
      t = null;
      o = new JSONObject();
      for (;;) {
        if (t == null) {
          t = x.nextToken();
        }

        // attribute = value

        if (t instanceof String) {
          s = (String) t;
          t = x.nextToken();
          if (t == EQ) {
            t = x.nextToken();
            if (!(t instanceof String)) {
              throw x.syntaxError(""Missing value"");
            }
            o.accumulate(s, JSONObject.stringToValue((String) t));
            t = null;
          } else {
            o.accumulate(s, """");
          }

          // Empty tag <.../>

        } else if (t == SLASH) {
          if (x.nextToken() != GT) {
            throw x.syntaxError(""Misshaped tag"");
          }
          context.accumulate(n, """");
          return false;

          // Content, between <...> and </...>

        } else if (t == GT) {
          for (;;) {
            t = x.nextContent();
            if (t == null) {
              if (n != null) {
                throw x.syntaxError(""Unclosed tag "" + n);
              }
              return false;
            } else if (t instanceof String) {
              s = (String) t;
              if (s.length() > 0) {
                o.accumulate(""content"", JSONObject.stringToValue(s));
              }

              // Nested element

            } else if (t == LT) {
              if (parse(x, o, n)) {
                if (o.length() == 0) {
                  context.accumulate(n, """");
                } else if (o.length() == 1 && o.opt(""content"") != null) {
                  context.accumulate(n, o.opt(""content""));
                } else {
                  context.accumulate(n, o);
                }
                return false;
              }
            }
          }
        } else {
          throw x.syntaxError(""Misshaped tag"");
        }
      }
    }
  }"
"@SuppressWarnings(""rawtypes"")
	public static void compareAccumulatorTypes(
			Object name,
			Class<? extends Accumulator> first,
			Class<? extends Accumulator> second) throws UnsupportedOperationException {
		if (first == null || second == null) {
			throw new NullPointerException();
		}

		if (first != second) {
			if (!first.getName().equals(second.getName())) {
				throw new UnsupportedOperationException(""The accumulator object '"" + name
					+ ""' was created with two different types: "" + first.getName() + "" and "" + second.getName());
			} else {
				// damn, name is the same, but different classloaders
				throw new UnsupportedOperationException(""The accumulator object '"" + name
						+ ""' was created with two different classes: "" + first + "" and "" + second
						+ "" Both have the same type ("" + first.getName() + "") but different classloaders: ""
						+ first.getClassLoader() + "" and "" + second.getClassLoader());
			}
		}
	}"
"private Proxy nextProxy() throws IOException {
    if (!hasNextProxy()) {
      throw new SocketException(""No route to "" + address.url().host()
          + ""; exhausted proxy configurations: "" + proxies);
    }
    Proxy result = proxies.get(nextProxyIndex++);
    resetNextInetSocketAddress(result);
    return result;
  }"
"public final void removeRun(RunT run) {
        if (!builds.remove(run)) {
            LOGGER.log(Level.WARNING, ""{0} did not contain {1} to begin with"", new Object[] {asJob(), run});
        }
    }"
"public int addScriptsFromDir (File dir) {
		logger.debug(""Adding scripts from dir: "" + dir.getAbsolutePath());
		trackedDirs.add(dir);
		int addedScripts = 0;
		for (ScriptType type : this.getScriptTypes()) {
			addedScripts += addScriptsFromDir(dir, type, null);
		}
		return addedScripts;
	}"
"public static long convertTime(long sourceDuration, TimeUnit sourceUnit, TimeUnit destUnit) {
		Assert.notNull(sourceUnit, ""sourceUnit is null !"");
		Assert.notNull(destUnit, ""destUnit is null !"");
		return destUnit.convert(sourceDuration, sourceUnit);
	}"
"public static Map<String, ? extends CacheConfig> fromYAML(InputStream inputStream) throws IOException {
        return new CacheConfigSupport().fromYAML(inputStream);
    }"
"public void processMessageToMatchUser(HttpMessage message) {
		// If the user is not yet authenticated, authenticate now
		// Make sure there are no simultaneous authentications for the same user
		synchronized (this) {
			if (this.requiresAuthentication()) {
				this.authenticate();
				if (this.requiresAuthentication()) {
					log.info(""Authentication failed for user: "" + name);
					return;
				}
			}
		}

		// Modify the message accordingly
		getContext().getSessionManagementMethod().processMessageToMatchSession(message, authenticatedSession);
	}"
"public static File getLogsRoot() {
        String tagsLogsPath = SystemProperties.getString(LOGS_ROOT_PATH_PROPERTY);
        if (tagsLogsPath == null) {
            return new File(Jenkins.get().getRootDir(), ""logs"");
        } else {
            Level logLevel = Level.INFO;
            if (ALREADY_LOGGED) {
                logLevel = Level.FINE;
            }
            LOGGER.log(logLevel,
                       ""Using non default root path for tasks logging: {0}. (Beware: no automated migration if you change or remove it again)"",
                       LOGS_ROOT_PATH_PROPERTY);
            ALREADY_LOGGED = true;
            return new File(tagsLogsPath);
        }
    }"
"public static Model loadModelGuess(InputStream stream, File tempDirectory) throws Exception {
        //Currently (Nov 2017): KerasModelImport doesn't support loading from input streams
        //Simplest solution here: write to a temporary file
        File f;
        if(tempDirectory == null){
            f = DL4JFileUtils.createTempFile(""loadModelGuess"","".bin"");
        } else {
            f = File.createTempFile(""loadModelGuess"", "".bin"", tempDirectory);
        }
        f.deleteOnExit();


        try (OutputStream os = new BufferedOutputStream(new FileOutputStream(f))) {
            IOUtils.copy(stream, os);
            os.flush();
            return loadModelGuess(f.getAbsolutePath());
        } catch (ModelGuesserException e){
            throw new ModelGuesserException(""Unable to load model from input stream (invalid model file not a known model type)"");
        } finally {
            f.delete();
        }
    }"
"public List<List<Writable>> executeSequence(List<List<Writable>> inputSequence) {
        return executeSequenceToSequence(inputSequence);
    }"
"public void set(String name, String value) {
        getOverlay().setProperty(name, value);
        getProps().setProperty(name, value);
    }"
"public static void writeToPath(BitMatrix matrix, String format, Path file) throws IOException {
    writeToPath(matrix, format, file, DEFAULT_CONFIG);
  }"
"protected void persistProcessDefinitionsAndAuthorizations(ParsedDeployment parsedDeployment) {
        CommandContext commandContext = Context.getCommandContext();
        ProcessDefinitionEntityManager processDefinitionManager = commandContext.getProcessDefinitionEntityManager();

        for (ProcessDefinitionEntity processDefinition : parsedDeployment.getAllProcessDefinitions()) {
            processDefinitionManager.insert(processDefinition,
                                            false);
            bpmnDeploymentHelper.addAuthorizationsForNewProcessDefinition(parsedDeployment.getProcessModelForProcessDefinition(processDefinition),
                                                                          processDefinition);
        }
    }"
"public static void genId(Object target, String property, Class<? extends GenId> genClass, String table, String column) throws MapperException {
        try {
            GenId genId;
            if (CACHE.containsKey(genClass)) {
                genId = CACHE.get(genClass);
            } else {
                LOCK.lock();
                try {
                    if (!CACHE.containsKey(genClass)) {
                        CACHE.put(genClass, genClass.newInstance());
                    }
                    genId = CACHE.get(genClass);
                } finally {
                    LOCK.unlock();
                }
            }
            MetaObject metaObject = MetaObjectUtil.forObject(target);
            if (metaObject.getValue(property) == null) {
                Object id = genId.genId(table, column);
                metaObject.setValue(property, id);
            }
        } catch (Exception e) {
            throw new MapperException(""生成 ID 失败!"", e);
        }
    }"
"public JSONStringer value(Object value) throws JSONException {
		if (this.stack.isEmpty()) {
			throw new JSONException(""Nesting problem"");
		}

		if (value instanceof JSONArray) {
			((JSONArray) value).writeTo(this);
			return this;

		}
		else if (value instanceof JSONObject) {
			((JSONObject) value).writeTo(this);
			return this;
		}

		beforeValue();

		if (value == null || value instanceof Boolean || value == JSONObject.NULL) {
			this.out.append(value);

		}
		else if (value instanceof Number) {
			this.out.append(JSONObject.numberToString((Number) value));

		}
		else {
			string(value.toString());
		}

		return this;
	}"
"public boolean isValidInfrastructureTld(String iTld) {
        final String key = chompLeadingDot(unicodeToASCII(iTld).toLowerCase(Locale.ENGLISH));
        return arrayContains(INFRASTRUCTURE_TLDS, key);
    }"
"@Override
	public void invoke(IN value) throws Exception {
		byte[] msg = schema.serialize(value);

		try {
			outputStream.write(msg);
			if (autoFlush) {
				outputStream.flush();
			}
		}
		catch (IOException e) {
			// if no re-tries are enable, fail immediately
			if (maxNumRetries == 0) {
				throw new IOException(""Failed to send message '"" + value + ""' to socket server at ""
						+ hostName + "":"" + port + "". Connection re-tries are not enabled."", e);
			}

			LOG.error(""Failed to send message '"" + value + ""' to socket server at "" + hostName + "":"" + port +
					"". Trying to reconnect..."" , e);

			// do the retries in locked scope, to guard against concurrent close() calls
			// note that the first re-try comes immediately, without a wait!

			synchronized (lock) {
				IOException lastException = null;
				retries = 0;

				while (isRunning && (maxNumRetries < 0 || retries < maxNumRetries)) {

					// first, clean up the old resources
					try {
						if (outputStream != null) {
							outputStream.close();
						}
					}
					catch (IOException ee) {
						LOG.error(""Could not close output stream from failed write attempt"", ee);
					}
					try {
						if (client != null) {
							client.close();
						}
					}
					catch (IOException ee) {
						LOG.error(""Could not close socket from failed write attempt"", ee);
					}

					// try again
					retries++;

					try {
						// initialize a new connection
						createConnection();

						// re-try the write
						outputStream.write(msg);

						// success!
						return;
					}
					catch (IOException ee) {
						lastException = ee;
						LOG.error(""Re-connect to socket server and send message failed. Retry time(s): "" + retries, ee);
					}

					// wait before re-attempting to connect
					lock.wait(CONNECTION_RETRY_DELAY);
				}

				// throw an exception if the task is still running, otherwise simply leave the method
				if (isRunning) {
					throw new IOException(""Failed to send message '"" + value + ""' to socket server at ""
							+ hostName + "":"" + port + "". Failed after "" + retries + "" retries."", lastException);
				}
			}
		}
	}"
"public final long getUlong40(final int pos) {
        final int position = origin + pos;

        if (pos + 4 >= limit || pos < 0) throw new IllegalArgumentException(""limit excceed: ""
                                                                            + (pos < 0 ? pos : (pos + 4)));

        byte[] buf = buffer;
        return ((long) (0xff & buf[position])) | ((long) (0xff & buf[position + 1]) << 8)
               | ((long) (0xff & buf[position + 2]) << 16) | ((long) (0xff & buf[position + 3]) << 24)
               | ((long) (0xff & buf[position + 4]) << 32);
    }"
"public void removeApplication(Application app) {
        this.appNameApplicationMap.remove(app.getName().toUpperCase(Locale.ROOT));
        this.applications.remove(app);
    }"
"@Override
	public void notifyLeaderAddress(String leaderAddress, UUID leaderSessionID) {
		future.complete(new LeaderAddressAndId(leaderAddress, leaderSessionID));
	}"
"private void enableUnsafeSSLRenegotiationCheckBoxActionPerformed(java.awt.event.ActionEvent evt) {
		
		boolean enabled = enableUnsafeSSLRenegotiationCheckBox.isSelected();
		
		if (enabled) {
			JOptionPane.showMessageDialog(null, new String[] {
					Constant.messages.getString(""options.cert.label.enableunsafesslrenegotiationwarning"")}, 
					Constant.messages.getString(""options.cert.label.enableunsafesslrenegotiation""), JOptionPane.INFORMATION_MESSAGE);
		}
	}"
"private M invalidMessage(Exception cause) {
        state = State.BAD_MESSAGE;
        M message = buildInvalidMessage();
        message.setDecoderResult(DecoderResult.failure(cause));
        return message;
    }"
"public static int maxFill(int n, float f) {
		return Math.min((int) Math.ceil((double) ((float) n * f)), n - 1);
	}"
"public void initializeSerializerUnlessSet(ExecutionConfig executionConfig) {
		if (serializer == null) {
			checkState(typeInfo != null, ""no serializer and no type info"");

			// instantiate the serializer
			serializer = typeInfo.createSerializer(executionConfig);

			// we can drop the type info now, no longer needed
			typeInfo  = null;
		}
	}"
"protected void execute(InputStream input, OutputStream output, C context) throws IOException {
        final ApplicationContext applicationContext = buildApplicationContext(context);
        if (context == null) {
            context = (C) applicationContext;
        }

        final Environment env = startEnvironment(applicationContext);
        final String functionName = resolveFunctionName(env);

        if (functionName == null) {
            throw new InvocationException(""No Function name configured. Set 'micronaut.function.name' in your Function configuration"");
        }

        LocalFunctionRegistry localFunctionRegistry = applicationContext.getBean(LocalFunctionRegistry.class);
        ExecutableMethod<Object, Object> method = resolveFunction(localFunctionRegistry, functionName);
        Class<?> returnJavaType = method.getReturnType().getType();
        if (ClassLoadingReporter.isReportingEnabled()) {
            ClassLoadingReporter.reportBeanPresent(returnJavaType);
        }

        Argument[] requiredArguments = method.getArguments();
        int argCount = requiredArguments.length;
        Object result;
        Qualifier<Object> qualifier = Qualifiers.byName(functionName);
        Class<Object> functionType = method.getDeclaringType();
        BeanDefinition<Object> beanDefinition = applicationContext.getBeanDefinition(functionType, qualifier);
        Object bean = applicationContext.getBean(functionType, qualifier);
        List<Argument<?>> typeArguments = beanDefinition.getTypeArguments();

        try {
            switch (argCount) {
                case 0:
                    result = method.invoke(bean);
                    break;
                case 1:

                    Argument arg = requiredArguments[0];
                    if (!typeArguments.isEmpty()) {
                        arg = Argument.of(typeArguments.get(0).getType(), arg.getName());
                    }
                    Object value = decodeInputArgument(env, localFunctionRegistry, arg, input);
                    result = method.invoke(bean, value);
                    break;
                case 2:
                    Argument firstArgument = requiredArguments[0];
                    Argument secondArgument = requiredArguments[1];

                    if (!typeArguments.isEmpty()) {
                        firstArgument = Argument.of(typeArguments.get(0).getType(), firstArgument.getName());
                    }

                    Object first = decodeInputArgument(env, localFunctionRegistry, firstArgument, input);
                    Object second = decodeContext(env, secondArgument, context);
                    result = method.invoke(bean, first, second);
                    break;
                default:
                    throw new InvocationException(""Function ["" + functionName + ""] cannot be made executable."");
            }
            if (result != null) {
                encode(env, localFunctionRegistry, returnJavaType, result, output);
            }
        } finally {
            closeApplicationContext();
        }
    }"
"public Long getLong(String key, String group) {
		return getLong(key, group, null);
	}"
"@SuppressWarnings(""unused"")
  public void addAll(ScalingStats stats)
  {
    synchronized (lock) {
      synchronized (stats.lock) {
        recentEvents.addAll(stats.recentEvents);
      }
    }
  }"
"@Override
    public void init(VoidConfiguration voidConfiguration, Clipboard clipboard, NodeRole role, String localIp,
                    int localPort, short shardIndex) {
        //Runtime.getRuntime().addShutdownHook(new Thread(() -> shutdownSilent()));
    }"
"public static void readFully(final InputStream in, final byte[] buf, int off, final int len)
			throws IOException {
		int toRead = len;
		while (toRead > 0) {
			final int ret = in.read(buf, off, toRead);
			if (ret < 0) {
				throw new IOException(""Premeture EOF from inputStream"");
			}
			toRead -= ret;
			off += ret;
		}
	}"
"public synchronized Object get(final long timeout)
            throws InterruptedException {
        if (status == closed) {
            return null;
        }

        long currentTime = System.currentTimeMillis();
        final long stopTime = currentTime + timeout;
        Object o = null;

        while (true) {
            if ((o = tryGet()) != null) {
                return o;
            }

            currentTime = System.currentTimeMillis();
            if (stopTime <= currentTime) {
                throw new InterruptedException(""Get operation timed out"");
            }

            try {
                this.wait(stopTime - currentTime);
            } catch (final InterruptedException e) {
                // ignore, but really should retry operation instead
            }
        }
    }"
"public static ExpectedCondition<Boolean> textToBePresentInElementValue(final WebElement element,
                                                                         final String text) {

    return new ExpectedCondition<Boolean>() {
      @Override
      public Boolean apply(WebDriver driver) {
        try {
          String elementText = element.getAttribute(""value"");
          if (elementText != null) {
            return elementText.contains(text);
          }
          return false;
        } catch (StaleElementReferenceException e) {
          return null;
        }
      }

      @Override
      public String toString() {
        return String.format(""text ('%s') to be the value of element %s"", text, element);
      }
    };
  }"
"public URLNormalizer addDomainTrailingSlash() {
        String urlRoot = HttpURL.getRoot(url);
        String path = toURL().getPath();
        if (StringUtils.isNotBlank(path)) {
            // there is a path so do nothing
            return this;
        }
        String urlRootAndPath = urlRoot + ""/"";
        url = StringUtils.replaceOnce(url, urlRoot, urlRootAndPath);
        return this;
    }"
"public static void setElementWiseStride(IntBuffer buffer, int elementWiseStride) {
        int length2 = shapeInfoLength(buffer.get(0));
        //        if (1 > 0) throw new RuntimeException(""setElementWiseStride called: ["" + elementWiseStride + ""], buffer: "" + bufferToString(buffer));
        buffer.put(length2 - 2, elementWiseStride);
    }"
"public void addHttpSessionToken(String site, String token) {
		// Add a default port
		if (!site.contains("":"")) {
			site = site + ("":80"");
		}
		HttpSessionTokensSet siteTokens = sessionTokens.get(site);
		if (siteTokens == null) {
			siteTokens = new HttpSessionTokensSet();
			sessionTokens.put(site, siteTokens);
		}

		if (log.isDebugEnabled()) {
			log.debug(""Added new session token for site '"" + site + ""': "" + token);
		}

		siteTokens.addToken(token);
		// If the session token is a default token and was previously marked as remove, undo that
		unmarkRemovedDefaultSessionToken(site, token);
	}"
"public List<AbstractPanel> getVisiblePanels() {
        List<AbstractPanel> panels = getPanels();
        for (Iterator<AbstractPanel> it = panels.iterator(); it.hasNext();) {
            if (hiddenTabs.contains(it.next())) {
                it.remove();
            }
        }
        return panels;
    }"
"public void movedTo(DirectlyModifiableTopLevelItemGroup destination, AbstractItem newItem, File destDir) throws IOException {
        newItem.onLoad(destination, name);
    }"
"public static void deleteContentsRecursive(@Nonnull File file) throws IOException {
        deleteContentsRecursive(fileToPath(file), PathRemover.PathChecker.ALLOW_ALL);
    }"
"public static long unixTimestamp(String dateStr, String format, TimeZone tz) {
		long ts = parseToTimeMillis(dateStr, format, tz);
		if (ts == Long.MIN_VALUE) {
			return Long.MIN_VALUE;
		} else {
			// return the seconds
			return ts / 1000;
		}
	}"
"public static String quote(String s)
    {
        if (s==null)
            return null;
        if (s.length()==0)
            return ""\""\"""";

        StringBuffer b=new StringBuffer(s.length()+8);
        quote(b,s);
        return b.toString();

    }"
"public void saveAsFile(List<String> labels, String path) throws IOException {
        BufferedWriter write = null;
        try {
            write = new BufferedWriter(new FileWriter(new File(path)));
            for (int i = 0; i < Y.rows(); i++) {
                if (i >= labels.size())
                    break;
                String word = labels.get(i);
                if (word == null)
                    continue;
                StringBuilder sb = new StringBuilder();
                INDArray wordVector = Y.getRow(i);
                for (int j = 0; j < wordVector.length(); j++) {
                    sb.append(wordVector.getDouble(j));
                    if (j < wordVector.length() - 1)
                        sb.append("","");
                }

                sb.append("","");
                sb.append(word);
                sb.append(""\n"");
                write.write(sb.toString());

            }
            write.flush();
            write.close();
        } finally {
            if (write != null)
                write.close();
        }
    }"
"protected void checkMethods(Class<?> itfClass) {
        ConcurrentHashMap<String, Boolean> methodsLimit = new ConcurrentHashMap<String, Boolean>();
        for (Method method : itfClass.getMethods()) {
            String methodName = method.getName();
            if (methodsLimit.containsKey(methodName)) {
                // 重名的方法
                if (LOGGER.isWarnEnabled(providerConfig.getAppName())) {
                    LOGGER.warnWithApp(providerConfig.getAppName(), ""Method with same name \"""" + itfClass.getName()
                        + ""."" + methodName + ""\"" exists ! The usage of overloading method in rpc is deprecated."");
                }
            }
            // 判断服务下方法的黑白名单
            Boolean include = methodsLimit.get(methodName);
            if (include == null) {
                include = inList(providerConfig.getInclude(), providerConfig.getExclude(), methodName); // 检查是否在黑白名单中
                methodsLimit.putIfAbsent(methodName, include);
            }
            providerConfig.setMethodsLimit(methodsLimit);
        }
    }"
"public MapConfig buildMapConfig(final BaseHazelcastProperties hz, final String mapName, final long timeoutSeconds) {
        val cluster = hz.getCluster();
        val evictionPolicy = EvictionPolicy.valueOf(cluster.getEvictionPolicy());

        LOGGER.trace(""Creating Hazelcast map configuration for [{}] with idle timeoutSeconds [{}] second(s)"", mapName, timeoutSeconds);
        val maxSizeConfig = new MaxSizeConfig()
            .setMaxSizePolicy(MaxSizeConfig.MaxSizePolicy.valueOf(cluster.getMaxSizePolicy()))
            .setSize(cluster.getMaxHeapSizePercentage());

        val mergePolicyConfig = new MergePolicyConfig();
        if (StringUtils.hasText(cluster.getMapMergePolicy())) {
            mergePolicyConfig.setPolicy(cluster.getMapMergePolicy());
        }

        return new MapConfig()
            .setName(mapName)
            .setMergePolicyConfig(mergePolicyConfig)
            .setMaxIdleSeconds((int) timeoutSeconds)
            .setBackupCount(cluster.getBackupCount())
            .setAsyncBackupCount(cluster.getAsyncBackupCount())
            .setEvictionPolicy(evictionPolicy)
            .setMaxSizeConfig(maxSizeConfig);
    }"
"public <L, R> SingleOutputStreamOperator<R> select(
			final OutputTag<L> timedOutPartialMatchesTag,
			final PatternTimeoutFunction<T, L> patternTimeoutFunction,
			final PatternSelectFunction<T, R> patternSelectFunction) {

		final TypeInformation<R> rightTypeInfo = TypeExtractor.getUnaryOperatorReturnType(
			patternSelectFunction,
			PatternSelectFunction.class,
			0,
			1,
			TypeExtractor.NO_INDEX,
			builder.getInputType(),
			null,
			false);

		return select(
			timedOutPartialMatchesTag,
			patternTimeoutFunction,
			rightTypeInfo,
			patternSelectFunction);
	}"
